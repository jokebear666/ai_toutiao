# 20251229-20260104

## 2025-12-29

**cs.DC total: 16**

- **[arXiv251229] Harnessing Data Spaces to Build Intelligent Smart City Infrastructures Across the Cloud-Edge Continuum**
  - **tags:** [mlsys], [on-device ai], [data spaces, cloud-edge continuum, containerized microservices, edge AI, intelligent infrastructure monitoring]
  - **authors:** Dimitrios Amaxilatis, Themistoklis Sarantakos, Nikolaos Tsironis, Souvik Sengupta, Kostas Ramantas, Jhofre Ojeda
  - **institution:** Spark Works Ltd., IONOS SE, Iquadrat Informática S.L.
  - **link:** https://arxiv.org/pdf/2512.21340
  - **contributions:** 1. A real-world implementation of intelligent infrastructure monitoring within a data space-enabled cloud-edge framework, demonstrating practical integration. 2. Leveraging edge computing, containerized microservices, and interoperable data sharing to address challenges like sensor integration, data privacy, and scalability. 3. Showcasing the training and deployment of AI/ML services directly at the edge for optimized resource use and timely decision-making in smart city applications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a real-world use case for smart cities, implementing an intelligent climate monitoring system within a cloud-edge continuum framework enabled by data spaces. The method combines edge computing, containerized microservices, and secure data sharing to facilitate localized analytics and AI deployment. The conclusion highlights the transformative potential of integrating AI, edge computing, and data spaces for building efficient and resilient smart city infrastructures.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Harnessing Data Spaces for Smart City Infrastructures] --> B[核心问题/Problem: Enhancing smart city efficiency, sustainability, and resilience with secure, interoperable data exchange]
        A --> C[主要方法/Method: Data space-enabled cloud-edge framework with edge computing, containerized microservices, and edge AI/ML]
        A --> D[关键结果/Results: Demonstrates practical use case for intelligent monitoring, enabling localized analytics, real-time inference, and trusted data collaboration]
    ```

- **[arXiv251229] DeepCQ: General-Purpose Deep-Surrogate Framework for Lossy Compression Quality Prediction**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [lossy compression, quality prediction, deep-surrogate, mixture-of-experts, feature-extraction]
  - **authors:** Khondoker Mirazul Mumenin, Robert Underwood, Dong Dai, Jinzhen Wang, Sheng Di, Zarija Lukić, Franck Cappello
  - **institution:** University of North Carolina at Charlotte, Argonne National Laboratory, University of Delaware, Lawrence Berkeley National Laboratory
  - **link:** https://arxiv.org/pdf/2512.21433
  - **contributions:** 1) A generalizable surrogate model for predicting compression quality across different compressors, quality metrics, and datasets. 2) A novel two-stage design that decouples expensive feature extraction from lightweight prediction for efficient training and modular inference. 3) A mixture-of-experts design to optimize performance and robustness for time-evolving scientific data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06e831f83754144a92a117a184fdcc51da0584d4163390cf94b34d4175b77a1_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes DeepCQ, a deep-surrogate framework to efficiently predict the quality of data after lossy compression, which is traditionally computationally expensive to assess. The method uses a two-stage and mixture-of-experts design for generalizability and robustness across different compressors, metrics, and time-evolving datasets. The framework achieves high predictive accuracy (errors under 10%) on real-world applications, enabling informed compression decisions and reducing I/O and computational overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DeepCQ: 通用深度代理框架用于有损压缩质量预测] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[评估压缩后数据质量的计算成本高/Expensive to assess post-compression data quality]
        C --> C1[两阶段设计: 特征提取 + 轻量预测/Two-stage design: feature extraction + lightweight prediction]
        C --> C2[专家混合设计处理时变数据/Mixture-of-experts for time-evolving data]
        D --> D1[预测误差普遍低于10%/Prediction errors generally under 10%]
        D --> D2[显著优于现有方法/Significantly outperforms existing methods]
    ```

- **[arXiv251229] Demystifying ARM SME to Optimize General Matrix Multiplications**
  - **tags:** [mlsys], [gpu kernels], [ARM SME, GEMM, cache-aware partitioning, micro-kernels, on-the-fly transposition]
  - **authors:** Chencheng Deng, Weiling Yang, Jianbin Fang, Dezun Dong
  - **institution:** College of Computer Science and Technology, National University of Defense Technology
  - **link:** https://arxiv.org/pdf/2512.21473
  - **contributions:** 1. A systematic characterization of the ARM SME architecture that derives optimization guidelines for GEMM. 2. The design and implementation of MpGEMM, an open-source library featuring cache-aware partitioning and efficient data packing with on-the-fly transposition. 3. Specialized micro-kernels that fully utilize SME's multi-vector loads and all available tile registers to maximize performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bc3a0f3452bf6376dcfa53f5f9e56a621c5b526537a2008e7f55c112b765095_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the underutilization of ARM's Scalable Matrix Extension (SME) hardware for large-scale General Matrix Multiplication (GEMM). It proposes MpGEMM, an open-source library that optimizes GEMM through cache-aware partitioning, efficient data packing, and specialized micro-kernels tailored for SME. Evaluations on an Apple M4 Pro show MpGEMM achieves a 1.23x speedup over the vendor-optimized Apple Accelerate library.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Demystifying ARM SME to Optimize General Matrix Multiplications") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("现有库未能充分利用ARM SME硬件/Existing libraries fail to exploit ARM SME")
        Problem --> P2("大规模GEMM性能瓶颈/Large-scale GEMM performance bottlenecks")
        Method --> M1("系统化架构分析/Systematic SME characterization")
        Method --> M2("设计MpGEMM库/Design MpGEMM library")
        M2 --> M2a("缓存感知分区/Cache-aware partitioning")
        M2 --> M2b("高效数据打包/Efficient data packing")
        M2 --> M2c("专用微内核/Specialized micro-kernels")
        Results --> R1("性能超越Apple Accelerate库/Outperforms Apple Accelerate")
        Results --> R2("显著优于其他开源方案/Significantly beats other open-source alternatives")
    ```

- **[arXiv251229] Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism**
  - **tags:** [mlsys], [llm inference], [mixture-of-experts (MoE), disaggregated expert parallelism (DEP), task scheduling, inference throughput, fine-grained pipelining]
  - **authors:** Xinglin Pan, Shaohuai Shi, Wenxiang Lin, Yuxin Wang, Zhenheng Tang, Wei Wang, Xiaowen Chu
  - **institution:** The Hong Kong University of Science and Technology (Guangzhou), Harbin Institute of Technology (Shenzhen), Hong Kong Baptist University, The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.21487
  - **contributions:** 1) Partitioning intensive computation and communication tasks into smaller, fine-grained tasks to enable pipelining, including support for shared experts. 2) Formulating a fine-grained task scheduling optimization problem that supports variable task granularity and ordering. 3) Developing an efficient solver to navigate the large solution space and derive a near-optimal task schedule.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the memory-intensive inference problem in Mixture-of-Experts (MoE) models by proposing FinDEP, a fine-grained task scheduling algorithm for Disaggregated Expert Parallelism (DEP). FinDEP improves inference throughput by maximizing task overlap through computational partitioning and optimized scheduling. Experiments on systems with up to 32 GPUs show throughput improvements of up to 1.61x over prior methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FinDEP: Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[MoE推理内存密集，现有DEP调度效率低/MoE inference is memory-intensive, existing DEP scheduling is inefficient]
        C --> C1[细粒度任务划分与调度优化/Fine-grained task partitioning and scheduling optimization]
        D --> D1[吞吐量最高提升1.61倍/Throughput improved by up to 1.61x]
    ```

- **[arXiv251229] nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures**
  - **tags:** [mlsys], [compiler & ir], [e-graph, term rewriting, phase ordering, NUMA abstraction, auto vectorize]
  - **authors:** Hui Guo, Qihang Zheng, Chenghai Huo, Dongliang Guo, Haoqi Yang, Yang Zhang
  - **institution:** Canaan Inc.
  - **link:** https://arxiv.org/pdf/2512.21571
  - **code:** https://github.com/kendryte/nncase
  - **contributions:** 1. Proposes an end-to-end compilation framework (nncase) that unifies LLM deployment across heterogeneous memory architectures using a NUMA abstraction for a "compile once, adapt everywhere" capability. 2. Introduces an e-graph-based term rewriting engine with equality saturation to mitigate the phase ordering problem and enable global optimization of computation and data movement. 3. Integrates three key automated optimization modules: Auto Vectorize for heterogeneous computing units, Auto Distribution for parallel strategies with communication optimization, and Auto Schedule for on-chip cache locality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a555b38ecd80e8c11606362e5402405bbf0053e11754e06f720d50ce213ee0d_w640_q70.webp
  - **Simple LLM Summary:** The paper presents nncase, an end-to-end compiler framework designed to tackle the challenge of efficiently deploying large language models on heterogeneous memory architectures. Its core innovation is an e-graph-based rewriting engine that avoids the phase ordering problem, enabling unified optimization across diverse hardware targets. Evaluations show nncase outperforms frameworks like MLC LLM and Intel IPEX, achieving performance close to hand-optimized llama.cpp, demonstrating the viability of automated compilation for high-performance LLM deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures] --> B[核心问题/Problem: LLM部署受限于内存架构异构性，传统编译器流程碎片化/Memory architecture heterogeneity hinders efficient LLM deployment, traditional compilers have fragmented workflows.]
        A --> C[主要方法/Method: 基于e-graph的项重写引擎，统一NUMA抽象，集成自动向量化、分布、调度模块/E-graph-based term rewriting engine, unified NUMA abstraction, integrates Auto Vectorize, Distribution, Schedule modules.]
        A --> D[关键结果/Results: 性能超越MLC LLM和Intel IPEX，接近手工优化的llama.cpp/Outperforms MLC LLM & Intel IPEX, achieves performance comparable to hand-optimized llama.cpp.]
    ```

- **[arXiv251229] Embedding Samples Dispatching for Recommendation Model Training in Edge Environments**
  - **tags:** [mlsys], [memory & caching], [edge computing, embedding cache, parameter server, sample dispatching, transmission cost]
  - **authors:** Guopeng Li, Haisheng Tan, Chi Zhang, Hongqiu Ni, Zilong Wang, Xinyue Zhang, Yang Xu, Han Tian
  - **institution:** University of Science and Technology of China (USTC), Hefei University of Technology
  - **link:** https://arxiv.org/pdf/2512.21615
  - **contributions:** 1. Proposed ESD, a novel mechanism to optimize the dispatch of input embedding samples to edge workers to minimize embedding transmission cost. 2. Designed HybridDis, a dispatch decision method that combines an optimal algorithm and a heuristic to balance decision quality and resource consumption. 3. Implemented a prototype and demonstrated significant reductions in transmission cost (up to 36.76%) and training speedup (up to 1.74x) on real-world workloads.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f94cc43f65f5fd909f8762bda535a33eea94f879931ebe1a563280cb0db1be81_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high communication cost of embedding transmission during Deep Learning Recommendation Model (DLRM) training in edge environments. It proposes ESD, a mechanism that dispatches input samples to edge workers to minimize expected transmission cost, using a hybrid decision method called HybridDis. Experimental results show that ESD significantly reduces transmission cost and speeds up end-to-end training compared to state-of-the-art methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Embedding Samples Dispatching for Recommendation Model Training in Edge Environments<br>边缘环境中推荐模型训练的嵌入样本调度"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>DLRM边缘训练中嵌入传输成本高"] --> P1["挑战/Challenges<br>异构网络，资源受限"]
        Method["主要方法/Method<br>ESD机制与HybridDis调度"] --> M1["方法核心/Core<br>基于预期传输成本的样本调度"]
        Results["关键结果/Results<br>减少传输成本，加速训练"] --> R1["性能提升/Improvement<br>成本降低36.76%，速度提升1.74倍"]
    ```

- **[arXiv251229] LEFT-RS: A Lock-Free Fault-Tolerant Resource Sharing Protocol for Multicore Real-Time Systems**
  - **tags:** [sys], [real-time systems], [lock-free, fault-tolerance, resource sharing, multicore, worst-case response time analysis]
  - **authors:** Nan Chen, Xiaotian Dai, Tong Cheng, Alan Burns, Iain Bate, Shuai Zhao
  - **institution:** University of York, Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.21701
  - **contributions:** 1. Proposes the LEFT-RS protocol, a lock-free design that allows concurrent read access to global resources and parallel entry into critical sections, improving efficiency. 2. Enhances fault resilience by limiting overhead and enabling tasks to complete earlier if others experience faults, reducing blocking. 3. Provides a comprehensive worst-case response time analysis to ensure timing guarantees for the proposed protocol.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb19a780f9199527b92c55981536e4b4108e6135efe187882739942a46ebf5ed_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes LEFT-RS, a lock-free and fault-tolerant resource sharing protocol for multicore real-time systems. It allows tasks to concurrently access resources and enter critical sections in parallel, improving efficiency and resilience to transient faults. Evaluation shows it significantly outperforms existing methods, achieving up to an 84.5% average improvement in schedulability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[LEFT-RS: A Lock-Free Fault-Tolerant Resource Sharing Protocol] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Faults in critical sections cause error propagation; locking protocols lack fault tolerance, increasing blocking.]
        Method[主要方法/Method: LEFT-RS protocol enables concurrent read access and parallel critical section entry for fault resilience.]
        Results[关键结果/Results: Up to 84.5% average schedulability improvement over existing approaches.]
    ```

- **[arXiv251229] Hyperion: Low-Latency Ultra-HD Video Analytics via Collaborative Vision Transformer Inference**
  - **tags:** [mlsys], [multi-modal inference], [vision transformer, cloud-device collaboration, dynamic scheduling, patch-level importance, weighted ensembling]
  - **authors:** Linyi Jiang, Yifei Zhu, Hao Yin, Bo Li
  - **institution:** Shanghai Jiao Tong University, Tsinghua University, Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.21730
  - **contributions:** 1. A collaboration-aware importance scorer that identifies critical regions at the patch level for selective processing. 2. A dynamic scheduler that adaptively adjusts patch transmission quality to balance latency and accuracy under changing network conditions. 3. A weighted ensembler that fuses edge and cloud inference results to improve overall accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/883099a5be7486c0821b7ffc4858fa9de1fb7c6f3487310e5eb913db9f04c63e_w640_q70.webp
  - **Simple LLM Summary:** This paper presents Hyperion, a cloud-device collaborative framework designed to enable low-latency inference on Ultra-HD video using off-the-shelf vision transformers. It tackles computational and transmission bottlenecks by selectively processing critical patches, dynamically adjusting transmission quality, and fusing results. Experiments show Hyperion improves frame processing rate by up to 1.61x and accuracy by up to 20.2% compared to baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Hyperion: Low-Latency Ultra-HD Video Analytics<br>Hyperion: 低延迟超高清视频分析] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Ultra-HD视频处理的计算与传输瓶颈<br>Computational & Transmission Bottleneck for Ultra-HD Video]
        C[主要方法/Method<br>云-端协作的Vision Transformer推理框架<br>Cloud-Device Collaborative ViT Inference Framework]
        D[关键结果/Results<br>处理率提升1.61倍，准确率提升20.2%<br>1.61x Faster Frame Rate, 20.2% Higher Accuracy]
    ```

- **[arXiv251229] Smart IoT-Based Leak Forecasting and Detection for Energy-Efficient Liquid Cooling in AI Data Centers**
  - **tags:** [mlsys], [cluster infrastructure], [LSTM, Random Forest, MQTT, InfluxDB, Streamlit]
  - **authors:** Krishna Chaitanya Sunkara, Rambabu Konakanchi
  - **institution:** Oracle, Charles Schwab
  - **link:** https://arxiv.org/pdf/2512.21801
  - **contributions:** 1. Probabilistic LSTM forecasting validated within ±30-minute windows for coolant leaks, 2. 96.5% F1-score Random Forest detection for immediate leak identification, 3. Integrated smart IoT architecture design with MQTT streaming, InfluxDB storage, and Streamlit dashboards for energy-efficient data center operations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa113d59b2dc6ec7a3bf00f9eebc8541689a6235867cf59ce376cdcfa30a2a5c_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes a smart IoT monitoring system combining LSTM neural networks for probabilistic leak forecasting and Random Forest classifiers for instant detection in liquid-cooled AI data centers. The system, tested on synthetic data, achieves 96.5% detection accuracy and 87% forecasting accuracy, potentially preventing significant energy waste through proactive maintenance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Smart IoT-Based Leak Forecasting and Detection] --> B[核心问题/Problem: Coolant leaks cause energy loss in AI data centers]
        A --> C[主要方法/Method: LSTM for forecasting + Random Forest for detection with IoT sensors]
        A --> D[关键结果/Results: 96.5% detection accuracy, 87% forecasting accuracy, 1,500 kWh energy saved]
    ```

- **[arXiv251229] LIME:Accelerating Collaborative Lossless LLM Inference on Memory-Constrained Edge Devices**
  - **tags:** [mlsys], [llm inference], [collaborative inference, pipeline parallelism, model offloading, memory adaptation, edge computing]
  - **authors:** Mingyu Sun, Xiao Zhang, Shen Qu, Yan Li, Mengbai Xiao, Yuan Yuan, Dongxiao Yu
  - **institution:** Shandong University
  - **link:** https://arxiv.org/pdf/2512.21835
  - **contributions:** 1. Proposes LIME, a collaborative system for lossless LLM inference across multiple memory-constrained edge devices under limited bandwidth. 2. Employs an interleaved pipeline parallelism with model offloading to dynamically balance computation and communication. 3. Introduces a fine-grained offline allocation scheduler and an online memory adaptation strategy to optimize resource usage and minimize inference latency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d2da6a7be206646ebc1b92d8a0053408a991ec073254f89b4182ecdc54fe1b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes LIME, a system that enables lossless, collaborative LLM inference on multiple memory-constrained edge devices by using interleaved pipeline parallelism and model offloading, along with offline scheduling and online memory adaptation. Experiments on four Nvidia Jetson devices with LLaMA3.3-70B show that LIME achieves significant speedups over baselines without accuracy loss.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[LIME: 协作式无损LLM推理 / Collaborative Lossless LLM Inference] --> Problem[边缘设备内存受限 / Memory-Constrained Edge Devices]
        Root --> Method[交织流水线并行与模型卸载 / Interleaved Pipeline Parallelism & Offloading]
        Root --> Results[实现无损加速 / Achieves Lossless Speedup]
    ```

- **[arXiv251229] Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models**
  - **tags:** [mlsys], [llm inference], [distributed inference, block placement, request routing, performance modeling, resource allocation]
  - **authors:** Tingyang Sun, Ting He, Bo Ji, Parimal Parag
  - **institution:** Pennsylvania State University, Virginia Tech, Indian Institute of Science
  - **link:** https://arxiv.org/pdf/2512.21884
  - **contributions:** 1. Developed experimentally validated performance models for distributed LLM inference under given block placement and request routing decisions. 2. Formulated the offline optimization problem as a MILP, proved its NP-hardness, and designed a polynomial-complexity algorithm with performance guarantees. 3. Adapted the offline algorithm for the online setting with the same performance guarantee under bounded load.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the resource allocation problem for geographically-distributed LLM inference, focusing on optimizing block placement and request routing. It proposes performance models, offline and online algorithms with theoretical guarantees, and a lightweight CPU-only simulator. The solution significantly reduces inference time compared to the state-of-the-art in diverse distributed settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 分布式LLM推理的资源分配优化/Optimizing resource allocation for distributed LLM inference]
        C[主要方法/Method: 性能建模与优化算法/Performance modeling and optimization algorithms]
        D[关键结果/Results: 显著降低推理时间/Substantially reduces inference time]
    ```

- **[arXiv251229] BLEST: Blazingly Efficient BFS using Tensor Cores**
  - **tags:** [mlsys], [gpu kernels], [BFS, Tensor Cores, SpMSpV, Graph Reordering, Kernel Fusion]
  - **authors:** Deniz Elbek, Kamer Kaya
  - **institution:** Sabanci University
  - **link:** https://arxiv.org/pdf/2512.21967
  - **contributions:** 1. Introduces Binarised Virtual Slice Sets (BVSS) for warp-level load balancing and eliminating frontier-oblivious work assignment in BFS., 2. Applies two complementary graph reordering strategies (compression-oriented and bandwidth-reducing) to improve memory efficiency and update locality., 3. Develops a batched SpMSpV multiplication pattern using bitwise Tensor Core tiles and combines kernel fusion with a lazy vertex update scheme to reduce synchronization and atomic overheads.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da59a50541aea7cf054914628e80911f7ca77a9353af15a6a412588e726ca791_w640_q70.webp
  - **Simple LLM Summary:** The paper presents BLEST, a framework that accelerates Breadth-First Search (BFS) on GPUs by efficiently mapping the irregular computation onto dense-math Tensor Cores. The method reformulates the BFS pipeline using a bitmap-oriented structure, specialized load balancing, graph reordering, and kernel fusion. Experiments show that BLEST achieves significant speedups (3.58x to 4.9x) over state-of-the-art GPU-based BFS implementations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[BLEST: Blazingly Efficient BFS using Tensor Cores] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[如何将不规则图BFS映射到密集张量核心/Map irregular BFS to dense Tensor Cores]
        C --> C1[二值化虚拟切片集/Binarised Virtual Slice Sets (BVSS)]
        C --> C2[图重排序策略/Graph Reordering Strategies]
        C --> C3[批处理SpMSpV与核融合/Batched SpMSpV & Kernel Fusion]
        D --> D1[平均3.58-4.9倍加速/Average 3.58-4.9x Speedup]
    ```

- **[arXiv251229] Proceedings First Workshop on Adaptable Cloud Architectures**
  - **tags:** TBD
  - **authors:** Giuseppe De Palma, Saverio Giallorenzo
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.22054

- **[arXiv251229] FUSCO: High-Performance Distributed Data Shuffling via Transformation-Communication Fusion**
  - **tags:** [mlsys], [communication & networking], [Mixture-of-Experts, expert parallelism, data shuffling, transformation-communication fusion, collective communication]
  - **authors:** Zhuoran Zhu, Chunyang Zhu, Hao Lin, Xu Fu, Yiming Zhou, Quanlu Zhang, Zhenhua Li, Feng Qian, Chao Yu, Boxun Li, Guohao Dai, Yu Wang
  - **institution:** Tsinghua University, Infinigence AI, University of Southern California, Zhongguancun Academy, Shanghai Jiao Tong University
  - **link:** https://arxiv.org/pdf/2512.22036
  - **contributions:** 1. Identifies the root cause of inefficiency in MoE data shuffling as the misalignment between expert-major and device-major data layouts, requiring disaggregated transformation and communication. 2. Proposes FUSCO, a communication library that fuses data transformation and communication operations into a single, efficient pipeline to eliminate redundant data movement. 3. Introduces lightweight planning and load-balancing mechanisms to eliminate redundant communication and disperse traffic, further optimizing the shuffling process.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7cf69e647d44d7f0b5d2cdef643280359c8d359bbdf2f836c065bb3b6fb214ae_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the performance bottleneck of distributed data shuffling in Mixture-of-Experts (MoE) model training and inference. It proposes FUSCO, a communication library that fuses data transformation and communication to align expert-major and device-major data layouts efficiently. Evaluations show FUSCO achieves significant speedups over existing libraries like NCCL and DeepEP, reducing both training and inference latency.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[FUSCO: High-Performance Distributed Data Shuffling] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: MoE专家并行中的数据混洗开销大/High overhead of data shuffling in MoE expert parallelism]
        Method[主要方法/Method: 通过融合数据转换与通信实现高效混洗/Efficient shuffling via transformation-communication fusion]
        Results[关键结果/Results: 相比NCCL和DeepEP实现显著加速/Significant speedups over NCCL and DeepEP]
    ```

- **[arXiv251229] Robust Federated Fine-Tuning in Heterogeneous Networks with Unreliable Connections: An Aggregation View**
  - **tags:** [mlsys], [federated learning], [federated fine-tuning, connection failures, adaptive aggregation, data heterogeneity, convergence guarantee]
  - **authors:** Yanmeng Wang, Zhiwen Dai, Shuai Wang, Jian Zhou, Fu Xiao, Tony Q. S. Quek, Tsung-Hui Chang
  - **institution:** The affiliations include IEEE members, suggesting multiple institutions. Based on common patterns, likely institutions include The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen) and/or other Chinese universities/tech institutes, given authors like Tsung-Hui Chang and Tony Q. S. Quek are affiliated with such institutions.
  - **link:** https://arxiv.org/pdf/2512.22035
  - **contributions:** 1. Proposes FedAuto, a novel Federated Fine-Tuning framework that mitigates the combined effects of unreliable connections and data heterogeneity via adaptive aggregation, requiring no prior knowledge of network conditions. 2. Establishes a rigorous, per-round convergence guarantee for FedAuto that holds for each individual realization, removing common assumptions on failure probabilities or client selection. 3. Demonstrates through extensive experiments that FedAuto outperforms state-of-the-art baselines under diverse failure scenarios for both full and partial-parameter fine-tuning (e.g., LoRA).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b9295640a8e9a219a19de76effe76cb1ea0696845676f4a5d9a059161538fb_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the performance degradation of Federated Fine-Tuning (FFT) in real-world networks with unreliable connections and heterogeneous data. It proposes FedAuto, a framework that uses adaptive aggregation to handle these issues without prior network knowledge or infrastructure changes. Experiments show FedAuto consistently outperforms existing methods and provides stronger theoretical convergence guarantees.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Robust Federated Fine-Tuning in Heterogeneous Networks with Unreliable Connections: An Aggregation View] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[FFT性能受不可靠连接和数据异构性影响/FFT performance degraded by unreliable connections & data heterogeneity]
        C --> C1[FedAuto: 通过自适应聚合的FFT框架/FedAuto: FFT framework with adaptive aggregation]
        C --> C2[无需先验网络知识/No prior network knowledge needed]
        D --> D1[实验表现超越SOTA/Outperforms SOTA baselines]
        D --> D2[提供严格收敛保证/Provides rigorous convergence guarantee]
    ```

- **[arXiv251229] Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications**
  - **tags:** [mlsys], [agent system], [root cause analysis, service dependency graph, program dependence graph, LLM agent, cloud incident]
  - **authors:** Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer
  - **institution:** University of Illinois at Urbana-Champaign, IBM Research
  - **link:** https://arxiv.org/pdf/2512.22113
  - **contributions:** 1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Agentic Structured Graph Traversal for Root Cause Analysis<br/>基于智能体结构化图遍历的云应用根因分析] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br/>High cost of unresolved cloud incidents; Need for effective root cause analysis]
        C[主要方法/Method<br/>PRAXIS: LLM-driven traversal over Service Dependency Graph and Program Dependence Graph]
        D[关键结果/Results<br/>3.1x higher RCA accuracy, 3.8x lower token consumption vs. ReAct baselines]
    ```


**cs.AI/cs.LG contains "reinforcement learning" total: 17**
- **[arXiv251229] CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation**
  - **tags:** [ai], [reinforcement learning], [dream-replay reinforcement learning, evolutionary algorithms, adaptive code generation]
  - **authors:** Santhosh Kumar Ravindran
  - **institution:** Microsoft Corporation
  - **link:** https://arxiv.org/pdf/2512.21351
  - **contributions:** 1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as "genomes" that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp
  - **Simple LLM Summary:** CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM代码生成缺乏适应性，难以应对API变化/LLM code generation lacks adaptability to API changes]
        C --> C1[将RL轨迹视为基因组进行进化操作/Treat RL trajectories as genomes for evolutionary operations]
        C --> C2[在夜间回放阶段进行突变与选择/Mutation and selection during nocturnal replay]
        D --> D1[解决方案新颖性提升35%/35% higher novelty in solutions]
        D --> D2[适应速度加快25%/25% faster adaptation]
    ```

- **[arXiv251229] A Reinforcement Learning Approach to Synthetic Data Generation**
  - **tags:** [ai], [reinforcement learning], [synthetic data generation, reinforcement learning, proximal policy optimization, privacy, biomedical data]
  - **authors:** Natalia Espinosa-Dice, Nicholas J. Jackson, Chao Yan, Aaron Lee, Bradley A. Malin
  - **institution:** Princeton University, Vanderbilt University Medical Center, Washington University in St. Louis
  - **link:** https://arxiv.org/pdf/2512.21395
  - **contributions:** 1. Reframes synthetic data generation (SDG) as a reinforcement learning problem, introducing a novel perspective. 2. Proposes RLSyn, a framework that models the data generator as a stochastic policy optimized via Proximal Policy Optimization with discriminator-derived rewards for stable, data-efficient training. 3. Demonstrates the effectiveness of the RL approach, showing it performs comparably to or better than GANs and diffusion models, especially in data-scarce regimes on biomedical datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75d9e0c3d2cba88654d16f9652042680f0037508065d6d94fba27208a6199969_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes RLSyn, a reinforcement learning framework for generating synthetic biomedical data by modeling the generator as a policy optimized with PPO. It shows that this approach achieves performance comparable to or better than GANs and diffusion models, particularly when training data is limited, offering a stable and data-efficient alternative for privacy-preserving data sharing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Reinforcement Learning Approach to Synthetic Data Generation] --> B
        A --> C
        A --> D
        B[核心问题/Problem: State-of-the-art generative models need large datasets and complex training, limiting use in small-sample settings.]
        C[主要方法/Method: Reframe SDG as RL; introduce RLSyn (stochastic policy optimized via PPO with discriminator rewards).]
        D[关键结果/Results: RLSyn performs comparably to/better than GANs & diffusion models, especially on smaller datasets.]
    ```

- **[arXiv251229] A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning**
  - **tags:** [sys], [wireless networking], [Age of Information (AoI), reinforcement learning, freshness optimization, wireless networks, multi-agent systems]
  - **authors:** Alimu Alibotaiken, Suyang Wang, Oluwaseun T. Ajayi, Yu Cheng
  - **institution:** Illinois Institute of Technology, California State University, San Bernardino
  - **link:** https://arxiv.org/pdf/2512.21412
  - **contributions:** 1. Proposes a novel taxonomy for Age of Information (AoI) and its variants, categorizing them into native, function-based, and application-oriented families to clarify freshness modeling for B5G/6G systems. 2. Introduces a policy-centric taxonomy for reinforcement learning in freshness-aware networks, consisting of update-control RL, medium-access RL, risk-sensitive RL, and multi-agent RL. 3. Synthesizes recent RL-driven freshness control progress and highlights open challenges like delayed decision processes and cross-layer design to establish a unified foundation for learning-based freshness optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b58e6fe193d4299ab0beca4eb949d8b13e21e8198c223c3dd6c0ca64896bbf7d_w640_q70.webp
  - **Simple LLM Summary:** This survey addresses the gap between classical Age of Information (AoI) studies and broad reinforcement learning (RL) discussions in wireless networks by examining RL specifically for freshness optimization. It organizes AoI variants and introduces a policy-centric RL taxonomy to provide a coherent framework for freshness-aware decision-making in next-generation wireless systems. The paper aims to establish a unified foundation for learning-based freshness control and highlights key open challenges for future research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有综述的不足: 经典AoI与泛化RL研究分离 / Gap: Classical AoI vs. Broad RL]
        C --> C1[提出以AoI为中心的RL综述框架 / Propose AoI-centric RL Survey Framework]
        C --> C2[构建AoI变体分类与策略中心分类法 / Build AoI Variant & Policy-Centric Taxonomies]
        D --> D1[为B5G/6G建立学习式新鲜度优化的统一基础 / Establish Unified Foundation for Learning-based Freshness Optimization]
        D --> D2[识别开放挑战: 延迟决策、随机性、跨层设计 / Identify Open Challenges: Delayed Decisions, Stochasticity, Cross-layer]
    ```

- **[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning**
  - **tags:** [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]
  - **authors:** Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu
  - **institution:** University of Washington, University of California, Berkeley
  - **link:** https://arxiv.org/pdf/2512.21446
  - **contributions:** 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards "diffusion supremacy" over autoregressive models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[MDLMs解码慢，速度优势有限/MDLMs decode slowly, limiting speed advantage]
        C --> C1[基于GRPO的在线强化学习框架/On-policy RL framework based on GRPO]
        C --> C2[联合优化扩散模型与解掩码规划器/Jointly optimize diffusion model & unmasking planner]
        D --> D1[提升精度-效率权衡/Improves accuracy-efficiency trade-off]
        D --> D2[迈向"扩散霸权"/Moving towards "diffusion supremacy"]
    ```

- **[arXiv251229] DiverseGRPO: Mitigating Mode Collapse in Image Generation via Diversity-Aware GRPO**
  - **tags:** [cv], [diffusion models], [GRPO, mode collapse, diversity-aware reward, spectral clustering, structure-aware regularization]
  - **authors:** Henglin Liu, Huijuan Huang, Jing Wang, Chang Liu, Xiu Li, Xiangyang Ji
  - **institution:** Tsinghua University, Kuaishou Technology (Kling Team), Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.21514
  - **contributions:** 1. Identifies and analyzes the mode collapse problem in GRPO-based image generation from both reward modeling and generation dynamics perspectives. 2. Proposes a distributional creativity bonus reward based on semantic grouping via spectral clustering to encourage novel visual modes. 3. Introduces a structure-aware regularization that applies stronger constraints during early-stage denoising to preserve diversity without sacrificing quality optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the mode collapse problem in GRPO-based image generation, where models produce homogenized outputs. The proposed DiverseGRPO method introduces a diversity-aware reward based on semantic clustering and a structure-aware regularization to preserve generation diversity. Experiments show the method significantly improves semantic diversity while maintaining image quality, establishing a better quality-diversity trade-off.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DiverseGRPO: Mitigating Mode Collapse] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[GRPO导致模式崩溃/GRPO causes mode collapse]
        B1 --> B2[缺乏视觉多样性/Lacks visual diversity]
        C --> C1[奖励层面: 分布创造力奖励/Reward Level: Distributional Creativity Bonus]
        C --> C2[生成层面: 结构感知正则化/Generation Level: Structure-Aware Regularization]
        C1 --> C3[基于语义分组的谱聚类/Spectral Clustering for Semantic Grouping]
        D --> D1[语义多样性提升13%-18%/13%-18% Semantic Diversity Improvement]
        D --> D2[建立新的帕累托前沿/Establishes New Pareto Frontier]
    ```

- **[arXiv251229] Generative Actor Critic**
  - **tags:** [ai], [reinforcement learning], [generative modeling, policy evaluation, latent plan, offline-to-online, actor-critic]
  - **authors:** Aoyang Qin, Deqian Kong, Wei Wang, Ying Nian Wu, Song-Chun Zhu, Sirui Xie
  - **institution:** Tsinghua University, Beijing Institute of General Artificial Intelligence (BIGAI), UCLA, Peking University
  - **link:** https://arxiv.org/pdf/2512.21527
  - **code:** github.com/qayqaq/Generative-Actor-Critic
  - **contributions:** 1. Proposes the Generative Actor Critic (GAC) framework that reframes policy evaluation as learning a generative model of the joint distribution over trajectories and returns, decoupling decision-making. 2. Introduces a specific instantiation using a latent variable model with continuous latent plan vectors and novel inference strategies for exploitation and exploration. 3. Demonstrates strong offline performance and significantly enhanced offline-to-online improvement on benchmarks, even without step-wise rewards.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62b697a3a1c4a1b559c19af7d65fd19d2eed0bb097eccecdd9008a509a0456c0_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Generative Actor Critic (GAC), a novel reinforcement learning framework that decouples sequential decision-making by learning a generative model of trajectories and returns and then performing inference on it. It shows strong performance in offline learning and significantly improves when fine-tuned online, even in sparse-reward environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Generative Actor Critic] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统RL在线改进离线预训练模型存在挑战/Challenges in refining offline models online]
        C --> C1[将策略评估重构为学习轨迹与回报的联合生成模型/Reframe policy evaluation as learning p(τ, y)]
        C --> C2[将策略改进重构为在模型上进行多样化推理/Reframe policy improvement as versatile inference]
        C --> C3[基于潜变量模型的实例化与新颖推理策略/Instantiation with latent plans & novel inference]
        D --> D1[离线性能强大/Strong offline performance]
        D --> D2[离线到在线改进显著/Enhanced offline-to-online improvement]
    ```

- **[arXiv251229] Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model**
  - **tags:** [mlsys], [llm inference], [adaptive length penalty, reinforcement learning, constrained optimization, Lagrangian primal-dual, reasoning efficiency]
  - **authors:** Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo
  - **institution:** Peking University, Harbin Institute of Technology, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.21540
  - **contributions:** 1. Proposes Leash, a reinforcement learning framework that formulates length control as a constrained optimization problem and uses a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. 2. Introduces an adaptive mechanism that intensifies the penalty when generations exceed the target length and relaxes it when they are shorter, guiding models toward concise reasoning without sacrificing performance. 3. Demonstrates experimentally that Leash reduces average reasoning length by 60% across diverse tasks while maintaining competitive performance, offering a practical paradigm for efficient LLMs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of LLMs producing overly long reasoning traces, which increases computational cost. It proposes Leash, an adaptive reinforcement learning framework that dynamically adjusts length penalties using a Lagrangian method to balance conciseness and accuracy. Experiments show it reduces reasoning length by 60% while maintaining performance, providing an effective approach for efficient LLM reasoning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LEASH: Adaptive Length Penalty and Reward Shaping] --> B[核心问题/Problem: LLMs生成过长推理链，计算成本高/Fixed penalties fail to adapt, leading to suboptimal accuracy-conciseness trade-offs]
        A --> C[主要方法/Method: 自适应强化学习框架，使用拉格朗日对偶方法动态调整惩罚系数/Adaptive RL framework with Lagrangian primal-dual for dynamic penalty adjustment]
        A --> D[关键结果/Results: 平均推理长度减少60%，性能保持竞争力/Average reasoning length reduced by 60% while maintaining competitive performance across tasks]
    ```

- **[arXiv251229] Towards Learning-Based Formula 1 Race Strategies**
  - **tags:** [ai], [reinforcement learning], [mixed-integer nonlinear programming, reinforcement learning, energy allocation, tire wear, pit stop]
  - **authors:** Giona Fieni, Joschua Wüthrich, Marc-Philippe Neumann, Mohammad M. Moradi, Christopher H. Onder
  - **institution:** Institute for Dynamic Systems and Control, ETH Zürich
  - **link:** https://arxiv.org/pdf/2512.21570
  - **contributions:** 1. Proposes a comprehensive race scenario model for Formula 1 that jointly accounts for energy allocation, tire wear, and pit stop timing using lap time maps and a dynamic tire wear model. 2. Develops and solves the strategy optimization problem using a Mixed-Integer Nonlinear Program (MINLP) to handle the integer decisions of pit stops. 3. Implements a complementary Reinforcement Learning (RL) framework trained on the same scenario, providing a fast-inference solution suitable for real-time human decision support during races.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63fe52e5bd2040f57f04a5b1222af84097ec60d1ba7e39ef15695eb7f5b3c59f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes two complementary frameworks to optimize Formula 1 race strategies by jointly managing energy, tire wear, and pit stops. It uses a Mixed-Integer Nonlinear Program for optimal offline planning and a Reinforcement Learning agent for fast, real-time inference. The RL agent achieves suboptimality of only about 5 seconds in a 1.5-hour race, demonstrating its potential for real-time strategic assistance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Towards Learning-Based Formula 1 Race Strategies<br/>基于学习的F1比赛策略"] --> Problem["核心问题/Problem<br/>Optimize F1 race strategy (energy, tires, pit stops)<br/>优化F1比赛策略(能量、轮胎、进站)"]
        Root --> Method["主要方法/Method<br/>Two complementary frameworks<br/>两个互补框架"]
        Root --> Results["关键结果/Results<br/>RL agent ~5s suboptimal in 1.5h race<br/>RL智能体在1.5小时比赛中表现接近最优(约5秒差距)"]
        Method --> M1["MINLP for optimal solution<br/>混合整数非线性规划求最优解"]
        Method --> M2["Reinforcement Learning for fast inference<br/>强化学习用于快速推理"]
    ```

- **[arXiv251229] Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations**
  - **tags:** [ai], [imitation learning], [behavior cloning, latent representation, self-supervised learning, sample efficiency]
  - **authors:** Xin Liu, Haoran Li, Dongbin Zhao
  - **institution:** Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences
  - **link:** https://arxiv.org/pdf/2512.21586
  - **contributions:** 1. Proposes a novel, unsupervised framework (BCV-LR) for imitation learning from videos (ILV) that learns latent actions from visual inputs. 2. Introduces an iterative policy improvement loop that aligns pre-trained latent actions with the real action space online, enabling highly sample-efficient learning. 3. Demonstrates state-of-the-art sample efficiency, outperforming existing ILV and RL methods on a wide range of visual control tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c96d71be701998ebf55ef6ed2a0c0a001a306b44f3555239559ced527b17559_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes BCV-LR, a framework for learning policies from videos without action labels. It uses self-supervised learning to extract latent actions and an iterative alignment process for sample-efficient behavior cloning. The method achieves expert-level performance on many tasks with minimal interaction, showing videos can be highly effective supervision for policy learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1["从视频模仿学习的挑战 / Challenges of Imitation Learning from Videos"]
        C --> C1["BCV-LR框架 / BCV-LR Framework"]
        C1 --> C2["自监督提取潜在特征 / Self-supervised Latent Feature Extraction"]
        C1 --> C3["基于动态的潜在动作预测 / Dynamics-based Latent Action Prediction"]
        C1 --> C4["在线对齐与迭代策略改进 / Online Alignment & Iterative Policy Improvement"]
        D --> D1["高样本效率 / High Sample Efficiency"]
        D --> D2["超越SOTA方法 / Outperforms SOTA Baselines"]
        D --> D3["首次证明视频可作为高效监督 / First to Show Videos as Efficient Supervision"]
    ```

- **[arXiv251229] Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards**
  - **tags:** [ai], [reinforcement learning], [RLVR, sample polarity, advantage shaping, policy optimization, reasoning models]
  - **authors:** Xinyu Tang, Yuliang Zhan, Zhixun Li, Wayne Xin Zhao, Zhenduo Zhang, Zujie Wen, Zhiqiang Zhang, Jun Zhou
  - **institution:** Renmin University of China, The Chinese University of Hong Kong, Ant Group
  - **link:** https://arxiv.org/pdf/2512.21625
  - **contributions:** 1. A systematic investigation into the distinct roles of positive and negative samples (sample polarity) in RLVR training dynamics, showing positive samples sharpen existing patterns while negative samples encourage exploration. 2. An exploration of how adjusting advantage values for different sample polarities at both the sample and token levels affects training. 3. The proposal of A3PO, an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, which precisely allocates advantage signals to key tokens.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the distinct roles of positive and negative samples in Reinforcement Learning with Verifiable Rewards (RLVR) for training large reasoning models. It finds positive samples refine correct patterns while negative samples promote exploration, and proposes a new method called A3PO for adaptive, asymmetric token-level advantage shaping. Experiments on five reasoning benchmarks demonstrate the effectiveness of the proposed approach.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Rethinking Sample Polarity in RLVR] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[RLVR中正负样本的角色?/Roles of +/- samples in RLVR?]
        Method[主要方法/Method] --> M1[分析样本极性/Analyze Sample Polarity]
        Method --> M2[提出A3PO方法/Propose A3PO Method]
        Results[关键结果/Results] --> R1[正样本锐化模式/Positive samples sharpen patterns]
        Results --> R2[负样本鼓励探索/Negative samples encourage exploration]
        Results --> R3[A3PO有效/A3PO is effective]
    ```

- **[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search**
  - **tags:** [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]
  - **authors:** Maximilian Weichart
  - **institution:** University of Regensburg
  - **link:** https://arxiv.org/pdf/2512.21648
  - **code:** https://github.com/Max-We/inverse-rpo
  - **contributions:** 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Variance-Aware Prior-Based Tree Policies for MCTS] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Extending prior-based UCTs from other UCBs is challenging]
        C[主要方法/Method: Propose Inverse-RPO to derive prior-based UCTs; apply to UCB-V]
        D[关键结果/Results: New policies outperform PUCT without extra cost]
    ```

- **[arXiv251229] Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities**
  - **tags:** [sys], [communication & networking], [multiconnectivity, SAGIN, resource allocation, agentic reinforcement learning, heterogeneous networks]
  - **authors:** Abd Ullah Khan, Adnan Shahid, Haejoon Jung, Hyundong Shin
  - **institution:** Kyung Hee University, Ghent University
  - **link:** https://arxiv.org/pdf/2512.21717
  - **contributions:** 1. Provides a comprehensive review of current developments and key implementation challenges in SAGIN-enabled multiconnectivity. 2. Highlights the transformative potential of AI-driven approaches, particularly agentic reinforcement learning, for resource optimization in heterogeneous SAGIN environments. 3. Presents a case study demonstrating that learning-based methods can effectively enhance network performance (latency, capacity) with a moderate trade-off in power consumption.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp
  - **Simple LLM Summary:** This paper reviews the challenges of implementing multiconnectivity in heterogeneous Space-Air-Ground Integrated Networks (SAGIN) and proposes AI-driven solutions, specifically agentic reinforcement learning, for optimal resource allocation. A case study shows these methods significantly improve latency and capacity, albeit with a moderate increase in power consumption as a trade-off. The work concludes by outlining open research problems for realizing efficient SAGIN-enabled multiconnectivity.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem: Heterogeneous SAGIN complicates multiconnectivity and resource allocation"]
        Method["主要方法/Method: Use AI-driven approaches, specifically agentic reinforcement learning"]
        Results["关键结果/Results: Enhanced network performance (latency, capacity) with moderate power trade-off"]
    ```

- **[arXiv251229] Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection**
  - **tags:** [ai], [reinforcement learning], [Quantum Reinforcement Learning, Asynchronous Advantage Actor-Critic (A3C), Variational Quantum Circuits (VQCs), Time-series Dynamic Clustering, ETF Stock Selection]
  - **authors:** Yen-Ku Liu, Yun-Cheng Tsai, Samuel Yen-Chi Chen
  - **institution:** National Taiwan Normal University, Wells Fargo Bank
  - **link:** https://arxiv.org/pdf/2512.21819
  - **contributions:** 1. Proposes Q-A3C2, a novel quantum-enhanced A3C framework integrated with time-series dynamic clustering for adaptive financial decision-making. 2. Embeds Variational Quantum Circuits (VQCs) into the policy network to enhance nonlinear feature representation and mitigate overfitting in high-dimensional financial data. 3. Demonstrates superior performance through experiments on S&P 500 constituents, achieving significantly higher cumulative returns compared to benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24772abde7bff15c10d7b6e86ca20b5510d1c2c86dce26245e814a93d8ce5afd_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Q-A3C2, a quantum reinforcement learning framework that combines a quantum-enhanced A3C algorithm with time-series dynamic clustering to adaptively select ETF stocks. The method uses Variational Quantum Circuits to improve feature learning and dynamic clustering to capture evolving market regimes. Experimental results on S&P 500 data show Q-A3C2 achieves a 17.09% cumulative return, outperforming the benchmark's 7.09%, demonstrating its effectiveness in dynamic financial environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统方法问题/Traditional Methods' Issues]
        B1 --> B11[高维特征与过拟合/High-dimensional Features & Overfitting]
        B1 --> B12[静态聚类无法适应市场变化/Static Clustering Fails to Adapt]
        C --> C1[量子增强A3C/Quantum-enhanced A3C]
        C1 --> C11[策略网络嵌入VQC/Embed VQC in Policy Network]
        C --> C2[集成时序动态聚类/Integrate Time-series Dynamic Clustering]
        D --> D1[累计收益17.09%/Cumulative Return 17.09%]
        D --> D2[超越基准7.09%/Outperforms Benchmark 7.09%]
    ```

- **[arXiv251229] A Comedy of Estimators: On KL Regularization in RL Training of LLMs**
  - **tags:** [ai], [reinforcement learning], [KL divergence, policy gradient, on-policy sampling, off-policy training, gradient bias]
  - **authors:** Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, Nikolay Malkin, Moksh Jain, Siddarth Venkatraman, Aaron Courville
  - **institution:** Mila – Quebec AI Institute, Université de Montréal, McGill University, LLNL, University of Edinburgh, CIFAR
  - **link:** https://arxiv.org/pdf/2512.21852
  - **contributions:** 1. Systematic analysis of KL divergence estimator configurations in RL for LLMs, revealing how design choices introduce gradient bias. 2. Empirical demonstration that estimator configurations with unbiased gradients lead to better and more stable performance on both in-domain and out-of-domain tasks. 3. Investigation showing KL regularization can stabilize off-policy RL training in asynchronous setups.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the use of various estimators for the KL divergence regularization term in RL fine-tuning of LLMs, finding that common practices introduce biased gradients. Through experiments on models like Qwen2.5-7B, the study shows that using estimator configurations with unbiased gradients improves training stability and downstream task performance. The work also finds that KL regularization helps stabilize off-policy RL training.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Comedy of Estimators: On KL Regularization in RL Training of LLMs<br>论文标题"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>KL正则化估计器配置缺乏系统研究，梯度存在偏差"] --> P1["实践问题/Practical Issue<br>广泛使用但实现与目标不一致"]
        Problem --> P2["理论问题/Theoretical Issue<br>梯度偏差影响训练稳定性"]
        Method["主要方法/Method<br>分析梯度偏差并进行实证验证"] --> M1["分析/Analysis<br>研究多种估计器配置的梯度"]
        Method --> M2["实验/Experiments<br>RL微调多个LLM并评估性能"]
        Results["关键结果/Results<br>无偏梯度配置带来更好性能"] --> R1["在线策略/On-Policy<br>无偏梯度配置提升稳定性和性能"]
        Results --> R2["离线策略/Off-Policy<br>KL正则化有助于稳定异步训练"]
    ```

- **[arXiv251229] SWE-RM: Execution-free Feedback For Software Engineering Agents**
  - **tags:** [se], [software engineering agents], [reward model, test-time scaling, reinforcement learning, mixture-of-experts, SWE-Bench]
  - **authors:** KaShun Shum, Binyuan Hui, Jiawei Chen, Lei Zhang, X. W., Jiaxi Yang, Yuzhen Huang, Junyang Lin, Junxian He
  - **institution:** The Hong Kong University of Science and Technology, Alibaba Group (Qwen Team)
  - **link:** https://arxiv.org/pdf/2512.21919
  - **contributions:** 1. Identified that high TTS performance does not guarantee effective RL training, and introduced classification accuracy and calibration as crucial metrics for robust reward models. 2. Conducted comprehensive experiments to analyze factors (data scale, policy mixtures, data source) impacting reward model training for SWE agents. 3. Proposed SWE-RM, a large-scale mixture-of-experts reward model that significantly improves agent performance on both TTS and RL, achieving new SOTA on SWE-Bench Verified.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limitations of execution-based feedback for software engineering agents by proposing an execution-free reward model. It introduces SWE-RM, a robust reward model trained with insights from controlled experiments, which substantially improves agent performance on both test-time scaling and reinforcement learning, setting a new state-of-the-art on the SWE-Bench benchmark.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["SWE-RM: Execution-free Feedback For Software Engineering Agents"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["执行反馈的局限性/Limitations of Execution-based Feedback"]
        Problem --> P2["无执行反馈未被充分探索/Execution-free Feedback Underexplored"]
        Method --> M1["识别RL关键指标/Identify Key RL Metrics (Accuracy, Calibration)"]
        Method --> M2["可控实验分析/Controlled Experiments on Training Factors"]
        Method --> M3["提出SWE-RM模型/Propose SWE-RM (MoE Reward Model)"]
        Results --> R1["提升TTS性能/Improves TTS Performance (e.g., Qwen3-Coder-Max to 74.6%)"]
        Results --> R2["提升RL性能/Improves RL Performance (+3 points)"]
        Results --> R3["开源模型SOTA/New SOTA Among Open-Source Models"]
    ```

- **[arXiv251229] Latency-Optimal Cache-aided Multicast Streaming via Forward-Backward Reinforcement Learning**
  - **tags:** [mlsys], [memory & caching], [forward-backward MDP, multi-objective reinforcement learning, orthogonal multipoint multicast, wireless caching, latency optimization]
  - **authors:** Mohsen Amidzadeh
  - **institution:** Aalto University
  - **link:** https://arxiv.org/pdf/2512.21954
  - **contributions:** 1. Introduces a novel forward-backward Markov decision process (FB-MDP) model that captures both the forward dynamics of user preferences and the backward dynamics of latency in a cache-aided multicast network. 2. Proposes a forward-backward multi-objective reinforcement learning (FB-MORL) algorithm to optimize for expected latency, outage probability, and resource consumption simultaneously. 3. Demonstrates through simulation that the proposed FB-MORL algorithm can find a promising dynamic cache policy for latency-optimal streaming.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e067ef983249e0d5eda55e0e5e41b6159895affdd536e8f8f4b116a2dac1058_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of optimizing streaming latency in a cellular network with cache-enabled base stations using multicast. The authors propose a novel forward-backward reinforcement learning framework that models the network's temporal dynamics as a multi-objective Markov decision process. Simulation results show their method is effective in finding a dynamic cache policy that reduces latency.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Latency-Optimal Cache-aided Multicast Streaming via Forward-Backward Reinforcement Learning"] --> Problem["核心问题/Problem: Optimizing latency in cache-aided cellular multicast networks"]
        Root --> Method["主要方法/Method: Forward-Backward MDP modeling and FB-MORL algorithm"]
        Root --> Results["关键结果/Results: Proposed algorithm finds promising dynamic cache policy"]
    ```

- **[arXiv251229] Meta-Learning-Based Handover Management in NextG O-RAN**
  - **tags:** [sys], [communication & networking], [Conditional Handovers, O-RAN, Meta-Learning, Mobility Management, xApp]
  - **authors:** Michail Kalntis, George Iosifidis, José Suárez-Varela, Andra Lutu, Fernando A. Kuipers
  - **institution:** Delft University of Technology, Telefónica Research
  - **link:** https://arxiv.org/pdf/2512.22022
  - **contributions:** 1. Introduces CONTRA, the first framework to jointly optimize Traditional and Conditional Handovers within the O-RAN architecture. 2. Proposes a practical meta-learning algorithm for adaptive, on-the-fly handover type selection, guaranteeing universal no-regret performance. 3. Provides and analyzes unique, countrywide mobility management datasets from a top-tier mobile network operator, offering fresh insights into handover trade-offs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of traditional and conditional handovers in mobile networks by proposing CONTRA, a meta-learning-based framework for O-RAN that dynamically selects and optimizes handover types. It is designed as a near-real-time xApp and is evaluated using real-world datasets. The results show that CONTRA improves user throughput and reduces switching costs, outperforming standard and RL-based baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Meta-Learning-Based Handover Management in NextG O-RAN] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统切换延迟与失败/Traditional HO delays & failures]
        B --> B2[切换类型间的权衡/Trade-offs between HO types]
        C --> C1[CONTRA框架: 联合优化THO与CHO/CONTRA: Jointly optimizes THOs & CHOs]
        C --> C2[元学习算法动态选择/Meta-learning for dynamic selection]
        C --> C3[O-RAN xApp部署/O-RAN xApp deployment]
        D --> D1[提升用户吞吐量/Improves user throughput]
        D --> D2[降低切换成本/Reduces HO switching costs]
        D --> D3[优于3GPP与RL基线/Outperforms 3GPP & RL baselines]
    ```


**cs.AI/cs.LG contains "accelerate" total: 19**
- **[arXiv251229] Satellite Cybersecurity Across Orbital Altitudes: Analyzing Ground-Based Threats to LEO, MEO, and GEO**
  - **tags:** [sec], [satellite cybersecurity], [Telemetry, Tracking, and Command (TT&C), encryption weaknesses, radio-frequency (RF) links]
  - **authors:** Mark Ballard, Guanqun Song, Ting Zhu
  - **institution:** The Ohio State University
  - **link:** https://arxiv.org/pdf/2512.21367
  - **contributions:** 1. Presents a comparative analysis of satellite cybersecurity threats across LEO, MEO, and GEO orbital regimes, linking orbital altitude to attack feasibility and impact. 2. Synthesizes data from 60 publicly documented security incidents to characterize distinct threat profiles for different orbits (e.g., GEO uplink exposure vs. LEO hardware constraints). 3. Bridges the gap between cybersecurity and space sustainability, arguing that unmitigated cyber vulnerabilities accelerate hardware obsolescence and debris accumulation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes ground-based cybersecurity threats to satellites in different orbital altitudes (LEO, MEO, GEO). By synthesizing data from 60 security incidents and analyzing vulnerability proxies like TT&C anomalies and encryption, it characterizes how altitude dictates distinct threat profiles and concludes that weak encryption and command path irregularities are the most consistent predictors of adversarial success across all orbits.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Satellite Cybersecurity Across Orbital Altitudes] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[轨道高度如何影响卫星网络安全/How orbital altitude dictates satellite cybersecurity]
    C --> C1[分析60起安全事件与漏洞代理/Analyze 60 security incidents & vulnerability proxies]
    D --> D1[不同轨道有独特的威胁特征/Distinct threat profiles per orbit]
    D --> D2[弱加密和指令异常是主要预测因子/Weak encryption & command irregularities are key predictors]
    ```

- **[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning**
  - **tags:** [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]
  - **authors:** Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu
  - **institution:** University of Washington, University of California, Berkeley
  - **link:** https://arxiv.org/pdf/2512.21446
  - **contributions:** 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards "diffusion supremacy" over autoregressive models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[MDLMs解码慢，速度优势有限/MDLMs decode slowly, limiting speed advantage]
        C --> C1[基于GRPO的在线强化学习框架/On-policy RL framework based on GRPO]
        C --> C2[联合优化扩散模型与解掩码规划器/Jointly optimize diffusion model & unmasking planner]
        D --> D1[提升精度-效率权衡/Improves accuracy-efficiency trade-off]
        D --> D2[迈向"扩散霸权"/Moving towards "diffusion supremacy"]
    ```

- **[arXiv251229] Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism**
  - **tags:** [cv], [object detection], [Ground Penetrating Radar (GPR), Multi-modal Chain Feature Fusion (MCFF), Global Attention Mechanism (GAM), DCGAN, transfer learning]
  - **authors:** Haotian Lv, Yuhui Zhang, Jiangbo Dai, Hanli Wu, Jiaji Wang, Dawei Wang
  - **institution:** Harbin Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.21452
  - **contributions:** 1. Proposed a DCGAN-based data augmentation strategy to synthesize high-fidelity GPR images, mitigating data scarcity. 2. Designed a novel Multi-modal Chain and Global Attention Network (MCGA-Net) integrating Multi-modal Chain Feature Fusion (MCFF) and a Global Attention Mechanism (GAM) for enhanced defect representation. 3. Utilized MS COCO transfer learning to fine-tune the backbone network, accelerating convergence and improving model generalization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the subjective and inefficient interpretation of Ground Penetrating Radar (GPR) images for road defect detection by proposing a comprehensive framework. The method combines DCGAN-based data augmentation, a novel MCGA-Net architecture with feature fusion and attention mechanisms, and transfer learning. The proposed model achieves high precision, recall, and robustness, establishing a new paradigm for automated GPR-based defect detection.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Intelligent recognition of GPR road hidden defect images <br/> GPR道路隐蔽病害图像智能识别") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
    
        Problem --> P1("Subjective & inefficient GPR interpretation <br/> GPR图像解释主观且低效")
        Problem --> P2("Data scarcity <br/> 数据稀缺")
    
        Method --> M1("DCGAN-based Data Augmentation <br/> 基于DCGAN的数据增强")
        Method --> M2("MCGA-Net (MCFF + GAM) <br/> MCGA-Net网络")
        Method --> M3("MS COCO Transfer Learning <br/> MS COCO迁移学习")
    
        Results --> R1("High Performance (Precision 92.8%, mAP@50 95.9%) <br/> 高性能")
        Results --> R2("Robust to noise & weak signals <br/> 对噪声和弱信号鲁棒")
        Results --> R3("New paradigm for automated detection <br/> 自动化检测新范式")
    ```

- **[arXiv251229] GoldenFuzz: Generative Golden Reference Hardware Fuzzing**
  - **tags:** [sec], [hardware security verification], [hardware fuzzing, golden reference model, RISC-V, test case refinement, vulnerability discovery]
  - **authors:** Lichao Wu, Mohamadreza Rostami, Huimin Li, Nikhilesh Singh, Ahmad-Reza Sadeghi
  - **institution:** Technical University of Darmstadt
  - **link:** https://arxiv.org/pdf/2512.21524
  - **contributions:** 1. Introduces a novel two-stage hardware fuzzing framework that decouples test refinement from coverage exploration using a fast Golden Reference Model (GRM) as a "digital twin". 2. Proposes a method to iteratively construct test cases by concatenating instruction blocks, balancing inter- and intra-instruction quality, and uses a feedback mechanism from high- and low-coverage samples. 3. Demonstrates superior performance over existing fuzzers on RISC-V processors, discovering new severe vulnerabilities and achieving higher coverage with lower computational overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp
  - **Simple LLM Summary:** This paper presents GoldenFuzz, a hardware fuzzing framework that uses a fast Golden Reference Model to refine test cases efficiently before exploring the actual device. It employs a feedback-driven mechanism for instruction block selection to enhance state exploration. The evaluation shows GoldenFuzz achieves higher coverage with less overhead and discovers new severe vulnerabilities in RISC-V processors.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GoldenFuzz: Generative Golden Reference Hardware Fuzzing] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[硬件模糊测试存在语义感知有限、测试低效、计算开销大的问题/Hardware fuzzing suffers from limited semantic awareness, inefficiency, and high overhead]
        C --> C1[使用快速黄金参考模型(GRM)作为数字孪生进行两阶段模糊测试/Two-stage fuzzing using a fast Golden Reference Model (GRM) as a digital twin]
        C --> C2[通过连接指令块和反馈机制构建测试用例/Constructing test cases via instruction block concatenation and feedback]
        D --> D1[在RISC-V处理器上实现最高覆盖率和最小开销/Achieves highest coverage with minimal overhead on RISC-V processors]
        D --> D2[发现新的高危漏洞/Uncovers new high-severity vulnerabilities]
    ```

- **[arXiv251229] AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage Antiviral Peptide Identification**
  - **tags:** [ai], [bioinformatics], [adaptive gating mechanism, contrastive learning, transfer learning]
  - **authors:** Xinru Wen, Weizhong Lin, Xuan Xiao
  - **institution:** JCI (inferred from email domain `jci.edu.cn`)
  - **link:** https://arxiv.org/pdf/2512.21544
  - **contributions:** 1. Proposes a two-stage deep learning framework (AVP-Fusion) for antiviral peptide identification and subclass prediction. 2. Introduces an Adaptive Gating Mechanism to dynamically fuse local (CNN) and global (BiLSTM) sequence features. 3. Employs a contrastive learning strategy with OHEM and BLOSUM62-based data augmentation to sharpen decision boundaries and handle hard samples.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72c58b1c8ae5a53950bfc6d9e8fcca6dc27fc849f514d47d4a2cdff795cb10b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes AVP-Fusion, a two-stage deep learning framework that integrates adaptive feature fusion and contrastive learning for identifying antiviral peptides (AVPs). The method dynamically fuses multi-modal sequence features and uses contrastive learning to improve classification, achieving state-of-the-art accuracy and enabling precise prediction of antiviral activity against specific viral families.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[AVP-Fusion: 抗病毒肽识别 / Antiviral Peptide Identification] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题 / Problem] --> P1[现有方法难以捕捉复杂序列依赖 / Current methods struggle with sequence dependencies]
        Problem --> P2[难以处理模糊样本 / Hard to handle ambiguous samples]
        Method[主要方法 / Method] --> M1[构建全景特征空间 / Construct panoramic feature space]
        Method --> M2[自适应门控机制融合特征 / Adaptive Gating Mechanism for feature fusion]
        Method --> M3[对比学习与数据增强 / Contrastive learning & data augmentation]
        Results[关键结果 / Results] --> R1[准确率0.9531, MCC 0.9064 / Accuracy 0.9531, MCC 0.9064]
        Results --> R2[优于现有方法 / Outperforms SOTA]
        Results --> R3[实现病毒家族亚类预测 / Enables viral family subclass prediction]
    ```

- **[arXiv251229] Discovering Sparse Recovery Algorithms Using Neural Architecture Search**
  - **tags:** [ai], [sparse recovery], [neural architecture search, meta-learning, iterative shrinkage thresholding algorithm, sparse optimization, algorithm discovery]
  - **authors:** Patrick Yubeaton, Sarthak Gupta, M. Salman Asif, Chinmay Hegde
  - **institution:** New York University, University of California, Riverside
  - **link:** https://arxiv.org/pdf/2512.21563
  - **contributions:** 1. Proposes a meta-learning framework using Neural Architecture Search (NAS) for automated discovery of sparse recovery algorithms. 2. Demonstrates the framework's capability to rediscover key elements of ISTA and FISTA from a search space of over 50,000 variables. 3. Shows the framework's applicability to various data distributions and algorithms beyond ISTA/FISTA.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49f1d5d0a89c3d52b36f1e443675494175442f0930725fc8a763e525ca05243a_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a meta-learning framework that uses Neural Architecture Search (NAS) to automatically discover sparse recovery algorithms. It successfully rediscovers components of ISTA and FISTA from a large search space and demonstrates generalizability to other algorithms and data distributions.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Discovering Sparse Recovery Algorithms Using Neural Architecture Search] --> B[核心问题/Problem: Automated discovery of sparse optimization algorithms is difficult and heuristic-driven]
    A --> C[主要方法/Method: Meta-learning framework using Neural Architecture Search (NAS) for algorithm rediscovery]
    A --> D[关键结果/Results: Rediscovered ISTA/FISTA elements; framework applies to various data and algorithms]
    ```

- **[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search**
  - **tags:** [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]
  - **authors:** Maximilian Weichart
  - **institution:** University of Regensburg
  - **link:** https://arxiv.org/pdf/2512.21648
  - **code:** https://github.com/Max-We/inverse-rpo
  - **contributions:** 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Variance-Aware Prior-Based Tree Policies for MCTS] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Extending prior-based UCTs from other UCBs is challenging]
        C[主要方法/Method: Propose Inverse-RPO to derive prior-based UCTs; apply to UCB-V]
        D[关键结果/Results: New policies outperform PUCT without extra cost]
    ```

- **[arXiv251229] How Do Agents Perform Code Optimization? An Empirical Study**
  - **tags:** [se], [code optimization], [AI coding agents, performance optimization, empirical study, pull request analysis, AIDev dataset]
  - **authors:** Huiyun Peng, Antonio Zhong, Ricardo Andrés Calvo Méndez, Kelechi G. Kalu, James C. Davis
  - **institution:** Purdue University
  - **link:** https://arxiv.org/pdf/2512.21757
  - **contributions:** 1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp
  - **Simple LLM Summary:** This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[How Do Agents Perform Code Optimization? An Empirical Study] --> B[核心问题/Problem: AI coding agents' effectiveness on real-world performance optimization tasks is unknown.]
        A --> C[主要方法/Method: Empirical comparison of 324 agent-generated and 83 human-authored performance PRs from AIDev dataset.]
        A --> D[关键结果/Results: AI-authored PRs use similar patterns but include less explicit performance validation (45.7% vs 63.6%).]
    ```

- **[arXiv251229] UniLabOS: An AI-Native Operating System for Autonomous Laboratories**
  - **tags:** [mlsys], [agent system], [autonomous laboratory, operating system, distributed edge-cloud architecture, CRUTD protocol, A/R/A&R model]
  - **authors:** Jing Gao, Junhan Chang, Haohui Que, Yanfei Xiong, Shixiang Zhang, Xianwei Qi, Zhen Liu, Jun-Jie Wang, Qianjun Ding, Xinyu Li, Ziwei Pan, Qiming Xie, Zhuang Yan, Junchi Yan, Linfeng Zhang
  - **institution:** DP Technology, Shanghai Jiao Tong University, Peking University, AI for Science Institute, Beijing
  - **link:** https://arxiv.org/pdf/2512.21766
  - **contributions:** 1. Proposes UniLabOS, an AI-native operating system that bridges high-level planning and low-level robotic execution for autonomous labs using typed, stateful abstractions and transactional safeguards. 2. Introduces a unified Action/Resource/Action&Resource (A/R/A&R) model and a dual-topology representation for lab structure, enabling protocol mobility across reconfigurable hardware. 3. Implements a transactional CRUTD protocol and a distributed edge-cloud architecture to reconcile digital state with physical motion and support robust, decentralized orchestration of heterogeneous instruments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c14a317a7f4c0283c03fbbdb64bfa6d4f6990a787d704f45dddd3134c96d9a_w640_q70.webp
  - **Simple LLM Summary:** The paper presents UniLabOS, an AI-native operating system designed to unify fragmented software in autonomous laboratories. It uses a novel A/R/A&R model, dual-topology representation, and a transactional CRUTD protocol on a distributed architecture to enable robust, reproducible, and agent-ready experimentation. The system is demonstrated across four real-world settings, establishing a scalable foundation for closed-loop scientific discovery.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[UniLabOS: An AI-Native Operating System for Autonomous Laboratories] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[软件碎片化阻碍自主实验室采用/Fragmented software hinders adoption of autonomous labs]
        C --> C1[AI原生操作系统/AI-native operating system]
        C1 --> C2[统一模型: A/R/A&R/Unified A/R/A&R model]
        C1 --> C3[双重拓扑结构/Dual-topology representation]
        C1 --> C4[事务性CRUTD协议/Transactional CRUTD protocol]
        C1 --> C5[分布式边云架构/Distributed edge-cloud architecture]
        D --> D1[四个真实场景验证/Four real-world demonstrations]
        D --> D2[异构仪器稳健编排/Robust orchestration across heterogeneous instruments]
        D --> D3[为可复现、可溯源的实验奠定基础/Foundation for reproducible, provenance-aware experimentation]
    ```

- **[arXiv251229] BertsWin: Resolving Topological Sparsity in 3D Masked Autoencoders via Component-Balanced Structural Optimization**
  - **tags:** [cv], [3d medical image analysis], [Masked Autoencoder, Swin Transformer, Self-Supervised Learning, 3D Vision Transformer, Structural Priority Loss]
  - **authors:** Evgeny Alves Limarenko, Anastasiia Studenikina
  - **institution:** Moscow Institute of Physics and Technology
  - **link:** https://arxiv.org/pdf/2512.21769
  - **contributions:** 1. Proposed BertsWin, a hybrid architecture combining full BERT-style token masking with Swin Transformer windows to preserve 3D spatial topology during SSL pre-training. 2. Introduced a structural priority loss function to enhance learning. 3. Demonstrated significant acceleration in semantic convergence (5.8x) and a 15-fold reduction in training epochs to reach SOTA fidelity when combined with the GradientConductor optimizer, without increasing computational FLOPs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18d8b6d7f8a20f3bce77706daf18b554423899bdff962eb21fde56292e0c3fde_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the difficulty of applying standard Masked Autoencoders to 3D medical images, which lose spatial context. It proposes BertsWin, a hybrid architecture that maintains a full 3D token grid using Swin Transformer windows and a structural loss. The method achieves much faster convergence and state-of-the-art reconstruction fidelity for 3D CBCT scans without extra computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("BertsWin: 3D MAE优化") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("3D MAE拓扑稀疏性/Topological Sparsity in 3D MAE")
        Problem --> P2("破坏空间关系/Destroys Spatial Context")
        Method --> M1("BertsWin混合架构/BertsWin Hybrid Architecture")
        Method --> M2("完整3D令牌网格/Full 3D Token Grid")
        Method --> M3("Swin窗口 & 结构损失/Swin Windows & Structural Loss")
        Results --> R1("5.8x语义收敛加速/5.8x Faster Convergence")
        Results --> R2("15倍训练轮次减少/15x Fewer Epochs")
        Results --> R3("FLOPs持平，总资源减少/FLOP Parity, Net Resource Reduction")
    ```

- **[arXiv251229] Fast Inference of Visual Autoregressive Model with Adjacency-Adaptive Dynamical Draft Trees**
  - **tags:** [mlsys], [multi-modal inference], [speculative decoding, draft tree, inference acceleration, autoregressive image generation, dynamic tree structure]
  - **authors:** Haodong Lei, Hongsong Wang, Xin Geng, Liang Wang, Pan Zhou
  - **institution:** Southeast University, Institute of Automation Chinese Academy of Sciences, Singapore Management University
  - **link:** https://arxiv.org/pdf/2512.21857
  - **code:** https://github.com/Haodong-Lei-Ray/ADT-Tree
  - **contributions:** 1. Identified the key obstacle of applying speculative decoding to visual AR models: inconsistent acceptance rates across draft trees due to spatially varying token prediction difficulty. 2. Proposed ADT-Tree, an adjacency-adaptive dynamic draft tree that dynamically adjusts tree depth and width based on adjacent token states and prior acceptance rates. 3. Demonstrated significant speedups (over 3x) on benchmarks and seamless integration with relaxed sampling methods for further acceleration.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b9ff13149fa2d6733868b2125e7af2ae06239a529152a057b80d0d6f357ccf3_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the slow inference of visual autoregressive models by proposing ADT-Tree, a dynamic draft tree method that adapts its structure to image region complexity. It achieves over 3x speedup on standard benchmarks and can be combined with other sampling techniques for additional gains.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Fast Inference of Visual AR Model with ADT-Tree<br>视觉自回归模型快速推理与ADT-Tree"]
        Root --> Problem["核心问题/Problem<br>Visual AR models have slow sequential inference.<br>视觉AR模型推理慢"]
        Root --> Method["主要方法/Method<br>Propose Adjacency-Adaptive Dynamical Draft Trees (ADT-Tree).<br>提出邻接自适应动态草稿树"]
        Root --> Results["关键结果/Results<br>Achieves 3.13x/3.05x speedup on benchmarks.<br>在基准测试上实现3.13x/3.05x加速"]
        Problem --> P1["Spatially varying token prediction difficulty.<br>空间变化的token预测难度"]
        Method --> M1["Dynamically adjusts tree depth & width.<br>动态调整树深度与宽度"]
        Method --> M2["Leverages adjacency & prior acceptance rates.<br>利用邻接关系和先验接受率"]
        Results --> R1["Integrates with relaxed sampling.<br>可与松弛采样方法结合"]
    ```

- **[arXiv251229] Accelerate Speculative Decoding with Sparse Computation in Verification**
  - **tags:** [mlsys], [llm inference], [speculative decoding, sparse computation, verification stage, mixture-of-experts (MoE), efficiency-accuracy trade-off]
  - **authors:** Jikai Wang, Jianchao Tan, Yuxuan Hu, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Juntao Li, Min Zhang
  - **institution:** Soochow University, Meituan
  - **link:** https://arxiv.org/pdf/2512.21911
  - **contributions:** 1. Systematically analyzes and identifies structured computational redundancy across attention, FFN, and MoE components during the verification stage of speculative decoding. 2. Proposes a sparse verification framework that jointly sparsifies these components to reduce the dominant computation cost. 3. Introduces an inter-draft token and inter-layer retrieval reuse strategy to further reduce redundant computation without additional training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the computational bottleneck in the verification stage of speculative decoding for LLMs, especially for long-context and MoE models. It proposes a framework that applies sparse computation techniques to the verification stage and employs a retrieval reuse strategy to reduce redundant calculations. Experiments show the method achieves a favorable efficiency-accuracy trade-off while maintaining stable acceptance length.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Accelerate Speculative Decoding with Sparse Computation in Verification] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[验证阶段成为瓶颈/Verification stage is bottleneck]
        B1 --> B2[长上下文与MoE模型/Long-context & MoE models]
        C --> C1[稀疏验证框架/Sparse Verification Framework]
        C1 --> C2[联合稀疏化注意力、FFN、MoE/Jointly sparsifies Attention, FFN, MoE]
        C1 --> C3[检索重用策略/Retrieval Reuse Strategy]
        D --> D1[有利的效率-精度权衡/Favorable efficiency-accuracy trade-off]
        D --> D2[稳定的接受长度/Stable acceptance length]
    ```

- **[arXiv251229] Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms**
  - **tags:** [ai], [multi-armed bandits], [combinatorial multi-armed bandits, probabilistically triggered arms, hybrid learning, offline data, online interaction]
  - **authors:** Kongchang Zhou, Tingyu Zhang, Wei Chen, Fang Kong
  - **institution:** Southern University of Science and Technology, Microsoft Research
  - **link:** https://arxiv.org/pdf/2512.21925
  - **contributions:** 1. Proposes a new hybrid CMAB-T framework that integrates offline data with online interaction to address the complementary weaknesses of purely online or offline methods. 2. Introduces the hybrid CUCB algorithm, which leverages offline data to guide exploration and strategically uses online interactions to correct dataset bias. 3. Provides theoretical regret guarantees and empirical results demonstrating the algorithm's consistent advantage over purely online or offline baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e97b8cf09a0691d48238a8272fecd32791ddc20b9ba00115a757d778b1e2017f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a hybrid framework for combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) that combines offline data with online interaction. The core method is the hybrid CUCB algorithm, which uses offline data to accelerate learning and online interaction to correct for dataset limitations. Theoretical and empirical results show this hybrid approach outperforms purely online or offline methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Hybrid CMAB-T<br>混合组合多臂老虎机") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("在线方法成本高、适应慢<br>Online: High Cost, Slow")
        Problem --> P2("离线方法受数据质量限制<br>Offline: Data Quality Limits")
        Method --> M1("提出混合CMAB-T框架<br>Propose Hybrid CMAB-T Framework")
        Method --> M2("设计混合CUCB算法<br>Design Hybrid CUCB Algorithm")
        M2 --> M2a("利用离线数据引导探索<br>Use Offline Data to Guide")
        M2 --> M2b("结合在线交互纠正偏差<br>Use Online to Correct Bias")
        Results --> R1("理论悔恨界保证<br>Theoretical Regret Guarantee")
        Results --> R2("实验显示一致优势<br>Empirical Consistent Advantage")
    ```

- **[arXiv251229] StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision**
  - **tags:** [cv], [robotic vision], [stereo vision, vision-language-action models, geometric-semantic fusion, depth estimation, robotic manipulation]
  - **authors:** Shengliang Deng, Mi Yan, Yixin Zheng, Jiayi Su, Wenhao Zhang, Xiaoguang Zhao, Heming Cui, Zhizheng Zhang, He Wang
  - **institution:** Peking University, The University of Hong Kong, Institute of Automation, Chinese Academy of Sciences, Beijing Academy of Artificial Intelligence
  - **link:** https://arxiv.org/pdf/2512.21970
  - **code:** https://shengliangd.github.io/StereoVLA-Webpage
  - **contributions:** 1. Proposed StereoVLA, a novel Vision-Language-Action model that leverages stereo vision for enhanced spatial perception. 2. Introduced a Geometric-Semantic Feature Extraction module to fuse geometric cues from stereo differences with semantic features from a monocular view. 3. Designed an auxiliary Interaction-Region Depth Estimation task to improve spatial understanding and accelerate model convergence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fbd07a25a843958488215748e8162f92542370bba173316326de44d4be3c65f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of single-view input in Vision-Language-Action (VLA) models for robotic manipulation by introducing StereoVLA, which utilizes stereo vision. The core method involves a novel module to extract and fuse geometric and semantic features, along with an auxiliary depth estimation task. Experiments show the model significantly outperforms baselines in stereo-based tasks and is robust to camera pose variations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1(单目VLA模型缺乏精确的几何感知/Single-view VLAs lack accurate geometry perception)
        C --> C1(提出StereoVLA模型/Propose StereoVLA model)
        C1 --> C2(几何-语义特征提取模块/Geometric-Semantic Feature Extraction)
        C2 --> C3(从立体视图提取几何特征/Extract geometric features from stereo views)
        C2 --> C4(从单目视图提取语义特征/Extract semantic features from monocular view)
        C1 --> C5(辅助交互区域深度估计任务/Auxiliary Interaction-Region Depth Estimation task)
        D --> D1(在立体设置下大幅超越基线/Large margin outperforms baselines under stereo setting)
        D --> D2(对相机位姿变化具有强鲁棒性/Strong robustness to camera pose variations)
    ```

- **[arXiv251229] DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction**
  - **tags:** [ai], [computational biology], [protein language model, ESM-2, dual-stream architecture, 1D CNN, transformer encoder]
  - **authors:** Aicha Boutorh, Soumia Bouyahiaoui, Sara Belhadj, Nour El Yakine Guendouz, Manel Kara Laouar
  - **institution:** National School of Artificial Intelligence (ENSIA)
  - **link:** https://arxiv.org/pdf/2512.22007
  - **contributions:** 1. Proposes DuaDeep-SeqAffinity, a novel sequence-only deep learning framework for antigen-antibody affinity prediction using a dual-stream hybrid architecture. 2. Integrates pre-trained ESM-2 embeddings with 1D CNNs for local motifs and Transformer encoders for global context, followed by a fusion module. 3. Demonstrates superior performance over single-branch models and existing SOTA methods, even surpassing some structure-sequence hybrid models, proving the efficacy of sequence-only high-fidelity embeddings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1985304be62407b10b5e5be53aea80fe4ff1468be03e261847b49774ddd937a8_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces DuaDeep-SeqAffinity, a deep learning framework that predicts antigen-antibody binding affinity using only amino acid sequences. It combines ESM-2 embeddings with a dual-stream architecture of 1D CNNs and Transformers to capture local and global features. The model outperforms existing methods, showing that sequence-only models can effectively capture binding patterns and accelerate therapeutic discovery.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DuaDeep-SeqAffinity: 序列抗原-抗体亲和力预测 / Sequence-Only Antigen-Antibody Affinity Prediction] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统方法依赖稀缺的3D结构 / Traditional methods rely on scarce 3D structures]
        C --> C1[双流混合架构 / Dual-Stream Hybrid Architecture]
        C1 --> C2[使用ESM-2嵌入 / Uses ESM-2 Embeddings]
        C1 --> C3[1D CNN检测局部模式 / 1D CNN for Local Motifs]
        C1 --> C4[Transformer编码全局上下文 / Transformer for Global Context]
        C1 --> C5[融合模块整合特征 / Fusion Module Integrates Features]
        D --> D1[性能超越SOTA / Outperforms SOTA]
        D --> D2[皮尔逊相关: 0.688 / Pearson: 0.688]
        D --> D3[AUC: 0.890]
        D --> D4[证明序列嵌入的有效性 / Proves Efficacy of Sequence Embeddings]
    ```

- **[arXiv251229] StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars**
  - **tags:** [mlsys], [diffusion models], [autoregressive distillation, adversarial refinement, real-time streaming, reference-anchored positional re-encoding, consistency-aware discriminator]
  - **authors:** Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu
  - **institution:** Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University
  - **link:** https://arxiv.org/pdf/2512.22065
  - **code:** https://streamavatar.github.io
  - **contributions:** 1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Non-causal, high-cost diffusion models unsuitable for real-time streaming; Limited to head-and-shoulder, lacking gestures.]
        C[主要方法/Method<br>Two-stage autoregressive adaptation (distillation + refinement) with Reference Sink, RAPR, Consistency-Aware Discriminator.]
        D[关键结果/Results<br>State-of-the-art real-time, interactive full-body avatar with natural talking/listening and gestures.]
    ```

- **[arXiv251229] Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling**
  - **tags:** [mlsys], [llm inference], [SRAM, frequency scaling, energy-delay product, systolic array, memory bandwidth]
  - **authors:** Hannah Atmer, Yuan Yao, Thiemo Voigt, Stefanos Kaxiras
  - **institution:** Uppsala University
  - **link:** https://arxiv.org/pdf/2512.22066
  - **contributions:** 1. Quantified the distinct energy and performance impacts of SRAM size and operating frequency on the compute-bound prefill and memory-bound decode phases of LLM inference. 2. Demonstrated a counter-intuitive result: high compute frequency can reduce total energy by shortening execution time and reducing static energy more than the dynamic power increase. 3. Identified an optimal hardware configuration (high frequency, small SRAM buffer) that minimizes the energy-delay product, providing concrete design insights for energy-efficient accelerators.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how on-chip SRAM size and operating frequency affect the energy efficiency of LLM inference. Using a simulation methodology combining OpenRAM, LLMCompass, and ScaleSIM, it finds that a high-frequency, small-SRAM configuration optimizes the energy-delay product, as memory bandwidth caps decode phase improvements. The analysis provides architectural guidance for designing efficient LLM accelerators.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>LLM推理能耗高，Prefill与Decode阶段瓶颈不同"] --> Problem_Sub1["SRAM大小与频率如何影响能效？"]
        Problem --> Problem_Sub2["内存带宽如何限制性能？"]
        Method["主要方法/Method<br>结合OpenRAM, LLMCompass, ScaleSIM的模拟方法"] --> Method_Sub1["能耗建模/Energy Modeling"]
        Method --> Method_Sub2["延迟模拟/Latency Simulation"]
        Method --> Method_Sub3["操作强度分析/Operational Intensity"]
        Results["关键结果/Results"] --> Results_Sub1["总能耗主要由SRAM大小决定<br>大缓存增加静态能耗"]
        Results --> Results_Sub2["高频可降低总能耗<br>（减少静态能耗）"]
        Results --> Results_Sub3["最优配置：高频(1200-1400MHz) + 小缓存(32-64KB)"]
    ```

- **[arXiv251229] Yume-1.5: A Text-Controlled Interactive World Generation Model**
  - **tags:** [mlsys], [diffusion models], [interactive world generation, long-video generation, attention distillation, context compression, text-controlled generation]
  - **authors:** Xiaofeng Mao, Zhen Li, Chuanhao Li, Xiaojie Xu, Kaining Ying, Tong He, Jiangmiao Pang, Yu Qiao, Kaipeng Zhang
  - **institution:** Shanghai AI Laboratory, Fudan University, Shanghai Innovation Institute
  - **link:** https://arxiv.org/pdf/2512.22096
  - **code:** https://github.com/stdstu12/YUME
  - **contributions:** 1. A long-video generation framework integrating unified context compression with linear attention. 2. A real-time streaming acceleration strategy using bidirectional attention distillation and an enhanced text embedding scheme. 3. A text-controlled method for generating world events.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f7ffd3f0a90ba67551ade4e28abf8e27d5d08c106e463f85f9447011008416b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Yume-1.5, a framework to address challenges in generating interactive, explorable worlds using diffusion models, such as large model size and slow inference. The method introduces a novel architecture combining context compression, attention distillation, and text-based event control to enable real-time, keyboard-controlled world generation from text or images. The work concludes with a public codebase demonstrating the feasibility of text-controlled interactive world creation.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Yume-1.5: A Text-Controlled Interactive World Generation Model] --> Problem(核心问题/Problem)
        Root --> Method(主要方法/Method)
        Root --> Results(关键结果/Results)
        Problem --> P1[大模型参数与慢推理/Large Model & Slow Inference]
        Problem --> P2[缺乏文本控制/Lack of Text Control]
        Method --> M1[长视频生成框架/Long-Video Gen Framework]
        Method --> M2[实时流加速策略/Real-time Streaming]
        Method --> M3[文本控制事件生成/Text-Controlled Events]
        M1 --> M1_Sub[统一上下文压缩与线性注意力/Unified Context Compression & Linear Attention]
        M2 --> M2_Sub[双向注意力蒸馏与文本嵌入/Bidirectional Attention Distillation & Text Embedding]
        Results --> R1[生成交互式世界/Generates Interactive Worlds]
        Results --> R2[支持键盘探索/Supports Keyboard Exploration]
        Results --> R3[公开代码库/Public Codebase]
    ```

- **[arXiv251229] Enabling Ultra-Fast Cardiovascular Imaging Across Heterogeneous Clinical Environments with a Generalist Foundation Model and Multimodal Database**
  - **tags:** [cv], [medical image reconstruction], [foundation model, k-space, multimodal database, zero-shot generalization, accelerated imaging]
  - **authors:** Zi Wang, Mingkai Huang, Zhang Shi, Hongjie Hu, Lan Lan, Hui Zhang, Yan Li, Xi Hu, Qing Lu, Zongming Zhu, Qiong Yao, Yuxiang Dai, Fanwen Wang, Yinzhe Wu, Jun Lyu, Qianqian Gao, Guangming Xu, Zhenxuan Zhang, Haosen Zhang, Qing Li, Guangming Wang, Tianxing He, Lizhen Lan, Siyue Li, Le Xue, Mengting Sun, Yuntong Lyu, Junpu Hu, Jiayu Zhu, Rizwan Ahmad, Zhengyu Bu, Xianling Qian, Guanke Cai, Ruiyu Cao, Weirui Cai, Chang Xu, Yuyang Ren, Feidan Yu, Siying Ma, Ziqiang Xu, Xinran Chen, Sha Hua, Daniel Kim, Yajing Zhang, Chen Ouyang, Wenjia Bai, Jing Qin, Yucheng Yang, Daniel Rueckert, He Wang, Qian Tao, Claudia Prieto, Michael Markl, Alistair Young, Lianming Wu, Shuo Wang, Chen Qin, Mengsu Zeng, Xihong Hu, Haibo Xu, Xiaobo Qu, Hao Li, Guang Yang, Chengyan Wang
  - **institution:** Imperial College London, Fudan University, Xiamen University
  - **link:** https://arxiv.org/pdf/2512.21652
  - **contributions:** 1. The curation of MMCMR-427K, the largest and most comprehensive multimodal cardiovascular magnetic resonance (CMR) k-space database. 2. The introduction of CardioMM, a generalist reconstruction foundation model that unifies semantic understanding with physics-informed data consistency for robust, accelerated imaging. 3. Demonstrating state-of-the-art performance and strong zero-shot generalization across heterogeneous clinical settings, enabling up to 24x acceleration without compromising clinical integrity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the slow scan times and environmental heterogeneity limiting clinical cardiovascular MRI. It proposes CardioMM, a generalist foundation model trained on a large multimodal k-space database (MMCMR-427K), which achieves robust, ultra-fast reconstructions across diverse scanners and protocols. The results show that CardioMM enables high acceleration (up to 24x) while preserving diagnostic quality and generalizing to unseen clinical environments.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Enabling Ultra-Fast Cardiovascular Imaging...] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[CMR扫描时间长/CMR Scan Time Long]
    B --> B2[临床环境异质性高/High Clinical Heterogeneity]
    C --> C1[构建多模态数据库MMCMR-427K/Build Multimodal DB MMCMR-427K]
    C --> C2[提出通用基础模型CardioMM/Propose Generalist Foundation Model CardioMM]
    D --> D1[实现24倍加速成像/Achieve 24x Accelerated Imaging]
    D --> D2[零样本泛化至新环境/Zero-shot Generalization to New Settings]
    D --> D3[保持诊断质量/Preserve Diagnostic Quality]
    ```

## 2025-12-30

**cs.DC total: 42**

- **[arXiv251230] GPU-Virt-Bench: A Comprehensive Benchmarking Framework for Software-Based GPU Virtualization Systems**
  - **tags:** [mlsys], [llm inference], [GPU Virtualization, Benchmarking, Multi-tenancy, CUDA, Performance Isolation]
  - **authors:** Jithin VG, Ditto PS
  - **institution:** Bud Ecosystem Inc
  - **link:** https://arxiv.org/pdf/2512.22125
  - **code:** https://github.com/BudEcosystem/GPU-Virt-Bench
  - **contributions:** 1. Proposed GPU-Virt-Bench, a comprehensive benchmarking framework with 56 metrics across 10 categories for evaluating software-based GPU virtualization systems. 2. Enabled systematic comparison between software virtualization approaches (e.g., HAMi-core, BUD-FCSP) and ideal hardware-based MIG behavior. 3. Demonstrated the framework's utility by revealing critical performance characteristics for production deployment decisions in multi-tenant environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a1c9f2d4dfba1fc452a424ad0f1298f01afe6d95dfd39dd2ff3f0c1bac9430c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of standardized evaluation for software-based GPU virtualization systems, which are needed for efficient GPU sharing in AI/LLM workloads. The authors propose GPU-Virt-Bench, a comprehensive benchmarking framework that measures performance across multiple critical dimensions. The framework provides actionable insights for practitioners by comparing software solutions against hardware-based baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GPU-Virt-Bench: A Comprehensive Benchmarking Framework] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[GPU资源共享需求高，但软件虚拟化方案缺乏标准化评估/High demand for GPU sharing, but software virtualization lacks standardized evaluation]
        C --> C1[提出包含56个指标、10个类别的综合基准测试框架/Propose a comprehensive benchmarking framework with 56 metrics across 10 categories]
        D --> D1[系统比较软件方案与MIG，为生产部署提供关键性能洞察/Systematic comparison between software approaches and MIG provides key performance insights for deployment]
    ```

- **[arXiv251230] SoDA: An Efficient Interaction Paradigm for the Agentic Web**
  - **tags:** [mlsys], [agent system], [Sovereign Digital Avatar, Intent-Permission Handshake, orthogonal decoupling, A2A protocols, dual-factor adaptive routing]
  - **authors:** Zicai Cui, Zhouyuan Jian, Weiwen Liu, Weinan Zhang
  - **institution:** Shanghai Jiao Tong University, Shanghai Innovation Institute
  - **link:** https://arxiv.org/pdf/2512.22135
  - **contributions:** 1. Proposes a user sovereignty interaction paradigm for the Agentic Web, decoupling memory from application logic to break data lock-in and shifting from explicit instruction to implicit intent alignment to reduce cognitive load. 2. Implements the paradigm via the Sovereign Digital Avatar (SoDA) with an orthogonal decoupling design of storage, computation, and interaction, establishing the principle of "data as a persistent asset, model as a transient tool". 3. Designs an Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor adaptive routing for active risk governance in zero-trust environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes the Sovereign Digital Avatar (SoDA), a new interaction paradigm for the Agentic Web that decouples user memory from applications and uses intent alignment to reduce cognitive load. It introduces an architecture with orthogonal decoupling and a secure handshake mechanism for zero-trust environments. Empirical results show it significantly reduces token consumption and user cognitive load compared to existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SoDA: An Efficient Interaction Paradigm for the Agentic Web] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[数据锁定/Data Lock-in]
        B --> B2[认知过载/Cognitive Overload]
        C --> C1[主权数字化身/Sovereign Digital Avatar (SoDA)]
        C --> C2[正交解耦设计/Orthogonal Decoupling Design]
        C --> C3[意图-权限握手机制/Intent-Permission Handshake Mechanism]
        D --> D1[降低令牌消耗/Reduces Token Consumption by 27-35%]
        D --> D2[降低认知负载/Reduces Cognitive Load by 72% vs RAG, 88% vs Manual]
    ```

- **[arXiv251230] SlimEdge: Lightweight Distributed DNN Deployment on Constrained Hardware**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [Structured Pruning, Multi-Objective Optimization, Edge Inference, MVCNN, View-Adaptive Compression]
  - **authors:** Mahadev Sunil Kumar, Arnab Raha, Debayan Das, Gopakumar G, Amitava Mukherjee
  - **institution:** Accenture PLC, Intel Corporation, Indian Institute of Science, Amrita Vishwa Vidyapeetham, Birla Institute of Technology and Science
  - **link:** https://arxiv.org/pdf/2512.22136
  - **contributions:** 1. Proposes a framework for lightweight DNN deployment that integrates structured pruning with multi-objective optimization to meet heterogeneous hardware constraints. 2. Demonstrates the framework on MVCNN by quantifying the contribution of individual views to accuracy for view-adaptive pruning budget allocation. 3. Shows experimentally that the compressed models meet user-specified accuracy and memory bounds while achieving 1.2x to 5.0x inference speedup across diverse hardware.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7687c3e58bfa2b22573745dffb608fb7c36a0c339dd9216829f78a284f51e662_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of deploying large DNNs on resource-constrained edge devices. It proposes SlimEdge, a method that combines structured pruning and multi-objective optimization to compress models like MVCNN while preserving task performance. The results show that this approach successfully meets specified accuracy and memory constraints while significantly reducing inference latency on various edge hardware platforms.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SlimEdge: Lightweight Distributed DNN Deployment] --> B(核心问题/Problem: DNN部署在资源受限的边缘设备上/DNN deployment on resource-constrained edge devices)
        A --> C(主要方法/Method: 结构化剪枝与多目标优化/Structured Pruning & Multi-Objective Optimization)
        A --> D(关键结果/Results: 满足精度与内存约束，推理延迟降低1.2x-5.0x/Meets accuracy & memory bounds, 1.2x-5.0x latency reduction)
    ```

- **[arXiv251230] HybridFlow: Adaptive Task Scheduling for Fast and Token-Efficient LLM Inference in Edge-Cloud Collaboration**
  - **tags:** [mlsys], [llm inference], [edge-cloud collaboration, task decomposition, adaptive routing, parallel execution, token-efficient inference]
  - **authors:** Jiangwen Dong, Jiayu Li, Wanyu Lin
  - **institution:** The Hong Kong Polytechnic University
  - **link:** https://arxiv.org/pdf/2512.22137
  - **contributions:** 1. Proposes HybridFlow, a resource-adaptive inference framework for collaborative reasoning between edge and cloud LLMs. 2. Introduces a two-stage method involving dynamic task decomposition for parallel execution and a learned router for resource-aware subtask assignment. 3. Demonstrates effectiveness in reducing end-to-end inference time and token usage while maintaining accuracy on multiple reasoning benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a14e12f757065eef8f857ead7c55331977412b8a4d1ba64499c5c1457d797284_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenges of high latency and token cost for LLM inference on edge devices by proposing HybridFlow, a framework that dynamically decomposes queries into parallel subtasks and adaptively routes them between edge and cloud models. The method reduces inference time and token consumption while preserving competitive accuracy, as validated on several reasoning benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("HybridFlow: Adaptive Task Scheduling for Fast and Token-Efficient LLM Inference in Edge-Cloud Collaboration") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("LLM推理延迟高，Token消耗大/High LLM inference latency & token cost")
        Problem --> P2("边缘设备资源受限/Resource-limited edge devices")
        Problem --> P3("现有协作方法粗粒度，效率低/Existing coarse-grained collaboration is inefficient")
        Method --> M1("任务分解与并行执行/Task Decomposition & Parallel Execution")
        Method --> M2("资源感知子任务路由/Resource-Aware Subtask Routing")
        Results --> R1("减少端到端推理时间/Reduces end-to-end inference time")
        Results --> R2("降低总体Token使用/Lowers overall token usage")
        Results --> R3("保持有竞争力的准确率/Maintains competitive accuracy")
    ```

- **[arXiv251230] HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA**
  - **tags:** [mlsys], [on-device ai], [FPGA, HLS, Point Cloud, Model Compression, Fixed-Point]
  - **authors:** Amur Saqib Pal, Muhammad Mohsin Ghaffar, Faisal Shafait, Christian Weis, Norbert Wehn
  - **institution:** National University of Sciences and Technology (Pakistan), RPTU Kaiserslautern-Landau (Germany)
  - **link:** https://arxiv.org/pdf/2512.22139
  - **code:** https://github.com/dll-ncai/HLS4PC
  - **contributions:** 1. Proposed HLS4PC, a parameterizable HLS framework for accelerating point-based 3D point cloud models on FPGA. 2. Introduced PointMLP-Lite, a 4x less complex model variant created via hardware-aware compression techniques (URS, quantization, pruning, fusion). 3. Demonstrated FPGA acceleration achieving 3.56x higher throughput than prior work and outperforming GPU/CPU implementations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21433bfda0767bbdfcee46f13fb3acd9373d13bb741d87a755643767c9ad74f9_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of real-time 3D point cloud processing by proposing HLS4PC, a parameterizable FPGA acceleration framework. The method combines algorithmic optimizations and hardware-aware model compression to create an efficient fixed-point implementation, which significantly outperforms previous accelerators and GPU/CPU baselines in throughput.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[GPU under-utilization due to sparse, unstructured point cloud data]
        P1 --> P2[High memory/computation demand hinders real-time performance]
        Method[主要方法/Method] --> M1[Parameterizable HLS framework for FPGA]
        M1 --> M2[Hardware-aware compression: URS, quantization, pruning, fusion]
        M2 --> M3[Creates PointMLP-Lite model]
        Results[关键结果/Results] --> R1[PointMLP-Lite: 4x less complex, ~2% accuracy drop]
        R1 --> R2[3.56x higher throughput vs. prior work]
        R2 --> R3[2.3x (GPU) and 22x (CPU) higher throughput]
    ```

- **[arXiv251230] On Harnessing Idle Compute at the Edge for Foundation Model Training**
  - **tags:** [mlsys], [llm training], [edge computing, tensor parallelism, parameter server, device heterogeneity, fault-tolerance]
  - **authors:** Leyang Xue, Meghana Madhyastha, Myungjin Lee, Amos Storkey, Randal Burns, Mahesh K. Marina
  - **institution:** The University of Edinburgh, Johns Hopkins University, Cisco Research
  - **link:** https://arxiv.org/pdf/2512.22142
  - **contributions:** 1. A novel selective hybrid tensor parallelism method to finely partition training operations for edge devices. 2. A parameter server-centric training framework to cope with device memory limits and avoid communication bottlenecks. 3. A cost optimization model to guide device selection and workload distribution, effectively handling device heterogeneity and churn.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fefe0f72fa70ae7be2cad54f15e74f96fd08cc506630060214e298521278148_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of decentralized foundation model training on edge devices, which is hindered by memory limits, communication overhead, and device heterogeneity. It proposes Cleave, a new paradigm that uses selective hybrid tensor parallelism and a parameter server framework to partition training efficiently. The evaluation shows Cleave matches cloud-based training performance, scales to thousands of devices, and handles failures with much faster recovery than prior methods.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[On Harnessing Idle Compute at the Edge for Foundation Model Training] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[现有边缘训练方法性能不足/Existing edge training falls short]
    B --> B2[设备内存与通信瓶颈/Device memory & communication bottlenecks]
    B --> B3[设备异构性与动态性/Device heterogeneity & dynamism]
    C --> C1[选择性混合张量并行/Selective hybrid tensor parallelism]
    C --> C2[参数服务器框架/Parameter server framework]
    C --> C3[成本优化模型/Cost optimization model]
    D --> D1[匹配云端训练性能/Matches cloud-based training]
    D --> D2[扩展至数千设备/Scales to thousands of devices]
    D --> D3[快速故障恢复/Fast failure recovery]
    ```

- **[arXiv251230] GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs**
  - **tags:** [hpc], [gpu kernels], [Minimal Executable Program (MEP), Automatic Error Repair, Performance Pattern Inheritance, iterative optimization, cross-platform]
  - **authors:** Ruifan Chu, Anbang Wang, Xiuxiu Bai, Shuai Liu, Xiaoshe Dong
  - **institution:** School of Software Engineering, Xi’an Jiaotong University
  - **link:** https://arxiv.org/pdf/2512.22147
  - **contributions:** 1. Proposes an end-to-end LLM framework that optimizes GPU kernels by constructing Minimal Executable Programs (MEPs) to avoid expensive full application builds and executions. 2. Introduces Automatic Error Repair and Performance Pattern Inheritance to automatically fix faults and reuse effective optimization strategies, reducing search cost. 3. Demonstrates cross-platform portability and effectiveness on NVIDIA GPUs and the Haiguang DCU platform, achieving significant speedups over direct LLM optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fd593bd3569f30bdbf11d361054f51142863fb91e592b76bc4eb2f600850c5e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high cost of full builds for GPU kernel optimization in large HPC applications by proposing an LLM framework that uses Minimal Executable Programs (MEPs) for iterative optimization. The method integrates automatic error repair and performance pattern inheritance to maintain correctness and reuse strategies. It achieves substantial speedups across different hardware platforms without requiring full-source dependencies.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Full builds & runs are expensive in large applications/大型应用中完整构建与运行成本高]
        C --> C1[Construct Minimal Executable Program (MEP) for kernel/为内核构建最小可执行程序]
        C --> C2[Multi-round iterative optimization with LLM feedback/基于LLM反馈的多轮迭代优化]
        C --> C3[Integrate Automatic Error Repair & Performance Pattern Inheritance/集成自动错误修复与性能模式继承]
        D --> D1[Achieves significant speedups (e.g., 5.05x, 7.77x)/获得显著加速比]
        D --> D2[Cross-platform portability (NVIDIA, DCU)/跨平台可移植性]
        D --> D3[Surpasses direct LLM optimization/超越直接LLM优化]
    ```

- **[arXiv251230] Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments**
  - **tags:** [mlsys], [agent system], [serverless computing, GPU resource allocation, workload scheduling, multi-agent systems, collaborative reasoning]
  - **authors:** Guilin Zhang, Wulan Guo, Ziqi Tan
  - **institution:** George Washington University
  - **link:** https://arxiv.org/pdf/2512.22149
  - **contributions:** 1. An adaptive GPU resource allocation framework for multi-agent systems in serverless environments that dynamically adjusts resources based on workload characteristics, agent priorities, and minimum requirements. 2. An O(N) complexity algorithm for real-time adaptation, enabling millisecond-scale reallocation to handle dynamic workload fluctuations. 3. A comprehensive evaluation demonstrating the framework's superiority over static and round-robin strategies, achieving 85% latency reduction while maintaining throughput and improving GPU utilization and cost-efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2fe7e30427c00e4689f161fb9912d4d11cc091ed6dd1dae3c4ea2c5805084e3b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes an adaptive GPU resource allocation framework to address the challenge of efficiently deploying heterogeneous multi-agent AI systems on serverless platforms. The method dynamically allocates resources using a real-time algorithm to handle varying computational demands and workload fluctuations. The results show it significantly reduces latency compared to baseline schedulers while maintaining throughput, offering a cost-effective solution for serverless multi-agent deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments<br/>面向无服务器环境的多智能体协同推理的自适应GPU资源分配"] --> Problem["核心问题/Problem<br/>Heterogeneous agent workloads & dynamic demands on serverless GPU platforms<br/>多智能体工作负载异构与无服务器GPU平台动态需求"]
        Root --> Method["主要方法/Method<br/>Adaptive GPU resource allocation framework with O(N) real-time algorithm<br/>基于O(N)实时算法的自适应GPU资源分配框架"]
        Root --> Results["关键结果/Results<br/>85% latency reduction vs. round-robin, maintains throughput<br/>相比轮询调度延迟降低85%，保持吞吐量"]
    ```

- **[arXiv251230] TL: Automatic End-to-End Compiler of Tile-Based Languages for Spatial Dataflow Architectures**
  - **tags:** [mlsys], [compiler & ir], [spatial dataflow, tile-based compilation, MLIR, on-chip network, hardware representation]
  - **authors:** Wei Li, Zhenyu Bai, Heru Wang, Pranav Dangi, Zhiqiang Zhang, Cheng Tan, Huiying Lan, Weng-Fai Wong, Tulika Mitra
  - **institution:** National University of Singapore, Arizona State University, Google, Lumai Ltd.
  - **link:** https://arxiv.org/pdf/2512.22168
  - **contributions:** 1. An end-to-end compiler framework (TL) that compiles tile-based programs (e.g., Triton kernels) onto spatial dataflow architectures, focusing on distributing tile instances across cores. 2. A novel hardware representation that captures interconnect topology, memory hierarchy, and compute capabilities to enable architecture-specific optimizations and support diverse targets. 3. A practical implementation built on the MLIR ecosystem, providing a generic entry point for different front-ends and an end point for different back-ends, demonstrated with performance gains over vendor libraries.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cce8d87d1dd357c986e9809985cc87b6430fd568820f39521500addb34e7eef7_w640_q70.webp
  - **Simple LLM Summary:** This paper presents TL, an end-to-end compiler framework that tackles the limited programmability of spatial dataflow accelerators by automatically mapping tile-based workloads across distributed cores to optimize data reuse and reduce communications. TL introduces a hardware-aware representation and is built on MLIR to support diverse targets. Experiments show it can match or exceed the performance of hand-tuned vendor libraries on kernels like GEMM and FlashAttention.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[TL: Automatic End-to-End Compiler] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[Limited Programmability of Spatial Accelerators<br/>空间加速器的有限可编程性]
        Problem --> P2[Poor Performance of Naive Mappings<br/>朴素映射性能差]
        Method[主要方法/Method] --> M1[End-to-End Tile-Based Compiler Framework<br/>端到端基于分块的编译器框架]
        Method --> M2[Hardware Representation for Topology & Memory<br/>用于拓扑和内存的硬件表示]
        Method --> M3[Built on MLIR Ecosystem<br/>基于MLIR生态系统构建]
        Results[关键结果/Results] --> R1[Performance on par with/vs Vendor Library (GEMM)<br/>性能与厂商库相当/超越(GEMM)]
        Results --> R2[Significant Speedup for FlashAttention<br/>FlashAttention显著加速]
    ```

- **[arXiv251230] BitFlipScope: Scalable Fault Localization and Recovery for Bit-Flip Corruptions in LLMs**
  - **tags:** [mlsys], [fault-tolerance], [bit-flip faults, fault localization, transformer reliability, residual-path perturbation, loss-sensitivity profiling]
  - **authors:** Muhammad Zeeshan Karamat, Sadman Saif, Christiana Chamon Garcia
  - **institution:** Virginia Tech
  - **link:** https://arxiv.org/pdf/2512.22174
  - **contributions:** 1. Introduces BitFlipScope, a scalable software framework for localizing bit-flip corruptions in transformer-based LLMs under two deployment scenarios (with and without a clean reference model). 2. Proposes differential analysis for fault localization when a reference model is available and residual-path perturbation/loss-sensitivity profiling for localization when no reference exists. 3. Enables lightweight performance recovery for corrupted models without requiring costly fine-tuning or full retraining.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e931785a8ed1d0dca51ed3c75265de72147ccd6e3d68df21de1c7cad78a1d912_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces BitFlipScope, a framework for localizing and recovering from bit-flip corruptions in LLMs. It uses differential analysis with a reference model or perturbation-based profiling without one to identify fault-affected regions, enabling targeted recovery without full retraining. The work aims to improve fault resilience for LLMs in hardware-prone and adversarial environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[BitFlipScope: Scalable Fault Localization and Recovery for Bit-Flip Corruptions in LLMs] --> B[核心问题/Problem: Bit-flip faults corrupt LLM parameters, causing unpredictable behavior]
        A --> C[主要方法/Method: Differential analysis with reference model; Residual-path perturbation & loss-sensitivity profiling without reference]
        A --> D[关键结果/Results: Enables fault localization and lightweight recovery, improving fault-resilient LLM deployment]
    ```

- **[arXiv251230] AiiDAlab: on the route to accelerate science**
  - **tags:** [hpc], [scientific workflow management], [AiiDAlab, AiiDA, provenance tracking, FAIR principles, web-based interface]
  - **authors:** Aliaksandr V.Yakutovich, Jusong Yu, Daniel Hollas, Edan Bainglass, Corsin Battaglia, Miki Bonacci, Lucas Fernandez Vilanova, Stephan Henne, Anders Kaestner, Michel Kenzelmann, Graham Kimbell, Jakob Lass, Fabio Lopes, Daniel G. Mazzone, Andres Ortega-Guerrero, Xing Wang, Nicola Marzari, Carlo A. Pignedoli, Giovanni Pizzi
  - **institution:** Empa, Paul Scherrer Institute, École Polytechnique Fédérale de Lausanne, University of Bristol
  - **link:** https://arxiv.org/pdf/2512.22173
  - **contributions:** 1. Development of the AiiDAlab platform, a web-based interface that simplifies access to and execution of complex computational workflows on supercomputers, lowering the barrier to entry for non-experts. 2. Maturation and expansion of the platform from its origins in computational materials science to support diverse scientific disciplines including quantum chemistry, atmospheric modeling, and experimental data analysis. 3. Integration with electronic laboratory notebooks (ELNs) and emphasis on automatic provenance tracking via AiiDA to enforce reproducibility and adherence to FAIR principles for generating Open Research Data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ffb3ec2c93f3c0a0b3a1f69f46586695b4825664dea8e67ccbdf005064367c46_w640_q70.webp
  - **Simple LLM Summary:** The paper presents AiiDAlab, a web-based platform designed to simplify the execution of complex computational workflows on supercomputers. It abstracts away technical details, provides an intuitive interface, and automatically tracks simulation provenance to ensure reproducibility. The platform has evolved to accelerate scientific discovery across multiple disciplines by allowing researchers to focus on their science rather than computational challenges.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[AiiDAlab: on the route to accelerate science]
        Root --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[复杂工作流执行需要专业知识/Complex workflow execution requires technical expertise]
        Method --> M1[提供基于浏览器的用户界面/Provide web-browser-based user interface]
        Method --> M2[底层AiiDA引擎自动追踪溯源/Underlying AiiDA engine automatically tracks provenance]
        Results --> R1[跨多学科加速科学发现/Accelerates scientific discovery across multiple disciplines]
        Results --> R2[确保可重复性与FAIR原则/Ensures reproducibility and FAIR principles]
    ```

- **[arXiv251230] iOS as Acceleration**
  - **tags:** [mlsys], [on-device ai], [distributed pipeline parallelism, mobile acceleration, iOS, memory constraints, thermal throttling]
  - **authors:** Alexander K. Chen
  - **institution:** Independent High School Researcher (No institutional affiliation inferred)
  - **link:** https://arxiv.org/pdf/2512.22180
  - **contributions:** 1. Proposes a novel proof-of-concept system using distributed pipeline parallelism to harness iOS devices as computational accelerators for local ML tasks. 2. Demonstrates the system's effectiveness in accelerating modest model training (e.g., ResNet-34) and agentic LRM tool-usage, achieving a 44% decrease in training time in a specific setup. 3. Explores the unique potential of ubiquitous mobile devices with powerful processors and sensors (e.g., LiDAR, GPS) as cost-effective resources for embodied agentic AI and local compute, discussing practical use-cases and limitations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2533767e76bdf97e302af13359b973b06a9948269cc9017131b6e880553cb6b9_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the barrier of expensive compute for local machine learning by proposing a system that uses distributed pipeline parallelism to leverage underutilized iOS phones as accelerators. The method partitions model weights to circumvent mobile memory limits, successfully accelerating tasks like training ResNet-34. The work concludes that commonplace mobile devices have significant potential to contribute to ML, especially for local, cost-sensitive, or sensor-driven applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[iOS as Acceleration] --> B[核心问题/Problem: Powerful compute is a barrier for local ML; Cloud is not always viable]
        A --> C[主要方法/Method: Use distributed pipeline parallelism to harness iOS devices as accelerators]
        A --> D[关键结果/Results: Achieved faster training for modest models; Highlights mobile potential for ML]
    ```

- **[arXiv251230] MatKV: Trading Compute for Flash Storage in LLM Inference**
  - **tags:** [mlsys], [llm inference], [retrieval-augmented generation, key-value cache, flash storage, prefill optimization, power efficiency]
  - **authors:** Kun-Woo Shin, Jay H. Park, Moonwook Oh, Yohan Jo, Jaeyoung Do, Sang-Won Lee
  - **institution:** Seoul National University, Samsung Electronics
  - **link:** https://arxiv.org/pdf/2512.22195
  - **code:** https://github.com/kunwooshin/MatKV
  - **contributions:** 1. Proposes MatKV, a scheme to precompute and materialize KV vectors of RAG documents in flash storage to avoid recomputation during inference. 2. Demonstrates that MatKV reduces inference time and power consumption by half for RAG workloads with minimal accuracy impact. 3. Shows MatKV enables additional optimizations like overlapping KV loading with decoding and enabling the use of low-end GPUs for decoding.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d47111ab2d615579a09c00ff5a99f391f035b974cc23e324cddfbabf4d23cec_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high compute and energy cost of the prefill phase in RAG-based LLM inference. It proposes MatKV, which precomputes and stores key-value vectors of documents in flash storage for reuse, trading compute for storage. Experiments show this approach halves inference time and power consumption while maintaining accuracy and enabling further hardware optimizations.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["MatKV: Trading Compute for Flash Storage in LLM Inference"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>RAG推理中prefill阶段计算开销大<br>High compute cost of prefill in RAG inference"]
        Method["主要方法/Method<br>预计算并物化KV向量到闪存<br>Precompute & materialize KVs to flash storage"]
        Results["关键结果/Results<br>推理时间与能耗减半<br>Halves inference time & power consumption"]
    ```

- **[arXiv251230] SPUMA: a minimally invasive approach to the GPU porting of OPENFOAM**
  - **tags:** [hpc], [computational fluid dynamics], [GPU porting, unified memory, memory pool manager, OpenFOAM, scalability]
  - **authors:** Simone Bnà, Giuseppe Giaquinto, Ettore Fadiga, Tommaso Zanelli, Francesco Bottau
  - **institution:** Cineca Supercomputing Centre, Università degli Studi di Napoli Federico II
  - **link:** https://arxiv.org/pdf/2512.22215
  - **contributions:** 1. Presents SPUMA, a full GPU porting of OpenFOAM targeting both NVIDIA and AMD GPUs. 2. Implements a portable programming model with a memory pool manager leveraging unified memory for efficient GPU utilization. 3. Demonstrates significant performance and energy efficiency gains through extensive testing on pre-exascale clusters, showing up to 82% energy reduction compared to CPU simulations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ea486a67026343b5f3c7d85db1ef1ff1202af04d0bd147ef25d9dc29565e2b1_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of GPU programmability for open-source CFD by introducing SPUMA, a portable GPU port of OpenFOAM that uses a memory pool manager with unified memory. The method was tested on LUMI and Leonardo clusters, showing strong scalability up to 65% efficiency and weak scalability up to 85%, while reducing energy consumption by up to 82% compared to CPU-based simulations.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[SPUMA: a minimally invasive approach to the GPU porting of OPENFOAM] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: GPU programmability challenge in open-source CFD] --> P1[GPU可编程性挑战/GPU Programmability Challenge]
        Method[主要方法/Method: Portable GPU porting with memory pool] --> M1[便携式编程模型/Portable Programming Model]
        Method --> M2[内存池管理器/Memory Pool Manager]
        Method --> M3[利用统一内存/Leverages Unified Memory]
        Results[关键结果/Results: Performance and energy efficiency on pre-exascale clusters] --> R1[强可扩展性达65%/Strong Scalability 65%]
        Results --> R2[弱可扩展性达85%/Weak Scalability 85%]
        Results --> R3[能耗降低82%/Energy Reduction 82%]
    ```

- **[arXiv251230] Mirage Persistent Kernel: A Compiler and Runtime for Mega-Kernelizing Tensor Programs**
  - **tags:** [mlsys], [llm inference], [megakernel, kernel fusion, SM-level graph, software pipelining, CUDA]
  - **authors:** Xinhao Cheng, Zhihao Zhang, Yu Zhou, Jianan Ji, Jinchen Jiang, Zepeng Zhao, Ziruo Xiao, Zihao Ye, Yingyi Huang, Ruihang Lai, Hongyi Jin, Bohan Hou, Mengdi Wu, Yixin Dong, Anthony Yip, Zihao Ye, Songting Wang, Wenqin Yang, Xupeng Miao, Tianqi Chen, Zhihao Jia
  - **institution:** Carnegie Mellon University, Tsinghua University, NVIDIA, University of Michigan, Purdue University
  - **link:** https://arxiv.org/pdf/2512.22219
  - **code:** https://github.com/mirage-project/mirage
  - **contributions:** 1. Introduces an SM-level graph representation for capturing fine-grained data dependencies across GPU streaming multiprocessors. 2. Develops a compiler and an in-kernel parallel runtime that automatically transforms multi-operator inference into a single, high-performance mega-kernel. 3. Enables previously infeasible GPU optimizations like cross-operator software pipelining and fine-grained kernel overlap, significantly reducing inference latency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f886cd06ce6c0f773c062fa38aae0fa982d862cc66ef54da9fbbfd6cf62dd86a_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces Mirage Persistent Kernel (MPK), a compiler and runtime system that automatically fuses multiple GPU kernels for model inference into a single, optimized mega-kernel. It achieves this by using a novel SM-level graph representation and decentralized scheduling to enable fine-grained optimizations like software pipelining. Evaluation shows MPK reduces LLM inference latency by up to 1.7x, pushing performance close to hardware limits.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Mirage Persistent Kernel<br>幻影持久内核] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Kernel-per-operator execution<br>limits GPU optimization<br>逐算子内核执行限制GPU优化]
        C --> C1[SM-level graph &<br>mega-kernel runtime<br>SM级图与巨型内核运行时]
        D --> D1[Reduces inference latency<br>by up to 1.7x<br>推理延迟降低高达1.7倍]
    ```

- **[arXiv251230] Scalable Cloud-Native Architectures for Intelligent PMU Data Processing**
  - **tags:** [mlsys], [cluster infrastructure], [cloud-native, distributed stream processing, containerized microservices, elastic resource orchestration, edge-cloud hybrid]
  - **authors:** Nachiappan Chockalingam, Akshay Deshpande, Lokesh Butra, Ram Sekhar Bodala, Nitin Saksena, Adithya Parthasarathy, Balakrishna Pothineni, Akash Kumar Agarwal
  - **institution:** IEEE, NTT Data, Amtrak, Albertsons Companies
  - **link:** https://arxiv.org/pdf/2512.22231
  - **contributions:** 1. A comprehensive theoretical framework for AI-enhanced cloud-based PMU analytics. 2. Mathematical formulations for distributed machine learning optimized for PMU time-series data. 3. Analysis of edge-cloud hybrid architectures with integrated security and privacy considerations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59263c4210b1af52fedb9e9660a5117d937ac4a63d70c41f31a04dc3c553429f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a scalable cloud-native architecture to address the latency and scalability challenges of processing high-frequency data from Phasor Measurement Units (PMUs) in smart grids. The method integrates AI with edge and cloud computing, using distributed stream processing and containerized microservices for real-time analytics. The analysis shows the architecture can achieve sub-second response times while scaling to large deployments, providing a robust foundation for next-generation grid analytics.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Scalable Cloud-Native Architectures for Intelligent PMU Data Processing"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>PMU数据规模大，传统架构延迟高，可扩展性差"]
        Method["主要方法/Method<br>云原生架构，集成AI、边缘与云计算，使用分布式流处理和微服务"]
        Results["关键结果/Results<br>实现亚秒级响应，可扩展至大规模部署，提供安全可靠的基础"]
    ```

- **[arXiv251230] Valori: A Deterministic Memory Substrate for AI Systems**
  - **tags:** [mlsys], [memory & caching], [deterministic memory, fixed-point arithmetic, vector embeddings, approximate nearest neighbor search, state machine]
  - **authors:** Varshith Gudur
  - **institution:** Independent Researcher (Valori Kernel Project)
  - **link:** https://arxiv.org/pdf/2512.22280
  - **code:** https://github.com/varshith-Git/Valori-Kernel
  - **contributions:** 1. Identifies and characterizes the fundamental non-determinism in AI memory systems caused by hardware-dependent floating-point arithmetic, which leads to divergent memory states and retrieval results. 2. Proposes Valori, a deterministic AI memory substrate that replaces floating-point operations with fixed-point arithmetic (Q16.16) and models memory as a replayable state machine. 3. Demonstrates that Valori guarantees bit-identical memory states, snapshots, and search results across different hardware platforms (e.g., x86 vs. ARM), establishing deterministic memory as a necessary primitive for trustworthy AI.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb7ed17a8a06e6a2b8760f08fa9345391995aee74a3542cacf55dd051b383f_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies non-determinism in AI memory systems due to hardware-dependent floating-point arithmetic, which compromises replayability and auditability. It proposes Valori, a memory substrate using fixed-point arithmetic and a state machine model to guarantee bit-identical behavior across platforms. The work concludes that deterministic memory is essential for building trustworthy AI systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Valori: A Deterministic Memory Substrate for AI Systems] --> B
        A --> C
        A --> D
        B[核心问题/Problem: AI内存非确定性/AI Memory Non-Determinism]
        C[主要方法/Method: 固定点算术与状态机/Fixed-Point Arithmetic & State Machine]
        D[关键结果/Results: 跨平台比特一致性/Cross-Platform Bit-Identical Results]
    ```

- **[arXiv251230] Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries**
  - **tags:** [mlsys], [llm inference], [Text-to-SQL, Cloud Cost Optimization, Query Efficiency, Large Language Models, Google BigQuery]
  - **authors:** Saurabh Deochake, Debajyoti Mukhopadhyay
  - **institution:** SentinelOne, WIDiCoReL Research Lab
  - **link:** https://arxiv.org/pdf/2512.22364
  - **contributions:** 1. Introduced a cloud-native cost evaluation methodology for Text-to-SQL systems, measuring bytes processed, slot utilization, and estimated query cost on production infrastructure. 2. Conducted an empirical evaluation of six LLMs on Google BigQuery, demonstrating that reasoning models achieve significantly lower cloud compute costs while maintaining high correctness. 3. Quantified cost variance across models, identified prevalent inefficiency patterns (e.g., missing partition filters), and provided deployment guidelines for cost-sensitive environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06f17566f5fb65cb73b79b0dbb64bde11c2f87d177f02865af7fc2d8910e3ac4_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the cloud compute costs of SQL queries generated by Large Language Models (LLMs) for Text-to-SQL tasks. By evaluating six state-of-the-art LLMs on Google BigQuery, it finds that reasoning models are more cost-efficient, processing far fewer bytes, and that execution time is a poor proxy for cloud cost. The work provides a new cost-focused evaluation methodology and guidelines for deploying cost-aware Text-to-SQL systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Existing efficiency metrics (e.g., VES) measure time, not cloud compute costs.] --> B1[问题背景/Context<br>LLMs achieve high Text-to-SQL accuracy, but cost efficiency in cloud deployments is unknown.]
        C[主要方法/Method<br>Systematic evaluation of 6 LLMs on Google BigQuery (StackOverflow dataset).] --> C1[评估指标/Metrics<br>Measure bytes processed, slot utilization, estimated cost, and correctness.]
        D[关键结果/Results] --> D1[发现1/Finding 1<br>Reasoning models process 44.5% fewer bytes with equivalent correctness.]
        D --> D2[发现2/Finding 2<br>Weak correlation (r=0.16) between execution time and query cost.]
        D --> D3[发现3/Finding 3<br>Up to 3.4x cost variance; standard models produce high-cost outliers.]
    ```

- **[arXiv251230] Efficient Multi-Model Orchestration for Self-Hosted Large Language Models**
  - **tags:** [mlsys], [llm inference], [Kubernetes, Helm, DistilBERT, scale-to-zero, hybrid routing]
  - **authors:** Bhanu Prakash Vangala, Tanu Malik
  - **institution:** University of Missouri
  - **link:** https://arxiv.org/pdf/2512.22402
  - **contributions:** 1. A unified Helm-based deployment system for self-hosted LLMs on Kubernetes, 2. An adaptive scale-to-zero automation mechanism for efficient GPU resource utilization, 3. A hybrid routing module combining keyword heuristics and a lightweight DistilBERT classifier to balance cost, latency, and accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14e9270400ac5f7fbf1ac4048cb82d9527c762106e232f9cd97653eb0ab3bdb4_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces "Pick and Spin," a framework for efficient orchestration of self-hosted large language models. It addresses challenges in GPU utilization and workload routing by integrating Kubernetes-based deployment, adaptive scaling, and a hybrid routing strategy. The system demonstrates significant improvements in success rate, latency, and cost compared to static deployments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Efficient Multi-Model Orchestration for Self-Hosted LLMs] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Self-hosted LLM deployment challenges: GPU utilization, workload routing, reliability/自托管LLM部署挑战：GPU利用率、工作负载路由、可靠性]
        C --> C1[Pick and Spin Framework: Kubernetes, Helm, scale-to-zero, hybrid routing/Pick and Spin框架：Kubernetes, Helm, 缩容至零, 混合路由]
        D --> D1[21.6% higher success rate, 30% lower latency, 33% lower cost/成功率提升21.6%，延迟降低30%，成本降低33%]
    ```

- **[arXiv251230] Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving**
  - **tags:** [mlsys], [llm inference], [speculative decoding, dynamic adaptation, multi-armed bandit, throughput optimization, latency reduction]
  - **authors:** Rui Li, Zhaoning Zhang, Libo Zhang, Huaimin Wang, Xiang Fu, Zhiquan Lai
  - **institution:** National University of Defense Technology
  - **link:** https://arxiv.org/pdf/2512.22420
  - **contributions:** 1. Identifies the critical trade-off in speculative decoding: beneficial in memory-bound (low-load) scenarios but detrimental in compute-bound (high-load) scenarios due to verification overhead. 2. Proposes Nightjar, a novel learning-based algorithm that dynamically adapts the speculative length (or disables SD) based on real-time request load and batch size. 3. Demonstrates significant performance gains, achieving up to 14.8% higher throughput and 20.2% lower latency compared to standard speculative decoding.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c6466394cd16e760ca78e05f13eba9852a284e7e8231b58de2c71fbee1e7b39_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the inefficiency of fixed-length speculative decoding in LLM serving, which fails to adapt to dynamic request loads. It proposes Nightjar, a learning-based algorithm that dynamically selects the optimal speculative length. Experiments show Nightjar significantly improves throughput and reduces latency compared to standard speculative decoding.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Nightjar: Dynamic Adaptive Speculative Decoding] --> B[核心问题/Problem: Fixed speculative length fails under dynamic loads]
        A --> C[主要方法/Method: Learning-based algorithm adapts speculative length]
        A --> D[关键结果/Results: Higher throughput, lower latency]
    ```

- **[arXiv251230] Role-Based Fault Tolerance System for LLM RL Post-Training**
  - **tags:** [mlsys], [fault-tolerance], [role-based fault tolerance, RL post-training, UCX communication, warm standby, Effective Training Time Ratio (ETTR)]
  - **authors:** Zhenqian Chen, Baoquan Zhong, Xiang Li, Qing Dai, Xinkui Zhao, Miao Ye, Ren Cheng, Lufei Zhang, Jianwei Yin
  - **institution:** Zhejiang University, State Key Laboratory of Mathematical Engineering and Advanced Computing
  - **link:** https://arxiv.org/pdf/2512.22492
  - **contributions:** 1. Proposes a role-based fault isolation and recovery system (RobustRL) for RL post-training, enabling recovery of only the failed component (trainer, rollout) instead of restarting the entire task. 2. Introduces a role-aware monitoring mechanism to accurately detect failures and avoid false positives/delays specific to different RL roles. 3. Implements dynamic, UCX-based point-to-point communication to reconnect recovered roles and synchronize weights immediately, replacing static collective communication.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ceff77cfb9d0c7d7e763916b77716ee6534c3aa3d54d41253fef6ea4d9a86ec0_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of fault tolerance for RL post-training of LLMs, which interleaves training and inference workloads. It proposes RobustRL, a system that isolates and recovers failed roles (e.g., trainer, rollout) individually using a Detect-Restart-Reconnect paradigm, instead of restarting the entire job. This approach significantly improves the Effective Training Time Ratio and reduces end-to-end training time compared to baseline methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Role-Based Fault Tolerance System for LLM RL Post-Training] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[RL后训练混合训练与推理工作负载，易受双方故障影响/RL post-training mixes training & inference, vulnerable to faults from both]
        B --> B2[现有容错框架未针对RL的异步执行优化/Existing FT frameworks not optimized for RL's async execution]
        C --> C1[基于角色的故障隔离与恢复/Role-based fault isolation & recovery]
        C --> C2[检测-重启-重连范式/Detect-Restart-Reconnect paradigm]
        C2 --> C21[角色感知监控/Role-aware monitoring]
        C2 --> C22[非中断式重启/Non-disruptive restart with warm standbys]
        C2 --> C23[动态UCX点对点通信重连/Dynamic UCX P2P reconnection]
        D --> D1[ETTR超过80%，优于基线的60%/ETTR >80%, better than baseline 60%]
        D --> D2[端到端训练时间加快8.4%-17.4%/End-to-end training time 8.4%-17.4% faster]
    ```

- **[arXiv251230] Object Abstraction To Streamline Edge-Cloud-Native Application Development**
  - **tags:** [sys], [serverless computing, edge computing], [Object-as-a-Service (OaaS), edge-cloud continuum, serverless, FaaS, declarative SLA]
  - **authors:** Pawissanutt Lertpongrujikorn
  - **institution:** University of North Texas
  - **link:** https://arxiv.org/pdf/2512.22534
  - **contributions:** 1. Proposed the Object-as-a-Service (OaaS) paradigm, unifying resource, state, and workflow management with the Oparaca prototype. 2. Extended OaaS to the edge-cloud continuum with OaaS-IoT/EdgeWeaver, improving performance and reducing code complexity. 3. Established an empirical methodology and commercialization pathway for cloud-native research grounded in practitioner needs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fcd35442b8b6cfbc12c61e295e970899c2bfb10184fe06c88745b8fbf0137055_w640_q70.webp
  - **Simple LLM Summary:** This dissertation addresses the complexity and fragmentation in serverless and cloud-native development by proposing the Object-as-a-Service (OaaS) paradigm. It introduces a unified abstraction for resources, state, and workflows, and extends it to the edge-cloud continuum, demonstrating improved developer productivity and system performance. The work concludes that OaaS effectively hides infrastructure complexity, allowing developers to focus on application logic.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Object Abstraction for Edge-Cloud-Native Apps<br>面向边缘云原生应用的对象抽象") --> Problem
        Root --> Method
        Root --> Results
        Problem("核心问题/Problem") --> P1("Serverless 承诺与实践存在差距<br>Gap in serverless promise vs. practice")
        Problem --> P2("基础设施碎片化与复杂化<br>Infrastructure fragmentation & complexity")
        Method("主要方法/Method") --> M1("提出 OaaS 范式<br>Propose OaaS paradigm")
        Method --> M2("开发 Oparaca 原型<br>Develop Oparaca prototype")
        Method --> M3("扩展至边缘云连续体<br>Extend to edge-cloud continuum (OaaS-IoT)")
        Results("关键结果/Results") --> R1("统一资源、状态、工作流管理<br>Unified resource, state, workflow management")
        Results --> R2("性能开销可忽略，可扩展性领先<br>Negligible overhead, state-of-the-art scalability")
        Results --> R3("任务完成更快，代码行数减少<br>Faster task completion, reduced lines of code")
    ```

- **[arXiv251230] RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure**
  - **tags:** [mlsys], [agent system], [disaggregated infrastructure, hardware-affinity mapping, fine-grained asynchrony]
  - **authors:** Wei Gao, Yuheng Zhao, Tianyuan Wu, Shaopan Xiong, Weixun Wang, Dakai An, Lunxi Cao, Dilxat Muhtar, Zichen Liu, Haizhou Zhao, Ju Huang, Siran Yang, Yongbin Li, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng, Wei Wang
  - **institution:** HKUST, Alibaba Group
  - **link:** https://arxiv.org/pdf/2512.22560
  - **code:** https://github.com/alibaba/ROLL
  - **contributions:** 1. A hardware-affinity workload mapping strategy that routes compute-bound and bandwidth-bound tasks to best-fit GPU devices. 2. A fine-grained asynchrony mechanism that manages execution at the trajectory level to mitigate resource bubbles and improve utilization. 3. A statefulness-aware computation design that offloads stateless components to serverless infrastructure for elastic scaling.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc8e408c613097b7b60bc32e41ec3137faa8dd94184658c8a802b65cbf57c593_w640_q70.webp
  - **Simple LLM Summary:** The paper presents RollArt, a distributed system designed to scale agentic reinforcement learning training on disaggregated infrastructure. It addresses the heterogeneity of agentic RL workloads by proposing three core techniques: hardware-affinity workload mapping, fine-grained asynchrony, and statefulness-aware computation. The system demonstrates significant improvements in training throughput, achieving 1.35-2.05x speedup over baselines, and scales to thousands of GPUs.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure"] --> Problem["核心问题/Problem: Agentic RL workloads are heterogeneous, causing inefficiency in monolithic infrastructure."]
        Root --> Method["主要方法/Method: Disaggregated system with hardware-affinity mapping, fine-grained asynchrony, and statefulness-aware computation."]
        Root --> Results["关键结果/Results: Achieves 1.35-2.05x training speedup and scales to >3000 GPUs."]
    ```

- **[arXiv251230] Modality Inflation: Energy Characterization and Optimization Opportunities for MLLM Inference**
  - **tags:** [mlsys], [multi-modal inference], [energy efficiency, dynamic voltage and frequency scaling (DVFS), GPU underutilization, visual token sequences, stage-level analysis]
  - **authors:** Mona Moghadampanah, Adib Rezaei Shahmirzadi, Farhana Amin, Dimitrios S. Nikolopoulos
  - **institution:** Virginia Tech
  - **link:** https://arxiv.org/pdf/2512.22695
  - **contributions:** 1. Provides the first detailed, stage-level energy characterization of MLLM inference, identifying modality inflation as a key inefficiency. 2. Quantifies the significant energy overhead (17%-94%) of multimodal inference and reveals diverse bottlenecks (vision encoder vs. prefill) and GPU underutilization. 3. Demonstrates stage-wise DVFS as an effective optimization to reduce energy consumption with minimal performance impact.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f6dd42f6aa45e4d0992cdd9fa407ab5c4268e31f45ecafdc9b44861ceb445e1_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the energy inefficiency of multimodal large language model (MLLM) inference, termed "modality inflation," where extra encoding stages and longer token sequences increase energy consumption. It provides a stage-level energy analysis on GPUs, quantifying overheads and identifying bottlenecks, and proposes stage-wise dynamic voltage and frequency scaling (DVFS) as an effective optimization to save energy with modest performance loss.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Modality Inflation: Energy Characterization and Optimization Opportunities for MLLM Inference] --> B[核心问题/Problem: Multimodal inference introduces unexplored energy trade-offs and inefficiencies (modality inflation)]
        A --> C[主要方法/Method: Stage-level energy analysis (vision encoding, prefill, decode) on GPU, and proposes stage-wise DVFS optimization]
        A --> D[关键结果/Results: Quantifies 17%-94% energy overhead, identifies bottlenecks and GPU underutilization, demonstrates DVFS saves energy with minor impact]
    ```

- **[arXiv251230] OptiNIC: A Resilient and Tail-Optimal RDMA NIC for Distributed ML Workloads**
  - **tags:** [mlsys], [communication & networking], [RDMA, tail latency, collective communication, reliability, domain-specific transport]
  - **authors:** Ertza Warraich, Ali Imran, Annus Zulfiqar, Shay Vargaftik, Sonia Fahmy, Muhammad Shahbaz
  - **institution:** Purdue University, Broadcom, University of Michigan
  - **link:** https://arxiv.org/pdf/2512.22743
  - **contributions:** 1. Proposes OptiNIC, a domain-specific RDMA transport that eliminates retransmissions and in-order delivery from the NIC, shifting to a best-effort, out-of-order model. 2. Introduces adaptive timeouts to trigger forward progress in case of data loss or delay, decoupling completion signaling from complete data delivery. 3. Shifts loss recovery to the ML pipeline (e.g., via Hadamard Transform and Erasure Coding) while retaining standard congestion control, improving performance and resilience for distributed ML workloads.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3143921b3b275baf220b75c6f927e8a49b4fa31653bbd117324490a1b8f8da93_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies tail latency in collective communication as a major bottleneck for distributed ML. It proposes OptiNIC, a new RDMA transport that relaxes strict reliability guarantees based on ML's tolerance for data loss, using adaptive timeouts and moving recovery to the application layer. Evaluation shows OptiNIC significantly improves time-to-accuracy, throughput, and tail latency while reducing hardware resource usage.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[OptiNIC: A Resilient and Tail-Optimal RDMA NIC] --> B[核心问题/Problem: Tail latency in collective communication bottlenecks distributed ML scaling]
        A --> C[主要方法/Method: Domain-specific RDMA transport with best-effort delivery, adaptive timeouts, and loss recovery in ML pipeline]
        A --> D[关键结果/Results: Improves TTA 2x, throughput 1.6x, lowers 99th% latency 3.5x, cuts BRAM usage 2.7x]
    ```

- **[arXiv251230] Two-Robot Computational Landscape: A Complete Characterization of Model Power in Minimal Mobile Robot Systems**
  - **tags:** [sys], [distributed computing], [autonomous mobile robots, Look-Compute-Move (LCM), computational power hierarchy, finite-state robots, robots with lights]
  - **authors:** Naoki Kitamura, Yuichi Sudo, Koichi Wada
  - **institution:** The University of Osaka, Hosei University
  - **link:** https://arxiv.org/pdf/2512.22770
  - **contributions:** 1. Proves that under full synchrony, the FSTA (finite-state) and LUMI (robots with lights) models coincide for two robots, showing perfect synchrony can substitute for memory and communication at this minimal scale. 2. Shows that the FSTA and FCOM (finite-communication) models are orthogonal (bidirectionally incomparable), completing the landscape of incomparability. 3. Provides the first complete and exact characterization of the computational power hierarchy for two robots across all major models and schedulers using a novel simulation-free method.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddce34ada1bbaebc271a0c17bbc6cf8413606d2887ebd22bfe77cc4c0e90d34a_w640_q70.webp
  - **Simple LLM Summary:** This paper provides the first complete characterization of the computational power of two autonomous mobile robots across major models (OBLOT, FSTA, FCOM, LUMI) and schedulers. Using a novel simulation-free method, it reveals a landscape distinct from the general n-robot case, showing that perfect synchrony can substitute for memory and communication for two robots, and that FSTA and FCOM are orthogonal. This yields the first exact computational hierarchy for minimal robot systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Two-Robot Computational Landscape] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Two-robot computational hierarchy unresolved]
        C --> C1[Simulation-free analysis method]
        D --> D1[FSTA^F = LUMI^F under full sync]
        D --> D2[FSTA and FCOM are orthogonal]
        D --> D3[Complete landscape for two robots]
    ```

- **[arXiv251230] Argus: Token Aware Distributed LLM Inference Optimization**
  - **tags:** [mlsys], [llm inference], [token-aware offloading, Lyapunov optimization, length prediction, edge-cloud systems, distributed inference]
  - **authors:** Panlong Wu, Yifei Zhong, Danyang Chen, Ting Wang, Fangxin Wang
  - **institution:** The Chinese University of Hong Kong, Shenzhen (CUHK-SZ)
  - **link:** https://arxiv.org/pdf/2512.22925
  - **contributions:** 1. A Length-Aware Semantics (LAS) module that predicts output token lengths for prompts using a fine-tuned language model with token-length-sensitive feature modulation. 2. A Lyapunov-guided Offloading Optimization (LOO) module that formulates long-term Quality-of-Experience optimization considering both LLM prefilling and decoding costs. 3. A novel Iterative Offloading Algorithm with Damping and Congestion Control (IODCC) to solve the resulting integer nonlinear programming problem under time-varying constraints.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e6bf58921ba8401e4cc5e40322f2ce1b65861ebe0ac5f35cfead3e0339c7f09_w640_q70.webp
  - **Simple LLM Summary:** This paper presents Argus, a token-aware distributed LLM inference framework for edge-cloud systems. It addresses inference time variability by predicting output token lengths and using Lyapunov optimization for efficient task offloading. Evaluations show Argus achieves robust and efficient performance in dynamic, heterogeneous environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Argus: Token Aware Distributed LLM Inference Optimization] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[LLM推理时间可变性高 / High LLM Inference Time Variability]
        B --> B2[动态异构边缘云环境 / Dynamic Heterogeneous Edge-Cloud Environment]
        C --> C1[LAS: 输出长度预测 / LAS: Output Length Prediction]
        C --> C2[LOO: 李雅普诺夫优化卸载 / LOO: Lyapunov Optimization Offloading]
        C --> C3[IODCC: 迭代卸载算法 / IODCC: Iterative Offloading Algorithm]
        D --> D1[鲁棒性能 / Robust Performance]
        D --> D2[高效推理 / Efficient Inference]
    ```

- **[arXiv251230] A Domain Decomposition-based Solver for Acoustic Wave propagation in Two-Dimensional Random Media**
  - **tags:** [hpc], [uncertainty quantification], [stochastic Galerkin method, polynomial chaos expansion, domain decomposition, Neumann-Neumann preconditioner]
  - **authors:** Sudhi Sharma Padillath Vasudevan
  - **institution:** Carleton University
  - **link:** https://arxiv.org/pdf/2512.23027
  - **contributions:** 1. Applies an intrusive stochastic Galerkin method with Polynomial Chaos Expansion to solve acoustic wave propagation in random media, transforming the stochastic PDE into a deterministic system. 2. Employs Domain Decomposition-based solvers to address the high computational cost associated with large-scale, high-dimensional stochastic systems. 3. Utilizes a conjugate gradient iterative solver with a two-level Neumann-Neumann preconditioner, demonstrating efficient scalability for the problem.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a4a9c029830a2f5bbff0493a205dfd33bea894daf2a861a9f131c15f02f4b9d_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the high computational cost of simulating acoustic wave propagation in two-dimensional random media. It proposes a method combining an intrusive stochastic Galerkin approach with Polynomial Chaos Expansion and a Domain Decomposition-based linear solver preconditioned with a two-level Neumann-Neumann method. The results show that this approach provides an efficiently scalable solution for the problem.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[基于域分解的二维随机介质声波传播求解器<br>A Domain Decomposition-based Solver for Acoustic Wave Propagation in 2D Random Media]
        Root --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[计算成本高<br>High Computational Cost]
        P1 --> P2[网格、时间步、随机参数增加<br>Increasing Mesh, Time Step, Random Parameters]
        Method --> M1[侵入式随机伽辽金法<br>Intrusive Stochastic Galerkin]
        M1 --> M2[多项式混沌展开<br>Polynomial Chaos Expansion (PCE)]
        Method --> M3[域分解求解器<br>Domain Decomposition Solver]
        M3 --> M4[共轭梯度法+两层Neumann-Neumann预处理器<br>Conjugate Gradient with Two-level Neumann-Neumann Preconditioner]
        Results --> R1[高效可扩展性<br>Efficient Scalability]
    ```

- **[arXiv251230] Viability and Performance of a Private LLM Server for SMBs: A Benchmark Analysis of Qwen3-30B on Consumer-Grade Hardware**
  - **tags:** [mlsys], [llm inference], [quantization, mixture-of-experts, on-premise deployment, consumer-grade hardware, benchmark analysis]
  - **authors:** Alex Khalil, Guillaume Heilles, Maria Parraga, Simon Heilles
  - **institution:** UCLouvain, Universidad Espíritu Santo, DENEM Labs
  - **link:** https://arxiv.org/pdf/2512.23029
  - **contributions:** 1. A comprehensive benchmarking framework for evaluating both the intrinsic model capabilities and the server-side performance (latency, throughput, scalability) of a private LLM deployment. 2. A practical demonstration and performance analysis of deploying a quantized, large-scale (30B parameter) Mixture-of-Experts model (Qwen3) on next-generation consumer-grade hardware (NVIDIA RTX 5090). 3. Evidence that a carefully configured on-premises LLM server can achieve performance comparable to cloud services, offering SMBs a viable, cost-effective, and privacy-preserving alternative.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed34c10397ed5cae19c39a4a8e2a5a1f0fd64e2f76183b8ba093c74b9a79fe51_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the feasibility of deploying a private, high-performance LLM server for Small and Medium Businesses using consumer-grade hardware. It benchmarks a quantized Qwen3-30B model on an NVIDIA RTX 5090, evaluating both model capability and server performance under load. The results show that such an on-premises setup can achieve performance close to cloud services at a lower cost and with full data privacy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Viability and Performance of a Private LLM Server for SMBs<br>SMB私有LLM服务器的可行性与性能] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Cloud reliance: cost, privacy, sovereignty for SMBs<br>云依赖：成本、隐私、SMB主权]
        C[主要方法/Method<br>Benchmark quantized Qwen3-30B on consumer hardware (RTX 5090)<br>在消费级硬件上对量化Qwen3-30B进行基准测试]
        D[关键结果/Results<br>On-premises performance rivals cloud, viable for SMBs<br>本地性能媲美云端，对SMB可行]
    ```

- **[arXiv251230] Osmotic Learning: A Self-Supervised Paradigm for Decentralized Contextual Data Representation**
  - **tags:** [mlsys], [federated learning], [self-supervised learning, representation learning, distributed learning, decentralized clustering, contextual data]
  - **authors:** Mario Colosi, Reza Farahani, Maria Fazio, Radu Prodan, Massimo Villari
  - **institution:** University of Messina, University of Klagenfurt, University of Innsbruck
  - **link:** https://arxiv.org/pdf/2512.23096
  - **contributions:** 1. Introduces Osmotic Learning (OSM-L), a novel self-supervised paradigm for learning from distributed data without raw data exchange. 2. Proposes an "osmosis" process that aligns local representations to converge to a dynamic equilibrium, capturing contextual patterns. 3. Demonstrates that OSM-L functions as a decentralized clustering mechanism, identifying correlated data groups during training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2b452fb94443ab9846af33524787f0bc6c709b6e90ae3be4e653738c6fe592b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Osmotic Learning (OSM-L), a self-supervised distributed learning paradigm that extracts higher-level latent knowledge from decentralized data sources without sharing raw data. It achieves this through an iterative "osmosis" process that aligns local representations to converge to a contextual equilibrium, also enabling decentralized clustering. Experimental results show OSM-L achieves high accuracy in local information alignment while preserving contextual integrity.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Osmotic Learning: A Self-Supervised Paradigm for Decentralized Contextual Data Representation] --> B[核心问题/Problem: Extracting meaningful knowledge from distributed, heterogeneous data without raw data exchange]
        A --> C[主要方法/Method: Osmotic Learning (OSM-L) - self-supervised paradigm using iterative alignment and "osmosis" for representation convergence]
        A --> D[关键结果/Results: Achieves >0.99 alignment accuracy and preserves contextual integrity; enables decentralized clustering]
    ```

- **[arXiv251230] FairGFL: Privacy-Preserving Fairness-Aware Federated Learning with Overlapping Subgraphs**
  - **tags:** [mlsys], [federated learning], [graph federated learning, fairness, overlapping subgraphs, privacy-preserving, weighted aggregation]
  - **authors:** Zihao Zhou, Shusen Yang, Fangyuan Zhao, Xuebin Ren
  - **institution:** Xi'an Jiaotong University
  - **link:** https://arxiv.org/pdf/2512.23235
  - **contributions:** 1. Uncover and theoretically analyze the unfairness issue in graph federated learning caused by imbalanced overlapping subgraphs across clients. 2. Propose FairGFL, a novel algorithm that uses a privacy-preserving estimation of overlapping ratios and an interpretable weighted aggregation approach to enhance cross-client fairness. 3. Improve the tradeoff between model utility and fairness by integrating a carefully crafted regularizer into the federated composite loss function.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c67614889dfdf1e0e6de4fd0bd950e8649eb4d988fb1661c29ef6c14b73bba25_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a fairness problem in graph federated learning when client subgraphs overlap in an imbalanced way. To solve this, it proposes FairGFL, a method that uses privacy-preserving overlap estimation and a fairness-aware regularizer to balance utility and fairness. Experiments show FairGFL outperforms baselines in both utility and fairness on benchmark datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
    A(FairGFL: Privacy-Preserving Fairness-Aware Federated Learning with Overlapping Subgraphs) --> B(核心问题/Problem: Imbalanced overlapping subgraphs cause unfairness in GFL)
    A --> C(主要方法/Method: FairGFL with privacy-preserving overlap estimation, weighted aggregation, and fairness regularizer)
    A --> D(关键结果/Results: Outperforms baselines in model utility and fairness)
    ```

- **[arXiv251230] Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL**
  - **tags:** [mlsys], [llm inference], [Lyapunov Optimization, Deep Reinforcement Learning, Edge-Cloud Partitioning, Transformer Decomposition, Queue Stability]
  - **authors:** Abolfazl Younesi, Abbas Shabrang Maryan, Elyas Oustad, Zahra Najafabadi Samani, Mohsen Ansari, Thomas Fahringer
  - **institution:** University of Innsbruck, Sharif University of Technology
  - **link:** https://arxiv.org/pdf/2512.23310
  - **contributions:** 1. Proposes a fine-grained, adaptive partitioning framework (Splitwise) that decomposes transformer layers into attention heads and feed-forward sub-blocks, enabling exponentially more partition choices than layer-wise schemes. 2. Introduces a hierarchical DRL policy guided by Lyapunov optimization to jointly optimize latency, energy, and accuracy while guaranteeing queue stability under stochastic workloads and variable bandwidth. 3. Ensures robustness through partition checkpoints with exponential backoff recovery for communication failures, validated on real edge devices with large models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/121b71aa214f4a7c1671c9df76bf67a9cd64f3cb9e74186606a380ce86f7634f_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes Splitwise, a Lyapunov-assisted DRL framework for dynamically partitioning LLM inference between edge and cloud at a fine-grained sub-layer level. It aims to minimize latency and energy while maintaining accuracy under fluctuating network conditions. Experiments show Splitwise significantly reduces latency and energy consumption compared to existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL] --> B[核心问题/Problem: LLMs are hard to deploy on edge devices; cloud-only is slow; static partitions fail with bandwidth changes.]
        A --> C[主要方法/Method: Fine-grained partition of transformer layers; Lyapunov-assisted DRL for adaptive optimization; checkpointing for robustness.]
        A --> D[关键结果/Results: Reduces latency 1.4x-2.8x; cuts energy up to 41%; lowers 95th-percentile latency by 53-61%.]
    ```

- **[arXiv251230] An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes**
  - **tags:** [mlsys], [cluster infrastructure], [Kubernetes, Autoscaling, AIOps, Service Level Objectives, Cost Optimization]
  - **authors:** Vinoth Punniyamoorthy, Bikesh Kumar, Sumit Saha, Lokesh Butra, Mayilsamy Palanigounder, Akash Kumar Agarwal, Kabilan Kannan
  - **institution:** IEEE, East West Bank, NTT Data, Albertsons
  - **link:** https://arxiv.org/pdf/2512.23415
  - **contributions:** 1. A gap-driven analysis of existing Kubernetes autoscaling approaches, highlighting their limitations. 2. A safe and explainable multi-signal autoscaling framework that integrates SLO-aware and cost-conscious control with demand forecasting. 3. Experimental evaluation demonstrating significant improvements in SLO violation duration, scaling response time, and infrastructure cost compared to baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce581ba4d1249deeba9f1bffa6739ebbe74df663542fef3893eee5e0a117ae2e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses SLO violations and cost inefficiencies in Kubernetes autoscaling by proposing an AIOps-driven framework that uses multi-signal control and lightweight forecasting. The method integrates SLO and cost awareness to improve responsiveness and stability. Evaluation shows it reduces SLO violations by up to 31%, improves response time by 24%, and lowers cost by 18% compared to standard Kubernetes autoscalers.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("SLO违反与成本低效/SLO Violations & Cost Inefficiency")
        Problem --> P2("反应式扩展与不透明逻辑/Reactive Scaling & Opaque Logic")
        Method --> M1("AIOps驱动的多信号框架/AIOps-Driven Multi-Signal Framework")
        Method --> M2("SLO与成本感知控制/SLO & Cost-Aware Control")
        Method --> M3("轻量级需求预测/Lightweight Demand Forecasting")
        Results --> R1("SLO违反时长减少31%/SLO Violation Duration Reduced by 31%")
        Results --> R2("扩展响应时间提升24%/Scaling Response Time Improved by 24%")
        Results --> R3("基础设施成本降低18%/Infrastructure Cost Lowered by 18%")
    ```

- **[arXiv251230] Local Rendezvous Hashing: Bounded Loads and Minimal Churn via Cache-Local Candidates**
  - **tags:** [sys], [distributed systems], [consistent hashing, rendezvous hashing, load balancing, cache locality, minimal churn]
  - **authors:** Yongjie Guan
  - **institution:** Zhejiang University of Technology
  - **link:** https://arxiv.org/pdf/2512.23434
  - **contributions:** 1. Introduces Local Rendezvous Hashing (LRH), which restricts HRW selection to a cache-local window of C distinct neighboring physical nodes on a ring. 2. Proposes next-distinct offsets to enforce bounded distinct candidate enumeration in exactly C ring steps. 3. Demonstrates that under fixed-candidate liveness failover, LRH achieves 0% excess churn while maintaining high throughput and good load balance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40c222a782553ce278b2cbc43564ea8beed18effebd850b7b92ac28f04bda05_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the trade-off between load balance and performance in consistent hashing for distributed systems. It proposes Local Rendezvous Hashing (LRH), a method that performs a Highest Random Weight selection within a small, cache-local window of nodes on a ring. LRH achieves near-optimal load balance with minimal key churn and significantly higher lookup throughput compared to multi-probe consistent hashing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Local Rendezvous Hashing] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Ring-based consistent hashing has high load imbalance or scattered memory accesses.]
        C --> C1[Restrict HRW selection to a cache-local window of C distinct nodes.]
        D --> D1[Reduces Max/Avg load to 1.0947 and achieves 60.05 Mkeys/s throughput.]
    ```

- **[arXiv251230] Bitcoin-IPC: Scaling Bitcoin with a Network of Proof-of-Stake Subnets**
  - **tags:** [sys], [blockchain scalability], [Bitcoin, Layer-2, Proof-of-Stake, interoperability, SegWit]
  - **authors:** Marko Vukolić, Orestis Alpos, Jakov Mitrovski, Themis Papameletiou, Nikola Ristić, Dionysis Zindros
  - **institution:** Bitcoin Scaling Labs, Common Prefix
  - **link:** https://arxiv.org/pdf/2512.23439
  - **contributions:** 1. Introduces Bitcoin-IPC, a protocol enabling permissionless creation of Proof-of-Stake Layer-2 subnets with stake denominated in Bitcoin (BTC). 2. Proposes a novel design embedded within Bitcoin's SegWit mechanism, inspired by SWIFT messaging, for seamless cross-subnet value transfer routed through Bitcoin L1. 3. Achieves significant scalability improvements, reducing transaction cost by up to 23x and increasing throughput from 7 to over 160 tps without modifying Bitcoin L1.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c762e73812d8ecf4dff85e3904f4f2897f640f483515f122ffbda6dd2edfabcc_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses Bitcoin's limited transaction throughput for use as a Medium of Exchange. It proposes Bitcoin-IPC, a protocol that creates a network of programmable Proof-of-Stake Layer-2 chains (subnets) that use Bitcoin for security and settlement. The design significantly increases transaction throughput and reduces cost without requiring changes to the Bitcoin base layer.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Bitcoin-IPC: Scaling Bitcoin with a Network of Proof-of-Stake Subnets] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[比特币作为交换媒介的可扩展性不足/Bitcoin's limited scalability as Medium of Exchange]
        C --> C1[基于SegWit和SWIFT启发的L2 PoS子网协议/L2 PoS Subnet protocol inspired by SegWit & SWIFT]
        D --> D1[吞吐量从7 tps提升至160+ tps/Throughput increased from 7 to 160+ tps]
        D --> D2[每笔交易成本降低高达23倍/Tx cost reduced up to 23x]
    ```

- **[arXiv251230] Decoupling Adaptive Control in TeaStore**
  - **tags:** [se], [self-adaptive systems], [self-adaptation, microservices, control loop, operator pattern, software architecture]
  - **authors:** Eddy Truyen
  - **institution:** DistriNet, KU Leuven
  - **link:** https://arxiv.org/pdf/2512.23495
  - **contributions:** 1. Analyzes how software architectural methods, the cloud-native Operator pattern, and legacy programming techniques can decouple adaptive control from the application logic in a microservice system. 2. Examines the trade-offs between fine-grained expressive adaptation and system-wide control, highlighting when reuse of adaptation strategies is effective. 3. Proposes that these approaches are complementary and can be combined into a multi-tiered architecture for self-adaptive microservices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78e96b6ab1b10ae0a32ddc4e7967c5bedce7be1b0fe5db13bec216c9e0b657ae_w640_q70.webp
  - **Simple LLM Summary:** This paper discusses the implementation of self-adaptation in the Adaptable TeaStore microservice benchmark. It examines different technical approaches (software architecture, Operator pattern, programming techniques) for decoupling the adaptive control logic from the application, analyzing their trade-offs. The main conclusion is that these approaches can be combined into a multi-tiered architecture for effective self-adaptive microservices.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Decoupling Adaptive Control in TeaStore] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[实现微服务中的细粒度自适应/Implementing fine-grained self-adaptation in microservices]
        C --> C1[软件架构方法/Software architectural methods]
        C --> C2[Operator模式/Operator pattern]
        C --> C3[传统编程技术/Legacy programming techniques]
        D --> D1[权衡细粒度与系统范围控制/Trade-offs between fine-grained and system-wide control]
        D --> D2[可组合的多层架构/Composable multi-tiered architecture]
    ```

- **[arXiv251230] Fancy Some Chips for Your TeaStore? Modeling the Control of an Adaptable Discrete System**
  - **tags:** [sys], [modeling languages, control theory, distributed systems], [Chips, control theory, component-based modeling, Adaptable TeaStore, BIP]
  - **authors:** Anna Gallone, Simon Bliudze, Sophie Cerf, Olga Kouchnarenko
  - **institution:** Université Marie et Louis Pasteur (FEMTO-ST), Univ. Lille (Inria, CNRS, CRIStAL)
  - **link:** https://arxiv.org/pdf/2512.23496
  - **code:** https://github.com/NwaitDev/Chips_Public, https://github.com/NwaitDev/TeaStore-Variation
  - **contributions:** 1. Introduces Chips, a novel language for designing models of complex, intertwined systems by mixing control theory with general-purpose programming concepts. 2. Enables systematic design, modeling, and analysis of adaptable systems through functional block descriptions. 3. Demonstrates the language's application and utility using a variation of the Adaptable TeaStore as a concrete running example.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80812c1a02bcd560c40919556c5ed13e3adfb056050e40a68f66bb940765d6f7_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Chips, a modeling language that combines control theory with programming concepts to facilitate the design and analysis of robust, component-based systems. The method is demonstrated on an Adaptable TeaStore application, showing how Chips can be used to systematically model complex, interacting entities like software, hardware, and services. The main conclusion is that Chips aids in ensuring system robustness and quality of service for web applications and cyber-physical systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Fancy Some Chips for Your TeaStore?<br/>Modeling the Control of an Adaptable Discrete System] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br/>Web应用需管理复杂、相互依赖的资源以确保鲁棒性] --> Problem_Detail[系统复杂/Complex System<br/>软件、硬件、网络、微服务交织]
        Method[主要方法/Method<br/>提出Chips建模语言] --> Method_Detail1[混合概念/Mixed Concepts<br/>控制理论 + 通用编程语言]
        Method --> Method_Detail2[功能块描述/Functional Blocks<br/>生成鲁棒的组件模型]
        Results[关键结果/Results<br/>系统化设计、建模与分析] --> Results_Detail[案例演示/Case Study<br/>使用Adaptable TeaStore变体验证]
    ```

- **[arXiv251230] Optimal Configuration of API Resources in Cloud Native Computing**
  - **tags:** [sys], [cloud computing], [Kubernetes, resource optimization, microservices, DevOps, Bayesian optimization]
  - **authors:** Eddy Truyen, Wouter Joosen
  - **institution:** DistriNet, KU Leuven
  - **link:** https://arxiv.org/pdf/2512.23494
  - **contributions:** 1. Applies an existing black-box optimization framework to the largely unexplored problem of fine-tuning CPU and memory allocation during the DevOps Release phase, before deployment. 2. Empirically evaluates the framework using the TeaStore microservice application and provides a statistical comparison of different optimization algorithms, analyzing their trade-offs. 3. Provides practical guidance on when to use factor screening (for optimal configuration or algorithm comparison with a budget) versus pure Bayesian optimization (for finding a near-optimal configuration).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fd4cec4e268968c920e0f358d7cea15fb1e4dc177e4b11b53180a3f5172ef65_w640_q70.webp
  - **Simple LLM Summary:** This paper applies a black-box optimization framework to tune Kubernetes CPU and memory resource configurations for microservices during the DevOps Release phase, a problem often overlooked in favor of runtime autoscaling. The evaluation on the TeaStore application shows that factor screening is useful for finding the optimal configuration within a budget, but Bayesian optimization without screening is better for finding a near-optimal solution.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Optimal Configuration of API Resources in Cloud Native Computing<br/>云原生计算中API资源的最优配置"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br/>Untuned resource allocation before deployment<br/>部署前未调优的资源分配"] --> P1["子问题/Sub-Problem<br/>Focus on Release phase, not Ops<br/>关注发布阶段，而非运维阶段"]
        Method["主要方法/Method<br/>Apply black-box optimization framework<br/>应用黑盒优化框架"] --> M1["技术/Technique<br/>Factor screening & Bayesian optimization<br/>因子筛选与贝叶斯优化"]
        Method --> M2["评估/Evaluation<br/>Use TeaStore microservice app<br/>使用TeaStore微服务应用"]
        Results["关键结果/Results<br/>Guidance on screening vs. no screening<br/>关于是否使用筛选的指导"] --> R1["结果1/Result 1<br/>Screening helps find optimal config with budget<br/>筛选有助于在预算内找到最优配置"]
        Results --> R2["结果2/Result 2<br/>Pure BO better for near-optimal config<br/>纯贝叶斯优化对寻找近似最优配置更好"]
    ```

- **[arXiv251230] AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices**
  - **tags:** [sys], [autonomic computing], [MAPE-K loop, decentralized adaptation, event-driven, rule-based, microservices]
  - **authors:** Brice Arléon Zemtsop Ndadji, Simon Bliudze, Clément Quinton
  - **institution:** Univ. Lille, CNRS, Inria, Centrale Lille, CRIStAL
  - **link:** https://arxiv.org/pdf/2512.23499
  - **contributions:** 1. A framework (AdaptiFlow) providing abstraction layers for the Monitor and Execute phases of the MAPE-K loop to enable autonomous microservices. 2. A lightweight, event-driven and rule-based mechanism for specifying adaptation logic, decoupling it from metrics collection and action execution. 3. A workflow for service instrumentation and evidence that decentralized adaptation can emerge from localized decisions without global coordination, validated through three adaptation scenarios (self-healing, self-protection, self-optimization).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cea3a497714ae1ca6ead099b1f31177f6fe2bf3d4bc5a184a21835b1744db4a_w640_q70.webp
  - **Simple LLM Summary:** This paper presents AdaptiFlow, a framework for building self-adaptive cloud microservices by decoupling metrics collection and action execution from adaptation logic using an event-driven, rule-based approach. It enables decentralized autonomy, allowing services to adapt locally without global coordination. The framework was validated on a benchmark, demonstrating practical implementation of self-healing, self-protection, and self-optimization scenarios with minimal code changes.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有方案集中式控制不适用于微服务/Existing centralized control ill-suited for microservices]
        C --> C1[基于MAPE-K的抽象层与事件驱动规则/MAPE-K abstraction layers & event-driven rules]
        C --> C2[解耦监控、执行与逻辑/Decouple Monitor/Execute from adaptation logic]
        D --> D1[实现三种自治场景/Implemented three autonomy scenarios]
        D --> D2[去中心化适应无需全局协调/Decentralized adaptation without global coordination]
    ```

- **[arXiv251230] Synthesis of signal processing algorithms with constraints on minimal parallelism and memory space**
  - **tags:** [other], [digital signal processing, computer arithmetic, high-performance computing], [energy-efficient computing, integer-friendly approximation, conflict-free memory access, fast Fourier transform, fast Schur algorithm]
  - **authors:** Sergey Salishev
  - **institution:** Saint Petersburg State University
  - **link:** https://arxiv.org/pdf/2512.22676
  - **contributions:** 1. A power/energy consumption model for clocked CMOS logic to select optimal parallelism. 2. Integer-friendly approximation methods for elementary functions using constrained piecewise-polynomials to reduce lookup-table size. 3. Provably conflict-free data placement and execution order schemes for mixed-radix streaming FFT on multi-bank/single-port memories.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fe50589b6f9e67a8e1acb929b6cfc7dcaecddcc5c1837d218c89e297ca79994_w640_q70.webp
  - **Simple LLM Summary:** This thesis develops signal-processing algorithms and implementation schemes under constraints of minimal parallelism and memory space to improve energy efficiency. It proposes a power model, approximation methods, and conflict-free memory access schemes for FFT and fast Schur algorithms. The results provide constructive theorems and design trade-offs for building efficient specialized accelerators.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Synthesis of signal processing algorithms with constraints on minimal parallelism and memory space<br>信号处理算法在最小并行度和内存空间约束下的综合"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Improving energy efficiency of low-power computing hardware<br>提高低功耗计算硬件的能效"]
        Method["主要方法/Method<br>1. Power/energy model for CMOS logic<br>CMOS逻辑功耗/能耗模型<br>2. Integer-friendly function approximation<br>整数友好函数近似<br>3. Conflict-free FFT schedules<br>无冲突FFT调度<br>4. Parallelism/memory analysis for fast Schur algorithm<br>快速Schur算法的并行度/内存分析"]
        Results["关键结果/Results<br>Constructive theorems, schedules, and design trade-offs for efficient specialized accelerators<br>为高效专用加速器提供构造性定理、调度方案和设计权衡"]
    ```

- **[arXiv251230] Revisiting finite Abelian hidden subgroup problem and its distributed exact quantum algorithm**
  - **tags:** [other], [quantum computing], [hidden subgroup problem, exact quantum algorithm, distributed quantum algorithm, amplitude amplification, Chinese Remainder Theorem]
  - **authors:** Ziyuan Dong, Xiang Fan, Tengxun Zhong, Daowen Qiu
  - **institution:** Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.22959
  - **contributions:** 1. Proposes a new, more concise exact quantum algorithm for the finite Abelian hidden subgroup problem using amplitude amplification. 2. Introduces a distributed exact quantum algorithm for the same problem that reduces resource requirements and avoids quantum communication by leveraging the Chinese Remainder Theorem. 3. Develops a parallel exact classical algorithm with reduced query complexity, where the total queries across nodes do not exceed the centralized version under mild conditions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7feb61cf81eb163415a6709dd5e0b72019ffd85d693a4f2bc910ebd710ff58b_w640_q70.webp
  - **Simple LLM Summary:** This paper revisits the finite Abelian hidden subgroup problem (AHSP). It proposes a new exact quantum algorithm, a distributed quantum algorithm that requires fewer resources and no quantum communication, and a parallel classical algorithm. The main conclusion is that these methods offer more concise, resource-efficient, and scalable solutions for solving the AHSP.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Revisiting finite Abelian hidden subgroup problem and its distributed exact quantum algorithm] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[有限阿贝尔隐藏子群问题 / Finite Abelian Hidden Subgroup Problem]
        C --> C1[振幅放大 / Amplitude Amplification]
        C --> C2[中国剩余定理 / Chinese Remainder Theorem]
        D --> D1[精确量子算法 / Exact Quantum Algorithm]
        D --> D2[分布式量子算法 / Distributed Quantum Algorithm]
        D --> D3[并行经典算法 / Parallel Classical Algorithm]
    ```

- **[arXiv251230] Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity**
  - **tags:** [mlsys], [federated learning], [L0 regularization, probabilistic gates, communication efficiency, model sparsity, federated stochastic gradient descent]
  - **authors:** Krishna Harsha Kovelakuntla Huthasana, Alireza Olama, Andreas Lundell
  - **institution:** Åbo Akademi University
  - **link:** https://arxiv.org/pdf/2512.23071
  - **contributions:** 1. Proposes a novel federated learning method that enforces an L0 constraint on model parameters using probabilistic gates and their continuous relaxation to achieve target sparsity. 2. Derives the L0 constrained stochastic minimization objective from an entropy maximization problem of the stochastic gates. 3. Demonstrates that the method can achieve high target sparsity (down to ρ=0.005) under data and client heterogeneity with minimal loss in statistical performance, outperforming magnitude pruning-based methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259d06fa8e807f154e153891f40b44308796040886ed51e218b65ee4e67a8c9c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of poor generalizability and communication inefficiency in Federated Learning due to overly dense models. It proposes a method to enforce L0 sparsity constraints via probabilistic gates, deriving the objective from entropy maximization and implementing it with federated stochastic gradient descent. The method is shown to be communication-efficient and achieves high target sparsity with better statistical performance than pruning-based baselines on synthetic and real datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: 数据与模型固有的稀疏性未被解决，导致模型过密、泛化性差，且存在数据和客户端参与异质性。]
        Method[主要方法/Method: 通过概率门及其连续松弛对非零参数密度施加L0约束，目标源自随机门的熵最大化问题，并基于联邦随机梯度下降。]
        Results[关键结果/Results: 在数据和客户端异质性下，能达到目标密度(ρ)，统计性能损失最小，且比基于幅度的剪枝方法更优、通信高效。]
    ```


**cs.AI/cs.LG contains "reinforcement learning" total: 50**
- **[arXiv251230] Unbiased Visual Reasoning with Controlled Visual Inputs**
  - **tags:** [ai], [multimodal reasoning], [vision-language models, spurious correlations, information bottleneck, reinforcement learning, modular reasoning]
  - **authors:** Zhaonan Li, Shijie Lu, Fei Wang, Jacob Dineen, Xiao Ye, Zhikun Xu, Siyi Liu, Young Min Cho, Bangzheng Li, Daniel Chang, Kenny Nguyen, Qizheng Yang, Muhao Chen, Ben Zhou
  - **institution:** Arizona State University, University of Southern California, University of Pennsylvania, University of California, Davis
  - **link:** https://arxiv.org/pdf/2512.22183
  - **contributions:** 1. Proposes VISTA, a modular framework that decouples visual perception from reasoning using an explicit information bottleneck to control visual inputs. 2. Introduces a training method using reinforcement learning (GRPO) on a small curated dataset to align the reasoner with unbiased visual evidence. 3. Demonstrates improved robustness against spurious correlations, transferability across VLM sensors, and enhanced interpretability in reasoning traces.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f546535b9c36b7873d0f685328a4f4a8e058e6a4788639c170f69e073d8f9e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of vision-language models (VLMs) relying on spurious correlations rather than causal visual evidence. It proposes VISTA, a modular framework that separates perception (via a frozen VLM) from reasoning (via an LLM) using controlled queries and trains the reasoner with reinforcement learning. The method shows significant gains in robustness on benchmarks like SpuriVerse while maintaining competitive performance on other tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Unbiased Visual Reasoning with Controlled Visual Inputs] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[VLMs exploit spurious correlations/VLMs利用虚假关联]
        C --> C1[VISTA: Modular framework decoupling perception & reasoning/VISTA: 解耦感知与推理的模块化框架]
        C1 --> C2[Frozen VLM sensor + LLM reasoner/冻结VLM感知器 + LLM推理器]
        C2 --> C3[Train with RL (GRPO)/使用强化学习(GRPO)训练]
        D --> D1[Improved robustness on SpuriVerse/在SpuriVerse上鲁棒性提升]
        D --> D2[Competitive on MMVP & SeedBench/在MMVP & SeedBench上保持竞争力]
        D --> D3[Transferable & interpretable/可迁移且可解释]
    ```

- **[arXiv251230] Learning Tennis Strategy Through Curriculum-Based Dueling Double Deep Q-Networks**
  - **tags:** [ai], [reinforcement learning], [Dueling Double Deep Q-Network, curriculum learning, tennis simulation, sequential decision-making, sports analytics]
  - **authors:** Vishnu Mohan
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2512.22186
  - **contributions:** 1. Developed a custom tennis simulation environment that models hierarchical scoring, tactical decisions, fatigue, and opponent skill. 2. Integrated a Dueling Double Deep Q-Network (DDQN) with curriculum learning to enable stable and effective strategy learning in a long-horizon, stochastic domain. 3. Identified a key limitation of win-rate optimization, revealing a learned defensive bias and highlighting challenges in reward design for sports RL.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/543e2f9f07244abac63adfdbdefd7fccfefed9147b55aed87016c10657f91bae_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a reinforcement learning framework using a Dueling Double Deep Q-Network trained with curriculum learning to optimize tennis strategy in a custom simulation. The method achieves high win rates and demonstrates stable convergence, but analysis reveals the learned policy is overly defensive, pointing to a fundamental issue with reward design in sports simulations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Learning Tennis Strategy Through Curriculum-Based Dueling Double Deep Q-Networks] --> B(核心问题/Problem: Tennis strategy optimization as a sequential decision-making challenge with hierarchical scoring, stochasticity, and opponent adaptation)
        A --> C(主要方法/Method: Dueling Double Deep Q-Network (DDQN) trained with curriculum learning in a custom tennis simulation environment)
        A --> D(关键结果/Results: High win rates (98-100%) and stable convergence, but reveals a defensive policy bias, highlighting reward design limitations)
    ```

- **[arXiv251230] Physics-Informed Machine Learning for Transformer Condition Monitoring -- Part I: Basic Concepts, Neural Networks, and Variants**
  - **tags:** [ai], [prognostics & health management (phm)], [Neural Networks, Convolutional Neural Networks, Reinforcement Learning, Uncertainty Quantification, Physics-Informed Machine Learning]
  - **authors:** Jose I. Aizpurua
  - **institution:** University of the Basque Country (UPV/EHU)
  - **link:** https://arxiv.org/pdf/2512.22190
  - **contributions:** 1. Introduces the application of Neural Networks (NNs) and their variants, specifically Convolutional Neural Networks (CNNs), for transformer condition monitoring using diverse data modalities. 2. Discusses the integration of NN concepts within the Reinforcement Learning (RL) paradigm for decision-making and control in transformer health management. 3. Provides perspectives on emerging research directions at the intersection of physics-informed machine learning and transformer Prognostics & Health Management (PHM).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73f2611de029a059f651f47ffd6b707f684cdbc0c0f865e4c8568c2765f5fede_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of traditional, rule-based transformer condition monitoring by proposing the use of machine learning, particularly Neural Networks and their variants. It explores Convolutional Neural Networks for processing diverse sensor data and discusses Reinforcement Learning for control, concluding that physics-informed ML provides a powerful framework for more accurate diagnostics, prognostics, and decision-making in power transformer health management.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Physics-Informed ML for Transformer Condition Monitoring – Part I"] --> Problem["核心问题/Problem: Traditional monitoring struggles with uncertainty & complexity"]
        Root --> Method["主要方法/Method: Use Neural Networks, CNNs, and Reinforcement Learning"]
        Root --> Results["关键结果/Results: Enables accurate diagnostics, prognostics, and control"]
    ```

- **[arXiv251230] Emotion-Inspired Learning Signals (EILS): A Homeostatic Framework for Adaptive Autonomous Agents**
  - **tags:** [ai], [reinforcement learning], [intrinsic motivation, homeostatic control, adaptive optimization, non-stationary learning]
  - **authors:** Dhruv Tiwari
  - **institution:** Lovely Professional University
  - **link:** https://arxiv.org/pdf/2512.22200
  - **contributions:** 1. Proposes a novel framework, Emotion-Inspired Learning Signals (EILS), that models emotions as continuous, homeostatic appraisal signals (e.g., Curiosity, Stress, Confidence) for adaptive control. 2. Formalizes these signals as vector-valued internal states derived from interaction history to dynamically modulate the agent's optimization landscape in real-time. 3. Hypothesizes that this closed-loop homeostatic regulation enables superior sample efficiency and adaptation to non-stationary environments compared to standard baselines like PPO.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a45d2a56af1becf3eaddb05dbaeff3cf5453d19d41771b6d8ce1c1a70d3825c2_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies the fragility of standard AI agents that rely on static, external rewards in open-ended environments. It proposes the Emotion-Inspired Learning Signals (EILS) framework, which uses bio-inspired internal signals like curiosity and stress to dynamically control learning. The authors hypothesize this approach will lead to more robust, adaptive, and sample-efficient autonomous agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[EILS: A Homeostatic Framework] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[静态外部奖励/Static Extrinsic Reward]
        Problem --> P2[脆弱性，无法适应/Fragile, Non-Adaptive]
        Method[主要方法/Method] --> M1[情绪启发信号/Emotion-Inspired Signals]
        Method --> M2[动态稳态调节/Dynamic Homeostatic Control]
        Results[关键结果/Results] --> R1[假设: 更高样本效率/Hypothesis: Higher Sample Efficiency]
        Results --> R2[假设: 更好非平稳适应/Hypothesis: Better Non-Stationary Adaptation]
    ```

- **[arXiv251230] DiRL: An Efficient Post-Training Framework for Diffusion Language Models**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [Diffusion Language Models, FlexAttention, Group Relative Policy Optimization, LMDeploy, blockwise training]
  - **authors:** Ying Zhu, Jiaxin Wan, Xiaoran Liu, Siyanag He, Qiqi Wang, Xu Guo, Tianyi Liang, Zengfeng Huang, Ziwei He, Xipeng Qiu
  - **institution:** Fudan University, Shanghai Innovation Institute, OpenMoss Team
  - **link:** https://arxiv.org/pdf/2512.22234
  - **code:** https://github.com/OpenMOSS/DiRL
  - **contributions:** 1. Proposes DiRL, an efficient post-training framework for Diffusion Language Models (dLLMs) that integrates FlexAttention-accelerated blockwise training with LMDeploy-optimized inference. 2. Introduces DiPO, the first unbiased Group Relative Policy Optimization (GRPO) implementation specifically designed for dLLMs. 3. Demonstrates state-of-the-art math reasoning performance for dLLMs by training DiRL-8B-Instruct, surpassing comparable models like Qwen2.5 series on benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the underdeveloped and inefficient post-training landscape for Diffusion Language Models (dLLMs). It proposes DiRL, an efficient framework combining accelerated training and optimized inference, and introduces DiPO, a tailored reinforcement learning method. The resulting model, DiRL-8B-Instruct, achieves state-of-the-art math performance among dLLMs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DiRL: An Efficient Post-Training Framework for Diffusion Language Models] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[dLLMs后训练低效/Post-training for dLLMs is inefficient]
        B --> B2[训练与推理目标不匹配/Training-Inference objective mismatch]
        C --> C1[DiRL框架/DiRL Framework]
        C1 --> C1_1[整合FlexAttention与LMDeploy/Integrates FlexAttention & LMDeploy]
        C1 --> C1_2[两阶段后训练/Two-stage post-training (SFT+RL)]
        C --> C2[DiPO算法/DiPO Algorithm]
        C2 --> C2_1[无偏GRPO实现/Unbiased GRPO for dLLMs]
        D --> D1[高效训练与推理/Efficient Training & Inference]
        D --> D2[数学SOTA性能/Math SOTA Performance]
        D --> D3[超越Qwen2.5系列/Surpasses Qwen2.5 series]
    ```

- **[arXiv251230] Masking Teacher and Reinforcing Student for Distilling Vision-Language Models**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [knowledge distillation, reinforcement learning, vision-language models, progressive masking, offline RL]
  - **authors:** Byung-Kwan Lee, Yu-Chiang Frank Wang, Ryo Hachiuma
  - **institution:** NVIDIA
  - **link:** https://arxiv.org/pdf/2512.22238
  - **contributions:** 1. Proposes Masters, a mask-progressive RL distillation framework that first masks non-dominant teacher weights to reduce complexity and then progressively restores them for stable student learning. 2. Introduces an offline RL stage with complementary accuracy and distillation rewards, leveraging pre-generated responses from masked teachers for efficient guidance. 3. Demonstrates that progressive teacher scaling (e.g., from 14B to 38B) yields smoother convergence and stronger generalization than one-shot distillation, providing a scalable path to efficient VLMs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72df4c6bab2069771a9955e5dac4af81d2f423474fdaf07bf9980aaea39edeaf_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of distilling large vision-language models (VLMs) into compact ones by proposing Masters, a framework that uses progressive masking of the teacher model and offline reinforcement learning. This method enables stable knowledge transfer and efficient training, resulting in small VLMs that achieve strong performance, sometimes surpassing larger models, while being far more efficient for deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Masking Teacher and Reinforcing Student for Distilling Vision-Language Models] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[大型VLM难以部署到移动/边缘设备/Large VLMs are impractical for mobile/edge deployment]
        B --> B2[师生模型尺寸差距导致知识蒸馏不稳定/Large size gap causes unstable distillation]
        C --> C1[掩码渐进式强化学习蒸馏框架/Mask-progressive RL distillation framework]
        C --> C2[先掩码教师非主导权重，再渐进恢复/First mask non-dominant teacher weights, then progressively restore]
        C --> C3[离线RL阶段使用准确性和蒸馏奖励/Offline RL stage with accuracy and distillation rewards]
        D --> D1[在多个基准测试中超越现有紧凑型VLM/Outperforms existing compact VLMs on diverse benchmarks]
        D --> D2[渐进增加教师尺寸带来更平滑收敛和更强泛化/Gradually increasing teacher size yields smoother convergence & stronger generalization]
        D --> D3[提供高效、可部署VLM的可扩展路径/Provides a scalable path toward efficient, deployable VLMs]
    ```

- **[arXiv251230] Agentic Software Issue Resolution with Large Language Models: A Survey**
  - **tags:** [se], [automated software maintenance], [large language models, agentic systems, software issue resolution, reinforcement learning, software engineering]
  - **authors:** Zhonghao Jiang, David Lo, Zhongxin Liu
  - **institution:** Zhejiang University, Singapore Management University
  - **link:** https://arxiv.org/pdf/2512.22256
  - **code:** https://github.com/ZhonghaoJiang/Awesome-Issue-Solving
  - **contributions:** 1. Provides a systematic survey of 126 recent studies on LLM-based agentic software issue resolution. 2. Establishes a taxonomy for the field across three key dimensions: benchmarks, techniques, and empirical studies. 3. Highlights the paradigm shift brought by agentic reinforcement learning in designing and training agentic systems for software engineering.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp
  - **Simple LLM Summary:** This paper surveys the use of Large Language Model (LLM)-based agentic systems for automating complex software issue resolution, such as bug fixing. It reviews recent research, categorizes approaches, and discusses how agentic reinforcement learning is changing system design. The conclusion outlines current challenges and future research directions for improving automated software maintenance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Agentic Software Issue Resolution with LLMs: A Survey] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[传统方法依赖人工，效率低/Traditional methods rely on human expertise, inefficient]
        Method[主要方法/Method] --> M1[基于LLM的智能体系统/LLM-based Agentic Systems]
        Method --> M2[系统综述126项研究/Systematic survey of 126 studies]
        Method --> M3[建立三维分类法/Establishes a 3D taxonomy]
        Results[关键结果/Results] --> R1[增强软件维护效率/Enhances software maintenance efficiency]
        Results --> R2[为智能体系统提供验证环境/Provides a validation environment for agentic systems]
        Results --> R3[总结挑战与未来方向/Summarizes challenges & future directions]
    ```

- **[arXiv251230] VideoZoomer: Reinforcement-Learned Temporal Focusing for Long Video Reasoning**
  - **tags:** [cv], [video understanding], [agentic framework, temporal zoom, reinforcement learning, long video reasoning, multimodal large language models]
  - **authors:** Yang Ding, Yizhen Zhang, Xin Lai, Ruihang Chu, Yujiu Yang
  - **institution:** Tsinghua University, The Chinese University of Hong Kong
  - **link:** https://arxiv.org/pdf/2512.22315
  - **code:** https://github.com/zsgvivo/VideoZoomer
  - **contributions:** 1. Proposes VideoZoomer, a novel agentic framework that enables MLLMs to dynamically control visual focus during reasoning for long videos. 2. Introduces a two-stage training strategy combining supervised fine-tuning on distilled trajectories with reinforcement learning to refine the agentic policy. 3. Demonstrates strong performance across long video benchmarks, surpassing open-source models and rivaling proprietary systems with superior efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab9b4b645f4fff1b4f548256b858cb41da2b35db78b1083f110e983d60c3547e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limitation of Multimodal LLMs in understanding long videos due to context window constraints. It proposes VideoZoomer, an agentic framework that dynamically selects and zooms into key temporal moments for fine-grained evidence gathering, trained with a two-stage strategy. The resulting 7B model achieves state-of-the-art performance on long video reasoning benchmarks with high efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[VideoZoomer: Reinforcement-Learned Temporal Focusing for Long Video Reasoning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[长视频理解受限/Limited Long Video Understanding]
        B1 --> B2[上下文窗口限制/Context Window Limitation]
        B1 --> B3[均匀采样忽略关键证据/Uniform Sampling Overlooks Evidence]
        C --> C1[代理框架/Agentic Framework]
        C1 --> C2[动态时间聚焦/Dynamic Temporal Focusing]
        C2 --> C3[从粗到细推理/Coarse-to-Fine Reasoning]
        C --> C4[两阶段训练/Two-Stage Training]
        C4 --> C5[监督微调/Supervised Fine-Tuning]
        C4 --> C6[强化学习/Reinforcement Learning]
        D --> D1[性能强劲/Strong Performance]
        D1 --> D2[超越开源模型/Surpasses Open-Source Models]
        D1 --> D3[媲美专有系统/Rivals Proprietary Systems]
        D --> D4[高效推理/Efficient Reasoning]
        D4 --> D5[低帧预算/Reduced Frame Budget]
    ```

- **[arXiv251230] SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents**
  - **tags:** [mlsys], [agent system], [self-verifying agent, proactive evidence seeking, LLM-as-a-Judge, 3C Principles, agentic reinforcement learning]
  - **authors:** Shaofei Cai, Yulei Qin, Haojia Lin, Zihan Xu, Gang Li, Yuchen Shi, Zongyi Li, Yong Mao, Siqi Cai, Xiaoyu Tan, Yitao Liang, Ke Li, Xing Sun
  - **institution:** Peking University, Tencent
  - **link:** https://arxiv.org/pdf/2512.22322
  - **code:** https://huggingface.co/collections/yolay/smartsnap
  - **contributions:** 1. Proposed SmartSnap, a paradigm shift from passive, post-hoc task verification to proactive, in-situ self-verification by the agent itself. 2. Introduced the Self-Verifying Agent, a new agent type with dual missions to complete tasks and prove accomplishment via curated snapshot evidences guided by 3C Principles (Completeness, Conciseness, Creativity). 3. Demonstrated that the SmartSnap paradigm enables scalable training of LLM-driven agents, achieving significant performance gains (up to 26.08% and 16.66%) on mobile tasks and competitive results against larger models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the scalability bottleneck in agentic RL caused by costly and unreliable post-hoc task verification. It proposes SmartSnap, a paradigm where agents proactively seek minimal, decisive snapshot evidence to prove task completion during execution, guided by 3C Principles. Experiments show this approach significantly improves agent performance and enables scalable training, achieving competitive results with much larger models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Passive, post-hoc verification is costly and unreliable for agentic RL]
        C[主要方法/Method: Proactive self-verification via Self-Verifying Agent and 3C Principles]
        D[关键结果/Results: Performance gains up to 26.08%; competitive with larger models]
    ```

- **[arXiv251230] PHANTOM: Physics-Aware Adversarial Attacks against Federated Learning-Coordinated EV Charging Management System**
  - **tags:** [sec], [Cyber-Physical Systems Security], [False Data Injection (FDI), Physics-Informed Neural Network (PINN), Multi-Agent Reinforcement Learning (MARL)]
  - **authors:** Mohammad Zakaria Haider, Amit Kumar Podder, Prabin Mali, Aranya Chakrabortty, Sumit Paudyal, Mohammad Ashiqur Rahman
  - **institution:** Florida International University, North Carolina State University
  - **link:** https://arxiv.org/pdf/2512.22381
  - **contributions:** 1. Proposes PHANTOM, a physics-aware adversarial attack framework that integrates a federated learning-enabled PINN as a digital twin for accurate modeling of EV charging systems. 2. Develops a multi-agent RL environment using DQN and SAC to generate stealthy FDI attack strategies that bypass conventional detection. 3. Constructs a T&D co-simulation platform to demonstrate the cascading, cross-boundary grid impacts (e.g., load imbalance, voltage instability) of the learned attacks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc4a49b77c0e517eadb20d321d77564888677d1f33b27adf452e13f7c0ffcb8c_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes PHANTOM, a physics-aware adversarial attack framework against federated learning-coordinated EV charging management. It uses a PINN-based digital twin and multi-agent RL to generate stealthy false data injection attacks, which are shown through co-simulation to cause significant grid instability, highlighting the need for physics-aware cybersecurity in vehicle-grid integration.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[PHANTOM: Physics-Aware Adversarial Attacks] --> B(核心问题/Problem: EV Charging Grid Security)
        A --> C(主要方法/Method: PINN Digital Twin + Multi-Agent RL)
        A --> D(关键结果/Results: Stealthy Attacks Cause Grid Instability)
    ```

- **[arXiv251230] AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [LoRA, Parameter-Efficient Fine-Tuning, Activation Function Annealing, Non-linear Adaptation, Model Merging]
  - **authors:** Jiacheng Li, Jianchao Tan, Zhidong Yang, Feiye Huo, Yerui Sun, Yuchen Xie, Xunliang Cai
  - **institution:** Meituan, Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.22455
  - **contributions:** 1. Proposes AFA-LoRA, a novel training strategy that introduces non-linear expressivity into LoRA while preserving its seamless mergeability., 2. Introduces an annealed activation function that transitions from non-linear to linear during training, enabling strong initial learning and final linear integration., 3. Demonstrates the method's effectiveness across multiple tasks, including supervised fine-tuning, reinforcement learning, and speculative decoding, reducing the performance gap with full-parameter training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a5573f75296283a39c5bdbbb0c94652e0aeb935ae378c12528544ca5e188deb_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limited expressive power of linear Low-Rank Adaptation (LoRA) by proposing AFA-LoRA, a method that uses an annealed activation function to enable non-linear training while ensuring the final adapter remains mergeable. This approach narrows the performance gap between LoRA and full-parameter fine-tuning across various tasks, offering a more powerful and practical parameter-efficient adaptation paradigm.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>LoRA线性适配的表达能力有限<br>LoRA's linear adaptation limits expressive power]
        C[主要方法/Method<br>引入退火激活函数<br>Introduce annealed activation function]
        D[关键结果/Results<br>缩小LoRA与全参数训练的差距<br>Reduces gap between LoRA and full-parameter training]
    ```

- **[arXiv251230] FinPercep-RM: A Fine-grained Reward Model and Co-evolutionary Curriculum for RL-based Real-world Super-Resolution**
  - **tags:** [cv], [image super-resolution], [reinforcement learning from human feedback (RLHF), reward hacking, perceptual quality, curriculum learning, fine-grained assessment]
  - **authors:** Yidi Liu, Zihao Fan, Jie Huang, Jie Xiao, Dong Li, Wenlong Zhang, Lei Bai, Xueyang Fu, Zheng-Jun Zha
  - **institution:** University of Science and Technology of China, Shanghai AI Laboratory
  - **link:** https://arxiv.org/pdf/2512.22647
  - **contributions:** 1. Proposes a Fine-grained Perceptual Reward Model (FinPercep-RM) with an encoder-decoder architecture that outputs both a global quality score and a Perceptual Degradation Map to localize defects. 2. Introduces the FGR-30k dataset containing diverse and subtle distortions from real-world super-resolution models for training the reward model. 3. Designs a Co-evolutionary Curriculum Learning (CCL) mechanism that synchronizes the progressive training of the reward model and the ISR model to ensure stable training and suppress reward hacking.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1738fd28b1410f3f5c393bd5d70851ae8df2e1196df6379de62b5d7d48c736b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of reward hacking in RLHF-based Image Super-Resolution, where traditional Image Quality Assessment models are insensitive to local distortions. The authors propose a fine-grained reward model (FinPercep-RM) and a co-evolutionary curriculum learning strategy to provide localized feedback and stabilize training. Experiments show the method improves both global quality and local realism in generated images.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FinPercep-RM: A Fine-grained Reward Model and Co-evolutionary Curriculum for RL-based Real-world Super-Resolution] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>传统IQA模型对局部失真不敏感，导致奖励欺骗/Reward Hacking]
        C[主要方法/Method<br>1. 细粒度感知奖励模型 (FinPercep-RM)<br>2. 协同进化课程学习 (CCL)]
        D[关键结果/Results<br>提升全局质量与局部真实感，实现稳定训练/Improves global quality & local realism, enables stable training]
    ```

- **[arXiv251230] Optimal Regulation of Nonlinear Input-Affine Systems via an Integral Reinforcement Learning-Based State-Dependent Riccati Equation Approach**
  - **tags:** [ai], [reinforcement learning], [State-Dependent Riccati Equation (SDRE), Integral Reinforcement Learning (IRL), Algebraic Riccati Equation (ARE), Nonlinear Input-Affine Systems, Optimal Regulation]
  - **authors:** Arya Rashidinejad Meibodi, Mahbod Gholamali Sinaki, Khalil Alipour
  - **institution:** University of Tehran, K. N. Toosi University of Technology
  - **link:** https://arxiv.org/pdf/2512.22668
  - **contributions:** 1. Proposes a partially model-free method for solving the State-Dependent Riccati Equation (SDRE) for nonlinear system control, eliminating the need for explicit drift dynamics knowledge. 2. Integrates Integral Reinforcement Learning (IRL) to learn the optimal control policy at each system state by solving the Algebraic Riccati Equation (ARE) online. 3. Demonstrates through simulation on a second-order nonlinear system that the IRL-based approach achieves performance comparable to the classical, model-dependent SDRE method.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4e534b9bbeb92e0817df99e432bb5925d48ed82bbc2dcc8e61dbc7faff88ee3_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the optimal regulation of nonlinear input-affine systems. It proposes a novel method that combines the State-Dependent Riccati Equation (SDRE) framework with Integral Reinforcement Learning (IRL) to learn optimal control without requiring a complete system model. Simulation results show that this IRL-based approach can achieve performance similar to the traditional model-dependent SDRE technique.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Optimal Regulation of Nonlinear Input-Affine Systems via an IRL-Based SDRE Approach] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统SDRE方法需要完整系统模型/Traditional SDRE requires full model]
        C --> C1[使用积分强化学习(IRL)在线求解ARE/Uses IRL to solve ARE online]
        C --> C2[部分免模型，无需漂移动力学知识/Partially model-free, no drift dynamics]
        D --> D1[性能接近传统SDRE方法/Performance matches traditional SDRE]
        D --> D2[为非线性控制提供可靠替代方案/Provides reliable alternative for nonlinear control]
    ```

- **[arXiv251230] Memento-II: Learning by Stateful Reflective Memory**
  - **tags:** [ai], [reinforcement learning], [stateful reflective decision process, episodic memory, policy iteration, continual learning, retrieval-augmented generation]
  - **authors:** Jun Wang
  - **institution:** University College London (UCL)
  - **link:** https://arxiv.org/pdf/2512.22716
  - **contributions:** 1. Introduces the Stateful Reflective Decision Process (SRDP), a formal theoretical framework that models continual learning in LLM agents as a two-stage read-write interaction with episodic memory, linking it to policy evaluation and improvement. 2. Provides a theoretical analysis showing that the reflective learning process induces an equivalent Markov Decision Process, enabling the use of classical dynamic programming and RL tools, and establishes convergence guarantees when instantiated with entropy-regularised policy iteration. 3. Unifies heuristic approaches like case-based reasoning and retrieval-augmented generation with principled reinforcement learning, offering a rigorous mathematical foundation for building memory-augmented agents capable of online adaptation without parameter updates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e8cff3c4a9f9d7b57c397010c69f5ae95897e34df30b8e86c43079e22a76db_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a theoretical framework for continual learning in LLM agents that uses episodic memory and reflection instead of back-propagation. The core method formalizes learning as a Stateful Reflective Decision Process, where writing to memory is policy evaluation and reading from it is policy improvement. The main conclusion is that this framework provides a principled, convergent foundation for agents to self-improve through interaction without fine-tuning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Memento-II: Learning by Stateful Reflective Memory] --> B[核心问题/Problem: 缺乏理论解释/Lack of theoretical explanation for memory-based continual learning in LLM agents]
        A --> C[主要方法/Method: 状态化反思决策过程/Stateful Reflective Decision Process (SRDP) with read-write episodic memory]
        A --> D[关键结果/Results: 提供理论框架与收敛保证/Provides theoretical framework and convergence guarantees for optimal policy]
        C --> E[写入对应策略评估/Writing corresponds to policy evaluation]
        C --> F[读取对应策略改进/Reading corresponds to policy improvement]
    ```

- **[arXiv251230] Cyber Resilience in Next-Generation Networks: Threat Landscape, Theoretical Foundations, and Design Paradigms**
  - **tags:** [sec], [network security], [software-defined networking, network function virtualization, zero trust architecture, reinforcement learning, large language models]
  - **authors:** Junaid Farooq, Quanyan Zhu
  - **institution:** University of Michigan-Dearborn, New York University
  - **link:** https://arxiv.org/pdf/2512.22721
  - **contributions:** 1. Provides an interdisciplinary survey and analysis of the evolving threat landscape for next-generation networks, including AI-driven threats. 2. Establishes rigorous definitions and evaluation frameworks for cyber resilience that extend beyond traditional robustness and fault-tolerance. 3. Delves into advanced design paradigms and practical strategies, such as zero trust architectures and AI-enabled autonomous network control, for building resilient systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45ce5f50020bb828e3588c3731b7d026aa73f3b8a029ede8f411eb0dc5e35dad_w640_q70.webp
  - **Simple LLM Summary:** This book examines the challenge of achieving cyber resilience in next-generation networks, which are characterized by technologies like SDN and NFV. It proposes a re-conceptualized framework for resilience and explores advanced design paradigms, including AI-driven methods, to enable adaptive and autonomous threat response. The main conclusion is that a fundamental redesign of resilience mechanisms is required to secure the evolving, heterogeneous network infrastructure.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cyber Resilience in Next-Generation Networks] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[下一代网络威胁格局演变 / Evolving Threat Landscape in Next-Gen Networks]
        C --> C1[建立弹性定义与评估框架 / Establishing Resilience Definitions & Evaluation Frameworks]
        C --> C2[探索先进弹性设计范式 / Exploring Advanced Resilience Design Paradigms]
        C1 --> C1a[超越鲁棒性与容错 / Beyond Robustness & Fault-Tolerance]
        C2 --> C2a[零信任架构 / Zero Trust Architecture]
        C2 --> C2b[AI与LLM驱动响应 / AI & LLM-Driven Response]
        D --> D1[需要重新概念化网络弹性 / Need to Re-conceptualize Network Resilience]
    ```

- **[arXiv251230] FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents**
  - **tags:** [mlsys], [agent system], [context folding, long-horizon RL, non-stationary observation, gradient dilution, selective segment training]
  - **authors:** Jiaqi Shao, Yufeng Miao, Wei Zhang, Bing Luo
  - **institution:** Hong Kong University of Science and Technology, Duke Kunshan University, Microsoft AI
  - **link:** https://arxiv.org/pdf/2512.22733
  - **code:** https://github.com/SHAO-Jiaqi757/FoldAct
  - **contributions:** 1. Separated loss computation for independent gradient signals on summary and action tokens to address gradient dilution. 2. Full context consistency loss to reduce distribution shift caused by policy-dependent observation changes. 3. Selective segment training to reduce computational cost by processing unique contexts efficiently.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebdb4b7ca8ea3a44c0e368eed5fbbebfc656b663cf280d1891abfbf823c742fa_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that treating context folding (history summarization) as a standard action in long-horizon RL for LLMs creates a non-stationary observation distribution, leading to training instability and inefficiency. It proposes FoldAct, a framework with three innovations—separated loss, consistency loss, and selective training—to stabilize training and improve efficiency. The method achieves stable training and a 5.19× speedup.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents] --> B[核心问题 / Problem]
        A --> C[主要方法 / Method]
        A --> D[关键结果 / Results]
        B --> B1[非平稳观测分布 / Non-stationary Observation Distribution]
        B --> B2[梯度稀释 / Gradient Dilution]
        B --> B3[计算成本高 / High Computational Cost]
        C --> C1[分离损失计算 / Separated Loss Computation]
        C --> C2[全上下文一致性损失 / Full Context Consistency Loss]
        C --> C3[选择性片段训练 / Selective Segment Training]
        D --> D1[稳定训练 / Stable Training]
        D --> D2[5.19倍加速 / 5.19× Speedup]
    ```

- **[arXiv251230] ReDiF: Reinforced Distillation for Few Step Diffusion**
  - **tags:** [mlsys], [diffusion models], [reinforcement learning, knowledge distillation, policy optimization, denoising paths, model agnostic]
  - **authors:** Amirhossein Tighkhorshid, Zahra Dehghanian, Gholamali Aminian, Chengchun Shi, Hamid R. Rabiee
  - **institution:** Sharif University of Technology, Alan Turing Institute, London School of Economics
  - **link:** https://arxiv.org/pdf/2512.22802
  - **contributions:** 1. Proposes a novel reinforcement learning framework for distilling diffusion models, treating distillation as a policy optimization problem. 2. Introduces a reward signal based on alignment with teacher outputs, allowing the student model to explore multiple denoising paths and take longer, optimized steps. 3. Demonstrates a model-agnostic framework that achieves superior performance with fewer inference steps and computational resources compared to existing distillation techniques.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73d47eb5443f9f8848454e65825da3569c70d954239d9794e6cff086fa5bc17a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the slow sampling problem in diffusion models by proposing ReDiF, a reinforcement learning-based distillation framework. Instead of using fixed losses, it treats distillation as policy optimization, using a reward signal to guide the student to take longer, optimized steps. The method achieves better performance with fewer steps and is applicable to various diffusion models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ReDiF: Reinforced Distillation for Few Step Diffusion] --> B(核心问题/Problem: Diffusion模型采样慢/Slow sampling in diffusion models)
        A --> C(主要方法/Method: 基于强化学习的蒸馏框架/Reinforcement learning based distillation framework)
        A --> D(关键结果/Results: 更少步骤，性能更优/Fewer steps, superior performance)
    ```

- **[arXiv251230] Parallel Diffusion Solver via Residual Dirichlet Policy Optimization**
  - **tags:** [mlsys], [diffusion models], [ODE solver, parallel gradient evaluation, reinforcement learning fine-tuning, low-latency sampling, Dirichlet policy]
  - **authors:** Ruoyu Wang, Ziyu Li, Beier Zhu, Liangyu Yuan, Hanwang Zhang, Xun Yang, Xiaojun Chang, Chi Zhang
  - **institution:** Westlake University, University of Illinois Urbana-Champaign, Nanyang Technological University, Shanghai Jiao Tong University, University of Science and Technology of China
  - **link:** https://arxiv.org/pdf/2512.22796
  - **contributions:** 1. Proposes EPD-Solver, a novel ODE solver that uses multiple parallel gradient evaluations per step to reduce truncation errors while maintaining low latency. 2. Introduces a two-stage optimization framework, including a parameter-efficient RL fine-tuning scheme that reformulates the solver as a stochastic Dirichlet policy to avoid reward hacking. 3. Demonstrates the method's flexibility as a plugin (EPD-Plugin) to enhance existing ODE samplers and shows state-of-the-art performance in both unconditional and text-to-image generation benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2678a61b07c4f5b5cfdd2006673a05c8a4699c07dee6180c47750600496f796_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high sampling latency of diffusion models by proposing EPD-Solver, a novel ODE solver that incorporates parallel gradient evaluations to reduce errors without increasing latency. The method uses a two-stage optimization, including RL fine-tuning with a Dirichlet policy, and can be used as a plugin. Experiments show it achieves superior image quality at low step counts and improves human preference scores in text-to-image generation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Parallel Diffusion Solver via Residual Dirichlet Policy Optimization] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[扩散模型采样延迟高 / High sampling latency of DMs]
        B --> B2[现有求解器在低步数下质量下降 / Existing solvers degrade quality at low NFEs]
        C --> C1[EPD-Solver: 集成并行方向求解器 / Ensemble Parallel Direction solver]
        C --> C2[两阶段优化: 蒸馏 + RL微调 / Two-stage optimization: Distillation + RL fine-tuning]
        C --> C3[作为插件提升现有求解器 / Plugin (EPD-Plugin) for existing samplers]
        D --> D1[低延迟下SOTA FID分数 / SOTA FID scores at low latency]
        D --> D2[在T2I任务中提升人类偏好分数 / Improved human preference scores in T2I]
    ```

- **[arXiv251230] TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [curriculum learning, goal-conditioned reinforcement learning, temporal variance, student-teacher paradigm, Q-function]
  - **authors:** Gaurav Chaudhary, Laxmidhar Behera
  - **institution:** IIT Kanpur
  - **link:** https://arxiv.org/pdf/2512.22824
  - **contributions:** 1. Proposes a novel Student-Teacher learning paradigm with a Temporal Variance-Driven Curriculum for accelerating Goal-Conditioned RL. 2. Establishes a theoretical connection between the temporal variance of Q-values and policy evolution. 3. Demonstrates the algorithm-agnostic nature of the approach, showing consistent improvements across 11 robotic manipulation and maze navigation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the sample inefficiency of uniform goal selection in multi-goal reinforcement learning. It proposes a TEACH framework where a teacher module dynamically selects goals with the highest temporal variance in Q-values to create an adaptive curriculum. The method is shown to improve learning efficiency over state-of-the-art curriculum learning methods across diverse robotic tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Uniform goal selection is sample inefficient in multi-goal RL/多目标RL中均匀目标选择样本效率低]
        C --> C1[Student-Teacher paradigm with Temporal Variance-Driven Curriculum/基于时序方差的师生课程学习范式]
        C --> C2[Teacher prioritizes goals with highest Q-value temporal variance/教师模块优先选择Q值时序方差最高的目标]
        D --> D1[Consistent improvements over SOTA methods/相比SOTA方法取得一致改进]
        D --> D2[Evaluated on 11 robotic manipulation and navigation tasks/在11个机器人操作与导航任务上验证]
    ```

- **[arXiv251230] MARPO: A Reflective Policy Optimization for Multi Agent Reinforcement Learning**
  - **tags:** [ai], [multi-agent reinforcement learning], [reflective policy optimization, asymmetric clipping, sample efficiency]
  - **authors:** Cuiling Wu, Yaozhong Gan, Junliang Xing, Ying Fu
  - **institution:** Beijing Institute of Technology, QiYuan Lab
  - **link:** https://arxiv.org/pdf/2512.22832
  - **contributions:** 1. Proposes a reflection mechanism that leverages subsequent trajectories to enhance sample efficiency. 2. Introduces an asymmetric clipping mechanism derived from KL divergence to dynamically adjust the clipping range for improved training stability. 3. Validates the proposed MARPO framework on complex multi-agent benchmarks, demonstrating superior performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f4bb8bd99df87d3fa5d6dae0b3405e01825ac1c612b07fbdd5519ae2b33ce19_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes MARPO, a new multi-agent reinforcement learning method to address sample inefficiency. It introduces a reflection mechanism to use trajectory information and an asymmetric clipping mechanism for stable training. The method is shown to outperform existing approaches in standard multi-agent environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[MARPO: A Reflective Policy Optimization for Multi-Agent Reinforcement Learning] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Sample inefficiency in MARL] --> P1[挑战/Challenge: High interaction cost]
        Method[主要方法/Method: MARPO Framework] --> M1[反射机制/Reflection Mechanism: Leverages subsequent trajectories]
        Method --> M2[非对称裁剪/Asymmetric Clipping: KL-based dynamic adjustment]
        Results[关键结果/Results: Outperforms other methods] --> R1[评估/Evaluation: Classic multi-agent environments]
    ```

- **[arXiv251230] AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning**
  - **tags:** [mlsys], [agent system], [automated environment synthesis, environment-level RL, agentic reinforcement learning, simulated user, policy optimization]
  - **authors:** Shihao Cai, Runnan Fang, Jialong Wu, Baixuan Li, Xinyu Wang, Yong Jiang, Liangcai Su, Liwen Zhang, Wenbiao Yin, Zhen Zhang, Fuli Feng, Pengjun Xie, Xiaobin Wang
  - **institution:** Tongyi Lab, Alibaba Group
  - **link:** https://arxiv.org/pdf/2512.22857
  - **contributions:** 1. A unified, automated pipeline for synthesizing scalable simulated environments with high-difficulty, easily verifiable tasks. 2. An Environment-level Relative Policy Optimization (ERPO) algorithm that mitigates simulated user instability and performs advantage estimation at the environment level. 3. Comprehensive validation on agentic benchmarks demonstrating effectiveness and out-of-domain generalization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf43f01b4afce8af27cc99730129e26bd5b170c90172ddf77134a48ec54cccb0_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes AutoForge, a framework to automate the synthesis of challenging simulated environments for training language-based agents via reinforcement learning. It introduces an environment-level RL algorithm to improve training stability and efficiency by handling simulated user instability and heterogeneous environments. Evaluations show the method is effective and generalizes well to out-of-domain tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AutoForge] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[环境合成半自动/Semi-automated Environment Synthesis]
        B --> B2[任务难度不足/Insufficient Task Difficulty]
        B --> B3[模拟用户不稳定/Simulated User Instability]
        C --> C1[自动化环境合成管道/Automated Environment Synthesis Pipeline]
        C --> C2[环境级RL算法/Environment-level RL Algorithm (ERPO)]
        D --> D1[基准测试有效/Effective on Benchmarks (τ-bench, etc.)]
        D --> D2[域外泛化强/Strong Out-of-domain Generalization]
    ```

- **[arXiv251230] Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks**
  - **tags:** [sec], [blockchain security, IoT security, adversarial machine learning], [Fully Homomorphic Encryption, Attribute-Based Access Control, Multi-Agent Reinforcement Learning, Byzantine Fault Tolerance, Trust-Based Consensus]
  - **authors:** Soham Padia, Dhananjay Vaidya, Ramchandra Mangrulkar
  - **institution:** Northeastern University, Dwarkadas J. Sanghvi College of Engineering
  - **link:** https://arxiv.org/pdf/2512.22860
  - **contributions:** 1. Proposes a novel trust-based delegated consensus framework for blockchain IoT that integrates Fully Homomorphic Encryption (FHE) with Attribute-Based Access Control (ABAC) for privacy-preserving policy evaluation. 2. Systematically compares the performance of three reinforcement learning approaches (RL, DRL, MARL) against five distinct and sophisticated adversarial attack families. 3. Empirically demonstrates that Multi-Agent RL (MARL) provides superior defense against collusive attacks and identifies the catastrophic vulnerability of all learning agents to Time-Delayed Poisoning (sleeper) attacks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373f990d6c218afb4f9e660bb84fd86dc8e9d7006d2b7bdef3d956a991960bff_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses securing blockchain-enabled IoT networks by proposing a trust-based consensus framework that combines privacy-preserving techniques (FHE and ABAC) with learning-based defenses. It compares RL, DRL, and MARL against five attack types, finding MARL most effective against collusive attacks but revealing that all methods are highly vulnerable to time-delayed poisoning attacks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Adaptive Trust Consensus for Blockchain IoT<br/>区块链物联网自适应信任共识"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["Securing Blockchain IoT Against Attacks<br/>保护区块链物联网免受攻击"] --> A1["Naive Malicious Attack (NMA)<br/>简单恶意攻击"]
        Problem --> A2["Collusive Rumor Attack (CRA)<br/>合谋谣言攻击"]
        Problem --> A3["Adaptive Adversarial Attack (AAA)<br/>自适应对抗攻击"]
        Problem --> A4["Byzantine Fault Injection (BFI)<br/>拜占庭故障注入"]
        Problem --> A5["Time-Delayed Poisoning (TDP)<br/>时间延迟投毒"]
    
        Method["Trust Framework with FHE & ABAC + Learning Defenses<br/>基于FHE和ABAC的信任框架与学习防御"] --> M1["Reinforcement Learning (RL)<br/>强化学习"]
        Method --> M2["Deep RL (DRL)<br/>深度强化学习"]
        Method --> M3["Multi-Agent RL (MARL)<br/>多智能体强化学习"]
    
        Results["Key Experimental Findings<br/>关键实验结果"] --> R1["MARL best vs. Collusive Attacks<br/>MARL对合谋攻击最佳"]
        Results --> R2["DRL & MARL perfect vs. Adaptive Attacks<br/>DRL和MARL完美防御自适应攻击"]
        Results --> R3["All agents fail vs. Time-Delayed Poisoning<br/>所有智能体在延迟投毒攻击下失效"]
    ```

- **[arXiv251230] Reinforcement Networks: novel framework for collaborative Multi-Agent Reinforcement Learning tasks**
  - **tags:** [ai], [multi-agent reinforcement learning], [Reinforcement Networks, directed acyclic graph (DAG), credit assignment, LevelEnv, hierarchical RL]
  - **authors:** Maksim Kryzhanovskiy, Svetlana Glazyrina, Roman Ischenko, Konstantin Vorontsov
  - **institution:** Lomonosov Moscow State University, Institute for Artificial Intelligence, Lomonosov Moscow State University
  - **link:** https://arxiv.org/pdf/2512.22876
  - **contributions:** 1. Introduces the Reinforcement Networks framework, a general approach for collaborative MARL that organizes agents as vertices in a directed acyclic graph (DAG)., 2. Formalizes training and inference methods for the framework and connects it to the LevelEnv concept for reproducible construction and evaluation., 3. Demonstrates improved performance over standard MARL baselines and unifies hierarchical, modular, and graph-structured views of MARL.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b613175c92e9bdddfbd57ed84d044a5846b7b8148cca8ab0405e69847f66c33a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of end-to-end training for AI systems with multiple learnable components. It proposes Reinforcement Networks, a framework that organizes agents in a directed acyclic graph for flexible credit assignment and coordination in multi-agent reinforcement learning. The method shows improved performance over baselines and provides a principled foundation for designing complex multi-agent systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Reinforcement Networks] --> B[核心问题/Problem: End-to-end training of multi-component AI systems]
        A --> C[主要方法/Method: MARL agents organized in a DAG (Reinforcement Networks)]
        A --> D[关键结果/Results: Improved performance, unified framework for structured MARL]
    ```

- **[arXiv251230] SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [hierarchical deep reinforcement learning, portfolio management, dynamic asset grouping, utility-based capital allocation, SHAP interpretability]
  - **authors:** Xiaotian Ren, Nuerxiati Abudurexiti, Zhengyong Jiang, Angelos Stefanidis, Hongbin Liu, Jionglong Su
  - **institution:** Not explicitly stated in provided content.
  - **link:** https://arxiv.org/pdf/2512.22895
  - **contributions:** 1. Proposes a hierarchical DRL framework (SAMP-HDRL) that integrates dynamic asset grouping, upper-lower agent coordination, and a utility-based capital allocation mechanism for robust portfolio management. 2. Demonstrates superior performance through extensive backtests across multiple market regimes, showing consistent improvements in return and risk-adjusted metrics over traditional and DRL baselines. 3. Provides interpretability via SHAP analysis, revealing a complementary "diversified + concentrated" decision pattern across agent layers.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07244b408b9238d10b2d5561e0007db8732b1d4e9e79bda5477bef5db2dd385c_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles portfolio optimization in non-stationary markets by proposing SAMP-HDRL, a hierarchical deep reinforcement learning framework that segments assets, coordinates global and local agents, and uses a utility-based capital allocator. The method outperforms numerous baselines in backtests, achieving higher returns and risk-adjusted ratios, and its decisions are made interpretable through SHAP analysis, revealing a combined diversified and concentrated investment strategy.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Portfolio optimization in non-stationary markets with regime shifts and limited DRL interpretability] --> P1[挑战/Challenges: Dynamic correlations, regime shifts]
        Method[主要方法/Method: Hierarchical DRL with segmented allocation] --> M1[上层代理/Upper-level Agent: Extracts global market signals]
        Method --> M2[动态资产分组/Dynamic Asset Grouping: Partitions market into subsets]
        Method --> M3[下层代理/Lower-level Agents: Perform intra-group allocation]
        Method --> M4[效用资本分配/Utility-based Capital Allocation: Integrates risky & risk-free assets]
        Results[关键结果/Results: Outperforms baselines, provides interpretability] --> R1[性能/Performance: Higher Return, Sharpe, Sortino, Omega ratios]
        Results --> R2[可解释性/Interpretability: SHAP reveals "diversified + concentrated" mechanism]
    ```

- **[arXiv251230] Sat-EnQ: Satisficing Ensembles of Weak Q-Learners for Reliable and Compute-Efficient Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [Q-learning, ensemble learning, satisficing, distillation, bounded rationality]
  - **authors:** Ünver Çiftçi
  - **institution:** Tekirdağ Namık Kemal University
  - **link:** https://arxiv.org/pdf/2512.22910
  - **contributions:** 1. Proposes a two-phase framework (Sat-EnQ) that first trains an ensemble of lightweight Q-networks using a satisficing objective to limit early value growth and reduce variance. 2. Provides theoretical proof that the satisficing objective induces bounded updates and cannot increase target variance, with a corollary for substantial reduction. 3. Demonstrates empirical results including significant variance reduction, elimination of catastrophic failures, robustness to noise, and improved compute efficiency compared to baseline methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d12c2382ed5ee9e4da47d1775097d950b626f676e5d3552cd0ff19b6c385b2a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the instability of deep Q-learning, especially early in training, by introducing Sat-EnQ. This framework first trains a satisficing ensemble of weak Q-learners to produce stable, low-variance estimates, then distills and fine-tunes the ensemble. The method significantly improves training reliability, robustness, and computational efficiency compared to standard approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Sat-EnQ] --> B[核心问题/Problem: Deep Q-Learning Instability]
        A --> C[主要方法/Method: Two-Phase Satisficing Ensemble]
        A --> D[关键结果/Results: Variance Reduction & Robustness]
        B --> B1[早期训练不稳定/Early Training Instability]
        B --> B2[高方差与灾难性失败/High Variance & Catastrophic Failure]
        C --> C1[阶段1: 满足化集成训练/Phase 1: Satisficing Ensemble Training]
        C --> C2[阶段2: 蒸馏与微调/Phase 2: Distillation & Fine-tuning]
        D --> D1[3.8倍方差降低/3.8x Variance Reduction]
        D --> D2[0%灾难性失败/0% Catastrophic Failure]
        D --> D3[2.5倍计算效率提升/2.5x Compute Efficiency]
    ```

- **[arXiv251230] Heterogeneity in Multi-Agent Reinforcement Learning**
  - **tags:** [ai], [multi-agent reinforcement learning], [heterogeneity, multi-agent reinforcement learning, parameter sharing, heterogeneity distance, dynamic algorithm]
  - **authors:** Tianyi Hu, Zhiqiang Pu, Yuan Wang, Tenghai Qiu, Min Chen, Xin Yu
  - **institution:** Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences
  - **link:** https://arxiv.org/pdf/2512.22941
  - **code:** https://github.com/Harry67Hu/HetDPS
  - **contributions:** 1. Proposes a systematic categorization of heterogeneity in MARL into five types with mathematical definitions. 2. Defines a heterogeneity distance and introduces a practical method to quantify agent heterogeneity. 3. Designs a heterogeneity-based dynamic parameter sharing algorithm that demonstrates better interpretability and adaptability compared to baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de4448c413f180749bc7f2220bea2793dad9a358fb068164020bd7b0421e5b05_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of a rigorous definition and understanding of heterogeneity in multi-agent reinforcement learning (MARL). It proposes a methodology to define, quantify, and utilize heterogeneity, culminating in a dynamic parameter sharing algorithm. Experiments show this algorithm offers improved interpretability and adaptability over other parameter-sharing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Heterogeneity in Multi-Agent Reinforcement Learning<br/>多智能体强化学习中的异质性"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["缺乏对异质性的严格定义<br/>Lacks rigorous definition of heterogeneity"]
        Method --> M1["定义与分类<br/>Definition & Categorization"]
        Method --> M2["量化方法<br/>Quantification Method"]
        Method --> M3["应用算法<br/>Application Algorithm"]
        M1 --> M1_1["五类异质性<br/>Five types of heterogeneity"]
        M2 --> M2_1["异质性距离<br/>Heterogeneity distance"]
        M3 --> M3_1["动态参数共享<br/>Dynamic Parameter Sharing"]
        Results --> R1["有效识别与量化<br/>Effective identification & quantification"]
        Results --> R2["算法性能优越<br/>Algorithm outperforms baselines"]
    ```

- **[arXiv251230] APO: Alpha-Divergence Preference Optimization**
  - **tags:** [ai], [reinforcement learning from human feedback (rlhf)], [alpha-divergence, preference optimization, mode collapse, anchored coordinates, gradient variance]
  - **authors:** Wang Zixian
  - **institution:** China Mobile Communications Group Shandong Co., Ltd. Tai’an Branch
  - **link:** https://arxiv.org/pdf/2512.22953
  - **contributions:** 1. Introduces APO, an anchored framework using Csiszár alpha-divergence to continuously interpolate between forward and reverse KL behavior for RLHF. 2. Derives unified gradient dynamics parameterized by alpha and analyzes gradient variance properties. 3. Proposes a practical reward-and-confidence-guarded alpha schedule to transition from mode-covering to mode-seeking behavior safely.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a407212dc95985ef8918d58e7c65f70fd3f6adf8764c95f85871cd1924b3528_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the trade-off between stable but under-exploitative mode-covering updates and high-reward but unstable mode-seeking updates in LLM alignment. It proposes APO, an anchored preference optimization framework that uses alpha-divergence to smoothly interpolate between these regimes via a guarded schedule. Experiments show APO achieves competitive performance while maintaining training stability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[APO: Alpha-Divergence Preference Optimization] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[两种分歧权衡 / Two Divergence Trade-off]
        P1 --> P2[前向KL覆盖但保守 / Forward KL: Mode-Covering but Conservative]
        P1 --> P3[反向KL寻求但易崩溃 / Reverse KL: Mode-Seeking but Collapses]
        Method[主要方法/Method] --> M1[锚定框架 / Anchored Framework]
        M1 --> M2[使用α-散度插值 / Use α-Divergence to Interpolate]
        M2 --> M3[调度α值 / Schedule α Value]
        Results[关键结果/Results] --> R1[竞争性性能 / Competitive Performance]
        Results --> R2[保持稳定性 / Maintains Training Stability]
    ```

- **[arXiv251230] Diversity or Precision? A Deep Dive into Next Token Prediction**
  - **tags:** [ai], [reinforcement learning], [policy gradient, reward shaping, next-token prediction, exploration space, cross-entropy loss]
  - **authors:** Haoyuan Wu, Hai Wang, Jiajia Wu, Jinxiang Ou, Keyao Wang, Weile Chen, Zihao Zheng, Bei Yu
  - **institution:** Tencent, The Chinese University of Hong Kong
  - **link:** https://arxiv.org/pdf/2512.22955
  - **contributions:** 1. Reinterprets standard cross-entropy loss as a specific instance of policy gradient optimization in a single-step episode, bridging supervised learning and RL. 2. Proposes a generalized pre-training objective using on-policy RL principles and a novel reward-shaping strategy to balance diversity and precision in the token-output distribution. 3. Empirically finds that a precision-oriented prior, rather than a high-entropy one, creates a more favorable exploration space for subsequent RL, enhancing reasoning performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e03f108685a26b73d2c14c07a3e7234e09a5b32e612d72a9751508fcbb93ec32_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how the token-output distribution from pre-training shapes the exploration space for subsequent reinforcement learning (RL) in language models. It proposes a new pre-training method that frames next-token prediction as an RL problem, using a reward-shaping strategy to control distribution precision. The key finding is that a precision-focused prior, contrary to intuition, provides a better exploration foundation for RL than a high-entropy one.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Diversity or Precision? A Deep Dive into Next Token Prediction] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[预训练分布如何影响后续RL的探索空间？/How does the pre-trained distribution affect the RL exploration space?]
        Method[主要方法/Method] --> M1[将交叉熵损失重新解释为策略梯度/Reinterpret cross-entropy as policy gradient]
        Method --> M2[提出基于奖励塑形的广义预训练目标/Propose a generalized pre-training objective with reward shaping]
        M2 --> M2_1[正奖励缩放因子/Positive reward scaling factor]
        M2 --> M2_2[排名感知的负令牌处理/Rank-aware negative token treatment]
        Results[关键结果/Results] --> R1[精度导向的先验优于高熵先验/Precision-oriented prior yields superior exploration space]
    ```

- **[arXiv251230] Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning**
  - **tags:** [mlsys], [llm training], [reinforcement learning, training-inference mismatch, vocabulary pruning, gradient estimation, numerical stability]
  - **authors:** Yingru Li, Jiawei Xu, Jiacai Liu, Yuxuan Tong, Ziniu Li, Tianle Cai, Ge Zhang, Qian Liu, Baoxiang Wang
  - **institution:** (Institutions not explicitly listed in provided content. Affiliation inference requires author list with affiliations or email domains, which are not present in the given text. Therefore, cannot be determined from the provided snippet.)
  - **link:** https://arxiv.org/pdf/2512.23087
  - **contributions:** 1. Proves that the training-inference mismatch in LLM RL has an asymmetric effect, where the bound on log-probability mismatch scales with (1-p), making low-probability "tail" tokens the primary source of instability. 2. Proposes a novel method to stabilize RL training by dynamically pruning the vocabulary to exclude the extreme tail tokens, trading large, biased mismatches for a small, bounded optimization bias. 3. Provides both empirical demonstration of stable training and a theoretical bound on the optimization bias introduced by the proposed vocabulary pruning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83b750895381feb238b14991a4015088fa8d05eb24ab0374082f6c25fb3ddd7_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a fundamental training-inference mismatch in LLM reinforcement learning caused by differing numerical precision between high-throughput inference and stable training systems. To address this, the authors propose dynamically pruning low-probability "tail" tokens from the vocabulary during RL optimization, which stabilizes training by replacing large, biased errors with a small, bounded bias. Both theoretical analysis and empirical results support the effectiveness of this method.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[训练-推理不匹配 / Training-Inference Mismatch]
        B1 --> B2[尾部token导致梯度不稳定 / Tail tokens destabilize gradient estimation]
        C --> C1[动态剪枝词汇表 / Dynamic Vocabulary Pruning]
        C1 --> C2[排除极端尾部token / Exclude extreme tail tokens]
        D --> D1[实现稳定训练 / Achieves stable training]
        D --> D2[理论界定优化偏差 / Theoretically bounds optimization bias]
    ```

- **[arXiv251230] A Note on Hybrid Online Reinforcement and Imitation Learning for LLMs: Formulations and Algorithms**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [Imitation Learning, Reinforcement Learning, KL divergence, Dense Gradient, Sparse Gradient]
  - **authors:** Yingru Li, Ziniu Li, Jiacai Liu
  - **institution:** Not explicitly stated in provided content.
  - **link:** https://arxiv.org/pdf/2512.23097
  - **contributions:** 1. Derives the exact gradient decomposition of a unified KL+reward objective into analytic Dense and sampled Sparse terms. 2. Provides an efficient logit-level gradient formula for GPU implementation. 3. Establishes mathematical equivalence to KL-regularized RLHF and discusses training curriculum implications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a unified framework for fine-tuning LLMs that integrates Imitation Learning and Reinforcement Learning. It analyzes the gradient of a combined objective to decompose it into a token-level Dense Gradient and a long-horizon Sparse Gradient, enabling efficient implementation. The work clarifies its relationship to existing methods like RLHF and discusses practical training considerations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Hybrid Online RL and IL for LLMs] --> B[核心问题/Problem: Train-inference distribution mismatch in LLM fine-tuning]
        A --> C[主要方法/Method: Unified framework combining Imitation Learning and Reinforcement Learning]
        A --> D[关键结果/Results: Gradient decomposes into Dense Gradient (analytic) and Sparse Gradient (sampled)]
    ```

- **[arXiv251230] Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients**
  - **tags:** [ai], [reinforcement learning], [reinforcement learning, vision-language model, supervised fine-tuning, generalization paradox, cross-dataset transferability]
  - **authors:** Armin Berger, Manuela Bergau, Helen Schneider, Saad Ahmad, Tom Anglim Lagones, Gianluca Brugnara, Martha Foltyn-Dumitru, Kai Schlamp, Philipp Vollmuth, Rafet Sifa
  - **institution:** Fraunhofer IAIS, University of Bonn, Lamarr Institute, Department of Health Queensland, Griffith University, University Hospital Bonn
  - **link:** https://arxiv.org/pdf/2512.23090
  - **contributions:** 1. Introduced ChexReason, a resource-efficient vision-language model for medical imaging trained with an R1-style (SFT+GRPO) method using minimal data and compute. 2. Identified a fundamental tension where RL optimization (GRPO) improves in-distribution benchmark performance but significantly degrades cross-dataset generalization, a pattern also observed in high-resource models. 3. Discovered a generalization paradox where the SFT checkpoint uniquely improves cross-dataset performance, suggesting teacher-guided reasoning captures more institution-agnostic features than RL optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87b0b1a571aa28f5dd9685e96b13ff3420ed36b0e1d569fff8b1394d564751f_w640_q70.webp
  - **Simple LLM Summary:** The paper investigates applying reinforcement learning (RL) to vision-language models for medical imaging, finding that while RL improves performance on the training benchmark, it harms the model's ability to generalize to new datasets. The authors conclude that for clinical robustness, curated supervised fine-tuning may be more effective than aggressive RL optimization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Benchmark Success, Clinical Failure<br>基准成功，临床失败] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[RL优化提升基准性能但损害泛化<br>RL improves benchmarks but harms generalization]
        C --> C1[使用SFT+GRPO训练ChexReason VLM<br>Train ChexReason VLM with SFT+GRPO]
        D --> D1[GRPO提升CheXpert性能23%<br>GRPO improves CheXpert by 23%]
        D --> D2[GRPO导致NIH性能下降19%<br>GRPO degrades NIH by 19%]
        D --> D3[SFT检查点提升跨数据集泛化<br>SFT checkpoint improves cross-dataset generalization]
    ```

- **[arXiv251230] Evaluating Parameter Efficient Methods for RLVR**
  - **tags:** [ai], [reinforcement learning], [Parameter-Efficient Fine-Tuning, Reinforcement Learning with Verifiable Rewards, LoRA, Spectral Collapse, Mathematical Reasoning]
  - **authors:** Qingyu Yin, Yulun Wu, Zhennan Shen, Sunbowen Li, Zhilin Wang, Yanshu Li, Chak Tou Leong, Jiale Kang, Jinjin Gu
  - **institution:** Zhejiang University, HKUST, WUST, USTC, Brown University, Hong Kong Polytechnic University, INSAIT
  - **link:** https://arxiv.org/pdf/2512.23165
  - **contributions:** 1. Conducted the first comprehensive evaluation of over 12 PEFT methods for RLVR, challenging the default use of standard LoRA. 2. Identified that structural PEFT variants (DoRA, AdaLoRA, MiSS) consistently outperform LoRA in this setting. 3. Discovered and explained the failure of SVD-informed initialization methods (e.g., PiSSA) due to a "spectral collapse" phenomenon and misalignment with RL optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87ad6f372a6a1a3b13e37f8468a6816e52a585402f7e4505a01391ffaed0621c_w640_q70.webp
  - **Simple LLM Summary:** This paper systematically evaluates Parameter-Efficient Fine-Tuning (PEFT) methods for Reinforcement Learning with Verifiable Rewards (RLVR) on mathematical reasoning tasks. It finds that structural variants like DoRA outperform standard LoRA, while SVD-based methods fail due to spectral collapse, and extreme parameter reduction bottlenecks performance. The work provides a guide for selecting PEFT methods in RLVR.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Evaluating Parameter Efficient Methods for RLVR] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[RLVR中最佳PEFT架构未知 / Optimal PEFT architecture for RLVR is unknown]
        C --> C1[系统评估12+种PEFT方法 / Systematically evaluate 12+ PEFT methods]
        C --> C2[在数学推理基准上测试 / Test on mathematical reasoning benchmarks]
        D --> D1[结构变体优于标准LoRA / Structural variants outperform standard LoRA]
        D --> D2[SVD初始化导致谱崩溃 / SVD initialization causes spectral collapse]
        D --> D3[极端参数减少损害推理能力 / Extreme parameter reduction harms reasoning]
    ```

- **[arXiv251230] A Human-Oriented Cooperative Driving Approach: Integrating Driving Intention, State, and Conflict**
  - **tags:** [ai], [reinforcement learning], [cooperative driving, human-machine conflict, intention-aware planning, authority allocation, shared control]
  - **authors:** Qin Wang, Shanmin Pang, Jianwu Fang, Shengye Dong, Fuhao Liu, Jianru Xue, Chen Lv
  - **institution:** Xi'an Jiaotong University, Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.23220
  - **code:** https://github.com/i-Qin/HOCD
  - **contributions:** 1. Proposes a Human-Oriented Cooperative Driving (HOCD) approach that minimizes human-machine conflict by prioritizing driver intention and state. 2. Designs an intention-aware trajectory planning method at the tactical level, using an intention consistency cost to align the trajectory with driver intention. 3. Develops a reinforcement learning-based control authority allocation strategy at the operational level to achieve consistency between driver state and authority allocation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d5e5ef9e0e93b645fd2997c604be86cc36eb4f1a7f88af7219f0cc6a908523b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a Human-Oriented Cooperative Driving (HOCD) approach to improve human-vehicle interaction by minimizing conflict. The method integrates intention-aware trajectory planning and a reinforcement learning-based authority allocation strategy. Simulation and human-in-the-loop experiments show the approach aligns with driver intention, ensures reasonable authority allocation, and enhances driving performance compared to other methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Human-Oriented Cooperative Driving Approach<br>人机协同驾驶方法"] --> Problem["核心问题/Problem<br>Human-machine conflict in cooperative driving<br>人机协同驾驶中的人机冲突"]
        Root --> Method["主要方法/Method<br>HOCD: Integrates intention & state<br>HOCD: 集成驾驶意图与状态"]
        Method --> SubMethod1["战术层面/Tactical Level<br>Intention-aware trajectory planning<br>意图感知轨迹规划"]
        Method --> SubMethod2["操作层面/Operational Level<br>RL-based authority allocation<br>基于强化学习的权限分配"]
        Root --> Results["关键结果/Results<br>Aligns intention, reasonable allocation, enhances performance<br>对齐意图、合理分配、提升性能"]
    ```

- **[arXiv251230] ViLaCD-R1: A Vision-Language Framework for Semantic Change Detection in Remote Sensing**
  - **tags:** [cv], [change detection], [vision-language model, remote sensing, semantic change detection, supervised fine-tuning, reinforcement learning]
  - **authors:** Xingwei Ma, Shiyang Feng, Bo Zhang, Bin Wang
  - **institution:** Fudan University, Shanghai Artificial Intelligence Laboratory
  - **link:** https://arxiv.org/pdf/2512.23244
  - **contributions:** 1. Proposes ViLaCD-R1, a novel two-stage vision-language framework for semantic change detection in remote sensing, comprising a Multi-Image Reasoner (MIR) and a Mask-Guided Decoder (MGD). 2. Introduces a training strategy for the VLM using supervised fine-tuning (SFT) and reinforcement learning (RL) on block-level dual-temporal inference tasks to generate a coarse change mask. 3. Demonstrates that the framework significantly improves semantic change recognition and localization while suppressing non-semantic variations, achieving state-of-the-art performance on multiple benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5871856f6e1854dd58df304f783ce8ea57314887e0296e446d48afb30805307_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of existing remote sensing change detection methods, such as poor semantic understanding and inaccurate localization, by proposing ViLaCD-R1. This two-stage vision-language framework first uses a fine-tuned VLM to generate a coarse change mask from dual-temporal images, then refines it with a decoder to produce a precise change map. The method shows superior performance in recognizing true semantic changes and suppressing irrelevant variations across several benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ViLaCD-R1: 遥感语义变化检测的视觉语言框架] --> B1(核心问题/Problem)
        A --> B2(主要方法/Method)
        A --> B3(关键结果/Results)
        B1 --> C1[传统方法语义理解不足/Traditional methods lack semantic understanding]
        B1 --> C2[现有VLM方法定位不准确/Existing VLM methods have inaccurate localization]
        B2 --> D1[两阶段框架/Two-stage framework]
        D1 --> E1[多图像推理器/Multi-Image Reasoner]
        E1 --> F1[SFT与RL训练/SFT and RL training]
        E1 --> F2[生成粗变化掩码/Generate coarse change mask]
        D1 --> E2[掩码引导解码器/Mask-Guided Decoder]
        E2 --> F3[融合特征与掩码/Fuse features and mask]
        E2 --> F4[预测精细变化图/Predict precise change map]
        B3 --> G1[提升语义变化识别/Improves semantic change recognition]
        B3 --> G2[抑制非语义变化/Suppresses non-semantic variations]
        B3 --> G3[达到SOTA性能/Achieves SOTA performance]
    ```

- **[arXiv251230] Agentic AI-Enhanced Semantic Communications: Foundations, Architecture, and Applications**
  - **tags:** [mlsys], [agent system], [semantic communications, agentic AI, joint source-channel coding, knowledge base, LLM/LVM agents]
  - **authors:** Haixiao Gao, Mengying Sun, Ruichen Zhang, Yanhan Wang, Xiaodong Xu, Nan Ma, Dusit Niyato, Ping Zhang
  - **institution:** Beijing University of Posts and Telecommunications, Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.23294
  - **contributions:** 1. Provides a comprehensive review of agentic AI-enhanced semantic communications, categorizing studies by agent types (embedded, LLM/LVM, RL). 2. Proposes a unified agentic AI-enhanced SemCom framework with a closed-loop architecture spanning application, semantic, and cloud-edge collaboration layers. 3. Introduces and validates a case study (AKB-JSCC) using agentic knowledge bases for joint source-channel coding, demonstrating improved reconstruction quality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c6cd44bc1697f7504257d222eee725293b69d3eb38f48ca78c0d8e06f828cc7_w640_q70.webp
  - **Simple LLM Summary:** This paper explores how agentic AI can enhance semantic communications for 6G networks. It proposes a unified framework and a specific method (AKB-JSCC) that uses LLM/LVM and RL agents to build knowledge bases for improved coding. Experimental results show the proposed method achieves higher information reconstruction quality under various channel conditions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Agentic AI-Enhanced Semantic Communications: Foundations, Architecture, and Applications"] --> Problem["核心问题/Problem: How to empower semantic communications with intelligent agent capabilities for 6G"]
        Root --> Method["主要方法/Method: Propose a unified agentic AI-enhanced SemCom framework and an AKB-JSCC case study using agentic knowledge bases"]
        Root --> Results["关键结果/Results: AKB-JSCC achieves higher information reconstruction quality under different channel conditions"]
    ```

- **[arXiv251230] CME-CAD: Heterogeneous Collaborative Multi-Expert Reinforcement Learning for CAD Code Generation**
  - **tags:** [ai], [reinforcement learning], [CAD code generation, multi-expert reinforcement learning, Chain-of-Thought, CADExpert benchmark, CADQuery]
  - **authors:** Ke Niu, Haiyang Yu, Zhuofan Chen, Zhengtao Yao, Weitao Jia, Xiaodong Ge, Jingqun Tang, Benlei Cui, Bin Li, Xiangyang Xue
  - **institution:** Fudan University, ByteDance Inc.
  - **link:** https://arxiv.org/pdf/2512.23333
  - **contributions:** 1. Proposes a novel Heterogeneous Collaborative Multi-Expert Reinforcement Learning (CME-CAD) paradigm for generating precise and editable CAD models., 2. Introduces a two-stage training process: Multi-Expert Fine-Tuning (MEFT) and Multi-Expert Reinforcement Learning (MERL)., 3. Presents CADExpert, an open-source benchmark with 17,299 instances including orthographic projections, CoT processes, CADQuery code, and 3D models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/854c145ea4394c54526f3cfa5f5b5e6528680bb17418bfc2756a03817bea2de5_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of automating the generation of high-precision, editable CAD models from sketches, which existing methods struggle with. It proposes a new training paradigm called CME-CAD, which uses a two-stage process of Multi-Expert Fine-Tuning and Reinforcement Learning to collaboratively improve model performance. The approach aims to generate accurate, constraint-compatible CAD code and is supported by a new open-source benchmark called CADExpert.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CME-CAD: CAD代码生成] --> B1
        A --> B2
        A --> B3
        B1[核心问题/Problem<br>现有方法生成模型不可编辑、不精确<br>依赖文本/图像输入，标注成本高]
        B2[主要方法/Method<br>异构协作多专家强化学习<br>两阶段训练: MEFT + MERL]
        B3[关键结果/Results<br>生成精确、可编辑的CAD模型<br>发布CADExpert基准数据集]
    ```

- **[arXiv251230] AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis**
  - **tags:** [nlp], [text-to-sql], [Reinforcement Learning, Data Synthesis, Policy Optimization, Semantic-Logic Alignment, Group Relative Policy Optimization]
  - **authors:** Cehua Yang, Dongyu Xiao, Junming Lin, Yuyang Song, Hanxu Yan, Shawn Guo, Wei Zhang, Jian Yang, Mingjie Tang, Bryan Dai
  - **institution:** Sichuan University, IQuest Research, Beihang University
  - **link:** https://arxiv.org/pdf/2512.23366
  - **contributions:** 1. Proposes an iterative data factory for synthesizing high-quality, RL-ready Text-to-SQL data with strict semantic-logic verification. 2. Introduces a novel Agentic Reinforcement Learning framework featuring a Diversity-Aware Cold Start stage and Group Relative Policy Optimization (GRPO). 3. Demonstrates state-of-the-art performance on the BIRD and Spider benchmarks through the synergistic combination of data-centric and model-centric approaches.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6740c1fc529b82b509bd38c2a7b5fb405b969bc5c3e11e6e0b7690e7fa791c85_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenges of data scarcity and limited reasoning in Text-to-SQL systems. It proposes a holistic framework that combines a data-centric approach for synthesizing high-fidelity training data with a model-centric approach using a novel Agentic Reinforcement Learning method called Group Relative Policy Optimization. The method achieves state-of-the-art results on major benchmarks, showing the effectiveness of the synergistic approach.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AGRO-SQL] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[数据稀缺与质量/Data Scarcity & Quality]
        B --> B2[模型推理限制/Model Reasoning Limitations]
        C --> C1[数据中心方法/Data-Centric Approach]
        C --> C2[模型中心方法/Model-Centric Approach]
        C1 --> C1a[迭代数据工厂/Iterative Data Factory]
        C1 --> C1b[语义逻辑对齐/Semantic-Logic Alignment]
        C2 --> C2a[多样性感知冷启动/Diversity-Aware Cold Start]
        C2 --> C2b[组相对策略优化/Group Relative Policy Optimization]
        D --> D1[在BIRD和Spider上SOTA/SOTA on BIRD & Spider]
    ```

- **[arXiv251230] The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis**
  - **tags:** [ai], [continual learning], [big world hypothesis, computationally-embedded agent, interactivity, partially observable Markov decision process, model-based reinforcement learning]
  - **authors:** Alex Lewandowski, Adtiya A. Ramesh, Edan Meyer, Dale Schuurmans, Marlos C. Machado
  - **institution:** University of Alberta, Amii, The Swiss AI Lab IDSIA, USI & SUPSI, Canada CIFAR AI Chair, Google DeepMind
  - **link:** https://arxiv.org/pdf/2512.23419
  - **contributions:** 1. Introduced a computationally-embedded perspective, representing an agent as an automaton simulated within a universal computer, proving it's equivalent to interacting with a POMDP over an infinite state-space. 2. Proposed a new objective called "interactivity" to measure an agent's ability to continually adapt its behavior by learning new predictions. 3. Developed a model-based RL algorithm for interactivity-seeking and constructed a synthetic problem to evaluate continual learning, finding deep linear networks outperform nonlinear ones in sustaining interactivity as capacity scales.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1eff9d76987d2bc49a07c8de307183661687471b7fe4f21ca75040ba3e1de25a_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a computationally-embedded perspective to formalize the "big world hypothesis" in continual learning, where an agent is modeled as an automaton within the environment. It introduces "interactivity" as a new objective and a corresponding model-based RL algorithm to seek it. The main finding is that, in their synthetic evaluation, deep linear networks sustain higher interactivity as capacity increases, whereas deep nonlinear networks struggle.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis<br>论文标题"]
        Root --> Problem["核心问题/Problem<br>如何形式化智能体在'大世界'中的持续学习约束"]
        Root --> Method["主要方法/Method<br>提出计算嵌入视角与'交互性'目标，开发基于模型的强化学习算法"]
        Root --> Results["关键结果/Results<br>深度线性网络比非线性网络更能维持交互性"]
    ```

- **[arXiv251230] Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following**
  - **tags:** [ai], [reinforcement learning], [instruction following, hindsight replay, sample-efficient RL]
  - **authors:** Kongcheng Zhang, Qi Yao, Shunyu Liu, Wenjian Zhang, Min Cen, Yang Zhou, Wenkai Fang, Yiru Zhao, Baisheng Lai, Mingli Song
  - **institution:** Zhejiang University, Cainiao Network, Nanyang Technological University, Dalian University of Technology, University of Science and Technology of China, Alibaba Cloud Computing, Chinese Academy of Sciences
  - **link:** https://arxiv.org/pdf/2512.23457
  - **code:** https://github.com/zhangkc97/HiR
  - **contributions:** 1. Proposes Hindsight instruction Replay (HiR), a novel RL framework that replays failed attempts as successes using a select-then-rewrite strategy to address sparse rewards. 2. Theoretically frames the RL objective as dual-preference learning at both instruction- and response-level, enabling efficient optimization with only binary rewards. 3. Demonstrates sample efficiency and promising results across various instruction following tasks with reduced computational budget.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of sparse rewards in RL for aligning LLMs to follow complex instructions. It proposes HiR, a sample-efficient framework that replays failed responses as successful ones based on partially satisfied constraints, framed as dual-preference learning. Experiments show HiR achieves strong performance on instruction-following tasks while being more computationally efficient.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Replay Failures as Successes: Sample-Efficient RL for Instruction Following] --> Problem
        Root --> Method
        Root --> Results
        Problem[稀疏/不可区分的奖励阻碍学习<br>Sparse/Indistinguishable Rewards Impede Learning]
        Method[后见指令重放 (HiR)<br>Hindsight instruction Replay (HiR)]
        Results[跨任务有效且计算高效<br>Effective Across Tasks & Computationally Efficient]
    ```

- **[arXiv251230] HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation**
  - **tags:** [cv], [motion generation], [flow matching, diffusion transformer (DiT), reinforcement learning from human feedback (RLHF)]
  - **authors:** Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao
  - **institution:** Tencent Hunyuan
  - **link:** https://arxiv.org/pdf/2512.23464
  - **code:** https://github.com/Tencent-Hunyuan/HY-Motion-1.0
  - **contributions:** 1. The first successful scaling of DiT-based flow matching models to billion parameters for motion generation. 2. A comprehensive full-stage training paradigm including large-scale pretraining, fine-tuning, and RLHF. 3. A meticulous data processing pipeline enabling extensive coverage of over 200 motion categories.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces HY-Motion 1.0, a large-scale model for generating 3D human motions from text. It scales up Diffusion Transformer-based flow matching and uses a full-stage training pipeline with pretraining, fine-tuning, and RLHF. The model achieves state-of-the-art performance and broad motion coverage, and is released open-source.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"]
        Root --> Problem["核心问题/Problem: Generating high-quality, text-aligned 3D human motions"]
        Root --> Method["主要方法/Method: Scale DiT-based flow matching, Full-stage training (pretrain, fine-tune, RLHF), Meticulous data pipeline"]
        Root --> Results["关键结果/Results: SOTA performance, Extensive motion coverage, Open-source release"]
    ```

- **[arXiv251230] Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance**
  - **tags:** [ai], [reinforcement learning from human feedback (RLHF)], [reward model, inductive bias, information bottleneck, mutual information, reward hacking]
  - **authors:** Zhuo Li, Pengyu Cheng, Zhechao Yu, Feifei Tong, Anningzhe Gao, Tsung-Hui Chang, Xiang Wan, Erchao Zhao, Xiaoxi Jiang, Guanjun Jiang
  - **institution:** Alibaba, The Chinese University of Hong Kong, Shenzhen Research Institute of Big Data
  - **link:** https://arxiv.org/pdf/2512.23461
  - **code:** https://github.com/Qwen-Applications/DIR
  - **contributions:** 1. Proposes DIR, a novel information-theoretic debiasing method for reward models that maximizes mutual information with human preference while minimizing it with biased attributes. 2. Theoretically justifies the method's ability to handle complex, non-linear inductive biases, extending beyond simple linear correlation models. 3. Empirically demonstrates DIR's effectiveness in mitigating three types of biases (length, sycophancy, format) and shows it enhances RLHF performance and generalization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/522f5bbb5a5776cd8df024fb1b24faf19bb1a1ea6e0408c7951f37bfd1657846_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of inductive biases in reward models (RMs) for RLHF, which can lead to overfitting and reward hacking. It proposes DIR, an information-theoretic debiasing method inspired by the information bottleneck that optimizes mutual information to reduce bias. Experiments show DIR effectively mitigates multiple biases and improves RLHF performance and generalization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Eliminating Inductive Bias in Reward Models<br>消除奖励模型中的归纳偏差] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Low-quality RM data with inductive biases<br>导致过拟合和奖励攻击] --> B1[举例/Example<br>Response length bias<br>响应长度偏差]
        C[主要方法/Method<br>DIR: Information-theoretic debiasing<br>基于信息瓶颈优化互信息] --> C1[目标/Objective<br>Max MI with preference, Min MI with bias<br>最大化偏好互信息，最小化偏差互信息]
        D[关键结果/Results<br>Mitigates multiple biases & enhances RLHF<br>减轻多种偏差并提升RLHF性能] --> D1[验证的偏差/Verified Biases<br>Length, Sycophancy, Format<br>长度、迎合性、格式]
    ```

- **[arXiv251230] Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation**
  - **tags:** [sec], [software supply chain security], [agentic AI, reinforcement learning, large language model, blockchain security ledger, CI/CD]
  - **authors:** Toqeer Ali Syed, Mohammad Riyaz Belgaum, Salman Jan, Asadullah Abdullah Khan, Saad Said Alqahtani
  - **institution:** Islamic University of Madinah, Arab Open University-Bahrain
  - **link:** https://arxiv.org/pdf/2512.23480
  - **contributions:** 1. Proposes an autonomous, agentic AI framework for software supply chain security that integrates LLM-based reasoning, RL, and multi-agent coordination for proactive vulnerability identification and mitigation. 2. Implements a system that interfaces with real CI/CD environments (e.g., GitHub Actions, Jenkins) via the Model Context Protocol (MCP) and logs actions to a blockchain for auditability. 3. Demonstrates through experiments that the framework outperforms rule-based and provenance-only baselines in detection accuracy and mitigation latency with acceptable operational overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f037ac5977c7275a7c48edbcb676154bcff19330c107fe4c9769750efc5350_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of current software supply chain security frameworks (like SLSA) which focus on provenance but lack active vulnerability mitigation. It proposes an agentic AI system that combines LLMs for semantic analysis and RL for adaptive response, integrated with CI/CD pipelines via MCP and logged on a blockchain. Experiments show it achieves better detection and faster mitigation than baselines, enabling a shift from reactive to proactive defense.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Agentic AI for Autonomous Defense in Software Supply Chain Security] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统溯源框架无法主动缓解漏洞/Traditional provenance frameworks lack active vulnerability mitigation]
        C --> C1[多智能体协调/Multi-Agent Coordination]
        C --> C2[LLM推理与RL策略/LLM Reasoning & RL]
        C --> C3[集成CI/CD与区块链日志/CI/CD Integration & Blockchain Ledger]
        D --> D1[更高的检测准确率/Higher Detection Accuracy]
        D --> D2[更短的缓解延迟/Lower Mitigation Latency]
        D --> D3[合理的构建开销/Reasonable Build Overhead]
    ```

- **[arXiv251230] Hierarchical Decision Mamba Meets Agentic AI: A Novel Approach for RAN Slicing in 6G**
  - **tags:** [mlsys], [agent system], [Hierarchical Decision Mamba, Agentic AI, RAN Slicing, LLM, Self-healing]
  - **authors:** Md Arafat Habib, Medhat Elsayed, Majid Bavand, Pedro Enrique Iturria Rivera, Yigit Ozcan, Melike Erol-Kantarci
  - **institution:** University of Ottawa, Ericsson Inc.
  - **link:** https://arxiv.org/pdf/2512.23502
  - **contributions:** 1. Proposes the first Hierarchical Decision Mamba (HDM) architecture for Agentic AI-based network management, enabling low-latency control via state-space sequence modeling. 2. Introduces a self-corrective control mechanism for continuous adjustment of slice weights and priorities to ensure SLA compliance. 3. Presents a coordinated Agentic AI framework that jointly orchestrates inter-slice provisioning, intra-slice scheduling, and self-healing for adaptive RAN management, integrating a Hybrid RAG-based LLM for context-aware decision-making.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05a50b9e8619f08f976fca766d72a9c64a17b17a2ce198f899fb8e68a2fb9f94_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a novel Agentic AI framework for 6G RAN slicing, which uses a Large Language Model (LLM) to interpret operator intents and a Hierarchical Decision Mamba (HDM) controller to coordinate specialized agents for resource scheduling and self-healing. The method addresses the lack of natural language understanding and coordinated decision-making in existing approaches. The framework demonstrates improved performance over baselines in terms of throughput, cell-edge performance, and latency.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Hierarchical Decision Mamba Meets Agentic AI: A Novel Approach for RAN Slicing in 6G] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Existing RAN slicing methods lack natural language understanding and coordinated decision-making.]
        C[主要方法/Method: Agentic AI framework with LLM for intent interpretation and HDM for coordinating inter/intra-slice & self-healing agents.]
        D[关键结果/Results: Shows higher throughput, improved cell-edge performance, and reduced latency vs. baselines.]
    ```

- **[arXiv251230] PathFound: An Agentic Multimodal Model Activating Evidence-seeking Pathological Diagnosis**
  - **tags:** [cv], [computational pathology], [agentic multimodal model, evidence-seeking inference, reinforcement learning, whole-slide images, vision-language model]
  - **authors:** Shengyi Hua, Jianfeng Wu, Tianle Shen, Kangzhe Hu, Zhongzhen Huang, Shujuan Ni, Zhihong Zhang, Yuan Li, Zhe Wang, Xiaofan Zhang
  - **institution:** Shanghai Jiao Tong University, Fourth Military Medical University, University of Science and Technology of China, Fudan University, Nanjing Medical University
  - **link:** https://arxiv.org/pdf/2512.23545
  - **contributions:** 1. Proposed PathFound, an agentic multimodal model that introduces an evidence-seeking inference paradigm for pathological diagnosis, moving beyond static, single-pass analysis. 2. Integrated pathological visual foundation models, vision-language models, and reasoning models trained with reinforcement learning to enable proactive information acquisition and multi-stage diagnosis refinement. 3. Demonstrated that the evidence-seeking strategy consistently improves diagnostic accuracy across models and that PathFound achieves state-of-the-art performance, showing strong potential for discovering subtle pathological details.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db008475f544af0752cf146b5b6ba57eaf58c0e376cb94807dd3df594fa09037_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes PathFound, an agentic multimodal model that mimics clinical workflows by actively seeking evidence for ambiguous pathological diagnoses through multi-turn interactions. It integrates visual foundation models, vision-language models, and reinforcement learning-based reasoning to refine its initial diagnosis. The method achieves state-of-the-art diagnostic accuracy and demonstrates the effectiveness of evidence-seeking workflows in computational pathology.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[PathFound: Agentic Multimodal Model] --> B[核心问题/Problem: Static inference vs. clinical workflow]
        A --> C[主要方法/Method: Agentic model with VFM, VLM, RL]
        A --> D[关键结果/Results: SOTA accuracy, discovers subtle details]
        B --> B1[静态推理范式/Static inference paradigm]
        B --> B2[缺乏证据再获取/Lacks reassessment & evidence acquisition]
        C --> C1[多阶段诊断/Multi-stage diagnosis]
        C --> C2[主动信息获取/Proactive information acquisition]
        D --> D1[诊断准确性提升/Improved diagnostic accuracy]
        D --> D2[发现细微特征/Discover subtle pathological features]
    ```

- **[arXiv251230] ThinkGen: Generalized Thinking for Visual Generation**
  - **tags:** [cv], [text-to-image generation], [Chain-of-Thought (CoT), Multimodal Large Language Model (MLLM), Diffusion Transformer (DiT), reinforcement learning, SepGRPO]
  - **authors:** Siyu Jiao, Yiheng Lin, Yujie Zhong, Qi She, Wei Zhou, Xiaohan Lan, Zilong Huang, Fei Yu, Yingchen Yu, Yunqing Zhao, Yao Zhao, Yunchao Wei
  - **institution:** Beijing Jiaotong University, Bytedance
  - **link:** https://arxiv.org/pdf/2512.23568
  - **code:** https://github.com/jiaosiyuu/ThinkGen
  - **contributions:** 1. Proposes ThinkGen, the first think-driven visual generation framework that explicitly leverages MLLM's CoT reasoning for various generation tasks. 2. Introduces a decoupled architecture using a pretrained MLLM to generate instructions and a DiT for image synthesis. 3. Proposes a separable GRPO-based training paradigm (SepGRPO) for alternating reinforcement learning between modules, enabling joint training across diverse datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f8377ac1537eac2a0f36b9ae8883a51e957cbbeb6e49b280cc20b5c5080e11f_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces ThinkGen, a framework that integrates Chain-of-Thought reasoning from Multimodal LLMs with a Diffusion Transformer for visual generation. It uses a decoupled architecture and a novel separable reinforcement learning training method to generalize across diverse generation scenarios. Experiments show it achieves state-of-the-art performance on multiple benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ThinkGen: Generalized Thinking for Visual Generation] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[CoT推理在生成任务中应用有限/CoT for generation is nascent and scenario-specific]
        C --> C1[解耦架构: MLLM + DiT/Decoupled architecture: MLLM + DiT]
        C --> C2[可分离GRPO训练范式/SepGRPO training paradigm]
        D --> D1[在多个基准上实现SOTA/Achieves SOTA across multiple benchmarks]
    ```

- **[arXiv251230] ProGuard: Towards Proactive Multimodal Safeguard**
  - **tags:** [ai], [multimodal safety], [proactive guard, out-of-distribution (OOD) detection, reinforcement learning (RL), multimodal safety taxonomy, synonym-bank reward]
  - **authors:** Shaohan Yu, Lijun Li, Chenyang Si, Lu Sheng, Jing Shao
  - **institution:** Shanghai Artificial Intelligence Laboratory, Nanjing University, Beihang University
  - **link:** https://arxiv.org/pdf/2512.23573
  - **code:** https://yushaohan.github.io/ProGuard
  - **contributions:** 1. Introduces ProGuard, a vision-language proactive guard model that identifies and describes out-of-distribution safety risks without requiring model adjustments. 2. Constructs a modality-balanced dataset of 87K samples with binary safety labels and hierarchical risk categories to mitigate modality bias. 3. Trains the model purely via reinforcement learning augmented with a synonym-bank-based similarity reward to enhance OOD risk inference and description.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ffca72668094b2c8095387a83d8b49cc465da7d2f333cac7db429f76193be61_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes ProGuard, a proactive multimodal safeguard that uses reinforcement learning on a balanced dataset to detect and describe unseen safety risks. It achieves performance comparable to closed-source models on safety classification and significantly improves OOD risk detection and description by over 50%.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ProGuard: Towards Proactive Multimodal Safeguard] --> B[核心问题/Problem: 生成模型快速发展带来持续的多模态安全风险，现有防御方法存在局限。]
        A --> C[主要方法/Method: 提出ProGuard，基于强化学习训练视觉语言基础模型，引入OOD类别推断任务和同义词库奖励。]
        A --> D[关键结果/Results: 在二元安全分类上媲美闭源大模型，OOD风险检测提升52.6%，描述提升64.8%。]
    ```

- **[arXiv251230] Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning**
  - **tags:** [ai], [transfer learning], [Le Cam Distortion, Deficiency Distance, Directional Simulability, Unsupervised Domain Adaptation, Negative Transfer]
  - **authors:** Deniz Akdemir
  - **institution:** None (Institution not specified in provided content)
  - **link:** https://arxiv.org/pdf/2512.23617
  - **contributions:** 1. Proposes a decision-theoretic framework for robust transfer learning based on Le Cam's theory, replacing symmetric invariance with directional simulability. 2. Introduces Le Cam Distortion, quantified by the Deficiency Distance, as a rigorous upper bound for transfer risk. 3. Demonstrates the framework's effectiveness across diverse experiments (genomics, vision, RL), showing it prevents source degradation and catastrophic negative transfer where traditional methods fail.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bd736028263c7eaaaaecae78f0df59f633374608f59295b1185c8385eea1e5_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a flaw in standard Unsupervised Domain Adaptation, which can cause harmful "negative transfer" by forcing invariance between unequally informative domains. It proposes a new framework based on Le Cam's theory, using directional simulability and a metric called Le Cam Distortion to enable safe transfer without degrading the source domain. Experiments show this method successfully prevents information loss and catastrophic failure in safety-critical applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[标准UDA的缺陷/Flaw of Standard UDA]
        Problem --> P2[负迁移与信息破坏/Negative Transfer & Information Destruction]
        Method --> M1[Le Cam理论/Le Cam's Theory]
        Method --> M2[方向可模拟性/Directional Simulability]
        Method --> M3[Le Cam Distortion度量/Le Cam Distortion Metric]
        Results --> R1[基因组学完美估计/Perfect Genomics Estimation]
        Results --> R2[零源域损失/Zero Source Utility Loss]
        Results --> R3[安全RL策略转移/Safe RL Policy Transfer]
    ```

- **[arXiv251230] Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation**
  - **tags:** [ai], [reinforcement learning], [Process Reward Model, Policy-Invariant Reward Shaping, Multi-Perspective Reward Fusion]
  - **authors:** Huajie Tan, Sixiang Chen, Yijie Xu, Zixiao Wang, Yuheng Ji, Cheng Chi, Yaoxu Lyu, Zhongxia Zhao, Xiansheng Chen, Peterson Co, Shaoxuan Xie, Guocai Yao, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang
  - **institution:** Peking University, Beijing Academy of Artificial Intelligence
  - **link:** https://arxiv.org/pdf/2512.23703
  - **code:** https://robo-dopamine.github.io
  - **contributions:** 1. Introduces Dopamine-Reward, a method for learning a step-aware, general-purpose process reward model (GRM) from multi-view inputs to overcome perceptual limitations. 2. Proposes a theoretically-sound Policy-Invariant Reward Shaping method within the Dopamine-RL framework to enable efficient policy learning without altering the optimal policy. 3. Demonstrates high efficiency and generalization, where a one-shot adapted GRM enables policy learning to achieve 95% success with only 150 online rollouts.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbdde8d7dea23f224b530580752926db8c72c9f5768172278573c890a3c6b0c6_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of designing effective reward functions for real-world robotic RL by introducing Robo-Dopamine. It proposes a general, step-aware reward model trained on a large dataset and a robust policy learning framework with theoretically-sound reward shaping. Experiments show the approach achieves state-of-the-art reward accuracy and significantly improves policy learning efficiency with strong generalization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation] --> B
        A --> C
        A --> D
        B[核心问题/Problem: RL reward design is hard; existing PRMs lack step-awareness & use single-view, reward shaping is unsound]
        C[主要方法/Method: Dopamine-Reward (GRM with Step-wise Discretization & Multi-Perspective Fusion) & Dopamine-RL (Policy-Invariant Reward Shaping)]
        D[关键结果/Results: SOTA reward accuracy; High policy learning efficiency (95% success with 150 rollouts); Strong generalization]
    ```

- **[arXiv251230] Training AI Co-Scientists Using Rubric Rewards**
  - **tags:** [ai], [reinforcement learning], [research plan generation, self-grading, rubric rewards]
  - **authors:** Shashwat Goel, Rishi Hazra, Dulhan Jayalath, Timon Willi, Parag Jain, William F. Shen, Ilias Leontiadis, Francesco Barbieri, Yoram Bachrach, Jonas Geiping, Chenxi Whitehouse
  - **institution:** Meta Superintelligence Labs, ELLIS Institute Tübingen, Max Planck Institute for Intelligent Systems, University of Oxford, University of Cambridge
  - **link:** https://arxiv.org/pdf/2512.23707
  - **contributions:** 1. A scalable method to automatically extract research goals and goal-specific grading rubrics from existing papers to build a training corpus. 2. A reinforcement learning framework with self-grading, where a frozen initial model acts as the grader using rubrics, enabling unsupervised improvement. 3. Demonstration of significant performance gains (12-22% relative improvement) and cross-domain generalization (e.g., to medical research) validated by human experts and frontier model juries.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of training language models to generate high-quality, constraint-following research plans. The proposed method uses reinforcement learning with self-grading, where rubrics automatically extracted from research papers provide reward signals. The approach shows significant improvements in plan quality and generalizes across domains like machine learning and medicine, validated by human expert preference.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Training AI Co-Scientists Using Rubric Rewards"] --> Problem["核心问题/Problem: LMs struggle to generate research plans that follow all constraints."]
        Root --> Method["主要方法/Method: RL with self-grading using automatically extracted rubrics."]
        Root --> Results["关键结果/Results: Human experts prefer finetuned model's plans; method generalizes across domains."]
    ```

- **[arXiv251230] Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [alpha screening, large language models, reinforcement learning, factor investing, economic reasoning]
  - **authors:** Zuoyou Jiang, Li Zhao, Rui Sun, Ruohan Sun, Zhongjian Li, Jing Li, Daxin Jiang, Zuo Bai, Cheng Hua
  - **institution:** Shanghai Jiao Tong University, StepFun, FinStep
  - **link:** https://arxiv.org/pdf/2512.23515
  - **code:** https://github.com/FinStep-AI/Alpha-R1
  - **contributions:** 1. Proposes Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. 2. Introduces a method for LLMs to reason over factor logic and real-time news to evaluate alpha relevance under changing market conditions. 3. Demonstrates that the model consistently outperforms benchmarks and shows improved robustness to alpha decay across multiple asset pools.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d921912985e0858276fe1088914641df9c33c30f5de309733b2244c86c21e75e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of alpha decay in non-stationary financial markets by proposing Alpha-R1, a reasoning model trained with reinforcement learning. It uses a large language model to process factor logic and news, selectively activating factors based on contextual economic relevance. Empirical results show it outperforms benchmark strategies and is more robust to signal decay.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning] --> B[核心问题/Problem: Signal decay and regime shifts in non-stationary markets; existing methods overlook semantic rationale for factor relevance.]
        A --> C[主要方法/Method: Alpha-R1, an 8B-parameter LLM trained via RL, reasons over factor logic and real-time news for context-aware alpha screening.]
        A --> D[关键结果/Results: Outperforms benchmark strategies; exhibits improved robustness to alpha decay across multiple asset pools.]
    ```


**cs.AI/cs.LG contains "accelerate" total: 30**
- **[arXiv251230] An Energy-Efficient RFET-Based Stochastic Computing Neural Network Accelerator**
  - **tags:** [mlsys], [on-device ai], [RFET, stochastic computing, SCNN, stochastic number generator, accelerator]
  - **authors:** Sheng Lu, Qianhou Qu, Sungyong Jung, Qilian Liang, Chenyun Pan
  - **institution:** University of Texas at Arlington (inferred from IEEE affiliation and author "Qilian Liang, Fellow, IEEE" known association)
  - **link:** https://arxiv.org/pdf/2512.22131
  - **contributions:** 1. Proposes a novel SCNN architecture leveraging Reconfigurable Field-Effect Transistors (RFETs) for device-level reconfigurability. 2. Designs highly efficient and compact core modules (e.g., SNGs, APCs) enabled by RFET technology. 3. Develops and evaluates a dedicated RFET-based SCNN accelerator, showing significant improvements in area, latency, and energy over a FinFET baseline.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d718d7962f59eda2ed3430de0579c28b976cb6dd1e7da5e6fb355787c2b15ee_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high resource consumption of Stochastic Computing Neural Networks (SCNNs) by proposing a novel accelerator architecture based on Reconfigurable Field-Effect Transistors (RFETs). The inherent reconfigurability of RFETs enables the design of compact and efficient core components like stochastic number generators. Experimental results demonstrate that the proposed RFET-based accelerator achieves substantial reductions in area, latency, and energy consumption compared to a FinFET-based design at the same technology node.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[An Energy-Efficient RFET-Based Stochastic Computing Neural Network Accelerator] --> B
        A --> C
        A --> D
        B[核心问题/Problem: SCNN资源消耗高/High SCNN Resource Usage]
        C[主要方法/Method: 基于RFET的架构/RFET-Based Architecture]
        D[关键结果/Results: 面积、延迟、能耗降低/Reduced Area, Latency, Energy]
    ```

- **[arXiv251230] HookMIL: Revisiting Context Modeling in Multiple Instance Learning for Computational Pathology**
  - **tags:** [cv], [computational pathology], [Multiple Instance Learning, Hook Tokens, Linear Complexity, Multimodal Initialization, Hook Diversity Loss]
  - **authors:** Xitong Ling, Minxi Ouyang, Xiaoxiao Li, Jiawen Li, Ying Chen, Yuxuan Sun, Xinrui Chen, Tian Guan, Xiaoping Liu, Yonghong He
  - **institution:** Tsinghua University, Xiamen University, Westlake University, Wuhan University
  - **link:** https://arxiv.org/pdf/2512.22188
  - **code:** https://github.com/lingxitong/HookMIL
  - **contributions:** 1. Proposes HookMIL, a context-aware MIL framework using learnable hook tokens for structured contextual aggregation with linear computational complexity. 2. Introduces a multimodal initialization strategy for hook tokens using visual, textual, and spatial priors to accelerate convergence and improve representation. 3. Presents a Hook Diversity Loss and a hook-to-hook communication mechanism to encourage token specialization and refine interactions while minimizing redundancy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/125d35cff1b2c94d5e736ab81d897743e3d0b37d50d5ba6ce441aa77f8bc620e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the loss of context in traditional MIL and the high computational cost of transformer-based MIL for whole-slide image analysis. It proposes HookMIL, a framework that uses learnable hook tokens for efficient, linear-complexity context modeling, enhanced by multimodal initialization and specialized loss functions. Experiments on four public datasets show that HookMIL achieves state-of-the-art performance with improved efficiency and interpretability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[HookMIL: Revisiting Context Modeling in MIL for Computational Pathology] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: MIL loses context; Transformers are inefficient] --> P1[传统MIL丢失上下文/Traditional MIL loses context]
        Problem --> P2[基于Transformer的MIL计算复杂/Transformer-based MIL has quadratic complexity]
        Method[主要方法/Method: HookMIL Framework] --> M1[使用可学习的Hook Tokens/Use learnable Hook Tokens]
        Method --> M2[多模态初始化/Multimodal Initialization]
        Method --> M3[Hook多样性损失与通信机制/Hook Diversity Loss & Communication]
        Results[关键结果/Results] --> R1[SOTA性能/State-of-the-art Performance]
        Results --> R2[计算高效/Computationally Efficient]
        Results --> R3[可解释性/Interpretability]
    ```

- **[arXiv251230] DiRL: An Efficient Post-Training Framework for Diffusion Language Models**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [Diffusion Language Models, FlexAttention, Group Relative Policy Optimization, LMDeploy, blockwise training]
  - **authors:** Ying Zhu, Jiaxin Wan, Xiaoran Liu, Siyanag He, Qiqi Wang, Xu Guo, Tianyi Liang, Zengfeng Huang, Ziwei He, Xipeng Qiu
  - **institution:** Fudan University, Shanghai Innovation Institute, OpenMoss Team
  - **link:** https://arxiv.org/pdf/2512.22234
  - **code:** https://github.com/OpenMOSS/DiRL
  - **contributions:** 1. Proposes DiRL, an efficient post-training framework for Diffusion Language Models (dLLMs) that integrates FlexAttention-accelerated blockwise training with LMDeploy-optimized inference. 2. Introduces DiPO, the first unbiased Group Relative Policy Optimization (GRPO) implementation specifically designed for dLLMs. 3. Demonstrates state-of-the-art math reasoning performance for dLLMs by training DiRL-8B-Instruct, surpassing comparable models like Qwen2.5 series on benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the underdeveloped and inefficient post-training landscape for Diffusion Language Models (dLLMs). It proposes DiRL, an efficient framework combining accelerated training and optimized inference, and introduces DiPO, a tailored reinforcement learning method. The resulting model, DiRL-8B-Instruct, achieves state-of-the-art math performance among dLLMs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DiRL: An Efficient Post-Training Framework for Diffusion Language Models] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[dLLMs后训练低效/Post-training for dLLMs is inefficient]
        B --> B2[训练与推理目标不匹配/Training-Inference objective mismatch]
        C --> C1[DiRL框架/DiRL Framework]
        C1 --> C1_1[整合FlexAttention与LMDeploy/Integrates FlexAttention & LMDeploy]
        C1 --> C1_2[两阶段后训练/Two-stage post-training (SFT+RL)]
        C --> C2[DiPO算法/DiPO Algorithm]
        C2 --> C2_1[无偏GRPO实现/Unbiased GRPO for dLLMs]
        D --> D1[高效训练与推理/Efficient Training & Inference]
        D --> D2[数学SOTA性能/Math SOTA Performance]
        D --> D3[超越Qwen2.5系列/Surpasses Qwen2.5 series]
    ```

- **[arXiv251230] Graph Attention-based Adaptive Transfer Learning for Link Prediction**
  - **tags:** [ai], [graph neural networks], [graph attention network, link prediction, transfer learning, graph transformer, contrastive loss]
  - **authors:** Huashen Lu, Wensheng Gan, Guoting Chen, Zhichao Huang, Philip S. Yu
  - **institution:** Jinan University, Great Bay University, JD Technology, University of Illinois Chicago
  - **link:** https://arxiv.org/pdf/2512.22252
  - **code:** https://github.com/DSI-Lab1/GAATNet
  - **contributions:** 1. Proposes GAATNet, a novel graph attention adaptive transfer network combining pre-training and fine-tuning for cross-dataset knowledge transfer in link prediction. 2. Incorporates distant neighbor embeddings as biases in self-attention to capture global node features. 3. Introduces a lightweight self-adapter module during fine-tuning to improve training efficiency and generalization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e9ea1091686509af1da226ce7553577b4005c5646524a5c6718473e451d3c39_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses challenges in link prediction on large-scale sparse graphs and cross-dataset transfer learning by proposing GAATNet, which integrates graph attention with adaptive transfer strategies. The method uses distant neighbor embeddings and a self-adapter module to enhance global feature capture and training efficiency. Experiments on seven datasets show state-of-the-art performance, offering a scalable solution for integrating GNNs with transfer learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Graph Attention-based Adaptive Transfer Learning for Link Prediction] --> B[核心问题/Problem: Challenges in large-scale sparse graphs and cross-dataset transfer learning for link prediction]
        A --> C[主要方法/Method: Proposes GAATNet with distant neighbor embeddings and lightweight self-adapter for adaptive transfer]
        A --> D[关键结果/Results: Achieves SOTA performance on seven datasets, provides scalable GNN-transfer learning solution]
    ```

- **[arXiv251230] LuxIA: A Lightweight Unitary matriX-based Framework Built on an Iterative Algorithm for Photonic Neural Network Training**
  - **tags:** [mlsys], [on-device ai], [photonic neural networks, transfer matrix, Slicing method, back-propagation, simulation framework]
  - **authors:** Tzamn Melendez Carmona, Federico Marchesin, Marco P. Abrate, Peter Bienstman, Stefano Di Carlo, Alessandro Savino Senior
  - **institution:** Politecnico di Torino, Ghent University - imec, University College London
  - **link:** https://arxiv.org/pdf/2512.22264
  - **contributions:** 1. Proposes the Slicing method, an efficient transfer matrix computation approach compatible with back-propagation for training Photonic Neural Networks (PNNs). 2. Introduces LuxIA, a unified simulation and training framework that integrates the Slicing method to enable scalable PNN training. 3. Demonstrates through experiments that LuxIA surpasses existing tools in speed and scalability for training large-scale PNNs on standard datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/362a4190a58349fa96aae555a8a4643a7fdd50b962ff88817d9c12e4678fbe98_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the scalability challenges in simulating and training large-scale Photonic Neural Networks (PNNs) by introducing the Slicing method for efficient transfer matrix computation. The method is integrated into the LuxIA framework, which significantly reduces memory usage and training time. Experimental results show LuxIA outperforms existing tools, enabling the exploration of larger and more complex photonic architectures.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LuxIA: A Lightweight Unitary matriX-based Framework] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[当前PNN仿真工具可扩展性差<br>Current PNN simulation tools lack scalability]
        C --> C1[提出Slicing方法<br>Propose the Slicing method]
        C --> C2[构建LuxIA统一框架<br>Build the unified LuxIA framework]
        D --> D1[显著降低内存与时间消耗<br>Significantly reduces memory and time consumption]
        D --> D2[在速度与可扩展性上超越现有工具<br>Outperforms existing tools in speed and scalability]
    ```

- **[arXiv251230] DBAW-PIKAN: Dynamic Balance Adaptive Weight Kolmogorov-Arnold Neural Network for Solving Partial Differential Equations**
  - **tags:** [ai], [scientific machine learning], [Physics-informed neural networks, Kolmogorov-Arnold networks, Adaptive weighting, B-splines, Partial differential equations]
  - **authors:** Guokan Chen, Yao Xiao
  - **institution:** Fujian University of Technology
  - **link:** https://arxiv.org/pdf/2512.22283
  - **contributions:** 1. Proposes DBAW-PIKAN, a novel architecture combining a Kolmogorov-Arnold Network (KAN) with learnable B-splines for enhanced function representation in solving PDEs., 2. Introduces an adaptive weighting strategy with a dynamic decay upper bound to mitigate gradient flow stiffness and spectral bias, addressing key failure modes of PINNs., 3. Demonstrates significant improvements in convergence speed and solution accuracy (at least an order of magnitude) on benchmarks like Klein-Gordon, Burgers, and Helmholtz equations without added computational cost.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb9e65232c0c340c6072237e2ad1388255462aafca80cf91d4b7f3054eb9fe8c_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes DBAW-PIKAN, a novel neural network that integrates a Kolmogorov-Arnold architecture with an adaptive weighting strategy to overcome the stiffness and spectral bias challenges faced by Physics-Informed Neural Networks (PINNs) when solving multi-scale PDEs. The method accelerates convergence and improves solution accuracy by at least an order of magnitude on standard benchmarks without increasing computational complexity.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[DBAW-PIKAN: Dynamic Balance Adaptive Weight Kolmogorov-Arnold Neural Network for Solving Partial Differential Equations] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[PINNs struggle with multi-scale/high-frequency PDEs / PINNs在处理多尺度/高频PDE时遇到困难]
        P1 --> P2[Issues: Gradient flow stiffness & spectral bias / 问题: 梯度流刚度和谱偏差]
        Method[主要方法/Method] --> M1[Architecture: Kolmogorov-Arnold Network (KAN) with learnable B-splines / 架构: 基于可学习B样条的KAN]
        Method --> M2[Strategy: Adaptive weighting with dynamic decay upper bound / 策略: 带动态衰减上界的自适应加权]
        Results[关键结果/Results] --> R1[Faster convergence & higher accuracy / 更快的收敛和更高的精度]
        R1 --> R2[Improvement: At least one order of magnitude / 提升: 至少一个数量级]
        Results --> R3[Benchmarks: Klein-Gordon, Burgers, Helmholtz equations / 基准: Klein-Gordon, Burgers, Helmholtz方程]
    ```

- **[arXiv251230] LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators**
  - **tags:** [sec], [hardware security, model protection], [logic locking, intellectual property protection, hardware accelerator, model theft, supply chain security]
  - **authors:** You Li, Guannan Zhao, Yuhao Ju, Yunqi He, Jie Gu, Hai Zhou
  - **institution:** Northwestern University
  - **link:** https://arxiv.org/pdf/2512.22307
  - **contributions:** 1. Proposes LLA, a hardware-software co-design scheme for protecting generative AI models by embedding key bits into neurons and using invariance transformations to obscure them. 2. Integrates a lightweight, dataflow-compatible locking module into the AI accelerator, using the accelerator with a secret key as a license for model access. 3. Demonstrates that the approach is resilient against oracle-guided key optimization attacks while adding minimal computational overhead (&lt;0.1% for 7,168 key bits).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces LLA, a method to protect generative AI models from supply chain threats like theft and corruption by combining software-based key embedding in neurons with a hardware locking module in the accelerator. This approach uses the accelerator as a license key, ensuring only authorized hardware can run the model correctly. Evaluation shows it effectively resists attacks with negligible performance overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators] --> Problem(核心问题/Problem: Model IP Protection & Supply Chain Threats)
        Root --> Method(主要方法/Method: Hardware-Software Co-design with Logic Locking)
        Root --> Results(关键结果/Results: Resists Attacks, <0.1% Overhead)
        Problem --> P1(模型盗窃/Model Theft)
        Problem --> P2(模型破坏/Model Corruption)
        Problem --> P3(信息泄露/Information Leakage)
        Method --> M1(软件侧: 神经元嵌入密钥/Software: Key Embedding in Neurons)
        Method --> M2(硬件侧: 轻量级锁定模块/Hardware: Lightweight Locking Module)
        Results --> R1(抵御优化攻击/Withstands Oracle-Guided Attacks)
        Results --> R2(低计算开销/Low Computational Overhead)
    ```

- **[arXiv251230] AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents**
  - **tags:** [mlsys], [agent system], [reproducibility, dependency management, code generation, large language models, empirical study]
  - **authors:** Bhanu Prakash Vangala, Ali Adibifar, Tanu Malik, Ashish Gehani
  - **institution:** University of Missouri, SRI International
  - **link:** https://arxiv.org/pdf/2512.22387
  - **contributions:** 1. Introduces a three-layer dependency framework (claimed, working, runtime) to quantify the execution reproducibility of LLM-generated code. 2. Conducts an empirical study evaluating three state-of-the-art LLM coding agents across 300 projects in three programming languages, revealing low out-of-the-box execution success rates. 3. Discovers a significant hidden dependency problem, with an average 13.5x expansion from declared to actual runtime dependencies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the reproducibility of code generated by LLM-based coding agents. It proposes a three-layer dependency framework and conducts an empirical study on 300 projects, finding that only 68.3% execute successfully out-of-the-box and that actual runtime dependencies are significantly larger than declared ones. The study concludes that AI-generated code currently suffers from major reproducibility issues due to dependency gaps and code generation errors.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents"] --> Problem["核心问题/Problem: Is AI-generated code reproducible?"]
        Root --> Method["主要方法/Method: Empirical study using a three-layer dependency framework on 300 projects from 3 LLM agents."]
        Root --> Results["关键结果/Results: Low out-of-the-box execution rate (68.3%) and large hidden dependencies (13.5x expansion)."]
    ```

- **[arXiv251230] Quantum Generative Models for Computational Fluid Dynamics: A First Exploration of Latent Space Learning in Lattice Boltzmann Simulations**
  - **tags:** [mlsys], [others], [Quantum Generative Models, Computational Fluid Dynamics, Lattice Boltzmann Method, Vector Quantized Variational Autoencoder, Quantum Circuit Born Machine]
  - **authors:** Achraf Hsain, Fouad Mohammed Abbou
  - **institution:** Al Akhawayn University
  - **link:** https://arxiv.org/pdf/2512.22672
  - **contributions:** 1. A complete open-source pipeline bridging CFD simulation and quantum machine learning. 2. The first empirical study of quantum generative modeling on compressed latent representations of physics simulations. 3. A comparative analysis of quantum (QCBM, QGAN) and classical (LSTM) generative models for a physics-derived latent distribution.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6094a8215d7304400e5580e08cc0e81135106aaf9b51ef11b7f4c5d62734237e_w640_q70.webp
  - **Simple LLM Summary:** This paper explores the application of quantum generative models to Computational Fluid Dynamics (CFD) data. The authors compress fluid simulation data into a discrete latent space using a VQ-VAE and then compare quantum (QCBM, QGAN) and classical (LSTM) models for generating samples from this distribution. Under their experimental conditions, the quantum models, particularly the QCBM, outperformed the classical baseline in generating samples closer to the true distribution.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Quantum Generative Models for CFD: Latent Space Learning in LBM Simulations"] --> Problem["核心问题/Problem: Modeling compressed CFD latent distributions"]
        Root --> Method["主要方法/Method: VQ-VAE compression + QCBM/QGAN vs LSTM"]
        Root --> Results["关键结果/Results: Quantum models (QCBM best) outperformed classical LSTM"]
    ```

- **[arXiv251230] Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach**
  - **tags:** [ai], [differential games], [Hamilton-Jacobi reachability, reach-avoid games, dimensionality decomposition, UAVs, tracking control]
  - **authors:** Minh Bui, Simon Monckton, Mo Chen
  - **institution:** Simon Fraser University, Defense Research & Development Canada (DRDC)
  - **link:** https://arxiv.org/pdf/2512.22793
  - **contributions:** 1. A novel dimensionality reduction framework for 3D reach-avoid games by decomposing the problem into horizontal and vertical sub-games., 2. A Hamilton-Jacobi-based tracking control algorithm to reconstruct the solution from sub-games, guaranteeing capture and subsequent tracking of the attacker., 3. Theoretical proof of the conditions for maintaining capture guarantees and empirical validation in both numerical simulations and a physics simulator (Gazebo).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14da164894760eae683bf30139829cd77a6bbd67cf14fee19eb09a05cb31eff_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the high-dimensional challenge of 3D reach-avoid differential games for UAVs by proposing a decomposition approach that splits the problem into horizontal and vertical sub-games, solves them using Hamilton-Jacobi reachability analysis, and uses a novel tracking control to reconstruct the solution. The method is proven to maintain optimality and capture guarantees, and its effectiveness is successfully demonstrated through simulations and a physics simulator for quadrotor capture.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题: Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[3D追逃博弈高维挑战/High Dimensionality of 3D Reach-Avoid Games]
        B --> B2[现有方法局限性/Limitations of Existing Approaches]
        C --> C1[维度分解/Dimensionality Decomposition]
        C1 --> C1_1[水平子博弈/Horizontal Sub-game]
        C1 --> C1_2[垂直子博弈/Vertical Sub-game]
        C --> C2[HJ可达性分析/HJ Reachability Analysis]
        C --> C3[HJ跟踪控制/HJ-based Tracking Control]
        D --> D1[保持最优性与保证/Maintains Optimality & Guarantees]
        D --> D2[仿真验证/Simulation Validation]
        D --> D3[物理模拟器成功捕获/Successful Capture in Physics Simulator]
    ```

- **[arXiv251230] Parallel Diffusion Solver via Residual Dirichlet Policy Optimization**
  - **tags:** [mlsys], [diffusion models], [ODE solver, parallel gradient evaluation, reinforcement learning fine-tuning, low-latency sampling, Dirichlet policy]
  - **authors:** Ruoyu Wang, Ziyu Li, Beier Zhu, Liangyu Yuan, Hanwang Zhang, Xun Yang, Xiaojun Chang, Chi Zhang
  - **institution:** Westlake University, University of Illinois Urbana-Champaign, Nanyang Technological University, Shanghai Jiao Tong University, University of Science and Technology of China
  - **link:** https://arxiv.org/pdf/2512.22796
  - **contributions:** 1. Proposes EPD-Solver, a novel ODE solver that uses multiple parallel gradient evaluations per step to reduce truncation errors while maintaining low latency. 2. Introduces a two-stage optimization framework, including a parameter-efficient RL fine-tuning scheme that reformulates the solver as a stochastic Dirichlet policy to avoid reward hacking. 3. Demonstrates the method's flexibility as a plugin (EPD-Plugin) to enhance existing ODE samplers and shows state-of-the-art performance in both unconditional and text-to-image generation benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2678a61b07c4f5b5cfdd2006673a05c8a4699c07dee6180c47750600496f796_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high sampling latency of diffusion models by proposing EPD-Solver, a novel ODE solver that incorporates parallel gradient evaluations to reduce errors without increasing latency. The method uses a two-stage optimization, including RL fine-tuning with a Dirichlet policy, and can be used as a plugin. Experiments show it achieves superior image quality at low step counts and improves human preference scores in text-to-image generation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Parallel Diffusion Solver via Residual Dirichlet Policy Optimization] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[扩散模型采样延迟高 / High sampling latency of DMs]
        B --> B2[现有求解器在低步数下质量下降 / Existing solvers degrade quality at low NFEs]
        C --> C1[EPD-Solver: 集成并行方向求解器 / Ensemble Parallel Direction solver]
        C --> C2[两阶段优化: 蒸馏 + RL微调 / Two-stage optimization: Distillation + RL fine-tuning]
        C --> C3[作为插件提升现有求解器 / Plugin (EPD-Plugin) for existing samplers]
        D --> D1[低延迟下SOTA FID分数 / SOTA FID scores at low latency]
        D --> D2[在T2I任务中提升人类偏好分数 / Improved human preference scores in T2I]
    ```

- **[arXiv251230] TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [curriculum learning, goal-conditioned reinforcement learning, temporal variance, student-teacher paradigm, Q-function]
  - **authors:** Gaurav Chaudhary, Laxmidhar Behera
  - **institution:** IIT Kanpur
  - **link:** https://arxiv.org/pdf/2512.22824
  - **contributions:** 1. Proposes a novel Student-Teacher learning paradigm with a Temporal Variance-Driven Curriculum for accelerating Goal-Conditioned RL. 2. Establishes a theoretical connection between the temporal variance of Q-values and policy evolution. 3. Demonstrates the algorithm-agnostic nature of the approach, showing consistent improvements across 11 robotic manipulation and maze navigation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the sample inefficiency of uniform goal selection in multi-goal reinforcement learning. It proposes a TEACH framework where a teacher module dynamically selects goals with the highest temporal variance in Q-values to create an adaptive curriculum. The method is shown to improve learning efficiency over state-of-the-art curriculum learning methods across diverse robotic tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Uniform goal selection is sample inefficient in multi-goal RL/多目标RL中均匀目标选择样本效率低]
        C --> C1[Student-Teacher paradigm with Temporal Variance-Driven Curriculum/基于时序方差的师生课程学习范式]
        C --> C2[Teacher prioritizes goals with highest Q-value temporal variance/教师模块优先选择Q值时序方差最高的目标]
        D --> D1[Consistent improvements over SOTA methods/相比SOTA方法取得一致改进]
        D --> D2[Evaluated on 11 robotic manipulation and navigation tasks/在11个机器人操作与导航任务上验证]
    ```

- **[arXiv251230] PreGME: Prescribed Performance Control of Aerial Manipulators based on Variable-Gain ESO**
  - **tags:** [other], [robotics control], [aerial manipulator, prescribed performance control, variable-gain extended state observer, dynamic coupling, motion control]
  - **authors:** Mengyu Ji, Shiliang Guo, Zhengzhen Li, Jiahao Shen, Huazi Cao, Shiyu Zhao
  - **institution:** Zhejiang University, Westlake University
  - **link:** https://arxiv.org/pdf/2512.22957
  - **contributions:** 1. A novel prescribed performance motion control framework (PreGME) for aerial manipulators. 2. The use of variable-gain extended state observers (ESOs) for accurate real-time estimation of rapidly varying dynamic coupling. 3. A control strategy that generates a preset error trajectory to ensure tracking errors remain within a prescribed performance envelope for high-precision control.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f2803479d85cfb232ae59d1133082b1c37608a63bed7f68577a5675d15b2598_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes PreGME, a new control framework for aerial manipulators that combines variable-gain extended state observers to estimate dynamic coupling with prescribed performance control to constrain error trajectories. The method enables high-precision control even during aggressive arm motions. Experiments, including aerial mixology and cart-pulling, validate its effectiveness under significant dynamic disturbances.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["PreGME: Prescribed Performance Control of Aerial Manipulators"] --> Problem["核心问题/Problem: Aerial manipulator dynamic coupling affects control precision"]
        Root --> Method["主要方法/Method: Variable-gain ESO + Prescribed performance control"]
        Root --> Results["关键结果/Results: High tracking performance validated by real-world experiments"]
    ```

- **[arXiv251230] Embodied Robot Manipulation in the Era of Foundation Models: Planning and Learning Perspectives**
  - **tags:** [ai], [robotic manipulation], [robotic foundation models, high-level planning, low-level control, imitation learning, reinforcement learning]
  - **authors:** Shuanghao Bai, Wenxuan Song, Jiayi Chen, Yuheng Ji, Zhide Zhong, Jin Yang, Han Zhao, Wanqi Zhou, Zhe Li, Pengxiang Ding, Cheng Chi, Chang Xu, Xiaolong Zheng, Donglin Wang, Haoang Li, Shanghang Zhang, Badong Chen
  - **institution:** Xi'an Jiaotong University, Hong Kong University of Science and Technology (Guangzhou), Chinese Academy of Sciences, Westlake University, Zhejiang University, University of Sydney, BAAI, Peking University
  - **link:** https://arxiv.org/pdf/2512.22983
  - **code:** Awesome-Robotics-Manipulation
  - **contributions:** 1. Proposes a unified algorithmic abstraction for robot manipulation, organizing approaches into high-level planning and low-level control. 2. Extends classical task planning to include reasoning over language, code, motion, affordances, and 3D representations. 3. Introduces a training-paradigm-oriented taxonomy for learning-based control, categorizing methods by input modeling, latent representation learning, and policy learning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22135ed5ae9ef66789b2dbe7f9c4c6e6a9de91ca6dd4b2025e75cfd5d4a89d02_w640_q70.webp
  - **Simple LLM Summary:** This survey paper organizes recent learning-based approaches to robot manipulation within a unified framework of high-level planning and low-level control. It extends task planning to include multimodal reasoning and proposes a new taxonomy for learning-based control. The analysis aims to clarify the design space and identifies key challenges like scalability and safety for future robotic foundation models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Embodied Robot Manipulation in the Era of Foundation Models] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Robot manipulation remains a central and challenging problem / 机器人操作仍是一个核心挑战]
        C --> C1[Unified abstraction: High-level planning & Low-level control / 统一抽象：高层规划与底层控制]
        C1 --> C2[High-level: Reasoning over language, code, motion, etc. / 高层：基于语言、代码、运动等的推理]
        C1 --> C3[Low-level: Taxonomy for learning-based control / 底层：基于学习的控制分类法]
        D --> D1[Clarifies design space of foundation models / 阐明基础模型的设计空间]
        D --> D2[Identifies open challenges: scalability, safety, etc. / 指出开放挑战：可扩展性、安全性等]
    ```

- **[arXiv251230] TYTAN: Taylor-series based Non-Linear Activation Engine for Deep Learning Accelerators**
  - **tags:** [mlsys], [on-device ai], [activation function, hardware accelerator, taylor series, energy efficiency, edge inference]
  - **authors:** Soham Pramanik, Vimal William, Arnab Raha, Debayan Das, Amitava Mukherjee, Janet L. Paluh
  - **institution:** Jadavpur University, SandLogic Technologies, Intel Corporation, Indian Institute of Science, Amrita University, SUNY Polytechnic Institute
  - **link:** https://arxiv.org/pdf/2512.23062
  - **contributions:** 1. Proposes TYTAN, a Taylor-series based Generalized Non-linear Approximation Engine (G-NAE) for accelerating non-linear activation functions in deep learning. 2. Integrates a re-configurable hardware design with a specialized algorithm to dynamically estimate approximations, aiming for minimal accuracy deviation. 3. Demonstrates significant performance gains and efficiency improvements, including ~2x performance, ~56% power reduction, and ~35x lower area compared to a baseline NVDLA implementation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/233e926fc1401824c658e53f6ee69cc2fa91152f36cad6ff674b919cf9a3aa0e_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes TYTAN, a hardware-software co-designed engine that uses Taylor series approximations to accelerate non-linear activation functions for energy-efficient AI inference at the edge. The system dynamically configures the approximation to maintain accuracy. Evaluations show it achieves high frequency operation (&gt;950 MHz) with substantial improvements in performance, power, and area compared to a standard accelerator.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[TYTAN: Taylor-series based Non-Linear Activation Engine] --> B[核心问题/Problem: Edge AI inference requires acceleration and energy efficiency, limited by high-power operations like activation functions.]
        A --> C[主要方法/Method: Proposes a Generalized Non-linear Approximation Engine (G-NAE) using Taylor series and re-configurable hardware with a dynamic approximation algorithm.]
        A --> D[关键结果/Results: >950 MHz operation, ~2x performance, ~56% power reduction, ~35x lower area vs. NVDLA baseline.]
    ```

- **[arXiv251230] SecureBank: A Financially-Aware Zero Trust Architecture for High-Assurance Banking Systems**
  - **tags:** [sec], [Zero Trust Architecture], [Zero Trust, Micro-Segmentation, Adaptive Identity, Security Automation, Financial Risk Modeling]
  - **authors:** Paulo Fernandes Biao
  - **institution:** Biaotech.dev
  - **link:** https://arxiv.org/pdf/2512.23124
  - **contributions:** 1. Proposes SecureBank, a financially-aware and context-adaptive Zero Trust architecture specifically for high-assurance banking systems. 2. Integrates novel components like Financial Zero Trust, Adaptive Identity Scoring, Contextual Micro-Segmentation, and Impact-Driven Security Automation. 3. Provides experimental validation through Monte Carlo simulation using new metrics (TII, ITAL, SAE), showing improved attack handling and trust adaptation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcead853a793849eb23351043665ca37b119208adc01fb0dece96fde5c56ad05_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces SecureBank, a Zero Trust architecture designed for banking systems that incorporates financial risk and context. It integrates components like adaptive identity scoring and impact-driven automation. Simulation results show it improves automated attack handling and identity trust adaptation while maintaining transactional integrity.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[SecureBank: A Financially-Aware Zero Trust Architecture] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[传统安全模型不足/Limitations of Traditional Security]
        Problem --> P2[现有零信任缺乏金融语义/Existing ZT Lacks Financial Awareness]
        Method[主要方法/Method] --> M1[金融零信任/Financial Zero Trust]
        Method --> M2[自适应身份评分/Adaptive Identity Scoring]
        Method --> M3[上下文微隔离/Contextual Micro-Segmentation]
        Method --> M4[影响驱动自动化/Impact-Driven Automation]
        Results[关键结果/Results] --> R1[提升攻击自动化处理/Improved Automated Attack Handling]
        Results --> R2[加速身份信任适应/Accelerated Identity Trust Adaptation]
        Results --> R3[保持交易完整性/Preserved Transactional Integrity]
    ```

- **[arXiv251230] SE-MLP Model for Predicting Prior Acceleration Features in Penetration Signals**
  - **tags:** [ai], [regression], [squeeze and excitation, channel attention, residual connections, multi-layer perceptron, penetration acceleration]
  - **authors:** Yankang Li, Changsheng Li
  - **institution:** Nanjing University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.23131
  - **contributions:** 1. Proposed SE-MLP, a novel MLP architecture integrating a channel attention mechanism for feature prediction. 2. Incorporated residual connections into the MLP framework to enhance model stability and performance. 3. Demonstrated the model's superior accuracy, generalization, and engineering applicability for rapidly predicting penetration acceleration features.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dab35d2c00d22564e8f3e36c067728bb8b4d1bb60f2ed675bfe34288c07503a_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes SE-MLP, a multi-layer perceptron model enhanced with squeeze-and-excitation channel attention and residual connections, to rapidly predict prior acceleration features for penetration signals. The model establishes a nonlinear mapping from physical parameters to acceleration features, outperforming baseline models like MLP, XGBoost, and Transformer in accuracy and stability. The results validate its feasibility and provide a practical basis for engineering applications in penetration fuse design.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SE-MLP Model for Predicting Prior Acceleration Features in Penetration Signals] --> B[核心问题/Problem: 侵彻加速度先验特征获取耗时耗力/Prior acceleration features are expensive and time-consuming to obtain]
        A --> C[主要方法/Method: 提出SE-MLP模型，集成通道注意力与残差连接/Proposed SE-MLP integrating channel attention and residual connections]
        A --> D[关键结果/Results: 预测精度高，泛化性好，工程误差可接受/High prediction accuracy, good generalization, acceptable engineering error]
    ```

- **[arXiv251230] HELM-BERT: A Transformer for Medium-sized Peptide Property Prediction**
  - **tags:** [nlp], [molecular language modeling], [HELM notation, DeBERTa, cyclic peptide, membrane permeability, peptide-protein interaction]
  - **authors:** Seungeon Lee, Takuto Koyama, Itsuki Maeda, Shigeyuki Matsumoto, Yasushi Okuno
  - **institution:** Kyoto University
  - **link:** https://arxiv.org/pdf/2512.23175
  - **contributions:** 1. Proposes HELM-BERT, the first encoder-based peptide language model trained on HELM notation, designed to capture hierarchical dependencies. 2. Pre-trains the model on a curated corpus of 39,079 chemically diverse linear and cyclic peptides. 3. Demonstrates superior performance over SMILES-based models in downstream tasks like cyclic peptide membrane permeability and peptide-protein interaction prediction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83ec939e21fe471473f433077555782bca673e92ad1bfd3578b0fe729e20446_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces HELM-BERT, a transformer model based on DeBERTa and trained on HELM notation to better represent therapeutic peptides. It shows that this approach significantly outperforms existing SMILES-based models in predicting key peptide properties, demonstrating the data-efficiency advantages of topology-aware representations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HELM-BERT: A Transformer for Medium-sized Peptide Property Prediction] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有分子表示(如SMILES)无法有效捕捉肽的化学与拓扑复杂性/Existing molecular representations fail to capture peptide complexity]
        C --> C1[基于DeBERTa, 使用HELM符号训练首个编码器肽语言模型/Based on DeBERTa, first encoder peptide LM trained on HELM notation]
        C --> C2[在39,079个多样化肽的语料库上进行预训练/Pre-trained on a corpus of 39,079 diverse peptides]
        D --> D1[在膜渗透性和肽-蛋白相互作用预测上显著优于SMILES模型/Significantly outperforms SMILES models on permeability & interaction prediction]
        D --> D2[HELM表示提供数据效率优势/HELM representations offer data-efficiency advantages]
    ```

- **[arXiv251230] KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta**
  - **tags:** [mlsys], [gpu kernels], [agentic kernel coding, heterogeneous accelerators, retrieval-augmented prompt synthesis, graph-based search, Triton/CuTe DSL]
  - **authors:** Gang Liao, Hongsen Qin, Ying Wang, Alicia Golden, Michael Kuchnik, Yavuz Yetim, Jia Jiunn Ang, Chunli Fu, Yihan He, Samuel Hsia, Zewei Jiang, Dianshi Li, Uladzimir Pashkevich, Varna Puvvada, Feng Shi, Matt Steiner, Ruichao Xiao, Nathan Yan, Xiayu Yu, Zhou Fang, Abdul Zainul-Abedin, Ketan Singh, Hongtao Yu, Wenyuan Chi, Barney Huang, Sean Zhang, Noah Weller, Zach Marine, Wyatt Cook, Carole-Jean Wu, Gaoxiang Liu
  - **institution:** Meta Platforms
  - **link:** https://arxiv.org/pdf/2512.23236
  - **contributions:** 1. Proposes KernelEvolve, an agentic framework that automates kernel generation and optimization for DLRMs across heterogeneous hardware (NVIDIA/AMD GPUs, Meta accelerators) by operating at multiple programming abstractions. 2. Introduces a kernel optimization process modeled as a graph-based search with dynamic adaptation to runtime context via retrieval-augmented prompt synthesis and a persistent hardware knowledge base. 3. Demonstrates the system's effectiveness by achieving 100% correctness on benchmark suites and substantial performance speedups (up to 17x) in production, reducing development time from weeks to hours and lowering the programmability barrier for new AI hardware.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp
  - **Simple LLM Summary:** This paper presents KernelEvolve, an agentic framework that automates the generation and optimization of compute kernels for deep learning recommendation models to address challenges posed by model, kernel, and hardware heterogeneity. The method uses a graph-based search process enhanced with retrieval-augmented prompts and operates across multiple programming abstractions. The system was validated on production models and benchmarks, showing significant performance improvements and reduced development time, effectively mitigating the programmability barrier for new AI accelerators.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[KernelEvolve: Scaling Agentic Kernel Coding] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[DLRM训练/推理效率<br/>DLRM Training/Inference Efficiency]
        B --> B2[模型、内核、硬件异构性<br/>Model, Kernel, Hardware Heterogeneity]
        C --> C1[智能内核编码框架<br/>Agentic Kernel Coding Framework]
        C --> C2[多抽象层: Triton, CuTe DSL<br/>Multi-Abstraction: Triton, CuTe DSL]
        C --> C3[图搜索与检索增强提示<br/>Graph Search & Retrieval-Augmented Prompt]
        D --> D1[100%正确率, 17倍加速<br/>100% Correctness, 17x Speedup]
        D --> D2[开发时间: 数周->数小时<br/>Dev Time: Weeks->Hours]
        D --> D3[降低新硬件编程壁垒<br/>Reduces New Hardware Programmability Barrier]
    ```

- **[arXiv251230] Plug-and-Play Fidelity Optimization for Diffusion Transformer Acceleration via Cumulative Error Minimization**
  - **tags:** [mlsys], [diffusion models], [diffusion transformer, inference acceleration, caching, error minimization, dynamic programming]
  - **authors:** Tong Shao, Yusen Fu, Guoying Sun, Jingde Kong, Zhuotao Tian, Jingyong Su
  - **institution:** Harbin Institute of Technology, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.23258
  - **contributions:** 1. Proposes CEM, a novel plugin for optimizing caching strategies in DiT acceleration via cumulative error minimization. 2. Introduces a dynamic programming algorithm guided by a predefined error prior to adaptively minimize caching error. 3. Demonstrates the method's model-agnostic nature, seamless integration into existing frameworks, and significant fidelity improvements across multiple models and tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b2f0b193709fc539d32a8fa74b0405ea99491982cb3f280e0dd10ff89b6b0a3_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the slow inference of Diffusion Transformers (DiTs) by proposing CEM, a plug-and-play fidelity optimization plugin. CEM minimizes cumulative caching error via a dynamic programming algorithm, adapting to error variations during denoising. The method is training-free, model-agnostic, and significantly improves generation fidelity when integrated with existing acceleration techniques.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Plug-and-Play Fidelity Optimization for Diffusion Transformer Acceleration via Cumulative Error Minimization"] --> Problem["核心问题/Problem: DiT推理慢，现有缓存加速方法存在固定策略导致的累积误差/DiT inference is slow; existing caching-based acceleration suffers from fixed-strategy cumulative error"]
        Root --> Method["主要方法/Method: 提出CEM插件，通过累积误差最小化的动态规划优化缓存策略/Propose CEM plugin, optimizing caching strategy via cumulative error minimization with dynamic programming"]
        Root --> Results["关键结果/Results: 显著提升生成保真度，模型无关，可无缝集成/Significantly improves generation fidelity, model-agnostic, seamlessly integrable"]
    ```

- **[arXiv251230] PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement Using Deep Learning-Based Dynamic Object Filtering**
  - **tags:** [cv], [visual SLAM], [ORB-SLAM3, YOLOv8, dynamic object filtering, point cloud refinement, CUDA acceleration]
  - **authors:** Sheng-Kai Chen, Jie-Yu Chao, Jr-Yu Chang, Po-Lien Wu, Po-Chiang Lin
  - **institution:** Yuan Ze University
  - **link:** https://arxiv.org/pdf/2512.23318
  - **contributions:** 1. Proposes PCR-ORB, an enhanced ORB-SLAM3 framework that integrates deep learning-based point cloud refinement to filter dynamic objects. 2. Implements a multi-stage filtering strategy combining semantic segmentation (YOLOv8), ground plane estimation, sky removal, edge filtering, and temporal consistency for robust dynamic object removal. 3. Achieves real-time performance through CUDA-accelerated processing and demonstrates significant accuracy improvements in specific dynamic sequences on the KITTI dataset.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e72d53f96b383c73428b67d24fbf2d4163ac5820be1bfed6f370c529922f919_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces PCR-ORB, an enhanced visual SLAM system that improves ORB-SLAM3's robustness in dynamic environments by integrating YOLOv8 for semantic segmentation and a multi-stage point cloud refinement process to filter moving objects. The method achieves real-time performance with CUDA acceleration. Evaluation on KITTI shows scenario-dependent effectiveness, with notable accuracy improvements in some sequences but mixed results overall.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: vSLAM accuracy compromised by dynamic objects]
        Method[主要方法/Method: ORB-SLAM3 + YOLOv8 segmentation + multi-stage point cloud filtering]
        Results[关键结果/Results: Mixed performance, notable improvement in specific sequences (e.g., Seq04)]
    ```

- **[arXiv251230] Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation: A Comparative Analysis of IKNet Variants**
  - **tags:** [ai], [explainable ai (xai)], [inverse kinematics, shapley additive explanations (SHAP), InterpretML, obstacle avoidance, neural network]
  - **authors:** Sheng-Kai Chen, Yi-Ling Tsai, Chun-Chih Chang, Yan-Chen Chen, Po-Chiang Lin
  - **institution:** Yuan Ze University
  - **link:** https://arxiv.org/pdf/2512.23312
  - **contributions:** 1. Proposes an explainability-centered workflow integrating SHapley Additive exPlanations (SHAP) with physics-based obstacle avoidance evaluation for neural inverse kinematics. 2. Introduces and trains two lightweight variants of IKNet (Improved IKNet with residual connections and Focused IKNet with position-orientation decoupling) on a synthetic dataset. 3. Demonstrates through simulation that neural IK architectures with more balanced feature importance attribution tend to maintain wider safety margins without sacrificing accuracy, linking XAI insights to robotic safety.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ab3055f2df7d03d7972b536c04fab2618a41cdd21ee682cf0f1ab9c0c6610f6_w640_q70.webp
  - **Simple LLM Summary:** This study addresses the lack of transparency in neural network-based inverse kinematics (IK) solvers by proposing an explainable AI workflow. It integrates SHAP analysis with physics-based simulation to evaluate two new IKNet variants on obstacle avoidance tasks. The key finding is that architectures with more evenly distributed feature importance achieve better safety performance, showing how XAI can guide the development of trustworthy robotic manipulation systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation<br>可解释神经逆运动学用于障碍物感知机器人操作"] --> B
        A --> C
        A --> D
        B["核心问题/Problem<br>Opaque neural IK models lack transparency and safety for responsible AI.<br>黑盒神经IK模型缺乏透明度与安全性"] --> B1["挑战/Challenges<br>Debugging failures, safety certification"]
        C["主要方法/Method<br>XAI workflow integrating SHAP and physics simulation.<br>集成SHAP与物理仿真的XAI工作流"] --> C1["模型/Variants<br>Improved IKNet, Focused IKNet"]
        C --> C2["工具/Tools<br>SHAP, InterpretML, Simulator"]
        D["关键结果/Results<br>Balanced feature attribution correlates with wider safety margins.<br>均衡的特征归因与更宽的安全裕度相关"] --> D1["结论/Conclusion<br>XAI guides architectural refinement for trustworthy IK.<br>XAI指导可信IK的架构改进"]
    ```

- **[arXiv251230] HL-index: Fast Reachability Query in Hypergraphs**
  - **tags:** [db], [graph databases], [hypergraph, reachability query, s-reachability, HL-index, index construction]
  - **authors:** Peiting Xie, Xiangjun Zai, Yanping Wu, Xiaoyang Wang, Wenjie Zhang, Lu Qin
  - **institution:** The University of New South Wales, University of Technology Sydney
  - **link:** https://arxiv.org/pdf/2512.23345
  - **contributions:** 1. Introduces the novel concept of s-reachability and the max-reachability query for hypergraphs, generalizing traditional reachability to model groupwise interactions. 2. Proposes the HL-index, a compact vertex-to-hyperedge index specifically designed to answer max-reachability queries efficiently. 3. Develops a fast covering relationship detection method and a lightweight neighbor-index to accelerate the construction of a minimal HL-index.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/319a455ca1c94672837d9f4e7ca6e0f1c6b652927ab50a3eaefdfd43f2b3cffc_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of efficiently answering reachability queries in hypergraphs, which model complex group interactions. It proposes a new index structure called HL-index, along with optimization techniques for its construction, to solve the max-reachability query problem. Experiments on 20 datasets show the approach is efficient and scalable.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HL-index: Fast Reachability Query in Hypergraphs] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[超图可达性查询<br>Hypergraph Reachability Query]
        B --> B2[建模高阶群体交互<br>Modeling Higher-order Group Interactions]
        C --> C1[提出s-可达性与最大可达性查询<br>Propose s-reachability & Max-reachability Query]
        C --> C2[设计HL-index索引结构<br>Design HL-index Structure]
        C --> C3[快速覆盖关系检测与邻居索引<br>Fast Covering Detection & Neighbor-index]
        D --> D1[在20个数据集上验证<br>Validated on 20 Datasets]
        D --> D2[高效且可扩展<br>Efficient and Scalable]
    ```

- **[arXiv251230] SoulX-LiveTalk Technical Report**
  - **tags:** [mlsys], [diffusion models], [Self-correcting Bidirectional Distillation, Multi-step Retrospective Self-Correction, hybrid sequence parallelism, Parallel VAE, kernel-level optimizations]
  - **authors:** Le Shen, Qiao Qian, Tan Yu, Ke Zhou, Tianhang Yu, Yu Zhan, Zhenjie Wang, Ming Tao, Shunshun Yin, Siyuan Liu
  - **institution:** Soul AI Lab, Donghua University
  - **link:** https://arxiv.org/pdf/2512.23379
  - **code:** https://soul-ailab.github.io/soulx-livetalk/
  - **contributions:** 1. Introduced a Self-correcting Bidirectional Distillation strategy that retains bidirectional attention within video chunks to preserve spatiotemporal correlations and enhance visual fidelity. 2. Proposed a Multi-step Retrospective Self-Correction Mechanism to ensure stability during infinite generation by enabling autonomous recovery from accumulated errors. 3. Engineered a full-stack inference acceleration suite with hybrid sequence parallelism, Parallel VAE, and kernel-level optimizations to achieve real-time performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d6b1bb994b3c3273da207d2f19494d99c1ff6bf6663f41b1d85b2f0c69b83bb_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of deploying large diffusion models for real-time, audio-driven avatar generation by introducing SoulX-LiveTalk, a 14B-parameter framework. It employs a bidirectional distillation strategy and a self-correction mechanism to maintain high visual quality and stability, while a suite of inference optimizations enables sub-second latency and 32 FPS throughput, setting a new standard for interactive digital humans.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SoulX-LiveTalk] --> B[核心问题/Problem: 实时无限时长音频驱动化身生成中计算负载与低延迟的冲突]
        A --> C[主要方法/Method: 自校正双向蒸馏与多步回顾自校正机制]
        A --> D[关键结果/Results: 0.87秒启动延迟，32 FPS实时吞吐]
    ```

- **[arXiv251230] AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis**
  - **tags:** [mlsys], [gpu kernels], [kernel generation, multi-agent system, domain-specific languages (DSLs), performance tuning, Triton]
  - **authors:** Jinye Du, Quan Yuan, Zuyao Zhang, Yanzhi Yi, Jiahui Hu, Wangyi Chen, Yiyang Zhu, Qishui Zheng, Wenxiang Zou, Xiangyu Chang, Zuohe Zheng, Zichun Ye, Chao Liu, Shanni Li, Renwei Zhang, Yiping Deng, Xinwei Hu, Xuefeng Jin, Jie Zhao
  - **institution:** Huawei Technologies Co., Ltd., Hunan University
  - **link:** https://arxiv.org/pdf/2512.23424
  - **contributions:** 1. Proposed AKG kernel agent, a multi-agent framework that automates the generation, migration, and performance tuning of computational kernels for diverse hardware platforms. 2. Designed the system to support multiple Domain-Specific Languages (DSLs) like Triton, TileLang, CPP, and CUDA-C, enabling cross-platform portability and correctness. 3. Demonstrated the system's effectiveness through evaluation on KernelBench, achieving an average 1.46x speedup over PyTorch Eager baselines on GPU and NPU backends.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40d5942348375e7b86203ab7a7420bba7105494296f349fdd48174b020a1527e_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes AKG kernel agent, a multi-agent framework that automates the development and optimization of high-performance computational kernels for modern AI workloads across diverse hardware. The system supports multiple DSLs for portability and uses LLMs for code generation and tuning. Evaluation shows it achieves a 1.46x average speedup over baseline implementations, effectively accelerating kernel development.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AKG Kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[AI模型对高性能计算内核的需求 / AI Models Demand High-Performance Kernels]
        B --> B2[硬件多样性与手动优化的瓶颈 / Hardware Diversity & Manual Optimization Bottleneck]
        C --> C1[多智能体系统自动化内核生成与调优 / Multi-Agent System Automates Kernel Generation & Tuning]
        C --> C2[支持多种DSL以面向不同硬件后端 / Supports Multiple DSLs for Different Hardware Backends]
        D --> D1[在KernelBench上评估 / Evaluated on KernelBench]
        D --> D2[平均加速1.46倍 / Average 1.46x Speedup Achieved]
    ```

- **[arXiv251230] Fuzzy-Logic and Deep Learning for Environmental Condition-Aware Road Surface Classification**
  - **tags:** [cv], [image classification], [convolutional neural networks, fuzzy logic, road surface classification, intelligent transport systems, data fusion]
  - **authors:** Mustafa Demetgul, Sanja Lazarova Molnar
  - **institution:** Karlsruhe Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.23436
  - **contributions:** 1. Proposes a real-time system for road surface classification by fusing weather-conditional data and road condition data. 2. Compares the performance of multiple deep learning CNNs (AlexNet, LeNet, VGG, ResNet) on both image-based and acceleration-data-as-image classification tasks. 3. Introduces the use of fuzzy logic to classify road surfaces according to environmental factors like weather and time of day, using sensor data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d74437ab4a94c7ac8b2148bba4e1b6dd8d4706d55db8a2ae146a41ace94ef9f9_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a real-time system for road surface condition monitoring. It employs deep learning CNNs to classify road types from images and acceleration data, achieving over 95% accuracy, and suggests using fuzzy logic to incorporate weather and time-of-day factors. The work aims to enhance vehicle safety and autonomous driving systems.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Fuzzy-Logic and Deep Learning for Environmental Condition-Aware Road Surface Classification] --> B[核心问题/Problem: Classical road monitoring is expensive and unsystematic.]
    A --> C[主要方法/Method: Use deep learning (CNN) on images/acceleration data and fuzzy logic for environmental context.]
    A --> D[关键结果/Results: Over 95% classification accuracy achieved.]
    ```

- **[arXiv251230] HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation**
  - **tags:** [cv], [motion generation], [flow matching, diffusion transformer (DiT), reinforcement learning from human feedback (RLHF)]
  - **authors:** Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao
  - **institution:** Tencent Hunyuan
  - **link:** https://arxiv.org/pdf/2512.23464
  - **code:** https://github.com/Tencent-Hunyuan/HY-Motion-1.0
  - **contributions:** 1. The first successful scaling of DiT-based flow matching models to billion parameters for motion generation. 2. A comprehensive full-stage training paradigm including large-scale pretraining, fine-tuning, and RLHF. 3. A meticulous data processing pipeline enabling extensive coverage of over 200 motion categories.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces HY-Motion 1.0, a large-scale model for generating 3D human motions from text. It scales up Diffusion Transformer-based flow matching and uses a full-stage training pipeline with pretraining, fine-tuning, and RLHF. The model achieves state-of-the-art performance and broad motion coverage, and is released open-source.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"]
        Root --> Problem["核心问题/Problem: Generating high-quality, text-aligned 3D human motions"]
        Root --> Method["主要方法/Method: Scale DiT-based flow matching, Full-stage training (pretrain, fine-tune, RLHF), Meticulous data pipeline"]
        Root --> Results["关键结果/Results: SOTA performance, Extensive motion coverage, Open-source release"]
    ```

- **[arXiv251230] Analysis of kinetic-diffusion Monte Carlo simulation and source term estimation scheme in nuclear fusion applications**
  - **tags:** [hpc], [scientific computing], [kinetic-diffusion Monte Carlo, asymptotic-preserving, Boltzmann-BGK, error analysis, plasma simulation]
  - **authors:** Zhirui Tang, Julian Koellermeier, Emil Løvbak, Giovanni Samaey
  - **institution:** KU Leuven, University of Groningen, Ghent University, Karlsruhe Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.23580
  - **contributions:** 1. Provides a comprehensive theoretical and numerical convergence analysis for the combined Kinetic-Diffusion Monte Carlo (KDMC) method and its associated fluid estimation scheme. 2. Proves theoretical upper bounds for the error of both the KDMC simulation and the fluid estimation technique. 3. Demonstrates through numerical experiments that the analyzed algorithm achieves lower error than a purely fluid-based method and significant speedup compared to a fully kinetic Monte Carlo reference.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6302c36c316815b29f4097f7a2975625261d744e473d4e2098cfa440ddbd03df_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes a combined Kinetic-Diffusion Monte Carlo (KDMC) method and fluid estimation scheme for simulating neutral particles in plasma edge physics, a computationally expensive problem for large fusion reactors. The work provides theoretical error bounds and numerical verification, showing the method is more accurate than fluid-based approaches and faster than fully kinetic Monte Carlo. The analysis confirms the effectiveness of this asymptotic-preserving approach for nuclear fusion applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Analysis of kinetic-diffusion Monte Carlo simulation and source term estimation scheme in nuclear fusion applications] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[高碰撞率导致计算成本巨大/High collision rates lead to substantial computational cost in large reactors (ITER, DEMO)]
        C --> C1[分析渐近保持的动力学-扩散蒙特卡洛(KDMC)与流体估计方案/Analyze Asymptotic-Preserving Kinetic-Diffusion Monte Carlo (KDMC) & fluid estimation]
        C --> C2[理论误差上界证明与数值验证/Prove theoretical upper bounds & numerical verification]
        D --> D1[比纯流体方法误差更低/Lower error than purely fluid-based method]
        D --> D2[相比全动力学MC显著加速/Significant speedup vs. fully kinetic MC]
        D --> D3[证实了在核聚变应用中的有效性/Confirms effectiveness in nuclear fusion applications]
    ```

- **[arXiv251230] Space AI: Leveraging Artificial Intelligence for Space to Improve Life on Earth**
  - **tags:** [ai], [autonomous systems], [autonomous operations, mission planning, in-situ resource utilisation]
  - **authors:** Ziyang Wang
  - **institution:** IEEE
  - **link:** https://arxiv.org/pdf/2512.22399
  - **contributions:** 1. Proposes and defines "Space AI" as a unified interdisciplinary field at the intersection of AI and space science. 2. Consolidates historical and contemporary progress into a systematic four-context framework (AI on Earth, in Orbit, in Deep Space, for Multi-Planetary Life). 3. Identifies key application areas where AI advances can translate to societal benefits on Earth, such as in sensing, robotics, and trustworthy AI.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6ab175271eb74821199e8998bba499198a030f7f6b329c43a525f851b07aabe_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces "Space AI" as a new interdisciplinary field and proposes a systematic framework to organize its applications across four mission contexts, from Earth-based planning to multi-planetary life support. It argues that AI is critical for enabling autonomous and resilient space operations under extreme conditions, and that advances in this domain will also yield significant benefits for life on Earth.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Space AI: Leveraging AI for Space to Improve Life on Earth] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>如何在极端不确定和有限监督下<br>实现太空自主弹性操作<br>How to enable autonomous, resilient space operations under extreme uncertainty and limited oversight]
        C[主要方法/Method<br>提出系统化四维框架<br>Propose a systematic four-context framework<br>(AI on Earth, in Orbit, in Deep Space, for Multi-Planetary Life)]
        D[关键结果/Results<br>统一了跨学科领域并识别关键应用<br>加速太空探索能力并产生广泛地球影响<br>Unifies interdisciplinary field and identifies key applications<br>Accelerates space exploration capability and yields broad Earth impact]
    ```

- **[arXiv251230] Constraint programming model and biased random-key genetic algorithm for the single-machine coupled task scheduling problem with exact delays to minimize the makespan**
  - **tags:** [other], [scheduling], [constraint programming, biased random-key genetic algorithm, makespan, exact delays, local search]
  - **authors:** Vítor A. Barbosa, Rafael A. Melo
  - **institution:** Institute of Computing, Universidade Federal da Bahia
  - **link:** https://arxiv.org/pdf/2512.23150
  - **contributions:** 1. A Constraint Programming (CP) model for the single-machine coupled task scheduling problem with exact delays, utilizing well-established global constraints. 2. A novel Biased Random-Key Genetic Algorithm (BRKGA) that incorporates an efficient decoder, periodical restarts, shakes, and a local search algorithm for enhanced exploration. 3. An empirical evaluation demonstrating that the BRKGA provides high-quality solutions quickly, while the CP model with extended resources can find best-known solutions for a majority of benchmark instances.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f80cc4c12e23f8eb80b390efdd4a8b62ea37fb03c01008317951d1079c35c319_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the NP-hard single-machine coupled task scheduling problem with exact delays to minimize makespan. It proposes both a Constraint Programming model and a Biased Random-Key Genetic Algorithm (BRKGA) enhanced with local search and shake components. Computational results show the BRKGA finds good solutions quickly, while the CP model with more resources achieves state-of-the-art results on most benchmark instances.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[论文标题/Paper Title: Constraint Programming and BRKGA for Coupled Task Scheduling] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: 单机精确延迟耦合任务调度，最小化完工时间/Single-machine coupled task scheduling with exact delays to minimize makespan]
        Method[主要方法/Method: 约束规划模型与带偏置随机密钥遗传算法/Constraint Programming model and Biased Random-Key Genetic Algorithm (BRKGA)]
        Results[关键结果/Results: BRKGA快速提供高质量解，CP模型在充分资源下达到当前最优解/BRKGA provides high-quality solutions quickly; CP model reaches best-known solutions with sufficient resources]
    ```

## 2026-01-01

**cs.DC total: 17**

- **[arXiv260101] Governing Cloud Data Pipelines with Agentic AI**
  - **tags:** [mlsys], [agent system], [policy-aware control, bounded AI agents, adaptive resource reconfiguration, schema reconciliation, automated failure recovery]
  - **authors:** Aswathnarayan Muthukrishnan Kirubakaran, Adithya Parthasarathy, Nitin Saksena, Ram Sekhar Bodala, Akshay Deshpande, Suhas Malempati, Shiva Carimireddy, Abhirup Mazumder
  - **institution:** IEEE, Independent Researcher, Albertsons, Amtrak, Cato
  - **link:** https://arxiv.org/pdf/2512.23737
  - **contributions:** 1. A production-oriented control plane architecture for policy-aware agentic management of cloud data pipelines. 2. Detailed agent workflows for monitoring, optimization, and schema management. 3. An evaluation demonstrating significant improvements in recovery time, operational cost, and reduction of manual intervention.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5297c02d67a11ab83e576eb218227051a192108c8ce2adf60d62e9fbdb7e355_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Agentic Cloud Data Engineering, a control architecture that integrates bounded AI agents to autonomously govern cloud data pipelines by analyzing telemetry and enforcing declarative policies. The method enables adaptive actions like resource reconfiguration and automated recovery. Experimental results show it reduces recovery time by up to 45%, lowers costs by ~25%, and cuts manual intervention by over 70% compared to static orchestration.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Governing Cloud Data Pipelines with Agentic AI"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["静态配置与被动运维/Static Config & Reactive Ops"]
        Problem --> P2["恢复慢、成本高、手动多/Slow Recovery, High Cost, Manual Overhead"]
        Method --> M1["策略感知控制架构/Policy-aware Control Architecture"]
        Method --> M2["集成有界AI代理/Integrate Bounded AI Agents"]
        Method --> M3["自适应操作/Adaptive Actions"]
        Results --> R1["恢复时间降低45%/Recovery Time ↓45%"]
        Results --> R2["运营成本降低25%/Operational Cost ↓25%"]
        Results --> R3["手动干预减少70%/Manual Intervention ↓70%"]
    ```

- **[arXiv260101] A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit**
  - **tags:** [ai], [subspace clustering], [Schubert Variety, Grassmann Manifold, Linde-Buzo-Grey (LBG), Subspace Clustering, Geometric Learning]
  - **authors:** Karim Salta, Michael Kirby, Chris Peterson
  - **institution:** Colorado State University
  - **link:** https://arxiv.org/pdf/2512.23766
  - **contributions:** 1. Introduces the concept of a trainable prototype called a Schubert Variety of Best Fit (SVBF) for representing clusters of subspaces. 2. Integrates the SVBF prototype into the Linde-Buzo-Grey (LBG) clustering pipeline to create the SVBF-LBG algorithm. 3. Demonstrates improved cluster purity on synthetic, image, spectral, and video action data compared to methods using subspace means.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a73e8fbe969f250567092a96ad55fca5bd7133b8ca34f30feedb918976b1faf5_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new subspace clustering method that uses a geometric prototype called a Schubert Variety of Best Fit (SVBF) instead of a simple subspace mean. The SVBF is integrated into the Linde-Buzo-Grey algorithm, resulting in an SVBF-LBG framework that shows improved clustering performance on various data types while preserving mathematical structure for analysis.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Need for geometric representatives in subspace clustering"] --> Problem_Sub["子问题/Sub-Problem<br>Subspace means on Grassmann manifold may not be optimal"]
        Method["主要方法/Method<br>Propose SVBF-LBG algorithm"] --> Method_Sub1["方法组件/Component 1<br>Schubert Variety of Best Fit (SVBF) prototype"]
        Method --> Method_Sub2["方法组件/Component 2<br>Integration into Linde-Buzo-Grey (LBG) pipeline"]
        Results["关键结果/Results<br>Improved cluster purity"] --> Results_Sub1["结果细节/Detail 1<br>Tested on synthetic, image, spectral, video data"]
        Results --> Results_Sub2["结果细节/Detail 2<br>Retains mathematical structure for downstream analysis"]
    ```

- **[arXiv260101] VGC: A High-Performance Zone-Based Garbage Collector Architecture for Python with Partitioning and Parallel Execution**
  - **tags:** [sys], [memory management], [garbage collection, concurrent mark-and-sweep, memory fragmentation, parallel execution, zone-based architecture]
  - **authors:** Abdulla M
  - **institution:** Could not be determined from the provided content.
  - **link:** https://arxiv.org/pdf/2512.23768
  - **code:** https://github.com/Abdullahlab-n/VGC-for-arxiv
  - **contributions:** 1. Introduces a dual-layer (Active and Passive) garbage collector architecture to separate compile-time and runtime memory management responsibilities., 2. Proposes a concurrent mark-and-sweep strategy for the Active VGC to reduce pause times in parallel workloads., 3. Employs predictive memory mapping and cache-aligned allocation in the Passive VGC to minimize fragmentation and reduce total memory usage.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0edb6409b92db2ec79f95ff72421bf0148b259c4251b261594c32563a128cb85_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes VGC, a novel garbage collector for Python designed to overcome performance bottlenecks like the GIL and fragmentation. It uses a dual-layer architecture with a runtime concurrent collector and a compile-time allocator to reduce pause times and memory usage. The results show significant improvements in performance and scalability for parallel applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[VGC: A High-Performance Zone-Based Garbage Collector Architecture for Python] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[Python GC Bottlenecks: GIL, Pauses, Fragmentation]
        Method[主要方法/Method] --> M1[Dual-Layer Architecture / 双层架构]
        M1 --> M1_1[Active VGC: Runtime Concurrent Mark-and-Sweep / 运行时并发标记清除]
        M1 --> M1_2[Passive VGC: Compile-Time Predictive Allocation / 编译时预测性分配]
        Results[关键结果/Results] --> R1[Reduced Pause Times (up to 30%) / 降低暂停时间]
        Results --> R2[Reduced Memory Usage (up to 25%) / 降低内存使用]
        Results --> R3[Improved Scalability for Parallel Apps / 提升并行应用可扩展性]
    ```

- **[arXiv260101] Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems**
  - **tags:** [mlsys], [federated learning], [Zero-Trust Architecture, SHAP-weighted aggregation, TPM-based attestation]
  - **authors:** Samaresh Kumar Singh, Joyjit Roy, Martin So
  - **institution:** Independent Researchers (based on provided affiliations: IEEE Senior Member in Texas, IEEE Member in Texas, Independent Researcher in Canada)
  - **link:** https://arxiv.org/pdf/2512.23809
  - **contributions:** 1) Proposed a hierarchical edge-fog-cloud zero-trust federated learning architecture for trusted agent participation. 2) Introduced a novel SHAP-weighted aggregation algorithm for explainable Byzantine detection in non-IID environments. 3) Integrated TPM-based cryptographic attestation and on-device adversarial training into a defense-in-depth framework.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/baa785fc442fcbc6a80214c4fdc6361e67a8e34e5a9bb6f5dd8fb34baf21bb68_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses security vulnerabilities in Federated Learning for Industrial IoT by proposing ZTA-FL, a framework combining zero-trust agent authentication, explainable Byzantine-resilient aggregation, and on-device adversarial training. It demonstrates high detection accuracy and robustness against attacks on intrusion detection benchmarks while reducing communication overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: IIoT安全漏洞与联邦学习攻击 / IIoT Security Gaps & FL Attacks]
        Method[主要方法/Method: 零信任认证与可解释聚合 / Zero-Trust Attestation & Explainable Aggregation]
        Results[关键结果/Results: 高检测精度与抗攻击鲁棒性 / High Detection Accuracy & Attack Robustness]
    ```

- **[arXiv260101] Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense**
  - **tags:** [sec], [IoT Security], [Economic Denial Security, Stackelberg Game, Cost Asymmetry, Computational Puzzles]
  - **authors:** Samaresh Kumar Singh, Joyjit Roy
  - **institution:** IEEE (Inferred from author affiliations as IEEE members; specific institutional affiliation not provided in the excerpt)
  - **link:** https://arxiv.org/pdf/2512.23849
  - **contributions:** 1. Proposed the Economic Denial Security (EDS) framework, a detection-independent defense that exploits the defender's environmental control to impose economic infeasibility on attackers., 2. Formally modeled EDS as a Stackelberg game, deriving optimal parameters and proving that the composition of its four mechanisms yields superlinear (2.1x) cost amplification., 3. Demonstrated practical efficacy with a lightweight (&lt;12KB) implementation, validated on a 20-device IoT testbed and against IoT-23 malware, showing significant attack slowdown, cost asymmetry, and improved mitigation rates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53020dd5fb969c1980dd7f764afe5f97440c1ef68620bdcd3383e97bf39600fc_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the failure of detection-based security in resource-constrained IoT/edge environments. It proposes Economic Denial Security (EDS), a framework that uses mechanisms like computational puzzles and bandwidth taxation to make attacks economically infeasible by amplifying attacker costs. The method is proven to be lightweight, effective in significantly slowing attacks and reducing success rates, and provides a detection-independent layer of defense.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[检测安全在资源受限的IoT/边缘环境中失效/Detection-based security fails in resource-constrained IoT/edge]
        C --> C1[经济拒绝安全框架 / Economic Denial Security (EDS) Framework]
        C1 --> C2[四种机制组合 / Four Mechanism Composition]
        C2 --> C3[计算谜题 / Computational Puzzles]
        C2 --> C4[交互熵 / Interaction Entropy]
        C2 --> C5[时间拉伸 / Temporal Stretching]
        C2 --> C6[带宽征税 / Bandwidth Taxation]
        C --> C7[斯塔克尔伯格博弈建模 / Stackelberg Game Modeling]
        D --> D1[32-560倍攻击减速 / 32-560x Attack Slowdown]
        D --> D2[85-520:1 成本不对称 / 85-520:1 Cost Asymmetry]
        D --> D3[内存占用<12KB / <12KB Memory Footprint]
        D --> D4[94% 恶意软件缓解 / 94% Malware Mitigation]
    ```

- **[arXiv260101] Squeezing Edge Performance: A Sensitivity-Aware Container Management for Heterogeneous Tasks**
  - **tags:** [mlsys], [on-device ai], [container-based resource management, mixed-integer nonlinear programming (MINLP), convex optimization, queueing-based delay, heterogeneous tasks]
  - **authors:** Yongmin Zhang, Pengyu Huang, Mingyi Dong, Jing Yao
  - **institution:** School of Computer Science and Engineering, Central South University
  - **link:** https://arxiv.org/pdf/2512.23952
  - **contributions:** 1. Proposed a measurement-driven, nonlinear fitting model to characterize the relationship between CPU/memory allocations and processing latency for heterogeneous edge workloads. 2. Formulated the joint latency and power minimization as an NP-hard MINLP problem and decomposed it into tractable convex subproblems. 3. Designed a two-stage container-based resource management scheme (CRMS) with polynomial-time complexity for quasi-dynamic execution.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b13e70a9fc316e5473ea643ee1dee12e7843bf02004c4bc9cb1c91fc4f547efb_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a sensitivity-aware container management framework (CRMS) for optimizing performance on a single edge server hosting heterogeneous tasks. It uses a profiling-derived model and convex optimization to minimize latency and power consumption. Simulation results show CRMS reduces latency by over 14% and improves energy efficiency compared to baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Squeezing Edge Performance: A Sensitivity-Aware Container Management for Heterogeneous Tasks<br>论文标题"]
        Root --> Problem["任务异构性与资源受限<br>Task Heterogeneity & Limited Resources"]
        Root --> Method["两阶段容器资源管理方案 (CRMS)<br>Two-stage Container-based Resource Management Scheme (CRMS)"]
        Root --> Results["延迟降低超14%，能效提升<br>Latency Reduced >14%, Energy Efficiency Improved"]
        Problem --> P1["边缘服务器资源优化挑战<br>Edge Server Resource Optimization Challenge"]
        Method --> M1["非线性拟合与排队延迟建模<br>Nonlinear Fitting & Queueing Delay Modeling"]
        Method --> M2["MINLP问题分解与凸优化求解<br>MINLP Decomposition & Convex Optimization"]
        Results --> R1["相比启发式和搜索基线更优<br>Outperforms Heuristic & Search-based Baselines"]
    ```

- **[arXiv260101] Time-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning**
  - **tags:** [mlsys], [federated learning], [decentralized federated learning, mixing matrix, energy consumption, time-varying topology, wireless networks]
  - **authors:** Xusheng Zhang, Tuan Nguyen, Ting He
  - **institution:** University of Oxford, Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2512.24069
  - **contributions:** 1. A novel convergence theorem for DFL that allows for arbitrarily time-varying mixing matrices, providing theoretical justification for dynamic communication topologies. 2. A multi-phase design framework for mixing matrices that activates time-varying communication topologies to trade off per-iteration energy consumption and convergence rate. 3. An optimization approach that minimizes the maximum per-node energy consumption until convergence, explicitly considering the broadcast nature of wireless communications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/090a96d0adae430f081f3c2325be19fc983de3cc1e88b07fcc83e4ab4e983d30_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of high energy consumption in Decentralized Federated Learning (DFL) for wireless networks by designing time-varying mixing matrices. The proposed method introduces a multi-phase framework that dynamically adjusts communication topologies to balance energy use across nodes and trade off per-iteration cost with convergence speed. The evaluation shows the solution effectively combines the low energy of sparse topologies with the fast convergence of dense ones.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Time-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning<br>时变混合矩阵设计用于能效去中心化联邦学习"]
        Root --> Problem["Minimize max per-node energy consumption in DFL<br>最小化DFL中最大单节点能耗"]
        Root --> Method["Multi-phase framework with time-varying topologies<br>基于时变拓扑的多阶段框架"]
        Root --> Results["Validated efficacy: low energy + fast convergence<br>验证有效性：低能耗+快速收敛"]
    ```

- **[arXiv260101] Data Heterogeneity-Aware Client Selection for Federated Learning in Wireless Networks**
  - **tags:** [mlsys], [federated learning], [client selection, resource allocation, generalization error, convex optimization, data heterogeneity]
  - **authors:** Yanbing Yang, Huiling Zhu, Wenchi Cheng, Jingqing Wang, Changrun Chen, Jiangzhou Wang
  - **institution:** Xidian University (Inferred from authors' affiliations: Yanbing Yang, Huiling Zhu, Wenchi Cheng, Jingqing Wang, Changrun Chen, and Jiangzhou Wang are typically affiliated with Xidian University, China, as per IEEE publications)
  - **link:** https://arxiv.org/pdf/2512.24286
  - **contributions:** 1. Presents a theoretical analysis linking client data heterogeneity to global model generalization error in Federated Learning. 2. Formulates an optimization problem to jointly minimize learning latency and energy consumption under a generalization error constraint. 3. Proposes a joint Client Selection and Resource Allocation (CSRA) scheme using convex optimization and relaxation techniques.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d00d21e4555bde2acb5f1a697568b443b6eb9860e36434dcc6d960ed7390c050_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the inefficiency of Federated Learning in wireless networks caused by data heterogeneity and resource constraints. It proposes a joint client selection and resource allocation (CSRA) optimization scheme to minimize latency and energy while controlling model error. Simulation results show the proposed CSRA achieves higher accuracy, lower latency, and reduced energy consumption compared to heterogeneity-agnostic baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Data Heterogeneity-Aware Client Selection for Federated Learning in Wireless Networks") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("FL效率受限/FL Efficiency Limited")
        P1 --> P1_1("通信与计算资源约束/Communication & Computation Constraints")
        P1 --> P1_2("客户端数据异构性/Client Data Heterogeneity")
        Method --> M1("理论分析/Theoretical Analysis")
        M1 --> M1_1("异构性对泛化误差的影响/Impact of Heterogeneity on Generalization Error")
        Method --> M2("优化问题建模/Optimization Problem Formulation")
        M2 --> M2_1("联合最小化延迟与能耗/Jointly Minimize Latency & Energy")
        M2 --> M2_2("约束泛化误差/Constraining Generalization Error")
        Method --> M3("提出CSRA方案/Proposed CSRA Scheme")
        M3 --> M3_1("联合客户端选择与资源分配/Joint Client Selection & Resource Allocation")
        M3 --> M3_2("凸优化与松弛技术/Convex Optimization & Relaxation")
        Results --> R1("更高测试准确率/Higher Test Accuracy")
        Results --> R2("降低学习延迟/Reduced Learning Latency")
        Results --> R3("更低能耗/Lower Energy Consumption")
    ```

- **[arXiv260101] RedunCut: Measurement-Driven Sampling and Accuracy Performance Modeling for Low-Cost Live Video Analytics**
  - **tags:** [mlsys], [others], [dynamic model size selection, live video analytics, measurement-driven sampling, accuracy performance modeling, cost-accuracy tradeoff]
  - **authors:** Gur-Eyal Sela, Kumar Krishna Agrawal, Bharathan Balaji, Joseph Gonzalez, Ion Stoica
  - **institution:** UC Berkeley, Amazon
  - **link:** https://arxiv.org/pdf/2512.24386
  - **contributions:** 1. A measurement-driven planner that estimates the cost-benefit tradeoff of sampling to avoid inefficient sampling. 2. A lightweight, data-driven performance model to improve per-segment accuracy prediction. 3. A new DMSS system (RedunCut) that reduces compute cost by 14-62% at fixed accuracy across diverse video workloads and remains robust to limited data and drift.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b99d771bb4464484bc20a905a41cf7ba47990b34219a4a1e3c0b5dc5c0c242bb_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high inference cost in live video analytics by proposing RedunCut, a dynamic model size selection system. It introduces a measurement-driven planner to optimize sampling and a data-driven model to predict accuracy, reducing compute costs by 14-62% while maintaining target accuracy across diverse video types. The system demonstrates robustness to limited historical data and concept drift.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[RedunCut: Low-Cost Live Video Analytics] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[高推理成本/High Inference Cost]
        Problem --> P2[现有方法泛化性差/Prior Methods Fail to Generalize]
        P2 --> P2_1[采样效率低/Inefficient Sampling]
        P2 --> P2_2[精度预测不准/Inaccurate Accuracy Prediction]
        Method[主要方法/Method] --> M1[测量驱动的规划器/Measurement-Driven Planner]
        Method --> M2[轻量级性能模型/Lightweight Performance Model]
        Results[关键结果/Results] --> R1[成本降低 14-62%/Cost Reduction 14-62%]
        Results --> R2[保持目标精度/Maintains Target Accuracy]
        Results --> R3[对数据漂移鲁棒/Robust to Drift]
    ```

- **[arXiv260101] PackKV: Reducing KV Cache Memory Footprint through LLM-Aware Lossy Compression**
  - **tags:** [mlsys], [llm inference], [KV cache, lossy compression, memory footprint, GPU kernels, attention mechanism]
  - **authors:** Bo Jiang, Taolue Yang, Youyuan Liu, Xubin He, Sheng Di, Sian Jin
  - **institution:** Temple University, Argonne National Laboratory
  - **link:** https://arxiv.org/pdf/2512.24449
  - **code:** https://github.com/BoJiang03/PackKV
  - **contributions:** 1. Proposes PackKV, a generic KV cache management framework featuring novel lossy compression techniques specifically tailored to KV cache data characteristics. 2. Presents a careful co-design of compression algorithms and system architecture that is compatible with the dynamically growing KV cache while preserving high computational efficiency. 3. Achieves significantly higher memory reduction rates and execution throughput compared to state-of-the-art methods, effectively eliminating decompression overhead and accelerating matrix-vector multiplication.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42e07bd3aaf7626174ef50b03ee71ac8de443f8fb5560e374d8293b4df52b84f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high memory footprint of the KV cache during long-context LLM inference by proposing PackKV, a framework that uses LLM-aware lossy compression. PackKV co-designs compression algorithms and system architecture to reduce memory usage while maintaining computational efficiency. The results show that PackKV achieves superior memory reduction and higher throughput compared to existing quantization methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[PackKV: Reducing KV Cache Memory Footprint] --> B[核心问题/Problem: KV缓存内存占用大/Large KV Cache Memory Footprint]
        A --> C[主要方法/Method: LLM感知的有损压缩/LLM-Aware Lossy Compression]
        A --> D[关键结果/Results: 更高内存减少与吞吐量/Higher Memory Reduction & Throughput]
    ```

- **[arXiv260101] Document Data Matching for Blockchain-Supported Real Estate**
  - **tags:** [sys], [decentralized systems], [Verifiable Credentials, Optical Character Recognition, Natural Language Processing, Blockchain, Data Matching]
  - **authors:** Henrique Lin, Tiago Dias, Miguel Correia
  - **institution:** INESC-ID, Instituto Superior Técnico, Universidade de Lisboa, Unlockit
  - **link:** https://arxiv.org/pdf/2512.24457
  - **contributions:** 1. Development of a prototype system that automates the extraction of key information from heterogeneous real estate documents using an OCR and NLP pipeline trained on synthetic data. 2. A framework for converting extracted document data into standardized Verifiable Credentials and performing automated data matching to detect inconsistencies. 3. Integration of blockchain as a decentralized trust layer to reinforce transparency and integrity in document verification and management.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/77d42eaf9ccd48f40b91694b8109e5b2c7abc796e86c6fd2151ac05f73c2f492_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the inefficiency and fraud risk in manual real estate document handling by proposing a system that integrates OCR, NLP, and Verifiable Credentials to automate document extraction and verification, backed by a blockchain trust layer. The developed prototype demonstrates competitive accuracy in information extraction and reduces verification time while maintaining reliability. The framework shows potential to streamline transactions and enhance trust in the real estate sector.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Document Data Matching for Blockchain-Supported Real Estate] --> B(核心问题/Problem: Manual document handling in real estate is inefficient and prone to fraud.)
        A --> C(主要方法/Method: Integrates OCR, NLP, and Verifiable Credentials for automated extraction and verification, using blockchain for trust.)
        A --> D(关键结果/Results: Prototype achieves competitive accuracy and reduces verification time, demonstrating potential to streamline transactions.)
    ```

- **[arXiv260101] Understanding LLM Checkpoint/Restore I/O Strategies and Patterns**
  - **tags:** [mlsys], [fault-tolerance], [checkpoint/restore, I/O characterization, liburing, I/O coalescing, parallel file systems]
  - **authors:** Mikaila J. Gossman, Avinash Maurya, Bogdan Nicolae, Jon C. Calhoun
  - **institution:** Clemson University, Argonne National Laboratory
  - **link:** https://arxiv.org/pdf/2512.24511
  - **contributions:** 1. Developed microbenchmarks to quantify trade-offs of using the kernel-accelerated I/O library `liburing` for LLM checkpointing, evaluating interactions between aggregation, alignment, and I/O coalescing. 2. Demonstrated that file system-aware aggregation and I/O coalescing strategies are critical for restoring bandwidth and reducing metadata overhead, significantly outperforming uncoalesced operations. 3. Achieved substantial performance improvements over state-of-the-art engines, with up to 3.9x higher write throughput than DataStates-LLM and 7.6x higher than TorchSnapshot.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a135466d9791e7bf6694d7dbe73c7c7a28f3f0c0d670bddbb0b4be458fd22e58_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the I/O bottleneck in checkpointing large language models (LLMs) by investigating the use of the `liburing` library for optimized I/O operations. The authors propose and evaluate strategies like aggregation and I/O coalescing to improve performance. Their approach significantly outperforms existing checkpointing engines, highlighting the need for file system-aware I/O strategies in modern LLM training systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["Understanding LLM Checkpoint/Restore I/O Strategies and Patterns<br/>论文标题"] --> B
        A --> C
        A --> D
        B["核心问题/Problem<br/>LLM checkpoint/restore is a big-data I/O bottleneck<br/>LLM检查点/恢复是大数据I/O瓶颈"]
        C["主要方法/Method<br/>Microbenchmark liburing, evaluate aggregation & coalescing<br/>对liburing进行微基准测试，评估聚合与合并"]
        D["关键结果/Results<br/>3.9x-7.6x higher throughput vs. SOTA<br/>相比SOTA吞吐量提升3.9-7.6倍"]
    ```

- **[arXiv260101] Distributed Bilevel Optimization with Dual Pruning for Resource-limited Clients**
  - **tags:** [mlsys], [federated learning], [distributed bilevel optimization, resource-adaptive, hypergradient estimator, convergence analysis, dual pruning]
  - **authors:** Mingyi Li, Xiao Zhang, Ruisheng Zheng, Hongjian Shi, Yuan Yuan, Xiuzhen Cheng, Dongxiao Yu
  - **institution:** Shandong University
  - **link:** https://arxiv.org/pdf/2512.24667
  - **contributions:** 1. Proposes the first resource-adaptive distributed bilevel optimization framework that allows clients to optimize submodels based on their available computational resources. 2. Introduces a second-order free hypergradient estimator to reduce computational overhead on resource-limited clients. 3. Provides theoretical convergence analysis for the proposed methods (RABO and RAFBO), showing they achieve an asymptotically optimal convergence rate dominated by the minimum coverage of outer parameters.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e1a37c13f80adceef30f4612f5b9f03192647fcb35238d17be6ae91567195d2_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of applying distributed bilevel optimization to large-scale models on resource-limited clients by proposing a resource-adaptive framework. The method uses a second-order free hypergradient estimator and allows clients to optimize submodels adapted to their available resources. Theoretical analysis shows the proposed methods achieve optimal convergence rates, and experiments demonstrate their effectiveness and computational efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Distributed Bilevel Optimization with Dual Pruning for Resource-limited Clients] --> B[核心问题/Problem: Traditional distributed bilevel optimization is computationally excessive for low-resource clients with large-scale models.]
    A --> C[主要方法/Method: Propose a resource-adaptive framework with a second-order free hypergradient estimator, enabling clients to optimize submodels based on available resources.]
    A --> D[关键结果/Results: The proposed methods (RABO, RAFBO) achieve an asymptotically optimal convergence rate of O(1/√C*xQ), proven by theory and validated by experiments.]
    ```

- **[arXiv260101] AI-Driven Cloud Resource Optimization for Multi-Cluster Environments**
  - **tags:** [mlsys], [cluster infrastructure], [multi-cluster systems, resource optimization, predictive learning, policy-aware decision-making, cross-cluster telemetry]
  - **authors:** Vinoth Punniyamoorthy, Akash Kumar Agarwal, Bikesh Kumar, Abhirup Mazumder, Kabilan Kannan, Sumit Saha
  - **institution:** IEEE (affiliations indicate authors are IEEE Senior Members, with industry affiliations from Albertsons and East West Bank, USA)
  - **link:** https://arxiv.org/pdf/2512.24914
  - **contributions:** 1. An AI-driven framework for adaptive resource optimization across multi-cluster cloud systems, moving beyond reactive, cluster-centric approaches. 2. Integration of predictive learning, policy-aware decision-making, and continuous feedback to enable proactive and coordinated resource management. 3. A prototype demonstrating improved resource efficiency, faster stabilization during workload fluctuations, and reduced performance variability compared to conventional methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02143e20715d24c6ab11a29c3710ca28e3f39c48ce36f9862a254d3564252726_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes an AI-driven framework to address the problem of inefficient and reactive resource management in multi-cluster cloud environments. The method uses predictive learning and policy-aware decision-making on cross-cluster telemetry to proactively optimize resource allocation for performance, cost, and reliability. The results show the framework improves resource efficiency and system stability compared to traditional approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AI-Driven Cloud Resource Optimization for Multi-Cluster Environments] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有方法反应式且集群中心化 / Existing approaches are reactive and cluster-centric]
        B --> B2[导致资源利用低效和延迟适应 / Causes inefficient resource utilization and delayed adaptation]
        C --> C1[AI驱动框架集成预测学习 / AI-driven framework integrates predictive learning]
        C --> C2[策略感知决策与持续反馈 / Policy-aware decision-making and continuous feedback]
        C --> C3[分析跨集群遥测数据 / Analyzes cross-cluster telemetry]
        D --> D1[提高资源效率 / Improved resource efficiency]
        D --> D2[更快稳定于工作负载波动 / Faster stabilization during workload fluctuations]
        D --> D3[减少性能变异 / Reduced performance variability]
    ```

- **[arXiv260101] Reliable and Resilient Collective Communication Library for LLM Training and Serving**
  - **tags:** [mlsys], [communication & networking], [fault-tolerant collective communication, multi-NIC failover, connection migration, bandwidth-aware load redistribution, resilient collective algorithms]
  - **authors:** Wei Wang, Nengneng Yu, Sixian Xiong, Zaoxing Liu
  - **institution:** University of Maryland, College Park
  - **link:** https://arxiv.org/pdf/2512.25059
  - **code:** https://github.com/r2cc-project/R-2CCL
  - **contributions:** 1. A fault-tolerant communication library (R²CCL) that provides lossless, low-overhead failover by exploiting multi-NIC hardware. 2. Techniques including rapid connection migration, bandwidth-aware load redistribution, and resilient collective algorithms to maintain progress under network failures. 3. Demonstrated high robustness to NIC failures with minimal overhead (&lt;1% for training, &lt;3% for inference) and significant performance improvements over baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd037366831b8135233f491feff11095f79c30662f36cb517794f6588542c452_w640_q70.webp
  - **Simple LLM Summary:** The paper presents R²CCL, a fault-tolerant collective communication library designed to handle network faults in large-scale LLM training and serving. It achieves low-overhead recovery through techniques like rapid connection migration and bandwidth-aware load redistribution. Evaluation shows it incurs minimal performance overhead and significantly outperforms existing solutions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Reliable and Resilient Collective Communication Library for LLM Training and Serving] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Network faults waste GPU hours and cause job failures in large-scale ML clusters]
        Method[主要方法/Method: R²CCL library with rapid connection migration, bandwidth-aware load redistribution, and resilient collective algorithms]
        Results[关键结果/Results: <1% training overhead, <3% inference overhead, 12.18x-47x faster than baselines]
    ```

- **[arXiv260101] Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search**
  - **tags:** [mlsys], [memory & caching], [heuristic synthesis, evolutionary search, instance-optimal, LLM code generation, cache eviction]
  - **authors:** Rohit Dwivedula, Divyanshu Saxena, Sujay Yadalam, Daehyeok Kim, Aditya Akella
  - **institution:** The University of Texas at Austin
  - **link:** https://arxiv.org/pdf/2512.25065
  - **contributions:** 1. Proposes Vulcan, a framework that recasts heuristic design as an automated search problem using LLMs to synthesize instance-optimal heuristics tailored to specific deployment contexts. 2. Introduces LLM-friendly, task-agnostic interfaces that separate policy and mechanism, making the synthesis tractable and enabling even small LLMs to generate correct code. 3. Demonstrates the framework's effectiveness by synthesizing heuristics for cache eviction and memory tiering that outperform state-of-the-art human-designed algorithms.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8daf2ac9cf0548fb6b41e5cb643f8b78cc3001bcb2d8b95b8ade5ced5201e53a_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes Vulcan, a framework that uses LLM-driven evolutionary search to automatically synthesize instance-optimal system heuristics, tailored to specific workloads and hardware. It introduces task-agnostic interfaces to separate policy from mechanism, enabling efficient code generation. The synthesized heuristics for cache eviction and memory tiering were shown to outperform existing state-of-the-art algorithms.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Manual heuristic design is slow and cannot adapt to changing hardware and workloads.]
        Method[主要方法/Method: Use LLM-driven evolutionary search over task-agnostic interfaces to synthesize instance-optimal heuristics.]
        Results[关键结果/Results: Synthesized heuristics outperform state-of-the-art algorithms in cache eviction and memory tiering.]
    ```

- **[arXiv260101] Adaptive Resource Orchestration for Distributed Quantum Computing Systems**
  - **tags:** [hpc], [Distributed Quantum Computing], [Modular Entanglement Hub, Quantum Network Orchestrator, Teleportation Success Rate, Ebit Cache, Monte Carlo Simulation]
  - **authors:** Kuan-Cheng Chen, Felix Burt, Nitish K. Panigrahy, Kin K. Leung
  - **institution:** Imperial College London, Binghamton University SUNY
  - **link:** https://arxiv.org/pdf/2512.24902
  - **contributions:** 1. Proposed the Modular Entanglement Hub (ModEn-Hub) architecture, a hub-and-spoke photonic interconnect with a central orchestrator for managing entanglement resources. 2. Introduced an adaptive orchestration policy featuring logarithmically scaled parallelism and opportunistic caching of entanglement bits (ebits). 3. Demonstrated through Monte Carlo simulation that the orchestrated system sustains high teleportation success rates (~90%) across many QPUs, significantly outperforming a naive sequential baseline.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5cdc243a82e638196fde6023c44f1f4a5ab3b6055535ac757574242b690b212_w640_q70.webp
  - **Simple LLM Summary:** To scale quantum computing, the paper proposes the Modular Entanglement Hub (ModEn-Hub) architecture, which centralizes entanglement generation and uses an adaptive orchestrator to manage resources. Simulation results show this approach maintains a high teleportation success rate of about 90% across 1-128 quantum processors, vastly outperforming a simple baseline, thus enabling scalable distributed quantum-HPC systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Adaptive Resource Orchestration for Distributed Quantum Computing Systems"] --> Problem["核心问题/Problem: Scaling quantum computing requires networking multiple QPUs, but managing entanglement is challenging."]
        Root --> Method["主要方法/Method: Propose Modular Entanglement Hub (ModEn-Hub) with an adaptive orchestrator for parallel entanglement attempts and caching."]
        Root --> Results["关键结果/Results: Orchestration sustains ~90% teleportation success vs. ~30% for baseline, enabling scalable quantum-HPC."]
    ```


**cs.AI/cs.LG contains "reinforcement learning" total: 46**
- **[arXiv260101] A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation**
  - **tags:** [hpc], [computational geometry], [mesh generation, geometry preparation, CAD-to-mesh, machine learning, large language models]
  - **authors:** Steven Owen, Nathan Brown, Nikos Chrisochoides, Rao Garimella, Xianfeng Gu, Franck Ledoux, Na Lei, Roshan Quadros, Navamita Ray, Nicolas Winovich, Yongjie Jessica Zhang
  - **institution:** Sandia National Laboratories, Old Dominion University, Los Alamos National Laboratory, New York University / Stony Brook University, CEA, Dalian University of Technology, Carnegie Mellon University
  - **link:** https://arxiv.org/pdf/2512.23719
  - **contributions:** 1. Surveys the application of AI/ML methods to automate and improve key steps in the CAD-to-mesh pipeline, such as part classification, mesh quality prediction, and defeaturing. 2. Reviews AI techniques for enhancing unstructured/block-structured meshing, volumetric parameterization, and parallel mesh generation. 3. Examines emerging tools like reinforcement learning and large language models for scripting automation in meshing workflows.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c3d8c73084ddd952c2e0c9fd20e1b7fe1d87bb02c884cf6327ca47e6ec442eb_w640_q70.webp
  - **Simple LLM Summary:** This survey paper reviews how artificial intelligence and machine learning are being applied to address bottlenecks in geometry preparation and mesh generation for engineering simulation. It explores a range of methods, from quality prediction to automation with large language models, concluding that AI serves as an assistive technology to extend traditional tools and highlights key challenges for future data-driven workflows.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[CAD-to-mesh流程瓶颈 / CAD-to-mesh Pipeline Bottlenecks]
        C --> C1[AI辅助几何与网格生成 / AI-aided Geometry & Meshing]
        C --> C2[机器学习方法 / Machine Learning Methods]
        C --> C3[新兴自动化工具 / Emerging Automation Tools]
        C1 --> C1a[部件分类 / Part Classification]
        C1 --> C1b[网格质量预测 / Mesh Quality Prediction]
        C1 --> C1c[去特征化 / Defeaturing]
        C2 --> C2a[非结构化/块结构化网格 / Unstructured/Block-structured Meshing]
        C2 --> C2b[体积参数化 / Volumetric Parameterizations]
        C2 --> C2c[并行网格生成 / Parallel Mesh Generation]
        C3 --> C3a[强化学习 / Reinforcement Learning]
        C3 --> C3b[大语言模型 / Large Language Models]
        D --> D1[AI作为辅助技术 / AI as Assistive Technology]
        D --> D2[代表性方法与部署 / Representative Methods & Deployments]
        D --> D3[关键研究挑战 / Key Research Challenges]
    ```

- **[arXiv260101] Audited Skill-Graph Self-Improvement for Agentic LLMs via Verifiable Rewards, Experience Synthesis, and Continual Memory**
  - **tags:** [mlsys], [agent system], [skill graph, verifiable rewards, continual memory, experience synthesis, audit logging]
  - **authors:** Ken Huang, Jerry Huang
  - **institution:** DistributedApps.ai, OWASP, Kleiner Perkins
  - **link:** https://arxiv.org/pdf/2512.23760
  - **contributions:** 1. Proposes the Audited Skill-Graph Self-Improvement (ASG-SI) framework, which treats agent self-improvement as the iterative compilation of an auditable, growing skill graph. 2. Introduces a verifier-auditor mechanism that uses replayable evidence and decomposed rewards to gate skill promotion, enabling independent audit and governance. 3. Integrates experience synthesis for scalable testing and continual memory control to manage context growth and preserve long-horizon performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bdd2b1c94a27644963b1a77d560eb3715fa72ea6468dc6c4e39e42eb5e040187_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses security and governance challenges in self-improving AI agents, such as reward hacking and opaque behavioral drift. It proposes the ASG-SI framework, which compiles agent improvements into an auditable skill graph verified by replayable evidence. The approach reframes self-improvement as the accumulation of verifiable, reusable capabilities for reproducible evaluation and operational governance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Audited Skill-Graph Self-Improvement (ASG-SI) / 审计技能图自我改进"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem"] --> P1["部署的自我改进代理存在安全与治理挑战 / Deployed self-improving agents pose security & governance challenges"]
        P1 --> P2["奖励黑客行为、行为漂移、不透明的更新 / Reward hacking, behavioral drift, opaque updates"]
        Method["主要方法/Method"] --> M1["ASG-SI 框架 / ASG-SI Framework"]
        M1 --> M2["将改进编译为可审计技能图 / Compile improvements into auditable skill graph"]
        M2 --> M3["基于验证器的证据和可分解奖励进行技能提升 / Verifier-backed evidence & decomposed rewards gate skill promotion"]
        M3 --> M4["集成经验合成和持续记忆控制 / Integrate experience synthesis & continual memory control"]
        Results["关键结果/Results"] --> R1["提供可验证、可重用的能力积累 / Provides accumulation of verifiable, reusable capabilities"]
        R1 --> R2["为自我改进AI提供可复现评估和操作治理的路径 / Offers path for reproducible evaluation & operational governance of self-improving AI"]
    ```

- **[arXiv260101] Safety-Biased Policy Optimisation: Towards Hard-Constrained Reinforcement Learning via Trust Regions**
  - **tags:** [ai], [safe reinforcement learning], [constrained MDP, trust region policy optimization, natural policy gradient, safety gymnasium, hard constraints]
  - **authors:** Ankit Kanwar, Dominik Wagner, Luke Ong
  - **institution:** Sony Corporation, Nanyang Technological University (NTU Singapore)
  - **link:** https://arxiv.org/pdf/2512.23770
  - **contributions:** 1. Proposes Safety-Biased Trust Region Policy Optimisation (SB-TRPO), a new algorithm for hard-constrained RL that adaptively biases policy updates towards safety while seeking reward improvement. 2. Introduces a trust-region update using a convex combination of the natural policy gradients of cost and reward to ensure a fixed fraction of optimal cost reduction per step. 3. Provides a theoretical guarantee of local progress towards safety and demonstrates superior balance of safety and task performance on Safety Gymnasium benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ea6c2a84f6cc7b4f3144847fc78a84736f7247b99f773ed23dd1861f2ff0760_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of reinforcement learning under hard safety constraints, where existing methods struggle to avoid violations without sacrificing reward. It proposes SB-TRPO, an algorithm that performs trust-region updates by combining reward and cost gradients to bias updates towards safety. Experiments show that SB-TRPO achieves a better balance of safety and task completion than state-of-the-art methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Safety-Biased Policy Optimisation] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: RL in safety-critical domains requires strict constraint adherence without sacrificing reward performance.]
        Method[主要方法/Method: SB-TRPO uses convex combination of natural policy gradients for cost and reward in trust-region updates.]
        Results[关键结果/Results: Achieves best balance of safety and task completion on Safety Gymnasium benchmarks.]
    ```

- **[arXiv260101] Prompt-Induced Over-Generation as Denial-of-Service: A Black-Box Attack-Side Benchmark**
  - **tags:** [sec], [adversarial attacks on llms], [denial-of-service, over-generation, black-box attack, evolutionary search, reinforcement learning]
  - **authors:** Manu, Yi Guo, Jo Plested, Tim Lynar, Kanchana Thilakarathna, Nirhoshan Sivaroopan, Jack Yang, Wangli Yang
  - **institution:** Western Sydney University, University of New South Wales Canberra, The University of Sydney, University of Wollongong
  - **link:** https://arxiv.org/pdf/2512.23779
  - **contributions:** 1. Introduces a black-box, query-only benchmark for evaluating prompt-induced denial-of-service attacks on LLMs. 2. Proposes two novel prompt-only attackers: an evolutionary search method (EOGen) and a goal-conditioned reinforcement learning method (RL-GOAL). 3. Defines the Over-Generation Factor (OGF) as a key metric to quantify attack success and characterize model vulnerability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3002b15ce3957d88befc241c59f1be73a9e49f4e8ad4c345e9d472f11883059e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of denial-of-service attacks on large language models via prompt-induced over-generation. It proposes a standardized black-box benchmark and two automated attack methods, EOGen and RL-GOAL, to find adversarial prefixes that delay model termination. The results show that the RL-GOAL attacker is particularly effective at forcing models to generate excessively long outputs, highlighting a significant vulnerability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Prompt-Induced Over-Generation as Denial-of-Service<br/>提示诱导过度生成作为拒绝服务攻击] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br/>LLM过度生成导致服务拒绝、延迟和成本增加]
        C[主要方法/Method<br/>黑盒基准与两种攻击者: EOGen(进化搜索)和RL-GOAL(强化学习)]
        D[关键结果/Results<br/>RL-GOAL攻击者实现更高的平均过度生成因子(OGF)]
    ```

- **[arXiv260101] FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading**
  - **tags:** [ai], [reinforcement learning], [ensemble reinforcement learning, selective update, variational autoencoder, high-frequency trading, risk management]
  - **authors:** Molei Qin, Xinyu Cai, Yewen Li, Haochong Xia, Chuqiao Zong, Shuo Sun, Xinrun Wang, Bo An
  - **institution:** Nanyang Technological University, Singapore Management University, Hong Kong University of Science and Technology (Guangzhou)
  - **link:** https://arxiv.org/pdf/2512.23773
  - **contributions:** 1. A selective update mechanism for ensemble Q-learners using ensemble TD errors to stabilize training and improve convergence in high-leverage environments. 2. A risk-aware filtering and routing mechanism that uses VAEs to model market state dynamics and identify agent capability boundaries, enabling dynamic policy selection to mitigate risk. 3. A novel three-stage ensemble RL framework (FineFT) that integrates stable training and risk management, demonstrating superior profitability and over 40% risk reduction in crypto futures trading.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c036ba975592c2c3be9068e742ccd28ed5b9722ff62085fbcc37e9f3627fe370_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes FineFT, a three-stage ensemble reinforcement learning framework designed to address the challenges of high leverage and unseen market states in futures trading. The method uses selective updates for stable training and VAEs for risk-aware policy routing, achieving higher profitability and significantly lower risk compared to state-of-the-art baselines in high-frequency crypto futures experiments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FineFT: Efficient and Risk-Aware Ensemble RL for Futures Trading] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[高杠杆放大波动/High leverage amplifies reward fluctuations]
        B --> B2[缺乏能力边界意识/Lack of self-awareness of capability boundaries]
        C --> C1[阶段I: 选择性更新/Stage I: Selective Update]
        C --> C2[阶段II: 过滤与VAE训练/Stage II: Filtering & VAE Training]
        C --> C3[阶段III: 动态路由/Stage III: Dynamic Routing]
        D --> D1[超越12个SOTA基线/Outperforms 12 SOTA baselines]
        D --> D2[风险降低超40%/Risk reduced by >40%]
        D --> D3[实现更高盈利/Achieves superior profitability]
    ```

- **[arXiv260101] Max-Entropy Reinforcement Learning with Flow Matching and A Case Study on LQR**
  - **tags:** [ai], [reinforcement learning], [max-entropy reinforcement learning, flow-based policy, flow matching, soft actor-critic, linear quadratic regulator]
  - **authors:** Yuyang Zhang, Yang Hu, Bo Dai, Na Li
  - **institution:** Harvard University, Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.23870
  - **contributions:** 1. Proposes a variant of the Soft Actor-Critic (SAC) algorithm that uses flow-based models to parameterize the policy, enhancing expressiveness. 2. Introduces an online variant of flow matching called Importance Sampling Flow Matching (ISFM) for policy updates using samples from a user-specified distribution instead of the unknown target. 3. Provides a theoretical analysis of ISFM, characterizing how the choice of sampling distribution impacts learning efficiency, and validates the method with a case study on max-entropy Linear Quadratic Regulator (LQR) problems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d43d8f718c30e1679c2274346eea229b95864ab6207cedce0e09dc784832028_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of simple policy approximations in max-entropy reinforcement learning by proposing a new SAC variant that uses expressive flow-based policies. The method employs a novel online flow matching technique (ISFM) for efficient policy updates and demonstrates its effectiveness by learning the optimal action distribution in max-entropy LQR problems.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Max-Entropy RL with Flow Matching and LQR Case Study] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[SAC使用简单策略类牺牲了表达性和鲁棒性/SAC's simple policy classes sacrifice expressiveness & robustness]
        Method[主要方法/Method] --> M1[提出使用流模型参数化策略的SAC变体/Propose SAC variant with flow-based policy]
        Method --> M2[开发在线流匹配变体ISFM进行策略更新/Develop online flow matching variant ISFM for policy update]
        Results[关键结果/Results] --> R1[理论分析ISFM采样分布的影响/Theoretical analysis of ISFM sampling distribution impact]
        Results --> R2[在最大熵LQR问题上验证算法有效性/Validate algorithm on max-entropy LQR problems]
    ```

- **[arXiv260101] Distributed Beamforming in Massive MIMO Communication for a Constellation of Airborne Platform Stations**
  - **tags:** [sys], [communication & networking], [distributed beamforming, multi-agent deep reinforcement learning, massive MIMO, aerial platform stations, channel state information]
  - **authors:** Hesam Khoshkbari, Georges Kaddoum, Bassant Selim, Omid Abbasi, Halim Yanikomeroglu
  - **institution:** École de technologie supérieure, Carleton University
  - **link:** https://arxiv.org/pdf/2512.23900
  - **contributions:** 1. Proposes a distributed beamforming framework for massive MIMO networks using a constellation of aerial platform stations (APSs) without requiring CSI sharing among agents, reducing overhead. 2. Introduces an entropy-based multi-agent deep reinforcement learning (DRL) model where each APS acts as an independent agent, capable of operating with imperfect channel state information (CSI). 3. Demonstrates through simulations that the proposed method outperforms conventional techniques like ZF and MRT in high-interference scenarios and shows robustness to CSI errors and scalability with increasing users.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58d49692981b3fd19b522f0e296bc9eed43c81e4a2c2f5a5b23a0691d21b1d5a_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a distributed beamforming framework for massive MIMO networks using a constellation of aerial platforms. It employs an entropy-based multi-agent deep reinforcement learning model where each platform acts independently without sharing channel state information, reducing overhead. Simulation results show the method outperforms traditional beamforming techniques in high-interference environments and remains robust and scalable.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Distributed Beamforming for Airborne Platform Stations<br/>分布式波束赋形用于空中平台站"] --> Problem["Beamforming & Interference in NTBS Networks<br/>NTBS网络中的波束赋形与干扰"]
        Root --> Method["Entropy-based Multi-agent DRL without CSI Sharing<br/>无需CSI共享的基于熵的多智能体DRL"]
        Root --> Results["Outperforms ZF/MRT, Robust, Scalable<br/>优于ZF/MRT，鲁棒，可扩展"]
    ```

- **[arXiv260101] Constraint Breeds Generalization: Temporal Dynamics as an Inductive Bias**
  - **tags:** [ai], [neuromorphic computing], [temporal inductive bias, dissipative dynamics, spiking neural networks, generalization, phase-space analysis]
  - **authors:** Xia Chen
  - **institution:** Technische Universität München (Georg Nemetschek Institute, Munich Data Science Institute)
  - **link:** https://arxiv.org/pdf/2512.23916
  - **contributions:** 1. Proposes that physical constraints (like metabolic budgets) act not as limitations but as a temporal inductive bias that promotes generalization in neural systems. 2. Reveals through phase-space analysis that proper dissipative dynamics compress the solution space and align with spectral bias to abstract invariant features, unlike expansive dynamics. 3. Empirically demonstrates across multiple tasks (classification, reconstruction, RL) that a critical "transition" regime of dynamical constraints maximizes generalization capability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b28592acb015fa66de83fc46eda200fa0018a58a31fbfacdf9dd0fced988bac9_w640_q70.webp
  - **Simple LLM Summary:** The paper argues that physical constraints, often seen as limitations, can serve as a beneficial temporal inductive bias for generalization in neural networks. It analyzes signal propagation to show that dissipative dynamics compress phase space and abstract features, a principle implemented using Spiking Neural Networks. Experiments across various tasks confirm that properly constrained temporal dynamics maximize generalization, suggesting a new direction for robust AI development.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["Constraint Breeds Generalization: Temporal Dynamics as an Inductive Bias"] --> B["核心问题/Problem: Conventional deep learning uses unconstrained optimization, unlike biologically constrained systems."]
        A --> C["主要方法/Method: Propose temporal constraints as inductive bias; analyze phase-space dynamics; use Spiking Neural Networks (SNNs) for temporal integration."]
        A --> D["关键结果/Results: Dissipative dynamics maximize generalization; a critical 'transition' regime is identified across tasks."]
    ```

- **[arXiv260101] CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards**
  - **tags:** [nlp], [spelling correction], [reinforcement learning, zero-supervision, Chinese spelling correction, PPO, cluster-consensus reward]
  - **authors:** Zhiming Lin, Kai Zhao, Sophie Zhang, Peilai Yu, Canran Xiao
  - **institution:** Nankai University, Western Sydney University, Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.23971
  - **contributions:** 1. Proposes CEC-Zero, a zero-supervision RL framework for Chinese spelling correction that enables LLMs to self-correct without labeled data. 2. Introduces a cluster-consensus reward mechanism based on semantic similarity and candidate agreement to guide policy optimization. 3. Demonstrates superior performance over supervised and fine-tuned LLM baselines across multiple benchmarks, establishing a label-free paradigm.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f497dc978d283e6c34450b390462e1f0ee33c507d41a14f70226f631c7d28168_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of Chinese spelling correction (CSC) by introducing CEC-Zero, a zero-supervision reinforcement learning framework. The method synthesizes errors from clean text and uses a novel cluster-consensus reward to optimize an LLM policy with PPO, eliminating the need for costly annotations. It significantly outperforms existing supervised and fine-tuned methods on multiple benchmarks, offering a robust and scalable solution for real-world noisy text processing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards] --> B[核心问题/Problem: 大规模中文拼写纠错依赖昂贵标注，现有方法对新型错误不鲁棒/Large-scale Chinese spelling correction relies on costly annotations; existing methods lack robustness to novel errors.]
        A --> C[主要方法/Method: 提出零监督强化学习框架，合成错误输入，使用聚类共识奖励和PPO优化/Proposes a zero-supervision RL framework, synthesizes errorful inputs, uses cluster-consensus rewards and PPO for optimization.]
        A --> D[关键结果/Results: 在9个基准测试上超越监督基线10-13 F1点，超越LLM微调5-8点/Outperforms supervised baselines by 10-13 F1 points and strong LLM fine-tunes by 5-8 points across 9 benchmarks.]
    ```

- **[arXiv260101] RSAgent: Learning to Reason and Act for Text-Guided Segmentation via Multi-Turn Tool Invocations**
  - **tags:** [cv], [text-guided segmentation], [agentic MLLM, multi-turn tool invocation, iterative mask refinement]
  - **authors:** Xingqi He, Yujie Zhang, Shuyong Gao, Wenjie Li, Lingyi Hong, Mingxi Chen, Kaixun Jiang, Jiyuan Fu, Wenqiang Zhang
  - **institution:** Fudan University, Shanghai Jiao Tong University School of Medicine
  - **link:** https://arxiv.org/pdf/2512.24023
  - **contributions:** 1. Proposes RSAgent, an agentic MLLM that interleaves reasoning and action for segmentation via multi-turn tool invocations, enabling iterative refinement. 2. Builds a data pipeline to synthesize multi-turn reasoning segmentation trajectories for training. 3. Introduces a two-stage training framework combining cold-start supervised fine-tuning with agentic reinforcement learning using fine-grained, task-specific rewards.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/492283683a8b1ec7673cb4aa97997d0e1ab70ed4a074c17cfa6a9a5e87c60998_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limitation of one-shot methods in text-guided segmentation, where initial errors cannot be corrected. It proposes RSAgent, an agentic multimodal LLM that iteratively uses a segmentation toolbox, observes feedback, and refines its spatial hypotheses over multiple turns. Experiments show RSAgent achieves state-of-the-art performance on benchmarks like ReasonSeg and RefCOCOg.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RSAgent: Learning to Reason and Act for Text-Guided Segmentation] --> B[核心问题/Problem: One-shot grounding methods lack verification and refinement capabilities]
        A --> C[主要方法/Method: Agentic MLLM with multi-turn tool invocation for iterative reasoning and mask refinement]
        A --> D[关键结果/Results: Achieves SOTA on benchmarks (66.5% gIoU on ReasonSeg, 81.5% cIoU on RefCOCOg)]
    ```

- **[arXiv260101] Reinforced Diffusion: Learning to Push the Limits of Anisotropic Diffusion for Image Denoising**
  - **tags:** [cv], [image denoising], [anisotropic diffusion, reinforcement learning, deep Q-learning, stochastic diffusion]
  - **authors:** Xinran Qin, Yuhui Quan, Ruotao Xu, Hui Ji
  - **institution:** South China University of Technology, National University of Singapore
  - **link:** https://arxiv.org/pdf/2512.24035
  - **contributions:** 1. A trainable anisotropic diffusion framework for image denoising based on reinforcement learning. 2. Modeling the denoising process as a series of diffusion actions with order learned by deep Q-learning, forming a stochastic anisotropic diffusion process. 3. Demonstrating that the proposed method outperforms existing diffusion-based methods and competes with deep CNN-based methods on multiple noise types.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3be25ff96e1d5d489676fdfbae564029c066808ffe1f445710f3d58c023ed964_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a novel image denoising method called Reinforced Diffusion, which uses deep reinforcement learning (deep Q-learning) to learn the optimal sequence of naive diffusion actions, forming an adaptive stochastic anisotropic diffusion process. This approach overcomes the limitations of traditional fixed diffusion operators. Experimental results show it outperforms other diffusion-based methods and is competitive with state-of-the-art deep CNN-based denoisers.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Reinforced Diffusion: Image Denoising] --> B(核心问题/Problem: Traditional anisotropic diffusion has limited performance due to non-adaptive operators.)
        A --> C(主要方法/Method: Trainable diffusion framework using Deep Q-Learning to learn action sequences.)
        A --> D(关键结果/Results: Outperforms diffusion-based methods, competes with deep CNN methods.)
    ```

- **[arXiv260101] ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment**
  - **tags:** [mlsys], [agent system], [prompt optimization, multi-agent architecture, decision tree protocols, zero-shot alignment, automated debugging]
  - **authors:** Natchaya Temyingyong, Daman Jain, Neeraj Kumarsahu, Prabhat Kumar, Rachata Phondi, Wachiravit Modecrua, Krittanon Kaewtawee, Krittin Pachtrachai, Touchapon Kraisingkorn
  - **institution:** Amity AI Research and Application Center
  - **link:** https://arxiv.org/pdf/2512.24040
  - **contributions:** 1. Introduces ROAD, a novel framework that treats prompt optimization as a dynamic debugging investigation, eliminating the need for curated gold-standard datasets. 2. Proposes a specialized multi-agent architecture (Analyzer, Optimizer, Coach) to convert unstructured failure logs into structured Decision Tree Protocols. 3. Demonstrates high sample efficiency and performance improvements on both academic benchmarks and a live production system, offering a data-efficient alternative to RL-based methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b2d710802d4ef2f4627a2a20e4c9834618953664f1165bf78a33477b890319f_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of optimizing LLM agents without requiring large, labeled datasets, which are often unavailable in real-world software engineering. It proposes ROAD, a framework that uses a multi-agent architecture to perform automated debugging on failure logs, converting them into structured protocols for improvement. The results show that ROAD is highly sample-efficient and significantly improves agent performance, providing a practical alternative to resource-intensive training methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ROAD: Reflective Optimization via Automated Debugging] --> B[核心问题/Problem: APO methods need large labeled datasets, but real-world has messy logs]
        A --> C[主要方法/Method: Multi-agent debugging (Analyzer, Optimizer, Coach) to create Decision Tree Protocols]
        A --> D[关键结果/Results: Sample-efficient, +5.6% success rate, +19% performance on complex tasks]
    ```

- **[arXiv260101] HY-MT1.5 Technical Report**
  - **tags:** [nlp], [machine translation], [holistic training framework, on-policy distillation, parameter efficiency]
  - **authors:** Mao Zheng, Zheng Li, Tao Chen, Mingyang Song, Di Wang
  - **institution:** Tencent Hunyuan Team
  - **link:** https://arxiv.org/pdf/2512.24092
  - **code:** https://github.com/Tencent-Hunyuan/HY-MT
  - **contributions:** 1. Introduces HY-MT1.5-1.8B and HY-MT1.5-7B, a new family of high-performance machine translation models. 2. Proposes a holistic multi-stage training framework integrating general/MT pre-training, supervised fine-tuning, on-policy distillation, and reinforcement learning. 3. Demonstrates state-of-the-art performance, with the 1.8B model achieving remarkable parameter efficiency and the 7B model surpassing ultra-large proprietary models on challenging benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ef782a5a818ae655e93a8b8755b15f73eb04f3d46c041e15eb5c4a26d7b05b1_w640_q70.webp
  - **Simple LLM Summary:** This report introduces the HY-MT1.5 series of machine translation models, developed using a holistic multi-stage training pipeline. The models, particularly the 1.8B parameter version, show exceptional parameter efficiency, outperforming much larger models and commercial APIs, while the 7B model sets a new state-of-the-art for its size class.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HY-MT1.5 Technical Report] --> B[核心问题/Problem: 高性能机器翻译/High-performance Machine Translation]
        A --> C[主要方法/Method: 整体训练框架/Holistic Training Framework]
        C --> C1[多阶段管道/Multi-stage Pipeline]
        C1 --> C1a[预训练/Pre-training]
        C1 --> C1b[监督微调/Supervised Fine-tuning]
        C1 --> C1c[策略蒸馏/On-policy Distillation]
        C1 --> C1d[强化学习/Reinforcement Learning]
        A --> D[关键结果/Results: 卓越性能与效率/Outstanding Performance & Efficiency]
        D --> D1[HY-MT1.5-1.8B: 参数高效/Parameter Efficient]
        D --> D2[HY-MT1.5-7B: 新SOTA/New SOTA]
    ```

- **[arXiv260101] GARDO: Reinforcing Diffusion Models without Reward Hacking**
  - **tags:** [ai], [reinforcement learning], [reward hacking, diffusion models, regularization, mode collapse, online RL]
  - **authors:** Haoran He, Yuxiao Ye, Jie Liu, Jiajun Liang, Zhiyong Wang, Ziyang Yuan, Xintao Wang, Hangyu Mao, Pengfei Wan, Ling Pan
  - **institution:** Hong Kong University of Science and Technology, Kuaishou Technology, CUHK MMLab, The University of Edinburgh
  - **link:** https://arxiv.org/pdf/2512.24138
  - **code:** https://tinnerhrhe.github.io/gardo_project
  - **contributions:** 1. Proposed GARDO, a framework with gated regularization that selectively penalizes high-uncertainty samples to mitigate reward hacking efficiently., 2. Introduced an adaptive regularization mechanism that periodically updates the reference model to align with the online policy, enabling effective exploration., 3. Designed a diversity-aware reward amplification strategy to encourage mode coverage and prevent diversity collapse during RL fine-tuning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df8973aa0f222e89b818973c0c7ef576738632b0095b29ac1f837f1a83f47f9b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of reward hacking in RL-fine-tuned diffusion models, where optimizing imperfect proxy rewards degrades real image quality and diversity. The authors propose GARDO, a framework featuring gated, adaptive regularization and diversity-aware optimization to prevent overfitting, maintain exploration, and enhance diversity. Experiments show GARDO effectively mitigates reward hacking and improves generation diversity without sacrificing sample efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GARDO: Reinforcing Diffusion Models without Reward Hacking] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Reward Hacking in RL for Diffusion Models/扩散模型RL中的奖励破解]
        B --> B2[Proxy Reward Mismatch & Mode Collapse/代理奖励不匹配与模式崩溃]
        C --> C1[Gated & Adaptive Regularization/门控自适应正则化]
        C --> C2[Diversity-aware Reward Optimization/多样性感知奖励优化]
        D --> D1[Mitigates Reward Hacking/缓解奖励破解]
        D --> D2[Enhances Diversity & Maintains Efficiency/提升多样性并保持效率]
    ```

- **[arXiv260101] Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning**
  - **tags:** [cv], [diffusion models], [Preference Mode Collapse, Reinforcement Learning from Human Feedback, reward hacking, generative diversity, directional correction]
  - **authors:** Chubin Chen, Sujie Hu, Jiashu Zhu, Meiqi Wu, Jintao Chen, Yanxun Li, Nisha Huang, Chengyu Fang, Jiahong Wu, Xiangxiang Chu, Xiu Li
  - **institution:** Tsinghua University, AMAP, Alibaba Group
  - **link:** https://arxiv.org/pdf/2512.24146
  - **contributions:** 1. Introduces and quantifies the phenomenon of Preference Mode Collapse (PMC) in diffusion model alignment. 2. Proposes DivGenBench, a novel benchmark to measure the extent of PMC. 3. Proposes the Directional Decoupling Alignment (D²-Align) framework to mitigate PMC by directionally correcting the reward signal.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f62594e4cc99762132258ccba4873b41aea26a85dbeb402b03da55458d0e32bf_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies Preference Mode Collapse (PMC), where diffusion models over-optimize for reward scores and lose generative diversity. To address this, the authors propose D²-Align, a framework that learns a directional correction to the reward signal to prevent collapse. The method achieves better alignment with human preference while preserving output diversity.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题/Paper Title: Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Preference Mode Collapse (PMC)导致生成多样性下降/PMC degrades generative diversity]
        C[主要方法/Method: 提出D²-Align框架，方向性校正奖励信号/Proposes D²-Align framework to directionally correct reward signal]
        D[关键结果/Results: 在保持多样性的同时实现更好的人类偏好对齐/Achieves better human preference alignment while preserving diversity]
    ```

- **[arXiv260101] Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem**
  - **tags:** [ai], [reinforcement learning], [Fleet Size and Mix Vehicle Routing Problem (FSMVRP), deep reinforcement learning (DRL), Markov Decision Process (MDP), fleet-and-route integrated policy network (FRIPN), remaining graph embedding]
  - **authors:** Pengfu Wan, Jiawei Chen, Gangyan Xu
  - **institution:** The Hong Kong Polytechnic University
  - **link:** https://arxiv.org/pdf/2512.24251
  - **contributions:** 1. Formulates the Fleet Size and Mix Vehicle Routing Problem (FSMVRP) as a Markov Decision Process (MDP) for a deep reinforcement learning approach. 2. Proposes a novel policy network (FRIPN) that integrates fleet composition and routing decisions into a single model. 3. Introduces specialized input embeddings, including a remaining graph embedding, to enhance decision-making for vehicle employment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3969891b48accce35280355d106951820196973739958b782a307a2a3df23aa3_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a deep reinforcement learning method to solve the complex Fleet Size and Mix Vehicle Routing Problem (FSMVRP). The core innovation is a policy network called FRIPN that jointly decides on fleet composition and routing. Experiments show the method is computationally efficient and scalable, producing near-optimal solutions quickly, especially for large-scale problems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem] --> B(核心问题/Problem: FSMVRP - simultaneous fleet composition & routing)
        A --> C(主要方法/Method: DRL-based MDP formulation with FRIPN policy network & remaining graph embedding)
        A --> D(关键结果/Results: Near-optimal solutions in seconds, high computational efficiency & scalability)
    ```

- **[arXiv260101] DRL-TH: Jointly Utilizing Temporal Graph Attention and Hierarchical Fusion for UGV Navigation in Crowded Environments**
  - **tags:** [ai], [reinforcement learning], [temporal graph attention, hierarchical graph pooling, multi-modal fusion, UGV navigation, deep reinforcement learning]
  - **authors:** Ruitong Li, Lin Zhang, Yuenan Zhao, Chengxin Liu, Ran Song, Wei Zhang
  - **institution:** The affiliations are not explicitly provided in the given content. Based on the author names, it is not possible to reliably infer the main research institution(s).
  - **link:** https://arxiv.org/pdf/2512.24284
  - **contributions:** 1. Proposed a DRL-based navigation framework (DRL-TH) that integrates historical observations and adaptively fuses multi-modal information. 2. Introduced a Temporal-Guided Graph Attention Network (TG-GAT) to capture temporal context and scene evolution between consecutive frames. 3. Designed a Graph Hierarchical Abstraction Module (GHAM) to dynamically and balance multi-scale representations from RGB and LiDAR features.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83abe1de24f9a7e490d93db45dec754f2a2ff7f3de84d6e6983a358e1d9dff40_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes DRL-TH, a deep reinforcement learning framework for UGV navigation in crowded environments. It addresses limitations of single-frame observation and simple fusion by introducing a temporal graph attention network and a hierarchical graph pooling module for adaptive multi-modal feature integration. Experiments and real-world deployment show that DRL-TH outperforms existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[DRL-TH: UGV导航框架] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[单帧观测/Single-frame observation]
        Problem --> P2[简单多模态融合/Simple multi-modal fusion]
        P1 --> P1_Sub[限制动态适应性/Limits dynamic adaptability]
        P2 --> P2_Sub[难以捕捉时序上下文/Hard to capture temporal context]
        Method[主要方法/Method] --> M1[时序引导图注意力网络/Temporal-Guided GAT (TG-GAT)]
        Method --> M2[图层次抽象模块/Graph Hierarchical Abstraction Module (GHAM)]
        M1 --> M1_Sub[捕捉连续帧关联/Captures correlations between consecutive frames]
        M2 --> M2_Sub[动态融合RGB与LiDAR特征/Dynamically fuses RGB & LiDAR features]
        Results[关键结果/Results] --> R1[性能超越现有方法/Outperforms existing methods]
        Results --> R2[真实UGV上表现良好/Performs well on real UGV]
    ```

- **[arXiv260101] Real-world Reinforcement Learning from Suboptimal Interventions**
  - **tags:** [ai], [reinforcement learning], [human-in-the-loop RL, constrained RL, state-wise Lagrangian, suboptimal interventions, robotic manipulation]
  - **authors:** Yinuo Zhao, Huiqian Jin, Lechun Jiang, Xinyi Zhang, Kun Wu, Pei Ren, Zhiyuan Xu, Zhengping Che, Lei Sun, Dapeng Wu, Chi Harold Liu, Jian Tang
  - **institution:** Beijing Innovation Center of Humanoid Robotics, City University of Hong Kong, Nankai University, Beijing Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.24288
  - **contributions:** 1. Proposes SiLRI, a state-wise Lagrangian RL algorithm that formulates the online manipulation problem as a constrained RL optimization where constraint bounds are determined by the uncertainty of human interventions. 2. Introduces a state-wise Lagrange multiplier and solves the problem via a min-max optimization to jointly optimize the policy and the multiplier, enabling exploitation of suboptimal interventions without being constrained by them. 3. Demonstrates through real-world experiments that SiLRI significantly accelerates learning, reducing time to 90% success rate by at least 50% compared to prior methods and achieving 100% success on long-horizon tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f15ba64d7b2d7760e2411270a47d97305fe1e21ad798c2423cb89a0e5cb5750_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of leveraging suboptimal human interventions to accelerate real-world robotic RL without being limited by them. It proposes SiLRI, a state-wise Lagrangian RL algorithm that treats interventions as state-dependent constraints and solves a min-max optimization. Real-world experiments show SiLRI cuts learning time by over 50% and achieves perfect success on complex tasks where other methods fail.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Real-world Reinforcement Learning from Suboptimal Interventions] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 如何利用可能次优的人类干预加速学习而不受其限制/How to leverage potentially suboptimal human interventions to accelerate learning without being constrained by them]
        C[主要方法/Method: 提出SiLRI，一种基于状态拉格朗日的RL算法，将干预不确定性作为约束/Propose SiLRI, a state-wise Lagrangian RL algorithm treating intervention uncertainty as constraints]
        D[关键结果/Results: 学习速度提升>50%，在长视野任务上达到100%成功率/Learning speed improved >50%, achieved 100% success rate on long-horizon tasks]
    ```

- **[arXiv260101] Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking**
  - **tags:** [ai], [multimodal reasoning], [visual thinking, reinforcement learning, chain-of-thought, geometric reasoning, multimodal integration]
  - **authors:** Meiqi Chen, Fandong Meng, Jie Zhou
  - **institution:** Tencent Inc (WeChat AI)
  - **link:** https://arxiv.org/pdf/2512.24297
  - **contributions:** 1. Introduces FIGR, a novel method that integrates active visual thinking into multi-step reasoning via end-to-end reinforcement learning. 2. Proposes a mechanism to adaptively regulate when and how to invoke visual reasoning, externalizing structural hypotheses by constructing visual representations. 3. Demonstrates significant performance improvements on challenging mathematical reasoning benchmarks, enhancing the stability and reliability of complex reasoning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87f7f4c5ac39e44125cddcd070468c932e7b1c2ea80095ffe3322857f26d40ed_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces FIGR, a method that enhances complex reasoning by integrating active visual thinking through reinforcement learning, allowing models to construct visual diagrams during problem-solving. It adaptively decides when to use visual reasoning to better capture spatial and structural relationships. Experiments show FIGR outperforms text-only baselines on mathematical reasoning benchmarks, improving stability and reliability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Text-based reasoning struggles with implicit spatial and structural relationships.]
        Method[主要方法/Method: FIGR integrates active visual thinking via RL to construct visual representations adaptively.]
        Results[关键结果/Results: Outperforms text-only baselines, improves stability and reliability on math benchmarks.]
    ```

- **[arXiv260101] MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems**
  - **tags:** [mlsys], [agent system], [Multi-Agent Reinforcement Learning, Centralized Training with Decentralized Execution (CTDE), Model Predictive Control (MPC), Dynamic Computation Allocation, Recommender Systems]
  - **authors:** Wan Jiang, Xinyi Zang, Yudong Zhao, Yusi Zou, Yunfei Lu, Junbo Tong, Yang Liu, Ming Li, Jiani Shi, Xin Yang
  - **institution:** JD.com, Tsinghua University
  - **link:** https://arxiv.org/pdf/2512.24325
  - **contributions:** 1. Proposes MaRCA, a multi-agent reinforcement learning framework that models recommender system stages as cooperative agents for end-to-end computation resource allocation. 2. Introduces an AutoBucket TestBench for accurate computation cost estimation in large-scale systems. 3. Designs a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5648d9986b292c2db26fc1ddb4325c3fc0f14c6516ddecf792ceaf524e365c4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of dynamic computation allocation in large-scale, multi-stage recommender systems under resource constraints. It proposes MaRCA, a multi-agent reinforcement learning framework that uses Centralized Training with Decentralized Execution (CTDE) and integrates a Model Predictive Control-based balancer to optimize revenue. The system was deployed on a major e-commerce platform, handling hundreds of billions of daily requests and achieving a 16.67% revenue uplift using existing resources.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MaRCA: Multi-Agent RL for Dynamic Computation Allocation] --> B[核心问题/Problem: 大规模推荐系统中，模型复杂度和流量规模增长带来的计算挑战，现有方法忽略阶段间依赖，限制全局最优性。]
        A --> C[主要方法/Method: 提出MaRCA框架，将推荐系统阶段建模为合作智能体，使用CTDE进行训练，并引入AutoBucket TestBench和基于MPC的收益-成本平衡器。]
        A --> D[关键结果/Results: 在领先的全球电商平台广告管线中端到端部署，每日处理数千亿广告请求，使用现有计算资源实现16.67%的收益提升。]
    ```

- **[arXiv260101] SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning**
  - **tags:** [mlsys], [agent system], [multimodal agent, reinforcement learning, tool-use, policy optimization, benchmark]
  - **authors:** Yong Xien Chng, Tao Hu, Wenwen Tong, Xueheng Li, Jiandong Chen, Haojia Yu, Jiefan Lu, Hewei Guo, Hanming Deng, Chengjun Xie, Gao Huang, Dahua Lin, Lewei Lu
  - **institution:** SenseTime Research, Tsinghua University, University of Science and Technology of China
  - **link:** https://arxiv.org/pdf/2512.24330
  - **code:** https://github.com/OpenSenseNova/SenseNova-MARS
  - **contributions:** 1. Introduces SenseNova-MARS, a novel framework that empowers Vision-Language Models (VLMs) with interleaved visual reasoning and tool-use capabilities via Reinforcement Learning (RL). 2. Proposes the Batch-Normalized Group Sequence Policy Optimization (BN-GSPO) algorithm to improve RL training stability and enhance the model's ability to invoke tools and reason effectively. 3. Introduces the HR-MMSearch benchmark, the first search-oriented benchmark composed of high-resolution images with knowledge-intensive and search-driven questions, for evaluating agentic VLMs on complex visual tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a82c0f2ba917fb46c8e884b39cb5c9d4a0a7e1d4671707b44bf5a18d77fa8e73_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces SenseNova-MARS, a framework that uses reinforcement learning to enable Vision-Language Models to dynamically interleave reasoning with external tools like search and image cropping. The proposed BN-GSPO algorithm improves training stability and tool-use capability. Experiments show the model achieves state-of-the-art performance on search and fine-grained image understanding benchmarks, even surpassing some proprietary models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SenseNova-MARS] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[VLMs缺乏动态工具调用与推理交织的能力/VLMs lack dynamic interleaving of tool-use and reasoning]
        C --> C1[提出BN-GSPO强化学习算法/Propose BN-GSPO RL algorithm]
        C --> C2[集成图像搜索、文本搜索、图像裁剪工具/Integrate image search, text search, image crop tools]
        D --> D1[在MMSearch和HR-MMSearch上SOTA/Achieves SOTA on MMSearch and HR-MMSearch]
        D --> D2[超越Gemini-3-Flash和GPT-5/Surpasses proprietary models like Gemini-3-Flash and GPT-5]
    ```

- **[arXiv260101] Efficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models**
  - **tags:** [ai], [reinforcement learning], [inverse reinforcement learning, dynamic discrete choice, semiparametric inference, debiased machine learning, efficient influence function]
  - **authors:** Lars van der Laan, Aurelien Bibaut, Nathan Kallus
  - **institution:** University of Washington, Netflix Research, Cornell University
  - **link:** https://arxiv.org/pdf/2512.24407
  - **contributions:** 1. Introduced a semiparametric framework for debiased inverse reinforcement learning that enables statistically efficient inference for reward-dependent functionals. 2. Showed that the log-behavior policy acts as a pseudo-reward that identifies policy value differences and, with normalization, the reward itself, formalizing these as smooth functionals. 3. Constructed automatic debiased machine-learning estimators that allow flexible nonparametric nuisance estimation while achieving √n-consistency, asymptotic normality, and semiparametric efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f071bfe838a84ec68caefb3e8f32ddce9a94446707278cc78a1f8f23d2b1cdcf_w640_q70.webp
  - **Simple LLM Summary:** This paper develops a unified semiparametric framework for inference in inverse reinforcement learning and dynamic discrete choice models. The method leverages the log-behavior policy as a pseudo-reward and constructs debiased machine learning estimators, enabling flexible nonparametric estimation while providing statistical guarantees like asymptotic normality and efficiency. The framework bridges classical econometric inference with modern machine learning tools for sequential decision-making problems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Efficient Inference for IRL and DDC Models] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Flexible IRL lacks inference guarantees;<br>Classical DDC is restrictive & computationally heavy]
        C[主要方法/Method<br>Semiparametric debiased IRL framework;<br>Log-behavior policy as pseudo-reward;<br>Automatic debiased ML estimators]
        D[关键结果/Results<br>√n-consistent, asymptotically normal,<br>semiparametrically efficient inference;<br>Unified, tractable approach]
    ```

- **[arXiv260101] Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics**
  - **tags:** [ai], [adaptive learning], [bias-noise-alignment, diagnostic-driven adaptation, temporal-difference error, stabilized optimizer, actor-critic]
  - **authors:** Akash Samanta, Sheldon Williamson
  - **institution:** Ontario Tech University
  - **link:** https://arxiv.org/pdf/2512.24445
  - **contributions:** 1. Proposes a novel diagnostic-driven adaptive learning framework that decomposes error evolution into bias, noise, and alignment components. 2. Derives and instantiates the framework across multiple learning paradigms, including supervised optimization, actor-critic RL, and learned optimizers. 3. Establishes theoretical stability guarantees and bounded updates for the proposed diagnostic-driven methods under standard assumptions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fffef5a11b6873e7029659f1544c8ea507323fdf48462b3c7caeee1ffd63e30_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of unstable and slow learning in nonstationary environments by proposing a new framework that models error evolution through bias, noise, and alignment diagnostics. The method uses these online-computed diagnostics to guide and stabilize learning in optimization, reinforcement learning, and meta-learning. The work provides a unifying, interpretable foundation for reliable adaptation in dynamic settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics] --> B(核心问题/Problem: Learning instability in nonstationary environments)
        A --> C(主要方法/Method: Diagnostic-driven framework decomposing error into bias, noise, alignment)
        A --> D(关键结果/Results: Unifying control backbone for optimization/RL/learned optimizers with stability guarantees)
    ```

- **[arXiv260101] Networked Markets, Fragmented Data: Adaptive Graph Learning for Customer Risk Analytics and Policy Design**
  - **tags:** [mlsys], [federated learning], [federated graph neural network, cross-bank Personalized PageRank, hierarchical reinforcement learning]
  - **authors:** Lecheng Zheng, Jian Ni, Chris Zobel, John R Birge
  - **institution:** Virginia Tech, University of Chicago
  - **link:** https://arxiv.org/pdf/2512.24487
  - **contributions:** 1. A federated graph neural network framework for collaborative customer behavior modeling across competing financial institutions without sharing raw data. 2. Introduction of cross-bank Personalized PageRank for identifying coordinated behavioral clusters and providing interpretable network segmentation. 3. A hierarchical reinforcement learning mechanism for optimizing dynamic intervention targeting policies to balance risk prevention, customer friction, and operational costs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c47cc80a0132ed420b5c61d870561d1aa347aadfb05091a6bcecd09c9007954d_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes an integrated framework combining federated graph learning and reinforcement learning to address customer risk analytics in fragmented financial markets. The method enables collaborative modeling across institutions and optimizes intervention policies, significantly improving fraud detection rates and loss prevention compared to isolated or rule-based approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Networked Markets, Fragmented Data: Adaptive Graph Learning for Customer Risk Analytics and Policy Design"]
        Root --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["数据孤岛/Data Silos"]
        Problem --> P2["类别不平衡/Class Imbalance"]
        Problem --> P3["次优策略/Suboptimal Policies"]
        Method --> M1["联邦图神经网络/Federated GNN"]
        Method --> M2["跨银行个性化PageRank/Cross-bank PPR"]
        Method --> M3["分层强化学习/Hierarchical RL"]
        Results --> R1["降低错误率/Reduced Error Rates"]
        Results --> R2["提升损失预防/Improved Loss Prevention"]
        Results --> R3["市场特定阈值/Market-specific Thresholds"]
    ```

- **[arXiv260101] From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [spatial reasoning, LoRA, GRPO, supervised fine-tuning, reinforcement learning]
  - **authors:** Amir Tahmasbi, Sadegh Majidi, Kazem Taram, Aniket Bera
  - **institution:** Purdue University
  - **link:** https://arxiv.org/pdf/2512.24532
  - **contributions:** 1. A two-stage approach for multi-step spatial reasoning that first fine-tunes an LLM on atomic spatial transformations and then trains lightweight LoRA adapters via RL to compose these blocks for planning. 2. The creation of a synthetic ASCII-art dataset and a corresponding ASCII-based RL environment to support training and evaluation. 3. Demonstration that the proposed method outperforms baselines in both dynamic and static environments, with faster convergence and more stable training than end-to-end RL.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b19427bf120d4b89a11879461b589b7313caa689fdec51f99f516c6485aef495_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of multi-step spatial reasoning in LLMs by proposing a two-stage method: first, supervised fine-tuning on basic spatial transformations to build physics awareness, and then training LoRA adapters with reinforcement learning (GRPO) to learn planning policies. The approach is evaluated using a custom ASCII-art environment and is shown to outperform various baselines, converging faster and more stably than training from scratch with RL.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>LLMs struggle with spatial transformations and multi-step planning]
        C[主要方法/Method<br>Two-stage: SFT on spatial blocks, then RL (GRPO) with LoRA for planning]
        D[关键结果/Results<br>Outperforms baselines, faster convergence, stable training]
    ```

- **[arXiv260101] From Perception to Punchline: Empowering VLM with the Art of In-the-wild Meme**
  - **tags:** [ai], [multimodal generation], [vision-language models, chain-of-thought, reinforcement learning from human feedback]
  - **authors:** Xueyan Li, Yingyi Xue, Mengjie Jiang, Qingzi Zhu, Yazhe Niu
  - **institution:** Shanghai Artificial Intelligence Laboratory, Xi'an Jiaotong University, Columbia University, The Chinese University of Hong Kong MMLab
  - **link:** https://arxiv.org/pdf/2512.24555
  - **contributions:** 1. Proposes a hierarchical, multi-path Chain-of-Thought (CoT) method to enhance reasoning diversity for meme generation. 2. Introduces a group-wise pairwise reward model trained on memes sharing the same template to robustly capture subjective human humor preferences. 3. Develops a group-wise reinforcement learning optimization framework with a theoretical guarantee for monotonic improvement, enabling better alignment with human preferences.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51d7b92e3cbe88fcb46458e3ce7a303a30ccee8230eb6865946f2c654b707c34_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces HUMOR, a framework for generating humorous memes. It uses a hierarchical multi-path Chain-of-Thought to guide reasoning and a group-wise reward model with RL for preference alignment. Experiments show it improves reasoning diversity, alignment, and overall meme quality in VLMs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[From Perception to Punchline: Empowering VLM with the Art of In-the-wild Meme] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 超越监督的幽默梗图生成/Humorous meme generation beyond direct supervision]
        C[主要方法/Method: HUMOR框架/HUMOR Framework]
        D[关键结果/Results: 提升多样性、对齐性和质量/Improved diversity, alignment, and quality]
        C --> C1[分层多路径思维链/Hierarchical Multi-path CoT]
        C --> C2[基于分组的奖励模型与强化学习/Group-wise Reward Model & RL]
    ```

- **[arXiv260101] Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization**
  - **tags:** [mlsys], [agent system], [Dec-POMDP, CTDE, GRPO]
  - **authors:** Dong Qiu, Duo Xu, Limengxi Yue
  - **institution:** New England College, Northeastern University, University of Massachusetts Amherst
  - **link:** https://arxiv.org/pdf/2512.24609
  - **contributions:** 1. A reinforcement learning-augmented LLM agent framework that formulates multi-agent collaboration as a Dec-POMDP and uses CTDE. 2. The introduction of Group Relative Policy Optimization (GRPO) for jointly optimizing agent policies with global training signals. 3. A simplified joint reward function that balances task quality, speed, and coordination cost.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/251d4cfbf0941a0b6ad2b2a8b7158ec06789c4a7a60653f447034ce562d8c91d_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of collaborative awareness in LLMs for multi-agent settings by proposing a framework that combines reinforcement learning with LLMs, using a Dec-POMDP formulation and CTDE. It introduces GRPO for policy optimization and a balanced reward function. The method significantly outperforms baselines in collaborative writing and coding tasks, demonstrating improved speed, consistency, and success rates.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Reinforcement Learning-Augmented LLM Agents<br/>强化学习增强的LLM智能体] --> B[核心问题/Problem<br/>LLMs lack collaborative awareness in multi-agent settings<br/>LLM在多智能体环境中缺乏协作意识]
        A --> C[主要方法/Method<br/>Dec-POMDP & CTDE framework with GRPO and a simplified joint reward<br/>基于Dec-POMDP和CTDE的框架，使用GRPO和简化联合奖励]
        A --> D[关键结果/Results<br/>3x speedup, 98.7% writing consistency, 74.6% coding pass rate<br/>3倍速度提升，98.7%写作一致性，74.6%编码通过率]
    ```

- **[arXiv260101] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization**
  - **tags:** [mlsys], [agent system], [LLM agent framework, automated agent generation, hybrid policy optimization, in-context optimization, reinforcement learning]
  - **authors:** Yuchen Shi, Yuzheng Cai, Siqi Cai, Zihan Xu, Lichao Chen, Yulei Qin, Zhijian Zhou, Xiang Fei, Chaofan Qiu, Xiaoyu Tan, Gang Li, Zongyi Li, Haojia Lin, Guocan Cai, Yong Mao, Yunsheng Wu, Ke Li, Xing Sun
  - **institution:** Tencent (inferred from "TencentCloudADP" in GitHub URL)
  - **link:** https://arxiv.org/pdf/2512.24615
  - **code:** https://github.com/TencentCloudADP/youtu-agent
  - **contributions:** 1. A modular LLM agent framework (Youtu-Agent) with a structured configuration system for decoupling components and enabling automated synthesis. 2. Two agent generation paradigms: Workflow mode for standard tasks and Meta-Agent mode for complex tasks, capable of auto-generating tools and prompts. 3. A hybrid policy optimization system combining an in-context learning "Agent Practice" module and a scalable reinforcement learning "Agent RL" module for continuous agent evolution.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0414a5769d966ffb5a9f4428d4a182e5095ba0b107862d50c8224788df0caa46_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes Youtu-Agent, a framework to automate the generation and continuous optimization of LLM agents, addressing high configuration costs and static capabilities. It introduces structured configuration, automated generation paradigms, and a hybrid optimization system combining in-context learning and reinforcement learning. Experiments show state-of-the-art performance on several benchmarks and significant improvements in agent capabilities through automated synthesis and optimization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Youtu-Agent] --> B[核心问题 / Problem]
        A --> C[主要方法 / Method]
        A --> D[关键结果 / Results]
        B --> B1[高配置成本 / High Configuration Cost]
        B --> B2[静态能力 / Static Capabilities]
        C --> C1[结构化配置系统 / Structured Configuration System]
        C --> C2[自动化生成 / Automated Generation]
        C --> C21[工作流模式 / Workflow Mode]
        C --> C22[元智能体模式 / Meta-Agent Mode]
        C --> C3[混合策略优化 / Hybrid Policy Optimization]
        C --> C31[智能体实践 / Agent Practice]
        C --> C32[智能体强化学习 / Agent RL]
        D --> D1[SOTA性能 / SOTA Performance]
        D --> D2[高工具合成率 / High Tool Synthesis Rate]
        D --> D3[能力显著提升 / Significant Capability Improvement]
    ```

- **[arXiv260101] Hybrid Motion Planning with Deep Reinforcement Learning for Mobile Robot Navigation**
  - **tags:** [ai], [robot navigation], [hybrid motion planning, deep reinforcement learning, entity-aware reward, graph-based global planner, collision avoidance]
  - **authors:** Yury Kolomeytsev, Dmitry Golembiovsky
  - **institution:** Lomonosov Moscow State University
  - **link:** https://arxiv.org/pdf/2512.24651
  - **contributions:** 1. Proposes HMP-DRL, a hybrid framework integrating a graph-based global planner with a local DRL policy via checkpoints. 2. Introduces an entity-aware reward structure for the local planner to ensure social compliance by adjusting safety based on agent type. 3. Validates the method in a realistic simulation, showing superior performance in success rate, collision rate, and time to goal.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6963a6e6a0df2bf9e5857d6154c70386d9271eb85763359a237ce12c4881bec_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes HMP-DRL, a hybrid motion planning framework that combines a graph-based global planner for long-range pathfinding with a local Deep Reinforcement Learning policy for reactive, socially-compliant navigation. The method uses checkpoints to integrate the global path and an entity-aware reward function to dynamically adjust to different moving agents. Experiments in realistic simulation show it outperforms other methods in key navigation metrics, enhancing safety and reliability in complex environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Hybrid Motion Planning with Deep Reinforcement Learning for Mobile Robot Navigation] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统图规划器缺乏反应性/Traditional graph planners lack reactivity]
        B --> B2[深度强化学习方法缺乏全局上下文/DRL methods lack global context]
        C --> C1[混合框架HMP-DRL/Hybrid framework HMP-DRL]
        C1 --> C2[图规划器生成路径/Graph planner generates path]
        C1 --> C3[局部DRL策略使用检查点和实体感知奖励/Local DRL policy uses checkpoints & entity-aware reward]
        D --> D1[更高的成功率/Higher success rate]
        D --> D2[更低的碰撞率/Lower collision rate]
        D --> D3[更短的到达时间/Shorter time to goal]
    ```

- **[arXiv260101] RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence**
  - **tags:** [ai], [embodied ai / robotic manipulation], [imitation learning, offline reinforcement learning, multimodal dataset, bimanual manipulation, sim-to-real transfer]
  - **authors:** Chengkai Hou, Kun Wu, Jiaming Liu, Zhengping Che, Di Wu, Fei Liao, Guangrun Li, Jingyang He, Qiuxuan Feng, Zhao Jin, Chenyang Gu, Zhuoyang Liu, Nuowei Han, Xiangju Mi, Yaoxu Lv, Yankai Fu, Gaole Dai, Langzhe Gu, Tao Li, Yuheng Zhang, Yixue Zhang, Xinhua Wang, Shichao Fan, Meng Li, Zhen Zhao, Ning Liu, Zhiyuan Xu, Pei Ren, Junjie Ji, Haonan Liu, Kuan Cheng, Shanghang Zhang, Jian Tang
  - **institution:** Beijing Innovation Center of Humanoid Robotics, Peking University
  - **link:** https://arxiv.org/pdf/2512.24653
  - **contributions:** 1. Introduces RoboMIND 2.0, a large-scale, multimodal real-world dataset with over 310K dual-arm manipulation trajectories across diverse robots and tasks, including tactile and mobile manipulation data. 2. Provides high-fidelity digital twins and a complementary 20K-trajectory simulated dataset to facilitate robust sim-to-real transfer research. 3. Proposes the MIND-2 system, a hierarchical framework optimized via offline RL that integrates a high-level semantic planner and a low-level vision-language-action executor for complex task decomposition and execution.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1a0e9601e4aa64a92e289971771ed61ad7545ed91ce3194cf342f87d6636d96_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the scarcity of diverse, large-scale real-world robotic manipulation data by introducing the RoboMIND 2.0 dataset, which includes hundreds of thousands of bimanual and mobile manipulation trajectories. To leverage this data, the authors propose the MIND-2 system, a hierarchical framework that uses offline reinforcement learning to integrate high-level planning with low-level control. The work aims to significantly advance the generalization capabilities of embodied AI agents in long-horizon, contact-rich, and unstructured environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RoboMIND 2.0 论文 / RoboMIND 2.0 Paper] --> B
        A --> C
        A --> D
        B[核心问题 / Problem] --> B1[数据稀缺 / Scarcity of large-scale, diverse real-world robotic demonstrations]
        B --> B2[泛化能力有限 / Limited generalization in long-horizon bimanual and mobile manipulation]
        C[主要方法 / Method] --> C1[发布RoboMIND 2.0数据集 / Release RoboMIND 2.0 Dataset]
        C1 --> C1_1[31万+真实轨迹 / 310K+ real trajectories]
        C1 --> C1_2[触觉与移动数据 / Tactile & mobile data]
        C1 --> C1_3[数字孪生与仿真数据 / Digital twins & simulated data]
        C --> C2[提出MIND-2系统 / Propose MIND-2 System]
        C2 --> C2_1[高层语义规划器 / High-level semantic planner (MIND-2-VLM)]
        C2 --> C2_2[低层VLA执行器 / Low-level VLA executor (MIND-2-VLA)]
        C2 --> C2_3[离线强化学习优化 / Optimized via offline RL]
        D[关键结果 / Results] --> D1[大规模多模态数据集 / Large-scale multimodal dataset]
        D --> D2[促进泛化研究 / Facilitates research on generalization]
        D --> D3[层次化系统框架 / Hierarchical system framework]
    ```

- **[arXiv260101] Hierarchical Online Optimization Approach for IRS-enabled Low-altitude MEC in Vehicular Networks**
  - **tags:** [sys], [wireless networks and mobile computing], [intelligent reflecting surface (IRS), multi-access edge computing (MEC), deep reinforcement learning (DRL), Stackelberg game, UAV trajectory optimization]
  - **authors:** Yixian Wang, Geng Sun, Zemin Sun, Jiacheng Wang, Changyuan Zhao, Daxin Tian, Dusit Niyato, Shiwen Mao
  - **institution:** Jilin University, Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.24659
  - **contributions:** 1. Proposes a novel IRS-enabled low-altitude MEC architecture with hybrid IRSs (building-installed and UAV-carried) to enhance air-ground connectivity in vehicular networks. 2. Formulates the joint optimization problem as a multi-objective NP-hard problem and solves it via a hierarchical online optimization approach (HOOA) based on a Stackelberg game. 3. Introduces a novel GDMTD3 (generative diffusion model-enhanced twin delayed deep deterministic policy gradient) algorithm integrated with a KKT-based method at the leader level for continuous decision-making.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a70ac61590f84cefea0f7f78edf4eaf7e0546f7c7759345e2ce5ad8ec8d0b049_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a hierarchical online optimization approach (HOOA) for an IRS-enabled low-altitude MEC system in vehicular networks to minimize task delay and energy consumption. The method reformulates the problem as a Stackelberg game, using a matching mechanism for vehicles and a novel deep reinforcement learning algorithm (GDMTD3) for server-side decisions. Simulation results show the proposed HOOA reduces average delay by 2.5% and energy consumption by 3.1% compared to benchmarks, demonstrating improved performance and stability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题 / Paper Title: Hierarchical Online Optimization Approach for IRS-enabled Low-altitude MEC in Vehicular Networks] --> B
        A --> C
        A --> D
        B[核心问题 / Problem: 动态车辆网络中高移动性和遮挡导致时变信道，限制可靠连接和计算服务 / Dynamic vehicular networks with high mobility and blockage lead to time-varying channels, limiting reliable connectivity and computing services.]
        C[主要方法 / Method: 分层在线优化方法(HOOA)，将问题重构为Stackelberg博弈，结合匹配机制和GDMTD3强化学习算法 / Hierarchical Online Optimization Approach (HOOA) reformulates problem as Stackelberg game, combining matching mechanism and GDMTD3 DRL algorithm.]
        D[关键结果 / Results: 平均任务完成延迟降低2.5%，平均能耗降低3.1%，具有优越的收敛稳定性和鲁棒性 / Reduces average task completion delay by 2.5% and energy consumption by 3.1%, with superior convergence stability and robustness.]
    ```

- **[arXiv260101] Dynamic Policy Learning for Legged Robot with Simplified Model Pretraining and Model Homotopy Transfer**
  - **tags:** [ai], [reinforcement learning], [model homotopy, continuation learning, single rigid body model, policy transfer, legged locomotion]
  - **authors:** Dongyun Kang, Min-Gyu Kim, Tae-Gyu Song, Hajun Kim, Sehoon Ha, Hae-Won Park
  - **institution:** Korea Advanced Institute of Science and Technology (KAIST), Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.24698
  - **contributions:** 1. Proposes a continuation-based learning framework combining simplified model pretraining and model homotopy transfer for efficient policy learning. 2. Introduces a model homotopy path defined by gradually redistributing mass and inertia from a Single Rigid Body (SRB) model to a full-body model. 3. Demonstrates faster convergence and superior transfer stability for complex dynamic tasks (e.g., flips, wall maneuvers) and successful real-robot deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f290446d6dbc75a7566abaf855c8d703414e58780e4d737ff33bd9bcd9c33512_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of transferring policies from simplified to full-body dynamics for legged robots. It proposes a framework that first pretrains a policy using a Single Rigid Body model and then uses a model homotopy to gradually transfer it to the full-body environment. The method achieves faster convergence, stable transfer, and is validated on dynamic tasks with a real quadruped robot.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Dynamic Policy Learning for Legged Robot] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[模型差异/Model discrepancy]
        P1 --> P2[简化模型到全身模型策略迁移困难/Difficult policy transfer from simplified to full-body model]
        Method[主要方法/Method] --> M1[简化模型预训练/Simplified model pretraining]
        M1 --> M2[使用单刚体模型/Using Single Rigid Body model]
        Method --> M3[模型同伦迁移/Model homotopy transfer]
        M3 --> M4[渐进质量与惯量重分配/Gradual mass & inertia redistribution]
        Results[关键结果/Results] --> R1[更快收敛/Faster convergence]
        Results --> R2[迁移稳定/Superior transfer stability]
        Results --> R3[真实机器人部署成功/Successful real-robot deployment]
    ```

- **[arXiv260101] Evolving, Not Training: Zero-Shot Reasoning Segmentation via Evolutionary Prompting**
  - **tags:** [cv], [reasoning segmentation], [evolutionary prompting, zero-shot learning, visual arena, semantic mutation, heterogeneous arena]
  - **authors:** Kai Ye, Xiaotong You, Jianghang Lin, Jiayi Ji, Pingyang Dai, Liujuan Cao
  - **institution:** Xiamen University, National University of Singapore
  - **link:** https://arxiv.org/pdf/2512.24702
  - **code:** https://github.com/AHideoKuzeA/Evol-SAM3
  - **contributions:** 1. Proposes EVOL-SAM3, a novel zero-shot framework that reformulates reasoning segmentation as an inference-time evolutionary search process. 2. Introduces a "Generate-Evaluate-Evolve" loop with a Visual Arena for reference-free fitness assessment and a Semantic Mutation operator for diversity and error correction. 3. Designs a Heterogeneous Arena module that integrates geometric priors with semantic reasoning for robust final selection.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b60e24e2f5e5668a6d7d977acfb32177365388575df74e72ccb5a8b3d4e7f7e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of static, training-free methods for reasoning segmentation by proposing EVOL-SAM3, a zero-shot framework that uses an evolutionary prompting strategy to iteratively refine prompt hypotheses at inference time. The method outperforms both static baselines and fully supervised state-of-the-art methods on the ReasonSeg benchmark without any training.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[EVOL-SAM3: 零样本推理分割的进化提示 / EVOL-SAM3: Zero-Shot Reasoning Segmentation via Evolutionary Prompting] --> B
        A --> C
        A --> D
        B[核心问题 / Problem] --> B1[静态推理范式 / Static Inference Paradigm]
        B1 --> B2[推理深度不足 / Insufficient Reasoning Depth]
        B1 --> B3[无法自我纠正 / Lack of Self-Correction]
        C[主要方法 / Method] --> C1[进化搜索 / Evolutionary Search]
        C1 --> C2[生成-评估-进化循环 / Generate-Evaluate-Evolve Loop]
        C2 --> C3[视觉竞技场 / Visual Arena]
        C2 --> C4[语义突变 / Semantic Mutation]
        C2 --> C5[异构竞技场 / Heterogeneous Arena]
        D[关键结果 / Results] --> D1[超越静态基线 / Outperforms Static Baselines]
        D --> D2[超越全监督SOTA / Surpasses Fully Supervised SOTA]
        D --> D3[零样本设置 / Zero-Shot Setting]
    ```

- **[arXiv260101] Control of Microrobots with Reinforcement Learning under On-Device Compute Constraints**
  - **tags:** [mlsys], [on-device ai], [reinforcement learning, quantization, domain randomization, gait scheduling, edge ML]
  - **authors:** Yichen Liu, Kesava Viswanadha, Zhongyu Li, Nelson Lojo, Kristofer S. J. Pister
  - **institution:** University of California, Berkeley
  - **link:** https://arxiv.org/pdf/2512.24740
  - **contributions:** 1. Proposes and implements an edge ML pipeline for microrobot locomotion, training a compact RL policy in simulation and deploying it on an ultra-low-power ARM Cortex-M0 SoC. 2. Introduces a resource-aware gait scheduling framework that selects the optimal gait mode (e.g., trot, gallop) based on the hardware's power budget and achievable inference frequency to maximize expected reward. 3. Demonstrates the use of domain randomization and integer quantization (Int8) to enhance policy robustness and enable higher update rates on severely resource-constrained hardware.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b59e857eb5b5c4d1e8a552ef8542246a2d1db88ba891759753679922c30b963c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of on-device, low-latency control for microrobots under strict compute and power constraints. The method involves training a compact reinforcement learning policy with domain randomization in simulation, quantizing it to Int8 for efficient inference on a 5 MHz microcontroller, and proposing a power-budget-aware gait scheduler. The main conclusion is that this edge ML approach enables autonomous locomotion control on ultra-small hardware, with domain randomization improving out-of-distribution stability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Control of Microrobots with RL under On-Device Compute Constraints<br>微机器人在设备计算约束下的强化学习控制] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[On-device autonomy for microrobots<br>微机器人的设备端自主性]
        B --> B2[Severe compute/power constraints<br>严苛的计算/功耗约束]
        C --> C1[Train compact RL policy with domain randomization<br>使用域随机化训练紧凑RL策略]
        C --> C2[Quantize policy (Int8) for efficient inference<br>量化策略(Int8)以实现高效推理]
        C --> C3[Resource-aware gait scheduling<br>资源感知的步态调度]
        D --> D1[Deployment on ultra-small SoC (Cortex-M0)<br>在超小型SoC上部署]
        D --> D2[Connects power budget to feasible update rate<br>连接功耗预算与可行更新频率]
        D --> D3[Improved OOD stability via domain randomization<br>通过域随机化提升OOD稳定性]
    ```

- **[arXiv260101] Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow**
  - **tags:** [ai], [robotic manipulation], [3D object flow, video generation, zero-shot manipulation, trajectory optimization, reinforcement learning]
  - **authors:** Karthik Dharmarajan, Wenlong Huang, Jiajun Wu, Li Fei-Fei, Ruohan Zhang
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2512.24766
  - **contributions:** 1. Proposes Dream2Flow, a framework that bridges video generation and robotic control using 3D object flow as an intermediate representation. 2. Demonstrates the ability to reconstruct 3D object motions from generated videos and formulate manipulation as object trajectory tracking, overcoming the embodiment gap. 3. Shows that the method enables zero-shot guidance from pre-trained video models to manipulate diverse object categories (rigid, articulated, deformable, granular) without task-specific demonstrations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c22839be4198942eb08182abe0606d486a3126572afb757ce865cb1b3a787721_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces Dream2Flow, a framework that uses 3D object flow extracted from videos generated by off-the-shelf models as an interface for robotic manipulation. It translates these generated motions into executable robot actions via trajectory optimization or reinforcement learning, enabling zero-shot manipulation of diverse objects in open-world settings. The results demonstrate 3D object flow as a general and scalable bridge between video generation models and robotic control.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow] --> B(核心问题/Problem: Translating human-like motions from video models into low-level robot actions)
        A --> C(主要方法/Method: Use 3D object flow as intermediate representation, reconstruct motions from videos, track trajectories)
        A --> D(关键结果/Results: Enables zero-shot manipulation of diverse objects, bridges video generation to robot control)
    ```

- **[arXiv260101] Throughput Optimization in UAV-Mounted RIS under Jittering and Imperfect CSI via DRL**
  - **tags:** [ai], [reinforcement learning], [UAV-mounted RIS, deep reinforcement learning, imperfect CSI, jitter, throughput optimization]
  - **authors:** Anas K. Saeed, Mahmoud M. Salim, Ali Arshad Nasir, Ali H. Muqaibel
  - **institution:** King Fahd University of Petroleum and Minerals
  - **link:** https://arxiv.org/pdf/2512.24773
  - **contributions:** 1. Formulated a stochastic nonconvex optimization problem for throughput maximization in a UAV-mounted RIS system under practical impairments of 3D UAV jitter and imperfect cascaded CSI. 2. Proposed a model-free DRL framework with a contextual bandit formulation, utilizing a differentiable feasibility layer to handle strict unit-modulus constraints and Monte Carlo estimation for the reward. 3. Instantiated the framework with constrained variants of DDPG and TD3 algorithms (without target networks) that achieve higher throughput than AO-WMMSE baselines under severe impairments and offer significantly faster online inference.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21b151210402631df4e03eef8b93269c08979932c1031e607f39d4ebdad4ff7f_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the problem of maximizing throughput in a UAV-mounted RIS communication system under practical impairments like UAV jitter and imperfect channel knowledge. It proposes a deep reinforcement learning framework with constrained policy gradient algorithms to jointly optimize the base station's beamforming and the RIS's phase shifts. The results show the DRL approach outperforms conventional optimization methods under severe impairments and offers much faster online decision-making.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Throughput Optimization in UAV-Mounted RIS under Jittering and Imperfect CSI via DRL] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[UAV抖动与不完美CSI降低系统性能/UAV Jitter & Imperfect CSI Degrade Performance]
        C --> C1[基于情境赌博机的无模型DRL框架/Model-free DRL with Contextual Bandit]
        C --> C2[使用可微可行性层与蒙特卡洛奖励/Using Differentiable Feasibility Layer & Monte Carlo Reward]
        C --> C3[实例化约束型DDPG与TD3算法/Instantiating Constrained DDPG & TD3]
        D --> D1[在严重损伤下性能优于AO-WMMSE/Outperforms AO-WMMSE under Severe Impairments]
        D --> D2[在线推理速度快(~0.6ms)/Fast Online Inference (~0.6ms)]
    ```

- **[arXiv260101] Iterative Deployment Improves Planning Skills in LLMs**
  - **tags:** [ai], [reinforcement learning], [iterative deployment, implicit reward, data curation, planning, fine-tuning]
  - **authors:** Augusto B. Corrêa, Yoav Gelberg, Luckeciano C. Melo, Ilia Shumailov, André G. Pereira, Yarin Gal
  - **institution:** University of Oxford, AI Sequrity Company, UFRGS
  - **link:** https://arxiv.org/pdf/2512.24940
  - **contributions:** 1. Demonstrates that iterative deployment and fine-tuning on curated user data significantly improves LLM planning skills, including emergent generalization to longer plans. 2. Provides a theoretical analysis showing iterative deployment effectively implements an outer-loop reinforcement learning process with an implicit reward function. 3. Highlights the AI safety implications of this implicit training regime and positions it as an alternative to explicit RL training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8da35d1ea681d386cec51c012c9f81bb54c6876b6c1e632e59874f77690cd1a_w640_q70.webp
  - **Simple LLM Summary:** The paper shows that repeatedly deploying LLMs and fine-tuning them on curated data from previous deployments significantly improves their planning capabilities. This process is analyzed as an implicit form of reinforcement learning, which raises safety concerns due to the undefined reward function and offers an alternative training paradigm based on data curation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Iterative Deployment Improves Planning Skills in LLMs] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM规划能力/LLM Planning Skills]
        C --> C1[迭代部署与微调/Iterative Deployment & Fine-tuning]
        C1 --> C2[用户数据筛选/User Data Curation]
        D --> D1[规划能力提升/Improved Planning Skills]
        D --> D2[发现隐式RL/Discovering Implicit RL]
        D2 --> D3[AI安全影响/AI Safety Implications]
    ```

- **[arXiv260101] MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates for Exponentially Stabilizing Control**
  - **tags:** [ai], [reinforcement learning], [Lyapunov certificates, exponential stability, multi-step learning, actor-critic, maximum entropy RL]
  - **authors:** Yongwei Zhang, Yuanzhe Xing, Quan Quan, Zhikun She
  - **institution:** Beihang University
  - **link:** https://arxiv.org/pdf/2512.24955
  - **contributions:** 1. Proposes a novel framework (MSACL) that integrates exponential stability theory with maximum entropy RL via multi-step Lyapunov certificate learning, using off-policy data to learn certificates that satisfy theoretical stability conditions. 2. Introduces Exponential Stability Labels (ESL) and a λ-weighted aggregation mechanism to effectively balance the bias-variance trade-off in multi-step learning. 3. Guides policy optimization with a stability-aware advantage function to ensure the learned policy promotes rapid Lyapunov descent, achieving provable stability and robustness under simple rewards.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea102a46402567fc13871b6bc5f72e6c07e79e6ee87e8349aee1c18c8fc9627e_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes MSACL, a model-free reinforcement learning framework that ensures provable exponential stability by learning Lyapunov certificates from multi-step data and guiding policy optimization with a stability-aware advantage. It demonstrates superior performance over baseline and state-of-the-art Lyapunov-based RL methods across six benchmarks, achieving rapid convergence and robustness with simple rewards. The work establishes a link between Lyapunov theory and actor-critic frameworks for verifiably safe control.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Provable Stability in Model-Free RL / 模型无关RL的可证明稳定性]
        C --> C1[Multi-Step Lyapunov Certificate Learning / 多步李雅普诺夫证书学习]
        C --> C2[Stability-Aware Advantage Function / 稳定性感知优势函数]
        D --> D1[Superiority over SOTA / 优于现有最优方法]
        D --> D2[Exponential Stability & Robustness / 指数稳定性与鲁棒性]
    ```

- **[arXiv260101] ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning**
  - **tags:** [ai], [reinforcement learning from human feedback (RLHF)], [preference strength, reward modeling, sample efficiency, utility difference, Pearson Distance Correlation (PDC)]
  - **authors:** Timo Kaufmann, Yannick Metz, Daniel Keim, Eyke Hüllermeier
  - **institution:** LMU Munich, University of Konstanz
  - **link:** https://arxiv.org/pdf/2512.25023
  - **contributions:** 1. ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals. 2. Empirical evidence of improved sample efficiency and robustness across diverse tasks. 3. The Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/89532a897b8fa7db270c20a989bfbc8848f6809665ba966305a08daa55266fce_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limitation of standard RLHF, which only captures the direction of a preference but not its strength. It proposes ResponseRank, a method that learns preference strength by ranking responses using relative differences in noisy proxy signals (like response times) within local strata. The method demonstrates improved sample efficiency and robustness across synthetic, language modeling, and RL control tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[标准RLHF仅提供偏好方向/Standard RLHF only provides preference direction]
        B --> B2[偏好强度难以可靠测量/Preference strength is hard to measure reliably]
        C --> C1[利用代理信号(如响应时间)/Leverage proxy signals (e.g., response time)]
        C --> C2[局部层内相对比较/Local within-strata relative comparison]
        C --> C3[排序推断强度/Rank to infer strength]
        D --> D1[提升样本效率与鲁棒性/Improved sample efficiency & robustness]
        D --> D2[提出新评估指标PDC/Proposed new metric PDC]
    ```

- **[arXiv260101] Many Minds from One Model: Bayesian Transformers for Population Intelligence**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [Bayesian Transformers, Variational Inference, Population Diversity, Normalization Layers, Wisdom of Crowds]
  - **authors:** Diji Yang, Yi Zhang
  - **institution:** University of California Santa Cruz
  - **link:** https://arxiv.org/pdf/2512.25063
  - **contributions:** 1. Proposes Population Bayesian Transformers (B-Trans), a method to convert a standard LLM into a Bayesian model by treating normalization layer biases as stochastic variables with a Gaussian variational approximation, enabling diverse model sampling from a single weight set. 2. Introduces sequence-level noise freezing to maintain temporal coherence within each sampled model instance's generation, ensuring consistent behavior across tokens. 3. Demonstrates that aggregating predictions from a population of sampled B-Trans instances enhances exploration and decision-making, leading to superior semantic diversity and task performance in zero-shot generation, RLVR, and RL without labels.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae0113a2c263c7e9a33e3b5ce49ac7afb88b3a3baeb7fd88c121fac5ef4b745b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of diversity and exploration in deterministic LLMs by proposing B-Trans, which transforms a standard LLM into a Bayesian model by making normalization biases stochastic. This allows sampling diverse "minds" from one model, and aggregating their predictions improves performance and semantic variety in reasoning tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Many Minds from One Model: Bayesian Transformers for Population Intelligence] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现代Transformer是单一思维的/Modern Transformers are single-minded]
        B --> B2[缺乏多样性阻碍探索/Lack of diversity hinders exploration]
        C --> C1[提出B-Trans: 贝叶斯Transformer/Propose B-Trans: Bayesian Transformer]
        C --> C2[归一化层偏置作为随机变量/Normalization biases as stochastic variables]
        C --> C3[序列级噪声冻结/Sequence-level noise freezing]
        D --> D1[增强语义多样性/Improved semantic diversity]
        D --> D2[提升任务性能/Better task performance]
        D --> D3[实现群体智慧/Achieves wisdom of crowds]
    ```

- **[arXiv260101] Scaling Open-Ended Reasoning to Predict the Future**
  - **tags:** [ai], [language model forecasting], [open-ended forecasting, reinforcement learning, retrieval-augmented generation, calibration, Qwen3]
  - **authors:** Nikhil Chandak, Shashwat Goel, Ameya Prabhu, Moritz Hardt, Jonas Geiping
  - **institution:** Max Planck Institute for Intelligent Systems, ELLIS Institute Tübingen, Tübingen AI Center, University of Tübingen
  - **link:** https://arxiv.org/pdf/2512.25070
  - **code:** /github (URL implied from first page content)
  - **contributions:** 1. A fully automated pipeline to synthesize a large-scale dataset (OpenForesight) for training language models on open-ended forecasting questions from news events. 2. A specialized forecasting system integrating retrieval and an improved RL reward function, trained on Qwen3, which prevents future information leakage. 3. The OpenForecaster 8B model, which demonstrates that specialized training improves accuracy, calibration, and consistency, matching larger proprietary models, with calibration benefits generalizing to other benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7433331ffccb9fb0f52db33a75b12ae808ae87c5410037274fcfdc5f22b3505_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of training language models for open-ended future prediction. The authors propose an automated method to generate a large forecasting dataset from news and train a specialized model (OpenForecaster 8B) using retrieval and an improved RL reward. Their final model matches the performance of much larger proprietary models, showing improved prediction accuracy, calibration, and consistency.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Scaling Open-Ended Reasoning to Predict the Future<br>预测未来的开放式推理扩展] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[训练语言模型进行开放式未来预测<br>Train LLMs for open-ended future forecasting]
        C --> C1[自动从新闻生成数据集<br>Automated dataset generation from news]
        C --> C2[使用检索和改进的RL进行训练<br>Training with retrieval & improved RL]
        C --> C3[防止未来信息泄露<br>Prevent future info leakage]
        D --> D1[OpenForecaster 8B 匹配更大模型<br>Matches larger proprietary models]
        D --> D2[提升准确性、校准和一致性<br>Improves accuracy, calibration, consistency]
    ```

- **[arXiv260101] Fitted Q Evaluation Without Bellman Completeness via Stationary Weighting**
  - **tags:** [ai], [reinforcement learning], [off-policy evaluation, fitted Q-evaluation, Bellman completeness, stationary distribution, density ratio]
  - **authors:** Lars van der Laan, Nathan Kallus
  - **institution:** University of Washington, Netflix, Cornell University
  - **link:** https://arxiv.org/pdf/2512.23805
  - **contributions:** 1. Identified the fundamental norm mismatch causing FQE's reliance on Bellman completeness, 2. Proposed a simple fix by reweighting regression steps with an estimated stationary density ratio, 3. Provided strong evaluation guarantees without requiring realizability or Bellman completeness, avoiding geometric error blow-up.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0334a3bea1166b5e2cbda1d446e2561bf91e6e45af4da23da7bb2759aa9a5043_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the fragility of Fitted Q-evaluation (FQE) in off-policy reinforcement learning, which traditionally requires the strong assumption of Bellman completeness. The authors propose a simple modification to FQE by reweighting each regression step using an estimate of the stationary density ratio, aligning the optimization with the contractive norm of the Bellman operator. This enables robust policy evaluation guarantees even when the function class is not Bellman complete, maintaining the practicality of regression-based methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Fitted Q Evaluation Without Bellman Completeness via Stationary Weighting] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[标准FQE需要贝尔曼完备性假设 / Standard FQE requires Bellman completeness]
        B --> B2[假设过强且难以满足 / Assumption is strong and hard to satisfy]
        C --> C1[识别根本的范数不匹配 / Identify fundamental norm mismatch]
        C --> C2[使用平稳密度比重新加权回归步骤 / Reweight regression steps using stationary density ratio]
        D --> D1[无需贝尔曼完备性的强保证 / Strong guarantees without Bellman completeness]
        D --> D2[避免几何误差爆炸 / Avoid geometric error blow-up]
    ```

- **[arXiv260101] Stationary Reweighting Yields Local Convergence of Soft Fitted Q-Iteration**
  - **tags:** [ai], [reinforcement learning], [fitted Q-iteration, entropy regularization, stationary distribution, Bellman operator, offline RL]
  - **authors:** Lars van der Laan, Nathan Kallus
  - **institution:** University of Washington, Netflix, Cornell University
  - **link:** https://arxiv.org/pdf/2512.23927
  - **contributions:** 1. Identified a geometric mismatch causing instability in soft FQI, showing the soft Bellman operator is contractive in the stationary norm of the soft-optimal policy, not the behavior norm. 2. Proposed stationary-reweighted soft FQI, a method that reweights regression updates using the current policy's stationary distribution to restore contraction. 3. Provided a theoretical analysis proving local linear convergence under function approximation with damped weight-estimation errors and suggested a continuation approach for global convergence via temperature annealing.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a133d7f0a68e796e5601b9dd17517ab3deea2ceb5f9dce008c265e4c615a1b43_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the instability of entropy-regularized fitted Q-iteration (soft FQI) under function approximation and distribution shift in offline reinforcement learning. The authors propose a new method, stationary-reweighted soft FQI, which reweights updates using the policy's stationary distribution to restore local contraction. They prove local linear convergence and suggest that global convergence can be achieved by gradually reducing the softmax temperature.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Stationary Reweighting Yields Local Convergence of Soft Fitted Q-Iteration] --> B[核心问题/Problem: Soft FQI instability under function approximation & distribution shift]
        A --> C[主要方法/Method: Stationary-reweighted soft FQI (reweights updates using policy's stationary distribution)]
        A --> D[关键结果/Results: Local linear convergence proven; global convergence via temperature annealing suggested]
    ```

- **[arXiv260101] Policy Mirror Descent with Temporal Difference Learning: Sample Complexity under Online Markov Data**
  - **tags:** [ai], [reinforcement learning], [policy mirror descent, temporal difference learning, sample complexity, Markov decision process, policy optimization]
  - **authors:** Wenye Li, Hongxu Chen, Jiacai Liu, Ke Wei
  - **institution:** Fudan University
  - **link:** https://arxiv.org/pdf/2512.24056
  - **contributions:** 1. Proposes two novel algorithms (Expected TD-PMD and Approximate TD-PMD) that combine policy mirror descent with TD learning under online Markovian sampling. 2. Establishes an $\tilde\{O\}(\varepsilon^\{-2\})$ sample complexity for achieving average-time $\varepsilon$-optimality with a constant step size. 3. Improves sample complexity to $O(\varepsilon^\{-2\})$ for last-iterate $\varepsilon$-optimality using adaptive policy update step sizes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e127c9df69a866d0fceeb04827980cde5bc823d8ff492633bf924e6720d9ce1_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the sample complexity of policy mirror descent combined with temporal difference learning under online Markovian data. It introduces two algorithms, Expected TD-PMD and Approximate TD-PMD, and proves they achieve $\tilde\{O\}(\varepsilon^\{-2\})$ sample complexity for average-time optimality, which is further refined to $O(\varepsilon^\{-2\})$ for last-iterate optimality with adaptive step sizes.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Policy Mirror Descent with Temporal Difference Learning: Sample Complexity under Online Markov Data] --> B[核心问题/Problem: Existing PMD analysis limited to generative or Markovian sampling with pre-approximated action values]
    A --> C[主要方法/Method: Propose Expected TD-PMD (off-policy) and Approximate TD-PMD (mixed policy) algorithms]
    A --> D[关键结果/Results: Achieve ˜O(ε⁻²) sample complexity for average-time ε-optimality; improved to O(ε⁻²) for last-iterate ε-optimality with adaptive steps]
    ```

- **[arXiv260101] Robust Bayesian Dynamic Programming for On-policy Risk-sensitive Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [risk-sensitive reinforcement learning, Bayesian dynamic programming, coherent risk measures, robust Markov decision process, convex optimization]
  - **authors:** Shanyu Han, Yangbo He, Yang Liu
  - **institution:** Peking University, The Chinese University of Hong Kong, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.24580
  - **contributions:** 1. Proposes a novel unified framework for risk-sensitive reinforcement learning (RSRL) that incorporates robustness against transition uncertainty by defining inner and outer coherent risk measures. 2. Develops a Bayesian Dynamic Programming algorithm that alternates posterior updates with value iteration, using a Monte Carlo and convex optimization estimator with strong consistency guarantees. 3. Provides theoretical analysis including convergence, sample complexity, and computational complexity under Dirichlet posterior and CVaR, validated through numerical experiments and an option hedging application.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b966fa69f9b8aafe26700ce5afe83099b3257d5b90314e5d3f668e4079ecdda_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces a robust Bayesian framework for on-policy risk-sensitive reinforcement learning that addresses transition uncertainty through coupled inner and outer risk measures. It develops a Bayesian Dynamic Programming algorithm with theoretical guarantees and demonstrates its effectiveness in convergence and robustness via numerical experiments and an option hedging application.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Robust Bayesian Dynamic Programming for On-policy Risk-sensitive Reinforcement Learning"] --> Problem["核心问题/Problem: Need for risk-sensitive RL robust to transition uncertainty"]
        Root --> Method["主要方法/Method: Unified framework with inner/outer risk measures, Bayesian DP algorithm with posterior updates and value iteration"]
        Root --> Results["关键结果/Results: Theoretical guarantees, convergence, validated via experiments and option hedging application"]
    ```

- **[arXiv260101] Sparse Offline Reinforcement Learning with Corruption Robustness**
  - **tags:** [ai], [reinforcement learning], [offline reinforcement learning, sparsity, corruption robustness, single-policy concentrability, actor-critic]
  - **authors:** Nam Phuong Tran, Andi Nika, Goran Radanovic, Long Tran-Thanh, Debmalya Mandal
  - **institution:** University of Warwick, Max Planck Institute for Software Systems (MPI-SWS)
  - **link:** https://arxiv.org/pdf/2512.24768
  - **contributions:** 1. Identifies limitations of integrating sparsity into standard robust offline RL methods like LSVI, showing they can fail due to overly pessimistic bonuses. 2. Proposes novel actor-critic methods with sparse robust estimator oracles that avoid pointwise pessimistic bonuses. 3. Provides the first non-vacuous theoretical guarantees for learning in high-dimensional sparse MDPs under weak (single-policy concentrability) coverage and strong data corruption.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ce133c71cdf619bf6a1597c047c8adc5b10b7d0584bd6af1944718635e12340_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of robust offline reinforcement learning in high-dimensional, sparse Markov Decision Processes where data may be corrupted. The authors propose new actor-critic methods that use sparse robust estimator oracles, avoiding the pitfalls of traditional approaches. Their work provides the first theoretical guarantees showing that learning a near-optimal policy is possible under weak data coverage and strong corruption, where previous methods fail.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Sparse Offline RL with Corruption Robustness<br>稀疏离线强化学习与抗污染鲁棒性"] --> Problem["Problem: High-dim sparse MDPs with corrupted data & weak coverage<br>问题: 具有污染数据和弱覆盖的高维稀疏MDP"]
        Root --> Method["Method: Actor-critic with sparse robust estimator oracles<br>方法: 使用稀疏鲁棒估计器oracle的Actor-critic"]
        Root --> Results["Results: First non-vacuous guarantees under single-policy concentrability & corruption<br>结果: 在单策略集中性和污染下的首个非平凡保证"]
    ```


**cs.AI/cs.LG contains "accelerate" total: 28**
- **[arXiv260101] A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation**
  - **tags:** [hpc], [computational geometry], [mesh generation, geometry preparation, CAD-to-mesh, machine learning, large language models]
  - **authors:** Steven Owen, Nathan Brown, Nikos Chrisochoides, Rao Garimella, Xianfeng Gu, Franck Ledoux, Na Lei, Roshan Quadros, Navamita Ray, Nicolas Winovich, Yongjie Jessica Zhang
  - **institution:** Sandia National Laboratories, Old Dominion University, Los Alamos National Laboratory, New York University / Stony Brook University, CEA, Dalian University of Technology, Carnegie Mellon University
  - **link:** https://arxiv.org/pdf/2512.23719
  - **contributions:** 1. Surveys the application of AI/ML methods to automate and improve key steps in the CAD-to-mesh pipeline, such as part classification, mesh quality prediction, and defeaturing. 2. Reviews AI techniques for enhancing unstructured/block-structured meshing, volumetric parameterization, and parallel mesh generation. 3. Examines emerging tools like reinforcement learning and large language models for scripting automation in meshing workflows.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c3d8c73084ddd952c2e0c9fd20e1b7fe1d87bb02c884cf6327ca47e6ec442eb_w640_q70.webp
  - **Simple LLM Summary:** This survey paper reviews how artificial intelligence and machine learning are being applied to address bottlenecks in geometry preparation and mesh generation for engineering simulation. It explores a range of methods, from quality prediction to automation with large language models, concluding that AI serves as an assistive technology to extend traditional tools and highlights key challenges for future data-driven workflows.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[CAD-to-mesh流程瓶颈 / CAD-to-mesh Pipeline Bottlenecks]
        C --> C1[AI辅助几何与网格生成 / AI-aided Geometry & Meshing]
        C --> C2[机器学习方法 / Machine Learning Methods]
        C --> C3[新兴自动化工具 / Emerging Automation Tools]
        C1 --> C1a[部件分类 / Part Classification]
        C1 --> C1b[网格质量预测 / Mesh Quality Prediction]
        C1 --> C1c[去特征化 / Defeaturing]
        C2 --> C2a[非结构化/块结构化网格 / Unstructured/Block-structured Meshing]
        C2 --> C2b[体积参数化 / Volumetric Parameterizations]
        C2 --> C2c[并行网格生成 / Parallel Mesh Generation]
        C3 --> C3a[强化学习 / Reinforcement Learning]
        C3 --> C3b[大语言模型 / Large Language Models]
        D --> D1[AI作为辅助技术 / AI as Assistive Technology]
        D --> D2[代表性方法与部署 / Representative Methods & Deployments]
        D --> D3[关键研究挑战 / Key Research Challenges]
    ```

- **[arXiv260101] An Electronic Ising Machine**
  - **tags:** [mlsys], [others], [Ising machine, analog computing, coupled oscillators, NP-Hard problems, energy-based learning]
  - **authors:** Matt Bowring, Ben Anderdson, Ben Tiffany
  - **institution:** Purdue University
  - **link:** https://arxiv.org/pdf/2512.23720
  - **contributions:** 1. Developed a custom printed circuit board (PCB) as a low-power, high-speed accelerator for NP-Hard graph problems. 2. Implemented an analog computing architecture using coupled nonlinear electronic oscillators based on the annealing principle. 3. Provided a detailed hardware design, simulations, and experiments, offering insight into novel physics-based computing devices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d9bd94424dd9d472b237fd13390bb509481b9b3c0f6c3249e5f405a2b4cec7c_w640_q70.webp
  - **Simple LLM Summary:** This paper presents an electronic Ising machine, a custom PCB accelerator that uses coupled analog oscillators to solve NP-Hard graph problems. The system leverages an energy-based representation and annealing to naturally find stable phase alignments that encode solutions. The work contributes a practical hardware implementation and insights into physics-based computing as an alternative paradigm.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[An Electronic Ising Machine] --> Problem[核心问题/Problem: Solving NP-Hard graph problems efficiently]
        Root --> Method[主要方法/Method: Custom PCB with analog coupled oscillators & annealing]
        Root --> Results[关键结果/Results: Low-power, high-speed physics-based accelerator]
    ```

- **[arXiv260101] Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data**
  - **tags:** [ai], [physics-informed machine learning], [coupled systems, sparsity regularization, multitask learning, partial differential equations, mesh-free sampling]
  - **authors:** Esha Saha, Hao Wang
  - **institution:** University of Alberta
  - **link:** https://arxiv.org/pdf/2512.23761
  - **contributions:** 1. Proposes MUSIC, a novel sparsity-induced multitask neural network framework for learning coupled system dynamics when physics constraints and data are incomplete and mutually exclusive. 2. Introduces a method that integrates partial physical constraints with data-driven learning using mesh-free sampling and sparsity regularization for model compression and efficiency. 3. Demonstrates the framework's effectiveness on complex solutions (e.g., shock waves) under data-scarce and noisy conditions, outperforming non-sparse baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0e3d79b9b98f61c6847aeaba2b3e63b7fa984963e6f3f20b8ab17794c98a542_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of modeling coupled dynamical systems where the governing equation is known for only one variable and data is available for another. It proposes MUSIC, a sparsity-regularized multitask neural network that integrates these partial constraints with data to recover full system solutions. The method shows improved accuracy and efficiency in learning complex solutions under scarce and noisy data conditions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Mismatch between known physics (for one variable) and observed data (for another) in coupled systems."]
        Method["主要方法/Method<br>MUSIC: Sparsity-induced multitask neural network with partial physics constraints and data-driven learning."]
        Results["关键结果/Results<br>Accurately learns complex solutions (shock waves, patterns) under data-scarce, noisy conditions; outperforms non-sparse methods."]
    ```

- **[arXiv260101] Entropy-Aware Speculative Decoding Toward Improved LLM Reasoning**
  - **tags:** [mlsys], [llm inference], [speculative decoding, entropy penalty, training-free, reasoning acceleration, draft-model verification]
  - **authors:** Tiancheng Su, Meicong Zhang, Guoxiu He
  - **institution:** East China Normal University
  - **link:** https://arxiv.org/pdf/2512.23765
  - **contributions:** 1. Proposes Entropy-Aware Speculative Decoding (EASD), a training-free method that introduces a dynamic entropy-based penalty to reject low-confidence draft tokens, 2. Enables speculative decoding to potentially surpass the target model's performance by incorporating draft-model verification and preventing error propagation, 3. Demonstrates that EASD maintains efficiency comparable to standard speculative decoding while improving reasoning accuracy across multiple benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/326c86ae03e220a7cb48737a0a6fe149bd4384ccc08f3113a051c3548bc2d30e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of speculative decoding being constrained by the target model's performance. It proposes Entropy-Aware Speculative Decoding (EASD), which uses entropy to quantify uncertainty and reject low-confidence draft tokens. Experiments show EASD outperforms existing methods and can surpass the target LLM's performance while maintaining comparable efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Entropy-Aware Speculative Decoding] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[SD性能受限于目标模型/SD performance capped by target model]
        Method[主要方法/Method] --> M1[引入动态熵惩罚/Introduce dynamic entropy penalty]
        Method --> M2[基于不确定性拒绝低置信度令牌/Reject low-confidence tokens based on uncertainty]
        Method --> M3[目标模型重采样/Target model re-sampling]
        Results[关键结果/Results] --> R1[超越现有SD方法/Outperforms existing SD methods]
        Results --> R2[常超越目标LLM本身/Often surpasses target LLM]
        Results --> R3[效率与SD相当/Efficiency comparable to SD]
    ```

- **[arXiv260101] Enabling Physical AI at the Edge: Hardware-Accelerated Recovery of System Dynamics**
  - **tags:** [mlsys], [on-device ai], [FPGA acceleration, model recovery, hardware-software co-design, GRU, Neural ODE]
  - **authors:** Bin Xu, Ayan Banerjee, Sandeep Gupta
  - **institution:** Arizona State University
  - **link:** https://arxiv.org/pdf/2512.23767
  - **contributions:** 1. Proposed MERINDA, a hardware-friendly FPGA-accelerated framework for model recovery that replaces Neural ODEs with a formulation combining GRU-based discretized dynamics, dense inverse-ODE layers, sparsity-driven dropout, and lightweight solvers. 2. Designed the framework for streaming parallelism, enabling critical computational kernels to be fully parallelized on FPGA hardware. 3. Demonstrated transformative efficiency gains over GPU implementations, including 114x lower energy, 28x smaller memory footprint, and 1.68x faster training while maintaining state-of-the-art accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e286e0d5a9672c23140099a1b5fd5c7ad7e56f56cb1c276735170b95ad29fd47_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of deploying physical AI for model recovery on resource-constrained edge devices, where state-of-the-art methods using Neural ODEs are inefficient. The authors propose MERINDA, an FPGA-accelerated framework that uses a hardware-friendly architecture to replace expensive Neural ODE components. The results show that MERINDA achieves substantial improvements in energy, memory, and speed over GPU implementations while matching model recovery accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Enabling Physical AI at the Edge<br>在边缘实现物理人工智能] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Model recovery methods (Neural ODEs) are inefficient for edge hardware<br>模型恢复方法在边缘硬件上效率低下]
        C[主要方法/Method<br>MERINDA: FPGA-accelerated, hardware-friendly framework<br>MERINDA: FPGA加速的硬件友好框架]
        D[关键结果/Results<br>114x lower energy, 28x smaller memory, 1.68x faster training<br>能耗降低114倍, 内存占用减少28倍, 训练速度提升1.68倍]
    ```

- **[arXiv260101] Hardware Acceleration for Neural Networks: A Comprehensive Survey**
  - **tags:** [mlsys], [compiler & ir], [hardware acceleration, systolic arrays, quantization, operator fusion, KV-cache]
  - **authors:** Bin Xu, Ayan Banerjee, Sandeep Gupta
  - **institution:** Arizona State University
  - **link:** https://arxiv.org/pdf/2512.23914
  - **contributions:** 1. Provides a unified taxonomy for hardware acceleration of neural networks across workloads, execution settings, and optimization levers. 2. Synthesizes key architectural ideas and discusses the role of software stacks and compilers in bridging models to hardware. 3. Highlights open challenges and future directions, such as efficient long-context LLM inference and robust support for dynamic workloads.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bc95cc34eab31cf02c422baf1703e4640782447f887e0a949c6377cc40e8dc57_w640_q70.webp
  - **Simple LLM Summary:** This survey comprehensively reviews the landscape of hardware acceleration for neural networks, organizing it by workloads, execution settings, and optimization techniques. It synthesizes key architectural approaches and the software-hardware co-design needed for efficient execution. The paper concludes by identifying open challenges like KV-cache management for LLMs and points to future research directions for next-generation accelerators.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Hardware Acceleration for Neural Networks: A Comprehensive Survey"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Hardware bottlenecks (memory, communication) limit neural network efficiency."]
        Method["主要方法/Method<br>Survey & taxonomy of accelerators (GPU, TPU, FPGA), workloads, and optimizations."]
        Results["关键结果/Results<br>Synthesis of architectural ideas and identification of open challenges (e.g., LLM inference)."]
    ```

- **[arXiv260101] HERO-Sign: Hierarchical Tuning and Efficient Compiler-Time GPU Optimizations for SPHINCS+ Signature Generation**
  - **tags:** [hpc], [gpu kernels], [SPHINCS+, GPU Optimization, Tree Fusion, Adaptive Compilation, Kernel Overlapping]
  - **authors:** Yaoyun Zhou, Qian Wang
  - **institution:** University of California, Merced
  - **link:** https://arxiv.org/pdf/2512.23969
  - **contributions:** 1. Introduces a Tree Fusion strategy for the FORS component, guided by an automated Tree Tuning search algorithm to adapt to different GPU architectures. 2. Employs an adaptive compilation strategy that automatically selects between PTX and native code paths for different SPHINCS+ kernels to maximize efficiency. 3. Optimizes batched signature generation using a task graph-based construction to reduce multi-stream idle time and kernel launch overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/29ca58021f9583efba2be9c3f10082df113be98d3f93c0f5ef9cc70c6fa8e481_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes HERO-Sign, a GPU-accelerated implementation for the post-quantum signature scheme SPHINCS+. It uses hierarchical tuning, including a Tree Fusion strategy and adaptive compilation, to better exploit GPU parallelism and reduce overhead. The method achieves significant throughput improvements and latency reduction compared to state-of-the-art GPU implementations across multiple architectures.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["HERO-Sign: SPHINCS+签名生成优化 / HERO-Sign: SPHINCS+ Signature Generation Optimization"]
        Root --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["SPHINCS+签名生成慢 / Slow SPHINCS+ Signature Generation"]
        Problem --> P2["现有GPU优化未充分利用并行性 / Existing GPU Optimizations Underutilize Parallelism"]
        Method --> M1["树融合策略 / Tree Fusion Strategy"]
        Method --> M2["自适应编译 / Adaptive Compilation"]
        Method --> M3["任务图构建 / Task Graph Construction"]
        Results --> R1["吞吐量提升1.24-3.13倍 / Throughput Improvement 1.24-3.13x"]
        Results --> R2["内核启动延迟降低两个数量级 / Kernel Launch Latency Reduced by Two Orders of Magnitude"]
    ```

- **[arXiv260101] RainFusion2.0: Temporal-Spatial Awareness and Hardware-Efficient Block-wise Sparse Attention**
  - **tags:** [mlsys], [diffusion models], [sparse attention, hardware-efficient, block-wise mean, spatiotemporal-aware permutation, first-frame sink]
  - **authors:** Aiyue Chen, Yaofu Liu, Junjian Huang, Guang Lian, Yiwu Yao, Wangli Lan, Jing Lin, Zhixin Ma, Tingting Zhou, Harry Yang
  - **institution:** Huawei Technologies Co., Ltd, The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.24086
  - **contributions:** 1. Proposes using block-wise mean values as representative tokens for low-overhead sparse mask prediction. 2. Implements spatiotemporal-aware token permutation to enhance the effectiveness of the sparse attention pattern. 3. Introduces a first-frame sink mechanism specifically optimized for video generation scenarios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41a00bea8b8b0ba5148f027ed70530ca8414368fe966ff2da38fd4f95487de2b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes RainFusion2.0, a hardware-efficient and adaptive sparse attention mechanism to reduce the high computational cost of Diffusion Transformers in video and image generation. The method uses block-wise mean tokens for mask prediction and introduces spatiotemporal-aware permutation and a first-frame sink mechanism. Experiments show it achieves 80% sparsity with 1.5-1.8x speedup without quality loss, and generalizes across models and hardware.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RainFusion2.0] --> B[核心问题/Problem: DiT模型注意力计算成本高，现有稀疏注意力方法开销大且硬件通用性差]
        A --> C[主要方法/Method: 块均值代表令牌预测，时空感知令牌重排，首帧下沉机制]
        A --> D[关键结果/Results: 80%稀疏度，1.5~1.8倍端到端加速，跨模型和硬件有效]
    ```

- **[arXiv260101] CorGi: Contribution-Guided Block-Wise Interval Caching for Training-Free Acceleration of Diffusion Transformers**
  - **tags:** [mlsys], [diffusion models], [diffusion transformer, inference acceleration, interval caching, cross-attention, training-free]
  - **authors:** Yonglak Son, Suhyeok Kim, Seungryong Kim, Young Geun Kim
  - **institution:** Korea University, KAIST AI
  - **link:** https://arxiv.org/pdf/2512.24195
  - **code:** https://casl-ku.github.io/CorGi
  - **contributions:** 1. Proposes CorGi, a training-free framework that accelerates DiT inference by selectively caching and reusing outputs of low-contribution transformer blocks across denoising steps. 2. Introduces CorGi+, an extension for text-to-image tasks that uses cross-attention maps to identify salient tokens and applies partial attention updates to protect important details. 3. Demonstrates significant speedup (up to 2.0x on average) on state-of-the-art DiT models while preserving high generation quality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92c567dd9feea285991c6dbbdd5d85a85129420ce1925c585625dca252b806c4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high inference cost of Diffusion Transformers (DiT) by proposing CorGi, a training-free acceleration framework that reduces redundant computation through contribution-guided, block-wise interval caching. For text-to-image tasks, CorGi+ further refines the approach using cross-attention maps for partial updates. Evaluations show the methods achieve up to 2.0x speedup while maintaining image quality.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CorGi: Contribution-Guided Block-Wise Interval Caching<br>CorGi: 贡献引导的块级间隔缓存] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[DiT推理成本高<br>High DiT Inference Cost]
        B1 --> B2[去噪步骤间存在冗余计算<br>Redundant Computation Across Steps]
        C --> C1[CorGi: 缓存低贡献块<br>Cache Low-Contribution Blocks]
        C1 --> C2[CorGi+: 使用交叉注意力图<br>Use Cross-Attention Maps]
        C2 --> C3[部分注意力更新<br>Partial Attention Updates]
        D --> D1[加速高达2.0倍<br>Up to 2.0x Speedup]
        D --> D2[保持生成质量<br>Preserve Generation Quality]
    ```

- **[arXiv260101] SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents**
  - **tags:** [mlsys], [agent system], [Science Context Protocol, autonomous scientific agents, unified resource integration, experiment lifecycle management, federated servers]
  - **authors:** Yankai Jiang, Wenjie Lou, Lilong Wang, Zhenyu Tang, Shiyang Feng, Jiaxuan Lu, Haoran Sun, Yaning Pan, Shuang Gu, Haoyang Su, Feng Liu, Wangxu Wei, Pan Tan, Dongzhan Zhou, Fenghua Ling, Cheng Tan, Bo Zhang, Xiaosong Wang, Lei Bai, Bowen Zhou
  - **institution:** Shanghai Artificial Intelligence Laboratory
  - **link:** https://arxiv.org/pdf/2512.24189
  - **code:** https://github.com/InternScience/scp
  - **contributions:** 1. Proposes SCP, an open-source protocol-level standard for universally describing and invoking heterogeneous scientific resources (tools, models, datasets, instruments)., 2. Introduces a secure service architecture (centralized Hub & federated Servers) for managing the complete, traceable experiment lifecycle and enforcing fine-grained access control., 3. Demonstrates a functional platform built on SCP, integrating over 1,600 tool resources to facilitate secure, large-scale, multi-institution collaboration between AI agents and human researchers, reducing integration overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8885d3eeb276d5044f777dc33201481a07be8831aaff9d61726e4a6c13e821be_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces the Science Context Protocol (SCP), an open-source standard designed to address the fragmentation and bespoke nature of current autonomous scientific agent systems. SCP provides a universal specification for resource integration and a secure service architecture for experiment orchestration, enabling seamless, large-scale collaboration across platforms. The authors conclude that SCP establishes essential infrastructure for scalable, reproducible, and agent-driven science by standardizing context and tool orchestration at the protocol level.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Bespoke, isolated agent systems; Lack of shared protocol for heterogeneous resources"] --> Problem_Detail["具体挑战/Specific Challenges<br>Difficult to deploy beyond single lab; Hard to reuse components & reproduce workflows"]
        Method["主要方法/Method<br>Science Context Protocol (SCP)"] --> Method_Pillar1["支柱1: 统一资源集成/Unified Resource Integration<br>Universal spec for describing/invoking tools, models, data, instruments"]
        Method --> Method_Pillar2["支柱2: 实验生命周期管理/Experiment Lifecycle Management<br>Secure architecture (Hub & Servers) for registration, execution, monitoring"]
        Results["关键结果/Results<br>Enables global web of autonomous agents"] --> Results_Outcome1["成果1: 大规模生态系统/Large-scale Ecosystem<br>1,600+ integrated tool resources"]
        Results --> Results_Outcome2["成果2: 促进协作/Facilitates Collaboration<br>Reduces integration overhead; Enhances reproducibility"]
    ```

- **[arXiv260101] Heteroscedastic Bayesian Optimization-Based Dynamic PID Tuning for Accurate and Robust UAV Trajectory Tracking**
  - **tags:** [ai], [control theory & optimization], [Heteroscedastic Bayesian Optimization, PID Tuning, UAV Trajectory Tracking]
  - **authors:** Fuqiang Gu, Jiangshan Ai, Xu Lu, Xianlei Long, Yan Li, Tao Jiang, Chao Chen, Huidong Liu
  - **institution:** Chongqing University, Macquarie University
  - **link:** https://arxiv.org/pdf/2512.24249
  - **contributions:** 1. Proposes HBO-PID, a novel control algorithm integrating Heteroscedastic Bayesian Optimization with classical PID for UAV control. 2. Introduces explicit modeling of input-dependent noise variance to improve adaptation to dynamic environments. 3. Adopts a two-stage optimization strategy to accelerate the convergence of finding optimal controller parameters.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f2d1516402e9370a6abddfcf55734a6f894512a452d5f59baa27df4f4b8fcdd_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes HBO-PID, a novel control algorithm that combines Heteroscedastic Bayesian Optimization with PID control to improve UAV trajectory tracking. The method explicitly models noise variance and uses a two-stage optimization for efficiency. Experiments show it significantly outperforms state-of-the-art methods in both position and angular accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题/Paper Title: Heteroscedastic Bayesian Optimization-Based Dynamic PID Tuning] --> B[核心问题/Problem: 无人机轨迹跟踪精度与鲁棒性不足/UAV Trajectory Tracking Accuracy & Robustness Limited]
        A --> C[主要方法/Method: 异方差贝叶斯优化PID/Heteroscedastic Bayesian Optimization PID (HBO-PID)]
        A --> D[关键结果/Results: 位置精度提升24.7%-42.9%, 角度精度提升40.9%-78.4%/Position Accuracy ↑24.7%-42.9%, Angular Accuracy ↑40.9%-78.4%]
    ```

- **[arXiv260101] Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning**
  - **tags:** [mlsys], [llm training], [data selection, policy gradient, mask learning, quality-diversity trade-off, FineWeb]
  - **authors:** Ziqing Fan, Yuqiao Xian, Yan Sun, Li Shen
  - **institution:** ByteDance Seed, Shanghai Jiao Tong University, University of Sydney, Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.24265
  - **code:** https://github.com/ByteDance-Seed/DATAMASK
  - **contributions:** 1. Introduces DATAMASK, a novel joint learning framework for large-scale pre-training data selection that simultaneously optimizes quality and diversity metrics. 2. Formulates data selection as a mask learning problem and solves it efficiently using policy gradient-based optimization with acceleration enhancements, reducing selection time by 98.9% compared to greedy algorithms. 3. Creates and releases FineWeb-Mask, a high-quality and diverse 10% subset of the 15-trillion-token FineWeb dataset, which significantly improves model performance (e.g., +3.2% on a 1.5B model) across diverse tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02fd504349b8c0bb1934304d821a648ed4ca490b2f41e136f9b7a6220f39d5d2_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of efficiently selecting high-quality and diverse data for large-scale LLM pre-training, where traditional methods are costly and suboptimal. It proposes DATAMASK, a policy gradient-based framework that learns optimal data masks to jointly optimize quality and diversity, drastically speeding up selection. The resulting curated dataset, FineWeb-Mask, leads to significant performance gains in pre-trained models, demonstrating the framework's effectiveness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 大规模预训练数据中，联合考虑质量与多样性指标进行样本选择计算成本过高]
        C[主要方法/Method: 提出DATAMASK框架，将选择过程视为掩码学习问题，使用策略梯度进行优化]
        D[关键结果/Results: 选择时间减少98.9%，从FineWeb中选出的子集显著提升多种模型性能]
    ```

- **[arXiv260101] Real-world Reinforcement Learning from Suboptimal Interventions**
  - **tags:** [ai], [reinforcement learning], [human-in-the-loop RL, constrained RL, state-wise Lagrangian, suboptimal interventions, robotic manipulation]
  - **authors:** Yinuo Zhao, Huiqian Jin, Lechun Jiang, Xinyi Zhang, Kun Wu, Pei Ren, Zhiyuan Xu, Zhengping Che, Lei Sun, Dapeng Wu, Chi Harold Liu, Jian Tang
  - **institution:** Beijing Innovation Center of Humanoid Robotics, City University of Hong Kong, Nankai University, Beijing Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.24288
  - **contributions:** 1. Proposes SiLRI, a state-wise Lagrangian RL algorithm that formulates the online manipulation problem as a constrained RL optimization where constraint bounds are determined by the uncertainty of human interventions. 2. Introduces a state-wise Lagrange multiplier and solves the problem via a min-max optimization to jointly optimize the policy and the multiplier, enabling exploitation of suboptimal interventions without being constrained by them. 3. Demonstrates through real-world experiments that SiLRI significantly accelerates learning, reducing time to 90% success rate by at least 50% compared to prior methods and achieving 100% success on long-horizon tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f15ba64d7b2d7760e2411270a47d97305fe1e21ad798c2423cb89a0e5cb5750_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of leveraging suboptimal human interventions to accelerate real-world robotic RL without being limited by them. It proposes SiLRI, a state-wise Lagrangian RL algorithm that treats interventions as state-dependent constraints and solves a min-max optimization. Real-world experiments show SiLRI cuts learning time by over 50% and achieves perfect success on complex tasks where other methods fail.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Real-world Reinforcement Learning from Suboptimal Interventions] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 如何利用可能次优的人类干预加速学习而不受其限制/How to leverage potentially suboptimal human interventions to accelerate learning without being constrained by them]
        C[主要方法/Method: 提出SiLRI，一种基于状态拉格朗日的RL算法，将干预不确定性作为约束/Propose SiLRI, a state-wise Lagrangian RL algorithm treating intervention uncertainty as constraints]
        D[关键结果/Results: 学习速度提升>50%，在长视野任务上达到100%成功率/Learning speed improved >50%, achieved 100% success rate on long-horizon tasks]
    ```

- **[arXiv260101] DermaVQA-DAS: Dermatology Assessment Schema (DAS) & Datasets for Closed-Ended Question Answering & Segmentation in Patient-Generated Dermatology Images**
  - **tags:** [cv], [medical image analysis], [visual question answering, lesion segmentation, multimodal models]
  - **authors:** Wen-wai Yim, Yujuan Fu, Asma Ben Abacha, Meliha Yetisgen, Noel Codella, Roberto Andres Novoa, Josep Malvehy
  - **institution:** Microsoft, University of Washington, Stanford University, Hospital Clinic of Barcelona
  - **link:** https://arxiv.org/pdf/2512.24340
  - **code:** https://osf.io/72rp3
  - **contributions:** 1. Introduction of the Dermatology Assessment Schema (DAS), a novel expert-developed framework for structured dermatological feature assessment. 2. Release of DermaVQA-DAS, an extended dataset supporting closed-ended question answering and lesion segmentation on patient-generated images. 3. Comprehensive benchmarking of state-of-the-art multimodal models on the new tasks, analyzing the impact of prompt design on segmentation performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dabc426dbf988c067106f76b5dca274abd76ad3a46bcddbd05c76b76893e508a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of patient-centered benchmarks in dermatology by introducing DermaVQA-DAS, a dataset extension built upon a novel expert-developed assessment schema (DAS) for structured feature annotation. It supports two tasks—closed-ended visual question answering and lesion segmentation—on patient-generated images and queries. The study benchmarks modern multimodal models, finding strong QA performance and demonstrating that prompt design significantly impacts segmentation results.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[DermaVQA-DAS] --> Problem
        Root --> Method
        Root --> Results
    
        Problem[核心问题/Problem] --> P1[现有数据集缺乏患者视角/Existing datasets lack patient perspective]
        P1 --> P2[限制以患者为中心的护理应用/Limits patient-centered care applications]
    
        Method[主要方法/Method] --> M1[提出皮肤病评估框架(DAS)/Propose Dermatology Assessment Schema (DAS)]
        M1 --> M2[扩展DermaVQA数据集/Extend DermaVQA dataset]
        M2 --> M3[支持两项任务:封闭式问答与分割/Support two tasks: closed QA & segmentation]
    
        Results[关键结果/Results] --> R1[提示设计影响分割性能/Prompt design impacts segmentation performance]
        R1 --> R2[模型在QA上表现强劲/Models perform strongly on QA]
        R2 --> R3[公开数据集与评估协议/Publicly release dataset & evaluation protocols]
    ```

- **[arXiv260101] Subsecond 3D Mesh Generation for Robot Manipulation**
  - **tags:** [cv], [3D reconstruction], [3D mesh generation, open-vocabulary segmentation, point cloud registration]
  - **authors:** Qian Wang, Omar Abdellall, Tony Gao, Xiatao Sun, Daniel Rakita
  - **institution:** Yale University
  - **link:** https://arxiv.org/pdf/2512.24428
  - **contributions:** 1. An end-to-end system for generating a contextually grounded 3D mesh from a single RGB-D image in under one second. 2. Integration of open-vocabulary segmentation, accelerated diffusion-based mesh generation, and robust point cloud registration into a single optimized pipeline. 3. Demonstration of the system's effectiveness in enabling real-world robot manipulation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c21c85b85a842e2b91805631063ff03077c9e225bd56663524ef2ce7b37de98b_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a fast, end-to-end system that generates a high-quality, contextually grounded 3D mesh from a single RGB-D image in under one second. The method integrates open-vocabulary segmentation, accelerated diffusion-based mesh generation, and point cloud registration. The system enables the practical use of meshes for real-time robotic perception and planning, as demonstrated in a manipulation task.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Subsecond 3D Mesh Generation for Robot Manipulation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[生成慢且缺乏场景关联/Slow generation & lack of contextual grounding]
        C --> C1[开放词汇分割/Open-vocabulary segmentation]
        C --> C2[加速扩散网格生成/Accelerated diffusion mesh generation]
        C --> C3[点云配准/Point cloud registration]
        D --> D1[<1秒生成/<1 second generation]
        D --> D2[支持机器人操作/Enables robot manipulation]
    ```

- **[arXiv260101] Evolutionary Discovery of Sequence Acceleration Methods for Slab Geometry Neutron Transport**
  - **tags:** [other], [computational physics, numerical methods], [genetic programming, sequence acceleration, neutron transport, slab geometry, discrete ordinates]
  - **authors:** Japan K. Patel, Barry D. Ganapol, Anthony Magliari, Matthew C. Schmidt, Todd A. Wareing
  - **institution:** Gateway Scripts, University of Arizona, Varian Medical Systems, Washington University in St. Louis
  - **link:** https://arxiv.org/pdf/2512.24559
  - **contributions:** 1. Applied genetic programming to automatically discover novel convergence acceleration methods for neutron transport problems, moving beyond classical methods with fixed assumptions. 2. Evolved a specific mathematical formula accelerator tailored to the convergence characteristics of discrete ordinates (SN) solutions in slab geometry. 3. Demonstrated the discovered accelerator's superior performance, achieving over 75% success rate in improving convergence, nearly double that of classical techniques on the tested problem set.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d34d82f8c1e37e97ac83244d31b5fb8965de8b3a0c8f93a666dd8bc4b3585880_w640_q70.webp
  - **Simple LLM Summary:** This paper uses genetic programming to automatically discover new mathematical formulas for accelerating the convergence of numerical solutions to neutron transport problems in slab geometry. The evolved accelerator, which uses second differences and cross-product terms, significantly outperformed classical methods like Aitken's and Wynn's, showing the potential of AI to generate novel numerical methods in computational physics.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Evolutionary Discovery of Sequence Acceleration Methods for Slab Geometry Neutron Transport] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[经典加速方法泛化性差<br>Classical acceleration methods lack generalization]
        C --> C1[使用遗传编程进化公式<br>Use Genetic Programming to evolve formulas]
        D --> D1[发现新型加速器<br>Discovered novel accelerator]
        D --> D2[成功率 >75%, 性能翻倍<br>>75% success rate, nearly double performance]
    ```

- **[arXiv260101] From Sequential to Spatial: Reordering Autoregression for Efficient Visual Generation**
  - **tags:** [mlsys], [multi-modal inference], [autoregressive visual generation, radial parallel prediction, nested attention mechanism]
  - **authors:** Siyang Wang, Hanting Li, Wei Li, Jie Hu, Xinghao Chen, Feng Zhao
  - **institution:** University of Science and Technology of China, Huawei Noah's Ark Lab
  - **link:** https://arxiv.org/pdf/2512.24639
  - **contributions:** 1. Proposed a radial parallel prediction framework (RadAR) that reorders the autoregressive generation process from sequential to spatial, grouping tokens into concentric rings for parallel prediction. 2. Introduced a nested attention mechanism to dynamically refine inconsistent predictions during the forward pass, mitigating error accumulation from parallel generation. 3. Designed a method that preserves the structural locality and spatial coherence of visual scenes while significantly improving inference efficiency and parallelizability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bffd5ae0463dd26d6d9beddadbbf4c0de1249205c2c3865172fb5172c4b22d2_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the low inference efficiency of traditional autoregressive models in visual generation due to their sequential token-by-token decoding. It proposes RadAR, a framework that organizes generation around a radial topology, enabling parallel prediction of tokens within the same spatial ring and using a nested attention mechanism to correct errors. The method significantly accelerates generation while maintaining representational capacity.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[From Sequential to Spatial: Reordering Autoregression for Efficient Visual Generation] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统自回归模型顺序解码导致推理效率低/Traditional autoregressive sequential decoding leads to low inference efficiency]
        C --> C1[提出RadAR框架：径向并行预测/Propose RadAR framework: Radial Parallel Prediction]
        C1 --> C2[将token按空间距离分组为同心环/Group tokens into concentric rings by spatial distance]
        C1 --> C3[引入嵌套注意力机制进行动态修正/Introduce nested attention for dynamic correction]
        D --> D1[保持视觉结构局部性和空间连贯性/Preserves structural locality and spatial coherence]
        D --> D2[显著提高并行化和生成效率/Significantly improves parallelization and generation efficiency]
    ```

- **[arXiv260101] VLA-RAIL: A Real-Time Asynchronous Inference Linker for VLA Models and Robots**
  - **tags:** [mlsys], [multi-modal inference], [VLA models, action chunking, trajectory smoothing, asynchronous inference, robot motion control]
  - **authors:** Yongsheng Zhao, Lei Zhao, Baoping Cheng, Gongxin Yao, Xuanzhang Wen, Han Gao
  - **institution:** China Mobile (Hangzhou) Information Technology Co., Ltd.
  - **link:** https://arxiv.org/pdf/2512.24673
  - **contributions:** 1. Proposes VLA-RAIL, a framework for asynchronous inference and motion control to enable smooth, continuous robot action execution. 2. Introduces a Trajectory Smoother using polynomial fitting to filter noise and jitter within an action chunk. 3. Designs a Chunk Fuser to ensure position, velocity, and acceleration continuity between successive action chunks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/886e2a128c843b55a605e8cbe2a7b174fc4b0e84225f1908b0b180891d09bdad_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of motion jitter, stalling, and pauses when deploying Vision-Language-Action (VLA) models on robots due to sequential inference and execution. It proposes VLA-RAIL, a framework that decouples model inference from robot control via a Trajectory Smoother and Chunk Fuser. Experiments show it reduces jitter, increases speed, and improves task success rates for robotic manipulation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[VLA-RAIL: A Real-Time Asynchronous Inference Linker] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有方法导致机器人动作抖动、卡顿/Existing methods cause jitter, stalling in robot actions]
        C --> C1[异步推理与运动控制/Asynchronous inference & motion control]
        C1 --> C2[轨迹平滑器/Trajectory Smoother]
        C1 --> C3[块融合器/Chunk Fuser]
        D --> D1[减少运动抖动/Reduces motion jitter]
        D --> D2[提升执行速度/Enhances execution speed]
        D --> D3[提高任务成功率/Improves task success rates]
    ```

- **[arXiv260101] FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [N:M structured pruning, 4-bit quantization, systolic array, FPGA accelerator, hardware-software co-design]
  - **authors:** Fen-Yu Hsieh, Yun-Chang Teng, Ding-Yong Hong, Jan-Jan Wu
  - **institution:** Institute of Information Science, Academia Sinica
  - **link:** https://arxiv.org/pdf/2512.24713
  - **contributions:** 1. Proposes an automation framework and unified pipeline for applying N:M structured pruning and 4-bit integer quantization to compress LLMs. 2. Presents a hardware-software co-design method that generates a custom systolic-array-based FPGA accelerator for efficient inference. 3. Demonstrates the synergy of fine-grained sparsity and quantization, achieving significant reductions in storage and latency while offering flexibility beyond fixed hardware sparsity patterns.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a594f5eb4f19e15f5f182ee786cc270613c6a3d07553a78731a54b9a3ae90ea_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high computational and memory demands of LLMs by proposing a hardware-software co-design framework. The method combines N:M structured pruning and 4-bit quantization to compress models, and implements a custom FPGA accelerator for efficient inference. The results show significant reductions in storage and latency, demonstrating the effectiveness of the approach for deployable LLM inference.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("LLM部署困难/LLM Deployment Challenge")
        P1 --> P2("高计算与内存需求/High Computation & Memory Requirements")
        Method --> M1("模型压缩/Model Compression")
        M1 --> M2("N:M结构化剪枝与4-bit量化/N:M Structured Pruning & 4-bit Quantization")
        Method --> M3("软硬件协同设计/Hardware-Software Co-Design")
        M3 --> M4("生成基于脉动阵列的FPGA加速器/Generating Systolic-Array-based FPGA Accelerator")
        Results --> R1("存储减少4倍/4x Weight Storage Reduction")
        Results --> R2("矩阵乘法加速1.71倍/1.71x Matrix Multiplication Speedup")
        Results --> R3("端到端延迟降低1.29倍/1.29x End-to-End Latency Reduction")
    ```

- **[arXiv260101] FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation**
  - **tags:** [mlsys], [diffusion models], [video generation, diffusion sampling, model capacity, velocity divergence, inference acceleration]
  - **authors:** Jibin Song, Mingi Kwon, Jaeseok Jeong, Youngjung Uh
  - **institution:** Yonsei University
  - **link:** https://arxiv.org/pdf/2512.24724
  - **code:** https://jibin86.github.io/flowblending_project_page
  - **contributions:** 1. The observation that model capacity impact varies across denoising timesteps, being crucial in early/late stages but negligible in intermediate stages., 2. The proposal of FlowBlending, a stage-aware multi-model sampling strategy that dynamically allocates large and small models to different stages., 3. The introduction of simple criteria and a velocity-divergence analysis to identify capacity-sensitive regions and choose stage boundaries.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ac4128c7bf14ee06860b55c2869f6a243b40a94d93faf3a63e6549b8c5d06f8_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high computational cost of video diffusion models by proposing FlowBlending, a stage-aware sampling strategy that uses a large model for critical early/late denoising stages and a small model for the intermediate stage. This method achieves up to 1.65x faster inference with significantly fewer FLOPs while preserving the output quality of the large model, and is compatible with other acceleration techniques.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation") --> Problem("核心问题/Problem: High computational cost of video diffusion models")
        Root --> Method("主要方法/Method: Stage-aware multi-model sampling (large model for early/late stages, small model for intermediate stage)")
        Root --> Results("关键结果/Results: Faster inference, fewer FLOPs, maintained visual fidelity")
    ```

- **[arXiv260101] Big AI is accelerating the metacrisis: What can we do?**
  - **tags:** [nlp], [ethics & society], [metacrisis, language engineers, human flourishing, planetary boundaries, technofeudalism]
  - **authors:** Steven Bird
  - **institution:** Charles Darwin University
  - **link:** https://arxiv.org/pdf/2512.24863
  - **contributions:** 1. Identifies and critiques the role of "Big AI" and language engineers in accelerating converging global crises (ecological, meaning, language). 2. Highlights the ethical conflict between professional obligations (e.g., ACL Code of Ethics) and the harms caused by current NLP/AI development practices. 3. Proposes a paradigm shift for NLP, advocating for a future centered on human flourishing and amplifying social networks rather than scaling through large, polluting models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2352136b878f355e9ebcad11726708c80426973daa2249fba0b79ba62b81b583_w640_q70.webp
  - **Simple LLM Summary:** This paper argues that the current trajectory of "Big AI," particularly in NLP, is accelerating a global metacrisis. It critiques the field's focus on scalability and value-neutral technology development, which benefits powerful interests at the expense of the public good and the planet. The paper concludes by urgently calling for an alternative, life-affirming future for NLP centered on human flourishing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Big AI is accelerating the metacrisis: What can we do?] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Big AI加速生态、意义和语言危机/Big AI accelerates ecological, meaning, and language crises]
        B --> B2[语言工程师的伦理困境/Ethical dilemma of language engineers]
        C --> C1[批判当前可扩展性叙事/Critique current scalability narrative]
        C --> C2[呼吁探索替代方案/Call to explore alternatives]
        D --> D1[需要以人类繁荣为中心的未来/NLP future must center human flourishing]
        D --> D2[利用集体智慧设计生命肯定的NLP/Design life-affirming NLP with collective intelligence]
    ```

- **[arXiv260101] Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing**
  - **tags:** [cv], [3D object detection], [semi-automated annotation, human-in-the-loop, 3D object detection, data anonymization, domain adaptation]
  - **authors:** Andrii Gamalii, Daniel Górniak, Robert Nowak, Bartłomiej Olber, Krystian Radlak, Jakub Winter
  - **institution:** Warsaw University of Technology
  - **link:** https://arxiv.org/pdf/2512.24896
  - **contributions:** 1. A semi-automated annotation pipeline that combines AI-generated initial annotations with human verification to reduce cost and time. 2. A system architecture supporting iterative model retraining and incorporating data anonymization and domain adaptation techniques. 3. A methodology and toolset that accelerates the creation of a large-scale, multimodal autonomous driving dataset tailored to Polish road conditions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/575844a7a43a73f8b8d00aa31dfa90a80dbb02b7129fa4cb48b23a397afe6e78_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the costly and time-consuming problem of manually annotating large-scale, multimodal datasets for autonomous vehicles. It proposes a semi-automated, human-in-the-loop annotation pipeline that uses 3D object detection to generate initial labels, enabling iterative retraining and incorporating anonymization and adaptation techniques. The developed solution significantly reduces annotation time while ensuring high-quality, consistent labels, directly supporting the creation of a Polish-specific autonomous driving dataset.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing"] --> Problem["核心问题/Problem: Manual annotation of multimodal AV datasets is costly and time-consuming."]
        Root --> Method["主要方法/Method: A semi-automated, human-in-the-loop pipeline using 3D object detection for initial annotations."]
        Root --> Results["关键结果/Results: Substantial time savings and consistent, high-quality annotations."]
    ```

- **[arXiv260101] FineTec: Fine-Grained Action Recognition Under Temporal Corruption via Skeleton Decomposition and Sequence Completion**
  - **tags:** TBD
  - **authors:** Dian Shao, Mingfei Shi, Like Liu
  - **institution:** 
  - **link:** https://arxiv.org/pdf/2512.25067
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5283ff5d47b7344e785800154886fe627c149576029db00dc6b0fd29ebf4b9fb_w640_q70.webp

- **[arXiv260101] q3-MuPa: Quick, Quiet, Quantitative Multi-Parametric MRI using Physics-Informed Diffusion Models**
  - **tags:** [cv], [medical imaging], [diffusion models, quantitative MRI, data consistency, physics-informed, multi-parametric mapping]
  - **authors:** Shishuai Wang, Florian Wiesinger, Noemi Sgambelluri, Carolin Pirkl, Stefan Klein, Juan A. Hernandez-Tamames, Dirk H.J. Poot
  - **institution:** Erasmus MC (Erasmus University Medical Center)
  - **link:** https://arxiv.org/pdf/2512.23726
  - **contributions:** 1. Proposes a diffusion model-based method (q3-MuPa) for quantitative MRI mapping that combines a deep generative model with a physics-based data consistency constraint., 2. Enables high-quality mapping from a fourfold-accelerated, nearly silent MRI scan (MuPa-ZTE), reducing acquisition time to ~1 minute., 3. Demonstrates successful training on synthetic data from digital phantoms alone, with strong generalization to real patient and phantom scans.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e081389f251cbbacaf7c704cd1a34c3a032b2173e63192833db976abd6541d5e_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes q3-MuPa, a method that uses a physics-informed diffusion model to generate high-quality quantitative MRI maps (T1, T2, proton density) from accelerated, silent scans. The method integrates a denoising diffusion model with the MRI signal physics as a constraint during inference. It achieves accurate mapping from 1-minute scans and generalizes well to real data despite being trained only on synthetic phantoms.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[q3-MuPa: Quick, Quiet, Quantitative Multi-Parametric MRI] --> B(核心问题/Problem: Need for fast, quiet, and accurate quantitative MRI mapping)
        A --> C(主要方法/Method: Physics-informed diffusion model with data consistency)
        A --> D(关键结果/Results: High-accuracy maps from 1-min scans, trained on synthetic data)
    ```

- **[arXiv260101] Stochastic Galerkin Method and Hierarchical Preconditioning for PDE-constrained Optimization**
  - **tags:** [hpc], [numerical linear algebra], [hierarchical preconditioning, stochastic Galerkin method, PDE-constrained optimization, generalized polynomial chaos, uncertainty quantification]
  - **authors:** Zhendong Li, Akwum Onwunta, Bedřich Sousedík
  - **institution:** Lehigh University, University of Maryland, Baltimore County
  - **link:** https://arxiv.org/pdf/2512.23804
  - **contributions:** 1. Development of efficient hierarchical preconditioners for large-scale, ill-conditioned linear systems in stochastic PDE-constrained optimization. 2. A discretize-then-optimize framework integrating finite elements, stochastic Galerkin approximation, and time discretization for problems with uncertain coefficients. 3. Exploitation of sparsity in generalized polynomial chaos expansions to balance computational cost and preconditioning quality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05293316aad14f8b4a2329613d52a860965c42ee1108d515f0cd4dc855e7ddac_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes hierarchical preconditioners to accelerate the solution of optimal control problems governed by PDEs with uncertain coefficients. The method combines a discretize-then-optimize framework with stochastic Galerkin approximation and exploits sparsity in polynomial chaos expansions. Numerical experiments show the preconditioners significantly improve solver convergence for both steady-state and time-dependent problems under uncertainty.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Stochastic Galerkin Method and Hierarchical Preconditioning<br>随机Galerkin方法与分层预处理"] --> Problem
        Root --> Method
        Root --> Results
        Problem["PDE约束优化问题含不确定系数<br>PDE-constrained Optimization with Uncertain Coefficients"] --> P1["大规模病态线性系统<br>Large-scale Ill-conditioned Linear Systems"]
        Method["离散-优化框架与分层预处理<br>Discretize-then-Optimize & Hierarchical Preconditioning"] --> M1["有限元/随机Galerkin/时间离散<br>FEM/Stochastic Galerkin/Time Discretization"]
        Method --> M2["利用gPC展开的稀疏性<br>Exploit Sparsity of gPC Expansion"]
        Results["数值实验<br>Numerical Experiments"] --> R1["显著加速迭代求解器<br>Significantly Accelerates Iterative Solvers"]
        Results --> R2["为稳态/瞬态问题提供鲁棒求解器<br>Robust Solvers for Steady/Time-dependent Problems"]
    ```

- **[arXiv260101] A multimodal Transformer for InSAR-based ground deformation forecasting with cross-site generalization across Europe**
  - **tags:** [cv], [remote sensing image analysis], [InSAR, Transformer, ground deformation forecasting, cross-site generalization, multimodal learning]
  - **authors:** Wendong Yao, Binhua Huang, Soumyabrata Dev
  - **institution:** ADAPT SFI Research Centre, University College Dublin
  - **link:** https://arxiv.org/pdf/2512.23906
  - **contributions:** 1. Proposed a novel multimodal patch-based Transformer architecture for InSAR-based ground deformation nowcasting, integrating displacement snapshots with static kinematic indicators and temporal encodings. 2. Demonstrated superior performance of the proposed model over baseline models (CNN-LSTM, STGCN) on a test tile in eastern Ireland, achieving high accuracy (RMSE=0.90mm, R²=0.97). 3. Showcased strong cross-site generalization by training on one tile and applying the model without fine-tuning to five unseen European tiles, maintaining high performance (R²≥0.93) across diverse deformation patterns.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/36024dc5598b92b146557714c9e66eeb494b793bdcfaacb98b73cf6725cc8bfa_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of forecasting ground deformation from InSAR time series data. It proposes a multimodal Transformer model that combines recent displacement maps with kinematic indicators and temporal features to predict the next displacement epoch. The model achieves high accuracy and demonstrates strong generalization across different geographic sites in Europe without requiring retraining.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[论文标题: A multimodal Transformer for InSAR-based ground deformation forecasting] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: 如何利用历史InSAR数据预测未来的地表形变?] --> P1[挑战/Challenges: 长期趋势、季节周期、突变事件的叠加]
        Method[主要方法/Method: 多模态Transformer] --> M1[输入/Inputs: 近期形变图、静态运动学指标、时间编码]
        Method --> M2[任务/Task: 单步、固定间隔的下一时期临近预报]
        Results[关键结果/Results] --> R1[性能/Performance: RMSE=0.90mm, R²=0.97 (爱尔兰测试集)]
        Results --> R2[泛化/Generalization: 跨欧洲5个未见区域，R²≥0.93]
    ```

- **[arXiv260101] An Adaptive, Disentangled Representation for Multidimensional MRI Reconstruction**
  - **tags:** [cv], [medical image reconstruction], [disentangled representation, latent diffusion model, self-supervised learning, multidimensional MRI, zero-shot adaptation]
  - **authors:** Ruiyang Zhao, Fan Lam
  - **institution:** University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2512.24674
  - **contributions:** 1. A novel learned feature-based image representation that disentangles features like geometry and contrast into distinct latent spaces. 2. The integration of a latent diffusion model to impose stronger constraints on the disentangled feature spaces. 3. New reconstruction formulations and algorithms that combine the learned representation with zero-shot self-supervised learning adaptation and subspace modeling.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f858a20b731ce7ed66cd4e854bc6e6bdd5ae01548b1060d4814f643684ce73a0_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new method for reconstructing multidimensional MRI data by learning a disentangled image representation that separates features like geometry and contrast into distinct latent spaces, enhanced by a latent diffusion model. The approach integrates this representation with zero-shot self-supervised learning, enabling improved reconstruction without task-specific training. It demonstrates superior performance on accelerated T1 and T2 parameter mapping compared to state-of-the-art methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["An Adaptive, Disentangled Representation for Multidimensional MRI Reconstruction"] --> Problem["核心问题/Problem: Limited data for task-specific training in multidimensional MRI reconstruction"]
        Root --> Method["主要方法/Method: Disentangled representation + Latent diffusion model + Zero-shot self-supervised adaptation"]
        Root --> Results["关键结果/Results: Improved performance on T1/T2 mapping without task-specific training"]
    ```

- **[arXiv260101] Are First-Order Diffusion Samplers Really Slower? A Fast Forward-Value Approach**
  - **tags:** [mlsys], [diffusion models], [diffusion model, training-free acceleration, first-order sampler, forward-value discretization]
  - **authors:** Yuchen Jiao, Na Li, Changxiao Cai, Gen Li
  - **institution:** The Chinese University of Hong Kong, Zhejiang University, University of Michigan
  - **link:** https://arxiv.org/pdf/2512.24927
  - **contributions:** 1. Challenges the prevailing belief that higher-order ODE solvers are inherently faster for DPM sampling, proposing that the placement of DPM evaluations is a crucial, independent design factor. 2. Introduces a novel, training-free first-order sampler that approximates the forward-value evaluation using a cheap one-step lookahead predictor, resulting in a leading discretization error with the opposite sign to DDIM. 3. Provides theoretical guarantees for the sampler's approximation of the ideal forward-value trajectory while maintaining first-order convergence, and demonstrates empirical competitiveness with higher-order samplers on standard benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef8de5dcbba9edb9daa0ab1ba8e254668331d9851247da681521a06ad8b83b22_w640_q70.webp
  - **Simple LLM Summary:** This paper challenges the view that first-order diffusion samplers are inherently slower than higher-order ones. It proposes a new first-order sampler that uses a forward-value approach with a lookahead predictor to better place model evaluations. The method is theoretically sound and empirically matches or outperforms state-of-the-art higher-order samplers on image generation tasks under the same computational budget.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["Are First-Order Diffusion Samplers Really Slower? A Fast Forward-Value Approach<br>论文标题"] --> B["核心问题/Problem<br>Higher-order solvers are standard; first-order methods are seen as slower.<br>高阶求解器是标准；一阶方法被认为更慢。"]
        A --> C["主要方法/Method<br>Proposes a training-free first-order sampler using forward-value evaluation via a one-step lookahead predictor.<br>提出一种免训练的一阶采样器，通过一步前瞻预测器进行前向值评估。"]
        A --> D["关键结果/Results<br>Sampler improves quality under same NFE budget, competitive with higher-order methods.<br>采样器在相同NFE预算下提升质量，与高阶方法竞争。"]
    ```
