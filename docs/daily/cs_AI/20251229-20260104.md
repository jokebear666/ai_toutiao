---
slug: /daily/csai/20251229-20260104
---
# 20251229-20260104 (cs.AI)

## 2025-12-29

- **[arXiv251229] CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation**
  - **tags:** [ai], [reinforcement learning], [dream-replay reinforcement learning, evolutionary algorithms, adaptive code generation]
  - **authors:** Santhosh Kumar Ravindran
  - **institution:** Microsoft Corporation
  - **link:** https://arxiv.org/pdf/2512.21351
  - **contributions:** 1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as "genomes" that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp
  - **Simple LLM Summary:** CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM代码生成缺乏适应性，难以应对API变化/LLM code generation lacks adaptability to API changes]
        C --> C1[将RL轨迹视为基因组进行进化操作/Treat RL trajectories as genomes for evolutionary operations]
        C --> C2[在夜间回放阶段进行突变与选择/Mutation and selection during nocturnal replay]
        D --> D1[解决方案新颖性提升35%/35% higher novelty in solutions]
        D --> D2[适应速度加快25%/25% faster adaptation]
    ```

- **[arXiv251229] EcoNet: Multiagent Planning and Control Of Household Energy Resources Using Active Inference**
  - **tags:** [mlsys], [agent system], [active inference, multi-agent systems, home energy management systems (HEMS), distributed energy resources (DER), Bayesian inference]
  - **authors:** John C. Boik, Kobus Esterhuysen, Jacqueline B. Hynes, Axel Constant, Ines Hipolito, Mahault Albarracin, Alex B. Kiefer, Karl Friston
  - **institution:** VERSES, University of Sussex, Macquarie University, UCL (University College London)
  - **link:** https://arxiv.org/pdf/2512.21343
  - **contributions:** 1. Proposes EcoNet, a novel Bayesian framework for household and neighborhood energy management based on active inference. 2. Addresses the challenge of planning under uncertainty (e.g., weather, solar forecasts) while handling complex, conditional, and conflicting household goals. 3. Demonstrates the approach through simulations for multiagent planning and control of distributed energy resources.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b885d3c6c9f392a494063522c79cde9a59fead8ab6b04010259b6485f007cec8_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces EcoNet, a multiagent planning and control system for household energy resources using active inference, a Bayesian approach, to manage uncertainty and conflicting goals. The method aims to optimize energy use, costs, and emissions while maintaining comfort. Simulation results demonstrate its potential for improved energy management and coordination.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[EcoNet: 多智能体家庭能源规划与控制 / EcoNet: Multiagent Household Energy Planning & Control] --> B[核心问题 / Problem]
        A --> C[主要方法 / Method]
        A --> D[关键结果 / Results]
        B --> B1[复杂且冲突的家庭目标 / Complex & Conflicting Household Goals]
        B --> B2[决策存在不确定性 / Decision-making Under Uncertainty]
        C --> C1[基于主动推理的贝叶斯方法 / Active Inference-based Bayesian Approach]
        C --> C2[多智能体规划与控制 / Multiagent Planning & Control]
        D --> D1[模拟结果展示 / Simulation Results Presented]
        D --> D2[改善能源管理与协调 / Improved Energy Management & Coordination]
    ```

- **[arXiv251229] Multi-Agent LLM Committees for Autonomous Software Beta Testing**
  - **tags:** [se], [automated software testing], [multi-agent system, large language model, vision-language model, consensus voting, beta testing]
  - **authors:** Sumanth Bharadwaj Hachalli Karanam, Dhiwahar Adhithya Kennady
  - **institution:** New York University
  - **link:** https://arxiv.org/pdf/2512.21352
  - **contributions:** 1. A novel multi-agent committee framework that uses a three-round voting protocol for consensus-based decision-making in software testing. 2. Integration of vision-enabled LLMs and diverse testing personas to systematically explore and understand web application user interfaces. 3. Demonstrated significant performance improvements over single-agent baselines in task success, bug detection (F1 score), and security vulnerability coverage on established benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40573d0b1209c41e9825c09111398107cc51ee9d86c5234b50bea2515d0ab37f_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high cost of manual software beta testing and the limitations of single-agent LLM approaches by proposing a multi-agent committee framework. The method employs diverse, vision-enabled LLMs that collaborate through a structured voting protocol and persona-driven behavior to autonomously test web applications. The results show that this multi-agent approach significantly outperforms single-agent baselines in task success rates, bug detection, and security testing coverage, making it suitable for real-time CI/CD integration.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multi-Agent LLM Committees for Autonomous Software Beta Testing] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[手动测试成本高，单智能体LLM存在幻觉/Manual testing costly, single-agent LLM hallucinates]
        C --> C1[多智能体委员会与三轮投票协议/Multi-agent committee & three-round voting]
        C --> C2[视觉LLM与角色多样性/Vision LLMs & persona diversity]
        D --> D1[任务成功率89.5%，超越基线/Task success 89.5%, beats baseline]
        D --> D2[动作延迟0.71秒，适合CI/CD/Action latency 0.71s, suitable for CI/CD]
        D --> D3[覆盖8/10 OWASP漏洞类别/Covers 8/10 OWASP Top 10]
    ```

- **[arXiv251229] Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software**
  - **tags:** [se], [software fairness], [correlation tuning, phi-coefficient, multi-objective optimization, pre-processing, bias mitigation]
  - **authors:** Ying Xiao, Shangwen Wang, Sicen Liu, Dingyuan Xue, Xian Zhan, Yepang Liu, Jie M. Zhang
  - **institution:** King’s College London, National University of Defense Technology, Southern University of Science and Technology, The Hong Kong Polytechnic University
  - **link:** https://arxiv.org/pdf/2512.21348
  - **contributions:** 1. Proposes a novel pre-processing bias mitigation method called Correlation Tuning (CoT) that adjusts data correlations. 2. Introduces the Phi-coefficient as an intuitive measure to quantify correlation between sensitive attributes and labels. 3. Employs multi-objective optimization to address proxy biases, demonstrating superior effectiveness over state-of-the-art methods in single and multiple attribute scenarios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4f80681a9ac6a6c3ad7d2bd938623a06836acba00279d9cec368a5ebbe44df3_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Correlation Tuning (CoT), a novel pre-processing method to mitigate bias in ML software by adjusting data correlations using the Phi-coefficient and multi-objective optimization. It frames fairness as a core software quality issue. Extensive evaluation shows CoT significantly improves performance for unprivileged groups and reduces key bias metrics, outperforming existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统公平研究忽视软件质量维度/Traditional fairness research neglects software quality dimension]
        B --> B2[预处理方法效果不足/Pre-processing methods lack effectiveness]
        C --> C1[提出相关性调优 (CoT)/Propose Correlation Tuning (CoT)]
        C --> C2[使用Phi系数量化相关性/Use Phi-coefficient to quantify correlation]
        C --> C3[采用多目标优化/Employ multi-objective optimization]
        D --> D1[提高弱势群体TPR 17.5%/Increase unprivileged group TPR by 17.5%]
        D --> D2[关键偏差指标降低 >50%/Key bias metrics reduced by >50%]
        D --> D3[超越SOTA方法 3-10个百分点/Outperform SOTA by 3-10 percentage points]
    ```

- **[arXiv251229] Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks**
  - **tags:** [db], [text-to-SQL], [unanswerable question detection, few-shot prompting, biomedical databases]
  - **authors:** Jasmin Saxer, Isabella Maria Aigner, Luise Linzmeier, Andreas Weiler, Kurt Stockinger
  - **institution:** Zurich University of Applied Sciences, University of Zurich
  - **link:** https://arxiv.org/pdf/2512.21345
  - **contributions:** 1. Proposed Query Carefully, a pipeline integrating LLM-based SQL generation with explicit detection of unanswerable inputs. 2. Constructed OncoMX-NAQ, a benchmark dataset of 80 no-answer questions for biomedical text-to-SQL. 3. Demonstrated that balanced few-shot prompting with both answerable and unanswerable examples achieves high unanswerable-detection accuracy without degrading performance on answerable queries.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d95c00b7fa86810771a1c8fb0ff6fd8768baaa0419f172cc5c7a3068ac67a64_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the risk of text-to-SQL systems generating executable but incorrect SQL for ambiguous or unanswerable queries, especially in biomedical contexts. The authors propose the Query Carefully pipeline, which uses an LLM with schema-aware prompts and few-shot examples to detect and abstain from unanswerable inputs. Their evaluation shows the method achieves high detection accuracy for structurally unanswerable queries, though challenges remain for semantic ambiguities like missing values.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks") --> Problem
        Root --> Method
        Root --> Results
        Problem("核心问题/Problem") --> P1("Text-to-SQL对不可回答查询生成可执行SQL/Text-to-SQL generates executable SQL for unanswerable queries")
        P1 --> P2("生物医学领域风险高/High risk in biomedical contexts")
        Method("主要方法/Method") --> M1("Query Carefully 管道/Query Carefully pipeline")
        M1 --> M2("LLM (llama3.3:70b) + 模式感知提示 + 少样本/LLM (llama3.3:70b) + schema-aware prompts + few-shot")
        M2 --> M3("包含可回答与不可回答示例/Includes answerable and unanswerable examples")
        Results("关键结果/Results") --> R1("构建OncoMX-NAQ基准/Built OncoMX-NAQ benchmark")
        R1 --> R2("不可回答检测准确率0.8/Unanswerable-detection accuracy 0.8")
        R2 --> R3("结构性问题检测好，语义模糊挑战大/Good for structural, challenging for semantic ambiguity")
    ```

- **[arXiv251229] A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers**
  - **tags:** [ai], [reinforcement learning], [Relevance-Zone Based Search, AlphaZero, Life-and-Death problems, heuristic search, pattern table]
  - **authors:** Chung-Chin Shih, Ti-Rong Wu, Ting Han Wei, Yu-Shan Hsu, Hung Guei, I-Chen Wu
  - **institution:** Academia Sinica, National Yang Ming Chiao Tung University, Kochi University of Technology
  - **link:** https://arxiv.org/pdf/2512.21365
  - **code:** https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ
  - **contributions:** 1. Applied and analyzed Relevance-Zone Based Search (RZS) and relevance-zone pattern tables to solve Go Life-and-Death problems, identifying critical relevance-zones. 2. Discovered that solvers can find rare patterns and even alternative solutions differing from established human grandmaster answers. 3. Identified and analyzed key limitations of current solvers, such as misjudging rare patterns and prioritizing direct survival over territory maximization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6376caf4e3dced23991e86eb4d5b0f512ce3623019adeaf18ee253d5fd00c507_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the performance of state-of-the-art computer Go solvers using Relevance-Zone Based Search on classic Life-and-Death problems. The study finds that while these solvers can identify critical areas and discover rare patterns, they exhibit limitations like misjudging pattern values and having a non-human preference for direct survival over territory. The authors suggest future approaches to address these solver issues.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers<br/>使用基于相关区域求解器解决围棋死活问题的研究"] --> B["核心问题/Problem<br/>Analyzing solver behavior on Go Life-and-Death problems<br/>分析求解器在围棋死活问题上的行为"]
        A --> C["主要方法/Method<br/>Using Relevance-Zone Based Search (RZS) and pattern tables<br/>使用基于相关区域的搜索和模式表"]
        A --> D["关键结果/Results<br/>Identifies relevance-zones, finds rare/alternative solutions, reveals solver limitations<br/>识别相关区域，发现罕见/替代解法，揭示求解器局限"]
    ```

- **[arXiv251229] From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration**
  - **tags:** [ai], [computational psychology], [multimodal large language model, multi-agent collaboration, cosine similarity, projective assessment, psychological report generation]
  - **authors:** Shuide Wen, Yu Sun, Beier Ku, Zhi Gao, Lijun Ma, Yang Yang, Can Jiao
  - **institution:** Tsinghua University, Shenzhen University, University of Oxford, Guangzhou University of Chinese Medicine, Harbin Institute of Technology, Shenzhen Institute of Education Sciences
  - **link:** https://arxiv.org/pdf/2512.21360
  - **contributions:** 1. Proposed a novel multi-agent collaboration framework to automate the interpretation of House-Tree-Person drawings, decoupling visual feature recognition from psychological inference. 2. Demonstrated that multimodal large language models (MLLMs) can achieve expert-level baseline comprehension in interpreting projective drawings, with high semantic similarity to human expert interpretations. 3. Introduced a destigmatizing narrative and social-psychological perspective integration to correct visual hallucinations and enhance the ecological validity and coherence of automated psychological reports.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/681955eb18a63880e0327c5debb6e992188de12ca52cef0c9c34258f09c3a91d_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes an automated assessment framework for the House-Tree-Person drawing test using multimodal LLMs and multi-agent collaboration to address issues of subjective scoring and lack of standardization. The framework effectively interprets drawings with high similarity to expert analysis and generates coherent psychological reports. The results confirm the potential of multimodal models as standardized tools for projective psychological assessment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration<br>从视觉感知到深度共情：基于多模态大模型与多智能体协作的房树人绘画自动评估框架] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>HTP测试评分标准不一，依赖主观经验，缺乏统一量化系统] --> B1
        C[主要方法/Method<br>多模态大语言模型与多智能体协作框架] --> C1
        D[关键结果/Results<br>模型解释与专家解释语义相似度高，多智能体系统生成有效心理报告] --> D1
        B1[HTP test has heterogeneous scoring, relies on subjective experience, lacks unified quantitative coding]
        C1[Multimodal LLMs and multi-agent collaboration framework]
        D1[High semantic similarity to expert interpretations; multi-agent system produces reports with high ecological validity]
    ```

- **[arXiv251229] Reflection-Driven Control for Trustworthy Code Agents**
  - **tags:** [mlsys], [agent system], [reflection-driven control, secure code generation, trustworthy agents, reflective memory, safety control]
  - **authors:** Bin Wang, Jiazheng Quan, Xingrui Yu, Hansen Hu, Yuhao, Ivor Tsang
  - **institution:** Peking University, Xiamen University, Agency for Science, Technology and Research (A*STAR)
  - **link:** https://arxiv.org/pdf/2512.21354
  - **contributions:** 1. Introduces Reflection-Driven Control, a standardized and pluggable control module that integrates self-reflection as an explicit, internal step in an agent's reasoning process. 2. Instantiates the method for secure code generation, using a reflection loop to monitor decisions and retrieve repair examples/guidelines from an evolving reflective memory to inject constraints. 3. Empirically demonstrates that the approach substantially improves security and policy compliance of generated code while preserving functional correctness, with minimal overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of reliable safety controls in LLM agents by proposing Reflection-Driven Control, a module that makes self-reflection an explicit, continuous part of the agent's reasoning to monitor and constrain its decisions using evidence from a reflective memory. Evaluated on security-critical code generation tasks, the method significantly improves code security and compliance while maintaining functionality, offering a practical path toward trustworthy AI coding agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Reflection-Driven Control for Trustworthy Code Agents] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[LLM代理缺乏可靠的安全控制/LLM agents lack reliable safety controls]
        Problem --> P2[可能产生有害输出/Can produce harmful outputs]
        Method --> M1[将自我反思作为推理的显式步骤/Elevates self-reflection to an explicit reasoning step]
        Method --> M2[内部反思循环监控决策路径/Internal reflection loop monitors decision path]
        Method --> M3[从反思记忆中检索修复示例/Retrieves repair examples from reflective memory]
        Results --> R1[显著提高生成代码的安全性和合规性/Substantially improves security & policy compliance]
        Results --> R2[基本保持功能正确性/Largely preserves functional correctness]
        Results --> R3[运行时和token开销最小/Minimal runtime & token overhead]
    ```

- **[arXiv251229] AInsteinBench: Benchmarking Coding Agents on Scientific Repositories**
  - **tags:** [se], [software engineering], [benchmark, scientific computing, code generation, pull requests, test-driven verification]
  - **authors:** Titouan Duston, Shuo Xin, Yang Sun, Daoguang Zan, Aoyan Li, Shulin Xin, Kai Shen, Yixiao Chen, Qiming Sun, Ge Zhang, Jiashuo Liu, Huan Zhou, Jingkai Liu, Zhichen Pu, Yuanheng Wang, Bo-Xuan Ge, Xin Tong, Fei Ye, Zhi-Chao Zhao, Wen-Biao Han, Zhoujian Cao, Yueran Zhao, Weiluo Ren, Qingshen Long, Yuxiao Liu, Anni Huang, Yidi Du, Yuanyuan Rong, Jiahao Peng
  - **institution:** ByteDance Seed, Princeton University
  - **link:** https://arxiv.org/pdf/2512.21373
  - **code:** https://github.com/ByteDance-Seed/AInsteinBench
  - **contributions:** 1. Introduces a novel benchmark (AInsteinBench) for evaluating LLM agents in end-to-end scientific development using real-world, production-grade codebases. 2. Curates tasks from maintainer-authored pull requests across six diverse scientific domains, ensuring scientific challenge and calibrated difficulty. 3. Employs executable environments and test-driven verification to measure core competencies beyond surface-level code generation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces AInsteinBench, a benchmark designed to evaluate LLM agents' ability to function as scientific computing developers by solving tasks derived from real pull requests in scientific repositories. It uses executable environments and test-driven verification to assess deeper competencies. The benchmark provides a new standard for measuring AI's role in computational scientific research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AInsteinBench: Benchmarking Coding Agents on Scientific Repositories] --> B[核心问题/Problem: Can LLM agents operate as scientific computing development agents?]
        A --> C[主要方法/Method: End-to-end evaluation using tasks from real scientific pull requests]
        A --> D[关键结果/Results: Measures ability beyond surface-level code generation]
    ```

- **[arXiv251229] Safe Path Planning and Observation Quality Enhancement Strategy for Unmanned Aerial Vehicles in Water Quality Monitoring Tasks**
  - **tags:** [cv], [robotic perception and planning], [Interfered Fluid Dynamical System (IFDS), Model Predictive Control (MPC), Dynamic Flight Altitude Adjustment (DFAA)]
  - **authors:** Yuanshuang Fu, Qianyao Wang, Qihao Wang, Bonan Zhang, Jiaxin Zhao, Yiming Cao, Zhijun Li
  - **institution:** University of Electronic Science and Technology of China, North China University of Technology
  - **link:** https://arxiv.org/pdf/2512.21375
  - **contributions:** 1. Proposes a dynamic prediction model that transforms time-varying light and shadow disturbances (e.g., sun glint) into 3D virtual obstacles for path planning. 2. Introduces an improved IFDS algorithm combined with an MPC framework to generate smooth, safe, and dynamically feasible real-time trajectories for UAVs. 3. Designs a Dynamic Flight Altitude Adjustment (DFAA) mechanism to actively lower flight altitude in narrow observable areas, enhancing spatial resolution and data quality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5582bc8dd27c45953b75b142df4da9d25f5164a9ed81f8842a846572fbb8a2f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of UAV water quality monitoring being hindered by dynamic illumination disturbances like shadows and sun glint, which degrade spectral data. The proposed method actively plans safe flight paths by modeling disturbances as obstacles, using an improved IFDS and MPC for real-time trajectory optimization, and dynamically adjusting altitude to improve data quality. Simulation results show the method achieves a 98% obstacle avoidance success rate and increases effective observation data volume by approximately 27%.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Safe Path Planning and Observation Quality Enhancement Strategy for UAVs in Water Quality Monitoring Tasks] --> B
    A --> C
    A --> D
    B[核心问题/Problem<br>Dynamic illumination disturbances (shadows, sun glint) cause spectral distortion, reducing data quality and safety.]
    C[主要方法/Method<br>1. Model disturbances as 3D virtual obstacles.<br>2. Improved IFDS + MPC for real-time path planning.<br>3. Dynamic Flight Altitude Adjustment (DFAA).]
    D[关键结果/Results<br>98% obstacle avoidance success rate, improved path smoothness, ~27% increase in effective observation data.]
    ```

- **[arXiv251229] LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors**
  - **tags:** [sec], [adversarial attacks], [adversarial attack, large language model, retrieval-augmented generation, Android malware detection, adversarial training]
  - **authors:** Tianwei Lan, Farid Naït-Abdesselam
  - **institution:** Université Paris Cité
  - **link:** https://arxiv.org/pdf/2512.21404
  - **contributions:** 1. Proposes LAMLAD, a novel adversarial attack framework that uses a dual-agent LLM architecture (manipulator and analyzer) to generate feature-level perturbations for evading Android malware detectors., 2. Integrates Retrieval-Augmented Generation (RAG) into the LLM pipeline to improve the efficiency and contextual awareness of the attack., 3. Proposes and evaluates an adversarial training-based defense strategy to enhance model robustness against the proposed LAMLAD-style attacks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6061210b194ba5cf79f70b8959faa3abe6b3e91ffad512d9cfd319de948593bb_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes LAMLAD, a novel adversarial attack framework that leverages the generative and reasoning capabilities of Large Language Models (LLMs) to bypass ML-based Android malware classifiers. The method uses a dual-agent LLM architecture with RAG to generate realistic, functionality-preserving feature perturbations, achieving a high attack success rate. The paper also demonstrates that adversarial training can significantly reduce the effectiveness of such attacks, enhancing model robustness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors] --> B[核心问题/Problem: ML-based Android malware detectors are vulnerable to adversarial attacks.]
        A --> C[主要方法/Method: Proposes LAMLAD, a dual-agent LLM framework with RAG for generating stealthy perturbations.]
        A --> D[关键结果/Results: Achieves up to 97% attack success rate; adversarial training defense reduces ASR by >30%.]
    ```

- **[arXiv251229] Feasible strategies in three-way conflict analysis with three-valued ratings**
  - **tags:** [ai], [conflict analysis], [three-way conflict analysis, feasible strategy, consistency measure, non-consistency measure, weighted agent-issue evaluation]
  - **authors:** Jing Liu, Mengjun Hu, Guangming Lang
  - **institution:** Changsha University of Science and Technology, Saint Mary's University
  - **link:** https://arxiv.org/pdf/2512.21420
  - **contributions:** 1. Proposes a novel framework for identifying feasible strategies in conflict resolution from the perspectives of consistency and non-consistency. 2. Introduces weighted consistency and non-consistency measures that incorporate the importance of both agents and issues. 3. Develops algorithms to systematically identify feasible strategies, L-order feasible strategies, and optimal solutions, demonstrating superior performance over existing approaches.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4b2e48e756e98608f4388b841aa7940f0ba7b237737fa314abc4db83fbf680f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the gap in formulating actionable strategies for conflict resolution within three-way conflict analysis. It proposes a method that computes agent clique ratings and uses novel weighted consistency and non-consistency measures to identify feasible and optimal strategies. The approach is validated through case studies and shown to outperform conventional conflict analysis models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Feasible strategies in three-way conflict analysis<br>三向冲突分析中的可行策略] --> B(Problem: Lack of focus on conflict resolution strategies<br>问题: 缺乏对冲突解决策略的关注)
        A --> C(Method: Weighted consistency/non-consistency measures & algorithms<br>方法: 加权一致/非一致性度量与算法)
        A --> D(Results: Outperforms conventional approaches, identifies optimal solutions<br>结果: 优于传统方法，识别最优解)
    ```

- **[arXiv251229] Three-way conflict analysis based on alliance and conflict functions**
  - **tags:** [ai], [decision theory], [three-way decision, conflict analysis, alliance function, conflict function, alliance set]
  - **authors:** Junfang Luo, Mengjun Hu, Guangming Lang, Xin Yang, Keyun Qin
  - **institution:** Southwestern University of Finance and Economics, University of Regina, Changsha University of Science and Technology, Southwest Jiaotong University
  - **link:** https://arxiv.org/pdf/2512.21419
  - **contributions:** 1. Proposes a novel separation of the traditional auxiliary function into distinct alliance and conflict functions to clarify semantic interpretation in conflict analysis. 2. Introduces a framework for trisecting agents, issues, and agent pairs based on the new alliance and conflict functions. 3. Explores and applies new concepts such as alliance sets and strategies to solve crucial questions in conflict analysis, demonstrating the model with a real-world application.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54277009925f58600c765060d6cbc575e96e562e3c9748aa2f54e97b83024e0b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the semantic ambiguity in aggregating traditional three-way conflict analysis functions by proposing a separation into distinct alliance and conflict functions. The method enables clearer trisection of agents, issues, and agent pairs, leading to the exploration of alliance sets and strategies. The main conclusion is that this separation provides a more interpretable and applicable framework for conflict analysis, as illustrated by a real-world example.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Three-way Conflict Analysis Based on Alliance and Conflict Functions] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统辅助函数聚合语义模糊/Semantic ambiguity in aggregating traditional auxiliary functions]
        C --> C1[分离为联盟与冲突函数/Separate into alliance and conflict functions]
        C --> C2[基于新函数进行三分/Trisec based on new functions]
        D --> D1[提出联盟集与策略概念/Propose alliance sets and strategies]
        D --> D2[提供真实应用案例/Provide a real-world application]
    ```

- **[arXiv251229] Teaching People LLM's Errors and Getting it Right**
  - **tags:** [nlp], [human-ai interaction], [overreliance, failure patterns, mental models, user study, meta-labels]
  - **authors:** Nathan Stringham, Fateme Hashemi Chaleshtori, Xinyuan Yan, Zhichao Xu, Bei Wang, Ana Marasović
  - **institution:** University of Utah
  - **link:** https://arxiv.org/pdf/2512.21422
  - **contributions:** 1. Empirically demonstrated that failure patterns for LLMs do exist by identifying sizable, error-prone meta-label groups in datasets, countering the hypothesis that their absence caused prior teaching failures. 2. Evaluated automated methods for discovering these failure patterns (prompting and embedding-based) and found mixed results, identifying a key bottleneck in the teaching pipeline. 3. Proposed and validated a new metric for teaching effectiveness—assessing a user's ability to anticipate LLM errors using taught patterns—which showed a positive effect, unlike traditional human-AI team accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83a262b8daf44fdf951904b9202074fd9db4ef9e9666cd5769ec1d8514053804_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates why prior attempts to teach users about LLM failure patterns to reduce overreliance have failed. It finds that failure patterns do exist, but automated methods to discover them are unreliable, and proposes a new user-centric evaluation metric that shows teaching can be effective. The conclusion is that teaching failure patterns is viable but requires better failure-discovery methods and appropriate metrics.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Teaching People LLM’s Errors and Getting it Right] --> B[核心问题/Problem: Users overrely on LLMs due to inaccurate mental models]
        A --> C[主要方法/Method: Analyze failure pattern existence, test discovery methods, propose new evaluation metric]
        A --> D[关键结果/Results: Patterns exist, discovery methods are mixed, new metric shows teaching is effective]
    ```

- **[arXiv251229] Three-way decision with incomplete information based on similarity and satisfiability**
  - **tags:** [ai], [rough set theory], [three-way decision, incomplete information, similarity degree, satisfiability degree, approximability]
  - **authors:** Junfang Luo, Mengjun Hu, Keyun Qin
  - **institution:** Southwest Jiaotong University, University of Regina
  - **link:** https://arxiv.org/pdf/2512.21421
  - **contributions:** 1. Proposes a new measure of similarity degree of objects as a generalization of equivalence relations for handling incomplete information in the computational formulation of three-way decision. 2. Introduces a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability for the conceptual formulation of three-way decision under incomplete information. 3. Proposes novel approaches for three-way decision using approximability of objects and confidence of formulas, pointing out new research directions beyond the common method of similarity classes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d87784acc1b1cc397b822153c118be23974be9721c3d19c9dfc95fbbaef158e_w640_q70.webp
  - **Simple LLM Summary:** This paper generalizes the computational and conceptual formulations of three-way decision to handle incomplete information, which is common in real-world applications. For the computational side, it introduces a similarity degree measure and explores decision-making via α-similarity classes and approximability; for the conceptual side, it proposes a satisfiability degree measure and studies approaches using α-meaning sets and confidence. The work extends rough set theory and identifies promising new directions for three-way decision under uncertainty.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Three-Way Decision with Incomplete Information Based on Similarity and Satisfiability] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[处理不完全信息/Handling Incomplete Information]
        C --> C1[计算式: 相似度/Computational: Similarity Degree]
        C --> C2[概念式: 可满足度/Conceptual: Satisfiability Degree]
        C1 --> C1a[α-相似类/α-Similarity Classes]
        C1 --> C1b[可逼近性/Approximability]
        C2 --> C2a[α-意义集/α-Meaning Sets]
        C2 --> C2b[置信度/Confidence]
        D --> D1[推广两种表述/Generalizes Both Formulations]
        D --> D2[指出新方向/Points to New Directions]
    ```

- **[arXiv251229] Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models**
  - **tags:** [nlp], [computational ethics], [moral context, probabilistic clustering, LLM semantics, interpretable prediction, human judgment]
  - **authors:** Geoffroy Morlat, Marceau Nahon, Augustin Chartouny, Raja Chatila, Ismael T. Freire, Mehdi Khamassi
  - **institution:** Institute of Intelligent Systems and Robotics, Sorbonne University
  - **link:** https://arxiv.org/pdf/2512.21439
  - **contributions:** 1. An empirically grounded dataset of 300 moral scenarios with human ternary judgments. 2. A reproducible pipeline (COMETH) combining human judgments, probabilistic context learning, and LLM-based semantic abstraction. 3. An interpretable, context-sensitive moral prediction model that outperforms end-to-end LLM prompting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f4abc9f666c2d29dadd77869bddf3f159d0bbc8839c7c0f65bbdb4c29ad40c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem that moral judgments depend heavily on context. It proposes the COMETH framework, which uses probabilistic clustering on human judgment data and LLM-based semantic abstraction to learn and explain action-specific moral contexts. The main conclusion is that COMETH significantly outperforms direct LLM prompting in aligning with human majority judgments while providing interpretable predictions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[COMETH: Learning Interpretable Moral Contexts] --> B[核心问题/Problem: Moral judgments are context-dependent]
        A --> C[主要方法/Method: Probabilistic clustering + LLM semantics + Human judgments]
        A --> D[关键结果/Results: Doubles alignment with human judgments vs. LLM prompting]
    ```

- **[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning**
  - **tags:** [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]
  - **authors:** Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu
  - **institution:** University of Washington, University of California, Berkeley
  - **link:** https://arxiv.org/pdf/2512.21446
  - **contributions:** 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards "diffusion supremacy" over autoregressive models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[MDLMs解码慢，速度优势有限/MDLMs decode slowly, limiting speed advantage]
        C --> C1[基于GRPO的在线强化学习框架/On-policy RL framework based on GRPO]
        C --> C2[联合优化扩散模型与解掩码规划器/Jointly optimize diffusion model & unmasking planner]
        D --> D1[提升精度-效率权衡/Improves accuracy-efficiency trade-off]
        D --> D2[迈向"扩散霸权"/Moving towards "diffusion supremacy"]
    ```

- **[arXiv251229] Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism**
  - **tags:** [cv], [object detection], [Ground Penetrating Radar (GPR), Multi-modal Chain Feature Fusion (MCFF), Global Attention Mechanism (GAM), DCGAN, transfer learning]
  - **authors:** Haotian Lv, Yuhui Zhang, Jiangbo Dai, Hanli Wu, Jiaji Wang, Dawei Wang
  - **institution:** Harbin Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.21452
  - **contributions:** 1. Proposed a DCGAN-based data augmentation strategy to synthesize high-fidelity GPR images, mitigating data scarcity. 2. Designed a novel Multi-modal Chain and Global Attention Network (MCGA-Net) integrating Multi-modal Chain Feature Fusion (MCFF) and a Global Attention Mechanism (GAM) for enhanced defect representation. 3. Utilized MS COCO transfer learning to fine-tune the backbone network, accelerating convergence and improving model generalization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the subjective and inefficient interpretation of Ground Penetrating Radar (GPR) images for road defect detection by proposing a comprehensive framework. The method combines DCGAN-based data augmentation, a novel MCGA-Net architecture with feature fusion and attention mechanisms, and transfer learning. The proposed model achieves high precision, recall, and robustness, establishing a new paradigm for automated GPR-based defect detection.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Intelligent recognition of GPR road hidden defect images <br/> GPR道路隐蔽病害图像智能识别") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
    
        Problem --> P1("Subjective & inefficient GPR interpretation <br/> GPR图像解释主观且低效")
        Problem --> P2("Data scarcity <br/> 数据稀缺")
    
        Method --> M1("DCGAN-based Data Augmentation <br/> 基于DCGAN的数据增强")
        Method --> M2("MCGA-Net (MCFF + GAM) <br/> MCGA-Net网络")
        Method --> M3("MS COCO Transfer Learning <br/> MS COCO迁移学习")
    
        Results --> R1("High Performance (Precision 92.8%, mAP@50 95.9%) <br/> 高性能")
        Results --> R2("Robust to noise & weak signals <br/> 对噪声和弱信号鲁棒")
        Results --> R3("New paradigm for automated detection <br/> 自动化检测新范式")
    ```

- **[arXiv251229] GPF-Net: Gated Progressive Fusion Learning for Polyp Re-Identification**
  - **tags:** [cv], [medical image retrieval], [polyp re-identification, gated progressive fusion, multimodal feature fusion]
  - **authors:** Suncheng Xiang, Xiaoyang Wang, Junjie Jiang, Hejia Wang, Dahong Qian
  - **institution:** Shanghai Jiao Tong University, Peking University, Shanghai Fifth People's Hospital
  - **link:** https://arxiv.org/pdf/2512.21476
  - **code:** https://github.com/JeremyXSC/GPF-Net
  - **contributions:** 1) Proposes a novel multimodal feature fusion framework named GPF-Net for polyp re-identification. 2) Introduces a gated progressive fusion strategy for layer-wise refinement of semantic information through multi-level feature interactions. 3) Demonstrates state-of-the-art performance on standard benchmarks, showing the benefit of multimodal fusion over unimodal methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75fe09ad1f753b61f2c30ab37c16d0deef5060ca95658846bc6dcaf6bb4c53f9_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of colonoscopic polyp re-identification, where coarse high-level features harm small object matching. The authors propose GPF-Net, a Gated Progressive Fusion network that selectively fuses multi-level features using gates. Experiments show this multimodal approach outperforms state-of-the-art unimodal ReID models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GPF-Net: Gated Progressive Fusion Learning for Polyp Re-Identification] --> B[核心问题/Problem: Coarse high-level features lead to inferior results for small polyps]
        A --> C[主要方法/Method: Gated Progressive Fusion network for selective, multi-level feature fusion]
        A --> D[关键结果/Results: Outperforms unimodal models, benefits of multimodal fusion strategy]
    ```

- **[arXiv251229] Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism**
  - **tags:** [mlsys], [llm inference], [mixture-of-experts (MoE), disaggregated expert parallelism (DEP), task scheduling, inference throughput, fine-grained pipelining]
  - **authors:** Xinglin Pan, Shaohuai Shi, Wenxiang Lin, Yuxin Wang, Zhenheng Tang, Wei Wang, Xiaowen Chu
  - **institution:** The Hong Kong University of Science and Technology (Guangzhou), Harbin Institute of Technology (Shenzhen), Hong Kong Baptist University, The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.21487
  - **contributions:** 1) Partitioning intensive computation and communication tasks into smaller, fine-grained tasks to enable pipelining, including support for shared experts. 2) Formulating a fine-grained task scheduling optimization problem that supports variable task granularity and ordering. 3) Developing an efficient solver to navigate the large solution space and derive a near-optimal task schedule.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the memory-intensive inference problem in Mixture-of-Experts (MoE) models by proposing FinDEP, a fine-grained task scheduling algorithm for Disaggregated Expert Parallelism (DEP). FinDEP improves inference throughput by maximizing task overlap through computational partitioning and optimized scheduling. Experiments on systems with up to 32 GPUs show throughput improvements of up to 1.61x over prior methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FinDEP: Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[MoE推理内存密集，现有DEP调度效率低/MoE inference is memory-intensive, existing DEP scheduling is inefficient]
        C --> C1[细粒度任务划分与调度优化/Fine-grained task partitioning and scheduling optimization]
        D --> D1[吞吐量最高提升1.61倍/Throughput improved by up to 1.61x]
    ```

- **[arXiv251229] Oogiri-Master: Benchmarking Humor Understanding via Oogiri**
  - **tags:** [nlp], [humor understanding], [Oogiri, benchmark, linguistic analysis, incongruity resolution, insight-augmented prompting]
  - **authors:** Soichiro Murakami, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura
  - **institution:** CyberAgent, Nara Institute of Science and Technology, Institute of Science Tokyo
  - **link:** https://arxiv.org/pdf/2512.21494
  - **contributions:** 1. Introduces Oogiri-Master, a benchmark for rigorous evaluation of humor understanding in LLMs, and Oogiri-Corpus, a dataset with ~100 diverse responses per prompt and independent human ratings to reduce bias. 2. Conducts quantitative analysis of linguistic factors (e.g., text length, ambiguity, incongruity resolution) to derive objective metrics for predicting human funniness judgments. 3. Benchmarks LLMs and human baselines, showing state-of-the-art models approach human performance and that insight-augmented prompting improves model humor understanding.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41486d2e77493633c6cf66d7f5134ccf646d1df0d17e6d258bc98cc3132ef02b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of evaluating humor understanding in LLMs by introducing the Oogiri-Master benchmark and Oogiri-Corpus dataset, which enable rigorous analysis of funniness through diverse responses and independent human ratings. It quantitatively analyzes linguistic factors to derive objective metrics and benchmarks LLMs, demonstrating that advanced models approach human-level performance and benefit from insight-augmented prompting. The work provides a principled basis for advancing humor understanding in AI.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Oogiri-Master: Benchmarking Humor Understanding via Oogiri] --> B[核心问题/Problem: What makes Oogiri responses funny to humans?]
        A --> C[主要方法/Method: Introduce Oogiri-Master benchmark and Oogiri-Corpus dataset with diverse responses and independent ratings]
        A --> D[关键结果/Results: LLMs approach human performance; insight-augmented prompting improves results]
    ```

- **[arXiv251229] LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis**
  - **tags:** [cv], [multimodal forgery detection], [visual-textual co-reasoning, cross-cues-aware chain of thought (CCT), GRPO-based optimization]
  - **authors:** Fanwei Zeng, Changtao Miao, Jing Huang, Zhiya Tan, Shutao Gong, Xiaoming Yu, Yang Wang, Huazhe Tan, Weibin Yao, Jianshu Li
  - **institution:** Ant Group, Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.21482
  - **contributions:** 1. Proposed LogicLens, a unified framework for visual-textual co-reasoning that jointly performs detection, grounding, and explanation for text-centric forgery analysis. 2. Introduced a Cross-Cues-aware Chain of Thought (CCT) mechanism for iterative cross-validation of visual and textual cues, and a weighted multi-task reward function for GRPO-based optimization. 3. Created the RealText dataset with 5,397 images and fine-grained annotations using a novel PR² (Perceiver, Reasoner, Reviewer) multi-agent annotation pipeline.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/138f8fcb4727c77950b23146e1184851aa8b8cea95056b1d6b161c37e231ad80_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces LogicLens, a unified visual-textual co-reasoning framework for analyzing text-centric forgeries. It uses a novel Cross-Cues-aware Chain of Thought mechanism and multi-task optimization to jointly handle detection, grounding, and explanation. Experiments show LogicLens achieves state-of-the-art performance, significantly outperforming specialized frameworks and other MLLMs in zero-shot and dense-text scenarios.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[文本中心伪造威胁/Sophisticated text-centric forgeries]
        B --> B2[现有方法缺乏推理/Current methods lack reasoning]
        B --> B3[任务割裂/Tasks treated as discrete]
        C --> C1[统一框架/Unified Visual-Textual Co-reasoning framework]
        C --> C2[跨线索思维链/Cross-Cues-aware Chain of Thought (CCT)]
        C --> C3[多任务奖励函数/Weighted multi-task reward function]
        C --> C4[PR²标注管道/PR² annotation pipeline]
        C --> C5[RealText数据集/RealText dataset]
        D --> D1[零样本评估领先/Superior zero-shot performance]
        D --> D2[密集文本数据集领先/Lead on dense-text dataset]
        D --> D3[公开资源/Public dataset, model, code]
    ```

- **[arXiv251229] MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding**
  - **tags:** [mlsys], [multi-modal training], [wearable sensing, actigraphy encoder, projection module, frozen LLM, behavioral summarization]
  - **authors:** Aiwei Zhang, Arvind Pillai, Andrew Campbell, Nicholas C. Jacobson
  - **institution:** Dartmouth College
  - **link:** https://arxiv.org/pdf/2512.21506
  - **contributions:** 1. Introduces MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs) for free-text generation of daily behavioral summaries. 2. Constructs a novel, large-scale dataset of 54,383 (actigraphy, text) pairs derived from real-world NHANES recordings. 3. Demonstrates superior performance over prompt-based baselines in semantic fidelity and lexical accuracy, with qualitative analysis showing the model captures circadian structure and behavioral transitions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of generating natural language summaries from raw physiological signals like actigraphy. It proposes MotionTeller, a framework that integrates a pretrained actigraphy encoder with a frozen LLM via a projection module. The model, trained on a novel dataset, outperforms baselines in generating fluent, human-centered descriptions of daily behavior.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs] --> B[核心问题/Problem: How to generate natural language summaries from raw physiological signals like actigraphy?]
        A --> C[主要方法/Method: Combines a pretrained actigraphy encoder and a projection module to map behavioral embeddings into a frozen LLM's token space.]
        A --> D[关键结果/Results: Achieves high semantic fidelity (BERTScore-F1=0.924) and lexical accuracy (ROUGE-1=0.722), outperforming baselines by 7%.]
    ```

- **[arXiv251229] DiverseGRPO: Mitigating Mode Collapse in Image Generation via Diversity-Aware GRPO**
  - **tags:** [cv], [diffusion models], [GRPO, mode collapse, diversity-aware reward, spectral clustering, structure-aware regularization]
  - **authors:** Henglin Liu, Huijuan Huang, Jing Wang, Chang Liu, Xiu Li, Xiangyang Ji
  - **institution:** Tsinghua University, Kuaishou Technology (Kling Team), Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.21514
  - **contributions:** 1. Identifies and analyzes the mode collapse problem in GRPO-based image generation from both reward modeling and generation dynamics perspectives. 2. Proposes a distributional creativity bonus reward based on semantic grouping via spectral clustering to encourage novel visual modes. 3. Introduces a structure-aware regularization that applies stronger constraints during early-stage denoising to preserve diversity without sacrificing quality optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the mode collapse problem in GRPO-based image generation, where models produce homogenized outputs. The proposed DiverseGRPO method introduces a diversity-aware reward based on semantic clustering and a structure-aware regularization to preserve generation diversity. Experiments show the method significantly improves semantic diversity while maintaining image quality, establishing a better quality-diversity trade-off.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DiverseGRPO: Mitigating Mode Collapse] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[GRPO导致模式崩溃/GRPO causes mode collapse]
        B1 --> B2[缺乏视觉多样性/Lacks visual diversity]
        C --> C1[奖励层面: 分布创造力奖励/Reward Level: Distributional Creativity Bonus]
        C --> C2[生成层面: 结构感知正则化/Generation Level: Structure-Aware Regularization]
        C1 --> C3[基于语义分组的谱聚类/Spectral Clustering for Semantic Grouping]
        D --> D1[语义多样性提升13%-18%/13%-18% Semantic Diversity Improvement]
        D --> D2[建立新的帕累托前沿/Establishes New Pareto Frontier]
    ```

- **[arXiv251229] Selective LLM-Guided Regularization for Enhancing Recommendation Models**
  - **tags:** [ai], [recommender systems], [selective regularization, knowledge distillation, cold-start, long-tail, gating mechanism]
  - **authors:** Shanglin Yang, Zhan Shi
  - **institution:** Sichuan University
  - **link:** https://arxiv.org/pdf/2512.21526
  - **contributions:** 1. Proposes a selective LLM-guided regularization framework (S-LLMR) that activates LLM supervision only when a gating mechanism predicts the LLM to be reliable, addressing the issue of inaccurate global distillation. 2. Introduces a trainable gating mechanism informed by user history length, item popularity, and model uncertainty to dynamically decide when to apply LLM-based pairwise ranking supervision. 3. Demonstrates through experiments that the method improves overall accuracy and yields substantial gains in cold-start and long-tail recommendation scenarios, outperforming global distillation baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76336a3d123794e83843c14c4b799afd0817948ee9dfeb2f6f19ce776f183796_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of leveraging large language models (LLMs) for recommendation without suffering from their high cost and unreliability in certain scenarios. It proposes Selective LLM-Guided Regularization (S-LLMR), a model-agnostic framework that uses a gating mechanism to selectively apply LLM-based supervision only when the LLM is predicted to be reliable. Experiments show this approach improves recommendation accuracy, especially for cold-start users and long-tail items, outperforming methods that uniformly distill LLM knowledge.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Selective LLM-Guided Regularization<br>选择性LLM引导正则化] --> B(Problem/核心问题<br>LLMs as standalone recommenders are costly/unreliable;<br>Global distillation forces imitation of inaccurate LLM guidance.)
        A --> C(Method/主要方法<br>Selective LLM-Guided Regularization (S-LLMR):<br>Trainable gating mechanism activates LLM supervision only when reliable.)
        A --> D(Results/关键结果<br>Improves overall accuracy;<br>Substantial gains in cold-start & long-tail regimes.)
    ```

- **[arXiv251229] Hierarchy-Aware Fine-Tuning of Vision-Language Models**
  - **tags:** [cv], [multimodal learning], [hierarchical classification, vision-language models, efficient fine-tuning, LoRA, Tree-Path KL Divergence]
  - **authors:** Jiayu Li, Rajesh Gangireddy, Samet Akcay, Wei Cheng, Juhua Hu
  - **institution:** University of Washington, Intel
  - **link:** https://arxiv.org/pdf/2512.21529
  - **contributions:** 1. Proposes an efficient hierarchy-aware fine-tuning framework for Vision-Language Models (VLMs) that updates only a few parameters. 2. Introduces two novel loss functions: Tree-Path KL Divergence (TP-KL) for vertical consistency along label paths and Hierarchy-Sibling Smoothed Cross-Entropy (HiSCE) for horizontal consistency among sibling classes. 3. Demonstrates consistent improvements in Full-Path Accuracy and reduced Tree-based Inconsistency Error across multiple hierarchical benchmarks with minimal parameter overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88b60d2fc3dd0ad92b5ac8857f844fed2dbe51e280dfb702c26028d91c14fd92_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of adapting large Vision-Language Models (VLMs) to hierarchical classification tasks efficiently. The proposed method combines two novel hierarchy-aware loss functions (TP-KL and HiSCE) with lightweight LoRA adaptation to enforce structural consistency in predictions. Experiments show the approach improves accuracy and reduces inconsistency across taxonomy levels with minimal computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Hierarchy-Aware Fine-Tuning of Vision-Language Models") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("VLMs适应层级分类效率低/VLMs inefficient for hierarchical classification")
        Problem --> P2("标准方法预测不一致/Standard methods produce inconsistent predictions")
        Method --> M1("提出层级感知微调框架/Propose hierarchy-aware fine-tuning framework")
        Method --> M2("结合TP-KL与HiSCE损失/Combine TP-KL and HiSCE losses")
        Method --> M3("集成轻量级LoRA适配/Integrate lightweight LoRA adaptation")
        Results --> R1("提升全路径精度/Improves Full-Path Accuracy")
        Results --> R2("降低不一致性错误/Reduces Tree-based Inconsistency Error")
        Results --> R3("参数开销最小/Minimal parameter overhead")
    ```

- **[arXiv251229] Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model**
  - **tags:** [mlsys], [llm inference], [adaptive length penalty, reinforcement learning, constrained optimization, Lagrangian primal-dual, reasoning efficiency]
  - **authors:** Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo
  - **institution:** Peking University, Harbin Institute of Technology, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.21540
  - **contributions:** 1. Proposes Leash, a reinforcement learning framework that formulates length control as a constrained optimization problem and uses a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. 2. Introduces an adaptive mechanism that intensifies the penalty when generations exceed the target length and relaxes it when they are shorter, guiding models toward concise reasoning without sacrificing performance. 3. Demonstrates experimentally that Leash reduces average reasoning length by 60% across diverse tasks while maintaining competitive performance, offering a practical paradigm for efficient LLMs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of LLMs producing overly long reasoning traces, which increases computational cost. It proposes Leash, an adaptive reinforcement learning framework that dynamically adjusts length penalties using a Lagrangian method to balance conciseness and accuracy. Experiments show it reduces reasoning length by 60% while maintaining performance, providing an effective approach for efficient LLM reasoning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LEASH: Adaptive Length Penalty and Reward Shaping] --> B[核心问题/Problem: LLMs生成过长推理链，计算成本高/Fixed penalties fail to adapt, leading to suboptimal accuracy-conciseness trade-offs]
        A --> C[主要方法/Method: 自适应强化学习框架，使用拉格朗日对偶方法动态调整惩罚系数/Adaptive RL framework with Lagrangian primal-dual for dynamic penalty adjustment]
        A --> D[关键结果/Results: 平均推理长度减少60%，性能保持竞争力/Average reasoning length reduced by 60% while maintaining competitive performance across tasks]
    ```

- **[arXiv251229] Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures**
  - **tags:** [other], [human-ai interaction], [bidirectional alignment, value-centered design, interactive alignment]
  - **authors:** Hua Shen, Tiffany Knearem, Divy Thakkar, Pat Pataranutaporn, Anoop Sinha, Yike, Jenny T. Liang, Lama Ahmad, Tanu Mitra, Brad A. Myers, Yang Li
  - **institution:** NYU Shanghai, MBZUAI, Google, Massachusetts Institute of Technology, Carnegie Mellon University, OpenAI, University of Washington, Google DeepMind
  - **link:** https://arxiv.org/pdf/2512.21551
  - **contributions:** 1. Proposes a shift from unidirectional to bidirectional human-AI alignment, framing it as a dynamic, reciprocal co-adaptation process. 2. Emphasizes embedding human and societal values into AI alignment research through value-centered design. 3. Aims to establish an interdisciplinary research agenda for responsible, reciprocal human-AI futures through collaborative workshop activities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp
  - **Simple LLM Summary:** This workshop paper identifies the inadequacy of traditional, one-way AI alignment and proposes a bidirectional human-AI alignment framework where humans and AI co-adapt through interaction and value-centered design. It aims to bring together interdisciplinary researchers to explore methods for interactive alignment and societal impact evaluation. The main conclusion is the need for a shared agenda to advance responsible, reciprocal collaboration between humans and AI systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Human-AI Interaction Alignment] --> B[核心问题/Problem: Unidirectional AI alignment is inadequate for dynamic human-AI interaction]
        A --> C[主要方法/Method: Bidirectional alignment via value-centered design, interaction, and evaluation]
        A --> D[关键结果/Results: Establishes agenda for reciprocal, responsible human-AI futures]
    ```

- **[arXiv251229] Bidirectional Human-AI Alignment in Education for Trustworthy Learning Environments**
  - **tags:** [ai], [ai for education], [human-ai alignment, trustworthy ai, adaptive learning, educational technology, ai ethics]
  - **authors:** Hua Shen
  - **institution:** NYU Shanghai, New York University
  - **link:** https://arxiv.org/pdf/2512.21552
  - **contributions:** 1. Proposes the novel concept of "bidirectional human-AI alignment" for education, emphasizing mutual adaptation between humans and AI systems. 2. Explores the evolution of AI's role in education from a support tool to a collaborative partner, analyzing its impact on teacher roles and student agency. 3. Provides actionable strategies for policymakers, developers, and educators to ensure AI advances equity, transparency, and human flourishing in learning environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7f40fe114da7bae34b09e44db18fa32bb4f64e57bd01e75e96afc80c2ddc136_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the risks of AI in education, such as bias and loss of autonomy, by proposing the concept of bidirectional human-AI alignment. The method involves not only embedding human values into AI but also equipping educators and students to guide these technologies. It concludes that reframing AI adoption as a process of mutual adaptation is key to creating trustworthy learning environments where humans and AI can grow together.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题: Bidirectional Human-AI Alignment in Education] --> B[核心问题/Problem: AI in education introduces risks to equity, privacy, and autonomy.]
        A --> C[主要方法/Method: Proposes bidirectional alignment: embedding human values into AI and equipping humans to interpret/guide AI.]
        A --> D[关键结果/Results: Envisions a future of mutual adaptation where AI advances equity, transparency, and human flourishing.]
    ```

- **[arXiv251229] Exploration of Reproducible Generated Image Detection**
  - **tags:** [cv], [image forensics], [AIGC detection, reproducibility, generalizability, diffusion models, binary classification]
  - **authors:** Yihang Duan
  - **institution:** Not explicitly stated in the provided content. (Author name only, no affiliation or email domain provided)
  - **link:** https://arxiv.org/pdf/2512.21562
  - **contributions:** 1. Identifies and analyzes the root causes of poor reproducibility in AIGC image detection research, citing omitted experimental details and overfitting to generator-specific features. 2. Provides empirical evidence for the reproducibility issue by constructing a test dataset and reproducing a representative detection method, demonstrating performance drops under cross-generator testing. 3. Proposes reference directions for the research community to improve reproducibility and generalizability, such as more comprehensive disclosure of experimental details.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c9df3d6873df2ea90e378adf52625583637b76319eb9a55ebf11b8f17abf1fc_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the reproducibility and generalizability challenges in AI-Generated Content (AIGC) image detection. By reviewing key literature, building a test dataset, and reproducing a detection method, it identifies causes like omitted experimental details and model overfitting. The study concludes that while basic performance can be reproduced, detection fails when preprocessing disrupts key features or when testing across different generators, highlighting the need for better methodological disclosure and robustness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Exploration of Reproducible Generated Image Detection] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Poor Reproducibility & Generalizability]
        C[主要方法/Method<br>Literature Review, Dataset Construction, Method Reproduction]
        D[关键结果/Results<br>Performance Drops with Preprocessing/Cross-Generator Tests]
    ```

- **[arXiv251229] Towards Long-window Anchoring in Vision-Language Model Distillation**
  - **tags:** [mlsys], [multi-modal training], [knowledge distillation, long-context, rotary position embeddings (RoPE), attention mechanism, vision-language models]
  - **authors:** Haoyi Zhou, Shuo Li, Tianyu Chen, Qi Song, Chonghan Gao, Jianxin Li
  - **institution:** Beihang University, Zhongguancun Laboratory
  - **link:** https://arxiv.org/pdf/2512.21576
  - **contributions:** 1. Identifies the problem of limited effective context windows in small, distilled vision-language models despite using identical positional embeddings and architectures as their larger counterparts. 2. Proposes LAid, a novel distillation method featuring progressive distance-weighted attention matching and learnable RoPE response gain modulation to transfer long-range attention mechanisms. 3. Demonstrates that LAid-distilled models achieve significantly longer effective context windows (up to 3.2x) while maintaining performance on standard benchmarks, and provides spectral analysis showing successful transfer of low-frequency attention components.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4663870a97f8c352e6cd352d0f9f9be365648a5545642796d256fa99c7ddcd4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem that small, distilled vision-language models have much shorter effective context windows than their large teacher models. The authors propose LAid, a new distillation method that transfers long-range attention capabilities via progressive attention matching and learnable RoPE modulation. Their method successfully extends the context window of small models by up to 3.2 times while preserving performance on standard benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Towards Long-window Anchoring in Vision-Language Model Distillation] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Small distilled VLMs have limited effective context windows]
        C[主要方法/Method: LAid - Progressive attention matching & learnable RoPE modulation]
        D[关键结果/Results: Achieves up to 3.2x longer context, maintains benchmark performance]
    ```

- **[arXiv251229] NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent**
  - **tags:** [mlsys], [agent system], [NeMo Framework, LoRA, Nemotron SLM, hyperparameter sweep, multi-agent system]
  - **authors:** Ali Sahami, Sudhanshu Garg, Andrew Wang, Chaitanya Kulkarni, Farhad Farahani, Sean Yun-Shiuan Chuang, Jian Wan, Srinivasan Manoharan, Uma Kona, Nitin Sharma, Linsey Pang, Prakhar Mehrotra, Jessica Clark, Mark Moyou
  - **institution:** PayPal AI, NVIDIA
  - **link:** https://arxiv.org/pdf/2512.21578
  - **contributions:** 1. The first application of NVIDIA's NeMo Framework to optimize commerce-specific agents. 2. An LLM-powered fine-tuning strategy for retrieval-focused commerce tasks. 3. A demonstration of significant latency and cost improvements while maintaining agent quality, providing a scalable framework for multi-agent system optimization in production e-commerce.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90dda98c8c5c5f9d75ede0c681c9024dc5973d432f246b90eed23aad0a03c916_w640_q70.webp
  - **Simple LLM Summary:** This paper presents the optimization of PayPal's Commerce Agent, a multi-agent system, by fine-tuning a Nemotron small language model using NVIDIA's NeMo Framework and LoRA. The method involved systematic hyperparameter sweeps to improve the performance-critical search component. The results show that the fine-tuned model effectively resolves the key latency issue in the retrieval component, which accounted for over 50% of response time, while maintaining or enhancing overall system performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["NEMO-4-PAYPAL: Empowering PayPal's Commerce Agent"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["Search Latency/搜索延迟"]
        P1 --> P2[">50% Response Time/超过50%响应时间"]
        Method --> M1["Fine-tuning with NeMo/使用NeMo微调"]
        M1 --> M2["LoRA on Nemotron SLM/在Nemotron SLM上使用LoRA"]
        M2 --> M3["Hyperparameter Sweep/超参数扫描"]
        Results --> R1["Latency & Cost Improvement/延迟与成本改进"]
        Results --> R2["Maintained Agent Quality/保持代理质量"]
        Results --> R3["Scalable Framework/可扩展框架"]
    ```

- **[arXiv251229] A Unified Definition of Hallucination, Or: It's the World Model, Stupid**
  - **tags:** [nlp], [hallucination detection & evaluation], [hallucination, world modeling, knowledge conflict, benchmark, language model evaluation]
  - **authors:** Emmy Liu, Varun Gangal, Chelsea Zou, Xiaoqi Huang, Michael Yu, Alex Chang, Zhuofu Tao, Sachin Kumar, Steven Y. Feng
  - **institution:** Carnegie Mellon University, Stanford University, The Ohio State University, Patronus AI, DegenAI Labs, Independent Researchers
  - **link:** https://arxiv.org/pdf/2512.21577
  - **contributions:** 1. Proposes a unified definition of hallucination as inaccurate internal world modeling that is observable to the user, synthesizing prior definitions. 2. Provides a framework for analyzing hallucinations by varying the reference world model and knowledge conflict policy, clarifying what constitutes a hallucination versus other error types. 3. Outlines plans for a family of benchmarks based on synthetic, fully-specified world models to stress-test and improve the world modeling components of language models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e2cc31121f769cca7464239d4aa27b26c8c4bc903970a4833fbebac56dc9b85_w640_q70.webp
  - **Simple LLM Summary:** This paper argues that the persistent problem of hallucination in language models stems from inaccurate internal world modeling. It unifies various historical definitions under this core concept and proposes a framework for clearer evaluation. The authors conclude by sketching plans for new benchmarks to rigorously test and improve language models' world modeling capabilities.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Unified Definition of Hallucination / 幻觉的统一定义"] --> Problem["核心问题/Problem"]
        Root["A Unified Definition of Hallucination / 幻觉的统一定义"] --> Method["主要方法/Method"]
        Root["A Unified Definition of Hallucination / 幻觉的统一定义"] --> Results["关键结果/Results"]
        Problem --> P1["Hallucination persists in LLMs / 幻觉在LLM中持续存在"]
        Method --> M1["Unified definition: inaccurate world modeling / 统一定义：不准确的世界建模"]
        Method --> M2["Framework: reference world & conflict policy / 框架：参考世界与冲突策略"]
        Results --> R1["Clarifies evaluation & terminology / 澄清评估与术语"]
        Results --> R2["Proposes new benchmark plans / 提出新基准计划"]
    ```

- **[arXiv251229] A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning**
  - **tags:** [mlsys], [multi-modal inference], [vision-language model, logic tree reasoning, medical multimodal diagnosis, explainable AI, LLaVA]
  - **authors:** Zelin Zang, Wenyi Gu, Siqi Ma, Dan Yang, Yue Shen, Zhu Zhang, Guohui Fan, Wing-Kuen Ling, Fuji Yang
  - **institution:** Tsientang Institute of Advanced Study (TIAS), Westlake University, Ant Group, China-Japan Friendship Hospital
  - **link:** https://arxiv.org/pdf/2512.21583
  - **contributions:** 1. Proposes a diagnostic framework integrating vision-language alignment with logic-regularized reasoning to enhance reliability. 2. Introduces a reasoning controller and logic tree generator to decompose tasks and assemble verifiable conclusions, improving interpretability. 3. Demonstrates improved diagnostic accuracy and more interpretable reasoning traces on multimodal medical benchmarks like MedXpertQA.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b6b8d6d34a614d3cb042f13334dede18494914ca29d6f0fd6f4467f789871f82_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of unreliable reasoning and hallucinations in existing multimodal medical AI models. It proposes a diagnostic framework built on LLaVA that combines vision-language alignment with logic-regularized reasoning to generate verifiable conclusions via logic trees. Evaluations show the method improves diagnostic accuracy and yields more interpretable reasoning traces, advancing trustworthy multimodal medical AI.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[医学多模态诊断框架<br/>Medical Multimodal Diagnostic Framework] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有模型幻觉与推理不一致<br/>Existing Models: Hallucinations & Inconsistent Reasoning]
        C --> C1[结合视觉语言对齐与逻辑树推理<br/>Vision-Language Alignment + Logic Tree Reasoning]
        D --> D1[提升诊断准确性与可解释性<br/>Improved Diagnostic Accuracy & Interpretability]
    ```

- **[arXiv251229] LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model**
  - **tags:** [mlsys], [llm inference], [item-to-item recommendation, data-centric, long-tail items, data augmentation, data filtering]
  - **authors:** Yinfu Feng, Yanjing Wu, Rong Xiao, Xiaoyi Zen
  - **institution:** Alibaba Group
  - **link:** https://arxiv.org/pdf/2512.21595
  - **contributions:** 1. Proposes LLM-I2I, a data-centric framework that leverages Large Language Models to enhance I2I recommendation models without altering their architecture. 2. Introduces an LLM-based data generator to synthesize user-item interactions, specifically targeting long-tail items to alleviate data sparsity. 3. Designs an LLM-based data discriminator to filter out noisy interactions from both real and synthetic data, improving overall data quality for training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cb08ea9b26b612493e4d48e7db88c46a869c2050c94d47b75488adcaf6ddfa9_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses data sparsity and noise problems in Item-to-Item (I2I) recommendation systems by proposing LLM-I2I, a data-centric framework that uses an LLM to generate synthetic interactions for long-tail items and filter noisy data. The refined data is then used to train existing I2I models. Experimental results on industrial and academic datasets show significant improvements in recommendation accuracy, especially for long-tail items, and deployment on a large e-commerce platform led to measurable gains in recall and gross merchandise value.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[数据稀疏与噪声/Data Sparsity & Noise]
        C --> C1[LLM数据生成器/LLM-based Data Generator]
        C --> C2[LLM数据判别器/LLM-based Data Discriminator]
        C1 --> C3[合成交互数据/Synthesize Interaction Data]
        C2 --> C4[过滤噪声数据/Filter Noisy Data]
        C3 & C4 --> C5[融合数据训练I2I模型/Fuse Data to Train I2I Model]
        D --> D1[提升推荐准确率/Improves Recommendation Accuracy]
        D --> D2[提升长尾物品性能/Better for Long-tail Items]
        D --> D3[线上指标提升/Online Metric Improvements (RN+6.02%, GMV+1.22%)]
    ```

- **[arXiv251229] AMS-IO-Bench and AMS-IO-Agent: Benchmarking and Structured Reasoning for Analog and Mixed-Signal Integrated Circuit Input/Output Design**
  - **tags:** [mlsys], [agent system], [AMS IC design, LLM-based agent, structured reasoning, design automation, I/O ring generation]
  - **authors:** Zhishuai Zhang, Xintian Li, Shilong Liu, Aodong Zhang, Lu Jie, Nan Sun
  - **institution:** Tsinghua University, Princeton University
  - **link:** https://arxiv.org/pdf/2512.21613
  - **code:** https://github.com/Arcadia-1/AMS-IO-Agent
  - **contributions:** 1. Proposed AMS-IO-Agent, a domain-specialized LLM-based agent for structure-aware I/O subsystem generation in AMS ICs. 2. Introduced AMS-IO-Bench, a benchmark for wirebond-packaged AMS I/O ring automation. 3. Demonstrated the first reported human-agent collaborative AMS IC design where an LLM agent's output was directly used in a silicon tape-out, achieving over 70% DRC+LVS pass rate and reducing design time from hours to minutes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7205181105fdcb012bb4c8c5b3cce6565751edc220003d3784f6dbf648ee893a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the labor-intensive and non-reusable nature of analog and mixed-signal (AMS) integrated circuit I/O design by proposing AMS-IO-Agent, an LLM-based agent that uses structured domain knowledge and intent structuring to automate the process. The method connects natural language design intent to industrial deliverables and is evaluated on a new benchmark, AMS-IO-Bench. The agent significantly outperforms baseline LLMs, achieves a high verification pass rate, and its generated I/O ring was successfully fabricated, demonstrating practical effectiveness in real design flows.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AMS-IO-Bench and AMS-IO-Agent<br>论文标题/Paper Title] --> B[手动AMS I/O设计费时且不可复用<br>核心问题/Problem: Manual AMS I/O design is time-consuming and non-reusable]
        A --> C[提出基于LLM的智能体与结构化推理框架<br>主要方法/Method: Proposes an LLM-based agent and structured reasoning framework]
        A --> D[验证通过率>70%，设计时间从小时减至分钟，成功流片<br>关键结果/Results: >70% pass rate, design time reduced from hours to minutes, successful tape-out]
    ```

- **[arXiv251229] Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design**
  - **tags:** [mlsys], [agent system], [multi-agent platform, knowledge graph, physiologically based pharmacokinetic (PBPK) simulations, autonomous execution, human-in-the-loop]
  - **authors:** Takahide Suzuki, Kazuki Nakanishi, Takashi Fujiwara, Hideyuki Shimizu
  - **institution:** Institute of Science Tokyo, Kyoto University
  - **link:** https://arxiv.org/pdf/2512.21623
  - **contributions:** 1. Introduces OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine for drug design. 2. Features an architecture with specialized agents (Biologist, Chemist, Pharmacologist) governed by an Orchestrator, which actively execute simulations and reason over results to create a dynamic feedback loop for iterative optimization. 3. Democratizes therapeutic design by transforming drug discovery from a stochastic search into a programmable, evidence-based engineering discipline through the integration of autonomous execution with human guidance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbd4a841925fb9129111928c81fe29ac7016c26df168e9b4ca87c8782a692d5e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of fragmented and passive tools in therapeutic discovery by proposing OrchestRA, a multi-agent platform where specialized AI agents autonomously execute and reason over biological, chemical, and pharmacological tasks. This creates a dynamic feedback loop for iterative drug candidate optimization, guided by human input. The conclusion is that this approach transforms drug discovery into a more programmable and evidence-based engineering process.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Fragmented domains & execution gap<br>AI as passive assistants]
        C[主要方法/Method<br>OrchestRA Multi-Agent Platform<br>Agents execute & reason<br>Human-in-the-loop]
        D[关键结果/Results<br>Autonomous discovery engine<br>Dynamic feedback loop<br>Programmable evidence-based design]
    ```

- **[arXiv251229] Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing**
  - **tags:** [ai], [multi-armed bandits], [multiple-play bandits, prioritized resource sharing, regret analysis, combinatorial optimization, UCB]
  - **authors:** Hong Xie, Haoran Gu, Yanying Huang, Tao Tan, Defu Lian
  - **institution:** University of Science and Technology of China, Chongqing University
  - **link:** https://arxiv.org/pdf/2512.21626
  - **contributions:** 1. Proposes a new variant of the multiple-play stochastic bandit model (MSB-PRS) that incorporates prioritized capacity sharing among plays, tailored for resource allocation in LLM and edge intelligence applications. 2. Establishes instance-independent and instance-dependent regret lower bounds for the proposed model, characterizing its fundamental learning difficulty. 3. Designs an offline optimal policy solver (MSB-PRS-OffOpt) and an online UCB-based learning algorithm with theoretical regret guarantees that nearly match the derived lower bounds.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8562089dc3d9fa0a65e8caf8921b51648e1718efd62395a7af2fadba8cf952d9_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a new multi-armed bandit model where multiple plays with priorities compete for the stochastic capacity of arms. The authors design an algorithm that first computes an optimal allocation offline and then uses it within an online UCB-based strategy, proving that its regret nearly matches the fundamental lower bounds they establish for this problem.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing<br/>多臂老虎机优先容量共享"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br/>Prioritized resource allocation in LLM/edge intelligence<br/>LLM/边缘智能中的优先资源分配"] --> P1["模型/Model<br/>M arms, K plays, stochastic capacity, priority weights<br/>M个臂，K个玩家，随机容量，优先级权重"]
        Method["主要方法/Method<br/>Algorithm Design<br/>算法设计"] --> M1["离线最优求解器/MSB-PRS-OffOpt<br/>Computes optimal policy<br/>计算最优策略"]
        Method --> M2["在线UCB算法/Online UCB Algorithm<br/>Uses offline solver as subroutine<br/>以离线求解器为子程序"]
        Results["关键结果/Results<br/>Theoretical Analysis<br/>理论分析"] --> R1["下界/Regret Lower Bounds<br/>Ω(α₁σ√KMT), Ω(α₁σ²(M/Δ)lnT)"]
        Results --> R2["上界/Regret Upper Bounds<br/>Matching lower bounds up to factors<br/>与下界匹配（差因子）"]
    ```

- **[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search**
  - **tags:** [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]
  - **authors:** Maximilian Weichart
  - **institution:** University of Regensburg
  - **link:** https://arxiv.org/pdf/2512.21648
  - **code:** https://github.com/Max-We/inverse-rpo
  - **contributions:** 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Variance-Aware Prior-Based Tree Policies for MCTS] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Extending prior-based UCTs from other UCBs is challenging]
        C[主要方法/Method: Propose Inverse-RPO to derive prior-based UCTs; apply to UCB-V]
        D[关键结果/Results: New policies outperform PUCT without extra cost]
    ```

- **[arXiv251229] TrackTeller: Temporal Multimodal 3D Grounding for Behavior-Dependent Object References**
  - **tags:** [cv], [3D object grounding], [temporal multimodal grounding, LiDAR-image fusion, language-conditioned decoding, UniScene representation, NuPrompt benchmark]
  - **authors:** Jiahong Yu, Ziqi Wang, Hailiang Zhao, Wei Zhai, Xueqiang Yan, Shuiguang Deng
  - **institution:** Zhejiang University, Fudan University, Huawei Technologies Ltd.
  - **link:** https://arxiv.org/pdf/2512.21641
  - **contributions:** 1. Proposes TrackTeller, a unified temporal multimodal framework for 3D grounding that integrates LiDAR-image fusion, language-conditioned decoding, and temporal reasoning. 2. Introduces a shared UniScene representation aligned with textual semantics to generate language-aware 3D proposals. 3. Demonstrates significant performance improvements on the NuPrompt benchmark, including a 70% relative gain in Average Multi-Object Tracking Accuracy and a 3.15-3.4x reduction in False Alarm Frequency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc60054c622874cc83217afc715702b65eb56126f722620ffb7004f46ebe296d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of grounding natural language references to objects in dynamic 3D driving scenes, which often depend on recent motion or behavior. The authors propose TrackTeller, a framework that fuses LiDAR and camera data with language, builds a unified scene representation, and uses temporal reasoning to refine object identification. Experiments show that TrackTeller significantly outperforms existing baselines in language-grounded tracking accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[TrackTeller: Temporal Multimodal 3D Grounding] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[动态3D场景中的行为依赖语言指代/Dynamic 3D Behavior-Dependent Language Grounding]
        C --> C1[统一多模态时序框架/Unified Temporal Multimodal Framework]
        C1 --> C2[LiDAR-图像融合与语言解码/LiDAR-Image Fusion & Language Decoding]
        C1 --> C3[构建UniScene表示/Build UniScene Representation]
        C1 --> C4[利用运动历史推理/Reason with Motion History]
        D --> D1[在NuPrompt上显著提升性能/Significant Improvement on NuPrompt]
        D1 --> D2[AMOTA提升70%/70% AMOTA Gain]
        D1 --> D3[误报率降低3.15-3.4倍/3.15-3.4x FA Reduction]
    ```

- **[arXiv251229] Near-Optimal Coalition Structures in Polynomial Time**
  - **tags:** [ai], [cooperative game theory], [coalition structure generation, anytime algorithms, sparse relaxations, dynamic programming, MILP]
  - **authors:** Angshul Majumdar
  - **institution:** Indraprastha Institute of Information Technology, Delhi
  - **link:** https://arxiv.org/pdf/2512.21657
  - **contributions:** 1. Proves that under a "sparse synergy" model, sparse relaxation methods can find near-optimal coalition structures in polynomial time with high probability. 2. Demonstrates that broad classes of dynamic programming and MILP algorithms require exponential time to achieve comparable solution quality. 3. Establishes a rigorous probabilistic anytime performance separation favoring sparse relaxations over exact methods for the CSG problem.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb8e459bba93eeaf4c9237729ad06cf13b47ef6a941811135ed634157dd979c7_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the coalition structure generation (CSG) problem. It compares three algorithmic paradigms and proves that, under a random sparse synergy model, sparse relaxation methods can find near-optimal solutions in polynomial time, while exact methods like DP and MILP require exponential time to reach similar quality, establishing a clear anytime performance advantage for the sparse approach.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Near-Optimal Coalition Structures in Polynomial Time] --> B[核心问题/Problem: Coalition Structure Generation (CSG)]
        A --> C[主要方法/Method: Compare DP, MILP, and Sparse Relaxations]
        A --> D[关键结果/Results: Sparse relaxations achieve near-optimal welfare in polynomial time; DP/MILP require exponential time]
    ```

- **[arXiv251229] Structural Induced Exploration for Balanced and Scalable Multi-Robot Path Planning**
  - **tags:** [ai], [swarm intelligence], [Ant Colony Optimization, structural prior, load-aware objective, overlap suppression, multi-robot path planning]
  - **authors:** Zikun Guo, Adeyinka P. Adedigba, Rammohan Mallipeddi, Heoncheol Lee
  - **institution:** Kyungpook National University, Kumoh National Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.21654
  - **contributions:** 1. Proposes a structure-induced exploration framework that integrates structural priors into ACO initialization to constrain the search space. 2. Designs a pheromone update rule that emphasizes structurally meaningful connections and incorporates a load-aware objective to balance total travel distance with individual robot workload. 3. Introduces an explicit overlap suppression strategy to ensure distinct and balanced task allocation across the robot team.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca4635b64758650f78e762004770f2a7ac8eb62cd36aa2db98d90af82d3f6eae_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of scalable and balanced multi-robot path planning. It proposes a new framework that integrates structural priors into Ant Colony Optimization, along with a load-aware objective and overlap suppression, to improve route compactness, stability, and workload distribution. The method demonstrates consistent improvements over metaheuristic baselines and offers a scalable solution for applications like logistics and search-and-rescue.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Structural Induced Exploration for Balanced and Scalable Multi-Robot Path Planning] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Multi-robot path planning is combinatorially complex and requires balancing global efficiency with fair task allocation. 传统方法难以扩展/Traditional methods struggle to scale.]
        C[主要方法/Method: A structure-induced ACO framework. 利用结构先验、负载感知目标和重叠抑制/Uses structural prior, load-aware objective, and overlap suppression.]
        D[关键结果/Results: Improves route compactness, stability, and workload distribution. 提供可扩展的框架/Provides a scalable framework.]
    ```

- **[arXiv251229] Comparative Analysis of Deep Learning Models for Perception in Autonomous Vehicles**
  - **tags:** [cv], [object detection], [YOLO-NAS, YOLOv8, perception, autonomous vehicles, custom dataset]
  - **authors:** Jalal Khan
  - **institution:** United Arab Emirates University
  - **link:** https://arxiv.org/pdf/2512.21673
  - **contributions:** 1. Conducted a comparative performance analysis of two emerging deep learning models, YOLO-NAS and YOLOv8, for object detection in autonomous vehicle perception. 2. Created and utilized a custom dataset to evaluate the models under real-world use case scenarios. 3. Provided empirical results showing YOLOv8s offers a 75% reduction in training time and a 2% higher object detection accuracy (83% vs 81%) compared to YOLO-NAS.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4a67f4b1902039d3a0f1a96acadea1a1625b1870da583b146bb58337f3c0561_w640_q70.webp
  - **Simple LLM Summary:** This paper compares the performance of YOLO-NAS and YOLOv8 deep learning models for object detection in autonomous vehicle perception using a custom dataset. The analysis finds that the YOLOv8s model is significantly faster to train and achieves slightly higher detection accuracy than the YOLO-NAS model.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Comparative Analysis of Deep Learning Models for Perception in Autonomous Vehicles] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[评估自动驾驶感知中深度学习模型的性能/Evaluate DL model performance for AV perception]
    C --> C1[使用自定义数据集比较YOLO-NAS与YOLOv8/Compare YOLO-NAS and YOLOv8 using a custom dataset]
    D --> D1[YOLOv8s训练时间减少75%/YOLOv8s saves 75% training time]
    D --> D2[YOLOv8s准确率更高(83% vs 81%)/YOLOv8s has higher accuracy (83% vs 81%)]
    ```

- **[arXiv251229] RIPCN: A Road Impedance Principal Component Network for Probabilistic Traffic Flow Forecasting**
  - **tags:** [ai], [spatiotemporal forecasting], [probabilistic forecasting, uncertainty estimation, principal component analysis, road impedance, traffic flow]
  - **authors:** Haochen Lv, Yan Lin, Shengnan Guo, Xiaowei Mao, Hong Nie, Letian Gong, Youfang Lin, Huaiyu Wan
  - **institution:** Beijing Jiaotong University, Aalborg University
  - **link:** https://arxiv.org/pdf/2512.21685
  - **contributions:** 1. Proposes a dynamic impedance evolution network to model directional traffic transfer patterns driven by congestion and flow variability, revealing causes of uncertainty and enhancing reliability and interpretability. 2. Designs a principal component network to forecast the dominant eigenvectors of future flow covariance, enabling the capture of spatiotemporal uncertainty correlations. 3. Integrates domain-specific transportation theory with spatiotemporal principal component learning for probabilistic traffic flow forecasting, achieving superior performance over existing methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f835b2051524d67481fbf9f4479086a541b29307c2876046f2c3ee4eec60f92_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes RIPCN, a Road Impedance Principal Component Network for probabilistic traffic flow forecasting. It integrates transportation theory with principal component learning to model the causes of uncertainty and capture spatiotemporal uncertainty correlations. Experimental results show it outperforms existing probabilistic forecasting methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RIPCN: A Road Impedance Principal Component Network for Probabilistic Traffic Flow Forecasting] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1(如何建模交通流不确定性的成因? / How to model the causes of traffic flow uncertainty?)
        B --> B2(如何捕捉不确定性的时空相关性? / How to capture spatiotemporal correlations of uncertainty?)
        C --> C1(动态阻抗演化网络 / Dynamic Impedance Evolution Network)
        C --> C2(主成分网络 / Principal Component Network)
        D --> D1(超越现有概率预测方法 / Outperforms existing probabilistic forecasting methods)
    ```

- **[arXiv251229] BeHGAN: Bengali Handwritten Word Generation from Plain Text Using Generative Adversarial Networks**
  - **tags:** [cv], [handwritten text generation], [Generative Adversarial Networks, Handwritten Text Generation, Bengali, Dataset, Pre-processing]
  - **authors:** Md. Rakibul Islam, Md. Kamrozzaman Bhuiyan, Safwan Muntasir, Arifur Rahman Jawad, Most. Sharmin Sultana Samu
  - **institution:** Not explicitly stated in provided text. Affiliation/domain cannot be reliably inferred.
  - **link:** https://arxiv.org/pdf/2512.21694
  - **contributions:** 1. Proposed a method for generating Bengali handwritten words from plain text using GANs, addressing a significant research gap. 2. Developed and used a novel, self-collected dataset of Bengali handwriting from approximately 500 diverse individuals. 3. Demonstrated the ability to produce diverse and realistic handwritten outputs through the described approach.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8b36b4afe805283b88409b54815e1bd251762075786246ae741c57cb65c191a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of research on Bengali handwritten text generation by proposing a GAN-based method to generate words from plain text. The authors created a new dataset of Bengali handwriting samples from hundreds of contributors. The work successfully generates diverse handwritten outputs and contributes to advancing research in this area for the Bengali language.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[BeHGAN: Bengali Handwritten Word Generation] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[HTG is challenging & understudied for Bengali<br/>孟加拉语手写文本生成研究不足且困难]
        C --> C1[Propose GAN-based method<br/>提出基于GAN的方法]
        C --> C2[Use self-collected dataset<br/>使用自收集数据集]
        C --> C3[Pre-process images<br/>预处理图像]
        D --> D1[Generates diverse handwritten words<br/>生成多样化手写词]
        D --> D2[Contributes to Bengali HTG research<br/>推动孟加拉语手写文本生成研究]
    ```

- **[arXiv251229] Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning**
  - **tags:** [mlsys], [agent system], [agentic AI, consensus-driven reasoning, explainable AI, responsible AI, multi-model governance]
  - **authors:** Eranga Bandara, Tharaka Hewa, Ross Gore, Sachin Shetty, Ravi Mukkamala, Peter Foytik, Abdul Rahman, Safdar H. Bouk, Xueping Liang, Amin Hass, Sachini Rajapakse, Ng Wee Keong, Kasun De Zoysa, Aruna Withanage, Nilaan Loganathan
  - **institution:** Old Dominion University, University of Oulu, Deloitte & Touche LLP, Florida International University, Nanyang Technological University, University of Colombo, IcicleLabs.AI, Accenture Technology Labs, Effectz.AI
  - **link:** https://arxiv.org/pdf/2512.21699
  - **contributions:** 1. Proposes a novel RAI/XAI agent architecture for production workflows based on multi-model consensus and reasoning-layer governance. 2. Introduces a mechanism where a consortium of heterogeneous LLM/VLM agents generate independent outputs, exposing uncertainty and alternatives for structured consolidation. 3. Demonstrates that the consensus-driven approach improves robustness, transparency, and operational trust across diverse real-world agentic AI workflows.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed22161f8f004c98e3fb6124bac7991548de5e54f47adb42f0d3eb1095409e6e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenges of explainability and responsibility in increasingly autonomous agentic AI systems. It proposes a new architecture where multiple AI agents generate candidate outputs, and a dedicated reasoning agent consolidates them while enforcing safety constraints, thereby improving decision robustness and auditability. The work provides a practical framework for building agentic systems that are both scalable and responsible by design.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Agentic AI lacks explainability & responsibility] --> B1[挑战/Challenges<br>Explainability, Accountability, Robustness, Governance]
        C[主要方法/Method<br>Multi-model Consensus & Reasoning-layer Governance] --> C1[架构/Architecture<br>Consortium of LLM/VLM Agents]
        C --> C2[过程/Process<br>Structured Consolidation by Dedicated Reasoning Agent]
        D[关键结果/Results<br>Improved Robustness, Transparency & Operational Trust]
    ```

- **[arXiv251229] Zero-Shot to Zero-Lies: Detecting Bengali Deepfake Audio through Transfer Learning**
  - **tags:** [sec], [audio deepfake detection], [transfer learning, zero-shot inference, fine-tuning, Bengali audio, BanglaFake dataset]
  - **authors:** Most. Sharmin Sultana Samu, Md. Rakibul Islam, Md. Zahid Hossain, Md. Kamrozzaman Bhuiyan, Farhad Uz Zaman
  - **institution:** Not explicitly stated in the provided content.
  - **link:** https://arxiv.org/pdf/2512.21702
  - **contributions:** 1. Conducts the first systematic benchmark for Bengali deepfake audio detection using the BanglaFake dataset. 2. Evaluates and demonstrates the limited performance of multiple pre-trained models in a zero-shot setting for this task. 3. Shows that fine-tuning deep learning models (e.g., ResNet18) significantly improves detection performance, establishing an effective approach for low-resource languages.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66eab5318a9b87f6facd46827f1723103def2a66467b77d3a3f1b6ea7a41d92f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the underexplored problem of Bengali deepfake audio detection. It first evaluates several pre-trained models using zero-shot inference, finding limited performance, and then fine-tunes various architectures, with ResNet18 achieving the best results. The study concludes that fine-tuning is crucial for effective deepfake detection in low-resource languages like Bengali.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Zero-Shot to Zero-Lies: Detecting Bengali Deepfake Audio through Transfer Learning] --> B(核心问题/Problem: Bengali Deepfake Audio Detection is unexplored)
        A --> C(主要方法/Method: Zero-shot inference & Fine-tuning of pre-trained models)
        A --> D(关键结果/Results: Fine-tuned ResNet18 achieves best performance (79.17% accuracy))
    ```

- **[arXiv251229] Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech**
  - **tags:** [nlp], [spoken dialogue systems], [Graph-of-Thoughts, full-duplex, speech acts, causal inference, multimodal transformer]
  - **authors:** Shuchang Pan, Siddharth Banerjee, Dhruv Hebbar, Siddhant Patel, Akshaj Gupta, Kan Jen Cheng, Hanjo Kim, Zeyi Austin Li, Martin Q. Ma, Tingle Li, Gopala Anumanchipalli, Jiachen Lian
  - **institution:** Zhejiang University, University of California, Berkeley, Carnegie Mellon University
  - **link:** https://arxiv.org/pdf/2512.21706
  - **code:** https://got-duplex.github.io/
  - **contributions:** 1. A framework that models conversational behavior reasoning as causal inference within a Graph-of-Thoughts (GoT) to enable interpretable decision-making in full-duplex dialogue. 2. A hierarchical labeling scheme and hybrid training corpus combining simulated dialogues with human rationales and real speech to learn causal and temporal dependencies between intents and speech acts. 3. A system that structures streaming predictions as an evolving graph, allowing a multimodal transformer to forecast the next speech act, generate justifications, and dynamically refine its reasoning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eaad0398d39f15391b728b9e3c53af71ff071dcfd269c61b0a277091d58ee7f3_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of explicit reasoning in full-duplex spoken dialogue systems by proposing a framework that models the perception-reasoning-generation loop as causal inference within a Graph-of-Thoughts (GoT). The method uses a hierarchical behavior detection model and a hybrid corpus to learn dependencies, enabling an agent to predict the next speech act and generate interpretable justifications. Experiments show the framework provides robust behavior detection and interpretable reasoning, establishing a foundation for benchmarking conversational reasoning.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Enabling Conversational Behavior Reasoning in Full-Duplex Speech<br/>实现全双工语音对话行为推理"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br/>Current systems lack explicit reasoning for conversational behaviors."]
        Method["主要方法/Method<br/>Model reasoning as causal inference in a Graph-of-Thoughts (GoT)."]
        Results["关键结果/Results<br/>Robust behavior detection and interpretable reasoning chains."]
    ```

- **[arXiv251229] Detecting AI-Generated Paraphrases in Bengali: A Comparative Study of Zero-Shot and Fine-Tuned Transformers**
  - **tags:** [nlp], [ai-generated text detection], [transformer, fine-tuning, zero-shot, Bengali, paraphrase detection]
  - **authors:** Md. Rakibul Islam, Most. Sharmin Sultana Samu, Md. Zahid Hossain, Farhad Uz Zaman, Md. Kamrozzaman Bhuiyan
  - **institution:** Not specified in provided content.
  - **link:** https://arxiv.org/pdf/2512.21709
  - **contributions:** 1. Conducts the first comparative study of transformer models for detecting AI-generated paraphrases specifically in the Bengali language. 2. Demonstrates that zero-shot evaluation of pre-trained models yields near-chance performance, highlighting the necessity of task-specific fine-tuning for this problem. 3. Shows that fine-tuning significantly boosts performance, with XLM-RoBERTa, mDeBERTa, and MultilingualBERT achieving high accuracy (~91%), establishing a strong baseline for future research.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b32597f75301412c6dbf1765506d21eb52c7e7727c1e3eefdfaa406f8c4ae44_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of detecting AI-generated paraphrased text in Bengali, a low-resource language. It evaluates five transformer models in zero-shot and fine-tuned settings, finding that fine-tuning is essential and leads to high detection accuracy (~91%) for several models. The work establishes a foundation for robust AI-generated content detection systems in Bengali.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Detecting AI-Generated Paraphrases in Bengali] --> B[核心问题/Problem: LLM misuse & lack of Bengali detection research]
        A --> C[主要方法/Method: Compare 5 transformers (Zero-Shot vs. Fine-Tuned)]
        A --> D[关键结果/Results: Fine-tuning needed; XLM-R, mDeBERTa, mBERT achieve ~91% accuracy]
    ```

- **[arXiv251229] Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought**
  - **tags:** [nlp], [interpretability & analysis], [latent tokens, chain-of-thought, model reliability, causal analysis, shortcut learning]
  - **authors:** Yuyi Zhang, Boyu Tang, Tianjie Ju, Sufeng Duan, Gongshen Liu
  - **institution:** Shanghai Jiao Tong University
  - **link:** https://arxiv.org/pdf/2512.21711
  - **contributions:** 1. Introduces "Steering Experiments" to causally test the impact of perturbing latent reasoning tokens, revealing COCONUT tokens are insensitive to perturbation unlike explicit CoT tokens. 2. Conducts "Shortcut Experiments" to evaluate models under biased and out-of-distribution settings, demonstrating COCONUT exploits dataset artifacts rather than performing genuine reasoning. 3. Repositions COCONUT as a "pseudo-reasoning" mechanism that generates plausible traces to conceal shortcut dependence, challenging its claimed reasoning capabilities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99abfa3b8406909febaa5ee077a1feab3c1d8b8cda1eebe350774e19cb82eb77_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the reliability of latent reasoning tokens in LLMs, specifically Chain-of-Continuous-Thought (COCONUT). Through causal steering and adversarial shortcut experiments, it finds that COCONUT tokens are uninterpretable placeholders insensitive to perturbation and that the method relies on dataset shortcuts. The main conclusion is that COCONUT is a pseudo-reasoning mechanism that inflates benchmark performance without faithful reasoning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Latent token mechanisms unclear, reliability concerns] --> B1[潜在令牌机制不明确/Unclear latent token mechanisms]
        B --> B2[可靠性问题/Reliability concerns]
        C[主要方法/Method: Causal & adversarial analysis] --> C1[引导实验/Steering experiments]
        C --> C2[捷径实验/Shortcut experiments]
        D[关键结果/Results: COCONUT is pseudo-reasoning] --> D1[令牌对扰动不敏感/Tokens insensitive to perturbation]
        D --> D2[利用数据集捷径/Exploits dataset shortcuts]
        D --> D3[性能提升不基于真实推理/Performance gains not from true reasoning]
    ```

- **[arXiv251229] Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities**
  - **tags:** [sys], [communication & networking], [multiconnectivity, SAGIN, resource allocation, agentic reinforcement learning, heterogeneous networks]
  - **authors:** Abd Ullah Khan, Adnan Shahid, Haejoon Jung, Hyundong Shin
  - **institution:** Kyung Hee University, Ghent University
  - **link:** https://arxiv.org/pdf/2512.21717
  - **contributions:** 1. Provides a comprehensive review of current developments and key implementation challenges in SAGIN-enabled multiconnectivity. 2. Highlights the transformative potential of AI-driven approaches, particularly agentic reinforcement learning, for resource optimization in heterogeneous SAGIN environments. 3. Presents a case study demonstrating that learning-based methods can effectively enhance network performance (latency, capacity) with a moderate trade-off in power consumption.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp
  - **Simple LLM Summary:** This paper reviews the challenges of implementing multiconnectivity in heterogeneous Space-Air-Ground Integrated Networks (SAGIN) and proposes AI-driven solutions, specifically agentic reinforcement learning, for optimal resource allocation. A case study shows these methods significantly improve latency and capacity, albeit with a moderate increase in power consumption as a trade-off. The work concludes by outlining open research problems for realizing efficient SAGIN-enabled multiconnectivity.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem: Heterogeneous SAGIN complicates multiconnectivity and resource allocation"]
        Method["主要方法/Method: Use AI-driven approaches, specifically agentic reinforcement learning"]
        Results["关键结果/Results: Enhanced network performance (latency, capacity) with moderate power trade-off"]
    ```

- **[arXiv251229] CATCH: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation**
  - **tags:** [nlp], [dialogue systems], [theme detection, topic clustering, hierarchical generation]
  - **authors:** Rui Ke, Jiahui Xu, Shenghao Yang, Kuang Wang, Feng Jiang, Haizhou Li
  - **institution:** The Chinese University of Hong Kong, Shenzhen; Shenzhen University of Advanced Technology; National University of Singapore
  - **link:** https://arxiv.org/pdf/2512.21715
  - **contributions:** 1. A context-aware topic representation method that enriches utterance semantics using surrounding topic segments. 2. A preference-guided topic clustering mechanism that jointly models semantic proximity and personalized feedback for cross-dialogue theme alignment. 3. A hierarchical theme generation mechanism designed to suppress noise and produce robust, coherent topic labels.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da012bcf7b19d126b0f1a64e4fc67ee4a82a999c3d110d6b449ab0c750d9458e_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes CATCH, a framework for controllable theme detection in dialogues, which integrates contextualized clustering and hierarchical generation to address sparse utterances and user preference alignment. It demonstrates effectiveness on the DSTC-12 benchmark using an 8B LLM for both clustering and label generation quality.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[CATCH: 可控主题检测框架 / Controllable Theme Detection Framework] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题 / Problem] --> P1[短话语稀疏语义 / Sparse, short utterances]
        Problem --> P2[跨对话主题对齐 / Cross-dialogue theme alignment]
        Problem --> P3[用户偏好整合 / Personalized user preferences]
        Method[主要方法 / Method] --> M1[上下文感知主题表示 / Context-aware topic representation]
        Method --> M2[偏好引导主题聚类 / Preference-guided topic clustering]
        Method --> M3[分层主题生成 / Hierarchical theme generation]
        Results[关键结果 / Results] --> R1[在DSTC-12基准测试有效 / Effective on DSTC-12 benchmark]
        Results --> R2[提升聚类与生成质量 / Improved clustering & generation quality with 8B LLM]
    ```

- **[arXiv251229] An Information Theoretic Perspective on Agentic System Design**
  - **tags:** [mlsys], [agent system], [mutual information, noisy channel, compressor-predictor, on-device AI, information-theoretic]
  - **authors:** Shizhe He, Avanika Narayan, Ishan S. Khare, Scott W. Linderman, Christopher Ré, Dan Biderman
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2512.21720
  - **contributions:** 1. Proposes an information-theoretic framework for analyzing agentic LM systems, viewing the compressor as a noisy channel. 2. Introduces a task-independent estimator of mutual information between context and compression to quantify compression quality. 3. Empirically demonstrates that scaling compressor models is more effective than scaling predictors for performance and cost, enabling efficient on-device compression.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124535642e159e8f7a123525ffbf3cb5f163a7ae4a7876a4d1e71e7e6c885ace_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the ad-hoc design of agentic LM systems that use a compressor LM to summarize context for a predictor LM. It proposes an information-theoretic framework using mutual information to evaluate compressors, finding that larger compressors are more accurate, concise, and information-dense, making scaling compressors more effective than scaling predictors for cost-efficient performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[An Information Theoretic Perspective on Agentic System Design] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1("Agentic系统设计缺乏理论指导<br/>Agentic system design lacks theoretical guidance")
        C --> C1("提出信息论框架与互信息估计器<br/>Propose information-theoretic framework & mutual information estimator")
        D --> D1("更大压缩器更高效、更准确<br/>Larger compressors are more efficient and accurate")
        D --> D2("扩展压缩器优于扩展预测器<br/>Scaling compressors outperforms scaling predictors")
    ```

- **[arXiv251229] HELP: Hierarchical Embodied Language Planner for Household Tasks**
  - **tags:** [mlsys], [agent system], [embodied agent, hierarchical planning, large language model, household tasks, open source LLM]
  - **authors:** Alexandr V. Korchemnyi, Anatoly O. Onishchenko, Eva A. Bakaeva, Alexey K. Kovalev, Aleksandr I. Panov
  - **institution:** MIRAI, Cognitive AI Systems Lab
  - **link:** https://arxiv.org/pdf/2512.21723
  - **contributions:** 1. Proposes a Hierarchical Embodied Language Planner (HELP) architecture using multiple LLM-based agents for decomposing and grounding natural language instructions. 2. Demonstrates the approach on a real-world household task using an embodied agent. 3. Focuses on the use of relatively small, open-source LLMs to enable autonomous deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d5e8ef0910254268525eec44918d2562afe5a6df81ece96ba720311313fef5b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of planning for embodied agents following ambiguous natural language instructions in complex environments. It proposes HELP, a hierarchical planner using multiple LLM-based agents to decompose high-level instructions into grounded, executable subtasks. The method is evaluated on a household task with a real robot, showing the feasibility of using smaller, open-source LLMs for autonomous operation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HELP: Hierarchical Embodied Language Planner for Household Tasks] --> B[核心问题/Problem: Embodied agents need robust planning for ambiguous natural language instructions in complex environments.]
        A --> C[主要方法/Method: Hierarchical planner with multiple LLM-based agents to decompose and ground instructions into executable steps.]
        A --> D[关键结果/Results: Evaluated on real-world household task; demonstrates use of smaller open-source LLMs for autonomous deployment.]
    ```

- **[arXiv251229] A Model of Causal Explanation on Neural Networks for Tabular Data**
  - **tags:** [ai], [explainable ai], [CENNET, structural causal models, entropy, causal explanation, tabular data]
  - **authors:** Takashi Isozaki, Masahiro Yamamoto, Atsushi Noda
  - **institution:** Sony Computer Science Laboratories, Inc., Sony Corporation of America
  - **link:** https://arxiv.org/pdf/2512.21746
  - **contributions:** 1. Proposes CENNET, a novel causal explanation method for neural network predictions on tabular data. 2. Introduces a new explanation power index based on entropy for evaluating the proposed method. 3. Demonstrates the method's effectiveness by combining structural causal models with neural networks for causal explanations, validated on synthetic and quasi-real data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02e8ba8968728eba560984773ed8ba2b124e42c46e3c839dec8a1ca2a5975ce1_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of providing causal explanations for neural network predictions on tabular data, where pseudo-correlations can mislead. The authors propose a method called CENNET, which integrates structural causal models with neural networks to generate causal explanations and introduces an entropy-based index to measure explanation power. Experiments on synthetic and quasi-real data show that CENNET effectively provides causal explanations compared to existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Model of Causal Explanation on Neural Networks for Tabular Data] --> B[核心问题/Problem: Explaining NN predictions on tabular data, addressing pseudo-correlation and causality]
        A --> C[主要方法/Method: Propose CENNET, a causal explanation method using SCMs and an entropy-based index]
        A --> D[关键结果/Results: CENNET provides causal explanations, validated via comparative experiments]
    ```

- **[arXiv251229] How Do Agents Perform Code Optimization? An Empirical Study**
  - **tags:** [se], [code optimization], [AI coding agents, performance optimization, empirical study, pull request analysis, AIDev dataset]
  - **authors:** Huiyun Peng, Antonio Zhong, Ricardo Andrés Calvo Méndez, Kelechi G. Kalu, James C. Davis
  - **institution:** Purdue University
  - **link:** https://arxiv.org/pdf/2512.21757
  - **contributions:** 1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp
  - **Simple LLM Summary:** This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[How Do Agents Perform Code Optimization? An Empirical Study] --> B[核心问题/Problem: AI coding agents' effectiveness on real-world performance optimization tasks is unknown.]
        A --> C[主要方法/Method: Empirical comparison of 324 agent-generated and 83 human-authored performance PRs from AIDev dataset.]
        A --> D[关键结果/Results: AI-authored PRs use similar patterns but include less explicit performance validation (45.7% vs 63.6%).]
    ```

- **[arXiv251229] A-QCF-Net: An Adaptive Quaternion Cross-Fusion Network for Multimodal Liver Tumor Segmentation from Unpaired Datasets**
  - **tags:** [cv], [medical image segmentation], [Quaternion Neural Networks, Cross-Attention, Unpaired Data, Multimodal Learning, Explainable AI]
  - **authors:** Arunkumar V, Firos V M, Senthilkumar S, Gangadharan G R
  - **institution:** Anna University, National Institute of Technology Tiruchirappalli
  - **link:** https://arxiv.org/pdf/2512.21760
  - **contributions:** 1. Proposes an Adaptive Quaternion Cross-Fusion (A-QCF) block for bidirectional knowledge transfer between unpaired CT and MRI data streams., 2. Introduces a unified segmentation model (A-QCF-Net) that leverages Quaternion Neural Networks to build a shared feature space from separate datasets., 3. Demonstrates significant performance gains over strong unimodal baselines and validates clinical relevance through explainability analysis.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebec19949c3fad65f84d0acee71e271ec2d8caca288cc4ecf24768e9533dbbe8_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of training multimodal segmentation models with unpaired datasets. It proposes A-QCF-Net, which uses Quaternion Neural Networks and an adaptive cross-fusion block to enable knowledge transfer between separate CT and MRI data. The method significantly outperforms unimodal baselines and provides a viable paradigm for leveraging large, unpaired medical image archives.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A-QCF-Net: An Adaptive Quaternion Cross-Fusion Network<br>for Multimodal Liver Tumor Segmentation from Unpaired Datasets] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Scarcity of paired & aligned multimodal medical datasets]
        C[主要方法/Method<br>Adaptive Quaternion Cross-Fusion (A-QCF) block<br>Quaternion Neural Networks for shared feature space]
        D[关键结果/Results<br>Significant Dice score improvement over nnU-Net<br>Validated by explainability analysis]
    ```

- **[arXiv251229] Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets**
  - **tags:** [sec], [Data Provenance], [Data Provenance, Compliance Rating, Generative AI, Dataset Ethics, Transparency]
  - **authors:** Matyas Bohacek, Ignacio Vilanova Echavarri
  - **institution:** Stanford University, Imperial College London
  - **link:** https://arxiv.org/pdf/2512.21775
  - **contributions:** 1. Proposes the Compliance Rating Scheme (CRS), a framework for evaluating dataset compliance with transparency, accountability, and security principles. 2. Develops and releases an open-source Python library that implements the CRS framework using data provenance technology. 3. Creates a tool that is both reactive (evaluating existing datasets) and proactive (guiding the responsible construction of new datasets).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa33a1fedd52ef1c87e9bf7d9a25dad61aae942ba50660263862470b9b677745_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of ethical and legal oversight in the creation and sharing of datasets for Generative AI. It proposes the Compliance Rating Scheme (CRS) framework and an accompanying open-source library to assess and ensure dataset compliance with key principles. The work aims to improve traceability and accountability in the AI data supply chain.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("数据集创建缺乏伦理与法律监督/Lack of ethical & legal oversight in dataset creation")
        Problem --> P2("数据来源与合法性信息丢失/Loss of data origin & legitimacy info")
        Method --> M1("提出合规评级方案(CRS)框架/Propose Compliance Rating Scheme (CRS) framework")
        Method --> M2("开发基于数据溯源技术的开源库/Develop open-source library using data provenance")
        Results --> R1("评估现有数据集的合规性/Evaluate compliance of existing datasets")
        Results --> R2("指导负责任的新数据集构建/Guide responsible construction of new datasets")
    ```

- **[arXiv251229] Inference-based GAN Video Generation**
  - **tags:** [cv], [video generation], [VAE-GAN, Markov chain, long video generation, temporal consistency, encoder-decoder]
  - **authors:** Jingbo Yang, Adrian G. Bors
  - **institution:** University of York
  - **link:** https://arxiv.org/pdf/2512.21776
  - **contributions:** 1. Proposes a new video generator, Encoder GAN3 (EncGAN3), which is a VAE-GAN hybrid structure that incorporates inference capabilities into an adversarial-based unconditional video generator. 2. Introduces a novel, memory-efficient approach to generate long videos (hundreds/thousands of frames) by extending the base VAE-GAN model. 3. Leverages a Markov chain framework with a recall mechanism, where each state is a short VAE-GAN generator, to sequentially connect video sub-sequences and ensure temporal continuity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5d6cd59a07e4478b6b21e586a92b15f90e237037b758a29738bf31e46f9843c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of generating long, high-quality videos, a task where existing models suffer from quality degradation. The proposed method first introduces a VAE-GAN hybrid video generator (EncGAN3) and then extends it using a Markov chain framework to sequentially generate short video clips, enabling the creation of temporally consistent long videos. The main conclusion is that this approach overcomes the temporal scaling limitation and allows for memory-efficient generation of long video sequences.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Inference-based GAN Video Generation] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[现有模型难以生成长视频/Existing models struggle with long video generation]
        P1 --> P2[视频长度增加导致质量下降/Increased length degrades quality]
        Method[主要方法/Method] --> M1[提出VAE-GAN混合视频生成器/Propose VAE-GAN hybrid video generator]
        M1 --> M2[使用马尔可夫链框架扩展/Extend with Markov chain framework]
        M2 --> M3[状态代表短视频生成器/Each state is a short video generator]
        Results[关键结果/Results] --> R1[能够生成长视频序列/Can generate long video sequences]
        R1 --> R2[确保时序连续性与一致性/Ensures temporal continuity and consistency]
    ```

- **[arXiv251229] Accelerating Scientific Discovery with Autonomous Goal-evolving Agents**
  - **tags:** [ai], [scientific discovery agents], [autonomous goal evolution, bi-level optimization, LLM agents, objective function design, scientific discovery]
  - **authors:** Yuanqi Du, Botao Yu, Tianyu Liu, Tony Shen, Junwu Chen, Jan G. Rittig, Kunyang Sun, Yikun Zhang, Zhangde Song, Bo Zhou, Cassandra Masschelein, Yingze Wang, Haorui Wang, Haojun Jia, Chao Zhang, Hongyu Zhao, Martin Ester, Teresa Head-Gordon, Carla P. Gomes, Huan Sun, Chenru Duan, Philippe Schwaller, Wengong Jin
  - **institution:** Cornell University, The Ohio State University, Yale University, Simon Fraser University, École Polytechnique Fédérale de Lausanne, University of California Berkeley, Northeastern University, Deep Principle, University of Illinois Chicago, Georgia Institute of Technology, Broad Institute of MIT and Harvard
  - **link:** https://arxiv.org/pdf/2512.21782
  - **contributions:** 1. Identifies and addresses the unmet requirement of automating objective function design for scientific discovery agents, moving beyond fixed, imperfect proxies. 2. Proposes the SAGA framework, a novel bi-level architecture where an outer loop of LLM agents evolves objectives and an inner loop optimizes solutions under them. 3. Demonstrates the framework's effectiveness across diverse scientific domains (antibiotic, materials, DNA, chemical process design), showing improved discovery outcomes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9035dcf8fd16c34c235e39c8960c63fa826c45df283663a01722181f7ab419d8_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces SAGA, a framework for scientific discovery where LLM agents autonomously evolve and refine the objective functions used to guide optimization, rather than relying on fixed human-specified goals. This bi-level architecture enables systematic exploration of objective spaces and their trade-offs. The method is shown to substantially improve the effectiveness of discovery agents across multiple application domains.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Accelerating Scientific Discovery with Autonomous Goal-evolving Agents] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[Fixed objectives are imperfect proxies for grand scientific challenges / 固定的目标函数是科学重大挑战的不完美代理]
        Method[主要方法/Method] --> M1[Proposes SAGA: Scientific Autonomous Goal-evolving Agent / 提出SAGA: 科学自主目标演化智能体]
        M1 --> M2[Bi-level architecture: LLM outer loop evolves objectives, inner loop optimizes solutions / 双层架构: LLM外循环演化目标，内循环优化解]
        Results[关键结果/Results] --> R1[Applied to antibiotic, materials, DNA, chemical process design / 应用于抗生素、材料、DNA、化工过程设计]
        R1 --> R2[Automating objective formulation improves discovery effectiveness / 自动化目标制定提升了发现效能]
    ```

- **[arXiv251229] Multi-agent Adaptive Mechanism Design**
  - **tags:** [ai], [mechanism design], [distributionally robust optimization, online learning, incentive compatibility, adaptive mechanism, regret analysis]
  - **authors:** Qiushi Han, David Simchi-Levi, Renfei Tan, Zishuo Zhao
  - **institution:** Massachusetts Institute of Technology, University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2512.21794
  - **contributions:** 1. Introduces DRAM, a novel framework combining mechanism design and online learning to handle unknown agent beliefs. 2. Provides theoretical guarantees of high-probability truthfulness and achieves optimal $\tilde\{O\}(\sqrt\{T\})$ cumulative regret with a matching lower bound. 3. Generalizes the framework (DRAM+) to support plug-in estimators, structured priors, and delayed feedback.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c99ece7d8b60855735e1eee48c51256eacf5f3997d56ced3396434f12a30ad44_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of designing a truthful mechanism when the principal has no prior knowledge of agents' beliefs. It proposes the Distributionally Robust Adaptive Mechanism (DRAM), which iteratively learns beliefs and updates a robust optimization problem to minimize cost while ensuring truthfulness. The mechanism is proven to achieve optimal regret, and the framework is the first to maintain truthfulness under these general learning conditions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multi-agent Adaptive Mechanism Design] --> B[核心问题/Problem: Elicit truthful reports with no prior knowledge of agent beliefs]
        A --> C[主要方法/Method: Distributionally Robust Adaptive Mechanism (DRAM)]
        A --> D[关键结果/Results: Guaranteed truthfulness & optimal $\tilde{O}(\sqrt{T})$ regret]
    ```

- **[arXiv251229] Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning**
  - **tags:** [nlp], [image captioning], [scientific figure captioning, large-scale dataset, domain-specific training, human evaluation, large language models (LLMs)]
  - **authors:** Ting-Hao K.Huang, Ryan A. Rossi, Sungchul Kim, Tong Yu, Ting-Yao E. Hsu, Ho Yin, C. Lee Giles
  - **institution:** The Pennsylvania State University, Adobe Research
  - **link:** https://arxiv.org/pdf/2512.21789
  - **contributions:** 1. Creation and continuous updating of a large-scale, real-world dataset of scientific figure-caption pairs from arXiv papers. 2. Conducting extensive evaluations, both automatic and human, on generated and author-written captions to assess quality. 3. Developing interactive systems and launching annual challenges to advance the field and help scientists write better captions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp
  - **Simple LLM Summary:** This paper reviews the SciCap project's first five years, which focused on generating and evaluating captions for scientific figures. The core method involved building a large-scale dataset from arXiv and exploring domain-specific training, similar to models like SciBERT, for captioning. The conclusion outlines key lessons learned and proposes future research directions to address unsolved challenges in the field.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[科学图表说明质量差/Poor quality of scientific figure captions]
        Problem --> P2[缺乏大规模真实数据集/Lack of large-scale real-world dataset]
        Method --> M1[构建arXiv图表-说明对数据集/Construct arXiv figure-caption dataset]
        Method --> M2[领域特定训练与评估/Domain-specific training & evaluation]
        Method --> M3[应对大语言模型兴起/Navigate rise of LLMs]
        Results --> R1[总结技术方法经验/Summarize technical & methodological lessons]
        Results --> R2[提出未来挑战与方向/Outline future challenges & directions]
    ```

- **[arXiv251229] InstructMoLE: Instruction-Guided Mixture of Low-rank Experts for Multi-Conditional Image Generation**
  - **tags:** [cv], [diffusion models], [Parameter-Efficient Fine-Tuning, Mixture of Low-rank Experts, Instruction-Guided Routing, Multi-Conditional Generation, Diffusion Transformers]
  - **authors:** Jinqi Xiao, Qing Yan, Liming Jiang, Zichuan Liu, Hao Kang, Shen Sang, Tiancheng Zhi, Jing Liu, Cheng Yang, Xin Lu, Bo Yuan
  - **institution:** ByteDance Inc., Rutgers University
  - **link:** https://arxiv.org/pdf/2512.21788
  - **code:** https://github.com/yanq095/InstructMoLE
  - **contributions:** 1. Introduces InstructMoLE, a framework using an Instruction-Guided Mixture of Low-Rank Experts for multi-conditional image generation., 2. Proposes Instruction-Guided Routing (IGR), a global routing signal derived from user instructions to select a coherent expert council for all tokens, addressing spatial fragmentation and semantic drift., 3. Introduces an output-space orthogonality loss to promote expert functional diversity and prevent representational collapse.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11bd8639cb632e86b35367843cf453bbc6a02fb6882f88ff7441c78b42b653ce_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of task interference in multi-conditional image generation when using monolithic PEFT adapters like LoRA. It proposes InstructMoLE, a novel framework that uses global instruction-guided routing to select a consistent mixture of low-rank experts, combined with an orthogonality loss for diversity, which outperforms existing methods on benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[InstructMoLE: Instruction-Guided Mixture of Low-rank Experts for Multi-Conditional Image Generation] --> B[核心问题/Problem: Task interference & spatial fragmentation in multi-conditional DiT fine-tuning]
        A --> C[主要方法/Method: Global Instruction-Guided Routing (IGR) & output-space orthogonality loss]
        A --> D[关键结果/Results: Outperforms LoRA & MoLE variants on benchmarks]
    ```

- **[arXiv251229] CellMamba: Adaptive Mamba for Accurate and Efficient Cell Detection**
  - **tags:** [cv], [object detection], [Mamba, Triple-Mapping Adaptive Coupling (TMAC), Adaptive Mamba Head, biomedical instance detection, VSSD backbone]
  - **authors:** Ruochen Liu, Yi Tian, Jiahao Wang, Hongbin Liu, Xianxu Hou, Jingxin Liu
  - **institution:** University of Liverpool, National University of Singapore, Xi'an Jiaotong-Liverpool University
  - **link:** https://arxiv.org/pdf/2512.21803
  - **contributions:** 1. Proposes a novel Triple-Mapping Adaptive Coupling (TMAC) module that splits channels into parallel branches with dual idiosyncratic and one consensus attention map for enhanced spatial discriminability. 2. Designs an Adaptive Mamba Head that fuses multi-scale features via learnable weights to handle varying object sizes robustly. 3. Introduces CellMamba, a lightweight one-stage detector built on a VSSD backbone with CellMamba Blocks, achieving superior accuracy and efficiency on biomedical cell detection datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fc3fe9b8372a27eedc5a8e2e1150bcdf6cf461c195f9ed154d8890662de191da_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes CellMamba, a lightweight one-stage detector for cell detection in pathological images. It introduces a novel Triple-Mapping Adaptive Coupling (TMAC) module and an Adaptive Mamba Head to improve spatial discriminability and multi-scale feature fusion. Experiments show CellMamba outperforms CNN, Transformer, and Mamba baselines in accuracy while being more efficient in model size and inference speed.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CellMamba: Adaptive Mamba for Cell Detection] --> B[核心问题/Problem: Cell detection challenges in pathological images]
        A --> C[主要方法/Method: CellMamba with TMAC module & Adaptive Mamba Head]
        A --> D[关键结果/Results: Outperforms baselines, lightweight & efficient]
    ```

- **[arXiv251229] S&P 500 Stock's Movement Prediction using CNN**
  - **tags:** [ai], [financial time series forecasting], [Convolutional Neural Network (CNN), multivariate raw data, stock movement prediction, historical data matrices, S&P 500]
  - **authors:** Rahul Gupta
  - **institution:** None (No affiliation or email domain provided in the given content)
  - **link:** https://arxiv.org/pdf/2512.21804
  - **contributions:** 1. Proposes the application of Convolutional Neural Networks (CNNs), typically used for image classification, to the problem of stock movement prediction by treating multivariate historical stock data as image-like matrices. 2. Utilizes raw, unprocessed market data including events like stock splits and dividends, instead of relying on pre-engineered financial features. 3. Demonstrates a flexible prediction framework that can be applied at different levels: individual stocks, sectors, or entire portfolios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d6197655292ac8e55d8c7606c8c3cfe730f7f8dad4004b93d4a9b3a8d8f457_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the problem of predicting stock price movements for the S&P 500 index. The core method involves using a Convolutional Neural Network (CNN) to analyze multivariate historical stock data, which is structured as image-like matrices, without extensive feature engineering. The approach shows promising results and offers a flexible model for stock, sector, or portfolio-level predictions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["S&P 500 Stock's Movement Prediction using CNN<br>使用CNN预测标普500股票走势"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Predicting stock price movement<br>预测股票价格走势"] --> P1["传统方法依赖特征工程<br>Traditional methods rely on engineered features"]
        Problem --> P2["现有研究多使用单维数据<br>Existing research often uses single-dimension data"]
        Method["主要方法/Method<br>Use CNN on raw multivariate data<br>对原始多变量数据使用CNN"] --> M1["将历史数据矩阵视为图像<br>Treat historical data matrices as images"]
        Method --> M2["包含原始市场事件(如拆股)<br>Include raw market events (e.g., splits)"]
        Results["关键结果/Results<br>Model achieves promising results<br>模型取得有希望的结果"] --> R1["支持股票/行业/组合级别预测<br>Supports stock/sector/portfolio prediction"]
    ```

- **[arXiv251229] MoonBot: Modular and On-Demand Reconfigurable Robot Toward Moon Base Construction**
  - **tags:** [other], [space robotics], [modular robot, reconfigurable robot, lunar construction, field demonstration, connector design]
  - **authors:** Kentaro Uno, Elian Neppel, Gustavo H. Diaz, Ashutosh Mishra, Shamistan Karimov, A. Sejal Jain, Ayesha Habib, Pascal Pama, Hazal Gozbasi, Shreya Santra, Kazuya Yoshida
  - **institution:** Space Robotics Laboratory (SRL), Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University
  - **link:** https://arxiv.org/pdf/2512.21853
  - **contributions:** 1. Introduces MoonBot, a modular and reconfigurable robotic system designed for lunar payload constraints and task adaptability. 2. Details the system's design and development, including a field demonstration simulating lunar infrastructure tasks like civil engineering and component deployment. 3. Systematically summarizes lessons learned, particularly on connector design, to inform future modular robotic systems for lunar missions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7ceec836e29be790b6ca39392714dc64e19923b0842210e75988ad1c5fdeeb2_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces MoonBot, a modular and reconfigurable robot designed for constructing lunar bases under strict mass constraints. It details the robot's design and validates its concept through field demonstrations of simulated construction tasks. The work concludes with lessons learned, especially regarding connector design, to guide future lunar robotic systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MoonBot: 面向月球基地建设的模块化按需可重构机器人] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[月球探索与基地建设需求 / Lunar Exploration & Base Construction Needs]
        C --> C1[模块化可重构机器人系统 / Modular & Reconfigurable Robotic System]
        C --> C2[概念验证与现场演示 / Proof-of-Concept & Field Demonstration]
        D --> D1[成功执行模拟任务 / Successfully Executed Simulated Tasks]
        D --> D2[总结了连接器设计等经验教训 / Summarized Lessons (e.g., Connector Design)]
    ```

- **[arXiv251229] HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs**
  - **tags:** [nlp], [evaluation], [anthropomorphic intelligence, benchmark, psychological counseling, rubric-based evaluation, reasoning-before-scoring]
  - **authors:** Jiaxin Liu, Peiyi Tu, Wenyu Chen, Yihong Zhuang, Xinxia Ling, Anji Zhou, Chenxi Wang, Zhuo Han, Zhengkai Yang, Junbo Zhao, Zenan Huang, Yuanyuan Wang
  - **institution:** Ant Group, Xiamen University, Beijing Normal University, Zhejiang University
  - **link:** https://arxiv.org/pdf/2512.21849
  - **code:** https://github.com/inclusionAI/HeartBench
  - **contributions:** 1. Introduces HeartBench, a novel benchmark framework for evaluating the integrated emotional, cultural, and ethical dimensions (anthropomorphic intelligence) of Chinese LLMs. 2. Proposes a theory-driven taxonomy and a case-specific, rubric-based "reasoning-before-scoring" evaluation protocol to translate abstract human-like traits into measurable criteria. 3. Provides an analysis revealing a significant performance gap in current LLMs, especially in scenarios with subtle emotional subtexts and complex ethical trade-offs, establishing a standardized metric and a blueprint for creating human-aligned training data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dc9f1570e111d07840de8240e6e5f545f05ae646e05a5121a0a6c4037e3637a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the gap in evaluating the social and emotional intelligence (anthropomorphic intelligence) of LLMs, particularly in the Chinese context. It proposes HeartBench, a benchmark framework grounded in psychological counseling scenarios, which uses a rubric-based evaluation method. The assessment of 13 LLMs shows a substantial performance ceiling, with even top models achieving only 60% of the expert ideal, highlighting significant decay in handling complex emotional and ethical nuances.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[LLMs缺乏拟人化智能 / LLMs lack anthropomorphic intelligence]
        B --> B2[中文语境缺乏评估框架 / Lack of evaluation frameworks in Chinese context]
        C --> C1[基于心理咨询场景的基准 / Benchmark based on psychological counseling scenarios]
        C --> C2[理论驱动的分类法 / Theory-driven taxonomy]
        C --> C3[基于量规的推理评分法 / Rubric-based reasoning-before-scoring]
        D --> D1[模型性能存在上限 / Performance ceiling in models]
        D --> D2[复杂场景表现显著下降 / Significant decay in complex scenarios]
    ```

- **[arXiv251229] A Comedy of Estimators: On KL Regularization in RL Training of LLMs**
  - **tags:** [ai], [reinforcement learning], [KL divergence, policy gradient, on-policy sampling, off-policy training, gradient bias]
  - **authors:** Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, Nikolay Malkin, Moksh Jain, Siddarth Venkatraman, Aaron Courville
  - **institution:** Mila – Quebec AI Institute, Université de Montréal, McGill University, LLNL, University of Edinburgh, CIFAR
  - **link:** https://arxiv.org/pdf/2512.21852
  - **contributions:** 1. Systematic analysis of KL divergence estimator configurations in RL for LLMs, revealing how design choices introduce gradient bias. 2. Empirical demonstration that estimator configurations with unbiased gradients lead to better and more stable performance on both in-domain and out-of-domain tasks. 3. Investigation showing KL regularization can stabilize off-policy RL training in asynchronous setups.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the use of various estimators for the KL divergence regularization term in RL fine-tuning of LLMs, finding that common practices introduce biased gradients. Through experiments on models like Qwen2.5-7B, the study shows that using estimator configurations with unbiased gradients improves training stability and downstream task performance. The work also finds that KL regularization helps stabilize off-policy RL training.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Comedy of Estimators: On KL Regularization in RL Training of LLMs<br>论文标题"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>KL正则化估计器配置缺乏系统研究，梯度存在偏差"] --> P1["实践问题/Practical Issue<br>广泛使用但实现与目标不一致"]
        Problem --> P2["理论问题/Theoretical Issue<br>梯度偏差影响训练稳定性"]
        Method["主要方法/Method<br>分析梯度偏差并进行实证验证"] --> M1["分析/Analysis<br>研究多种估计器配置的梯度"]
        Method --> M2["实验/Experiments<br>RL微调多个LLM并评估性能"]
        Results["关键结果/Results<br>无偏梯度配置带来更好性能"] --> R1["在线策略/On-Policy<br>无偏梯度配置提升稳定性和性能"]
        Results --> R2["离线策略/Off-Policy<br>KL正则化有助于稳定异步训练"]
    ```

- **[arXiv251229] Balancing Accuracy and Efficiency: CNN Fusion Models for Diabetic Retinopathy Screening**
  - **tags:** [cv], [medical image classification], [feature-level fusion, convolutional neural networks, diabetic retinopathy screening, EfficientNet, DenseNet]
  - **authors:** Md Rafid Islam, Rafsan Jany, Akib Ahmed, Mohammad Ashrafuzzaman Khan
  - **institution:** North South University, Korea Institute of Oriental Medicine, American International University–Bangladesh
  - **link:** https://arxiv.org/pdf/2512.21861
  - **contributions:** 1. Proposes and evaluates feature-level fusion of complementary CNN backbones (ResNet50, EfficientNet-B0, DenseNet121) for binary diabetic retinopathy screening. 2. Demonstrates that fusion models consistently outperform single backbones in accuracy and generalization across a large, heterogeneous dataset pooled from five public sources. 3. Provides a practical analysis of the accuracy-efficiency trade-off, identifying the EfficientNet-B0 + DenseNet121 fusion as offering the best balance between performance and computational latency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d879fd7c14baee1110e20d8ebdaec476df8f8819b2fc9a74154be1d0a91d7963_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates feature-level fusion of CNN models to improve binary diabetic retinopathy screening. It finds that fusing EfficientNet-B0 and DenseNet121 achieves the best accuracy (82.89%) with a favorable balance of performance and inference speed, demonstrating that lightweight fusion enhances generalization across diverse datasets for scalable screening.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Balancing Accuracy and Efficiency: CNN Fusion Models for Diabetic Retinopathy Screening] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Large-scale DR screening is constrained by limited specialists and variable image quality.]
        C[主要方法/Method<br>Feature-level fusion of complementary CNN backbones (e.g., EfficientNet, DenseNet) on pooled fundus images.]
        D[关键结果/Results<br>Fusion outperforms single models. Eff+Den fusion offers best accuracy-latency balance.]
    ```

- **[arXiv251229] Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?**
  - **tags:** [mlsys], [multi-modal inference], [copyright compliance, vision-language models, tool-augmented defense, benchmark dataset, multimodal query]
  - **authors:** Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji
  - **institution:** Zhejiang University, University of California, Los Angeles, Palo Alto Networks
  - **link:** https://arxiv.org/pdf/2512.21871
  - **code:** https://github.com/bluedream02/CopyGuard
  - **contributions:** 1. Introduced a large-scale benchmark dataset of 50,000 multimodal query-content pairs to evaluate copyright compliance in LVLMs. 2. Conducted a comprehensive evaluation revealing significant deficiencies in state-of-the-art LVLMs' ability to recognize and respect copyrighted content. 3. Proposed a novel tool-augmented defense framework to reduce copyright infringement risks in LVLM inference.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp
  - **Simple LLM Summary:** This paper evaluates how large vision-language models (LVLMs) handle copyrighted visual content and finds they often fail to comply with copyright regulations. To address this, the authors propose a tool-augmented defense framework for copyright compliance. The work highlights the need for developing copyright-aware LVLMs to ensure responsible use.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?"]
        Root --> Problem["核心问题/Problem: LVLMs may infringe copyright when processing visual inputs"]
        Root --> Method["主要方法/Method: Benchmark dataset & Tool-augmented defense framework"]
        Root --> Results["关键结果/Results: Current LVLMs are deficient; Proposed framework reduces risk"]
    ```

- **[arXiv251229] Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation**
  - **tags:** [sec], [Privacy-preserving machine learning], [dataset distillation, random forest, synthetic data generation, explainable AI, membership-inference attack]
  - **authors:** Yiming Qian, Thorsten Neumann, Xueyining Huang, David Hardoon, Fei Gao, Yong Liu, Siow Mong Rick Goh
  - **institution:** Institute of High Performance Computing (A*STAR), Standard Chartered Bank, Xi’an Jiaotong–Liverpool University
  - **link:** https://arxiv.org/pdf/2512.21866
  - **contributions:** 1. Proposes a privacy-preserving dataset distillation framework that converts a trained random forest into transparent rule regions and generates synthetic data by uniform sampling within these regions, creating a compact, auditable surrogate dataset. 2. Enables explainable AI by providing both global pattern summaries (e.g., support, lift) from aggregated rules and local, human-readable rationales with calibrated uncertainty for individual cases based on tree-vote disagreement. 3. Demonstrates strong utility-privacy trade-offs, showing the distilled data maintains competitive model performance (e.g., precision, F1) with significant data reduction (85-93%), improves cross-institution learning, and resists membership-inference attacks (AUC ~0.5), indicating low memorization risk.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6994d363f1e76d7cc78ab02d48685c11199b353aab61b3eb5297064b1df9b722_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a dataset distillation method for financial fraud detection that converts a random forest model into interpretable rule regions to generate synthetic data, preserving privacy and model utility. The approach produces a compact, explainable dataset that supports collaborative learning across institutions while resisting privacy attacks. Experiments show it reduces data volume by over 85% with minimal performance loss and enhances cross-cluster fraud detection.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("需要隐私保护的协作式欺诈检测/Need for privacy-preserving collaborative fraud detection")
        Problem --> P2("模型需要可解释性/Model needs explainability")
        Method --> M1("将随机森林转换为规则区域/Convert random forest to rule regions")
        Method --> M2("在区域内均匀采样生成合成数据/Uniformly sample within regions to generate synthetic data")
        Results --> R1("数据量减少85-93%/Data volume reduced by 85-93%")
        Results --> R2("保持竞争性性能/Maintains competitive performance")
        Results --> R3("抵抗成员推理攻击/Resists membership-inference attacks")
    ```

- **[arXiv251229] MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting**
  - **tags:** [mlsys], [agent system], [multi-agent framework, bias mitigation, financial forecasting, LLM integration, modular design]
  - **authors:** Marc S. Montalvo, Hamed Yaghoobian
  - **institution:** Rochester Institute of Technology, Muhlenberg College
  - **link:** https://arxiv.org/pdf/2512.21878
  - **contributions:** 1. Introduces MASFIN, a modular multi-agent framework that integrates LLMs with structured financial metrics and unstructured news for decomposed financial reasoning. 2. Embeds explicit bias-mitigation protocols (e.g., against survivorship and hindsight bias) to enhance transparency and robustness. 3. Demonstrates practical effectiveness through an eight-week evaluation showing outperformance of major market benchmarks, highlighting the promise of bias-aware generative AI in finance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/351cdc3ccfe2b2d987cf53c8380e153fe4b93de0def6253cbc7b2feb4af093fe_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces MASFIN, a multi-agent system that combines LLMs with financial data and news to perform decomposed reasoning and forecasting while mitigating biases. In an eight-week evaluation, it achieved a 7.33% cumulative return, outperforming benchmarks like the S&P 500 in most weeks, though with higher volatility. The results show the potential of modular, bias-aware AI frameworks for transparent and reproducible quantitative finance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统量化方法易受生存偏差影响/Traditional quantitative methods vulnerable to survivorship bias]
        B --> B2[AI方法在信号集成和可复现性上存在挑战/AI approaches struggle with signal integration and reproducibility]
        C --> C1[模块化多智能体框架/Modular multi-agent framework]
        C --> C2[集成LLM与结构化指标和非结构化新闻/Integrates LLMs with structured metrics and unstructured news]
        C --> C3[嵌入偏差缓解协议/Embeds bias-mitigation protocols]
        D --> D1[8周累计回报7.33%/7.33% cumulative return over eight weeks]
        D --> D2[在6/8周中超越基准/Outperformed benchmarks in six of eight weeks]
        D --> D3[波动性较高/Higher volatility]
    ```

- **[arXiv251229] CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics**
  - **tags:** [nlp], [text-to-sql], [benchmark, multilingual, domain-specific, large language models, sports analytics]
  - **authors:** Vaibhav Devraj, Dhruv Kumar, Jagat Sesh Challa
  - **institution:** Birla Institute of Technology and Science (BITS), Pilani
  - **link:** https://arxiv.org/pdf/2512.21877
  - **contributions:** 1. Introduces CricBench, a novel benchmark for evaluating LLMs on Text-to-SQL tasks in the specialized domain of cricket analytics. 2. Establishes a multilingual framework, providing a "Gold Standard" dataset in both English and Hindi, with extensibility to other languages. 3. Demonstrates a significant performance gap for LLMs between general and specialized domains and challenges the assumption of English as the optimal prompt language for such tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd335127a490c2b4b59330fd1867a57551c792f1b695f15e48789a3992b7c05a_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces CricBench, a multilingual benchmark for evaluating Large Language Models on Text-to-SQL tasks in the specialized domain of cricket analytics. The benchmark features a manually curated dataset in English and Hindi and is used to evaluate six state-of-the-art models. The results show that high performance on general benchmarks does not transfer well to this specialized domain, and surprisingly, code-mixed Hindi queries can perform as well as or better than English ones.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLMs在专业领域Text-to-SQL能力未充分探索/LLMs' Text-to-SQL capability in specialized domains is under-explored]
        B --> B2[现有基准缺乏多语言和体育分析特性/Existing benchmarks lack multilingual and sports analytics features]
        C --> C1[构建板球领域专业多语言基准/Build a specialized multilingual benchmark for cricket]
        C --> C2[与专家合作创建"黄金标准"查询/Collaborate with experts to create "Gold Standard" queries]
        C --> C3[评估六个最先进的LLMs/Evaluate six state-of-the-art LLMs]
        D --> D1[专业领域性能显著下降/Significant performance drop in specialized domain]
        D --> D2[DeepSeek R1表现最佳/DeepSeek R1 achieves SOTA]
        D --> D3[印地语查询准确率可比或更高/Hindi queries yield parity or higher accuracy]
    ```

- **[arXiv251229] Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models**
  - **tags:** [mlsys], [llm inference], [distributed inference, block placement, request routing, performance modeling, resource allocation]
  - **authors:** Tingyang Sun, Ting He, Bo Ji, Parimal Parag
  - **institution:** Pennsylvania State University, Virginia Tech, Indian Institute of Science
  - **link:** https://arxiv.org/pdf/2512.21884
  - **contributions:** 1. Developed experimentally validated performance models for distributed LLM inference under given block placement and request routing decisions. 2. Formulated the offline optimization problem as a MILP, proved its NP-hardness, and designed a polynomial-complexity algorithm with performance guarantees. 3. Adapted the offline algorithm for the online setting with the same performance guarantee under bounded load.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the resource allocation problem for geographically-distributed LLM inference, focusing on optimizing block placement and request routing. It proposes performance models, offline and online algorithms with theoretical guarantees, and a lightweight CPU-only simulator. The solution significantly reduces inference time compared to the state-of-the-art in diverse distributed settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 分布式LLM推理的资源分配优化/Optimizing resource allocation for distributed LLM inference]
        C[主要方法/Method: 性能建模与优化算法/Performance modeling and optimization algorithms]
        D[关键结果/Results: 显著降低推理时间/Substantially reduces inference time]
    ```

- **[arXiv251229] Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space**
  - **tags:** [cv], [visual navigation], [world model, future frame projection, 4-dof uav, long-horizon visual generation, aerial navigation]
  - **authors:** Weichen Zhang, Peizhi Tang, Xin Zeng, Fanhang Man, Shiquan Yu, Zichao Dai, Baining Zhao, Hongjin Chen, Yu Shang, Wei Wu, Chen Gao, Xinlei Chen, Xin Wang, Yong Li, Wenwu Zhu
  - **institution:** Tsinghua University
  - **link:** https://arxiv.org/pdf/2512.21887
  - **contributions:** 1. Proposes ANWM, an aerial navigation world model for predicting future visual observations to incorporate high-level semantics into UAV path planning. 2. Introduces a physics-inspired Future Frame Projection (FFP) module to provide coarse geometric priors and mitigate uncertainty in long-distance visual generation. 3. Demonstrates superior performance in long-distance visual forecasting and improves UAV navigation success rates in large-scale 3D environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02f69e3df37002aba4354016667950073739b574c3c8044ad15f65d9721e62db_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes ANWM, an aerial navigation world model that predicts future visual observations for UAVs using a novel Future Frame Projection module. It addresses the challenges of complex 4-DoF action spaces and long-horizon visual generation. The model outperforms existing methods in visual forecasting and enhances navigation success in large-scale environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[UAV导航缺乏高层语义规划能力/UAV navigation lacks high-level semantic planning]
        B --> B2[现有模型难以处理复杂动作空间与长距离视觉生成/Existing models struggle with complex action space & long-horizon visual generation]
        C --> C1[提出ANWM世界模型/Propose ANWM world model]
        C --> C2[引入未来帧投影模块/Introduce Future Frame Projection module]
        D --> D1[长距离视觉预测性能显著提升/Significantly outperforms in long-distance visual forecasting]
        D --> D2[提高大规模环境导航成功率/Improves UAV navigation success rates in large-scale environments]
    ```

- **[arXiv251229] Flexible Multitask Learning with Factorized Diffusion Policy**
  - **tags:** [mlsys], [diffusion models], [diffusion policy, modular architecture, multitask learning, imitation learning, mixture-of-experts]
  - **authors:** Chaoqi Liu, Haonan Chen, Sigmund H. Høeg, Shaoxiong Yao, Yunzhu Li, Kris Hauser, Yilun Du
  - **institution:** University of Illinois at Urbana-Champaign, Harvard University, Norwegian University of Science and Technology, Columbia University
  - **link:** https://arxiv.org/pdf/2512.21898
  - **contributions:** 1. Introduces a novel modular diffusion policy framework (FDP) that factorizes complex action distributions into a composition of specialized diffusion models. 2. Proposes continuous score aggregation via an observation-conditioned router for stable training and clear component specialization, addressing issues in standard MoE. 3. Demonstrates that the modular structure enables flexible policy adaptation to new tasks and mitigates catastrophic forgetting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b261f496908cd892964760d9f52edb76c57a6126f2c6a9969b7e36d9d43b048e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of multitask imitation learning in robotics, where complex action distributions are difficult to model. It proposes a Factorized Diffusion Policy (FDP) that decomposes the policy into specialized diffusion components and composes them via a router. The method outperforms baselines in simulation and real-world manipulation and supports flexible adaptation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Flexible Multitask Learning with Factorized Diffusion Policy] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[机器人多任务学习/Robot Multitask Learning]
        B1 --> B2[动作分布复杂多模态/Action Distribution Highly Multimodal]
        B2 --> B3[单体模型欠拟合与不灵活/Monolithic Models Underfit & Inflexible]
        C --> C1[因子化扩散策略/Factorized Diffusion Policy (FDP)]
        C1 --> C2[模块化扩散专家/Modular Diffusion Experts]
        C2 --> C3[基于观察的路由器/Observation-Conditioned Router]
        C3 --> C4[连续分数聚合/Continuous Score Aggregation]
        D --> D1[性能超越基线/Outperforms Baselines]
        D1 --> D2[仿真与真实机器人验证/Simulation & Real-World Validation]
        D2 --> D3[支持灵活策略适应/Enables Flexible Policy Adaptation]
    ```

- **[arXiv251229] MMCTOP: A Multimodal Textualization and Mixture-of-Experts Framework for Clinical Trial Outcome Prediction**
  - **tags:** [mlsys], [multi-modal training], [multimodal fusion, sparse mixture-of-experts, schema-guided textualization, clinical trial prediction, temperature scaling]
  - **authors:** Carolina Aparício, Qi Shi, Bo Wen, Tesfaye Yadete, Qiwei Han
  - **institution:** Nova School of Business and Economics, Hogarthian Technologies, IBM Research, Cleveland Clinic, Oregon Health & Science University
  - **link:** https://arxiv.org/pdf/2512.21897
  - **contributions:** 1. A multimodal framework (MMCTOP) that integrates molecular structures, protocol metadata, eligibility narratives, and disease ontologies for clinical trial outcome prediction. 2. A novel architecture combining schema-guided textualization for data normalization and a drug-disease-conditioned sparse Mixture-of-Experts (SMoE) for context-aware, specialized multimodal fusion. 3. Demonstrates improved prediction performance (precision, F1, AUC) over baselines and incorporates operational safeguards like temperature scaling for calibrated probabilities to enhance auditability and reproducibility.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb552211ea905d5cbf8e190ead9078caf65c5d200327a02c7a6dab156a030645_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes MMCTOP, a multimodal framework for predicting clinical trial outcomes. It uses schema-guided textualization to normalize heterogeneous data and a sparse Mixture-of-Experts model for specialized fusion, achieving better performance than existing methods and providing calibrated risk estimates.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[MMCTOP: 多模态文本化与专家混合框架<br>MMCTOP: Multimodal Textualization and Mixture-of-Experts Framework] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br>多模态数据融合挑战<br>Multimodal Data Fusion Challenge] --> P1[高维生物医学信息学<br>High-Dim Biomedical Informatics]
        Method[主要方法/Method<br>多模态框架<br>Multimodal Framework] --> M1[模式感知表征学习<br>Modality-Aware Representation Learning]
        Method --> M2[架构设计/Architecture Design]
        M1 --> M1_1[领域特定编码器<br>Domain-Specific Encoders]
        M2 --> M2_1[模式感知表征学习<br>Modality-Aware Representation Learning]
        M2 --> M2_2[稀疏专家混合<br>Sparse Mixture-of-Experts (SMoE)]
        M2 --> M2_3[模式感知表征学习<br>Modality-Aware Representation Learning]
        Results[关键结果/Results<br>性能提升与校准<br>Performance & Calibration] --> R1[指标改进<br>Metric Improvements]
        Results --> R2[消融研究<br>Ablation Studies]
        Results --> R3[概率校准<br>Probability Calibration]
    ```

- **[arXiv251229] SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?**
  - **tags:** [ai], [agent system], [spatial transcriptomics, AI agents, benchmark, deterministic grader, harness design]
  - **authors:** Kenny Workman, Zhen Yang, Harihara Muralidharan, Hannah Le
  - **institution:** LatchBio
  - **link:** https://arxiv.org/pdf/2512.21907
  - **contributions:** 1. Introduces SpatialBench, a benchmark of 146 verifiable problems derived from real-world spatial biology analysis workflows, covering five technologies and seven task categories. 2. Provides a deterministic grader for each problem to evaluate the recovery of key biological results from messy spatial datasets. 3. Demonstrates through benchmark data that frontier AI agents have low accuracy (20-38%) on these tasks and reveals the significant impact of harness design (tools, prompts, control flow, execution environment) on performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3912de9f7e0f0d2acbf8bcd709b023f2ed3b9ccd56886885ca3f8e9e9e81880_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces SpatialBench, a benchmark to evaluate whether AI agents can analyze messy, real-world spatial biology data. It tests frontier models on 146 practical problems and finds low accuracy, highlighting that performance heavily depends on the agent's harness design. The benchmark serves as a tool to measure and diagnose agent capabilities for faithful and reproducible data analysis.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[AI代理能否从混乱的真实空间数据中提取生物学见解?/Can AI agents extract biological insight from messy, real-world spatial datasets?]
        C --> C1[引入包含146个可验证问题的基准SpatialBench/Introduce SpatialBench benchmark with 146 verifiable problems]
        C --> C2[提供确定性评分器评估关键生物学结果恢复/Provide deterministic grader to evaluate recovery of key biological result]
        D --> D1[基础模型准确率低 (20-38%)/Base model accuracy remains low (20-38%)]
        D --> D2[工具链设计对性能有重大影响/Harness design has large empirical effect on performance]
    ```

- **[arXiv251229] Semiparametric Preference Optimization: Your Language Model is Secretly a Single-Index Model**
  - **tags:** [ai], [reinforcement learning from human feedback (rlhf)], [preference optimization, single-index model, semiparametric, link function, policy learning]
  - **authors:** Nathan Kallus
  - **institution:** Netflix, Cornell University
  - **link:** https://arxiv.org/pdf/2512.21917
  - **contributions:** 1. Formulates policy alignment as a semiparametric single-index model problem, relaxing the need for a known link function between preferences and rewards. 2. Develops novel policy learners based on profiling, orthogonalizing, and link-agnostic ranking objectives, providing theoretical error bounds. 3. Proposes practical first-order optimization implementations that are robust to unknown preference noise and scale, enabling direct policy optimization without explicit reward fitting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/378875cc0ef0eb142c184d960e479724ea3df83c84cf81e185efea5469a4387e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of bias in aligning language models when the assumed link function between human preferences and latent rewards is misspecified. It proposes a semiparametric framework that treats the link function as unknown, develops several robust policy learning algorithms, and provides theoretical guarantees. The main conclusion is that this approach enables more reliable policy alignment without needing to correctly specify the preference noise distribution.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Semiparametric Preference Optimization<br>你的语言模型是一个单指标模型"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["核心问题/Problem<br>已知链接函数错误导致策略偏差<br>Misspecified link function causes policy misalignment"]
        Method["主要方法/Method<br>将链接函数视为未知的半参数单指标模型<br>Treat link as unknown semiparametric single-index model"]
        Results["关键结果/Results<br>开发鲁棒的策略学习器并提供理论保证<br>Develop robust policy learners with theoretical guarantees"]
    ```

- **[arXiv251229] Unsupervised Anomaly Detection in Brain MRI via Disentangled Anatomy Learning**
  - **tags:** [cv], [medical image analysis], [unsupervised anomaly detection, disentangled representation, pseudo-healthy image reconstruction]
  - **authors:** Tao Yang, Xiuying Wang, Hao Liu, Guanzhong Gong, Lian-Ming Wu, Yu-Ping Wang, Lisheng Wang
  - **institution:** Shanghai Jiao Tong University
  - **link:** https://arxiv.org/pdf/2512.21924
  - **contributions:** 1. Proposed a disentangled representation module to decouple brain MRI into imaging-invariant anatomical information and imaging-specific information, improving model generalizability across multi-modality and multi-center data. 2. Designed an edge-to-image restoration module that reconstructs high-quality pseudo-healthy images from edge information, suppressing the propagation of abnormal residuals. 3. Introduced brain anatomical priors and a differentiable one-hot encoding operator to constrain and stabilize the disentanglement learning process.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/785ff0154b41353c2fdfb9a61f66c2f97de1b49c0e9dbba451d335e3a8460e71_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of generalizability and performance in unsupervised anomaly detection for brain MRI. It proposes a new framework that disentangles anatomical from imaging information and reconstructs pseudo-healthy images from edges, achieving state-of-the-art results on multi-center datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Unsupervised Anomaly Detection in Brain MRI via Disentangled Anatomy Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[泛化性差与异常残留/Generalizability & Residuals]
        C --> C1[解耦表示模块/Disentangled Representation Module]
        C --> C2[边缘到图像恢复模块/Edge-to-Image Restoration Module]
        D --> D1[性能超越17种SOTA方法/Outperforms 17 SOTA Methods]
    ```

- **[arXiv251229] LVLM-Aided Alignment of Task-Specific Vision Models**
  - **tags:** [cv], [model alignment and interpretability], [LVLM-VA, spurious correlations, explainable AI (XAI), vision-language model, human-in-the-loop]
  - **authors:** Alexander Koebler, Lukas Kuhn, Ingo Thon, Florian Buettner
  - **institution:** Goethe University Frankfurt, Siemens AG, German Cancer Research Center (DKFZ)
  - **link:** https://arxiv.org/pdf/2512.21985
  - **contributions:** 1. Introduces LVLM-Aided Visual Alignment (LVLM-VA), a novel method for aligning small task-specific vision models with human domain knowledge using a Large Vision Language Model (LVLM). 2. Proposes a bidirectional interface that translates model behavior into natural language and maps human class-level specifications to image-level critiques, enabling efficient expert-model interaction. 3. Demonstrates that the method effectively reduces the model's dependence on spurious features and group-specific biases without requiring fine-grained, instance-level feedback.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7c85ee676094853ba26d7711ac1d50d0ab994498bc2f91f2aaab4f1104d3222_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of small task-specific vision models relying on spurious correlations, which leads to brittle real-world performance. The authors propose LVLM-Aided Visual Alignment (LVLM-VA), a method that uses a Large Vision Language Model to create a bidirectional interface between human domain knowledge and the model, translating explanations and critiques. The method is shown to significantly improve model alignment with human specifications and reduce dependence on spurious features across synthetic and real-world datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LVLM-Aided Alignment of Task-Specific Vision Models] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[小规模任务专用视觉模型依赖虚假相关性/Small task-specific vision models rely on spurious correlations]
        B --> B2[导致部署时行为脆弱/Leads to brittle behavior when deployed]
        C --> C1[利用LVLM进行视觉对齐/Leverage LVLM for visual alignment]
        C --> C2[双向接口: 行为转语言, 规范转评估/Bidirectional interface: behavior to language, specs to critiques]
        D --> D1[模型行为与人类规范更好对齐/Better alignment of model behavior with human specifications]
        D --> D2[减少对虚假特征和偏见的依赖/Reduced dependence on spurious features and biases]
    ```

- **[arXiv251229] LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration**
  - **tags:** [cv], [vision-and-language navigation], [spatiotemporal context modeling, slot-based compression, prompt-guided multimodal integration]
  - **authors:** Wen Jiang, Li Wang, Kangyao Huang, Wei Fan, Jinyuan Liu, Shaoyu Liu, Hongwei Duan, Bin Xu, Xiangyang Ji
  - **institution:** Beijing Institute of Technology, Tsinghua University, Dalian University of Technology, Xidian University
  - **link:** https://arxiv.org/pdf/2512.22010
  - **contributions:** 1. A slot-based historical image compression module to distill multi-view historical observations into fixed-length contextual representations. 2. A spatiotemporal trajectory encoding module to capture the temporal dynamics and spatial structure of UAV trajectories. 3. A prompt-guided multimodal integration module to fuse spatiotemporal context with current observations for robust waypoint prediction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c00484796a9df425f1884ea8ae22314b0592466ebe305303cf7f1f0c467b528_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes LongFly, a framework for long-horizon UAV vision-and-language navigation that addresses the challenge of modeling spatiotemporal context. The method integrates a history-aware modeling strategy with modules for compressing past observations, encoding trajectories, and fusing multimodal information. Experimental results show it outperforms state-of-the-art baselines in navigation success metrics across seen and unseen environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LongFly: Long-Horizon UAV Vision-and-Language Navigation] --> B[核心问题/Problem: Current UAV VLN methods struggle with long-horizon spatiotemporal context, leading to inaccurate alignment and unstable planning.]
        A --> C[主要方法/Method: History-aware spatiotemporal modeling with slot-based image compression, trajectory encoding, and prompt-guided multimodal integration.]
        A --> D[关键结果/Results: Outperforms SOTA baselines by 7.89% in success rate and 6.33% in SPL.]
    ```

- **[arXiv251229] From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation**
  - **tags:** [ai], [generative models for drug discovery], [hit-like molecule generation, autoregressive models, diffusion models, docking scores, multi-stage filtering]
  - **authors:** Nagham Osman, Vittorio Lembo, Giovanni Bottegoni, Laura Toni
  - **institution:** University College London, University of Urbino Carlo Bo
  - **link:** https://arxiv.org/pdf/2512.22031
  - **contributions:** 1. Framing hit-like molecule generation as a standalone task for generative models. 2. Proposing a tailored evaluation framework integrating physicochemical, structural, and bioactivity criteria. 3. Benchmarking autoregressive and diffusion models, with synthesized GSK-3β hits confirmed active in vitro.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2a0d0d188f2e13e0f8561de5950d5637586c871a0ee36935ebfbd5bb2bad540_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether generative models can replace the hit identification step in drug discovery. It proposes a multi-stage evaluation framework and benchmarks autoregressive and diffusion models, showing they can generate valid, diverse, and biologically relevant compounds, with some synthesized hits confirmed active in vitro.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("Hit identification is resource-intensive/命中识别资源密集")
        Method --> M1("Propose tailored evaluation framework/提出定制评估框架")
        Method --> M2("Benchmark autoregressive & diffusion models/基准测试自回归和扩散模型")
        Results --> R1("Models generate valid, diverse, bioactive compounds/模型生成有效、多样、有生物活性的化合物")
        Results --> R2("Selected hits synthesized & confirmed active/选定命中物被合成并确认有效")
    ```

- **[arXiv251229] Meta-Learning-Based Handover Management in NextG O-RAN**
  - **tags:** [sys], [communication & networking], [Conditional Handovers, O-RAN, Meta-Learning, Mobility Management, xApp]
  - **authors:** Michail Kalntis, George Iosifidis, José Suárez-Varela, Andra Lutu, Fernando A. Kuipers
  - **institution:** Delft University of Technology, Telefónica Research
  - **link:** https://arxiv.org/pdf/2512.22022
  - **contributions:** 1. Introduces CONTRA, the first framework to jointly optimize Traditional and Conditional Handovers within the O-RAN architecture. 2. Proposes a practical meta-learning algorithm for adaptive, on-the-fly handover type selection, guaranteeing universal no-regret performance. 3. Provides and analyzes unique, countrywide mobility management datasets from a top-tier mobile network operator, offering fresh insights into handover trade-offs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of traditional and conditional handovers in mobile networks by proposing CONTRA, a meta-learning-based framework for O-RAN that dynamically selects and optimizes handover types. It is designed as a near-real-time xApp and is evaluated using real-world datasets. The results show that CONTRA improves user throughput and reduces switching costs, outperforming standard and RL-based baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Meta-Learning-Based Handover Management in NextG O-RAN] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统切换延迟与失败/Traditional HO delays & failures]
        B --> B2[切换类型间的权衡/Trade-offs between HO types]
        C --> C1[CONTRA框架: 联合优化THO与CHO/CONTRA: Jointly optimizes THOs & CHOs]
        C --> C2[元学习算法动态选择/Meta-learning for dynamic selection]
        C --> C3[O-RAN xApp部署/O-RAN xApp deployment]
        D --> D1[提升用户吞吐量/Improves user throughput]
        D --> D2[降低切换成本/Reduces HO switching costs]
        D --> D3[优于3GPP与RL基线/Outperforms 3GPP & RL baselines]
    ```

- **[arXiv251229] LibContinual: A Comprehensive Library towards Realistic Continual Learning**
  - **tags:** [mlsys], [others], [catastrophic forgetting, stability-plasticity dilemma, modular architecture, memory budget, online continual learning]
  - **authors:** Wenbin Li, Shangge Liu, Borui Kang, Yiyang Chen, KaXuan Lew, Yang Chen, Yinghuan Shi, Lei Wang, Yang Gao, Jiebo Luo
  - **institution:** Nanjing University, University of Wollongong, University of Rochester
  - **link:** https://arxiv.org/pdf/2512.22029
  - **code:** https://github.com/RL-VIG/LibContinual
  - **contributions:** 1. Proposed LibContinual, a unified, modular, and reproducible library for Continual Learning (CL) that integrates 19 representative algorithms across five methodological categories. 2. Systematically identified and investigated three unrealistic implicit assumptions (offline data accessibility, unregulated memory, intra-task semantic homogeneity) prevalent in mainstream CL evaluation. 3. Conducted a comprehensive analysis under stricter, more realistic settings (strict online CL, unified memory budget, category-randomized tasks), revealing significant performance drops in many existing methods and highlighting the need for resource-aware and semantically robust CL strategies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a733a967f663a216bbd5fb0cee657ed8bb70a4e6f0205d669f983cbf9bb6fd_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces LibContinual, a comprehensive library designed to unify and standardize research in Continual Learning (CL). By using this framework to evaluate existing methods under more realistic constraints, the study shows that many current CL algorithms suffer significant performance drops, underscoring the gap between common evaluation practices and real-world applicability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LibContinual: A Comprehensive Library towards Realistic Continual Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[研究碎片化，缺乏统一框架/Fragmented research landscape, lack of unified framework]
        B --> B2[评估存在不现实的隐含假设/Unrealistic implicit assumptions in evaluation]
        C --> C1[构建模块化、可复现的库/Build a modular, reproducible library]
        C --> C2[集成19种代表性算法/Integrate 19 representative algorithms]
        C --> C3[在更现实的设定下系统评估/Systematically evaluate under more realistic settings]
        D --> D1[现有方法在现实约束下性能显著下降/Existing methods show significant performance drop under realistic constraints]
        D --> D2[强调资源感知和语义鲁棒策略的必要性/Highlight the necessity of resource-aware and semantically robust strategies]
    ```

- **[arXiv251229] StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars**
  - **tags:** [mlsys], [diffusion models], [autoregressive distillation, adversarial refinement, real-time streaming, reference-anchored positional re-encoding, consistency-aware discriminator]
  - **authors:** Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu
  - **institution:** Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University
  - **link:** https://arxiv.org/pdf/2512.22065
  - **code:** https://streamavatar.github.io
  - **contributions:** 1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Non-causal, high-cost diffusion models unsuitable for real-time streaming; Limited to head-and-shoulder, lacking gestures.]
        C[主要方法/Method<br>Two-stage autoregressive adaptation (distillation + refinement) with Reference Sink, RAPR, Consistency-Aware Discriminator.]
        D[关键结果/Results<br>State-of-the-art real-time, interactive full-body avatar with natural talking/listening and gestures.]
    ```

- **[arXiv251229] Unifying Learning Dynamics and Generalization in Transformers Scaling Law**
  - **tags:** [ai], [learning theory], [scaling law, learning dynamics, generalization error, transformer, stochastic gradient descent]
  - **authors:** Chiwun Yang
  - **institution:** Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.22088
  - **contributions:** 1. Formalizes the learning dynamics of transformers as an ODE system and approximates it to kernel behaviors, moving beyond toy models to analyze SGD on multi-layer transformers with arbitrary data distributions. 2. Establishes a theoretical upper bound on excess risk with a distinct phase transition: exponential decay in the optimization phase and a power-law decay of Θ(C^\{-1/6\}) in the statistical phase. 3. Derives isolated scaling laws for model size, training time, and dataset size, explaining how each variable independently governs generalization bounds.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9b067b56202cd4607e684058e78ac331373bf12bf6848ca444276e2dcafe9f9_w640_q70.webp
  - **Simple LLM Summary:** This paper provides a theoretical foundation for the empirical scaling laws of large language models. It models transformer learning dynamics as an ODE system and analyzes SGD training on realistic data. The main result is a unified theory showing a phase transition in generalization error, from exponential to power-law decay, as computational resources scale.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Unifying Learning Dynamics and Generalization in Transformers Scaling Law] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Scaling Law理论原理不清 / Poorly understood theoretical underpinnings of scaling laws]
        C --> C1[形式化学习动态为ODE系统 / Formalize learning dynamics as ODE system]
        C --> C2[近似为核行为 / Approximate to kernel behaviors]
        C --> C3[分析SGD训练真实Transformer / Analyze SGD training for real transformers]
        D --> D1[泛化误差上界与相变 / Upper bound on excess risk with phase transition]
        D --> D2[优化相:指数衰减 / Optimization phase: Exponential decay]
        D --> D3[统计相:幂律衰减 Θ(C^{-1/6}) / Statistical phase: Power-law decay Θ(C^{-1/6})]
        D --> D4[分离的规模定律 / Isolated scaling laws for model size, time, data]
    ```

- **[arXiv251229] Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis**
  - **tags:** [nlp], [benchmark construction], [Turkish NLU benchmark, semi-automated annotation, sentiment analysis dataset]
  - **authors:** Duygu Altinok
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2512.22100
  - **contributions:** 1. Introduces TrGLUE, the first comprehensive GLUE-style benchmark for Turkish Natural Language Understanding, filling a critical gap. 2. Presents SentiTurca, a specialized benchmark for Turkish sentiment analysis. 3. Provides a scalable, reproducible semi-automated dataset creation pipeline combining LLM annotation, cross-model checks, and human validation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aae4aef01bf4bd7a32414041836c4d9d7383c50872f47bdb0dee4d45af35adb_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of a comprehensive benchmark for evaluating Turkish language understanding by introducing TrGLUE and SentiTurca. The benchmarks are created using a semi-automated pipeline with LLM annotation and human validation to ensure quality and linguistic naturalness. The work establishes a robust evaluation framework and provides resources to empower Turkish NLP research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Introducing TrGLUE and SentiTurca] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[缺乏土耳其语综合基准/Lack of Turkish NLU Benchmark]
        C --> C1[半自动标注流程/Semi-automated Pipeline]
        C1 --> C2[LLM标注 + 交叉验证 + 人工校验/LLM Annotation + Cross-check + Human Validation]
        D --> D1[发布TrGLUE & SentiTurca/Release TrGLUE & SentiTurca]
        D --> D2[提供代码与资源/Provide Code & Resources]
    ```

- **[arXiv251229] A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting**
  - **tags:** [mlsys], [agent system], [multi-agent pipeline, automated data analysis, insight generation, report synthesis, visual analytics]
  - **authors:** Shuyu Gan, Renxiang Wang, James Mooney, Dongyeop Kang
  - **institution:** University of Minnesota
  - **link:** https://arxiv.org/pdf/2512.22101
  - **contributions:** 1. A Data Analyzer agent that orchestrates data profiling, generates diverse visualizations, filters low-quality charts, and automatically scores candidate insights for depth, correctness, and actionability. 2. A Presenter agent that sequences topics, composes chart-grounded narratives from top insights, writes transitions, and revises the document to produce a coherent, publication-ready report. 3. An end-to-end Analyzer-to-Presenter (A2P) pipeline that operationalizes co-analysis by coupling quality-assured analysis with narrative synthesis, improving the real-world usefulness of automated data analysis.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92651ded84480402816f8db1df902e28dd62cce1b0958cece60e0f518bdd7e1c_w640_q70.webp
  - **Simple LLM Summary:** This paper presents A2P-Vis, a two-part multi-agent pipeline designed to automate the generation of data visualization reports. The system uses a Data Analyzer to create and vet visual insights and a Presenter to assemble them into a coherent narrative. The authors claim this end-to-end approach improves the practical utility of automated data analysis for practitioners.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A2P-Vis] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[自动化数据科学流程的瓶颈/Gaps in automating data science]
        B1 --> B2[生成有洞察力的可视化/Generating insightful visual evidence]
        B1 --> B3[组装成专业报告/Assembling coherent professional report]
        C --> C1[两部分多智能体管道/Two-part multi-agent pipeline]
        C1 --> C2[数据分析器/Data Analyzer]
        C2 --> C3[生成并评估图表与洞察/Generates & evaluates charts & insights]
        C1 --> C4[报告呈现器/Presenter]
        C4 --> C5[编排主题并撰写叙述/Orders topics & composes narrative]
        D --> D1[端到端协同分析/End-to-end co-analysis]
        D1 --> D2[提高自动化数据分析的实用性/Improves usefulness of automated analysis]
    ```

- **[arXiv251229] Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [neural network pruning, game theory, equilibrium, non-cooperative game, sparsification]
  - **authors:** Zubair Shah, Noaman Khan
  - **institution:** Hamad Bin Khalifa University
  - **link:** https://arxiv.org/pdf/2512.22106
  - **contributions:** 1. Proposes a novel game-theoretic perspective on neural network pruning, modeling parameter groups as players in a non-cooperative game where sparsity emerges as an equilibrium outcome. 2. Provides a theoretical analysis showing that dominated players (redundant parameters) collapse to zero participation under mild conditions, offering a principled explanation for pruning. 3. Derives a simple equilibrium-driven pruning algorithm that jointly updates network parameters and participation variables without relying on explicit, heuristic importance scores.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4fd762b6b064bb7810151beeb40f55c93bfc05054b2d4a98cd925aed8bea43b2_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a novel game-theoretic framework for neural network pruning, where sparsity emerges naturally from the equilibrium of a non-cooperative game among model components. The method jointly updates network parameters and participation variables without external importance scores. Experiments show it achieves competitive sparsity-accuracy trade-offs with a more interpretable, theory-grounded foundation.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks") --> Problem("核心问题/Problem: Sparsity is imposed externally via heuristics, lacking a principled model of parameter interaction.")
        Root --> Method("主要方法/Method: Model pruning as a non-cooperative game among parameters; sparsity emerges at equilibrium.")
        Root --> Results("关键结果/Results: Competitive sparsity-accuracy trade-offs with an interpretable, theory-grounded algorithm.")
    ```

- **[arXiv251229] Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications**
  - **tags:** [mlsys], [agent system], [root cause analysis, service dependency graph, program dependence graph, LLM agent, cloud incident]
  - **authors:** Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer
  - **institution:** University of Illinois at Urbana-Champaign, IBM Research
  - **link:** https://arxiv.org/pdf/2512.22113
  - **contributions:** 1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Agentic Structured Graph Traversal for Root Cause Analysis<br/>基于智能体结构化图遍历的云应用根因分析] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br/>High cost of unresolved cloud incidents; Need for effective root cause analysis]
        C[主要方法/Method<br/>PRAXIS: LLM-driven traversal over Service Dependency Graph and Program Dependence Graph]
        D[关键结果/Results<br/>3.1x higher RCA accuracy, 3.8x lower token consumption vs. ReAct baselines]
    ```

- **[arXiv251229] Atomistic Simulation Guided Convolutional Neural Networks for Thermal Modeling of Friction Stir Welding**
  - **tags:** [ai], [physics-informed machine learning], [molecular dynamics, convolutional neural network, friction stir welding, explainable AI, LAMMPS]
  - **authors:** Akshansh Mishra
  - **institution:** Politecnico di Milano, AI Fab Lab
  - **link:** https://arxiv.org/pdf/2512.21344
  - **contributions:** 1. Developed a novel method to transform atomistic simulation data (atomic positions and velocities) into physics-based 2D spatial grids for deep learning input. 2. Created and optimized a 2D CNN model to directly predict temperature evolution from spatially resolved atomistic data, achieving high accuracy (R²=0.94). 3. Used Class Activation Map analysis to provide explainability, showing the model's focus aligns with physical mechanisms (e.g., tool-material interface).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34d6f71500319f52aecac1e95e1951a537fdc504134a8ba43851f31acc2e41c6_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a method that combines molecular dynamics simulations with convolutional neural networks for thermal modeling in friction stir welding. The method transforms atomic-scale simulation data into spatial grids and uses a CNN to accurately predict temperature, with results validated against physical mechanisms. The approach demonstrates that deep learning can effectively learn from atomistic data to model complex thermomechanical processes.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Atomistic Simulation Guided CNNs for Thermal Modeling of FSW / 原子模拟引导的CNN用于搅拌摩擦焊热建模"]
        Root --> Problem["准确预测温度演化对于理解搅拌摩擦焊的热机械行为至关重要 / Accurate prediction of temperature evolution is essential for understanding thermomechanical behavior in FSW"]
        Root --> Method["使用LAMMPS进行分子动力学模拟，将原子数据转换为物理二维空间网格，并开发2D CNN进行预测 / Use LAMMPS for MD simulations, transform atomic data into physics-based 2D spatial grids, and develop a 2D CNN for prediction"]
        Root --> Results["模型预测精度高（R²=0.94），CAM分析表明模型关注与剧烈变形和生热相关的区域 / Model achieves high predictive accuracy (R²=0.94), CAM analysis shows model focuses on regions associated with intense deformation and heat generation"]
    ```

- **[arXiv251229] Applications of synthetic financial data in portfolio and risk modeling**
  - **tags:** [ai], [generative models for time series], [TimeGAN, Variational Autoencoder (VAE), synthetic financial data, portfolio optimization, risk modeling]
  - **authors:** Christophe D. Hounwanou, Yae Ulrich Gaba
  - **institution:** African Institute for Mathematical Sciences (AIMS Rwanda), Sefako Makgatho Health Sciences University (SMU), AI Research and Innovation Nexus for Africa (AIRINA Labs)
  - **link:** https://arxiv.org/pdf/2512.21798
  - **contributions:** 1. Evaluated and compared the performance of TimeGAN and VAEs for generating realistic synthetic financial time series data. 2. Demonstrated that TimeGAN-generated data closely matches real data in distributional, volatility, and autocorrelation properties. 3. Showed the practical utility of synthetic data in downstream financial tasks like mean-variance portfolio optimization, yielding similar portfolio weights and risk metrics to real data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a7ecf00c1350b58057e2f03c93bf0e8845d1441745fc22505c46475eceeeb65_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the scarcity and privacy issues of real financial data by using generative models like TimeGAN and VAEs to create synthetic return series. It evaluates the synthetic data on statistical similarity and financial tasks, concluding that TimeGAN effectively captures temporal dynamics and can serve as a privacy-preserving, cost-effective substitute for real data in portfolio and risk analysis.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Applications of synthetic financial data in portfolio and risk modeling") --> Problem("核心问题/Problem: Privacy and accessibility limit financial research")
        Root --> Method("主要方法/Method: Use TimeGAN and VAEs to generate synthetic financial time series")
        Root --> Results("关键结果/Results: TimeGAN data is realistic and useful for portfolio/risk tasks")
    ```

- **[arXiv251229] Residual Prior Diffusion: A Probabilistic Framework Integrating Coarse Latent Priors with Diffusion Models**
  - **tags:** [ai], [diffusion models], [diffusion models, generative modeling, evidence lower bound, residual learning, two-stage framework]
  - **authors:** Takuro Kutsuna
  - **institution:** Toyota Central R&D Labs., Inc.
  - **link:** https://arxiv.org/pdf/2512.21593
  - **contributions:** 1. Proposes Residual Prior Diffusion (RPD), a two-stage probabilistic framework that integrates a coarse prior model with a diffusion model to capture large-scale structure and fine-scale details separately. 2. Formulates RPD with a tractable evidence lower bound, showing optimization reduces to familiar noise/velocity prediction objectives, and introduces auxiliary variables to leverage prior information and theoretically reduce prediction difficulty. 3. Demonstrates experimentally that RPD outperforms standard diffusion models on synthetic datasets with fine local structure and matches or exceeds baselines on natural image generation, maintaining performance with few inference steps.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08078ea833fb6d000def6c1e69b08b734ff7e29a1c3014bf3ec3e8b313815438_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a problem where standard diffusion models struggle to simultaneously model global structure and fine local details. It proposes Residual Prior Diffusion (RPD), a two-stage framework that first learns a coarse prior and then a diffusion model for the residual. Experiments show RPD captures fine details better than standard models and maintains strong performance with fewer inference steps.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Residual Prior Diffusion (RPD) / 残差先验扩散模型"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["单一扩散模型难以同时捕捉全局结构和局部细节 / Single diffusion model struggles with global structure and local details"]
        Method --> M1["两阶段框架: 粗粒度先验 + 残差扩散模型 / Two-stage framework: coarse prior + residual diffusion model"]
        Method --> M2["概率模型与可处理ELBO / Probabilistic model with tractable ELBO"]
        Results --> R1["在合成数据上准确捕捉细节 / Accurately captures details on synthetic data"]
        Results --> R2["自然图像生成匹配或超越基线 / Natural image generation matches or exceeds baselines"]
        Results --> R3["少步推理保持性能 / Maintains performance with few inference steps"]
    ```

- **[arXiv251229] Enabling Ultra-Fast Cardiovascular Imaging Across Heterogeneous Clinical Environments with a Generalist Foundation Model and Multimodal Database**
  - **tags:** [cv], [medical image reconstruction], [foundation model, k-space, multimodal database, zero-shot generalization, accelerated imaging]
  - **authors:** Zi Wang, Mingkai Huang, Zhang Shi, Hongjie Hu, Lan Lan, Hui Zhang, Yan Li, Xi Hu, Qing Lu, Zongming Zhu, Qiong Yao, Yuxiang Dai, Fanwen Wang, Yinzhe Wu, Jun Lyu, Qianqian Gao, Guangming Xu, Zhenxuan Zhang, Haosen Zhang, Qing Li, Guangming Wang, Tianxing He, Lizhen Lan, Siyue Li, Le Xue, Mengting Sun, Yuntong Lyu, Junpu Hu, Jiayu Zhu, Rizwan Ahmad, Zhengyu Bu, Xianling Qian, Guanke Cai, Ruiyu Cao, Weirui Cai, Chang Xu, Yuyang Ren, Feidan Yu, Siying Ma, Ziqiang Xu, Xinran Chen, Sha Hua, Daniel Kim, Yajing Zhang, Chen Ouyang, Wenjia Bai, Jing Qin, Yucheng Yang, Daniel Rueckert, He Wang, Qian Tao, Claudia Prieto, Michael Markl, Alistair Young, Lianming Wu, Shuo Wang, Chen Qin, Mengsu Zeng, Xihong Hu, Haibo Xu, Xiaobo Qu, Hao Li, Guang Yang, Chengyan Wang
  - **institution:** Imperial College London, Fudan University, Xiamen University
  - **link:** https://arxiv.org/pdf/2512.21652
  - **contributions:** 1. The curation of MMCMR-427K, the largest and most comprehensive multimodal cardiovascular magnetic resonance (CMR) k-space database. 2. The introduction of CardioMM, a generalist reconstruction foundation model that unifies semantic understanding with physics-informed data consistency for robust, accelerated imaging. 3. Demonstrating state-of-the-art performance and strong zero-shot generalization across heterogeneous clinical settings, enabling up to 24x acceleration without compromising clinical integrity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the slow scan times and environmental heterogeneity limiting clinical cardiovascular MRI. It proposes CardioMM, a generalist foundation model trained on a large multimodal k-space database (MMCMR-427K), which achieves robust, ultra-fast reconstructions across diverse scanners and protocols. The results show that CardioMM enables high acceleration (up to 24x) while preserving diagnostic quality and generalizing to unseen clinical environments.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Enabling Ultra-Fast Cardiovascular Imaging...] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[CMR扫描时间长/CMR Scan Time Long]
    B --> B2[临床环境异质性高/High Clinical Heterogeneity]
    C --> C1[构建多模态数据库MMCMR-427K/Build Multimodal DB MMCMR-427K]
    C --> C2[提出通用基础模型CardioMM/Propose Generalist Foundation Model CardioMM]
    D --> D1[实现24倍加速成像/Achieve 24x Accelerated Imaging]
    D --> D2[零样本泛化至新环境/Zero-shot Generalization to New Settings]
    D --> D3[保持诊断质量/Preserve Diagnostic Quality]
    ```
