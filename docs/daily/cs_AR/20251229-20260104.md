---
slug: /daily/csar/20251229-20260104
---
# 20251229-20260104 (cs.AR)

## 2025-12-29

- **[arXiv251229] Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide**
  - **tags:** [sec], [side-channel analysis], [RISC-V, CVA6, Correlation Power Analysis (CPA), RTL simulation, power side-channel]
  - **authors:** Behnam Farnaghinejad, Antonio Porsia, Annachiara Ruospo, Alessandro Savino, Stefano Di Carlo, Ernesto Sanchez
  - **institution:** Politecnico di Torino
  - **link:** https://arxiv.org/pdf/2512.21362
  - **contributions:** 1. Presents the first side-channel vulnerability evaluation of the CVA6 RISC-V processor core. 2. Demonstrates the application of the VeriSide RTL-level power profiling framework for efficient power trace extraction without waveform files. 3. Shows that Correlation Power Analysis (CPA) on the CVA6 during software-based AES encryption enables key recovery, highlighting the need for early-stage RTL security assessments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f1045d9314e37006547d2c94a7c4490ff95449687fd13d7c467003b4c095bac_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the power side-channel vulnerability of the CVA6 RISC-V core using the VeriSide RTL simulation framework. By applying Correlation Power Analysis (CPA) to power traces during software AES execution, the authors successfully recover the secret key. The findings demonstrate significant leakage in the CVA6 design, emphasizing the importance of pre-silicon RTL-level security evaluation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现代RISC-V处理器需要抗侧信道攻击能力 / Modern RISC-V processors require resilience to side-channel attacks]
        C --> C1[使用VeriSide框架在RTL级进行功耗分析 / Use VeriSide framework for RTL-level power analysis]
        C --> C2[对软件AES执行进行相关性功耗分析(CPA) / Perform Correlation Power Analysis (CPA) on software AES execution]
        D --> D1[CVA6设计存在显著泄漏 / CVA6 design exhibits significant leakage]
        D --> D2[成功恢复AES密钥 / Successful AES key recovery]
    ```

- **[arXiv251229] Online Learning Extreme Learning Machine with Low-Complexity Predictive Plasticity Rule and FPGA Implementation**
  - **tags:** [mlsys], [on-device ai], [predictive plasticity rule, extreme learning machine, FPGA implementation, online learning, low-complexity training]
  - **authors:** Zhenya Zang, Xingda Li, David Day Uei Li
  - **institution:** University of Strathclyde
  - **link:** https://arxiv.org/pdf/2512.21777
  - **contributions:** 1. Proposed a simplified, biologically inspired predictive local learning rule that eliminates global backpropagation and membrane integration, using sparse, binary-driven vector additions triggered only by prediction errors. 2. Integrated this rule into an Extreme Learning Machine (ELM), replacing the conventional matrix inversion, thereby reducing training complexity from O(M^3) to O(M) for M hidden nodes. 3. Demonstrated an FPGA implementation showing significant reductions in computational and memory requirements, highlighting its potential for energy-efficient online learning on low-cost edge devices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fd9efea1b6faa314e48c1a0c90ad6c7bf79112ed59bfb1db6f14146d142848_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a low-complexity online learning method by integrating a simplified predictive plasticity rule into an Extreme Learning Machine (ELM), which reduces training complexity from cubic to linear order. The approach is implemented on FPGA, showing reduced computational and memory needs while maintaining comparable accuracy. The work demonstrates strong potential for enabling efficient online learning on resource-constrained edge devices.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Online Learning ELM with Low-Complexity Predictive Plasticity Rule and FPGA Implementation<br/>在线学习ELM与低复杂度预测可塑性规则及FPGA实现"]
        Root --> Problem["Problem: High complexity of online learning for edge devices<br/>问题：面向边缘设备的在线学习复杂度高"]
        Root --> Method["Method: Simplified predictive plasticity rule + ELM<br/>方法：简化的预测可塑性规则 + ELM"]
        Root --> Results["Results: O(M) training, FPGA implementation, low resource use<br/>结果：O(M)训练，FPGA实现，低资源消耗"]
    ```

- **[arXiv251229] Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling**
  - **tags:** [mlsys], [llm inference], [SRAM, frequency scaling, energy-delay product, systolic array, memory bandwidth]
  - **authors:** Hannah Atmer, Yuan Yao, Thiemo Voigt, Stefanos Kaxiras
  - **institution:** Uppsala University
  - **link:** https://arxiv.org/pdf/2512.22066
  - **contributions:** 1. Quantified the distinct energy and performance impacts of SRAM size and operating frequency on the compute-bound prefill and memory-bound decode phases of LLM inference. 2. Demonstrated a counter-intuitive result: high compute frequency can reduce total energy by shortening execution time and reducing static energy more than the dynamic power increase. 3. Identified an optimal hardware configuration (high frequency, small SRAM buffer) that minimizes the energy-delay product, providing concrete design insights for energy-efficient accelerators.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how on-chip SRAM size and operating frequency affect the energy efficiency of LLM inference. Using a simulation methodology combining OpenRAM, LLMCompass, and ScaleSIM, it finds that a high-frequency, small-SRAM configuration optimizes the energy-delay product, as memory bandwidth caps decode phase improvements. The analysis provides architectural guidance for designing efficient LLM accelerators.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>LLM推理能耗高，Prefill与Decode阶段瓶颈不同"] --> Problem_Sub1["SRAM大小与频率如何影响能效？"]
        Problem --> Problem_Sub2["内存带宽如何限制性能？"]
        Method["主要方法/Method<br>结合OpenRAM, LLMCompass, ScaleSIM的模拟方法"] --> Method_Sub1["能耗建模/Energy Modeling"]
        Method --> Method_Sub2["延迟模拟/Latency Simulation"]
        Method --> Method_Sub3["操作强度分析/Operational Intensity"]
        Results["关键结果/Results"] --> Results_Sub1["总能耗主要由SRAM大小决定<br>大缓存增加静态能耗"]
        Results --> Results_Sub2["高频可降低总能耗<br>（减少静态能耗）"]
        Results --> Results_Sub3["最优配置：高频(1200-1400MHz) + 小缓存(32-64KB)"]
    ```
