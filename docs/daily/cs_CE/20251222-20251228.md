---
slug: /daily/csce/20251222-20251228
---
# 20251222-20251228 (cs.CE)

## 2025-12-23

- **[arXiv251223] BeamformNet: Deep Learning-Based Beamforming Method for DoA Estimation via Implicit Spatial Signal Focusing and Noise Suppression**
  - **tags:** TBD
  - **authors:** Xuyao Deng, Yong Dou, Kele Xu
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18647
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef1555ca82f95607cd915f1b1a96634737ef77b6ac6498d44b4d21b6504c6adf_w640_q70.webp
  - **Simple LLM Summary:** BeamformNet: Deep Learning-Based Beamforming Method for DoA Estimation via Implicit Spatial Signal Focusing and Noise Suppression

- **[arXiv251223] Mixed formulation and structure-preserving discretization of Cosserat rod dynamics in a port-Hamiltonian framework**
  - **tags:** TBD
  - **authors:** Philipp L. Kinon, Simon R. Eugster, Peter Betsch
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19408
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a2011f29ba413592cebb090b3281d18ea6b552fbd91b93ffc64d7c6a5c901ca5_w640_q70.webp
  - **Simple LLM Summary:** Mixed formulation and structure-preserving discretization of Cosserat rod dynamics in a port-Hamiltonian framework

- **[arXiv251223] GLUE: Generative Latent Unification of Expertise-Informed Engineering Models**
  - **tags:** TBD
  - **authors:** Tim Aebersold, Soheyl Massoudi, Mark D. Fuge
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19469
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e870c1241b521f8cd85e2b95b902b04bfcabd5e890393790f05186cc61348532_w640_q70.webp
  - **Simple LLM Summary:** GLUE: Generative Latent Unification of Expertise-Informed Engineering Models

- **[arXiv251223] The Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference**
  - **tags:** TBD
  - **authors:** Rajyasri Roy, Dibyajyoti Nayak, Somdatta Goswami
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19643
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de5e312b39c5b4c9d5e5ba414dbf1be28f3eefa665a2062af2d2753365d7ba18_w640_q70.webp
  - **Simple LLM Summary:** The Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference

## 2025-12-24

- **[arXiv251224] Solving strategies for data-driven one-dimensional elasticity exhibiting nonlinear strains**
  - **tags:** TBD
  - **authors:** Thi-Hoa Nguyen, Viljar H. Gjerde, Bruno A. Roccia, Cristian G. Gebhardt
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19912
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65257810ef400b961512b1978129e52d685013bba0c1e27517340ebe7a96dc11_w640_q70.webp
  - **Simple LLM Summary:** Solving strategies for data-driven one-dimensional elasticity exhibiting nonlinear strains

- **[arXiv251224] A hybrid global local computational framework for ship hull structural analysis using homogenized model and graph neural network**
  - **tags:** TBD
  - **authors:** Yuecheng Cai, Jasmin Jelovica
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20020
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/be3b666aee548de323be0a87ee550591589e0be67a7c02fde2748878960bbe16_w640_q70.webp
  - **Simple LLM Summary:** A hybrid global local computational framework for ship hull structural analysis using homogenized model and graph neural network

- **[arXiv251224] Replacing Gas with Low-cost, Abundant Long-duration Pumped Hydro in Electricity Systems**
  - **tags:** TBD
  - **authors:** Timothy Weber, Cheng Cheng, Harry Thawley, Kylie Catchpole, Andrew Blakers, Bin Lu, Jennifer Zhao, Anna Nadolny
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20286
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24b8dbe15cd07fc09497cd413a3dcb0e0c23cb210693206f3ebaafe554b5c6dd_w640_q70.webp
  - **Simple LLM Summary:** Replacing Gas with Low-cost, Abundant Long-duration Pumped Hydro in Electricity Systems

- **[arXiv251224] Auditing Reproducibility in Non-Targeted Analysis: 103 LC/GC--HRMS Tools Reveal Temporal Divergence Between Openness and Operability**
  - **tags:** TBD
  - **authors:** Sarah Alsubaie, Sakhaa Alsaedi, Xin Gao
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20279
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8461db004ea160aa8af9906d632218283ad8a987409958ac11bd49b4d9c79d3c_w640_q70.webp
  - **Simple LLM Summary:** Auditing Reproducibility in Non-Targeted Analysis: 103 LC/GC--HRMS Tools Reveal Temporal Divergence Between Openness and Operability

- **[arXiv251224] Expected Revenue, Risk, and Grid Impact of Bitcoin Mining: A Decision-Theoretic Perspective**
  - **tags:** TBD
  - **authors:** Yuting Cai, Ruthav Sadali, Korok Ray, Chao Tian
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20518
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01e01ab2008077c445a5d9fa28a0c1b80ac593057c988ff480aa7bca26fb0a6d_w640_q70.webp
  - **Simple LLM Summary:** Expected Revenue, Risk, and Grid Impact of Bitcoin Mining: A Decision-Theoretic Perspective

- **[arXiv251224] Structured Event Representation and Stock Return Predictability**
  - **tags:** TBD
  - **authors:** Gang Li, Dandan Qiao, Mingxuan Zheng
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19484
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9928e7838f7931e8e7744dfacb70cdd35231fd0899564217b0ae95c9f53ffb7d_w640_q70.webp
  - **Simple LLM Summary:** Structured Event Representation and Stock Return Predictability

## 2025-12-25

- **[arXiv251225] Assessing Coronary Microvascular Dysfunction using Angiography-based Data-driven Methods**
  - **tags:** [ai], [medical image analysis], [coronary microvascular dysfunction, contrast intensity profiles, epistemic uncertainty, synthetic data, encoder-MLP]
  - **authors:** Haizhou Yang, Jiyang Zhang, Brahmajee K. Nallamothu, Krishna Garikipati, C. Alberto Figueroa
  - **institution:** University of Michigan
  - **link:** https://arxiv.org/pdf/2512.20797
  - **contributions:** 1. Proposed a novel data-driven framework for inferring coronary microvascular dysfunction (CMD) indices directly from coronary angiograms, eliminating the need for invasive pressure-wire measurements. 2. Developed two specialized neural network architectures (single and dual-input encoder-MLP models) for predicting the Index of Microcirculatory Resistance (IMR) and Coronary Flow Reserve (CFR), incorporating epistemic uncertainty estimation. 3. Demonstrated the utility of contrast intensity profiles (CIPs) from angiograms as informative surrogates for coronary physiology and validated the approach using a physiologically validated multi-physics model to generate synthetic training data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/37abd396b16ae3855217c60b216a9a70f84f52ba11058c08678b498a01844e29_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a data-driven method to assess coronary microvascular dysfunction (CMD) using routine angiography, avoiding invasive procedures. The method uses synthetic data from a physics model to train neural networks that predict CMD indices from angiogram contrast profiles, with built-in uncertainty estimation. The results show high predictive accuracy and validate the use of contrast intensity profiles for real-time, image-based CMD assessment.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Assessing Coronary Microvascular Dysfunction<br/>评估冠状动脉微血管功能障碍] --> B
    A --> C
    A --> D
    B[核心问题/Problem<br/>CMD underdiagnosed, invasive measurement risks<br/>CMD诊断不足，有创测量风险]
    C[主要方法/Method<br/>Data-driven framework, synthetic data, NN with uncertainty<br/>数据驱动框架，合成数据，带不确定性的神经网络]
    D[关键结果/Results<br/>High accuracy, CIPs as surrogates, real-time potential<br/>高精度，CIP作为替代指标，实时应用潜力]
    ```

- **[arXiv251225] When Experts Speak:Sequential LLM-Bayesian Learning for Startup Success Prediction**
  - **tags:** [nlp], [text classification], [sequential Bayesian learning, expert network calls, large language models]
  - **authors:** Yidong Chai, Yanguang Liu, Xuan Tian, Jiaheng Xie, Yonghang Zhou
  - **institution:** Hefei University of Technology, New Jersey Institute of Technology, Tsinghua University, University of Delaware
  - **link:** https://arxiv.org/pdf/2512.20900
  - **contributions:** 1. Proposes a novel LLM-Bayesian model that analyzes expert network call conversations at the question-answer turn level to extract semantic and evaluative signals. 2. Introduces a sequential Bayesian architecture that dynamically updates beliefs with new expert calls and attenuates contradictory assessments, a feature absent from existing tools. 3. Demonstrates empirical superiority, outperforming state-of-the-art benchmarks in F1-score and significantly increasing portfolio-level Return on Investment, with analyses showing particular effectiveness for informationally disadvantaged startups.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49c85d6f88ddbad39540f1ec78930a2f501d4856a79a87d1ebd5471c64806aa9_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of startup evaluation under information asymmetry by developing a sequential LLM-Bayesian model that analyzes expert network call dialogues. The method extracts signals using LLMs and aggregates them in a Bayesian framework to dynamically update success probabilities. It empirically outperforms existing benchmarks in prediction accuracy and portfolio return, proving especially useful for evaluating complex, young, or less visible startups.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[When Experts Speak: Sequential LLM-Bayesian Learning for Startup Success Prediction] --> B[核心问题/Problem: Evaluating startups with information asymmetry and limited data]
    A --> C[主要方法/Method: LLM-Bayesian model analyzing expert calls sequentially]
    A --> D[关键结果/Results: Outperforms benchmarks in F1-score and ROI]
    ```

- **[arXiv251225] A Mechanistic Analysis of Transformers for Dynamical Systems**
  - **tags:** [ai], [dynamical systems modeling], [transformers, attention mechanism, dynamical systems, representational analysis, delay embedding]
  - **authors:** Gregory Duthé, Nikolaos Evangelou, Wei Liu, Ioannis G. Kevrekidis, Eleni Chatzi
  - **institution:** ETH Zürich, Johns Hopkins University, Singapore-ETH Centre
  - **link:** https://arxiv.org/pdf/2512.21113
  - **contributions:** 1. Provides a mechanistic interpretation of causal self-attention in Transformers as a linear, history-dependent recurrence from a dynamical systems perspective. 2. Demonstrates that the softmax attention's convexity constraint fundamentally limits the representation of certain linear dynamics, leading to oversmoothing. 3. Shows that for nonlinear partially observable systems, attention acts as an adaptive delay-embedding mechanism for state reconstruction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ad3a459d499a20015cb02bd1e25bf788476d675d70043dd137b07a4b0f35b55_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the representational capabilities of single-layer Transformers for modeling dynamical systems, interpreting attention as a history-dependent recurrence. Through linear and nonlinear case studies, it finds that softmax attention restricts representable linear dynamics but can enable state reconstruction in nonlinear systems via adaptive delay embedding. The work bridges empirical Transformer performance with classical dynamical systems theory.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[论文标题/Paper Title: A Mechanistic Analysis of Transformers for Dynamical Systems] --> B[核心问题/Problem: Transformers as black boxes for time-series, lack of dynamical systems theory understanding];
    A --> C[主要方法/Method: Interpret causal self-attention as linear recurrence, analyze via linear/nonlinear case studies];
    A --> D[关键结果/Results: Softmax restricts linear dynamics (oversmoothing), attention enables nonlinear state reconstruction via delay embedding];
    ```

- **[arXiv251225] Quantum Homotopy Algorithm for Solving Nonlinear PDEs and Flow Problems**
  - **tags:** [other], [quantum computing for scientific computing], [quantum homotopy analysis, nonlinear PDEs, quantum algorithm, Burgers equation, flow simulation]
  - **authors:** Sachin S. Bharadwaj, Balasubramanya Nadiga, Stephan Eidenbenz, Katepalli R. Sreenivasan
  - **institution:** New York University, Los Alamos National Laboratory (LANL)
  - **link:** https://arxiv.org/pdf/2512.21033
  - **contributions:** 1. Proposes a near-optimal, robust, end-to-end quantum algorithm for solving time-dependent, dissipative nonlinear PDEs using a quantum homotopy analysis embedding scheme. 2. Provides improved complexity estimates and general bounds on stability, accuracy, gate counts, and query complexity, connecting a nonlinearity measure to an integration window parameter. 3. Demonstrates the algorithm's potential through numerical simulations of a 1D Burgers problem, showing applicability to near-term and fault-tolerant quantum devices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a5ccc689fae926cbd12774f2bfee28a0bae6a245cb9447a9256030a33952f9c_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a hybrid quantum algorithm for solving challenging nonlinear PDEs, such as those in fluid dynamics. The method uses quantum homotopy analysis to embed the PDEs into a high-dimensional linear space, which is then discretized and solved with a compact quantum algorithm. The work demonstrates improved complexity and shows the algorithm's potential for practical nonlinear simulations on quantum computers.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Quantum Homotopy Algorithm for Solving Nonlinear PDEs and Flow Problems] --> B(核心问题/Problem: Solving nonlinear PDEs for flow problems on quantum computers)
    A --> C(主要方法/Method: Quantum homotopy analysis embedding & finite-difference discretization)
    A --> D(关键结果/Results: Improved complexity, general bounds, demonstrated on Burgers equation)
    ```
