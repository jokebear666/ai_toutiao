---
slug: /daily/csce/20251229-20260104
---
# 20251229-20260104 (cs.CE)

## 2025-12-29

- **[arXiv251229] UniLabOS: An AI-Native Operating System for Autonomous Laboratories**
  - **tags:** [mlsys], [agent system], [autonomous laboratory, operating system, distributed edge-cloud architecture, CRUTD protocol, A/R/A&R model]
  - **authors:** Jing Gao, Junhan Chang, Haohui Que, Yanfei Xiong, Shixiang Zhang, Xianwei Qi, Zhen Liu, Jun-Jie Wang, Qianjun Ding, Xinyu Li, Ziwei Pan, Qiming Xie, Zhuang Yan, Junchi Yan, Linfeng Zhang
  - **institution:** DP Technology, Shanghai Jiao Tong University, Peking University, AI for Science Institute, Beijing
  - **link:** https://arxiv.org/pdf/2512.21766
  - **contributions:** 1. Proposes UniLabOS, an AI-native operating system that bridges high-level planning and low-level robotic execution for autonomous labs using typed, stateful abstractions and transactional safeguards. 2. Introduces a unified Action/Resource/Action&Resource (A/R/A&R) model and a dual-topology representation for lab structure, enabling protocol mobility across reconfigurable hardware. 3. Implements a transactional CRUTD protocol and a distributed edge-cloud architecture to reconcile digital state with physical motion and support robust, decentralized orchestration of heterogeneous instruments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c14a317a7f4c0283c03fbbdb64bfa6d4f6990a787d704f45dddd3134c96d9a_w640_q70.webp
  - **Simple LLM Summary:** The paper presents UniLabOS, an AI-native operating system designed to unify fragmented software in autonomous laboratories. It uses a novel A/R/A&R model, dual-topology representation, and a transactional CRUTD protocol on a distributed architecture to enable robust, reproducible, and agent-ready experimentation. The system is demonstrated across four real-world settings, establishing a scalable foundation for closed-loop scientific discovery.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[UniLabOS: An AI-Native Operating System for Autonomous Laboratories] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[软件碎片化阻碍自主实验室采用/Fragmented software hinders adoption of autonomous labs]
        C --> C1[AI原生操作系统/AI-native operating system]
        C1 --> C2[统一模型: A/R/A&R/Unified A/R/A&R model]
        C1 --> C3[双重拓扑结构/Dual-topology representation]
        C1 --> C4[事务性CRUTD协议/Transactional CRUTD protocol]
        C1 --> C5[分布式边云架构/Distributed edge-cloud architecture]
        D --> D1[四个真实场景验证/Four real-world demonstrations]
        D --> D2[异构仪器稳健编排/Robust orchestration across heterogeneous instruments]
        D --> D3[为可复现、可溯源的实验奠定基础/Foundation for reproducible, provenance-aware experimentation]
    ```

- **[arXiv251229] S&P 500 Stock's Movement Prediction using CNN**
  - **tags:** [ai], [financial time series forecasting], [Convolutional Neural Network (CNN), multivariate raw data, stock movement prediction, historical data matrices, S&P 500]
  - **authors:** Rahul Gupta
  - **institution:** None (No affiliation or email domain provided in the given content)
  - **link:** https://arxiv.org/pdf/2512.21804
  - **contributions:** 1. Proposes the application of Convolutional Neural Networks (CNNs), typically used for image classification, to the problem of stock movement prediction by treating multivariate historical stock data as image-like matrices. 2. Utilizes raw, unprocessed market data including events like stock splits and dividends, instead of relying on pre-engineered financial features. 3. Demonstrates a flexible prediction framework that can be applied at different levels: individual stocks, sectors, or entire portfolios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d6197655292ac8e55d8c7606c8c3cfe730f7f8dad4004b93d4a9b3a8d8f457_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the problem of predicting stock price movements for the S&P 500 index. The core method involves using a Convolutional Neural Network (CNN) to analyze multivariate historical stock data, which is structured as image-like matrices, without extensive feature engineering. The approach shows promising results and offers a flexible model for stock, sector, or portfolio-level predictions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["S&P 500 Stock's Movement Prediction using CNN<br>使用CNN预测标普500股票走势"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Predicting stock price movement<br>预测股票价格走势"] --> P1["传统方法依赖特征工程<br>Traditional methods rely on engineered features"]
        Problem --> P2["现有研究多使用单维数据<br>Existing research often uses single-dimension data"]
        Method["主要方法/Method<br>Use CNN on raw multivariate data<br>对原始多变量数据使用CNN"] --> M1["将历史数据矩阵视为图像<br>Treat historical data matrices as images"]
        Method --> M2["包含原始市场事件(如拆股)<br>Include raw market events (e.g., splits)"]
        Results["关键结果/Results<br>Model achieves promising results<br>模型取得有希望的结果"] --> R1["支持股票/行业/组合级别预测<br>Supports stock/sector/portfolio prediction"]
    ```

- **[arXiv251229] Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection**
  - **tags:** [ai], [reinforcement learning], [Quantum Reinforcement Learning, Asynchronous Advantage Actor-Critic (A3C), Variational Quantum Circuits (VQCs), Time-series Dynamic Clustering, ETF Stock Selection]
  - **authors:** Yen-Ku Liu, Yun-Cheng Tsai, Samuel Yen-Chi Chen
  - **institution:** National Taiwan Normal University, Wells Fargo Bank
  - **link:** https://arxiv.org/pdf/2512.21819
  - **contributions:** 1. Proposes Q-A3C2, a novel quantum-enhanced A3C framework integrated with time-series dynamic clustering for adaptive financial decision-making. 2. Embeds Variational Quantum Circuits (VQCs) into the policy network to enhance nonlinear feature representation and mitigate overfitting in high-dimensional financial data. 3. Demonstrates superior performance through experiments on S&P 500 constituents, achieving significantly higher cumulative returns compared to benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24772abde7bff15c10d7b6e86ca20b5510d1c2c86dce26245e814a93d8ce5afd_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Q-A3C2, a quantum reinforcement learning framework that combines a quantum-enhanced A3C algorithm with time-series dynamic clustering to adaptively select ETF stocks. The method uses Variational Quantum Circuits to improve feature learning and dynamic clustering to capture evolving market regimes. Experimental results on S&P 500 data show Q-A3C2 achieves a 17.09% cumulative return, outperforming the benchmark's 7.09%, demonstrating its effectiveness in dynamic financial environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统方法问题/Traditional Methods' Issues]
        B1 --> B11[高维特征与过拟合/High-dimensional Features & Overfitting]
        B1 --> B12[静态聚类无法适应市场变化/Static Clustering Fails to Adapt]
        C --> C1[量子增强A3C/Quantum-enhanced A3C]
        C1 --> C11[策略网络嵌入VQC/Embed VQC in Policy Network]
        C --> C2[集成时序动态聚类/Integrate Time-series Dynamic Clustering]
        D --> D1[累计收益17.09%/Cumulative Return 17.09%]
        D --> D2[超越基准7.09%/Outperforms Benchmark 7.09%]
    ```

- **[arXiv251229] Batched Training for QLSTM vs. QFWP: A System-Oriented Approach to EPC-Aware RMSE-DA**
  - **tags:** [mlsys], [others], [quantum machine learning, batching, adjoint differentiation, performance benchmarking, time series forecasting]
  - **authors:** Jun-Hao Chen, Ming-Kai Hung, Yun-Cheng Tsai, Samuel Yen-Chi Chen
  - **institution:** National Taiwan Normal University, Wells Fargo Bank
  - **link:** https://arxiv.org/pdf/2512.21820
  - **contributions:** 1. Introduced a unified Equal-Parameter-Count (EPC) benchmarking pipeline for quantum sequence models, enabling fair comparison of QLSTM and QFWP. 2. Provided a detailed system-oriented analysis of component-wise runtime scaling (forward/backward passes) with batch size under adjoint differentiation, revealing a bottleneck in backward pass scaling. 3. Identified a clear speed-accuracy Pareto frontier between the two models, with QFWP achieving higher accuracy and QLSTM achieving higher throughput.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6ea33d5050a471fe3705f085fc2670ef548afc5da1eb373bfceb7390def862f_w640_q70.webp
  - **Simple LLM Summary:** This paper systematically compares two quantum sequence models, QLSTM and QFWP, for time series forecasting under an equal-parameter-count constraint. It analyzes their runtime performance across different batch sizes and finds that while forward passes scale well, backward passes scale modestly, limiting overall training speedup. The main conclusion is that QFWP offers better accuracy, QLSTM offers higher throughput, revealing a trade-off for practitioners.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Batched Training for QLSTM vs. QFWP<br>QLSTM与QFWP的批处理训练"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>缺乏量子序列模型在批处理和伴随微分下的系统性基准测试"] --> P1["子问题/Sub-Problem<br>量化前向/后向传播的扩展性"]
        Problem --> P2["子问题/Sub-Problem<br>跨批次大小的精度稳定性"]
        Method["主要方法/Method<br>在EUR/USD预测任务上对QLSTM和QFWP进行等参数数量化基准测试"] --> M1["技术/Technique<br>分解运行时（前向、后向、训练、推理）"]
        Method --> M2["技术/Technique<br>测量RMSE和方向精度"]
        Results["关键结果/Results"] --> R1["结果1/Result 1<br>前向扩展良好(~2.2-2.4倍)，后向扩展有限"]
        Results --> R2["结果2/Result 2<br>QFWP精度更高，QLSTM吞吐量更高"]
        Results --> R3["结果3/Result 3<br>揭示了速度-精度的帕累托前沿"]
    ```

- **[arXiv251229] Atomistic Simulation Guided Convolutional Neural Networks for Thermal Modeling of Friction Stir Welding**
  - **tags:** [ai], [physics-informed machine learning], [molecular dynamics, convolutional neural network, friction stir welding, explainable AI, LAMMPS]
  - **authors:** Akshansh Mishra
  - **institution:** Politecnico di Milano, AI Fab Lab
  - **link:** https://arxiv.org/pdf/2512.21344
  - **contributions:** 1. Developed a novel method to transform atomistic simulation data (atomic positions and velocities) into physics-based 2D spatial grids for deep learning input. 2. Created and optimized a 2D CNN model to directly predict temperature evolution from spatially resolved atomistic data, achieving high accuracy (R²=0.94). 3. Used Class Activation Map analysis to provide explainability, showing the model's focus aligns with physical mechanisms (e.g., tool-material interface).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34d6f71500319f52aecac1e95e1951a537fdc504134a8ba43851f31acc2e41c6_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a method that combines molecular dynamics simulations with convolutional neural networks for thermal modeling in friction stir welding. The method transforms atomic-scale simulation data into spatial grids and uses a CNN to accurately predict temperature, with results validated against physical mechanisms. The approach demonstrates that deep learning can effectively learn from atomistic data to model complex thermomechanical processes.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Atomistic Simulation Guided CNNs for Thermal Modeling of FSW / 原子模拟引导的CNN用于搅拌摩擦焊热建模"]
        Root --> Problem["准确预测温度演化对于理解搅拌摩擦焊的热机械行为至关重要 / Accurate prediction of temperature evolution is essential for understanding thermomechanical behavior in FSW"]
        Root --> Method["使用LAMMPS进行分子动力学模拟，将原子数据转换为物理二维空间网格，并开发2D CNN进行预测 / Use LAMMPS for MD simulations, transform atomic data into physics-based 2D spatial grids, and develop a 2D CNN for prediction"]
        Root --> Results["模型预测精度高（R²=0.94），CAM分析表明模型关注与剧烈变形和生热相关的区域 / Model achieves high predictive accuracy (R²=0.94), CAM analysis shows model focuses on regions associated with intense deformation and heat generation"]
    ```

## 2025-12-30

- **[arXiv251230] Hierarchical Stacking Optimization Using Dirichlet's Process (SoDip): Towards Accelerated Design for Graft Polymerization**
  - **tags:** [ai], [bayesian optimization], [Dirichlet Process Mixture Model, Gaussian Process Regression, Transformer, TabNet, XGBoost]
  - **authors:** Amgad Ahmed Ali Ibrahim, Hein Htet, Ryoji Asahi
  - **institution:** Nagoya University
  - **link:** https://arxiv.org/pdf/2512.22279
  - **contributions:** 1. Proposed a hierarchical stacking optimization framework (SoDip) integrating a Transformer for text, TabNet/XGBoost for multimodal features, and GPR with DPMM for uncertainty. 2. Curated a diverse dataset for radiation-induced grafting using automated tools to handle numerical and textual variables. 3. Demonstrated ~33% performance improvement over standard GPR with calibrated confidence intervals for identifying low-reproducibility regimes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e1ff3feaf3b0e588ef295bb1595e516fbcdb32563ea40c93095217ac66e1fc5_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses reproducibility issues in radiation-induced graft polymerization by proposing SoDip, a hierarchical data-driven framework that combines Transformer encoders, multimodal feature models, and Bayesian optimization with uncertainty quantification. The method integrates sparse textual and numerical data, showing a 33% improvement over Gaussian Process Regression and providing reliable confidence estimates. This establishes a foundation for morphology-aware, reproducible design in polymer research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SoDip: Hierarchical Stacking Optimization] --> B(核心问题/Problem: Radiation-induced grafting reproducibility limited by unreported base-film morphology variability)
        A --> C(主要方法/Method: Hierarchical framework with Transformer (text), TabNet/XGBoost (features), GPR+DPMM (uncertainty), Bayesian Optimization)
        A --> D(关键结果/Results: ~33% improvement over GPR, calibrated confidence intervals, integrates sparse multimodal data)
    ```

- **[arXiv251230] Volume and Surface Area of two Orthogonal, Partially Intersecting Cylinders: A Generalization of the Steinmetz Solid**
  - **tags:** [other], [computational geometry], [cylinder intersection, Steinmetz solid, geometric integration, Quasi-Monte Carlo, empirical approximation]
  - **authors:** Fynn Jerome Aschmoneit, Bastiaan Cockx
  - **institution:** Aalborg University, Bundesamt für Materialforschung und -prüfung (BAM)
  - **link:** https://arxiv.org/pdf/2512.22555
  - **contributions:** 1. Presents general integral expressions for the volume and surface area of two orthogonal, partially intersecting cylinders as explicit functions of intersection depth. 2. Provides empirical closed-form approximation functions for volume and surface area with relative errors below 15% across the full parameter range. 3. Validates the analytical and approximate solutions against Quasi-Monte Carlo simulation, confirming their accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2824ac7ebfaa17e6cb90747c37fb20ea61279e9ae9c278ddbfa8261fb811e83_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the classical problem of calculating the volume and surface area for the partial intersection of two orthogonal cylinders, generalizing the Steinmetz solid. It provides exact integral formulations and simple empirical approximations as functions of the intersection depth. The proposed solutions are validated via simulation, offering accurate tools for engineering and computational geometry applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Volume and Surface Area of two Orthogonal, Partially Intersecting Cylinders<br>正交、部分相交圆柱体的体积与表面积] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Generalizing Steinmetz solid for partial intersections<br>推广Steinmetz立体至部分相交情形]
        C --> C1[Derive exact integral expressions<br>推导精确积分表达式]
        C --> C2[Develop empirical approximation functions<br>构建经验近似函数]
        C --> C3[Validate with Quasi-Monte Carlo simulation<br>用拟蒙特卡洛模拟验证]
        D --> D1[Closed-form approximations with <15% error<br>闭式近似误差<15%]
        D --> D2[Accurate solutions for engineering design<br>为工程设计提供精确解]
    ```

- **[arXiv251230] LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based Collective Simulation**
  - **tags:** [mlsys], [agent system], [multi-agent system, graph neural network, collective decision-making, startup success prediction, role-playing agents]
  - **authors:** Zhongyang Liu, Haoyu Pei, Xiangyi Xiao, Xiaocong Du, Yihui Li, Suting Hong, Kunpeng Zhang, Haipeng Zhang
  - **institution:** ShanghaiTech University, Xi’an Jiaotong-Liverpool University, University of Maryland
  - **link:** https://arxiv.org/pdf/2512.22608
  - **contributions:** 1. Proposes SimVC-CAS, a novel collective agent system that reformulates startup financing prediction as a multi-agent group decision-making task, moving beyond single decision-maker models. 2. Introduces role-playing agents with unique traits and a GNN-based supervised interaction module to capture heterogeneous investor evaluations and behavioral dynamics within a co-investment network. 3. Demonstrates significant predictive performance improvement (e.g., ~25% relative improvement in average precision@10) on real-world PitchBook data with strict leakage controls, while providing interpretable, multi-perspective reasoning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5560279fcb9dca880844ffe21da36f9901c81ce8898e265fff9cc80a5e7cfb8a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of predicting startup success by simulating venture capital decision-making as a collective process. It proposes SimVC-CAS, a multi-agent system where role-playing LLM agents interact via a GNN module to model investor networks. The method significantly outperforms previous approaches in predicting financing outcomes and offers interpretable reasoning from multiple investor perspectives.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based Collective Simulation] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[预测初创企业成功/Predicting Startup Success]
        B --> B2[现有方法忽略投资者群体动态/Existing methods overlook investor group dynamics]
        C --> C1[提出SimVC-CAS集体代理系统/Propose SimVC-CAS collective agent system]
        C --> C2[角色扮演代理与GNN交互模块/Role-playing agents & GNN-based interaction module]
        D --> D1[预测准确性显著提升/Significantly improved predictive accuracy]
        D --> D2[提供可解释的多视角推理/Provides interpretable, multi-perspective reasoning]
    ```

- **[arXiv251230] A Domain Decomposition-based Solver for Acoustic Wave propagation in Two-Dimensional Random Media**
  - **tags:** [hpc], [uncertainty quantification], [stochastic Galerkin method, polynomial chaos expansion, domain decomposition, Neumann-Neumann preconditioner]
  - **authors:** Sudhi Sharma Padillath Vasudevan
  - **institution:** Carleton University
  - **link:** https://arxiv.org/pdf/2512.23027
  - **contributions:** 1. Applies an intrusive stochastic Galerkin method with Polynomial Chaos Expansion to solve acoustic wave propagation in random media, transforming the stochastic PDE into a deterministic system. 2. Employs Domain Decomposition-based solvers to address the high computational cost associated with large-scale, high-dimensional stochastic systems. 3. Utilizes a conjugate gradient iterative solver with a two-level Neumann-Neumann preconditioner, demonstrating efficient scalability for the problem.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a4a9c029830a2f5bbff0493a205dfd33bea894daf2a861a9f131c15f02f4b9d_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the high computational cost of simulating acoustic wave propagation in two-dimensional random media. It proposes a method combining an intrusive stochastic Galerkin approach with Polynomial Chaos Expansion and a Domain Decomposition-based linear solver preconditioned with a two-level Neumann-Neumann method. The results show that this approach provides an efficiently scalable solution for the problem.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[基于域分解的二维随机介质声波传播求解器<br>A Domain Decomposition-based Solver for Acoustic Wave Propagation in 2D Random Media]
        Root --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[计算成本高<br>High Computational Cost]
        P1 --> P2[网格、时间步、随机参数增加<br>Increasing Mesh, Time Step, Random Parameters]
        Method --> M1[侵入式随机伽辽金法<br>Intrusive Stochastic Galerkin]
        M1 --> M2[多项式混沌展开<br>Polynomial Chaos Expansion (PCE)]
        Method --> M3[域分解求解器<br>Domain Decomposition Solver]
        M3 --> M4[共轭梯度法+两层Neumann-Neumann预处理器<br>Conjugate Gradient with Two-level Neumann-Neumann Preconditioner]
        Results --> R1[高效可扩展性<br>Efficient Scalability]
    ```

- **[arXiv251230] Machine Learning-Assisted Vocal Cord Ultrasound Examination: Project VIPR**
  - **tags:** [cv], [medical image classification], [vocal cord ultrasound, image segmentation, VIPRnet, vocal cord paralysis, classification model]
  - **authors:** Will Sebelik-Lassiter, Evan Schubert, Muhammad Alliyu, Quentin Robbins, Excel Olatunji, Mustafa Barry
  - **institution:** Milwaukee School of Engineering, Emory University
  - **link:** https://arxiv.org/pdf/2512.23177
  - **contributions:** 1. Developed a machine learning pipeline for automated analysis of vocal cord ultrasound (VCUS) videos. 2. Created a segmentation model to automatically identify vocal cords in ultrasound images with 96% validation accuracy. 3. Proposed VIPRnet, a classification model to distinguish normal vocal cords from vocal cord paralysis (VCP) with 99% validation accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5abcb457a7fbefffa7d7836af553a8db8fa248fdd34a0459a027299b3ce2ce44_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a machine learning-assisted system to automate the analysis of vocal cord ultrasound (VCUS) to reduce operator dependency. The method involves segmenting the vocal cords and classifying them as normal or paralyzed using models trained on frames from volunteer videos. The results show high validation accuracy (96% for segmentation, 99% for classification), indicating promise for improving diagnostic accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Project VIPR: Machine Learning-Assisted Vocal Cord Ultrasound Examination] --> B[核心问题/Problem: VCUS accuracy is operator-dependent]
    A --> C[主要方法/Method: Use ML models for vocal cord segmentation and VCP classification]
    A --> D[关键结果/Results: Segmentation accuracy 96%, VIPRnet classification accuracy 99%]
    ```

- **[arXiv251230] Verifiable Off-Chain Governance**
  - **tags:** [sec], [blockchain governance], [verifiable off-chain computation, attestation-based governance, Policy-as-Code]
  - **authors:** Jake Hartnell, Eugenio, Battaglia
  - **institution:** wavs.xyz, meaning.systems
  - **link:** https://arxiv.org/pdf/2512.23618
  - **contributions:** 1. A formal model for attestation-based governance that computes multi-dimensional stakeholder legitimacy from verifiable social graphs. 2. Collective intelligence mechanisms that process community preferences through verifiable, auditable pipelines. 3. Autonomous policy execution via Policy-as-Code for adaptive governance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5282b480f8d7def5c388ece05857d963165050c3da457b3dac40b85083fb957_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of primitive, token-weighted voting in DAOs caused by on-chain computational limits. It proposes a framework using verifiable off-chain computation (Verifiable Services, TEEs, ZK proofs) to enable more expressive and efficient governance mechanisms. The conclusion is that this framework provides a practical path for DAOs to achieve higher-resolution governance, validated by pioneering implementations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Verifiable Off-Chain Governance] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[DAO治理受限<br/>DAO Governance Constrained]
        B1 --> B2[链上计算限制<br/>On-Chain Computational Limits]
        B2 --> B3[单一投票<br/>Token-Weighted Voting]
        C --> C1[可验证链下计算<br/>Verifiable Off-Chain Computation]
        C1 --> C2[机制1: 证明系统<br/>Mechanism 1: Attestation]
        C1 --> C3[机制2: 集体智能<br/>Mechanism 2: Collective Intelligence]
        C1 --> C4[机制3: 策略即代码<br/>Mechanism 3: Policy-as-Code]
        D --> D1[架构规范<br/>Architectural Specs]
        D --> D2[安全模型<br/>Security Models]
        D --> D3[验证可行<br/>Practical Viability]
    ```

- **[arXiv251230] Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [alpha screening, large language models, reinforcement learning, factor investing, economic reasoning]
  - **authors:** Zuoyou Jiang, Li Zhao, Rui Sun, Ruohan Sun, Zhongjian Li, Jing Li, Daxin Jiang, Zuo Bai, Cheng Hua
  - **institution:** Shanghai Jiao Tong University, StepFun, FinStep
  - **link:** https://arxiv.org/pdf/2512.23515
  - **code:** https://github.com/FinStep-AI/Alpha-R1
  - **contributions:** 1. Proposes Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. 2. Introduces a method for LLMs to reason over factor logic and real-time news to evaluate alpha relevance under changing market conditions. 3. Demonstrates that the model consistently outperforms benchmarks and shows improved robustness to alpha decay across multiple asset pools.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d921912985e0858276fe1088914641df9c33c30f5de309733b2244c86c21e75e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of alpha decay in non-stationary financial markets by proposing Alpha-R1, a reasoning model trained with reinforcement learning. It uses a large language model to process factor logic and news, selectively activating factors based on contextual economic relevance. Empirical results show it outperforms benchmark strategies and is more robust to signal decay.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning] --> B[核心问题/Problem: Signal decay and regime shifts in non-stationary markets; existing methods overlook semantic rationale for factor relevance.]
        A --> C[主要方法/Method: Alpha-R1, an 8B-parameter LLM trained via RL, reasons over factor logic and real-time news for context-aware alpha screening.]
        A --> D[关键结果/Results: Outperforms benchmark strategies; exhibits improved robustness to alpha decay across multiple asset pools.]
    ```
