---
slug: /daily/csce/20251229-20260104
---
# 20251229-20260104 (cs.CE)

## 2025-12-29

- **[arXiv251229] UniLabOS: An AI-Native Operating System for Autonomous Laboratories**
  - **tags:** [mlsys], [agent system], [autonomous laboratory, operating system, distributed edge-cloud architecture, CRUTD protocol, A/R/A&R model]
  - **authors:** Jing Gao, Junhan Chang, Haohui Que, Yanfei Xiong, Shixiang Zhang, Xianwei Qi, Zhen Liu, Jun-Jie Wang, Qianjun Ding, Xinyu Li, Ziwei Pan, Qiming Xie, Zhuang Yan, Junchi Yan, Linfeng Zhang
  - **institution:** DP Technology, Shanghai Jiao Tong University, Peking University, AI for Science Institute, Beijing
  - **link:** https://arxiv.org/pdf/2512.21766
  - **contributions:** 1. Proposes UniLabOS, an AI-native operating system that bridges high-level planning and low-level robotic execution for autonomous labs using typed, stateful abstractions and transactional safeguards. 2. Introduces a unified Action/Resource/Action&Resource (A/R/A&R) model and a dual-topology representation for lab structure, enabling protocol mobility across reconfigurable hardware. 3. Implements a transactional CRUTD protocol and a distributed edge-cloud architecture to reconcile digital state with physical motion and support robust, decentralized orchestration of heterogeneous instruments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c14a317a7f4c0283c03fbbdb64bfa6d4f6990a787d704f45dddd3134c96d9a_w640_q70.webp
  - **Simple LLM Summary:** The paper presents UniLabOS, an AI-native operating system designed to unify fragmented software in autonomous laboratories. It uses a novel A/R/A&R model, dual-topology representation, and a transactional CRUTD protocol on a distributed architecture to enable robust, reproducible, and agent-ready experimentation. The system is demonstrated across four real-world settings, establishing a scalable foundation for closed-loop scientific discovery.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[UniLabOS: An AI-Native Operating System for Autonomous Laboratories] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[软件碎片化阻碍自主实验室采用/Fragmented software hinders adoption of autonomous labs]
        C --> C1[AI原生操作系统/AI-native operating system]
        C1 --> C2[统一模型: A/R/A&R/Unified A/R/A&R model]
        C1 --> C3[双重拓扑结构/Dual-topology representation]
        C1 --> C4[事务性CRUTD协议/Transactional CRUTD protocol]
        C1 --> C5[分布式边云架构/Distributed edge-cloud architecture]
        D --> D1[四个真实场景验证/Four real-world demonstrations]
        D --> D2[异构仪器稳健编排/Robust orchestration across heterogeneous instruments]
        D --> D3[为可复现、可溯源的实验奠定基础/Foundation for reproducible, provenance-aware experimentation]
    ```

- **[arXiv251229] S&P 500 Stock's Movement Prediction using CNN**
  - **tags:** [ai], [financial time series forecasting], [Convolutional Neural Network (CNN), multivariate raw data, stock movement prediction, historical data matrices, S&P 500]
  - **authors:** Rahul Gupta
  - **institution:** None (No affiliation or email domain provided in the given content)
  - **link:** https://arxiv.org/pdf/2512.21804
  - **contributions:** 1. Proposes the application of Convolutional Neural Networks (CNNs), typically used for image classification, to the problem of stock movement prediction by treating multivariate historical stock data as image-like matrices. 2. Utilizes raw, unprocessed market data including events like stock splits and dividends, instead of relying on pre-engineered financial features. 3. Demonstrates a flexible prediction framework that can be applied at different levels: individual stocks, sectors, or entire portfolios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d6197655292ac8e55d8c7606c8c3cfe730f7f8dad4004b93d4a9b3a8d8f457_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the problem of predicting stock price movements for the S&P 500 index. The core method involves using a Convolutional Neural Network (CNN) to analyze multivariate historical stock data, which is structured as image-like matrices, without extensive feature engineering. The approach shows promising results and offers a flexible model for stock, sector, or portfolio-level predictions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["S&P 500 Stock's Movement Prediction using CNN<br>使用CNN预测标普500股票走势"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Predicting stock price movement<br>预测股票价格走势"] --> P1["传统方法依赖特征工程<br>Traditional methods rely on engineered features"]
        Problem --> P2["现有研究多使用单维数据<br>Existing research often uses single-dimension data"]
        Method["主要方法/Method<br>Use CNN on raw multivariate data<br>对原始多变量数据使用CNN"] --> M1["将历史数据矩阵视为图像<br>Treat historical data matrices as images"]
        Method --> M2["包含原始市场事件(如拆股)<br>Include raw market events (e.g., splits)"]
        Results["关键结果/Results<br>Model achieves promising results<br>模型取得有希望的结果"] --> R1["支持股票/行业/组合级别预测<br>Supports stock/sector/portfolio prediction"]
    ```

- **[arXiv251229] Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection**
  - **tags:** [ai], [reinforcement learning], [Quantum Reinforcement Learning, Asynchronous Advantage Actor-Critic (A3C), Variational Quantum Circuits (VQCs), Time-series Dynamic Clustering, ETF Stock Selection]
  - **authors:** Yen-Ku Liu, Yun-Cheng Tsai, Samuel Yen-Chi Chen
  - **institution:** National Taiwan Normal University, Wells Fargo Bank
  - **link:** https://arxiv.org/pdf/2512.21819
  - **contributions:** 1. Proposes Q-A3C2, a novel quantum-enhanced A3C framework integrated with time-series dynamic clustering for adaptive financial decision-making. 2. Embeds Variational Quantum Circuits (VQCs) into the policy network to enhance nonlinear feature representation and mitigate overfitting in high-dimensional financial data. 3. Demonstrates superior performance through experiments on S&P 500 constituents, achieving significantly higher cumulative returns compared to benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24772abde7bff15c10d7b6e86ca20b5510d1c2c86dce26245e814a93d8ce5afd_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Q-A3C2, a quantum reinforcement learning framework that combines a quantum-enhanced A3C algorithm with time-series dynamic clustering to adaptively select ETF stocks. The method uses Variational Quantum Circuits to improve feature learning and dynamic clustering to capture evolving market regimes. Experimental results on S&P 500 data show Q-A3C2 achieves a 17.09% cumulative return, outperforming the benchmark's 7.09%, demonstrating its effectiveness in dynamic financial environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统方法问题/Traditional Methods' Issues]
        B1 --> B11[高维特征与过拟合/High-dimensional Features & Overfitting]
        B1 --> B12[静态聚类无法适应市场变化/Static Clustering Fails to Adapt]
        C --> C1[量子增强A3C/Quantum-enhanced A3C]
        C1 --> C11[策略网络嵌入VQC/Embed VQC in Policy Network]
        C --> C2[集成时序动态聚类/Integrate Time-series Dynamic Clustering]
        D --> D1[累计收益17.09%/Cumulative Return 17.09%]
        D --> D2[超越基准7.09%/Outperforms Benchmark 7.09%]
    ```

- **[arXiv251229] Batched Training for QLSTM vs. QFWP: A System-Oriented Approach to EPC-Aware RMSE-DA**
  - **tags:** [mlsys], [others], [quantum machine learning, batching, adjoint differentiation, performance benchmarking, time series forecasting]
  - **authors:** Jun-Hao Chen, Ming-Kai Hung, Yun-Cheng Tsai, Samuel Yen-Chi Chen
  - **institution:** National Taiwan Normal University, Wells Fargo Bank
  - **link:** https://arxiv.org/pdf/2512.21820
  - **contributions:** 1. Introduced a unified Equal-Parameter-Count (EPC) benchmarking pipeline for quantum sequence models, enabling fair comparison of QLSTM and QFWP. 2. Provided a detailed system-oriented analysis of component-wise runtime scaling (forward/backward passes) with batch size under adjoint differentiation, revealing a bottleneck in backward pass scaling. 3. Identified a clear speed-accuracy Pareto frontier between the two models, with QFWP achieving higher accuracy and QLSTM achieving higher throughput.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6ea33d5050a471fe3705f085fc2670ef548afc5da1eb373bfceb7390def862f_w640_q70.webp
  - **Simple LLM Summary:** This paper systematically compares two quantum sequence models, QLSTM and QFWP, for time series forecasting under an equal-parameter-count constraint. It analyzes their runtime performance across different batch sizes and finds that while forward passes scale well, backward passes scale modestly, limiting overall training speedup. The main conclusion is that QFWP offers better accuracy, QLSTM offers higher throughput, revealing a trade-off for practitioners.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Batched Training for QLSTM vs. QFWP<br>QLSTM与QFWP的批处理训练"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>缺乏量子序列模型在批处理和伴随微分下的系统性基准测试"] --> P1["子问题/Sub-Problem<br>量化前向/后向传播的扩展性"]
        Problem --> P2["子问题/Sub-Problem<br>跨批次大小的精度稳定性"]
        Method["主要方法/Method<br>在EUR/USD预测任务上对QLSTM和QFWP进行等参数数量化基准测试"] --> M1["技术/Technique<br>分解运行时（前向、后向、训练、推理）"]
        Method --> M2["技术/Technique<br>测量RMSE和方向精度"]
        Results["关键结果/Results"] --> R1["结果1/Result 1<br>前向扩展良好(~2.2-2.4倍)，后向扩展有限"]
        Results --> R2["结果2/Result 2<br>QFWP精度更高，QLSTM吞吐量更高"]
        Results --> R3["结果3/Result 3<br>揭示了速度-精度的帕累托前沿"]
    ```

- **[arXiv251229] Atomistic Simulation Guided Convolutional Neural Networks for Thermal Modeling of Friction Stir Welding**
  - **tags:** [ai], [physics-informed machine learning], [molecular dynamics, convolutional neural network, friction stir welding, explainable AI, LAMMPS]
  - **authors:** Akshansh Mishra
  - **institution:** Politecnico di Milano, AI Fab Lab
  - **link:** https://arxiv.org/pdf/2512.21344
  - **contributions:** 1. Developed a novel method to transform atomistic simulation data (atomic positions and velocities) into physics-based 2D spatial grids for deep learning input. 2. Created and optimized a 2D CNN model to directly predict temperature evolution from spatially resolved atomistic data, achieving high accuracy (R²=0.94). 3. Used Class Activation Map analysis to provide explainability, showing the model's focus aligns with physical mechanisms (e.g., tool-material interface).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34d6f71500319f52aecac1e95e1951a537fdc504134a8ba43851f31acc2e41c6_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a method that combines molecular dynamics simulations with convolutional neural networks for thermal modeling in friction stir welding. The method transforms atomic-scale simulation data into spatial grids and uses a CNN to accurately predict temperature, with results validated against physical mechanisms. The approach demonstrates that deep learning can effectively learn from atomistic data to model complex thermomechanical processes.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Atomistic Simulation Guided CNNs for Thermal Modeling of FSW / 原子模拟引导的CNN用于搅拌摩擦焊热建模"]
        Root --> Problem["准确预测温度演化对于理解搅拌摩擦焊的热机械行为至关重要 / Accurate prediction of temperature evolution is essential for understanding thermomechanical behavior in FSW"]
        Root --> Method["使用LAMMPS进行分子动力学模拟，将原子数据转换为物理二维空间网格，并开发2D CNN进行预测 / Use LAMMPS for MD simulations, transform atomic data into physics-based 2D spatial grids, and develop a 2D CNN for prediction"]
        Root --> Results["模型预测精度高（R²=0.94），CAM分析表明模型关注与剧烈变形和生热相关的区域 / Model achieves high predictive accuracy (R²=0.94), CAM analysis shows model focuses on regions associated with intense deformation and heat generation"]
    ```

## 2025-12-30

- **[arXiv251230] Hierarchical Stacking Optimization Using Dirichlet's Process (SoDip): Towards Accelerated Design for Graft Polymerization**
  - **tags:** [ai], [bayesian optimization], [Dirichlet Process Mixture Model, Gaussian Process Regression, Transformer, TabNet, XGBoost]
  - **authors:** Amgad Ahmed Ali Ibrahim, Hein Htet, Ryoji Asahi
  - **institution:** Nagoya University
  - **link:** https://arxiv.org/pdf/2512.22279
  - **contributions:** 1. Proposed a hierarchical stacking optimization framework (SoDip) integrating a Transformer for text, TabNet/XGBoost for multimodal features, and GPR with DPMM for uncertainty. 2. Curated a diverse dataset for radiation-induced grafting using automated tools to handle numerical and textual variables. 3. Demonstrated ~33% performance improvement over standard GPR with calibrated confidence intervals for identifying low-reproducibility regimes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e1ff3feaf3b0e588ef295bb1595e516fbcdb32563ea40c93095217ac66e1fc5_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses reproducibility issues in radiation-induced graft polymerization by proposing SoDip, a hierarchical data-driven framework that combines Transformer encoders, multimodal feature models, and Bayesian optimization with uncertainty quantification. The method integrates sparse textual and numerical data, showing a 33% improvement over Gaussian Process Regression and providing reliable confidence estimates. This establishes a foundation for morphology-aware, reproducible design in polymer research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SoDip: Hierarchical Stacking Optimization] --> B(核心问题/Problem: Radiation-induced grafting reproducibility limited by unreported base-film morphology variability)
        A --> C(主要方法/Method: Hierarchical framework with Transformer (text), TabNet/XGBoost (features), GPR+DPMM (uncertainty), Bayesian Optimization)
        A --> D(关键结果/Results: ~33% improvement over GPR, calibrated confidence intervals, integrates sparse multimodal data)
    ```

- **[arXiv251230] Volume and Surface Area of two Orthogonal, Partially Intersecting Cylinders: A Generalization of the Steinmetz Solid**
  - **tags:** [other], [computational geometry], [cylinder intersection, Steinmetz solid, geometric integration, Quasi-Monte Carlo, empirical approximation]
  - **authors:** Fynn Jerome Aschmoneit, Bastiaan Cockx
  - **institution:** Aalborg University, Bundesamt für Materialforschung und -prüfung (BAM)
  - **link:** https://arxiv.org/pdf/2512.22555
  - **contributions:** 1. Presents general integral expressions for the volume and surface area of two orthogonal, partially intersecting cylinders as explicit functions of intersection depth. 2. Provides empirical closed-form approximation functions for volume and surface area with relative errors below 15% across the full parameter range. 3. Validates the analytical and approximate solutions against Quasi-Monte Carlo simulation, confirming their accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2824ac7ebfaa17e6cb90747c37fb20ea61279e9ae9c278ddbfa8261fb811e83_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the classical problem of calculating the volume and surface area for the partial intersection of two orthogonal cylinders, generalizing the Steinmetz solid. It provides exact integral formulations and simple empirical approximations as functions of the intersection depth. The proposed solutions are validated via simulation, offering accurate tools for engineering and computational geometry applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Volume and Surface Area of two Orthogonal, Partially Intersecting Cylinders<br>正交、部分相交圆柱体的体积与表面积] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Generalizing Steinmetz solid for partial intersections<br>推广Steinmetz立体至部分相交情形]
        C --> C1[Derive exact integral expressions<br>推导精确积分表达式]
        C --> C2[Develop empirical approximation functions<br>构建经验近似函数]
        C --> C3[Validate with Quasi-Monte Carlo simulation<br>用拟蒙特卡洛模拟验证]
        D --> D1[Closed-form approximations with <15% error<br>闭式近似误差<15%]
        D --> D2[Accurate solutions for engineering design<br>为工程设计提供精确解]
    ```

- **[arXiv251230] LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based Collective Simulation**
  - **tags:** [mlsys], [agent system], [multi-agent system, graph neural network, collective decision-making, startup success prediction, role-playing agents]
  - **authors:** Zhongyang Liu, Haoyu Pei, Xiangyi Xiao, Xiaocong Du, Yihui Li, Suting Hong, Kunpeng Zhang, Haipeng Zhang
  - **institution:** ShanghaiTech University, Xi’an Jiaotong-Liverpool University, University of Maryland
  - **link:** https://arxiv.org/pdf/2512.22608
  - **contributions:** 1. Proposes SimVC-CAS, a novel collective agent system that reformulates startup financing prediction as a multi-agent group decision-making task, moving beyond single decision-maker models. 2. Introduces role-playing agents with unique traits and a GNN-based supervised interaction module to capture heterogeneous investor evaluations and behavioral dynamics within a co-investment network. 3. Demonstrates significant predictive performance improvement (e.g., ~25% relative improvement in average precision@10) on real-world PitchBook data with strict leakage controls, while providing interpretable, multi-perspective reasoning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5560279fcb9dca880844ffe21da36f9901c81ce8898e265fff9cc80a5e7cfb8a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of predicting startup success by simulating venture capital decision-making as a collective process. It proposes SimVC-CAS, a multi-agent system where role-playing LLM agents interact via a GNN module to model investor networks. The method significantly outperforms previous approaches in predicting financing outcomes and offers interpretable reasoning from multiple investor perspectives.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based Collective Simulation] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[预测初创企业成功/Predicting Startup Success]
        B --> B2[现有方法忽略投资者群体动态/Existing methods overlook investor group dynamics]
        C --> C1[提出SimVC-CAS集体代理系统/Propose SimVC-CAS collective agent system]
        C --> C2[角色扮演代理与GNN交互模块/Role-playing agents & GNN-based interaction module]
        D --> D1[预测准确性显著提升/Significantly improved predictive accuracy]
        D --> D2[提供可解释的多视角推理/Provides interpretable, multi-perspective reasoning]
    ```

- **[arXiv251230] A Domain Decomposition-based Solver for Acoustic Wave propagation in Two-Dimensional Random Media**
  - **tags:** [hpc], [uncertainty quantification], [stochastic Galerkin method, polynomial chaos expansion, domain decomposition, Neumann-Neumann preconditioner]
  - **authors:** Sudhi Sharma Padillath Vasudevan
  - **institution:** Carleton University
  - **link:** https://arxiv.org/pdf/2512.23027
  - **contributions:** 1. Applies an intrusive stochastic Galerkin method with Polynomial Chaos Expansion to solve acoustic wave propagation in random media, transforming the stochastic PDE into a deterministic system. 2. Employs Domain Decomposition-based solvers to address the high computational cost associated with large-scale, high-dimensional stochastic systems. 3. Utilizes a conjugate gradient iterative solver with a two-level Neumann-Neumann preconditioner, demonstrating efficient scalability for the problem.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a4a9c029830a2f5bbff0493a205dfd33bea894daf2a861a9f131c15f02f4b9d_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the high computational cost of simulating acoustic wave propagation in two-dimensional random media. It proposes a method combining an intrusive stochastic Galerkin approach with Polynomial Chaos Expansion and a Domain Decomposition-based linear solver preconditioned with a two-level Neumann-Neumann method. The results show that this approach provides an efficiently scalable solution for the problem.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[基于域分解的二维随机介质声波传播求解器<br>A Domain Decomposition-based Solver for Acoustic Wave Propagation in 2D Random Media]
        Root --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[计算成本高<br>High Computational Cost]
        P1 --> P2[网格、时间步、随机参数增加<br>Increasing Mesh, Time Step, Random Parameters]
        Method --> M1[侵入式随机伽辽金法<br>Intrusive Stochastic Galerkin]
        M1 --> M2[多项式混沌展开<br>Polynomial Chaos Expansion (PCE)]
        Method --> M3[域分解求解器<br>Domain Decomposition Solver]
        M3 --> M4[共轭梯度法+两层Neumann-Neumann预处理器<br>Conjugate Gradient with Two-level Neumann-Neumann Preconditioner]
        Results --> R1[高效可扩展性<br>Efficient Scalability]
    ```

- **[arXiv251230] Machine Learning-Assisted Vocal Cord Ultrasound Examination: Project VIPR**
  - **tags:** [cv], [medical image classification], [vocal cord ultrasound, image segmentation, VIPRnet, vocal cord paralysis, classification model]
  - **authors:** Will Sebelik-Lassiter, Evan Schubert, Muhammad Alliyu, Quentin Robbins, Excel Olatunji, Mustafa Barry
  - **institution:** Milwaukee School of Engineering, Emory University
  - **link:** https://arxiv.org/pdf/2512.23177
  - **contributions:** 1. Developed a machine learning pipeline for automated analysis of vocal cord ultrasound (VCUS) videos. 2. Created a segmentation model to automatically identify vocal cords in ultrasound images with 96% validation accuracy. 3. Proposed VIPRnet, a classification model to distinguish normal vocal cords from vocal cord paralysis (VCP) with 99% validation accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5abcb457a7fbefffa7d7836af553a8db8fa248fdd34a0459a027299b3ce2ce44_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a machine learning-assisted system to automate the analysis of vocal cord ultrasound (VCUS) to reduce operator dependency. The method involves segmenting the vocal cords and classifying them as normal or paralyzed using models trained on frames from volunteer videos. The results show high validation accuracy (96% for segmentation, 99% for classification), indicating promise for improving diagnostic accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Project VIPR: Machine Learning-Assisted Vocal Cord Ultrasound Examination] --> B[核心问题/Problem: VCUS accuracy is operator-dependent]
    A --> C[主要方法/Method: Use ML models for vocal cord segmentation and VCP classification]
    A --> D[关键结果/Results: Segmentation accuracy 96%, VIPRnet classification accuracy 99%]
    ```

- **[arXiv251230] Verifiable Off-Chain Governance**
  - **tags:** [sec], [blockchain governance], [verifiable off-chain computation, attestation-based governance, Policy-as-Code]
  - **authors:** Jake Hartnell, Eugenio, Battaglia
  - **institution:** wavs.xyz, meaning.systems
  - **link:** https://arxiv.org/pdf/2512.23618
  - **contributions:** 1. A formal model for attestation-based governance that computes multi-dimensional stakeholder legitimacy from verifiable social graphs. 2. Collective intelligence mechanisms that process community preferences through verifiable, auditable pipelines. 3. Autonomous policy execution via Policy-as-Code for adaptive governance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5282b480f8d7def5c388ece05857d963165050c3da457b3dac40b85083fb957_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of primitive, token-weighted voting in DAOs caused by on-chain computational limits. It proposes a framework using verifiable off-chain computation (Verifiable Services, TEEs, ZK proofs) to enable more expressive and efficient governance mechanisms. The conclusion is that this framework provides a practical path for DAOs to achieve higher-resolution governance, validated by pioneering implementations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Verifiable Off-Chain Governance] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[DAO治理受限<br/>DAO Governance Constrained]
        B1 --> B2[链上计算限制<br/>On-Chain Computational Limits]
        B2 --> B3[单一投票<br/>Token-Weighted Voting]
        C --> C1[可验证链下计算<br/>Verifiable Off-Chain Computation]
        C1 --> C2[机制1: 证明系统<br/>Mechanism 1: Attestation]
        C1 --> C3[机制2: 集体智能<br/>Mechanism 2: Collective Intelligence]
        C1 --> C4[机制3: 策略即代码<br/>Mechanism 3: Policy-as-Code]
        D --> D1[架构规范<br/>Architectural Specs]
        D --> D2[安全模型<br/>Security Models]
        D --> D3[验证可行<br/>Practical Viability]
    ```

- **[arXiv251230] Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [alpha screening, large language models, reinforcement learning, factor investing, economic reasoning]
  - **authors:** Zuoyou Jiang, Li Zhao, Rui Sun, Ruohan Sun, Zhongjian Li, Jing Li, Daxin Jiang, Zuo Bai, Cheng Hua
  - **institution:** Shanghai Jiao Tong University, StepFun, FinStep
  - **link:** https://arxiv.org/pdf/2512.23515
  - **code:** https://github.com/FinStep-AI/Alpha-R1
  - **contributions:** 1. Proposes Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. 2. Introduces a method for LLMs to reason over factor logic and real-time news to evaluate alpha relevance under changing market conditions. 3. Demonstrates that the model consistently outperforms benchmarks and shows improved robustness to alpha decay across multiple asset pools.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d921912985e0858276fe1088914641df9c33c30f5de309733b2244c86c21e75e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of alpha decay in non-stationary financial markets by proposing Alpha-R1, a reasoning model trained with reinforcement learning. It uses a large language model to process factor logic and news, selectively activating factors based on contextual economic relevance. Empirical results show it outperforms benchmark strategies and is more robust to signal decay.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning] --> B[核心问题/Problem: Signal decay and regime shifts in non-stationary markets; existing methods overlook semantic rationale for factor relevance.]
        A --> C[主要方法/Method: Alpha-R1, an 8B-parameter LLM trained via RL, reasons over factor logic and real-time news for context-aware alpha screening.]
        A --> D[关键结果/Results: Outperforms benchmark strategies; exhibits improved robustness to alpha decay across multiple asset pools.]
    ```

## 2026-01-01

- **[arXiv260101] Wind Speed Weibull Model Identification in Oman, and Computed Normalized Annual Energy Production (NAEP) From Wind Turbines Based on Data From Weather Stations**
  - **tags:** [other], [renewable energy assessment], [Weibull distribution, wind speed modeling, normalized annual energy production (NAEP), wind resource assessment, Oman]
  - **authors:** Osama A. Marzouk
  - **institution:** Not explicitly stated. Likely an Omani research institution or university (e.g., Sultan Qaboos University) or a meteorological agency based on the data source.
  - **link:** https://arxiv.org/pdf/2512.23715
  - **contributions:** 1. Estimation of Weibull distribution parameters (shape and scale) for wind speed at 10 weather stations across Oman using 23 years of observational data. 2. Computation of Normalized Annual Energy Production (NAEP) for a 1 MWp wind turbine at these locations to assess wind energy potential. 3. Statistical analysis of wind direction and identification of the four most promising sites (Thumrait, Masirah, Sur, Fahud) based on probability of exceeding 6 m/s wind speed and NAEP values.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b90442d936529f970be86cae48b8ce3a6c8c8681f1ff2bb71bb473135a1e84b_w640_q70.webp
  - **Simple LLM Summary:** This paper models wind speed distributions using the Weibull distribution based on long-term weather station data from Oman to assess wind energy potential. The method calculates key parameters and uses them to estimate the Normalized Annual Energy Production (NAEP) for a reference wind turbine. The main conclusion identifies Thumrait as the most promising site due to its high average wind speed, unidirectional wind pattern, and highest estimated NAEP.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Wind Speed Weibull Model Identification in Oman, and Computed Normalized Annual Energy Production (NAEP) From Wind Turbines Based on Data From Weather Stations] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[评估阿曼的风能潜力<br/>Assess wind energy potential in Oman]
        C --> C1[使用威布尔分布拟合风速数据<br/>Fit wind speed data using Weibull distribution]
        C --> C2[计算归一化年发电量 (NAEP)<br/>Compute Normalized Annual Energy Production (NAEP)]
        C --> C3[分析风向<br/>Analyze wind direction]
        D --> D1[确定四个有前景的地点<br/>Identify four promising locations]
        D --> D2[Thumrait 的 NAEP 最高<br/>Thumrait has the highest NAEP]
        D --> D3[Thumrait 风向最单一<br/>Thumrait wind is most unidirectional]
    ```

- **[arXiv260101] A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation**
  - **tags:** [hpc], [computational geometry], [mesh generation, geometry preparation, CAD-to-mesh, machine learning, large language models]
  - **authors:** Steven Owen, Nathan Brown, Nikos Chrisochoides, Rao Garimella, Xianfeng Gu, Franck Ledoux, Na Lei, Roshan Quadros, Navamita Ray, Nicolas Winovich, Yongjie Jessica Zhang
  - **institution:** Sandia National Laboratories, Old Dominion University, Los Alamos National Laboratory, New York University / Stony Brook University, CEA, Dalian University of Technology, Carnegie Mellon University
  - **link:** https://arxiv.org/pdf/2512.23719
  - **contributions:** 1. Surveys the application of AI/ML methods to automate and improve key steps in the CAD-to-mesh pipeline, such as part classification, mesh quality prediction, and defeaturing. 2. Reviews AI techniques for enhancing unstructured/block-structured meshing, volumetric parameterization, and parallel mesh generation. 3. Examines emerging tools like reinforcement learning and large language models for scripting automation in meshing workflows.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c3d8c73084ddd952c2e0c9fd20e1b7fe1d87bb02c884cf6327ca47e6ec442eb_w640_q70.webp
  - **Simple LLM Summary:** This survey paper reviews how artificial intelligence and machine learning are being applied to address bottlenecks in geometry preparation and mesh generation for engineering simulation. It explores a range of methods, from quality prediction to automation with large language models, concluding that AI serves as an assistive technology to extend traditional tools and highlights key challenges for future data-driven workflows.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[CAD-to-mesh流程瓶颈 / CAD-to-mesh Pipeline Bottlenecks]
        C --> C1[AI辅助几何与网格生成 / AI-aided Geometry & Meshing]
        C --> C2[机器学习方法 / Machine Learning Methods]
        C --> C3[新兴自动化工具 / Emerging Automation Tools]
        C1 --> C1a[部件分类 / Part Classification]
        C1 --> C1b[网格质量预测 / Mesh Quality Prediction]
        C1 --> C1c[去特征化 / Defeaturing]
        C2 --> C2a[非结构化/块结构化网格 / Unstructured/Block-structured Meshing]
        C2 --> C2b[体积参数化 / Volumetric Parameterizations]
        C2 --> C2c[并行网格生成 / Parallel Mesh Generation]
        C3 --> C3a[强化学习 / Reinforcement Learning]
        C3 --> C3b[大语言模型 / Large Language Models]
        D --> D1[AI作为辅助技术 / AI as Assistive Technology]
        D --> D2[代表性方法与部署 / Representative Methods & Deployments]
        D --> D3[关键研究挑战 / Key Research Challenges]
    ```

- **[arXiv260101] Integrating Domain Knowledge for Financial QA: A Multi-Retriever RAG Approach with LLMs**
  - **tags:** [nlp], [question answering], [Retrieval-Augmented Generation (RAG), SecBERT, financial numerical reasoning, multi-retriever, few-shot learning]
  - **authors:** Yukun Zhang, Stefan Elbl Droguett, Samyak Jain
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2512.23848
  - **contributions:** 1. Proposed a multi-retriever RAG system that retrieves both external domain knowledge (e.g., financial definitions) and internal question contexts to improve financial QA. 2. Demonstrated that domain-specific training with the SecBERT encoder significantly boosts performance, allowing a neural symbolic model to surpass a strong baseline. 3. Showed that a prompt-based LLM generator achieves state-of-the-art performance with a &gt;7% improvement, highlighting the enhanced few-shot numerical reasoning of latest LLMs and the trade-off between hallucination and external knowledge gains.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de021f75daa09442db831a9d2d84064bf5381a47f4cb0fc792e2cfd3bfbd128b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses errors in financial numerical QA by proposing a multi-retriever RAG system that retrieves external financial knowledge and internal context. The best model, using domain-specific training and a prompt-based LLM, achieves state-of-the-art results, though still below human expert performance, and reveals a trade-off between hallucination and knowledge gains.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Integrating Domain Knowledge for Financial QA<br>金融QA领域知识集成] --> B[Problem: Errors in financial numerical QA due to lack of domain knowledge<br>核心问题: 金融数值QA因缺乏领域知识出错]
        A --> C[Method: Multi-retriever RAG system with external/internal retrieval<br>主要方法: 多检索器RAG系统]
        A --> D[Results: SOTA performance, domain-specific training effective, trade-off analyzed<br>关键结果: SOTA性能, 领域训练有效, 权衡分析]
    ```

- **[arXiv260101] Networked Markets, Fragmented Data: Adaptive Graph Learning for Customer Risk Analytics and Policy Design**
  - **tags:** [mlsys], [federated learning], [federated graph neural network, cross-bank Personalized PageRank, hierarchical reinforcement learning]
  - **authors:** Lecheng Zheng, Jian Ni, Chris Zobel, John R Birge
  - **institution:** Virginia Tech, University of Chicago
  - **link:** https://arxiv.org/pdf/2512.24487
  - **contributions:** 1. A federated graph neural network framework for collaborative customer behavior modeling across competing financial institutions without sharing raw data. 2. Introduction of cross-bank Personalized PageRank for identifying coordinated behavioral clusters and providing interpretable network segmentation. 3. A hierarchical reinforcement learning mechanism for optimizing dynamic intervention targeting policies to balance risk prevention, customer friction, and operational costs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c47cc80a0132ed420b5c61d870561d1aa347aadfb05091a6bcecd09c9007954d_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes an integrated framework combining federated graph learning and reinforcement learning to address customer risk analytics in fragmented financial markets. The method enables collaborative modeling across institutions and optimizes intervention policies, significantly improving fraud detection rates and loss prevention compared to isolated or rule-based approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Networked Markets, Fragmented Data: Adaptive Graph Learning for Customer Risk Analytics and Policy Design"]
        Root --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["数据孤岛/Data Silos"]
        Problem --> P2["类别不平衡/Class Imbalance"]
        Problem --> P3["次优策略/Suboptimal Policies"]
        Method --> M1["联邦图神经网络/Federated GNN"]
        Method --> M2["跨银行个性化PageRank/Cross-bank PPR"]
        Method --> M3["分层强化学习/Hierarchical RL"]
        Results --> R1["降低错误率/Reduced Error Rates"]
        Results --> R2["提升损失预防/Improved Loss Prevention"]
        Results --> R3["市场特定阈值/Market-specific Thresholds"]
    ```

- **[arXiv260101] A Scalable Framework for logP Prediction: From Terabyte-Scale Data Integration to Interpretable Ensemble Modeling**
  - **tags:** [mlsys], [cluster infrastructure], [byte-offset indexing, ensemble modeling, SHAP analysis, heteroskedasticity, stratified modeling]
  - **authors:** Malikussaid, Septian Caesar Floresko, Ade Romadhony, Isman Kurniawan, Warih Maharani, Hilal Hudan Nuha
  - **institution:** Telkom University
  - **link:** https://arxiv.org/pdf/2512.24643
  - **contributions:** 1. Developed a novel computational infrastructure for terabyte-scale data integration, achieving a 740-fold speedup in processing time using a byte-offset indexing architecture. 2. Conducted a comprehensive analysis revealing the multivariate nature of lipophilicity, identifying molecular weight as the most important global predictor via SHAP analysis, despite its weak bivariate correlation. 3. Proposed and validated a stratified modeling strategy (specialized models for drug-like vs. extreme molecules) that achieved optimal predictive performance, demonstrating the competitiveness of well-curated descriptor-based ensemble models with graph neural networks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad416775f59ba17a28f8c4aa4f177b114e9e8b7b5d9ab0210d586ba595ee51e6_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a scalable framework for predicting molecular lipophilicity (logP). It introduces a high-performance data integration infrastructure and employs tree-based ensemble models with a stratified strategy, achieving robust prediction accuracy and providing insights into key molecular descriptors. The work shows that carefully engineered traditional machine learning models can remain competitive with advanced neural architectures for this task.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Scalable Framework for logP Prediction<br>可扩展的logP预测框架"] --> Problem["核心问题/Problem<br>Accurate, scalable logP prediction for drug discovery<br>药物发现中准确、可扩展的logP预测"]
        Root --> Method["主要方法/Method<br>Byte-offset indexing & stratified ensemble modeling<br>字节偏移索引与分层集成建模"]
        Root --> Results["关键结果/Results<br>740x speedup, robust models competitive with GNNs<br>740倍加速，模型性能与图神经网络相当"]
    ```

- **[arXiv260101] FinMMDocR: Benchmarking Financial Multimodal Reasoning with Scenario Awareness, Document Understanding, and Multi-Step Computation**
  - **tags:** [ai], [multimodal reasoning], [multimodal large language models, financial numerical reasoning, retrieval-augmented generation, benchmark, scenario awareness]
  - **authors:** Zichen Tang, Haihong E, Rongjin Li, Jiacheng Liu, Linwei Jia, Zhuodi Hao, Zhongjun Yang, Yuanze Li, Haolin Tian, Xinyi Hu, Peizhi Zhao, Yuan Liu, Zhengyu Wang, Xianghe Wang, Yiling Huang, Xueyuan Lin, Ruofei Bai, Zijian Xie, Qian Huang, Ruining Cao, Haocheng Gao
  - **institution:** Beijing University of Posts and Telecommunications, Hithink RoyalFlush Information Network Co., Ltd.
  - **link:** https://arxiv.org/pdf/2512.24903
  - **code:** https://bupt-reasoning-lab.github.io/FinMMDocR
  - **contributions:** 1. Introduces scenario awareness with 12 types of implicit financial scenarios integrated into 57.9% of problems. 2. Provides extensive document understanding with 837 bilingual documents averaging 50.8 pages across 9 types. 3. Requires complex multi-step computation averaging 11 reasoning steps, with 65% of problems needing cross-page evidence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a504876f4f69142bef32716f3ea6e7e385402763fd546c94f689c9b33389ebe8_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces FinMMDocR, a bilingual multimodal benchmark designed to evaluate MLLMs on complex, real-world financial numerical reasoning. It challenges models with scenario-aware problems, long documents, and multi-step computations. The best-performing model achieved only 58.0% accuracy, highlighting the difficulty of the benchmark and its potential to drive improvements in MLLMs and reasoning methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FinMMDocR] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[评估MLLMs在真实世界金融数值推理上的表现/Evaluating MLLMs on Real-World Financial Numerical Reasoning]
        C --> C1[构建包含场景感知、文档理解、多步计算的基准/Building a Benchmark with Scenario Awareness, Document Understanding, Multi-Step Computation]
        D --> D1[最佳模型准确率仅为58.0%/Best Model Accuracy is Only 58.0%]
        D --> D2[RAG方法表现差异显著/Significant Performance Variations in RAG Methods]
    ```

- **[arXiv260101] Generative AI-enhanced Sector-based Investment Portfolio Construction**
  - **tags:** [ai], [quantitative finance], [portfolio optimization, large language models, sector-based investment, Sharpe ratio, regime shift]
  - **authors:** Alina Voronina, Oleksandr Romanko, Ruiwen Cao, Roy H. Kwon, Rafael Mendoza-Arriaga
  - **institution:** Ukrainian Catholic University, SS&C Algorithmics, University of Toronto, Hong Kong Polytechnic University
  - **link:** https://arxiv.org/pdf/2512.24526
  - **contributions:** 1. Conducts a multi-model, cross-provider evaluation of LLMs (OpenAI, Google, Anthropic, DeepSeek, xAI) for stock selection in quantitative portfolio construction. 2. Demonstrates a strong temporal dependence in LLM portfolio performance, showing outperformance in stable markets but underperformance in volatile periods. 3. Proposes and validates a hybrid framework that improves performance and consistency by combining LLM-based stock selection with classical portfolio optimization techniques.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76999779560abd5e04b9d83f5cf53223a1c444ffacf2142f6df9f0e236e87dd0_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates using LLMs from multiple providers to select and weight stocks for sector-based portfolios. The study finds that while LLM-weighted portfolios can outperform sector indices in stable markets, they struggle during volatile periods; however, combining LLM selection with traditional optimization improves outcomes. The results highlight the potential and current limitations of LLMs in investment management, advocating for hybrid AI-quantitative frameworks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Generative AI-enhanced Sector-based Investment Portfolio Construction] --> B
        A --> C
        A --> D
        B[核心问题/Problem: How can LLMs be applied to quantitative sector-based portfolio construction?]
        C[主要方法/Method: Prompt LLMs to select/weight stocks, combine with classical portfolio optimization, evaluate across stable and volatile periods.]
        D[关键结果/Results: LLM performance is market-dependent; hybrid frameworks (LLM + optimization) improve performance and consistency.]
    ```

- **[arXiv260101] Advances in Agentic AI: Back to the Future**
  - **tags:** [mlsys], [agent system], [Agentic AI, Algorithmization, M1 (first Machine in Machine Learning), M2 (second Machine in Machine Learning), Strategies-based Agentic AI]
  - **authors:** Sergio Alvarez-Telena, Marta Diez-Fernandez
  - **institution:** University College London, SciTheWorld
  - **link:** https://arxiv.org/pdf/2512.24856
  - **contributions:** 1. Proposes precise definitions and a structured analytical framework for Agentic AI and its convergence with Algorithmization. 2. Introduces and distinguishes the concepts of the first Machine in Machine Learning (M1) as the platform for LLM-based Agentic AI and the second Machine (M2) as the architectural prerequisite for production-grade B2B transformation. 3. Provides conceptual and technical insight into what is claimed to be the first fully realized implementation of an M2 system and outlines a forward-looking research agenda.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/840ae0fbf1973bad5d93eb708489774eab0a0df7bdc273f111d764666bd471bc_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the fragmented discourse around Agentic AI by proposing a clarifying framework and distinguishing between two key architectural concepts: M1 for current LLM-based systems and M2 for future, robust B2B transformation. It positions M2, or Strategies-based Agentic AI, as the necessary evolution to overcome operational barriers. The conclusion outlines a research agenda for the next two decades based on the authors' prior work in Algorithmization.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Advances in Agentic AI: Back to the Future<br/>Agentic AI进展：回到未来"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["核心问题/Problem<br/>Fragmented discourse on Agentic AI<br/>Agentic AI领域论述碎片化"] --> P1["缺乏清晰定义/Lack of clear definitions"]
        Problem --> P2["需要B2B转型框架/Need for B2B transformation framework"]
    
        Method["主要方法/Method<br/>Propose analytical framework<br/>提出分析框架"] --> M1["区分M1与M2/Distinguish M1 & M2"]
        M1 --> M1a["M1: LLM-based Agentic AI platform<br/>M1: 基于LLM的Agentic AI平台"]
        M1 --> M1b["M2: Strategies-based Agentic AI<br/>M2: 基于策略的Agentic AI"]
        Method --> M2["回顾算法化工作/Review Algorithmization work"]
    
        Results["关键结果/Results<br/>Framework & Future Agenda<br/>框架与未来议程"] --> R1["提供清晰定义与框架/Provide clear definitions & framework"]
        Results --> R2["介绍首个M2实现/Introduce first M2 implementation"]
        Results --> R3["提出未来20年议程/Propose 20-year future agenda"]
    ```
