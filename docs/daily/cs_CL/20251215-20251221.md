# 20251215-20251221 (cs.CL)

## 2025-12-18

- **[arXiv251218] LLM as a Neural Architect: Controlled Generation of Image Captioning Models Under Strict API Contracts**
  - **tags:** [mlsys], [multi-modal training], [neural architecture search, large language models, image captioning, prompt engineering, CNN encoder, LSTM, GRU, Transformer, BLEU-4]
  - **authors:** Krunal Jesani, Dmitry Ignatov, Radu Timofte
  - **institution:** University of Würzburg
  - **link:** https://arxiv.org/pdf/2512.14706
  - **Simple LLM Summary:** This paper presents NN-Caption, a pipeline that uses a large language model (LLM) to automatically generate runnable image-captioning model architectures by composing CNN encoders and sequence decoders under a strict API. The method successfully produced dozens of models, with over half training successfully, demonstrating the promise of LLM-guided neural architecture search while highlighting challenges like code hallucinations.

- **[arXiv251218] SepsisSuite: Beyond Risk Stratification -- A Comparative Analysis of Deep Fusion vs. Expert Stacking for Prescriptive Sepsis AI**
  - **tags:** [mlsys], [multi-modal training], [Mixture-of-Experts (MoE), Hierarchical Gated Attention Network, CatBoost meta-learner, multimodal fusion, deep fusion, expert stacking, Quad-Modal Ensemble]
  - **authors:** Ryan Cartularo
  - **institution:** The University of Texas at Austin
  - **link:** https://arxiv.org/pdf/2512.14712
  - **Simple LLM Summary:** This paper compares two multimodal AI architectures for sepsis prediction and antibiotic selection: a complex end-to-end deep fusion model (SepsisFusionFormer) and a leaner, context-aware Mixture-of-Experts stacking model (SepsisLateFusion). The main conclusion is that for this high-stakes, data-sparse clinical domain, the interpretable expert stacking approach, which treats modalities as orthogonal experts and uses a CatBoost meta-learner, significantly outperformed the deep fusion model, achieving state-of-the-art predictive performance and enabling a prescriptive window for intervention.

- **[arXiv251218] SoMe: A Realistic Benchmark for LLM-based Social Media Agents**
  - **tags:** [mlsys], [others], [SoMe benchmark, social media agents, LLM-based agents, agent tools, task evaluation, quantitative analysis, qualitative analysis]
  - **authors:** Dizhan Xue, Jing Cui, Shengsheng Qian, Chuanrui Hu, Changsheng Xu
  - **institution:** Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Tianjin University of Technology; Nanjing University of Posts and Telecommunications; Peng Cheng Laboratory
  - **link:** https://arxiv.org/pdf/2512.14720
  - **Simple LLM Summary:** This paper introduces SoMe, a comprehensive benchmark for evaluating LLM-based social media agents across diverse tasks using real social media data and agent tools. The evaluation shows that current LLMs, both closed and open-source, perform unsatisfactorily on these realistic social media agent tasks. SoMe serves as a challenging testbed to advance future social media agent development.

- **[arXiv251218] NoveltyRank: Estimating Conceptual Novelty of AI Papers**
  - **tags:** [ai], [natural language processing], [binary classification, pairwise comparison, semantic similarity, SPECTER2, fine-tuning, Qwen3-4B-Instruct-2507, SciBERT]
  - **authors:** Zhengxu Yan, Han Li, Yuming Feng
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2512.14738
  - **Simple LLM Summary:** The paper proposes NoveltyRank, a model that estimates the conceptual novelty of AI papers using title, abstract, and semantic similarity to prior literature, evaluated through binary classification and pairwise comparison tasks. It fine-tunes Qwen3-4B-Instruct-2507 and SciBERT, benchmarking against GPT-5.1, and finds that task formulation and modeling choices significantly impact performance, with the implementation made publicly available.

- **[arXiv251218] Revisiting the Reliability of Language Models in Instruction-Following**
  - **tags:** [ai], [llm evaluation], [instruction-following, reliability, data augmentation, benchmark, IFEval++, reliable@k]
  - **authors:** Jianshuo Dong, Yutong Zhang, Yan Liu, Zhenyu Zhong, Tao Wei, Chao Zhang, Han Qiu
  - **institution:** Tsinghua University, Ant Group
  - **link:** https://arxiv.org/pdf/2512.14754
  - **Simple LLM Summary:** The paper introduces a new metric, reliable@k, and an automated data augmentation pipeline to generate "cousin prompts" for evaluating nuance-oriented reliability in LLMs, constructing the IFEval++ benchmark. It finds that current LLMs show significant performance drops (up to 61.8%) with nuanced prompt variations, highlighting a crucial gap in real-world reliability.

- **[arXiv251218] Incentives or Ontology? A Structural Rebuttal to OpenAI's Hallucination Thesis**
  - **tags:** [ai], [large language models], [transformer architecture, structural hallucination, Licensing Oracle, hybrid systems, statistical ontology]
  - **authors:** Richard Ackermann, Simeon Emanuilov
  - **institution:** RA Software, Sofia University “St. Kliment Ohridski”
  - **link:** https://arxiv.org/pdf/2512.14801
  - **Simple LLM Summary:** The paper argues that hallucination in LLMs is an architectural inevitability of transformers, which model token co-occurrence rather than the world, and demonstrates through a Licensing Oracle that external truth-validation modules are required for reliable abstention. It concludes that hallucination is a structural property, not a correctable incentive problem, necessitating hybrid systems to separate linguistic fluency from epistemic responsibility.

- **[arXiv251218] Audio MultiChallenge: A Multi-Turn Evaluation of Spoken Dialogue Systems on Natural Human Interaction**
  - **tags:** [mlsys], [multi-modal inference], [end-to-end spoken dialogue systems, audio language models, multi-turn evaluation, speech-to-speech, audio-native benchmark, inference memory, instruction retention, self coherence, voice editing]
  - **authors:** Advait Gosai, Tyler Vuong, Utkarsh Tyagi, Steven Li, Wenjia You, Miheer Bavare, Arda Uçar, Zhongwang Fang, Brian Jang, Bing Liu, Yunzhong He
  - **institution:** Scale AI
  - **link:** https://arxiv.org/pdf/2512.14865
  - **Simple LLM Summary:** The paper introduces Audio MultiChallenge, a benchmark for evaluating end-to-end spoken dialogue systems on natural, multi-turn conversations. It extends a text-based framework with a new "Voice Editing" axis and audio-specific augmentations, using a hybrid pipeline to curate conversations with natural disfluencies. The evaluation shows even top models like Gemini 3 Pro Preview struggle, highlighting difficulties in tracking audio edits, cues, and long context in spoken dialogue.

- **[arXiv251218] Task Matrices: Linear Maps for Cross-Model Finetuning Transfer**
  - **tags:** [ai], [model adaptation], [task matrix, linear transformation, finetuning, linear probe, embedding space]
  - **authors:** Darrin O' Brien, Dhikshith Gajulapalli, Eric Xia
  - **institution:** Algoverse AI Research, Brown University
  - **link:** https://arxiv.org/pdf/2512.14880
  - **Simple LLM Summary:** This paper introduces the concept of a "task matrix," a linear transformation that maps a base model's embedding state to a finetuned model's state. It demonstrates that applying this matrix to a base model can outperform linear probes and sometimes approach full finetuning performance across vision and text models on various datasets. The results validate the existence of cross-layer linear encodings between pretrained and finetuned architectures.

- **[arXiv251218] Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media**
  - **tags:** [mlsys], [llm inference], [large language models, knowledge graphs, viewpoint classification, fine-tuning, wikidata, semantic enrichment]
  - **authors:** Massimiliano Fadda, Enrico Motta, Francesco Osborne, Diego Reforgiato Recupero, Angelo Salatino
  - **institution:** University of Cagliari, The Open University
  - **link:** https://arxiv.org/pdf/2512.14887
  - **Simple LLM Summary:** This paper improves a pipeline for analyzing political viewpoints in news by fine-tuning Large Language Models for classification and enriching claim representations with semantic actor descriptions from Wikidata. The integrated approach, evaluated on UK immigration debate data, shows that combining fine-tuned LLMs with knowledge graph context yields the best performance, particularly with models capable of processing long inputs.

- **[arXiv251218] DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline**
  - **tags:** [mlsys], [llm inference], [retrieval-augmented generation, structured drug knowledge, pharmacy question-answering, external knowledge integration]
  - **authors:** Houman Kazemzadeh, Kiarash Mokhtari Dizaji, Seyed Reza Tavakoli, Farbod Davoodi, MohammadReza KarimiNejad, Parham Abed Azad, Ali Sabzi, Armin Khosravi, Siavash Ahmadi, Mohammad Hossein Rohban, Glolamali Aminian, Tahereh Javaheri
  - **institution:** Tehran University of Medical Sciences, Sharif University of Technology, Amir Kabir University of Technology, Missouri University of Science and Technology, The Alan Turing Institute, Boston University
  - **link:** https://arxiv.org/pdf/2512.14896
  - **Simple LLM Summary:** The paper introduces DrugRAG, a three-step retrieval-augmented generation pipeline that integrates external structured drug knowledge into LLM prompts to improve accuracy on pharmacy QA tasks. It demonstrates that this external method enhances performance across multiple models without modifying their architecture, providing a practical approach for evidence-based AI in pharmacy.

- **[arXiv251218] Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models**
  - **tags:** [mlsys], [multi-modal training], [LoRA, dataset translation, visual question answering, instruction tuning, parameter-efficient fine-tuning]
  - **authors:** George-Andrei Dima, Dumitru-Clementin Cercel
  - **institution:** National University of Science and Technology POLITEHNICA Bucharest
  - **link:** https://arxiv.org/pdf/2512.14926
  - **Simple LLM Summary:** This paper introduces a parameter-efficient method for adapting vision-language models to Romanian by translating the Flickr30k dataset and generating QA pairs, then fine-tuning models like LLaMA, LLaVA, and Qwen2 using LoRA. The results show significant improvements in Romanian visual QA and image captioning, with the Qwen2-VL-RoVQA model achieving the best performance and reduced grammatical errors.

- **[arXiv251218] Cross-Tokenizer Likelihood Scoring Algorithms for Language Model Distillation**
  - **tags:** [mlsys], [llm training], [knowledge distillation, byte-pair encoding, cross-tokenizer likelihood scoring, vocabulary misalignment, next-token probability]
  - **authors:** Buu Phan, Ashish Khisti, Karen Ullrich
  - **institution:** University of Toronto, Meta AI
  - **link:** https://arxiv.org/pdf/2512.14954
  - **Simple LLM Summary:** This paper introduces a method for cross-tokenizer likelihood scoring to enable knowledge distillation between language models with different vocabularies. It leverages the recursive structure of Byte-Pair Encoding to compute exact or approximate next-token probabilities. The approach reduces memory footprint and improves model performance on tasks like mathematical reasoning compared to baseline distillation methods.

- **[arXiv251218] Prompt Repetition Improves Non-Reasoning LLMs**
  - **tags:** [mlsys], [llm inference], [prompt repetition, causal language model, attention mechanism, non-reasoning tasks]
  - **authors:** Yaniv Leviathan, Matan Kalman, Yossi Matias
  - **institution:** Google Research
  - **link:** https://arxiv.org/pdf/2512.14982
  - **Simple LLM Summary:** The paper proposes a simple method of repeating the input prompt to improve the performance of LLMs on non-reasoning tasks. This technique allows all prompt tokens to attend to each other within the causal attention mechanism, addressing order sensitivity. The authors demonstrate that this method boosts accuracy for models like Gemini, GPT, Claude, and Deepseek without increasing output length or latency.

- **[arXiv251218] Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams**
  - **tags:** [mlsys], [multi-modal inference], [multimodal reasoning, chain-of-thought prompting, ablation studies, occlusion-based interpretability, benchmark evaluation, modality fusion]
  - **authors:** Yiming Cui, Xin Yao, Yuxuan Qin, Xin Li, Shijin Wang, Guoping Hu
  - **institution:** State Key Laboratory of Cognitive Intelligence, iFLYTEK AI Research
  - **link:** https://arxiv.org/pdf/2512.14989
  - **Simple LLM Summary:** This paper systematically evaluates 40 multimodal large language models on a benchmark of chemistry Olympiad questions requiring visual and textual reasoning. The core method involves using chain-of-thought prompting and interpretability techniques like ablation and occlusion. The main conclusion is that current models struggle with modality fusion, but chain-of-thought improves both accuracy and visual grounding, revealing critical limitations in scientific reasoning.

- **[arXiv251218] DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding**
  - **tags:** [mlsys], [post-training], [Process Reward Model (PRM), Chain-of-Function, meta-learning, label correction, bi-level optimization, test-time scaling, LiveCodeBench]
  - **authors:** Ruiyi Zhang, Peijia Qin, Qi Cao, Pengtao Xie
  - **institution:** University of California, San Diego
  - **link:** https://arxiv.org/pdf/2512.15000
  - **Simple LLM Summary:** The paper proposes DreamPRM-Code, a process reward model for coding that treats functions as reasoning steps using a Chain-of-Function strategy and employs a meta-learning-based label correction mechanism to refine noisy intermediate training labels. It achieves state-of-the-art performance on LiveCodeBench, surpassing OpenAI o4-mini.

- **[arXiv251218] HERO: Hierarchical Traversable 3D Scene Graphs for Embodied Navigation Among Movable Obstacles**
  - **tags:** [ai], [embodied navigation], [3D scene graphs, hierarchical traversable graphs, movable obstacles, path planning, scene understanding]
  - **authors:** Yunheng Wang, Yixiao Feng, Yuetong Fang, Shuning Zhang, Tan Jing, Jian Li, Xiangrui Jiang, Renjing Xu
  - **institution:** The Hong Kong University of Science and Technology (Guangzhou)
  - **link:** https://arxiv.org/pdf/2512.15047
  - **Simple LLM Summary:** The paper proposes HERO, a framework for building Hierarchical Traversable 3D Scene Graphs that model movable obstacles as pathways by capturing their interactivity and semantics. This redefinition of traversability allows for more efficient navigation planning in obstructed environments. The results show HERO significantly reduces path length in partially obstructed scenes and increases success rate in fully obstructed ones compared to baselines.

- **[arXiv251218] The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops**
  - **tags:** [mlsys], [llm inference], [Meta-Prompting Protocol, Adversarial Trinity, DSPy, TextGrad, textual gradients, semantic computation graph]
  - **authors:** Fanzhe Fu
  - **institution:** Zhejiang University
  - **link:** https://arxiv.org/pdf/2512.15053
  - **Simple LLM Summary:** The paper introduces the Meta-Prompting Protocol, a framework that formalizes LLM orchestration as a programmable system using an adversarial topology (Generator, Auditor, Optimizer) to treat prompts as differentiable variables. It leverages textual critiques as gradients within a semantic computation graph to mitigate hallucination and improve reliability. The authors demonstrate its theoretical viability with tools like DSPy and TextGrad, proposing a foundation for deterministic "Observable Software Engineering" for probabilistic models.

- **[arXiv251218] SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification**
  - **tags:** [mlsys], [multi-modal inference], [neuron-level intervention, expertise-weighted soft suppression, MM-TOXIC-QA, white-box detoxification, SGM*]
  - **authors:** Hongbo Wang, MaungMaung AprilPyone, Isao Echizen
  - **institution:** The University of Tokyo, National Institute of Informatics
  - **link:** https://arxiv.org/pdf/2512.15052
  - **Simple LLM Summary:** The paper proposes SGM, a neuron-level intervention method that selectively recalibrates toxic expert neurons in multimodal large language models (MLLMs) using expertise-weighted soft suppression to reduce harmful outputs. Experiments show SGM significantly cuts toxicity rates from 48.2% to 2.5% while preserving model fluency and reasoning, and it can be combined with other methods for stronger safety.

- **[arXiv251218] The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems**
  - **tags:** [ai], [retrieval-augmented generation], [conformal prediction, semantic similarity, natural language inference, hallucination detection, text embeddings]
  - **authors:** Debu Sinha
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2512.15068
  - **Simple LLM Summary:** The paper applies conformal prediction to provide statistical guarantees for hallucination detection in RAG systems, rigorously evaluating embedding-based methods. It finds that while these methods work on synthetic data, they fail on real benchmarks due to the "semantic illusion," where plausible hallucinations remain semantically similar to source documents. The study concludes that embedding-based detection is insufficient for production, as reasoning-based methods like GPT-4 as a judge perform significantly better.

- **[arXiv251218] Quantifying Return on Security Controls in LLM Systems**
  - **tags:** [mlsys], [llm inference], [retrieval-augmented generation (RAG), Monte Carlo simulation, loss exceedance curves, Laplace's Rule of Succession, adversarial probing, Garak, attribute-based access control (ABAC), named entity recognition (NER) redaction, NeMo Guardrails]
  - **authors:** Richard Helder Moulton, Austin O'Brien, John D. Hastings
  - **institution:** Dakota State University
  - **link:** https://arxiv.org/pdf/2512.15081
  - **Simple LLM Summary:** This paper introduces a framework to quantify the financial return on security controls for LLM systems by simulating attacks on a RAG service, estimating attack success probabilities, and modeling potential losses with Monte Carlo methods. The main conclusion is that controls like ABAC and NER redaction significantly reduce expected financial losses and offer high return-on-control, whereas NeMo Guardrails provides minimal benefit in the tested scenarios.

- **[arXiv251218] From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?**
  - **tags:** [ai], [interpretability], [sparse autoencoders, sparse probes, concept disentanglement, steering experiments, multi-concept evaluation]
  - **authors:** Aaron Mueller, Andrew Lee, Shruti Joshi, Ekdeep Singh Lubana, Dhanya Sridhar, Patrik Reizinger
  - **institution:** Boston University, Harvard University, Mila – Quebec AI Institute, Goodfire, University of Tübingen
  - **link:** https://arxiv.org/pdf/2512.15134
  - **Simple LLM Summary:** The paper proposes a multi-concept evaluation framework to test whether interpretability methods like sparse autoencoders and sparse probes recover disentangled and independently manipulable concept representations. It finds that features often correspond to single concepts, but concepts are distributed across many features, and steering one feature typically affects multiple concepts, indicating a lack of true independence. The results highlight that correlational metrics are insufficient for proving disentanglement and underscore the need for compositional evaluations in interpretability research.

- **[arXiv251218] MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers**
  - **tags:** [mlsys], [llm inference], [MCP (Model Context Protocol), safety benchmark, multi-turn evaluation, multi-server workflows, attack taxonomy, agentic systems]
  - **authors:** Xuanjun Zong, Zhiqi Shen, Lei Wang, Yunshi Lan, Chao Yang
  - **institution:** East China Normal University, National University of Singapore, Singapore Management University, Shanghai AI Laboratory
  - **link:** https://arxiv.org/pdf/2512.15163
  - **Simple LLM Summary:** This paper introduces MCP-SafetyBench, a benchmark built on real Model Context Protocol servers to evaluate the safety of LLMs operating as agents across tools and services. It systematically tests models on multi-step, multi-server tasks across five domains, revealing significant safety vulnerabilities that escalate with task complexity. The results highlight the urgent need for improved defenses in real-world LLM agent deployments.

- **[arXiv251218] RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA**
  - **tags:** [ai], [knowledge-aware question answering], [knowledge graph, chain-of-thought, few-shot in-context learning, relation-driven adaptive hop-count selection, path guidance]
  - **authors:** Chao Zhang, Minghan Li, Tianrui Lv, Guodong Zhou
  - **institution:** Soochow University
  - **link:** https://arxiv.org/pdf/2512.15219
  - **Simple LLM Summary:** This paper proposes RFKG-CoT, a method that enhances knowledge-aware question answering by dynamically selecting reasoning steps in a knowledge graph based on relations and using few-shot examples to guide large language models in understanding reasoning paths. It improves answer accuracy over previous methods by making the integration of knowledge graph evidence more adaptive and guided. Experiments show significant accuracy gains on multiple benchmarks.

- **[arXiv251218] Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024**
  - **tags:** [mlsys], [llm training], [fine-tuning, LoRA, zero-shot prompting, few-shot prompting, supervised fine-tuning, transformer models]
  - **authors:** Yash Bhaskar, Parameswari Krishnamurthy
  - **institution:** IIIT Hyderabad
  - **link:** https://arxiv.org/pdf/2512.15226
  - **Simple LLM Summary:** This paper explores various methods for low-resource Indic language translation, including fine-tuning models like mT5 and IndicBart, using LoRA with IndicTrans2 and Llama 3, and prompting LLMs like Llama 3 and Mixtral. The results highlight the challenges of data scarcity and demonstrate the potential of fine-tuned large language models for these translation tasks.

- **[arXiv251218] Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning**
  - **tags:** [mlsys], [llm training], [reinforcement learning with verifiable rewards, progressive prefix-token policy optimization, beginning lock-in effect, prefix optimization, continuation accumulated reward]
  - **authors:** Yiliu Sun, Zicheng Zhao, Yang Wei, Yanfang Zhang, Chen Gong
  - **institution:** Nanjing University of Science and Technology, North University of China, Shanghai Jiao Tong University
  - **link:** https://arxiv.org/pdf/2512.15274
  - **Simple LLM Summary:** This paper proposes Progressive Prefix-token Policy Optimization (PPPO), a reinforcement learning method that focuses on optimizing the initial prefix tokens of an LLM's reasoning output, based on the identified Beginning Lock-in Effect. It introduces strategies like Progressive Prefix Retention and Continuation Accumulated Reward to improve training efficiency. The method achieves significant accuracy improvements on reasoning tasks while using far fewer training tokens compared to standard approaches.

- **[arXiv251218] ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I**
  - **tags:** [mlsys], [multi-modal inference], [multimodal reasoning, perception-cognition gap, calculation-conceptualization discrepancy, process hallucination, OCR, AI-resistant questions]
  - **authors:** Seok-Hyun Ga, Chun-Yen Chang
  - **institution:** Institute for Research Excellence in Learning Sciences, National Taiwan Normal University, Seoul National University, Universitas Negeri Malang
  - **link:** https://arxiv.org/pdf/2512.15298
  - **Simple LLM Summary:** This study evaluates the multimodal scientific reasoning of LLMs like GPT-4o and Gemini on the Korean CSAT Earth Science I exam under different input conditions. It finds that models suffer from fundamental cognitive flaws, such as a perception-cognition gap and calculation-conceptualization discrepancy, even with optimized inputs. The paper concludes by suggesting these vulnerabilities can be exploited to design AI-resistant assessment questions to ensure academic integrity.

- **[arXiv251218] Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies**
  - **tags:** [ai], [scientific information extraction], [zero-shot prompting, few-shot prompting, event-specific prompting, reflection-based prompting, in-context learning, event extraction, argument extraction]
  - **authors:** Charan Prakash Rathore, Saumi Ray, Dhruv Kumar
  - **institution:** Birla Institute of Technology and Science, Pilani
  - **link:** https://arxiv.org/pdf/2512.15312
  - **Simple LLM Summary:** This paper systematically evaluates six state-of-the-art LLMs using four prompting strategies (zero-shot, few-shot, event-specific, reflection-based) for extracting structured event and argument information from zeolite synthesis procedures. It finds that while LLMs achieve strong performance on high-level event classification, they show modest results on fine-grained parameter extraction, with advanced prompting offering minimal gains over zero-shot approaches. The conclusion is that precise scientific information extraction requires domain-adapted models, as current LLMs have fundamental limitations in capturing synthesis-specific nuances.

- **[arXiv251218] Adversarial versification in portuguese as a jailbreak operator in LLMs**
  - **tags:** [mlsys], [llm inference], [adversarial versification, poetry jailbreak, guardrail vulnerabilities, semiotic-formal variation, latent region displacement]
  - **authors:** Joao Queiroz
  - **institution:** Federal University of Juiz de Fora
  - **link:** https://arxiv.org/pdf/2512.15353
  - **Simple LLM Summary:** The paper investigates using versification, or rewriting prompts as poetry, as a method to bypass safety guardrails in aligned large language models. It concludes that this structural adversarial technique exploits a model's over-reliance on surface patterns, causing significant safety failures, and highlights a critical research gap for Portuguese due to its linguistic complexity.

- **[arXiv251218] Emotion Recognition in Signers**
  - **tags:** [mlsys], [multi-modal training], [cross-lingual transfer, temporal segment selection, hand motion features, textual emotion recognition, facial expression analysis]
  - **authors:** Kotaro Funakoshi, Yaoxiong Zhu
  - **institution:** Institute of Science Tokyo
  - **link:** https://arxiv.org/pdf/2512.15376
  - **Simple LLM Summary:** This paper introduces a new dataset for emotion recognition in Japanese Sign Language and addresses the challenges of overlapping grammatical/affective expressions and data scarcity using cross-lingual transfer from textual emotion recognition in spoken language. The authors demonstrate that selecting specific temporal segments and incorporating hand motion features significantly improves emotion recognition performance in signers, establishing a stronger baseline than spoken language LLMs.

- **[arXiv251218] Tracking Temporal Dynamics of Vector Sets with Gaussian Process**
  - **tags:** [ai], [temporal analysis], [Gaussian Process, Random Fourier Features, vector sets, temporal dynamics, low-dimensional visualization]
  - **authors:** Taichi Aida, Mamoru Komachi, Toshinobu Ogiso, Hiroya Takamura, Daichi Mochihashi
  - **institution:** Tokyo Metropolitan University, Hitotsubashi University, National Institute for Japanese Language and Linguistics, National Institute of Advanced Industrial Science and Technology, The Institute of Statistical Mathematics
  - **link:** https://arxiv.org/pdf/2512.15538
  - **Simple LLM Summary:** The paper proposes a method to model time-varying vector sets using infinite-dimensional Gaussian Processes, approximating the latent function with Random Fourier Features to obtain compact, comparable representations over time. It demonstrates effectiveness in capturing temporal dynamics in crime distributions and word embeddings, providing interpretable, low-dimensional visualizations of structural changes.

- **[arXiv251218] Evaluating Metrics for Safety with LLM-as-Judges**
  - **tags:** [mlsys], [llm inference], [LLM-as-Judges, weighted metrics, confidence thresholds, context sensitivity, safety evaluation, human review]
  - **authors:** Kester Clegg, Richard Hawkins, Ibrahim Habli, Tom Lawton
  - **institution:** University of York, Bradford Royal Infirmary
  - **link:** https://arxiv.org/pdf/2512.15617
  - **Simple LLM Summary:** This paper proposes a safety evaluation method for LLMs in critical applications by focusing on evidence from LLM-as-Judges frameworks. It suggests using a basket of weighted metrics and context-sensitive error severity to lower risk, with low-confidence judgments triggering human review. The main conclusion is that such an approach can enhance the reliability of LLMs in safety-critical information flows.

- **[arXiv251218] How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness**
  - **tags:** [mlsys], [llm training], [Low-Rank Adaptation (LoRA), supervised fine-tuning (SFT), parameter-efficient fine-tuning (PEFT), rank sweep, representational drift, attention patterns]
  - **authors:** Darshita Rathore, Vineet Kumar, Chetna Bansal, Anindya Moitra
  - **institution:** PayPal
  - **link:** https://arxiv.org/pdf/2512.15634
  - **Simple LLM Summary:** This paper comprehensively evaluates the trade-offs between full supervised fine-tuning (SFT) and Low-Rank Adaptation (LoRA) for fine-tuning large language models. It finds that LoRA, especially at specific rank values, can achieve competitive or even superior performance to SFT on reasoning tasks, while also analyzing the structural changes in model representations.

- **[arXiv251218] PPSEBM: An Energy-Based Model with Progressive Parameter Selection for Continual Learning**
  - **tags:** [ai], [continual learning], [energy-based model, progressive parameter selection, pseudo-sample generation, catastrophic forgetting mitigation]
  - **authors:** Xiaodi Li, Dingcheng Li, Rujun Gao, Mahmoud Zamani, Feng Mi, Latifur Khan
  - **institution:** Mayo Clinic, Google, Texas A&M University, The University of Texas at Dallas
  - **link:** https://arxiv.org/pdf/2512.15658
  - **Simple LLM Summary:** The paper introduces PPSEBM, a framework combining an Energy-Based Model with Progressive Parameter Selection to address catastrophic forgetting in continual learning for NLP tasks. It uses task-specific parameters and generates pseudo-samples from prior tasks to retain past knowledge. Experimental results show PPSEBM outperforms state-of-the-art methods in mitigating forgetting.

- **[arXiv251218] Explaining the Reasoning of Large Language Models Using Attribution Graphs**
  - **tags:** [ai], [interpretability], [attribution methods, context attribution, attribution graph, CAGE, faithfulness]
  - **authors:** Chase Walker, Rickard Ewetz
  - **institution:** University of Florida
  - **link:** https://arxiv.org/pdf/2512.15663
  - **Simple LLM Summary:** The paper introduces the CAGE framework, which uses an attribution graph to explain autoregressive LLMs by quantifying how each generated token is influenced by both the prompt and all prior tokens, preserving causality and row stochasticity. This approach improves the faithfulness of context attributions by accounting for inter-generational influences, achieving average gains of up to 40% over existing methods.

- **[arXiv251218] VTCBench: Can Vision-Language Models Understand Long Context with Vision-Text Compression?**
  - **tags:** [mlsys], [multi-modal inference], [vision-text compression, VTCBench, DeepSeek-OCR, Glyph, VTC-Retrieval, VTC-Reasoning, VTC-Memory]
  - **authors:** Hongbo Zhao, Meng Wang, Fei Zhu, Wenzhuo Liu, Bolin Ni, Fanhu Zeng, Gaofeng Meng, Zhaoxiang Zhang
  - **institution:** Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, CAS; Tencent Hunyuan Team
  - **link:** https://arxiv.org/pdf/2512.15649
  - **Simple LLM Summary:** This paper introduces VTCBench, the first benchmark to evaluate Vision-Language Models' ability to understand long context using Vision-Text Compression (VTC), a technique that converts long text into dense 2D images for token efficiency. The study systematically tests models on retrieval, reasoning, and memory tasks with VTC-compressed inputs. The main conclusion is that most VLMs perform poorly on long-context understanding with VTC, despite good OCR decoding, failing to capture long-range associations in the compressed visual context.

- **[arXiv251218] Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers**
  - **tags:** [ai], [llm interpretability], [LatentQA, Activation Oracles, activation analysis, fine-tuning detection, natural language queries]
  - **authors:** Adam Karvonen, James Chua, Clément Dumas, Kit Fraser-Taliente, Subhash Kantamneni, Julian Minder, Euan Ong, Arnab Sen Sharma, Daniel Wen, Owain Evans, Samuel Marks
  - **institution:** MATS, Truthful AI, EPFL, ENS Paris-Saclay, Northeastern University, Anthropic
  - **link:** https://arxiv.org/pdf/2512.15674
  - **Simple LLM Summary:** This paper introduces Activation Oracles, models trained using the LatentQA approach to answer natural language questions about the internal activations of other LLMs. The core finding is that these oracles, especially when trained on diverse datasets, can generalize to out-of-distribution tasks and effectively verbalize hidden information, such as knowledge from fine-tuning, often matching or exceeding prior white-box interpretability methods.

- **[arXiv251218] Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants**
  - **tags:** [mlsys], [post-training], [predictive concept decoder, communication bottleneck, sparse concept list, encoder-decoder, auto-interp score, fine-tuning]
  - **authors:** Vincent Huang, Dami Choi, Daniel D. Johnson, Sarah Schwettmann, Jacob Steinhardt
  - **institution:** Transluce
  - **link:** https://arxiv.org/pdf/2512.15712
  - **Simple LLM Summary:** This paper proposes Predictive Concept Decoders (PCDs), an end-to-end trained architecture where an encoder compresses a model's internal activations into a sparse list of concepts, and a decoder uses this list to answer questions about the model's behavior. The method is pretrained on large datasets and then finetuned, showing that the interpretability and downstream performance of the bottleneck concepts improve with more data.
