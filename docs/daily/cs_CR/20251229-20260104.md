---
slug: /daily/cscr/20251229-20260104
---
# 20251229-20260104 (cs.CR)

## 2025-12-29

- **[arXiv251229] Composition Theorems for f-Differential Privacy**
  - **tags:** [sec], [Differential Privacy], [f-differential privacy, quantitative information flow, composition theorems, Galois connection, trade-off functions]
  - **authors:** Natasha Fernandes, Annabelle McIver, Parastoo Sadeghi
  - **institution:** Macquarie University, UNSW (University of New South Wales)
  - **link:** https://arxiv.org/pdf/2512.21358
  - **contributions:** 1. Establishes an equivalence between f-Differential Privacy (f-DP) and the channel model of Quantitative Information Flow (QIF) via a Galois connection. 2. Derives novel general composition theorems for f-DP enabled by this equivalence. 3. Applies the new composition theorems to analyze privacy amplification mechanisms like sub-sampling and purification, producing new f-DP profiles for these algorithms.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d202b6f3d64108f2672eaab827a63e5c6cfac205fcbbf58e2eb8b75c09924dbe_w640_q70.webp
  - **Simple LLM Summary:** This paper connects the theory of f-Differential Privacy (f-DP) with Quantitative Information Flow (QIF) by showing their equivalence through a Galois connection. This foundational link enables the derivation of new, general composition theorems for f-DP. The authors apply these theorems to analyze complex privacy-enhancing algorithms, such as sub-sampling, yielding improved privacy profiles.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Composition Theorems for f-Differential Privacy] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Need for better composition analysis in complex privacy designs] --> Problem_Sub[子问题/Sub-problem: Relating f-DP to foundational information theory]
        Method[主要方法/Method: Formal equivalence via Galois connection] --> Method_Sub[子方法/Sub-method: Mapping between f-DP trade-off functions and QIF channels]
        Results[关键结果/Results: Novel general composition theorems for f-DP] --> Results_Sub[子结果/Sub-results: Improved f-DP analysis for sub-sampling & purification]
    ```

- **[arXiv251229] Satellite Cybersecurity Across Orbital Altitudes: Analyzing Ground-Based Threats to LEO, MEO, and GEO**
  - **tags:** [sec], [satellite cybersecurity], [Telemetry, Tracking, and Command (TT&C), encryption weaknesses, radio-frequency (RF) links]
  - **authors:** Mark Ballard, Guanqun Song, Ting Zhu
  - **institution:** The Ohio State University
  - **link:** https://arxiv.org/pdf/2512.21367
  - **contributions:** 1. Presents a comparative analysis of satellite cybersecurity threats across LEO, MEO, and GEO orbital regimes, linking orbital altitude to attack feasibility and impact. 2. Synthesizes data from 60 publicly documented security incidents to characterize distinct threat profiles for different orbits (e.g., GEO uplink exposure vs. LEO hardware constraints). 3. Bridges the gap between cybersecurity and space sustainability, arguing that unmitigated cyber vulnerabilities accelerate hardware obsolescence and debris accumulation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes ground-based cybersecurity threats to satellites in different orbital altitudes (LEO, MEO, GEO). By synthesizing data from 60 security incidents and analyzing vulnerability proxies like TT&C anomalies and encryption, it characterizes how altitude dictates distinct threat profiles and concludes that weak encryption and command path irregularities are the most consistent predictors of adversarial success across all orbits.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Satellite Cybersecurity Across Orbital Altitudes] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[轨道高度如何影响卫星网络安全/How orbital altitude dictates satellite cybersecurity]
    C --> C1[分析60起安全事件与漏洞代理/Analyze 60 security incidents & vulnerability proxies]
    D --> D1[不同轨道有独特的威胁特征/Distinct threat profiles per orbit]
    D --> D2[弱加密和指令异常是主要预测因子/Weak encryption & command irregularities are key predictors]
    ```

- **[arXiv251229] Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide**
  - **tags:** [sec], [side-channel analysis], [RISC-V, CVA6, Correlation Power Analysis (CPA), RTL simulation, power side-channel]
  - **authors:** Behnam Farnaghinejad, Antonio Porsia, Annachiara Ruospo, Alessandro Savino, Stefano Di Carlo, Ernesto Sanchez
  - **institution:** Politecnico di Torino
  - **link:** https://arxiv.org/pdf/2512.21362
  - **contributions:** 1. Presents the first side-channel vulnerability evaluation of the CVA6 RISC-V processor core. 2. Demonstrates the application of the VeriSide RTL-level power profiling framework for efficient power trace extraction without waveform files. 3. Shows that Correlation Power Analysis (CPA) on the CVA6 during software-based AES encryption enables key recovery, highlighting the need for early-stage RTL security assessments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f1045d9314e37006547d2c94a7c4490ff95449687fd13d7c467003b4c095bac_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the power side-channel vulnerability of the CVA6 RISC-V core using the VeriSide RTL simulation framework. By applying Correlation Power Analysis (CPA) to power traces during software AES execution, the authors successfully recover the secret key. The findings demonstrate significant leakage in the CVA6 design, emphasizing the importance of pre-silicon RTL-level security evaluation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现代RISC-V处理器需要抗侧信道攻击能力 / Modern RISC-V processors require resilience to side-channel attacks]
        C --> C1[使用VeriSide框架在RTL级进行功耗分析 / Use VeriSide framework for RTL-level power analysis]
        C --> C2[对软件AES执行进行相关性功耗分析(CPA) / Perform Correlation Power Analysis (CPA) on software AES execution]
        D --> D1[CVA6设计存在显著泄漏 / CVA6 design exhibits significant leakage]
        D --> D2[成功恢复AES密钥 / Successful AES key recovery]
    ```

- **[arXiv251229] The Imitation Game: Using Large Language Models as Chatbots to Combat Chat-Based Cybercrimes**
  - **tags:** [sec], [adversarial interaction], [Large Language Models, chat-based cybercrime, adversarial engagement, OCR-based analysis, Telegram scams]
  - **authors:** Yifan Yao, Baojuan Wang, Jinhao Duan, Kaidi Xu, ChuanKai Guo, Zhibo Eric Sun, Yue Zhang
  - **institution:** Drexel University, Shandong University
  - **link:** https://arxiv.org/pdf/2512.21371
  - **contributions:** 1. Proposes LURE, the first system to deploy LLMs as active agents (not passive classifiers) within adversarial chat environments to combat cybercrime. 2. Introduces a novel methodology combining automated discovery, adversarial interaction, and OCR-based analysis of image-embedded payment data. 3. Demonstrates the system's effectiveness in real-world illicit Telegram scams, where it maintained human-like conversations in over 56% of interactions, revealing key scammer behavioral patterns.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f4b9846e0125e1fe793dd441a994299b8568cd5c2bf7c05200309276b60eece_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes LURE, a system that uses Large Language Models as active chatbots to engage with and deceive chat-based cybercriminals, turning their own tactics against them. Applied to Telegram video chat scams, LURE successfully maintained undetected multi-round conversations in over 56% of interactions, uncovering scam operation patterns like payment flows and upselling strategies.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Imitation Game: Using Large Language Models as Chatbots to Combat Chat-Based Cybercrimes] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Chat-based cybercrime using trust & deception, hard for traditional defenses]
        C[主要方法/Method<br>LURE system: LLMs as active agents, adversarial interaction, OCR analysis]
        D[关键结果/Results<br>56% success rate, engaged 53 actors, revealed scam patterns]
    ```

- **[arXiv251229] Key Length-Oriented Classification of Lightweight Cryptographic Algorithms for IoT Security**
  - **tags:** [sec], [lightweight cryptography], [lightweight ciphers, key size, IoT security, symmetric cryptography, security evaluation]
  - **authors:** Arsalan Vahi
  - **institution:** Middle East Technical University
  - **link:** https://arxiv.org/pdf/2512.21368
  - **contributions:** 1. Conducts a security-focused survey of symmetric lightweight ciphers for IoT, addressing a gap in existing literature. 2. Proposes a taxonomy for classifying IoT applications based on their inherent characteristics. 3. Proposes a taxonomy for evaluating security levels of lightweight ciphers based on key size, concluding that keys shorter than 128 bits are less secure.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07f480d571b5dcb81f609c0a05f097dbfe5bc783bd4de5936cf4b4c301e2ab61_w640_q70.webp
  - **Simple LLM Summary:** This paper surveys lightweight cryptographic algorithms for IoT security, focusing on evaluating their security strength rather than just performance. It proposes two taxonomies for classifying IoT applications and cipher security levels based on key length. The main finding is that key size is critical, with ciphers using keys shorter than 128 bits being considered insecure for sensitive data.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Key Length-Oriented Classification of Lightweight Cryptographic Algorithms for IoT Security] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有调查缺乏针对物联网环境的全面安全评估/Existing surveys lack comprehensive IoT-specific security evaluation]
        C --> C1[对轻量级密码进行以安全为重点的综述/Conduct a security-focused survey of lightweight ciphers]
        C --> C2[提出物联网应用分类法/Propose an IoT application taxonomy]
        C --> C3[提出基于密钥长度的安全等级分类法/Propose a key size-based security level taxonomy]
        D --> D1[密钥长度是轻量级密码安全的关键参数/Key size is a critical security parameter]
        D --> D2[密钥短于128位的密码安全性不足/Ciphers with keys <128 bits are less secure]
    ```

- **[arXiv251229] Reflection-Driven Control for Trustworthy Code Agents**
  - **tags:** [mlsys], [agent system], [reflection-driven control, secure code generation, trustworthy agents, reflective memory, safety control]
  - **authors:** Bin Wang, Jiazheng Quan, Xingrui Yu, Hansen Hu, Yuhao, Ivor Tsang
  - **institution:** Peking University, Xiamen University, Agency for Science, Technology and Research (A*STAR)
  - **link:** https://arxiv.org/pdf/2512.21354
  - **contributions:** 1. Introduces Reflection-Driven Control, a standardized and pluggable control module that integrates self-reflection as an explicit, internal step in an agent's reasoning process. 2. Instantiates the method for secure code generation, using a reflection loop to monitor decisions and retrieve repair examples/guidelines from an evolving reflective memory to inject constraints. 3. Empirically demonstrates that the approach substantially improves security and policy compliance of generated code while preserving functional correctness, with minimal overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of reliable safety controls in LLM agents by proposing Reflection-Driven Control, a module that makes self-reflection an explicit, continuous part of the agent's reasoning to monitor and constrain its decisions using evidence from a reflective memory. Evaluated on security-critical code generation tasks, the method significantly improves code security and compliance while maintaining functionality, offering a practical path toward trustworthy AI coding agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Reflection-Driven Control for Trustworthy Code Agents] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[LLM代理缺乏可靠的安全控制/LLM agents lack reliable safety controls]
        Problem --> P2[可能产生有害输出/Can produce harmful outputs]
        Method --> M1[将自我反思作为推理的显式步骤/Elevates self-reflection to an explicit reasoning step]
        Method --> M2[内部反思循环监控决策路径/Internal reflection loop monitors decision path]
        Method --> M3[从反思记忆中检索修复示例/Retrieves repair examples from reflective memory]
        Results --> R1[显著提高生成代码的安全性和合规性/Substantially improves security & policy compliance]
        Results --> R2[基本保持功能正确性/Largely preserves functional correctness]
        Results --> R3[运行时和token开销最小/Minimal runtime & token overhead]
    ```

- **[arXiv251229] A Systematic Review of Technical Defenses Against Software-Based Cheating in Online Multiplayer Games**
  - **tags:** [sec], [game security], [server-side detection, client-side anti-tamper, kernel-level anti-cheat, hardware-assisted TEEs, adversarial resistance]
  - **authors:** Adwa Alangari, Ohoud Alharbi
  - **institution:** King Saud University
  - **link:** https://arxiv.org/pdf/2512.21377
  - **contributions:** 1. A systematic categorization of technical anti-cheat defenses into four distinct categories: server-side detection, client-side anti-tamper, kernel-level drivers, and hardware-assisted TEEs. 2. A comparative evaluation framework for these categories based on detection effectiveness, performance overhead, privacy impact, and scalability. 3. An analysis highlighting the key trade-offs and the ongoing adversarial arms race, emphasizing the need for robust anti-cheat designs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/137ad02b7b97dcc6332136fab185dc8b3ccf11a4a306f05b35f33d8d9520ec12_w640_q70.webp
  - **Simple LLM Summary:** This systematic review surveys technical defenses against software-based cheating in online multiplayer games. It categorizes and evaluates approaches like server-side detection and kernel-level anti-cheat, highlighting trade-offs between visibility and privacy. The review concludes that the field is an ongoing arms race, requiring robust, adversary-resistant designs.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Systematic Review of Technical Defenses Against Software-Based Cheating in Online Multiplayer Games"] --> Problem["核心问题/Problem: Software-based cheating threatens game integrity and fair competition"]
        Root --> Method["主要方法/Method: Systematic review and categorization of technical defenses (server-side, client-side, kernel-level, hardware-assisted)"]
        Root --> Results["关键结果/Results: Highlights trade-offs (e.g., visibility vs. privacy), emphasizes ongoing arms race and need for robust designs"]
    ```

- **[arXiv251229] Security Risks Introduced by Weak Authentication in Smart Home IoT Systems**
  - **tags:** [sec], [IoT security], [authentication security, replay attacks, local network threats, empirical security analysis]
  - **authors:** Daniyal Ganiuly, Nurzhau Bolatbek, Assel Smaiyl
  - **institution:** Astana IT University
  - **link:** https://arxiv.org/pdf/2512.21374
  - **contributions:** 1. Conducted an empirical analysis of authentication enforcement in deployed smart home IoT devices across multiple categories and ecosystems. 2. Demonstrated that authentication state is long-lived, persists through network changes, and can be replayed from another host on the same local network. 3. Identified that current mechanisms rely on long-lived trust with weak binding to session freshness, network context, or controller identity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85258f2b6afddb7ba218b720666454027995d978e3c0c5c5d1c10ce3ac5fd6ee_w640_q70.webp
  - **Simple LLM Summary:** This paper empirically analyzes authentication in smart home IoT devices, finding that authentication tokens are long-lived, persist through network events, and are vulnerable to replay attacks from other local hosts. The study concludes that current mechanisms prioritize usability over security, creating significant local network threats.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Security Risks Introduced by Weak Authentication in Smart Home IoT Systems") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("智能家居IoT认证机制需平衡安全与可用性/Smart home IoT authentication must balance security & usability")
        Method --> M1("在受控住宅环境中进行实证分析/Empirical analysis in controlled residential environment")
        Method --> M2("使用被动网络测量和官方应用交互/Using passive network measurement & official app interaction")
        Method --> M3("检查配对、长期运行、网络变化和重放尝试/Examining pairing, long-term operation, network changes, replay")
        Results --> R1("认证状态被长期重用且持久/Authentication state is long-lived & persistent")
        Results --> R2("在网络事件后保持有效/Remains valid after network events")
        Results --> R3("易受同一局域网重放攻击/Vulnerable to replay attacks from same local network")
    ```

- **[arXiv251229] LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors**
  - **tags:** [sec], [adversarial attacks], [adversarial attack, large language model, retrieval-augmented generation, Android malware detection, adversarial training]
  - **authors:** Tianwei Lan, Farid Naït-Abdesselam
  - **institution:** Université Paris Cité
  - **link:** https://arxiv.org/pdf/2512.21404
  - **contributions:** 1. Proposes LAMLAD, a novel adversarial attack framework that uses a dual-agent LLM architecture (manipulator and analyzer) to generate feature-level perturbations for evading Android malware detectors., 2. Integrates Retrieval-Augmented Generation (RAG) into the LLM pipeline to improve the efficiency and contextual awareness of the attack., 3. Proposes and evaluates an adversarial training-based defense strategy to enhance model robustness against the proposed LAMLAD-style attacks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6061210b194ba5cf79f70b8959faa3abe6b3e91ffad512d9cfd319de948593bb_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes LAMLAD, a novel adversarial attack framework that leverages the generative and reasoning capabilities of Large Language Models (LLMs) to bypass ML-based Android malware classifiers. The method uses a dual-agent LLM architecture with RAG to generate realistic, functionality-preserving feature perturbations, achieving a high attack success rate. The paper also demonstrates that adversarial training can significantly reduce the effectiveness of such attacks, enhancing model robustness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors] --> B[核心问题/Problem: ML-based Android malware detectors are vulnerable to adversarial attacks.]
        A --> C[主要方法/Method: Proposes LAMLAD, a dual-agent LLM framework with RAG for generating stealthy perturbations.]
        A --> D[关键结果/Results: Achieves up to 97% attack success rate; adversarial training defense reduces ASR by >30%.]
    ```

- **[arXiv251229] Weighted Fourier Factorizations: Optimal Gaussian Noise for Differentially Private Marginal and Product Queries**
  - **tags:** [sec], [differential privacy], [factorization mechanism, Fourier basis, marginal queries, product queries, Gaussian noise]
  - **authors:** Christian Janos Lebeda, Aleksandar Nikolov, Haohua Tang
  - **institution:** Inria, Université de Montpellier, INSERM, University of Toronto
  - **link:** https://arxiv.org/pdf/2512.21499
  - **contributions:** 1. Proposes a simpler, polynomial-time algorithm for releasing weighted marginal queries under differential privacy using Fourier factorization, achieving exact optimality among factorization mechanisms. 2. Extends the algorithm to a more general class of product queries, maintaining exact optimality. 3. Shows the mechanism is almost optimal for extended marginal queries with threshold predicates, achieving optimal noise variance up to lower-order terms.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/589c857d3c263098ff5b7608b80fed9cb6cf72f1228f01d3ba136496420444dc_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new algorithm for releasing marginal and product queries under differential privacy by adding correlated Gaussian noise. The method works by releasing queries in the Fourier basis with independent, carefully calibrated noise and then reconstructing the answers, which is proven to be exactly optimal among factorization mechanisms and runs in polynomial time. It simplifies and improves upon prior work, extending optimality to more general query classes.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Weighted Fourier Factorizations<br>加权傅里叶分解] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Releasing marginal queries<br>with differential privacy<br>在差分隐私下发布边际查询]
        C --> C1[Use Fourier basis &<br>independent Gaussian noise<br>使用傅里叶基和独立高斯噪声]
        C --> C2[Reconstruct via<br>inverse Fourier transform<br>通过逆傅里叶变换重构]
        D --> D1[Exactly optimal for<br>marginal & product queries<br>对边际和乘积查询精确最优]
        D --> D2[Polynomial-time algorithm<br>多项式时间算法]
        D --> D3[Simpler & better than<br>prior work (Xiao et al.)<br>比先前工作更简单更好]
    ```

- **[arXiv251229] Enhancing Distributed Authorization With Lagrange Interpolation And Attribute-Based Encryption**
  - **tags:** [sec], [Attribute-Based Encryption], [Lagrange Interpolation, Shamir Secret Sharing, Involution Function-Based Stream Cipher]
  - **authors:** Keshav Sinha, Sumitra, Richa Kumari, Akashdeep Bhardwaj, Shawon Rahman
  - **institution:** UPES (University of Petroleum and Energy Studies), University of Hawaii - Hilo
  - **link:** https://arxiv.org/pdf/2512.21525
  - **contributions:** 1. Proposes a multi-party execution approach to reduce server computational overhead and response time in distributed authorization. 2. Introduces an encryption method using an Involution Function-Based Stream Cipher for file data. 3. Utilizes Shamir secret sharing with second-order Lagrange interpolation for secure key distribution and reconstruction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d614980b77b93ae670a09dec954155af73838387f014f381092232a41d17e816_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the server overhead and slow response time in secure data access by proposing a multi-party execution approach. The method combines an Involution Function-Based Stream Cipher for encryption with Shamir secret sharing and Lagrange interpolation for key management. The results show reduced computational overhead, evaluated through encryption/decryption time, throughput, and security analysis.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ENHANCING DISTRIBUTED AUTHORIZATION<br>增强分布式授权] --> B(核心问题/Problem: Server overhead & slow response in secure data access<br>服务器开销大、安全数据访问响应慢)
        A --> C(主要方法/Method: Multi-party execution with encryption & key distribution<br>多参与方执行，结合加密与密钥分发)
        C --> C1[加密/Encryption: Involution Function-Based Stream Cipher<br>基于对合函数的流密码]
        C --> C2[密钥分发/Key Distribution: Shamir Secret Sharing & Lagrange Interpolation<br>沙米尔秘密共享与拉格朗日插值]
        A --> D(关键结果/Results: Reduced computational overhead, evaluated via time & security analysis<br>降低计算开销，通过时间和安全分析评估)
    ```

- **[arXiv251229] GoldenFuzz: Generative Golden Reference Hardware Fuzzing**
  - **tags:** [sec], [hardware security verification], [hardware fuzzing, golden reference model, RISC-V, test case refinement, vulnerability discovery]
  - **authors:** Lichao Wu, Mohamadreza Rostami, Huimin Li, Nikhilesh Singh, Ahmad-Reza Sadeghi
  - **institution:** Technical University of Darmstadt
  - **link:** https://arxiv.org/pdf/2512.21524
  - **contributions:** 1. Introduces a novel two-stage hardware fuzzing framework that decouples test refinement from coverage exploration using a fast Golden Reference Model (GRM) as a "digital twin". 2. Proposes a method to iteratively construct test cases by concatenating instruction blocks, balancing inter- and intra-instruction quality, and uses a feedback mechanism from high- and low-coverage samples. 3. Demonstrates superior performance over existing fuzzers on RISC-V processors, discovering new severe vulnerabilities and achieving higher coverage with lower computational overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp
  - **Simple LLM Summary:** This paper presents GoldenFuzz, a hardware fuzzing framework that uses a fast Golden Reference Model to refine test cases efficiently before exploring the actual device. It employs a feedback-driven mechanism for instruction block selection to enhance state exploration. The evaluation shows GoldenFuzz achieves higher coverage with less overhead and discovers new severe vulnerabilities in RISC-V processors.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GoldenFuzz: Generative Golden Reference Hardware Fuzzing] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[硬件模糊测试存在语义感知有限、测试低效、计算开销大的问题/Hardware fuzzing suffers from limited semantic awareness, inefficiency, and high overhead]
        C --> C1[使用快速黄金参考模型(GRM)作为数字孪生进行两阶段模糊测试/Two-stage fuzzing using a fast Golden Reference Model (GRM) as a digital twin]
        C --> C2[通过连接指令块和反馈机制构建测试用例/Constructing test cases via instruction block concatenation and feedback]
        D --> D1[在RISC-V处理器上实现最高覆盖率和最小开销/Achieves highest coverage with minimal overhead on RISC-V processors]
        D --> D2[发现新的高危漏洞/Uncovers new high-severity vulnerabilities]
    ```

- **[arXiv251229] Security Boundaries of Quantum Key Reuse: A Quantitative Evaluation Method for QKD Key Rotation Interval and Security Benefits Combined with Block Ciphers**
  - **tags:** [sec], [Post-Quantum Cryptography / Quantum Cryptography], [Quantum Key Distribution (QKD), Key Rotation, Block Cipher Modes (CTR/CBC/ECBC-MAC), Concrete Security, SM4]
  - **authors:** Xiaoming Chen, Haoze Chen, Fei Xu, Meifeng Gao, Jianguo Xie, Cheng Ye, An Hua, Jiao Zhao, Minghan Li, Feilong Li, Yajun Miao, Wei Qi
  - **institution:** CAS Quantum Network Co., Ltd., University of Science and Technology of China
  - **link:** https://arxiv.org/pdf/2512.21561
  - **contributions:** 1. Constructed a precise calculation model for the key rotation interval in hybrid QKD-block cipher systems. 2. Proposed a quantitative method to evaluate the security benefit of using QKD keys with block ciphers, deriving the maximum safe number of files per key (Q*). 3. Quantified the security enhancement from key rotation, showing it can increase security strength by log2(k) to 2log2(k) bits for a target like 80-bit security.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c46c72f07d378546c8a8a3c260c860de7093f78f6c38b6f32868e53b31ca6f56_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the security degradation when a single QKD-derived key is reused to encrypt multiple files with block ciphers. It proposes a quantitative model to calculate safe key rotation intervals and evaluates the security benefits, using SM4 as a case study. The results show that regular key rotation can significantly enhance the security level of the hybrid cryptographic system.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Security Boundaries of Quantum Key Reuse] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[QKD密钥重用导致安全强度降低/QKD Key Reuse Reduces Security]
        C --> C1[构建密钥轮换间隔计算模型/Build Key Rotation Interval Model]
        C --> C2[提出安全收益定量评估方法/Propose Quantitative Security Benefit Method]
        C --> C3[分析不同分组密码模式/Analyze Block Cipher Modes (CTR, CBC, ECBC-MAC)]
        D --> D1[推导单密钥最大安全文件数Q*/Derive Max Safe Files per Key Q*]
        D --> D2[量化轮换提升安全强度log2k~2log2k位/Quantify Rotation Benefit: log2k~2log2k bits]
    ```

- **[arXiv251229] Verifiable Passkey: The Decentralized Authentication Standard**
  - **tags:** [sec], [authentication], [Verifiable Passkey, Verifiable Credential, Decentralized Identity, FIDO2]
  - **authors:** Aditya Mitra, Sibi Chakkaravarthy Sethuraman
  - **institution:** Kadir Has University, VIT-AP University
  - **link:** https://arxiv.org/pdf/2512.21663
  - **contributions:** 1. Proposes a novel 'Verifiable Passkey' standard to enable decentralized, privacy-preserving authentication. 2. Addresses the storage limitation of traditional FIDO2 passkeys by allowing a single passkey to be used across multiple services. 3. Mitigates the user tracking risk associated with centralized Identity Providers (IdPs) in federated SSO systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf89aa4a9e3ca27de6380a24d719d401a00dd63929ea0b794171f19c33959345_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies the problems of limited storage for FIDO2 passkeys and privacy risks in federated SSO. It proposes a new 'Verifiable Passkey' standard that leverages Verifiable Credentials to allow a single passkey to be used across different platforms without compromising privacy. The main conclusion is that this approach provides a decentralized, scalable, and privacy-preserving alternative to current authentication methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Verifiable Passkey: The Decentralized Authentication Standard] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Passkey存储限制/Passkey Storage Limit]
        B --> B2[集中式IdP的隐私风险/Centralized IdP Privacy Risk]
        C --> C1[提出可验证通行密钥标准/Propose Verifiable Passkey Standard]
        D --> D1[去中心化认证/Decentralized Authentication]
        D --> D2[隐私保护/Privacy Preservation]
    ```

- **[arXiv251229] Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation**
  - **tags:** [sec], [software security], [backdoor attack, retrieval-augmented code generation, vulnerable code, supply-chain vulnerability, stealthy attack]
  - **authors:** Tian Li, Bo Lin, Shangwen Wang, Yusong Tan
  - **institution:** National University of Defense Technology
  - **link:** https://arxiv.org/pdf/2512.21681
  - **contributions:** 1. Conducted the first systematic exploration of backdoor attacks targeting the retriever component in Retrieval-Augmented Code Generation (RACG), identifying it as a critical supply-chain vulnerability. 2. Proposed VenomRACG, a new class of potent and stealthy attack that makes poisoned code statistically indistinguishable from benign code, enabling realistic threat analysis. 3. Demonstrated the severe practical impact of the attack, showing that injecting only 0.05% poisoned data can manipulate the retriever and cause downstream models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while evading current defenses.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74c266d46865bfe9ae8b97f18b92cf9b8209ecd63852c6f32f3fe8533329fe2_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the security threat of backdoor attacks on the retriever in Retrieval-Augmented Code Generation (RACG). To enable a realistic analysis, the authors developed a stealthy attack called VenomRACG. Their findings reveal that this attack is highly effective and evades current defenses, posing a practical threat to the software development ecosystem.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Retriever Backdoor: 供应链漏洞/Supply-Chain Vulnerability]
        C --> C1[VenomRACG: 隐蔽攻击/Stealthy Attack]
        D --> D1[低投毒率有效/Low Poisoning Rate Effective]
        D --> D2[下游模型生成漏洞代码/Downstream Model Generates Vulnerable Code]
        D --> D3[防御机制失效/Defenses Ineffective]
    ```

- **[arXiv251229] Raster Domain Text Steganography: A Unified Framework for Multimodal Secure Embedding**
  - **tags:** [sec], [steganography], [raster domain steganography, glyph perturbation, deterministic rasterization, multimodal embedding, text-based data hiding]
  - **authors:** A V Uday Kiran Kandala
  - **institution:** Queen Mary University of London
  - **link:** https://arxiv.org/pdf/2512.21698
  - **contributions:** 1. Proposes a unified Glyph Perturbation Cardinality (GPC) framework for embedding heterogeneous data (text, images, audio, video) directly into the pixel space of rendered text glyphs. 2. Operates exclusively in the raster domain after font rendering, modifying bitmap pixels with minimal, visually imperceptible intensity increments for covert communication. 3. Introduces a decoding method based on re-rasterizing cover text, subtracting canonical glyph rasters, and recovering payload via pixel count analysis, leveraging deterministic raster behavior.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/86fd7815a5837b02c5d9e31511c3faca8253eee6c4c977836c3a42782decfdc2_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a raster domain steganography framework that embeds multimodal data into text by minimally perturbing the interior pixels of rendered glyphs. The method is visually imperceptible and computationally lightweight, enabling ordinary text to serve as a covert medium for secure data embedding. It generalizes beyond traditional linguistic steganography by operating directly on the deterministic bitmap output of text rendering pipelines.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Raster Domain Text Steganography: A Unified Framework for Multimodal Secure Embedding") --> Problem("核心问题/Problem: How to embed multimodal data covertly into ordinary text?")
        Root --> Method("主要方法/Method: Glyph Perturbation Cardinality (GPC) Framework")
        Root --> Results("关键结果/Results: Visually imperceptible, lightweight embedding in raster domain")
        Problem --> P1("传统方法局限/Limitations of linguistic & structural methods")
        Method --> M1("操作于栅格化后/Operates post-rasterization")
        Method --> M2("扰动字形内部像素/Perturbs interior ink pixels")
        Method --> M3("基于像素基数编码/Encodes via pixel cardinality")
        Results --> R1("支持多模态数据/Supports multimodal data")
        Results --> R2("解码稳定可靠/Stable & decodable signal")
    ```

- **[arXiv251229] Machine Learning Power Side-Channel Attack on SNOW-V**
  - **tags:** [sec], [side-channel analysis], [SNOW-V, power analysis, profiling attack, Linear Discriminant Analysis, Fully Connected Neural Network]
  - **authors:** Deepak, Rahul Balout, Anupam Golder, Suparna Kundu, Angshuman Karmakar, Debayan Das
  - **institution:** Indian Institute of Science, Bangalore; KU Leuven; Intel Corporation; Indian Institute of Technology, Kanpur
  - **link:** https://arxiv.org/pdf/2512.21737
  - **contributions:** 1. Systematically evaluates the effectiveness of Side-Channel Analysis (SCA) on the SNOW-V cipher using two profiling-based machine learning techniques: Linear Discriminant Analysis (LDA) and Fully Connected Neural Networks (FCN). 2. Demonstrates progressive recovery of the secret key using these ML models, with FCN achieving a greater than 5x reduction in Minimum Traces to Disclosure (MTD) compared to the state-of-the-art CPA+LDA method. 3. Highlights the vulnerability of the 5G candidate cipher SNOW-V to machine learning-based SCA and underscores the need for robust countermeasures.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/317918426c0513400f22837d9127c1ab14ed2fb0ca1358968c6f98ca7da95a39_w640_q70.webp
  - **Simple LLM Summary:** This paper demonstrates a power side-channel attack on the SNOW-V stream cipher, a candidate for 5G security. Using power traces from an STM32 microcontroller, the authors employ profiling attacks with Linear Discriminant Analysis (LDA) and Fully Connected Neural Networks (FCN) for key recovery. The results show that FCN significantly outperforms prior methods, revealing SNOW-V's vulnerability to machine learning-based attacks and emphasizing the need for stronger defenses.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Machine Learning Power Side-Channel Attack on SNOW-V] --> B
        A --> C
        A --> D
        B[核心问题/Problem: SNOW-V 对侧信道攻击的脆弱性/Vulnerability of SNOW-V to Side-Channel Attacks]
        C[主要方法/Method: 使用LDA和FCN的侧信道分析/SCA using LDA and FCN]
        D[关键结果/Results: FCN实现>5倍MTD降低/FCN achieves >5x lower MTD]
    ```

- **[arXiv251229] Assessing the Effectiveness of Membership Inference on Generative Music**
  - **tags:** [sec], [membership inference attacks], [membership inference attack (MIA), generative music, MuseGAN, privacy, copyright]
  - **authors:** Kurtis Chow, Omar Samiullah, Vinesh Sridhar, Hewen Zhang
  - **institution:** University of California, Irvine
  - **link:** https://arxiv.org/pdf/2512.21762
  - **contributions:** 1. Conducts the first preliminary study on the effectiveness of membership inference attacks (MIAs) specifically on generative music models., 2. Evaluates several existing MIA techniques on the popular MuseGAN model to assess their performance in this domain., 3. Provides empirical evidence suggesting that generative music data is relatively resilient to known membership inference techniques, aligning with prior findings in generative audio.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b7176fccbb69c4f0a15bfa6bcbb6ff59b09cf6ac02e0f524334f306ce4041f_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether membership inference attacks (MIAs) are effective against generative music models. The authors conduct a preliminary study by applying several existing MIA techniques to the MuseGAN model. Their findings indicate that generative music data is fairly resilient to these known attacks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Assessing the Effectiveness of Membership Inference on Generative Music"] --> Problem["核心问题/Problem: Lack of MIA study on generative music, privacy & copyright concerns"]
        Root --> Method["主要方法/Method: Apply existing MIAs to MuseGAN model"]
        Root --> Results["关键结果/Results: Music data is resilient to known MIAs"]
    ```

- **[arXiv251229] Organizational Learning in Industry 4.0: Applying Crossan's 4I Framework with Double Loop Learning**
  - **tags:** [sec], [cybersecurity incident response], [Dynamic Security Learning, double-loop learning, 4I framework, cyber-physical systems, organizational learning]
  - **authors:** Nimra Akram, Atif Ahmad, Sean B Maynard
  - **institution:** The University of Melbourne
  - **link:** https://arxiv.org/pdf/2512.21813
  - **contributions:** 1. Proposes the Advanced Dynamic Security Learning (DSL) Process Model, a novel cybersecurity incident response architecture for Industry 4.0 environments. 2. Integrates Argyris and Schön's double-loop learning theory with Crossan's 4I organizational learning framework to address proactive and reflective governance. 3. Provides a scalable and methodical approach to cybersecurity maturity that bridges operational obstacles and promotes systemic resilience in complex cyber-physical systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/140960f0ea33407610ec595750733a88a05966b1af849210f2f418cec775a463_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the critical gap in cybersecurity incident response for the dynamic and decentralized operational technology (OT) systems of Industry 4.0. It proposes the Advanced Dynamic Security Learning (DSL) Process Model, which combines double-loop learning with the 4I organizational learning framework to enable proactive governance and strategic adaptation. The model aims to help organizations build systemic resilience against growing cyber threats in industrial environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Organizational Learning in Industry 4.0: Applying Crossan's 4I Framework with Double Loop Learning] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Industry 4.0 cybersecurity threats in dynamic OT systems]
        C[主要方法/Method: DSL Model combining Double-Loop Learning & 4I Framework]
        D[关键结果/Results: Proactive governance & systemic resilience for incident response]
    ```

- **[arXiv251229] Securing Cross-Domain Internet of Drones: An RFF-PUF Allied Authenticated Key Exchange Protocol With Over-the-Air Enrollment**
  - **tags:** [sec], [authenticated key exchange], [Radio Frequency Fingerprint (RFF), Physical Unclonable Function (PUF), One-Time-Pad (OTP), ProVerif, over-the-air enrollment]
  - **authors:** Xuanyu Chen, Yue Zheng, Junqing Zhang, Guanxiong Shen, Chip-Hong Chang
  - **institution:** The Chinese University of Hong Kong, Shenzhen; University of Liverpool; Southeast University; Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.21827
  - **contributions:** 1. Proposes a lightweight mutual authentication protocol for IoD by integrating RFF and PUF technologies for secure D2D and D2G communication. 2. Achieves over-the-air enrollment using RFF-based device identification and uses PUF as a root of trust, eliminating the need for secret storage in drones. 3. Co-designs PUF's on-the-fly key generation with OTP encryption for ephemeral keying and demonstrates security resilience through formal verification with ProVerif.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad8808d2092e10128228471d5fad90003211bb9fb8e1df6bb71ef3ac783f8df8_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a lightweight authenticated key exchange protocol for securing cross-domain Internet of Drones (IoD). The method integrates Radio Frequency Fingerprint (RFF) for over-the-air enrollment and Physical Unclonable Function (PUF) as a root of trust to enable mutual authentication and ephemeral keying without storing secrets on drones. The protocol is shown to be resilient against common attacks and outperforms existing schemes in security features and overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Securing Cross-Domain IoD: RFF-PUF Protocol] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[IoD安全挑战/Security Challenges in IoD]
        B1 --> B2[高开销与依赖第三方/High Overhead & Third-Party Reliance]
        C --> C1[轻量级认证协议/Lightweight Authentication Protocol]
        C1 --> C2[集成RFF与PUF/Integrating RFF & PUF]
        C2 --> C3[RFF用于空中注册/RFF for OTA Enrollment]
        C2 --> C4[PUF作为信任根/PUF as Root of Trust]
        C4 --> C5[PUF+OTP实现临时密钥/PUF+OTP for Ephemeral Keying]
        D --> D1[抵抗常见攻击/Resilient to Common Attacks]
        D --> D2[优于现有方案/Outperforms Existing Schemes]
        D2 --> D3[安全特性与开销/Security Features & Overhead]
    ```

- **[arXiv251229] Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?**
  - **tags:** [mlsys], [multi-modal inference], [copyright compliance, vision-language models, tool-augmented defense, benchmark dataset, multimodal query]
  - **authors:** Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji
  - **institution:** Zhejiang University, University of California, Los Angeles, Palo Alto Networks
  - **link:** https://arxiv.org/pdf/2512.21871
  - **code:** https://github.com/bluedream02/CopyGuard
  - **contributions:** 1. Introduced a large-scale benchmark dataset of 50,000 multimodal query-content pairs to evaluate copyright compliance in LVLMs. 2. Conducted a comprehensive evaluation revealing significant deficiencies in state-of-the-art LVLMs' ability to recognize and respect copyrighted content. 3. Proposed a novel tool-augmented defense framework to reduce copyright infringement risks in LVLM inference.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp
  - **Simple LLM Summary:** This paper evaluates how large vision-language models (LVLMs) handle copyrighted visual content and finds they often fail to comply with copyright regulations. To address this, the authors propose a tool-augmented defense framework for copyright compliance. The work highlights the need for developing copyright-aware LVLMs to ensure responsible use.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?"]
        Root --> Problem["核心问题/Problem: LVLMs may infringe copyright when processing visual inputs"]
        Root --> Method["主要方法/Method: Benchmark dataset & Tool-augmented defense framework"]
        Root --> Results["关键结果/Results: Current LVLMs are deficient; Proposed framework reduces risk"]
    ```

- **[arXiv251229] Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models**
  - **tags:** [sec], [backdoor attacks], [video segmentation foundation models, backdoor attack, two-stage training, gradient analysis, attention shift]
  - **authors:** Zongmin Zhang, Zhen Sun, Yifan Liao, Wenhan Dong, Xinlei He, Xingshuo Han, Shengmin Xu, Xinyi Huang
  - **institution:** Hong Kong University of Science and Technology (Guangzhou), Nanjing University of Aeronautics and Astronautics, Fujian Normal University, Jinan University
  - **link:** https://arxiv.org/pdf/2512.22046
  - **contributions:** 1. Identifies the ineffectiveness of classic backdoor attacks on prompt-driven Video Segmentation Foundation Models (VSFMs) and provides analysis via gradient and attention maps. 2. Proposes BadVSFM, the first dedicated backdoor attack framework for VSFMs, using a novel two-stage training strategy to separate clean and triggered representations. 3. Demonstrates strong, controllable attack performance across multiple models and datasets while preserving clean-task accuracy, and shows the vulnerability persists against existing defenses.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a7e9ff0ffc63f2085d6ca65db8e87f14fed435be5d8a51fd3d1265b22b668b1_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies that standard backdoor attacks fail on prompt-driven Video Segmentation Foundation Models (VSFMs) like SAM2. To solve this, the authors propose BadVSFM, a two-stage backdoor attack framework that successfully implants a controllable backdoor by steering the encoder and decoder separately. Experiments show the attack is effective and evades current defenses, revealing a significant security vulnerability in VSFMs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Classic backdoor attacks fail on VSFMs (ASR<5%)]
        C[主要方法/Method: BadVSFM - Two-stage training (steer encoder, train decoder)]
        D[关键结果/Results: High ASR, preserves clean performance, defenses ineffective]
    ```

- **[arXiv251229] Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management**
  - **tags:** [nlp], [AI Governance & Compliance], [lifecycle management, bias detection, differential privacy, federated learning, terminology drift]
  - **authors:** Sunil Arora, John Hastings
  - **institution:** Dakota State University
  - **link:** https://arxiv.org/pdf/2512.22060
  - **contributions:** 1. Proposes the SC-NLP-LMF, a comprehensive six-phase framework for secure and compliant NLP model lifecycle management. 2. Integrates established technical methods (e.g., bias detection, differential privacy) with leading organizational standards (e.g., NIST AI RMF, EU AI Act). 3. Validates the framework's practicality through a healthcare case study demonstrating detection of and response to terminology drift.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/113703d05215aac7e8678f24cb38d882fa4c99927066ea2264ef3d1b4c3a1d67_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces the Secure and Compliant NLP Lifecycle Management Framework (SC-NLP-LMF), a six-phase model developed from a systematic review to address security, privacy, and compliance risks in NLP systems. It integrates methods like bias detection and differential privacy with standards like NIST AI RMF and the EU AI Act. The framework provides a practical structure for organizations to manage NLP systems in high-risk environments, as illustrated by a healthcare case study on handling terminology drift.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>NLP systems in sensitive domains face unaddressed security, privacy, and compliance risks."]
        Method["主要方法/Method<br>Proposes SC-NLP-LMF, a six-phase framework integrating standards (NIST, ISO, EU AI Act) and techniques (bias detection, differential privacy)."]
        Results["关键结果/Results<br>Provides a practical lifecycle structure for secure, accountable NLP systems, validated via a healthcare case study."]
    ```

- **[arXiv251229] ReSMT: An SMT-Based Tool for Reverse Engineering**
  - **tags:** [sec], [reverse engineering], [SMT solving, deobfuscation, logical assertions, automated analysis]
  - **authors:** Nir Somech, Guy Katz
  - **institution:** The Hebrew University of Jerusalem
  - **link:** https://arxiv.org/pdf/2512.22076
  - **contributions:** 1. A novel automated tool (ReSMT) that converts obfuscated assembly code into a system of logical assertions for analysis. 2. An approach that applies SMT solving and simulation to inspect obfuscated code execution, reducing the need for specialized manual skills. 3. Demonstration of the tool's effectiveness through a successful case study on complex, obfuscated code.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/910bd3ef1ea1d824f29ec5a3c12c77ea64068337777edd67f0de1e2b98014c86_w640_q70.webp
  - **Simple LLM Summary:** The paper presents ReSMT, an automated tool that addresses the difficulty of reverse engineering obfuscated code by transforming it into logical assertions and using SMT solvers for analysis. This method reduces reliance on expert manual deobfuscation. A case study shows ReSMT can successfully answer queries about complex obfuscated code, demonstrating its potential utility.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ReSMT: An SMT-Based Tool for Reverse Engineering] --> B(核心问题/Problem: Reverse engineering obfuscated code is difficult and slow)
        A --> C(主要方法/Method: Convert assembly to logical assertions, apply SMT solving and simulation)
        A --> D(关键结果/Results: Tool successfully tackled complex code in a case study)
    ```

- **[arXiv251229] Abstraction of Trusted Execution Environments as the Missing Layer for Broad Confidential Computing Adoption: A Systematization of Knowledge**
  - **tags:** [sec], [trusted execution environments], [Trusted Execution Environments, Confidential Computing, Abstraction Layer, WebAssembly, Systematization of Knowledge]
  - **authors:** Quentin Michaud, Sara Ramezanian, Dhouha Ayed, Olivier Levillain, Joaquin Garcia-Alfaro
  - **institution:** Télécom SudParis, Institut Polytechnique de Paris, Thales, Lund University, Karlstad University
  - **link:** https://arxiv.org/pdf/2512.22090
  - **contributions:** 1. Provides a comprehensive overview and classification of existing TEE technologies based on their design choices. 2. Proposes a systematization of knowledge (SoK) focusing on abstraction layers for TEEs to unify the confidential computing ecosystem. 3. Identifies WebAssembly as a promising approach for abstraction and discusses future research directions for integrating abstraction layers.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e9b906f168ce76656e0e7d95497572cc5edc40d2ad1966cd32644ac97261bb7_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the fragmentation in Trusted Execution Environment (TEE) technologies by proposing abstraction layers as a solution to unify the confidential computing ecosystem. It conducts a systematization of knowledge, reviewing and classifying TEE designs and their corresponding abstraction layers. The study concludes that WebAssembly is a promising abstraction approach and highlights opportunities for future research to improve and integrate these layers.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Abstraction of TEEs as the Missing Layer for Broad Confidential Computing Adoption] --> Problem[核心问题/Problem: Fragmentation of TEE technologies hinders broad adoption]
        Root --> Method[主要方法/Method: Systematization of Knowledge on TEEs and abstraction layers]
        Root --> Results[关键结果/Results: WebAssembly is a promising abstraction; Future research directions identified]
    ```

- **[arXiv251229] When the Base Station Flies: Rethinking Security for UAV-Based 6G Networks**
  - **tags:** [sec], [wireless network security], [UAV-BS, non-terrestrial networks (NTN), denial-of-service (DoS), GNSS spoofing, handover manipulation]
  - **authors:** Ammar El Falou
  - **institution:** King Abdullah University of Science and Technology (KAUST)
  - **link:** https://arxiv.org/pdf/2512.21574
  - **contributions:** 1. Identifies unique security vulnerabilities introduced by mobile, wireless, and resource-constrained UAV base stations in 6G networks. 2. Outlines specific attack surfaces for UAV-BS systems, including emergency alert spoofing, DoS, jamming, and malicious handover manipulation. 3. Proposes principles and mitigation techniques for securing the architecture of UAV-based non-terrestrial networks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9bf0cf9e709be88409d70b055d12514f5509bc714ec219eefb408d1ab8fbe51_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the security challenges of using unmanned aerial vehicles (UAVs) as mobile base stations in 6G non-terrestrial networks. It identifies new attack vectors due to their mobility, wireless backhaul, and resource constraints, and outlines principles for mitigating these threats to build a secure architecture.
  - **Mindmap:**

    ```mermaid
    graph TB
    Root("When the Base Station Flies: Rethinking Security for UAV-Based 6G Networks") --> Problem("核心问题/Problem")
    Root --> Method("主要方法/Method")
    Root --> Results("关键结果/Results")
    Problem --> P1("UAV-BS引入新安全挑战/New Security Challenges from UAV-BS")
    Problem --> P2("易受DoS、欺骗、干扰攻击/Vulnerable to DoS, Spoofing, Jamming")
    Method --> M1("识别攻击面/Identify Attack Surfaces")
    Method --> M2("提出缓解原则/Outline Mitigation Principles")
    Results --> R1("为安全6G架构提供指导/Provide Guidance for Secure 6G Architecture")
    ```
