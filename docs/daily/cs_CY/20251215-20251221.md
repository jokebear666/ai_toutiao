# 20251215-20251221 (cs.CY)

## 2025-12-18

- **[arXiv251218] SepsisSuite: Beyond Risk Stratification -- A Comparative Analysis of Deep Fusion vs. Expert Stacking for Prescriptive Sepsis AI**
  - **tags:** [mlsys], [multi-modal training], [Mixture-of-Experts (MoE), Hierarchical Gated Attention Network, CatBoost meta-learner, multimodal fusion, deep fusion, expert stacking, Quad-Modal Ensemble]
  - **authors:** Ryan Cartularo
  - **institution:** The University of Texas at Austin
  - **link:** https://arxiv.org/pdf/2512.14712
  - **Simple LLM Summary:** This paper compares two multimodal AI architectures for sepsis prediction and antibiotic selection: a complex end-to-end deep fusion model (SepsisFusionFormer) and a leaner, context-aware Mixture-of-Experts stacking model (SepsisLateFusion). The main conclusion is that for this high-stakes, data-sparse clinical domain, the interpretable expert stacking approach, which treats modalities as orthogonal experts and uses a CatBoost meta-learner, significantly outperformed the deep fusion model, achieving state-of-the-art predictive performance and enabling a prescriptive window for intervention.

- **[arXiv251218] AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally**
  - **tags:** [mlsys], [others], [multi-agent reasoning, chain-of-responsibility, modular architecture, governance mechanisms, multilingual interactions, real-time tools]
  - **authors:** Nadine Angela Cantonjos, Arpita Biswas
  - **institution:** Rutgers University
  - **link:** https://arxiv.org/pdf/2512.14910
  - **Simple LLM Summary:** This paper presents AgroAskAI, a multi-agent AI framework designed to support smallholder farmers with climate adaptation queries. It uses a modular, role-specialized architecture coordinated via a chain-of-responsibility approach, integrating real-time data and multilingual support. The experimental results show that this system delivers more actionable and grounded outputs for agricultural decision support.

- **[arXiv251218] Epistemic diversity across language models mitigates knowledge collapse**
  - **tags:** [mlsys], [llm training], [model collapse, epistemic diversity, AI ecosystem, self-training, distributed training]
  - **authors:** Damian Hodel, Jevin D. West
  - **institution:** University of Washington
  - **link:** https://arxiv.org/pdf/2512.15011
  - **Simple LLM Summary:** The paper investigates whether diversity across language models (an "AI ecosystem") can mitigate performance decay from training on model-generated data. It segments training data across multiple models and evaluates performance over self-training iterations. The main conclusion is that increased epistemic diversity mitigates knowledge collapse, but only up to an optimal level, with too few or too many models leading to poor performance.

- **[arXiv251218] Governing rapid technological change: Policy Delphi on the future of European AI governance**
  - **tags:** [ai], [policy analysis], [Policy Delphi, anticipatory governance, future-proof regulation, AI Act]
  - **authors:** Atte Ojanen, Johannes Anttila, Thilo H. K. Thelitz, Anna Bjork
  - **institution:** Demos Helsinki, University of Turku
  - **link:** https://arxiv.org/pdf/2512.15196
  - **Simple LLM Summary:** This paper uses a two-round Policy Delphi method with European experts to study the future of AI governance. It finds a consensus that effective regulation depends more on practical implementation and enforcement than on technical specifics, and identifies a gap between desirable policy directions (like citizen participation) and their perceived feasibility.

- **[arXiv251218] ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I**
  - **tags:** [mlsys], [multi-modal inference], [multimodal reasoning, perception-cognition gap, calculation-conceptualization discrepancy, process hallucination, OCR, AI-resistant questions]
  - **authors:** Seok-Hyun Ga, Chun-Yen Chang
  - **institution:** Institute for Research Excellence in Learning Sciences, National Taiwan Normal University, Seoul National University, Universitas Negeri Malang
  - **link:** https://arxiv.org/pdf/2512.15298
  - **Simple LLM Summary:** This study evaluates the multimodal scientific reasoning of LLMs like GPT-4o and Gemini on the Korean CSAT Earth Science I exam under different input conditions. It finds that models suffer from fundamental cognitive flaws, such as a perception-cognition gap and calculation-conceptualization discrepancy, even with optimized inputs. The paper concludes by suggesting these vulnerabilities can be exploited to design AI-resistant assessment questions to ensure academic integrity.

- **[arXiv251218] Exploring User Acceptance and Concerns toward LLM-powered Conversational Agents in Immersive Extended Reality**
  - **tags:** [mlsys], [others], [crowdsourcing, user study, extended reality, conversational agents, privacy, technology acceptance model]
  - **authors:** Efe Bozkir, Enkelejda Kasneci
  - **institution:** Technical University of Munich
  - **link:** https://arxiv.org/pdf/2512.15343
  - **Simple LLM Summary:** This paper conducted a large-scale crowdsourcing study with 1036 participants to explore user acceptance and concerns regarding LLM-powered conversational agents in Extended Reality (XR). The study found that while users generally accept these technologies, they express significant concerns about security, privacy, social implications, and trust, with location data being the most sensitive. The results highlight the importance of practitioner transparency and that familiarity with generative AI increases acceptance, while prior XR device ownership is linked to lower acceptance.
