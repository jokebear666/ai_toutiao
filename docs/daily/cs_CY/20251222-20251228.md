---
slug: /daily/cscy/20251222-20251228
---
# 20251222-20251228 (cs.CY)

## 2025-12-22

- **[arXiv251222] The Role of Islamic Ethics in Preventing the Abuse of Artificial Intelligence (AI) Based Deepfakes**
  - **tags:** [ai], [ethics and society], [Systematic Literature Review (SLR), PRISMA, Maqasid al-Shariah, hifz al-ird, hifz al-nafs, adl, tabayyun]
  - **authors:** Wisnu Uriawan, Imany Fauzy Rahman, Muhamad Zidan, Irma Rohmatillah, Muhammad Arkan Raihan, Irma Dwiyanti
  - **institution:** UIN Sunan Gunung Djati Bandung
  - **link:** https://arxiv.org/pdf/2512.17218
  - **Simple LLM Summary:** This study employs a Systematic Literature Review (SLISMA) to formulate an Islamic ethical framework for preventing deepfake abuse. It concludes that principles from Maqasid al-Shariah, such as protecting honor and self, provide a normative basis for shifting from punitive to preventative approaches, focusing on human dignity and the common good in the digital age.

- **[arXiv251222] Privacy-Preserving Synthetic Dataset of Individual Daily Trajectories for City-Scale Mobility Analytics**
  - **tags:** [ai], [privacy-preserving data synthesis], [multi-objective optimization, origin-destination matrices, dwell-travel time quantiles, universal law of daily visited locations, synthetic trajectory generation]
  - **authors:** Jun'ichi Ozaki, Ryosuke Susuta, Takuhiro Moriyama, Yohei Shida
  - **institution:** Not explicitly provided; cannot infer from given information.
  - **link:** https://arxiv.org/pdf/2512.17239
  - **Simple LLM Summary:** This paper proposes a method to generate a privacy-preserving synthetic dataset of individual daily trajectories by integrating aggregated origin-destination flows with behavioral constraints in a multi-objective optimization framework. The method successfully reproduces realistic human mobility patterns in two Japanese regions, providing a practical pathway for high-resolution mobility analytics without using sensitive personal data.

- **[arXiv251222] Are Vision Language Models Cross-Cultural Theory of Mind Reasoners?**
  - **tags:** [ai], [vision-language models], [CulturalToM-VQA, visual question answering, chain-of-thought prompting, compositional chain-of-thought prompting, false belief reasoning, social desirability bias]
  - **authors:** Zabir Al Nazi, G M Shahariar, Abrar Hossain, Wei Peng
  - **institution:** University of California, Riverside, University of Dhaka, Stanford University
  - **link:** https://arxiv.org/pdf/2512.17394
  - **Simple LLM Summary:** The paper introduces CulturalToM-VQA, a benchmark dataset built via a VLM-assisted human-in-the-loop pipeline to evaluate cross-cultural Theory of Mind reasoning in Vision-Language Models. It finds that while newer VLMs show strong performance on explicit tasks, they systematically struggle with false belief reasoning, and their results may be inflated by social desirability bias rather than genuine visual understanding.

- **[arXiv251222] Fair Voting Methods as a Catalyst for Democratic Resilience: A Trilogy on Legitimacy, Impact and AI Safeguarding**
  - **tags:** [ai], [democratic systems], [fair voting methods, cumulative voting, equal shares, proportional representation, participatory budgeting, AI voting assistance]
  - **authors:** Evangelos Pournaras
  - **institution:** University of Leeds
  - **link:** https://arxiv.org/pdf/2512.17461
  - **Simple LLM Summary:** This paper proposes that combining expressive ballot formats like cumulative voting with proportional aggregation methods like equal shares constitutes a "fair voting method." It concludes that such methods enhance democratic legitimacy, accelerate impactful outcomes in areas like welfare and education, and serve as a safeguard against biases in emerging AI-assisted voting scenarios.

- **[arXiv251222] Integrating Computational Methods and AI into Qualitative Studies of Aging and Later Life**
  - **tags:** [ai], [computational social science], [computational text analysis, machine learning (ML), natural language processing (NLP), ethnography, in-depth interviews, mixed-methods]
  - **authors:** Corey M. Abramson
  - **institution:** Rice University, UC San Francisco
  - **link:** https://arxiv.org/pdf/2512.17850
  - **Simple LLM Summary:** This paper demonstrates how computational social science tools like machine learning and natural language processing can be integrated with traditional qualitative methods (e.g., ethnography, interviews) to study aging. It concludes that these computational methods can broaden qualitative research by streamlining workflows, scaling up projects, and enabling new multi-method insights, rather than replacing its foundational approaches.

- **[arXiv251222] Penalized Fair Regression for Multiple Groups in Chronic Kidney Disease**
  - **tags:** [ai], [fair machine learning], [penalized regression, cost-sensitive classification, true positive rate disparity penalties]
  - **authors:** Carter H. Nakamoto, Lucia Lushi Chen, Agata Foryciarz, Sherri Rose
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2512.17340
  - **Simple LLM Summary:** The paper proposes a penalized fair regression framework using unfairness penalties for multiple groups, implemented via reduction to cost-sensitive classification. The method is applied to predict end-stage renal disease in a chronic kidney disease study, showing substantial fairness improvements for multiple race and ethnicity groups without appreciable loss in overall model fit.

## 2025-12-23

- **[arXiv251223] CoPE: A Small Language Model for Steerable and Scalable Content Labeling**
  - **tags:** TBD
  - **authors:** Samidh Chakrabarti, David Willner, Kevin Klyman, Tiffany Saade, Emily Capstick, Sabina Nong
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18027
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/423158010714f415c807a9ae93864ccaf58e7d33b462039083dce106e5d195f2_w640_q70.webp
  - **Simple LLM Summary:** CoPE: A Small Language Model for Steerable and Scalable Content Labeling

- **[arXiv251223] Securing Agentic AI Systems -- A Multilayer Security Framework**
  - **tags:** TBD
  - **authors:** Sunil Arora, John Hastings
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18043
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96ca042b8b2e4295fa813434a544ac9adb3df55cbea55e3fe9b24f2dcbee4733_w640_q70.webp
  - **Simple LLM Summary:** Securing Agentic AI Systems -- A Multilayer Security Framework

- **[arXiv251223] Statistical laws and linguistics inform meaning in naturalistic and fictional conversation**
  - **tags:** TBD
  - **authors:** Ashley M. A. Fehr, Calla G. Beauregard, Julia Witte Zimmerman, Katie Ekström, Pablo Rosillo-Rodes, Christopher M. Danforth, Peter Sheridan Dodds
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18072
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0119bf39897b4bb6f848dd8818e4a75f43e327cbc8223e8cff6bafd0a8277d08_w640_q70.webp
  - **Simple LLM Summary:** Statistical laws and linguistics inform meaning in naturalistic and fictional conversation

- **[arXiv251223] Conscious Data Contribution via Community-Driven Chain-of-Thought Distillation**
  - **tags:** TBD
  - **authors:** Lena Libon, Meghana Bhange, Rushabh Solanki, Elliot Creager, Ulrich Aïvodji
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18174
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd7baf972d08bf5c53e0a32c68fda68879e3c2febf3407ecf6537a3fcd6d36fd_w640_q70.webp
  - **Simple LLM Summary:** Conscious Data Contribution via Community-Driven Chain-of-Thought Distillation

- **[arXiv251223] Measuring Fine-Grained Negotiation Tactics of Humans and LLMs in Diplomacy**
  - **tags:** TBD
  - **authors:** Wenkai Li, Lynnette Hui Xian Ng, Andy Liu, Daniel Fried
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18292
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bca157c21b274184903d6db27d719924ad61a7ebd545421b88ee4959f34a8c8_w640_q70.webp
  - **Simple LLM Summary:** Measuring Fine-Grained Negotiation Tactics of Humans and LLMs in Diplomacy

- **[arXiv251223] Color, Sentiment, and Structure: A Comparative Study of Instagram Marketing Across Economies**
  - **tags:** TBD
  - **authors:** Ritesh Konka, Pranali Kurani
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18310
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e65cc34f685b4b7bf660511cdf826180cf02d70ba203ea70dda36cd297ca2194_w640_q70.webp
  - **Simple LLM Summary:** Color, Sentiment, and Structure: A Comparative Study of Instagram Marketing Across Economies

- **[arXiv251223] Adaptive Learning Mechanisms for Learning Management Systems: A Scoping Review and Practical Considerations**
  - **tags:** TBD
  - **authors:** Sebastian Kucharski, Iris Braun, Gregor Damnik, Matthias Wählisch
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18383
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2e9d57258150307a25d518af179c53c0ca673829d832d1ec68a69597699251d_w640_q70.webp
  - **Simple LLM Summary:** Adaptive Learning Mechanisms for Learning Management Systems: A Scoping Review and Practical Considerations

- **[arXiv251223] A Formal Descriptive Language for Learning Dynamics: A Five-Layer Structural Coordinate System**
  - **tags:** TBD
  - **authors:** Miyuki T. Nakata
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18525
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c5fa66d8eb7deac60effe912ce57cc5b3a8decb9a70cf6acda4def17328ab6c_w640_q70.webp
  - **Simple LLM Summary:** A Formal Descriptive Language for Learning Dynamics: A Five-Layer Structural Coordinate System

- **[arXiv251223] The MEVIR 2 Framework: A Virtue-Informed Moral-Epistemic Model of Human Trust Decisions**
  - **tags:** TBD
  - **authors:** Daniel Schwabe
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18539
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de4aed802558b93b84676a34a5c94c1e36401bacbc797e08c3d54cd9b553df8c_w640_q70.webp
  - **Simple LLM Summary:** The MEVIR 2 Framework: A Virtue-Informed Moral-Epistemic Model of Human Trust Decisions

- **[arXiv251223] Proof of Authenticity of General IoT Information with Tamper-Evident Sensors and Blockchain**
  - **tags:** TBD
  - **authors:** Kenji Saito
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18560
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/32ec910f91d8d1488c0f9d63f1d11998ee65c7eeda5092f2969d5ed6f17bd9c4_w640_q70.webp
  - **Simple LLM Summary:** Proof of Authenticity of General IoT Information with Tamper-Evident Sensors and Blockchain

- **[arXiv251223] Measuring the Impact of Student Gaming Behaviors on Learner Modeling**
  - **tags:** TBD
  - **authors:** Qinyi Liu, Lin Li, Valdemar Švábenský, Conrad Borchers, Mohammad Khalil
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18659
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/64d34ddb491ed807e5ee9ca576fcefea5ef3bafa335bbc00244fb21f30908497_w640_q70.webp
  - **Simple LLM Summary:** Measuring the Impact of Student Gaming Behaviors on Learner Modeling

- **[arXiv251223] "Even GPT Can Reject Me": Conceptualizing Abrupt Refusal Secondary Harm (ARSH) and Reimagining Psychological AI Safety with Compassionate Completion Standard (CCS)**
  - **tags:** TBD
  - **authors:** Yang Ni, Tong Yang
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18776
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4c436bec45a43d86e53531d2849399bd87e6bf3d4305bd5fa2744e56f7b83352_w640_q70.webp
  - **Simple LLM Summary:** "Even GPT Can Reject Me": Conceptualizing Abrupt Refusal Secondary Harm (ARSH) and Reimagining Psychological AI Safety with Compassionate Completion Standard (CCS)

- **[arXiv251223] Quantifying the Lifelong Impact of Resilience Interventions via Agent-Based LLM Simulation**
  - **tags:** TBD
  - **authors:** Vivienne L'Ecuyer Ming
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18803
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbb9912dc64ced0a3542815309f1cfd619aff6ad7759e8db7f3222089c75b40e_w640_q70.webp
  - **Simple LLM Summary:** Quantifying the Lifelong Impact of Resilience Interventions via Agent-Based LLM Simulation

- **[arXiv251223] Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers**
  - **tags:** TBD
  - **authors:** Bruno Campello de Souza
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18871
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/446f3fb717e9b018a154458859c845d2583ea717613eb2a7397f53ffedb8700f_w640_q70.webp
  - **Simple LLM Summary:** Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers

- **[arXiv251223] Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction**
  - **tags:** TBD
  - **authors:** Ming Li, Han Chen, Yunze Xiao, Jian Chen, Hong Jiao, Tianyi Zhou
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18880
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69c02cdd0b38302d7f949dfe357cef926fc143c19edf1038c18dd4c5b1573b09_w640_q70.webp
  - **Simple LLM Summary:** Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction

- **[arXiv251223] Configuration Work: Four Consequences of LLMs-in-use**
  - **tags:** TBD
  - **authors:** Gabriel Alcaras, Donato Ricci
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19189
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a83a2317a41e15570e4b6245ad55aba15267903a198b04d5c65b2ef3c623e155_w640_q70.webp
  - **Simple LLM Summary:** Configuration Work: Four Consequences of LLMs-in-use

- **[arXiv251223] Epistemological Fault Lines Between Human and Artificial Intelligence**
  - **tags:** TBD
  - **authors:** Walter Quattrociocchi, Valerio Capraro, Matjaž Perc
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19466
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e38aa1bf279d77f222964e2fa6eaf6b1a85cc9955ae786124894e9ed3fb93c1_w640_q70.webp
  - **Simple LLM Summary:** Epistemological Fault Lines Between Human and Artificial Intelligence

- **[arXiv251223] Learning from sanctioned government suppliers: A machine learning and network science approach to detecting fraud and corruption in Mexico**
  - **tags:** TBD
  - **authors:** Martí Medina-Hern ández, Janos Kertész, Mihály Fazekas
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19491
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4c4c038ee2a9e249f2f33259b933475235132c1cbefe5a1ac37223ea8fc2367_w640_q70.webp
  - **Simple LLM Summary:** Learning from sanctioned government suppliers: A machine learning and network science approach to detecting fraud and corruption in Mexico

- **[arXiv251223] Detecting Coordinated Activities Through Temporal, Multiplex, and Collaborative Analysis**
  - **tags:** TBD
  - **authors:** Letizia Iannucci, Elisa Muratore, Antonis Matakos, Mikko Kivelä
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19677
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1131679bb8ebe54426d2398fe26bd82130fdf3a7e9489d5343133522014524c0_w640_q70.webp
  - **Simple LLM Summary:** Detecting Coordinated Activities Through Temporal, Multiplex, and Collaborative Analysis

## 2025-12-24

- **[arXiv251224] "All You Need" is Not All You Need for a Paper Title: On the Origins of a Scientific Meme**
  - **tags:** TBD
  - **authors:** Anton Alyakin
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19700
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7dd2926116b7f555fd465c856929048f8fcdbf9a408910ee765667d89ab6c77_w640_q70.webp
  - **Simple LLM Summary:** "All You Need" is Not All You Need for a Paper Title: On the Origins of a Scientific Meme

- **[arXiv251224] CS-Guide: Leveraging LLMs and Student Reflections to Provide Frequent, Scalable Academic Monitoring Feedback to Computer Science Students**
  - **tags:** TBD
  - **authors:** Samuel Jacob Chacko, An-I Andy Wang, Lara Perez-Felkner, Sonia Haiduc, David Whalley, Xiuwen Liu
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19866
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/400e33eafa2cbde4debfc18c1a5e5f0a16f436d1494edd99b4338169da7879de_w640_q70.webp
  - **Simple LLM Summary:** CS-Guide: Leveraging LLMs and Student Reflections to Provide Frequent, Scalable Academic Monitoring Feedback to Computer Science Students

- **[arXiv251224] Counterfactual LLM-based Framework for Measuring Rhetorical Style**
  - **tags:** TBD
  - **authors:** Jingyi Qiu, Hong Chen, Zongyi Li
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19908
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6db39310497bbc29a6efe3c72529c4c231f4c45f6ccb6856571045197a2f074d_w640_q70.webp
  - **Simple LLM Summary:** Counterfactual LLM-based Framework for Measuring Rhetorical Style

- **[arXiv251224] Prediction Air Temperature in Geothermal Heat Exchangers Using Pseudorandom Numbers: The New DARL Model**
  - **tags:** TBD
  - **authors:** C. Ramírez-Dolores, J.C. Zamora-Luria, J.A. Altamirano-Acosta, L. Sarao-Cruz, P. Jiménez-Palma, J. Moreno-Falconi
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19976
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/441f7620f3757f4471a93018d5814fc4d03f1187c1a80f7194c4047e3eeea5d0_w640_q70.webp
  - **Simple LLM Summary:** Prediction Air Temperature in Geothermal Heat Exchangers Using Pseudorandom Numbers: The New DARL Model

- **[arXiv251224] S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test**
  - **tags:** TBD
  - **authors:** Zhe Sun, Xueyuan Yang, Yujie Lu, Zhenliang Zhang
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19992
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a7f6951c4ebc6cf6c8bd633198ae7d4c6a7c8f1e0cd348aa9e6737966dfe600_w640_q70.webp
  - **Simple LLM Summary:** S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test

- **[arXiv251224] Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives**
  - **tags:** TBD
  - **authors:** Karolina Drożdż, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20298
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e46ae09622d9142a3896f2528685617edcbaae96bc105754e16929ed630e3f0_w640_q70.webp
  - **Simple LLM Summary:** Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives

- **[arXiv251224] Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information**
  - **tags:** TBD
  - **authors:** İbrahim Oğuz Çetinkaya, Sajad Khodadadian, Taylan G. Topçu
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20589
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bd8f6dd1aa27848e72f81ba7279a1abe238ea198e2b3aa7513fc9ca373e7554_w640_q70.webp
  - **Simple LLM Summary:** Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information

## 2025-12-25

- **[arXiv251225] From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education**
  - **tags:** [ai], [educational technology], [generative AI, personalization, adaptive learning, large language models, intelligent tutoring systems]
  - **authors:** Iman Reihanian, Yunfei Hou, Qingquan Sun
  - **institution:** California State University, San Bernardino
  - **link:** https://arxiv.org/pdf/2512.20714
  - **contributions:** 1. Identified and analyzed five key application domains for GenAI-enabled personalization in CS education: intelligent tutoring, personalized materials, formative feedback, AI-augmented assessment, and code review. 2. Synthesized four design patterns for successful implementations: context-aware tutoring anchored in student artifacts, multi-level hint structures, composition with traditional CS infrastructure, and human-in-the-loop quality assurance. 3. Proposed an exploration-first adoption framework for integrating GenAI, emphasizing piloting, instrumentation, learning-preserving defaults, and evidence-based scaling, while pairing recurrent risks with operational mitigations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e46f313e494a41a4a12873eddb6320db4cd59b6fb958bb008fd6f6512729af4_w640_q70.webp
  - **Simple LLM Summary:** This scoping review maps how generative AI enables personalized computer science education. It analyzes design choices across 32 studies and finds that structured implementations with explanation-first guidance and artifact grounding lead to more positive learning outcomes than unconstrained chat interfaces. The paper concludes that generative AI can provide precision scaffolding when embedded in audit-ready workflows that preserve productive struggle.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education] --> B[核心问题/Problem: Does GenAI personalization support or undermine CS learning?]
    A --> C[主要方法/Method: Scoping review of 32 studies; Analysis of design choices & patterns]
    A --> D[关键结果/Results: Structured designs (e.g., hint ladders, artifact grounding) are more effective; Proposes an exploration-first adoption framework]
    ```

- **[arXiv251225] Sark: Oblivious Integrity Without Global State**
  - **tags:** [sys], [distributed ledger systems], [oblivious integrity, crash fault-tolerant blockchain, integrity locus, USO asset system, local centrality]
  - **authors:** Alex Lynham, David Alesch, Ziyi Li, Geoff Goodell
  - **institution:** University College London (UCL)
  - **link:** https://arxiv.org/pdf/2512.20775
  - **contributions:** 1. Presents Sark, a reference architecture implementing the Unforgeable, Stateful, and Oblivious (USO) asset system for oblivious, non-custodial asset management. 2. Introduces the concept of "Integrity Locus" as a framework to analyze and address design trade-offs related to decentralization. 3. Describes the design and implementation of Sloop, a permissioned crash fault-tolerant (CFT) blockchain, and Porters, subsystems that form the core of the Sark architecture.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b30bc13516511718c7bc6ed68789e79948291909f0ae043653903321e5a6bcc_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Sark, a distributed system architecture designed for managing assets with oblivious integrity, eliminating the need for a global state ledger. Its core components include the Sloop blockchain and Porters for handling client commitments, analyzed through the CIA triad. The main conclusion is that Sark offers a more decentralized trust topology by leveraging local integrity proofs instead of a global ledger, though it introduces trade-offs like local centrality.
  - **Mindmap:**

    ```mermaid
    graph LR
        A[Sark: Oblivious Integrity Without Global State] --> B(核心问题/Problem: How to achieve asset integrity without a global state ledger?);
        A --> C(主要方法/Method: Implement USO asset system with Sloop CFT blockchain & Porters);
        A --> D(关键结果/Results: Decentralized via local integrity proofs, introduces Integrity Locus concept);
    ```

- **[arXiv251225] Large Language Models Approach Expert Pedagogical Quality in Math Tutoring but Differ in Instructional and Linguistic Profiles**
  - **tags:** [nlp], [educational technology / intelligent tutoring systems], [large language models, pedagogical quality, instructional strategies, linguistic analysis, math tutoring]
  - **authors:** Ramatu Oiza Abdulsalam, Segun Aroyehun
  - **institution:** African University of Science and Technology, University of Konstanz
  - **link:** https://arxiv.org/pdf/2512.20780
  - **contributions:** 1. Conducted a controlled, turn-level comparison of tutoring responses between expert human tutors, novice human tutors, and multiple large language models (LLMs) in math remediation. 2. Identified systematic differences in instructional and linguistic profiles, finding that LLMs underuse restating/revoicing strategies but produce longer, more lexically diverse, and more polite responses compared to human tutors. 3. Established statistical associations between specific instructional/linguistic features (e.g., restating, lexical diversity) and perceived pedagogical quality, showing LLMs can achieve comparable quality using different strategies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4c157f4475efaa64bb039e61eccf65a1facd8888dde9576734865854a42e878_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how closely the instructional behavior of large language models (LLMs) aligns with expert human tutors in math tutoring. By comparing responses from experts, novices, and LLMs to the same conversation turns, the study analyzes instructional strategies and linguistic features. It finds that LLMs approach expert-level pedagogical quality on average but rely on systematically different strategies, such as underusing restating/revoicing while being more verbose and polite.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Large Language Models Approach Expert Pedagogical Quality in Math Tutoring but Differ in Instructional and Linguistic Profiles] --> B(核心问题/Problem: LLM教学行为与人类专家的一致性/Alignment of LLM instructional behavior with expert human tutors)
    A --> C(主要方法/Method: 控制性对话轮比较/Controlled turn-level comparison of expert, novice, and LLM responses)
    A --> D(关键结果/Results: LLM接近专家教学水平但策略不同/LLMs approach expert quality but use different instructional & linguistic strategies)
    ```

- **[arXiv251225] Making AI Work: An Autoethnography of a Workaround in Higher Education**
  - **tags:** [other], [Information Systems], [Autoethnography, Invisible Labour, Workaround, Sociotechnical Systems, User Innovation]
  - **authors:** Shang Chieh Lee, Bhuva Narayan, Simon Buckingham Shum, Stella Ng, A. Baki Kocaballi
  - **institution:** University of Technology Sydney
  - **link:** https://arxiv.org/pdf/2512.21055
  - **contributions:** 1. Provides an insider, autoethnographic account of the sociotechnical friction and "invisible labour" required to make enterprise GenAI functional in higher education. 2. Applies and extends Alter's theory of workarounds to interpret user-driven adaptations as integral acts of sociotechnical integration, not mere deviations. 3. Highlights the central paradox of GenAI workarounds: they enable functionality but can create unofficial "shadow" systems and obscure the crucial, politically charged labour involved.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c38d81a4b275e82620a51814d2cbc6d349963475ab4224ec58e70714de1ab37_w640_q70.webp
  - **Simple LLM Summary:** This study uses analytic autoethnography to examine a workaround developed when an institutional goal of empowering staff with GenAI clashed with technical and political constraints. It argues such workarounds are essential acts of sociotechnical integration that reveal the "invisible labour" needed to make AI functional, but this labour is often obscured, creating a paradox. The findings position this invisible labour as a core, rather than peripheral, component of practical GenAI implementation.
  - **Mindmap:**

    ```mermaid
    graph LR
        A[Making AI Work: An Autoethnography of a Workaround in Higher Education] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[GenAI实施中的社会技术摩擦与隐性劳动/Sociotechnical Friction & Invisible Labour in GenAI Implementation]
        C --> C1[分析性自我民族志与工作区理论/Analytic Autoethnography & Workaround Theory]
        D --> D1[工作区是核心的社会技术整合行为/Workarounds as Integral Sociotechnical Integration]
        D --> D2[揭示了GenAI的整合悖论/Reveals GenAI Integration Paradox]
    ```

- **[arXiv251225] Beyond Context: Large Language Models Failure to Grasp Users Intent**
  - **tags:** [nlp], [ai safety], [intent recognition, contextual understanding, safety circumvention, prompt engineering, transformer architectures]
  - **authors:** Ahmed M. Hussain, Salahuddin Salahuddin, Panos Papadimitratos
  - **institution:** KTH Royal Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.21110
  - **contributions:** 1. Identifies and empirically demonstrates a critical vulnerability in LLMs: their inability to understand user intent and context, which allows safety mechanisms to be circumvented. 2. Evaluates multiple state-of-the-art LLMs (ChatGPT, Claude, Gemini, DeepSeek) and shows that exploitation techniques like emotional framing and progressive revelation are effective, and that reasoning capabilities can amplify this risk. 3. Proposes a paradigmatic shift in AI safety design, arguing for contextual understanding and intent recognition to be core capabilities rather than post-hoc protective mechanisms.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/55c1a596dd6375317c809bb19f466455285faf18a1f9810649d755b8027e383c_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies a fundamental vulnerability in Large Language Models (LLMs): their lack of contextual understanding and intent recognition, which allows safety mechanisms to be systematically bypassed. The authors empirically evaluate several LLMs, showing they can be exploited through techniques like emotional framing, and find that reasoning capabilities often worsen the problem. They conclude that a paradigm shift is needed to build intent recognition directly into LLM architectures for safety.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Beyond Context: Large Language Models Failure to Grasp Users Intent] --> B[核心问题/Problem: LLMs缺乏上下文和意图理解能力/LLMs lack contextual understanding & intent recognition]
    A --> C[主要方法/Method: 对多种LLM进行经验性评估/Empirical evaluation of multiple LLMs]
    A --> D[关键结果/Results: 安全机制可被系统规避，需范式转变/Safety mechanisms can be systematically circumvented, requiring a paradigm shift]
    B --> E[导致可利用的漏洞/Creates exploitable vulnerabilities]
    C --> F[使用情感框架、渐进揭示等技术/Using emotional framing, progressive revelation, etc.]
    D --> G[Claude Opus 4.1部分例外，推理能力加剧风险/Claude Opus 4.1 partial exception, reasoning amplifies risk]
    ```

- **[arXiv251225] Microtopia: Exploring the Impact of Interdisciplinary Projects on Ethnic Minority Female Pupils' Perceptions of Computer Science**
  - **tags:** [other], [computer science education, diversity and inclusion], [interdisciplinary learning, design thinking, sustainable development goals, AI/IoT/Robotics, problem-based learning]
  - **authors:** Nadine Aburumman, Ju-Ling Shih, Cigdem Sengul, Monica Pereira
  - **institution:** [Inferred from authors: Nadine Aburumman, Ju-Ling Shih, Cigdem Sengul, Monica Pereira. No explicit affiliations in provided text. Institution cannot be reliably inferred.]
  - **link:** https://arxiv.org/pdf/2512.21214
  - **contributions:** 1. Proposes the Microtopia programme, an interdisciplinary CS initiative integrating AI, IoT, and Robotics with design thinking and collaborative project work. 2. Demonstrates that linking CS content to real-world sustainability challenges and global issues significantly enhances engagement and perceived relevance among ethnic minority female pupils. 3. Identifies through statistical analysis that socioeconomic and ethnocultural factors (e.g., SES, perception of field as male-dominated) are underlying factors shaping pupils' perceptions of CS.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05065a9796e995884552033fb1ebac6397879e6ec0b2560e03b8ac9fb067c627_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Microtopia, an interdisciplinary programme that combines coding, AI, IoT, and Robotics with design thinking and sustainability themes to broaden participation in computer science among ethnic minority girls. The study, using pre- and post-questionnaires, found that participation significantly increased students' confidence, enjoyment, and motivation, especially when computing was presented as relevant to solving global challenges.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Microtopia: Exploring the Impact of Interdisciplinary Projects on Ethnic Minority Female Pupils' Perceptions of Computer Science] --> B(核心问题/Problem: Broadening participation of ethnic minority girls in CS)
    A --> C(主要方法/Method: Interdisciplinary programme with AI/IoT/Robotics, design thinking, SDGs, collaborative projects)
    A --> D(关键结果/Results: Increased confidence, enjoyment, motivation; CS linked to sustainability enhances engagement)
    ```
