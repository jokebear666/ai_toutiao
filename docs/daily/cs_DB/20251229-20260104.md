---
slug: /daily/csdb/20251229-20260104
---
# 20251229-20260104 (cs.DB)

## 2025-12-29

- **[arXiv251229] Harnessing Data Spaces to Build Intelligent Smart City Infrastructures Across the Cloud-Edge Continuum**
  - **tags:** [mlsys], [on-device ai], [data spaces, cloud-edge continuum, containerized microservices, edge AI, intelligent infrastructure monitoring]
  - **authors:** Dimitrios Amaxilatis, Themistoklis Sarantakos, Nikolaos Tsironis, Souvik Sengupta, Kostas Ramantas, Jhofre Ojeda
  - **institution:** Spark Works Ltd., IONOS SE, Iquadrat Informática S.L.
  - **link:** https://arxiv.org/pdf/2512.21340
  - **contributions:** 1. A real-world implementation of intelligent infrastructure monitoring within a data space-enabled cloud-edge framework, demonstrating practical integration. 2. Leveraging edge computing, containerized microservices, and interoperable data sharing to address challenges like sensor integration, data privacy, and scalability. 3. Showcasing the training and deployment of AI/ML services directly at the edge for optimized resource use and timely decision-making in smart city applications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a real-world use case for smart cities, implementing an intelligent climate monitoring system within a cloud-edge continuum framework enabled by data spaces. The method combines edge computing, containerized microservices, and secure data sharing to facilitate localized analytics and AI deployment. The conclusion highlights the transformative potential of integrating AI, edge computing, and data spaces for building efficient and resilient smart city infrastructures.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Harnessing Data Spaces for Smart City Infrastructures] --> B[核心问题/Problem: Enhancing smart city efficiency, sustainability, and resilience with secure, interoperable data exchange]
        A --> C[主要方法/Method: Data space-enabled cloud-edge framework with edge computing, containerized microservices, and edge AI/ML]
        A --> D[关键结果/Results: Demonstrates practical use case for intelligent monitoring, enabling localized analytics, real-time inference, and trusted data collaboration]
    ```

- **[arXiv251229] Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks**
  - **tags:** [db], [text-to-SQL], [unanswerable question detection, few-shot prompting, biomedical databases]
  - **authors:** Jasmin Saxer, Isabella Maria Aigner, Luise Linzmeier, Andreas Weiler, Kurt Stockinger
  - **institution:** Zurich University of Applied Sciences, University of Zurich
  - **link:** https://arxiv.org/pdf/2512.21345
  - **contributions:** 1. Proposed Query Carefully, a pipeline integrating LLM-based SQL generation with explicit detection of unanswerable inputs. 2. Constructed OncoMX-NAQ, a benchmark dataset of 80 no-answer questions for biomedical text-to-SQL. 3. Demonstrated that balanced few-shot prompting with both answerable and unanswerable examples achieves high unanswerable-detection accuracy without degrading performance on answerable queries.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d95c00b7fa86810771a1c8fb0ff6fd8768baaa0419f172cc5c7a3068ac67a64_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the risk of text-to-SQL systems generating executable but incorrect SQL for ambiguous or unanswerable queries, especially in biomedical contexts. The authors propose the Query Carefully pipeline, which uses an LLM with schema-aware prompts and few-shot examples to detect and abstain from unanswerable inputs. Their evaluation shows the method achieves high detection accuracy for structurally unanswerable queries, though challenges remain for semantic ambiguities like missing values.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks") --> Problem
        Root --> Method
        Root --> Results
        Problem("核心问题/Problem") --> P1("Text-to-SQL对不可回答查询生成可执行SQL/Text-to-SQL generates executable SQL for unanswerable queries")
        P1 --> P2("生物医学领域风险高/High risk in biomedical contexts")
        Method("主要方法/Method") --> M1("Query Carefully 管道/Query Carefully pipeline")
        M1 --> M2("LLM (llama3.3:70b) + 模式感知提示 + 少样本/LLM (llama3.3:70b) + schema-aware prompts + few-shot")
        M2 --> M3("包含可回答与不可回答示例/Includes answerable and unanswerable examples")
        Results("关键结果/Results") --> R1("构建OncoMX-NAQ基准/Built OncoMX-NAQ benchmark")
        R1 --> R2("不可回答检测准确率0.8/Unanswerable-detection accuracy 0.8")
        R2 --> R3("结构性问题检测好，语义模糊挑战大/Good for structural, challenging for semantic ambiguity")
    ```

- **[arXiv251229] Weighted Fourier Factorizations: Optimal Gaussian Noise for Differentially Private Marginal and Product Queries**
  - **tags:** [sec], [differential privacy], [factorization mechanism, Fourier basis, marginal queries, product queries, Gaussian noise]
  - **authors:** Christian Janos Lebeda, Aleksandar Nikolov, Haohua Tang
  - **institution:** Inria, Université de Montpellier, INSERM, University of Toronto
  - **link:** https://arxiv.org/pdf/2512.21499
  - **contributions:** 1. Proposes a simpler, polynomial-time algorithm for releasing weighted marginal queries under differential privacy using Fourier factorization, achieving exact optimality among factorization mechanisms. 2. Extends the algorithm to a more general class of product queries, maintaining exact optimality. 3. Shows the mechanism is almost optimal for extended marginal queries with threshold predicates, achieving optimal noise variance up to lower-order terms.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/589c857d3c263098ff5b7608b80fed9cb6cf72f1228f01d3ba136496420444dc_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new algorithm for releasing marginal and product queries under differential privacy by adding correlated Gaussian noise. The method works by releasing queries in the Fourier basis with independent, carefully calibrated noise and then reconstructing the answers, which is proven to be exactly optimal among factorization mechanisms and runs in polynomial time. It simplifies and improves upon prior work, extending optimality to more general query classes.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Weighted Fourier Factorizations<br>加权傅里叶分解] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Releasing marginal queries<br>with differential privacy<br>在差分隐私下发布边际查询]
        C --> C1[Use Fourier basis &<br>independent Gaussian noise<br>使用傅里叶基和独立高斯噪声]
        C --> C2[Reconstruct via<br>inverse Fourier transform<br>通过逆傅里叶变换重构]
        D --> D1[Exactly optimal for<br>marginal & product queries<br>对边际和乘积查询精确最优]
        D --> D2[Polynomial-time algorithm<br>多项式时间算法]
        D --> D3[Simpler & better than<br>prior work (Xiao et al.)<br>比先前工作更简单更好]
    ```

- **[arXiv251229] Embedding Samples Dispatching for Recommendation Model Training in Edge Environments**
  - **tags:** [mlsys], [memory & caching], [edge computing, embedding cache, parameter server, sample dispatching, transmission cost]
  - **authors:** Guopeng Li, Haisheng Tan, Chi Zhang, Hongqiu Ni, Zilong Wang, Xinyue Zhang, Yang Xu, Han Tian
  - **institution:** University of Science and Technology of China (USTC), Hefei University of Technology
  - **link:** https://arxiv.org/pdf/2512.21615
  - **contributions:** 1. Proposed ESD, a novel mechanism to optimize the dispatch of input embedding samples to edge workers to minimize embedding transmission cost. 2. Designed HybridDis, a dispatch decision method that combines an optimal algorithm and a heuristic to balance decision quality and resource consumption. 3. Implemented a prototype and demonstrated significant reductions in transmission cost (up to 36.76%) and training speedup (up to 1.74x) on real-world workloads.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f94cc43f65f5fd909f8762bda535a33eea94f879931ebe1a563280cb0db1be81_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high communication cost of embedding transmission during Deep Learning Recommendation Model (DLRM) training in edge environments. It proposes ESD, a mechanism that dispatches input samples to edge workers to minimize expected transmission cost, using a hybrid decision method called HybridDis. Experimental results show that ESD significantly reduces transmission cost and speeds up end-to-end training compared to state-of-the-art methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Embedding Samples Dispatching for Recommendation Model Training in Edge Environments<br>边缘环境中推荐模型训练的嵌入样本调度"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>DLRM边缘训练中嵌入传输成本高"] --> P1["挑战/Challenges<br>异构网络，资源受限"]
        Method["主要方法/Method<br>ESD机制与HybridDis调度"] --> M1["方法核心/Core<br>基于预期传输成本的样本调度"]
        Results["关键结果/Results<br>减少传输成本，加速训练"] --> R1["性能提升/Improvement<br>成本降低36.76%，速度提升1.74倍"]
    ```

- **[arXiv251229] Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets**
  - **tags:** [sec], [Data Provenance], [Data Provenance, Compliance Rating, Generative AI, Dataset Ethics, Transparency]
  - **authors:** Matyas Bohacek, Ignacio Vilanova Echavarri
  - **institution:** Stanford University, Imperial College London
  - **link:** https://arxiv.org/pdf/2512.21775
  - **contributions:** 1. Proposes the Compliance Rating Scheme (CRS), a framework for evaluating dataset compliance with transparency, accountability, and security principles. 2. Develops and releases an open-source Python library that implements the CRS framework using data provenance technology. 3. Creates a tool that is both reactive (evaluating existing datasets) and proactive (guiding the responsible construction of new datasets).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa33a1fedd52ef1c87e9bf7d9a25dad61aae942ba50660263862470b9b677745_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of ethical and legal oversight in the creation and sharing of datasets for Generative AI. It proposes the Compliance Rating Scheme (CRS) framework and an accompanying open-source library to assess and ensure dataset compliance with key principles. The work aims to improve traceability and accountability in the AI data supply chain.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("数据集创建缺乏伦理与法律监督/Lack of ethical & legal oversight in dataset creation")
        Problem --> P2("数据来源与合法性信息丢失/Loss of data origin & legitimacy info")
        Method --> M1("提出合规评级方案(CRS)框架/Propose Compliance Rating Scheme (CRS) framework")
        Method --> M2("开发基于数据溯源技术的开源库/Develop open-source library using data provenance")
        Results --> R1("评估现有数据集的合规性/Evaluate compliance of existing datasets")
        Results --> R2("指导负责任的新数据集构建/Guide responsible construction of new datasets")
    ```

- **[arXiv251229] Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs**
  - **tags:** [mlsys], [others], [Tabular Data Generation, Large Language Models, Multi-Arm Bandit, Data Diversity, In-context Learning]
  - **authors:** Yafeng Tang, Xiaoou Ding, Jianzhuo Du, Zishuo Yan, Zhuang Ma, Zheng Liang, Zekai Qian, Hongzhi Wang
  - **institution:** Harbin Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.21915
  - **code:** https://github.com/windblow32/DATE
  - **contributions:** 1. Introduces DATE, a framework that partitions heterogeneous tabular data into diverse subsets to prepare high-quality examples for in-context learning. 2. Proves the selection problem in heterogeneous data generation lacks the greedy-choice property and designs a Multi-Arm Bandit-based sampling algorithm to balance diversity and quality. 3. Demonstrates that DATE-generated data improves downstream tasks like Direct Preference Optimization (DPO) and enhances LLM reasoning on target data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d8fa8039f8a5fa0717fc5e4a9c7ba2cf1fd158e44821059f4a767bc88790eaf_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of generating high-quality synthetic tabular data from heterogeneous distributions. It proposes DATE, a framework that uses LLMs with decision tree feedback for subset-specific generation and a Multi-Arm Bandit algorithm for data selection. Experiments show DATE outperforms existing methods, reducing error rates and improving downstream model performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs"] --> Problem["核心问题/Problem: Real-world tabular data is heterogeneous, making universal generation models challenging"]
        Root --> Method["主要方法/Method: DATE framework partitions data, uses LLMs with decision tree feedback, and applies Multi-Arm Bandit for selection"]
        Root --> Results["关键结果/Results: Outperforms SOTA methods, reduces error rate by 23.75%, improves DPO and LLM reasoning"]
    ```

## 2025-12-30

- **[arXiv251230] MonoM: Enhancing Monotonicity in Learned Cardinality Estimators**
  - **tags:** [db], [query optimization], [cardinality estimation, monotonicity, regularization, workload generator, MSCN]
  - **authors:** Lyu Yi, Weiqi Feng, Yuanbiao Wang, Yuhong Kan
  - **institution:** University of Wisconsin–Madison, Harvard University, University of Texas at Austin
  - **link:** https://arxiv.org/pdf/2512.22122
  - **contributions:** 1. Proposes MonoM, a metric to quantitatively measure monotonicity adherence in cardinality estimators. 2. Introduces a monotonic training framework with a workload generator for producing directly comparable queries. 3. Designs a novel regularization term for the loss function to enforce monotonicity and improve generalization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c0c68b14fa636a4e8969cdb572e60e2fdd2e789895a2bce33cefa2686133c9b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of learned cardinality estimators violating monotonicity, a key barrier to their adoption. It proposes a new metric (MonoM) and a training framework with a specialized workload generator and a regularization term to enforce monotonicity. Experiments show the method improves both monotonicity adherence and estimation accuracy by reducing overfitting.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MonoM: Enhancing Monotonicity<br>增强单调性] --> B(Problem: Learned estimators violate monotonicity<br>问题: 学习模型违反单调性)
        A --> C(Method: MonoM metric & training framework<br>方法: MonoM指标与训练框架)
        C --> D(Sub-Method: Workload generator<br>子方法: 工作负载生成器)
        C --> E(Sub-Method: Regularization term<br>子方法: 正则化项)
        A --> F(Results: Improves monotonicity & accuracy<br>结果: 提升单调性与准确性)
    ```

- **[arXiv251230] Valori: A Deterministic Memory Substrate for AI Systems**
  - **tags:** [mlsys], [memory & caching], [deterministic memory, fixed-point arithmetic, vector embeddings, approximate nearest neighbor search, state machine]
  - **authors:** Varshith Gudur
  - **institution:** Independent Researcher (Valori Kernel Project)
  - **link:** https://arxiv.org/pdf/2512.22280
  - **code:** https://github.com/varshith-Git/Valori-Kernel
  - **contributions:** 1. Identifies and characterizes the fundamental non-determinism in AI memory systems caused by hardware-dependent floating-point arithmetic, which leads to divergent memory states and retrieval results. 2. Proposes Valori, a deterministic AI memory substrate that replaces floating-point operations with fixed-point arithmetic (Q16.16) and models memory as a replayable state machine. 3. Demonstrates that Valori guarantees bit-identical memory states, snapshots, and search results across different hardware platforms (e.g., x86 vs. ARM), establishing deterministic memory as a necessary primitive for trustworthy AI.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb7ed17a8a06e6a2b8760f08fa9345391995aee74a3542cacf55dd051b383f_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies non-determinism in AI memory systems due to hardware-dependent floating-point arithmetic, which compromises replayability and auditability. It proposes Valori, a memory substrate using fixed-point arithmetic and a state machine model to guarantee bit-identical behavior across platforms. The work concludes that deterministic memory is essential for building trustworthy AI systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Valori: A Deterministic Memory Substrate for AI Systems] --> B
        A --> C
        A --> D
        B[核心问题/Problem: AI内存非确定性/AI Memory Non-Determinism]
        C[主要方法/Method: 固定点算术与状态机/Fixed-Point Arithmetic & State Machine]
        D[关键结果/Results: 跨平台比特一致性/Cross-Platform Bit-Identical Results]
    ```

- **[arXiv251230] Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries**
  - **tags:** [mlsys], [llm inference], [Text-to-SQL, Cloud Cost Optimization, Query Efficiency, Large Language Models, Google BigQuery]
  - **authors:** Saurabh Deochake, Debajyoti Mukhopadhyay
  - **institution:** SentinelOne, WIDiCoReL Research Lab
  - **link:** https://arxiv.org/pdf/2512.22364
  - **contributions:** 1. Introduced a cloud-native cost evaluation methodology for Text-to-SQL systems, measuring bytes processed, slot utilization, and estimated query cost on production infrastructure. 2. Conducted an empirical evaluation of six LLMs on Google BigQuery, demonstrating that reasoning models achieve significantly lower cloud compute costs while maintaining high correctness. 3. Quantified cost variance across models, identified prevalent inefficiency patterns (e.g., missing partition filters), and provided deployment guidelines for cost-sensitive environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06f17566f5fb65cb73b79b0dbb64bde11c2f87d177f02865af7fc2d8910e3ac4_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the cloud compute costs of SQL queries generated by Large Language Models (LLMs) for Text-to-SQL tasks. By evaluating six state-of-the-art LLMs on Google BigQuery, it finds that reasoning models are more cost-efficient, processing far fewer bytes, and that execution time is a poor proxy for cloud cost. The work provides a new cost-focused evaluation methodology and guidelines for deploying cost-aware Text-to-SQL systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Existing efficiency metrics (e.g., VES) measure time, not cloud compute costs.] --> B1[问题背景/Context<br>LLMs achieve high Text-to-SQL accuracy, but cost efficiency in cloud deployments is unknown.]
        C[主要方法/Method<br>Systematic evaluation of 6 LLMs on Google BigQuery (StackOverflow dataset).] --> C1[评估指标/Metrics<br>Measure bytes processed, slot utilization, estimated cost, and correctness.]
        D[关键结果/Results] --> D1[发现1/Finding 1<br>Reasoning models process 44.5% fewer bytes with equivalent correctness.]
        D --> D2[发现2/Finding 2<br>Weak correlation (r=0.16) between execution time and query cost.]
        D --> D3[发现3/Finding 3<br>Up to 3.4x cost variance; standard models produce high-cost outliers.]
    ```

- **[arXiv251230] Robust LLM-based Column Type Annotation via Prompt Augmentation with LoRA Tuning**
  - **tags:** [mlsys], [llm training], [Column Type Annotation, Prompt Augmentation, LoRA, Parameter-Efficient Fine-Tuning, Prompt Sensitivity]
  - **authors:** Hanze Meng, Jianhao Cao, Rachel Pottinger
  - **institution:** University of British Columbia
  - **link:** https://arxiv.org/pdf/2512.22742
  - **code:** https://github.com/fripSideMeng/PACTA
  - **contributions:** 1. Proposes a parameter-efficient fine-tuning framework for Column Type Annotation (CTA) using Low-Rank Adaptation (LoRA) to reduce computational cost. 2. Introduces a prompt augmentation strategy during training to mitigate model sensitivity to variations in prompt wording and structure. 3. Demonstrates robust and stable performance across diverse datasets and prompt templates, achieving higher weighted F1 scores than single-template fine-tuning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95317c9af6072a1e0ffbb34950b7d9da057c55baaf301c56bb751746b366785a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenges of prompt sensitivity and high computational cost in using Large Language Models (LLMs) for Column Type Annotation. It proposes a parameter-efficient framework that fine-tunes LLMs using LoRA on prompt-augmented data. The method achieves robust performance across different prompts and datasets while requiring significantly fewer trainable parameters.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Robust LLM-based Column Type Annotation via Prompt Augmentation with LoRA Tuning") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("现有方法对提示词敏感/Existing methods are sensitive to prompts")
        Problem --> P2("完全微调成本高昂/Full fine-tuning is computationally prohibitive")
        Method --> M1("使用LoRA进行参数高效微调/Parameter-efficient fine-tuning with LoRA")
        Method --> M2("使用增强的提示数据进行训练/Training on prompt-augmented data")
        Results --> R1("对不同提示模式性能稳定/Stable performance across diverse prompts")
        Results --> R2("获得更高的加权F1分数/Higher weighted F1 scores")
    ```

- **[arXiv251230] OrchANN: A Unified I/O Orchestration Framework for Skewed Out-of-Core Vector Search**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [out-of-core, approximate nearest neighbor search, I/O orchestration, vector search, SSD]
  - **authors:** Chengying Huan, Lizheng Chen, Zhengyi Yang, Shaonan Ma, Rong Gu, Renjie Yao, Zhibin Wang, Mingxing Zhang, Fang Xi, Jie Tao, Gang Zhang, Guihai Chen, Chen Tian
  - **institution:** Nanjing University, University of New South Wales, AISoft (QiyuanLab), Tsinghua University, China Mobile (Suzhou) Software Technology Co., Ltd.
  - **link:** https://arxiv.org/pdf/2512.22838
  - **contributions:** 1. Introduces a heterogeneous local index selection per cluster via offline auto-profiling to match varying cluster scales. 2. Maintains a query-aware in-memory navigation graph that adapts to skewed query workloads for efficient routing. 3. Applies multi-level pruning with geometric bounds to filter clusters and vectors before issuing SSD reads, preventing "fetch-to-discard" overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efdb94f456d7410c515c5dcba047400662a1afb3a011cd9a57efd9526c5cc408_w640_q70.webp
  - **Simple LLM Summary:** The paper presents OrchANN, a new out-of-core approximate nearest neighbor search engine designed for billion-scale vector search where data resides on SSD. It addresses performance degradation under skewed data distributions by unifying I/O governance through adaptive navigation and multi-level pruning. OrchANN significantly outperforms existing systems in queries per second and latency while reducing SSD accesses, without sacrificing accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("OrchANN: A Unified I/O Orchestration Framework for Skewed Out-of-Core Vector Search") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("大规模ANNS是外存问题/Large-scale ANNS is an out-of-core problem")
        Problem --> P2("现有系统在倾斜数据下失效/Existing systems break down under skewed data")
        Method --> M1("异构本地索引/Heterogeneous local index per cluster")
        Method --> M2("查询感知导航图/Query-aware in-memory navigation graph")
        Method --> M3("多级剪枝/Multi-level pruning with geometric bounds")
        Results --> R1("更高的QPS和更低延迟/Higher QPS and lower latency")
        Results --> R2("减少SSD访问/Reduced SSD accesses")
        Results --> R3("保持准确性/Maintains accuracy")
    ```

- **[arXiv251230] Time Sensitive Multiple POIs Route Planning on Bus Networks**
  - **tags:** [db], [route planning], [bus network, time-sensitive, EA-Star algorithm, DME-Graph, A* algorithm]
  - **authors:** Simu Liu, Kailin Jiao, Junping Du, Yawen Li, Zhe Xue, Xiaoyang Sean Wang, Ziqiang Yu, Yunchuan Shi
  - **institution:** Yantai University, Shandong University, Beijing University of Posts and Telecommunications, Fudan University
  - **link:** https://arxiv.org/pdf/2512.22893
  - **contributions:** 1. Proposed a modified graph structure (DME-Graph) to model bus networks with varying travel and waiting times. 2. Introduced the EA-Star algorithm to efficiently find the optimal route by evaluating promising POI visit sequences and using a terminal condition. 3. Employed the A* algorithm on the modified graph to compute the shortest route for each sequence, narrowing the search space and improving efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4fea9498baf83db6fa13479c937b5c1a0181f3763fbacddea216bc87c93a7e0_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the time-sensitive multi-POI route planning problem on bus networks, where travel and waiting times vary. The authors propose a new graph model (DME-Graph) and the EA-Star algorithm, which combines sequence evaluation with A* search, to find the optimal route efficiently. Experiments on the New York bus network demonstrate the effectiveness of the proposed approach.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Time Sensitive Multiple POIs Route Planning on Bus Networks] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[公交网络多POI路径规划/Bus Network Multi-POI Route Planning]
        B --> B2[最小化包含等待时间的总旅行时间/Minimize Total Travel Time Including Waiting]
        C --> C1[提出DME-Graph模型/Propose DME-Graph Model]
        C --> C2[设计EA-Star算法/Design EA-Star Algorithm]
        C2 --> C2_1[结合A*搜索与序列评估/Combine A* Search & Sequence Evaluation]
        D --> D1[在纽约公交数据集上验证有效/Validated on New York Bus Dataset]
    ```

- **[arXiv251230] Evolution of Buffer Management in Database Systems: From Classical Algorithms to Machine Learning and Disaggregated Memory**
  - **tags:** [db], [buffer management], [cache replacement, machine learning, disaggregated memory, eBPF, NVM]
  - **authors:** Prudhvi Gadupudi, Suman Saha
  - **institution:** The Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2512.22995
  - **contributions:** 1. Provides a historical analysis and systematic taxonomy of buffer management algorithms from classical heuristics to modern learned policies. 2. Examines implementation details and trade-offs in production database systems and operating systems like PostgreSQL, Oracle, and Linux. 3. Surveys emerging trends and outlines a future research direction integrating machine learning with kernel extensibility (eBPF) for adaptive, cross-layer buffer management in heterogeneous memory hierarchies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/009dc91aabc69a6fa35d611d86e0b83916498ee8fea16451b55cdd26e0e623cd_w640_q70.webp
  - **Simple LLM Summary:** This paper is a comprehensive survey that traces the evolution of buffer management in database systems over four decades. It systematically reviews the progression from classical algorithms (e.g., LRU-K, ARC) to contemporary approaches using machine learning and architectures for disaggregated memory. The authors conclude by proposing a research direction that integrates machine learning with kernel extensibility to enable adaptive buffer management for modern heterogeneous memory systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Evolution of Buffer Management in Database Systems] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Bridging the latency gap between CPU and storage] --> P1[内存层次结构/Memory Hierarchy]
        Problem --> P2[性能关键组件/Performance Critical Component]
        Method[主要方法/Method: Comprehensive survey of evolution] --> M1[历史分析/Historical Analysis]
        Method --> M2[分类与实现研究/Taxonomy & Implementation Study]
        Method --> M3[新兴趋势调研/Emerging Trends Survey]
        Results[关键结果/Results: Identified patterns and future direction] --> R1[架构模式与权衡/Architectural Patterns & Trade-offs]
        Results --> R2[开放挑战/Open Research Challenges]
        Results --> R3[研究方向/Research Direction: ML + eBPF for adaptation]
    ```

- **[arXiv251230] ChronoConnect: Tracking Pathways Along Highly Dynamic Vertices in Temporal Graphs**
  - **tags:** [db], [temporal graph analysis], [temporal pathways, dynamic vertices, parallel processing, interactive visualization]
  - **authors:** Jiacheng Ding, Cong Guo, Xiaofei Zhang
  - **institution:** University of Memphis
  - **link:** https://arxiv.org/pdf/2512.23289
  - **contributions:** 1. Introduces ChronoConnect, a novel system for tracking temporal pathways in evolving graphs with a focus on highly dynamic vertices. 2. Proposes a methodology for extracting significant subgraphs that maintain temporal correlation among dynamic vertices to understand information propagation. 3. Provides an interactive user interface for graph visualization and query result exploration, enabling detailed examination of information flow.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb4541a015072fd8bffa44223cd262753902794a2deeb1726333290cd1c78cf9_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces ChronoConnect, a system designed to track information propagation pathways in temporal graphs, with a specific focus on analyzing the role of highly dynamic vertices. It enables users to configure temporal traversal algorithms and utilizes parallel processing to handle large-scale evolving graphs. The system is presented as an effective tool for analyzing information diffusion patterns over time.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ChronoConnect: Tracking Pathways in Temporal Graphs] --> B(核心问题/Problem: Existing static snapshot systems struggle to capture temporal information flows.)
        A --> C(主要方法/Method: Novel system ChronoConnect tracks pathways along highly dynamic vertices using parallel processing.)
        A --> D(关键结果/Results: Enables efficient analysis of information diffusion with interactive visualization.)
    ```

- **[arXiv251230] BRkNN-light: Batch Processing of Reverse k-Nearest Neighbor Queries for Moving Objects on Road Networks**
  - **tags:** [db], [spatial databases], [reverse k-nearest neighbor, road network, batch processing, moving objects, dynamic caching]
  - **authors:** Anbang Song, Ziqiang Yu, Wei Liu, Yating Xu, Mingjin Tao
  - **institution:** Yantai University
  - **link:** https://arxiv.org/pdf/2512.23298
  - **contributions:** 1. Proposes the first exploration of batch processing for multiple RkNN queries on road networks to share computations and reduce costs. 2. Introduces the BRkNN-Light algorithm with rapid verification, pruning, and optimized range search for efficient individual query processing. 3. Designs a dynamic distance caching mechanism to enable computation reuse across multiple queries, significantly cutting unnecessary calculations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d343019169c0724222b0ab633a704338a075b230d1f2f1fe0089add7e443a1ec_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of efficiently processing multiple simultaneous Reverse k-Nearest Neighbor queries for moving objects on road networks. It proposes the BRkNN-Light algorithm, which uses geometric pruning, optimized search, and a dynamic caching mechanism to share computations across queries. Experiments on real-world road networks show the algorithm's superiority in batch query processing.
  - **Mindmap:**

    ```mermaid
    graph TB
    Root("BRkNN-light: Batch Processing of Reverse k-Nearest Neighbor Queries for Moving Objects on Road Networks") --> Problem("核心问题/Problem")
    Root --> Method("主要方法/Method")
    Root --> Results("关键结果/Results")
    Problem --> P1("现有方法忽略批量查询处理/Existing methods overlook batch query processing")
    Problem --> P2("无法共享冗余计算/Cannot share redundant computations")
    Method --> M1("BRkNN-Light算法/BRkNN-Light Algorithm")
    M1 --> M1_1("快速验证与剪枝/Rapid verification & pruning")
    M1 --> M1_2("优化范围搜索/Optimized range search")
    M1 --> M1_3("动态距离缓存/Dynamic distance caching")
    Results --> R1("减少总体计算成本/Reduces overall computation cost")
    Results --> R2("实验证明优越性/Experiments demonstrate superiority")
    ```

- **[arXiv251230] Flexible Keyword-Aware Top-$k$ Route Search**
  - **tags:** [db], [spatial databases], [keyword-aware route search, top-k query, explore-and-bound paradigm, bound estimation, POI (Point of Interest)]
  - **authors:** Ziqiang Yu, Xiaohui Yu, Yueting Chen, Wei Liu, Anbang Song, Bolong Zheng
  - **institution:** Yantai University, York University, Seattle University, Wuhan University of Technology
  - **link:** https://arxiv.org/pdf/2512.23319
  - **contributions:** 1. Introduces the Keyword-Aware Top-k Routes (KATR) query, a flexible semantic for route planning that supports flexible POI visiting order, flexible travel distance budget, and personalized POI ratings., 2. Proposes an efficient explore-and-bound paradigm to process KATR queries by pruning redundant route candidates using estimated score bounds at global and local levels., 3. Demonstrates through extensive experiments that the proposed approach outperforms existing methods in various scenarios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/71fbb7c8673230f33df0d1038d081c3e752c58145cafe731ca10b83c9a359a8d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of generating optimal tourist routes based on keyword queries, which is challenging for LLMs due to the vast search space of POIs and routes. It proposes the KATR query for flexible route planning and an efficient explore-and-bound algorithm to find top-k routes. Experiments show the method's superior performance over existing approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Flexible Keyword-Aware Top-k Route Search<br>论文标题") --> Problem("LLMs无法生成满足详细需求的最优路线<br>核心问题/Problem")
        Root --> Method("提出KATR查询与探索-定界范式<br>主要方法/Method")
        Root --> Results("方法在多种场景下性能优于现有方法<br>关键结果/Results")
        Problem --> Method
        Method --> Results
    ```

- **[arXiv251230] Database Theory in Action: From Inexpressibility to Efficiency in GQL's Order-Constrained Paths**
  - **tags:** [db], [graph query languages], [GQL, property graphs, pattern matching, order-constrained paths, leveled graphs]
  - **authors:** Hadar Rotschield, Liat Peterfreund
  - **institution:** The Hebrew University of Jerusalem
  - **link:** https://arxiv.org/pdf/2512.23330
  - **code:** https://github.com/hadarrot/Order-Constrained-Paths-in-Leveled-Graphs
  - **contributions:** 1. A constructive translation that overcomes the expressiveness limitation of core GQL for checking increasing edge values along a path. 2. A compilation method that transforms the input graph and order condition into a leveled graph to capture the intended semantics. 3. A proof-of-concept implementation demonstrating that the compiled approach yields practical performance gains, running faster and avoiding timeouts compared to native expressions in systems like Neo4j's Cypher.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37076b55eeee6292e1ced20bc6e34983c94d5ae41216828cbf2e182f986c992_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the inexpressibility of order-constrained path queries (e.g., checking for increasing edge values) in the core GQL standard. It proposes a method to compile this condition into the input graph, creating a leveled graph that enables such queries via reachability. The implementation shows this theoretically motivated translation not only closes the expressiveness gap but also leads to significant performance improvements in practice.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Database Theory in Action: From Inexpressibility to Efficiency in GQL's Order-Constrained Paths"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Core GQL cannot express<br>increasing edge values along a path"]
        Method["主要方法/Method<br>Compile condition into input graph<br>using leveled graph construction"]
        Results["关键结果/Results<br>Restores expressiveness<br>and improves performance"]
    ```

- **[arXiv251230] HL-index: Fast Reachability Query in Hypergraphs**
  - **tags:** [db], [graph databases], [hypergraph, reachability query, s-reachability, HL-index, index construction]
  - **authors:** Peiting Xie, Xiangjun Zai, Yanping Wu, Xiaoyang Wang, Wenjie Zhang, Lu Qin
  - **institution:** The University of New South Wales, University of Technology Sydney
  - **link:** https://arxiv.org/pdf/2512.23345
  - **contributions:** 1. Introduces the novel concept of s-reachability and the max-reachability query for hypergraphs, generalizing traditional reachability to model groupwise interactions. 2. Proposes the HL-index, a compact vertex-to-hyperedge index specifically designed to answer max-reachability queries efficiently. 3. Develops a fast covering relationship detection method and a lightweight neighbor-index to accelerate the construction of a minimal HL-index.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/319a455ca1c94672837d9f4e7ca6e0f1c6b652927ab50a3eaefdfd43f2b3cffc_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of efficiently answering reachability queries in hypergraphs, which model complex group interactions. It proposes a new index structure called HL-index, along with optimization techniques for its construction, to solve the max-reachability query problem. Experiments on 20 datasets show the approach is efficient and scalable.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HL-index: Fast Reachability Query in Hypergraphs] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[超图可达性查询<br>Hypergraph Reachability Query]
        B --> B2[建模高阶群体交互<br>Modeling Higher-order Group Interactions]
        C --> C1[提出s-可达性与最大可达性查询<br>Propose s-reachability & Max-reachability Query]
        C --> C2[设计HL-index索引结构<br>Design HL-index Structure]
        C --> C3[快速覆盖关系检测与邻居索引<br>Fast Covering Detection & Neighbor-index]
        D --> D1[在20个数据集上验证<br>Validated on 20 Datasets]
        D --> D2[高效且可扩展<br>Efficient and Scalable]
    ```

- **[arXiv251230] AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis**
  - **tags:** [nlp], [text-to-sql], [Reinforcement Learning, Data Synthesis, Policy Optimization, Semantic-Logic Alignment, Group Relative Policy Optimization]
  - **authors:** Cehua Yang, Dongyu Xiao, Junming Lin, Yuyang Song, Hanxu Yan, Shawn Guo, Wei Zhang, Jian Yang, Mingjie Tang, Bryan Dai
  - **institution:** Sichuan University, IQuest Research, Beihang University
  - **link:** https://arxiv.org/pdf/2512.23366
  - **contributions:** 1. Proposes an iterative data factory for synthesizing high-quality, RL-ready Text-to-SQL data with strict semantic-logic verification. 2. Introduces a novel Agentic Reinforcement Learning framework featuring a Diversity-Aware Cold Start stage and Group Relative Policy Optimization (GRPO). 3. Demonstrates state-of-the-art performance on the BIRD and Spider benchmarks through the synergistic combination of data-centric and model-centric approaches.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6740c1fc529b82b509bd38c2a7b5fb405b969bc5c3e11e6e0b7690e7fa791c85_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenges of data scarcity and limited reasoning in Text-to-SQL systems. It proposes a holistic framework that combines a data-centric approach for synthesizing high-fidelity training data with a model-centric approach using a novel Agentic Reinforcement Learning method called Group Relative Policy Optimization. The method achieves state-of-the-art results on major benchmarks, showing the effectiveness of the synergistic approach.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AGRO-SQL] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[数据稀缺与质量/Data Scarcity & Quality]
        B --> B2[模型推理限制/Model Reasoning Limitations]
        C --> C1[数据中心方法/Data-Centric Approach]
        C --> C2[模型中心方法/Model-Centric Approach]
        C1 --> C1a[迭代数据工厂/Iterative Data Factory]
        C1 --> C1b[语义逻辑对齐/Semantic-Logic Alignment]
        C2 --> C2a[多样性感知冷启动/Diversity-Aware Cold Start]
        C2 --> C2b[组相对策略优化/Group Relative Policy Optimization]
        D --> D1[在BIRD和Spider上SOTA/SOTA on BIRD & Spider]
    ```

- **[arXiv251230] Distributed Processing of kNN Queries over Moving Objects on Dynamic Road Networks**
  - **tags:** [db], [spatial databases], [kNN query, dynamic road network, distributed algorithm, Dijkstra's algorithm, network expansion]
  - **authors:** Mingjin Tao, Kailin Jiao, Yawen Li, Wei Liu, Ziqiang Yu
  - **institution:** Yantai University, Beijing University of Posts and Telecommunications
  - **link:** https://arxiv.org/pdf/2512.23399
  - **contributions:** 1. Pioneers the study of kNN queries on dynamic road networks with evolving travel costs, moving beyond static distance metrics. 2. Proposes DkNN, a distributed algorithm that partitions the road network for parallel, incremental exploration using Dijkstra's algorithm, avoiding the maintenance overhead of global indexes. 3. Effectively addresses the challenge of maintaining global distance accuracy during local subgraph exploration while minimizing unnecessary searches and enabling early termination.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34095d1bd1c2f5f873ce8c45a88c287cb1232db027d484638870a82e174044f3_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of finding k nearest neighbors for moving objects on dynamic road networks where travel costs fluctuate over time. It proposes DkNN, a distributed algorithm that partitions the network and performs parallel, incremental expansion using Dijkstra's algorithm to efficiently find results without relying on indexes that are costly to maintain. Implemented on Storm, DkNN shows superior efficiency and effectiveness compared to traditional methods in real-world scenarios.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Distributed Processing of kNN Queries over Moving Objects on Dynamic Road Networks] --> B
        A --> C
        A --> D
        B[核心问题/Problem: kNN查询在动态路网中/kNN query on dynamic road networks with fluctuating travel costs]
        C[主要方法/Method: DkNN分布式算法，分区并行扩展/DkNN distributed algorithm, partitioned parallel expansion]
        D[关键结果/Results: 在Storm上实现，优于传统方法/Implemented on Storm, outperforms traditional methods]
    ```

- **[arXiv251230] SPER: Accelerating Progressive Entity Resolution via Stochastic Bipartite Maximization**
  - **tags:** [db], [entity resolution], [progressive entity resolution, stochastic bipartite maximization, linear-time prioritization, high-velocity streams, scalability]
  - **authors:** Dimitrios Karapiperis, George Papadakis, Themis Palpanas, Vassilios Verykios
  - **institution:** International Hellenic University, National and Kapodistrian University of Athens, Université Paris Cité; IUF, Hellenic Open University
  - **link:** https://arxiv.org/pdf/2512.23491
  - **contributions:** 1. Introduces SPER, a novel framework that redefines candidate pair prioritization in Progressive ER from a ranking problem to a sampling problem. 2. Proposes a continuous stochastic bipartite maximization strategy to replace deterministic global sorting, enabling strictly linear-time operation. 3. Demonstrates through extensive experiments that SPER achieves significant speedups (3x to 6x) over state-of-the-art baselines while maintaining comparable recall and precision.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb9a0b2b37277a329fd22df71d790c106e63e812c17e0e0a3ae1c3882eb51179_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the scalability limitations of existing Progressive Entity Resolution (ER) methods, which rely on super-linear deterministic sorting for candidate prioritization. It proposes SPER, a novel framework that uses a stochastic bipartite maximization strategy to act as a probabilistic high-pass filter, selecting high-utility pairs in linear time. Experiments show SPER achieves 3x to 6x speedups over state-of-the-art methods while maintaining similar accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SPER: Accelerating Progressive Entity Resolution via Stochastic Bipartite Maximization] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统渐进式ER方法无法扩展到高速数据流/Traditional Progressive ER fails to scale to high-velocity streams]
        B --> B2[确定性排序导致超线性复杂度和高初始化成本/Deterministic sorting incurs super-linear complexity & heavy initialization]
        C --> C1[将优先级排序重新定义为采样问题/Redefine prioritization as a sampling problem]
        C --> C2[使用连续随机二分图最大化策略/Use continuous stochastic bipartite maximization strategy]
        C --> C3[作为概率性高通滤波器，实现线性时间选择/Act as a probabilistic high-pass filter for linear-time selection]
        D --> D1[在8个真实数据集上验证/Validated on 8 real-world datasets]
        D --> D2[速度提升3-6倍/Speedups of 3x to 6x]
        D --> D3[保持相当的召回率和精度/Maintains comparable recall & precision]
    ```
