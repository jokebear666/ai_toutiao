---
slug: /daily/csgr/20251229-20260104
---
# 20251229-20260104 (cs.GR)

## 2025-12-29

- **[arXiv251229] ShinyNeRF: Digitizing Anisotropic Appearance in Neural Radiance Fields**
  - **tags:** [cv], [neural rendering], [Neural Radiance Fields, anisotropic specular reflections, Anisotropic Spherical Gaussian, von Mises-Fisher distribution, material editing]
  - **authors:** Albert Barreiro, Roger Marí, Rafael Redondo, Gloria Haro, Carles Bosch
  - **institution:** Eurecat, Centre Tecnològic de Catalunya; Universitat Pompeu Fabra; Universitat de Vic - UCC
  - **link:** https://arxiv.org/pdf/2512.21692
  - **contributions:** 1. Introduces ShinyNeRF, a novel NeRF framework capable of modeling both isotropic and anisotropic specular reflections. 2. Proposes a method to jointly estimate physical surface properties (normals, tangents, specular concentration, anisotropy) by approximating outgoing radiance with a mixture of isotropic von Mises-Fisher distributions. 3. Achieves state-of-the-art performance in digitizing anisotropic materials and enables interpretable material property editing.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad12a4dd31b4ec9b89dafef4a6d4d851fe0aa09b5e3d8c6f918d085ee2acda50_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces ShinyNeRF, a novel Neural Radiance Fields framework designed to accurately model anisotropic specular reflections, such as those on brushed metals, which previous methods struggled with. The method learns an approximation of outgoing radiance using a mixture of isotropic von Mises-Fisher distributions to jointly estimate physical surface properties. Experimental results show it achieves state-of-the-art performance and enables plausible material editing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ShinyNeRF: Digitizing Anisotropic Appearance in Neural Radiance Fields] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有方法难以建模各向异性高光/Existing methods struggle with anisotropic specular reflections]
        C --> C1[提出ShinyNeRF框架/Propose ShinyNeRF framework]
        C1 --> C2[使用各向同性vMF混合近似出射辐射度/Use isotropic vMF mixture to approximate outgoing radiance]
        C2 --> C3[联合估计法线、切线、高光参数/Jointly estimate normals, tangents, specular parameters]
        D --> D1[实现SOTA性能/Achieves SOTA performance]
        D --> D2[提供物理解释和材质编辑/Provides physical interpretation and material editing]
    ```

- **[arXiv251229] Graph Drawing Stress Model with Resistance Distances**
  - **tags:** [other], [graph drawing], [resistance distance, stress model, graph Laplacian, stochastic gradient descent, spectral embedding]
  - **authors:** Yosuke Onoue
  - **institution:** Nihon University
  - **link:** https://arxiv.org/pdf/2512.21901
  - **contributions:** 1. Proposes a new stress-based graph drawing paradigm using resistance distance instead of graph-theoretic shortest distance, which better captures global graph structure and admits an isometric embedding in Euclidean space. 2. Introduces Omega, a linear-time graph drawing algorithm that combines fast resistance distance embedding with random node-pair sampling for SGD, achieving more effective and robust optimization than pivot-based methods. 3. Establishes a practical and scalable connection between spectral graph theory and stress-based layouts, demonstrating improved neighborhood preservation and cluster faithfulness in visualizations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90743acf53987a8cc4eeb2edd80f71bfd5deac0b98227953e258bc7a00aa5f41_w640_q70.webp
  - **Simple LLM Summary:** This paper challenges the conventional use of shortest-path distances in stress-based graph drawing by proposing resistance distance as a superior alternative derived from the graph Laplacian. It introduces the Omega algorithm, which efficiently computes resistance distance embeddings and uses random sampling for SGD to produce more readable layouts with lower stress. The method effectively reveals global graph structures like clusters and maintains linear-time complexity for large networks.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Graph Drawing Stress Model with Resistance Distances] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[传统应力模型使用最短路径距离，存在理论和计算限制/Traditional stress models use shortest-path distances with theoretical and computational limitations]
    C --> C1[提出基于电阻距离的新范式，源自拉普拉斯谱/Propose new paradigm based on resistance distance from graph Laplacian spectrum]
    C --> C2[引入Omega算法：快速电阻距离嵌入与随机节点对采样/Introduce Omega algorithm: fast resistance distance embedding with random node-pair sampling]
    D --> D1[改进邻域保持和聚类忠实性/Improved neighborhood preservation and cluster faithfulness]
    D --> D2[更低、更稳定的应力值，线性复杂度/Lower and more stable stress values, linear-time complexity]
    ```

## 2025-12-30

- **[arXiv251230] Topology-Preserving Scalar Field Optimization for Boundary-Conforming Spiral Toolpaths on Multiply Connected Freeform Surfaces**
  - **tags:** [other], [computer-aided manufacturing (CAM)], [spiral toolpath planning, scalar field optimization, topology-preserving deformation, conformal slit mapping, boundary-conforming]
  - **authors:** Shen Changqing, Xu Bingzhou, Qi Bosong, Zhang Xiaojian, Yan Sijie, Ding Han
  - **institution:** Huazhong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.22502
  - **contributions:** 1. Proposes a strategy to enforce boundary conformity and eliminate zero-gradient singularities in scalar-field-based toolpath optimization for multiply connected surfaces. 2. Reformulates the optimization as a topology-preserving mesh deformation with boundary-synchronous updates to achieve globally optimized spacing and smooth transitions. 3. Demonstrates significant improvements in machining efficiency, scallop-height uniformity, and vibration reduction compared to a state-of-the-art method.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8db268a37d6b76e48aa2571b6519b562d7e55bfc3d4e8f7c07120bc4dbfc1315_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of generating continuous, boundary-conforming spiral toolpaths for ball-end milling on complex freeform surfaces. The proposed method uses conformal slit mapping to create an initial singularity-free scalar field and then optimizes it via a topology-preserving mesh deformation process. Experimental results show the approach increases machining efficiency by over 14%, improves surface finish uniformity, and reduces vibrations compared to existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Topology-Preserving Scalar Field Optimization for Boundary-Conforming Spiral Toolpaths on Multiply Connected Freeform Surfaces] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[挑战: 保持边界一致性并消除奇点/Challenge: Maintain boundary conformity & eliminate singularities]
        C --> C1[使用共形狭缝映射初始化/Use conformal slit mapping for initialization]
        C --> C2[拓扑保持网格变形优化/Topology-preserving mesh deformation optimization]
        D --> D1[效率提升 14.24%/Efficiency improved by 14.24%]
        D --> D2[均匀性提升 5.70%/Uniformity improved by 5.70%]
        D --> D3[振动减少 >10%/Vibration reduced by >10%]
    ```

- **[arXiv251230] ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning**
  - **tags:** [cv], [video generation], [Human-Object Interaction, Diffusion Transformer, Relative Coordinate Maps, Progressive Curriculum Learning, Geometry Consistency]
  - **authors:** Bangya Liu, Xinyu Gong, Zelin Zhao, Ziyang Song, Yulei Lu, Suhui Wu, Jun Zhang, Suman Banerjee, Hao Zhang
  - **institution:** University of Wisconsin-Madison, ByteDance, Georgia Institute of Technology, The Hong Kong Polytechnic University
  - **link:** https://arxiv.org/pdf/2512.22854
  - **code:** https://neutrinoliu.github.io/byteloom/
  - **contributions:** 1. Proposes ByteLoom, a Diffusion Transformer-based framework for generating realistic HOI videos with geometrically consistent objects. 2. Introduces the RCM-cache mechanism using Relative Coordinate Maps to maintain object geometry consistency and control 6-DoF transformations. 3. Designs a progressive training curriculum to compensate for HOI dataset scarcity and relax the need for fine-grained hand mesh annotations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9f5ff16308904b889be6695aafd24bfc28b798f080cc6c723a25066bcdc2bdf_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenges of poor cross-view consistency and reliance on hand mesh annotations in Human-Object Interaction (HOI) video generation. It proposes ByteLoom, a framework that uses a novel RCM-cache mechanism for geometry consistency and a progressive curriculum learning strategy for training. The method effectively preserves human identity and object geometry while generating smooth motion.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有方法缺乏多视图信息注入机制/Existing methods lack multi-view injection]
        B --> B2[严重依赖手部网格标注/Heavy reliance on hand mesh annotations]
        C --> C1[提出RCM-cache机制/Propose RCM-cache mechanism]
        C --> C2[设计渐进式课程学习/Design progressive curriculum learning]
        D --> D1[保持物体几何一致性/Preserves object geometry consistency]
        D --> D2[生成平滑运动视频/Generates smooth motion videos]
    ```

- **[arXiv251230] HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation**
  - **tags:** [cv], [motion generation], [flow matching, diffusion transformer (DiT), reinforcement learning from human feedback (RLHF)]
  - **authors:** Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao
  - **institution:** Tencent Hunyuan
  - **link:** https://arxiv.org/pdf/2512.23464
  - **code:** https://github.com/Tencent-Hunyuan/HY-Motion-1.0
  - **contributions:** 1. The first successful scaling of DiT-based flow matching models to billion parameters for motion generation. 2. A comprehensive full-stage training paradigm including large-scale pretraining, fine-tuning, and RLHF. 3. A meticulous data processing pipeline enabling extensive coverage of over 200 motion categories.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces HY-Motion 1.0, a large-scale model for generating 3D human motions from text. It scales up Diffusion Transformer-based flow matching and uses a full-stage training pipeline with pretraining, fine-tuning, and RLHF. The model achieves state-of-the-art performance and broad motion coverage, and is released open-source.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"]
        Root --> Problem["核心问题/Problem: Generating high-quality, text-aligned 3D human motions"]
        Root --> Method["主要方法/Method: Scale DiT-based flow matching, Full-stage training (pretrain, fine-tune, RLHF), Meticulous data pipeline"]
        Root --> Results["关键结果/Results: SOTA performance, Extensive motion coverage, Open-source release"]
    ```

- **[arXiv251230] OpenPBR: Novel Features and Implementation Details**
  - **tags:** [other], [computer graphics rendering], [physically based rendering, uber-shader, microfacet theory, subsurface scattering, thin-film interference]
  - **authors:** Jamie Portsmouth, Peter Kutz, Stephen Hill
  - **institution:** Autodesk, Adobe, Lucasfilm
  - **link:** https://arxiv.org/pdf/2512.23696
  - **contributions:** 1. Proposes OpenPBR, a standardized, physically based uber-shader for interoperable material authoring across VFX, animation, and design visualization workflows. 2. Details novel model features including slab-based layering, statistical mixing, and specific physical components like metallic/dielectric substrates, subsurface scattering, and thin-film iridescence layers. 3. Provides in-depth implementation guidance and mathematical derivations for technical topics such as decoupling specular reflectivity from transmission and coat darkening physics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34de1d742b1a9090342372c28b227530e6e3c7bfbebef32f3a6f3cfd4dd32542_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces OpenPBR, a standardized physically based rendering shader designed for material interoperability across different rendering systems. It details the model's theoretical foundations, layered components, and provides implementation guidance. The work serves as a companion to the official specification, aiming to standardize and improve material workflows in graphics production.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("OpenPBR: Novel Features and Implementation Details") --> Problem("核心问题/Problem: Need for interoperable, physically based material authoring across VFX/animation workflows")
        Root --> Method("主要方法/Method: Standardized uber-shader with slab-based layering, microfacet theory, and multi-layer substrates (metallic, dielectric, subsurface, coat, fuzz, thin-film)")
        Root --> Results("关键结果/Results: Detailed model specification, implementation guidance, and demonstration of interoperability across renderers")
    ```

- **[arXiv251230] Domain matters: Towards domain-informed evaluation for link prediction**
  - **tags:** [ai], [graph machine learning], [link prediction, algorithm evaluation, domain adaptation, complex networks, graph neural networks]
  - **authors:** Yilin Bi, Junhao Bian, Shuyan Wan, Shuaijia Wang, Tao Zhou
  - **institution:** University of Electronic Science and Technology of China
  - **link:** https://arxiv.org/pdf/2512.23371
  - **contributions:** 1. Conducted a large-scale, systematic evaluation of 12 link prediction algorithms across 740 networks from 7 domains, revealing low consistency in algorithm rankings across domains. 2. Proposed the Winner Score metric to identify domain-specific top-performing algorithms (e.g., NMF for social networks, NeoGNN for economics). 3. Introduced the Ranking Stability Coefficient (RSC) to quantify the number of networks needed for stable evaluation, showing significant variation across domains.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/052f77d6e344a45d0c05f39094686bed2c2049bf461f2d4ea65caf1fbb66f68e_w640_q70.webp
  - **Simple LLM Summary:** This paper systematically evaluates link prediction algorithms across diverse network domains, finding that algorithm performance rankings are highly domain-specific rather than universal. It proposes metrics to identify the best algorithm for each domain and to determine the number of networks needed for stable evaluation, emphasizing the importance of aligning algorithmic mechanisms with network structure.
  - **Mindmap:**

    ```mermaid
    graph TB
    A["Domain matters: Towards domain-informed evaluation for link prediction<br>领域重要：面向领域感知的链接预测评估"] --> B["核心问题/Problem<br>Existing evaluations assume consistent algorithm performance across domains.<br>现有评估假设算法性能在不同领域一致。"]
    A --> C["主要方法/Method<br>Large-scale evaluation of 12 algorithms on 740 networks across 7 domains.<br>在7个领域的740个网络上对12种算法进行大规模评估。"]
    A --> D["关键结果/Results<br>Algorithm rankings are domain-specific; Proposed Winner Score & RSC metrics.<br>算法排名是领域特定的；提出了Winner Score和RSC指标。"]
    ```

## 2026-01-01

- **[arXiv260101] PartMotionEdit: Fine-Grained Text-Driven 3D Human Motion Editing via Part-Level Modulation**
  - **tags:** [cv], [human motion generation and editing], [part-level modulation, bidirectional cross-modal attention, diffusion models]
  - **authors:** Yujie Yang, Zhichao Zhang, Jiazhou Chen, Zichao Wu
  - **institution:** Zhejiang University of Technology, Hangzhou Dianzi University
  - **link:** https://arxiv.org/pdf/2512.24200
  - **contributions:** 1. Proposes a Part-aware Motion Modulation (PMM) module for fine-grained, part-specific motion editing via time-varying part weights. 2. Introduces a part-level similarity curve supervision mechanism with dual-layer normalization to guide PMM training. 3. Designs a Bidirectional Motion Interaction (BMI) module using bidirectional cross-modal attention for better text-motion semantic alignment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a35321bae3cf5142e02d89f04a13673ff8306173f82f32bd722d0923dbbcd1f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes PartMotionEdit, a framework for fine-grained text-driven 3D human motion editing. It introduces a part-level modulation module and a bidirectional interaction module to achieve precise, local motion control based on textual instructions, and demonstrates superior performance over existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["PartMotionEdit: Fine-Grained Text-Driven 3D Human Motion Editing"] --> Problem["核心问题/Problem: Existing methods lack precise, part-specific motion control due to global modeling."]
        Root --> Method["主要方法/Method: Proposes Part-aware Motion Modulation (PMM) and Bidirectional Motion Interaction (BMI) modules."]
        Root --> Results["关键结果/Results: Outperforms state-of-the-art methods in quantitative and qualitative evaluations."]
    ```

- **[arXiv260101] BATISNet: Instance Segmentation of Tooth Point Clouds with Boundary Awareness**
  - **tags:** [cv], [instance segmentation], [point cloud segmentation, boundary-aware loss, dental point clouds]
  - **authors:** Yating Cai, Yanghui Xu, Zehua Hu, Jiazhou Chen, Jing Huang
  - **institution:** Zhejiang University of Technology, Zhejiang Gongshang University
  - **link:** https://arxiv.org/pdf/2512.24201
  - **contributions:** 1. Proposes BATISNet, a boundary-aware instance segmentation network for tooth point clouds that learns both semantic and instance features. 2. Designs a boundary-aware loss function to specifically supervise and improve the segmentation accuracy at tooth boundaries. 3. Demonstrates robust performance in complex clinical scenarios (e.g., missing teeth, malposed teeth) where existing semantic segmentation methods struggle.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/700103c92b00e30f54ce87dbe0220c75481c776fda9612b68afbf5ccb0030515_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes BATISNet, a boundary-aware instance segmentation network for tooth point clouds, to address the challenges of tightly packed teeth and unclear boundaries in complex dental cases. The method combines semantic and instance feature learning with a specialized boundary-aware loss to mitigate adhesion and ambiguity. Experimental results show it outperforms existing methods, providing more reliable data for clinical applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[BATISNet: Instance Segmentation of Tooth Point Clouds with Boundary Awareness] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Semantic segmentation struggles with tightly packed teeth, unclear boundaries, and complex cases like missing/malposed teeth.] --> Problem_Detail[问题细节/Problem Details: Tooth adhesion and boundary ambiguity]
        Method[主要方法/Method: BATISNet, a boundary-aware instance network] --> Method_Component1[网络组件/Network Components: Feature extraction backbone and instance segmentation module]
        Method --> Method_Component2[损失函数/Loss Function: Boundary-aware loss for supervising instance boundaries]
        Results[关键结果/Results: Outperforms existing methods in tooth integrity segmentation, robust in complex clinical scenarios.]
    ```

- **[arXiv260101] The Uncanny Valley in medical simulation-based training: a visual summary**
  - **tags:** [cv], [virtual reality], [Uncanny Valley, virtual reality, medical simulation, photorealism, anthropomorphism]
  - **authors:** Eleni Grigoriou, Manos Kamarianakis, George Papagiannakis
  - **institution:** University of Crete, FORTH - Institute of Computer Science (ICS), ORamaVR
  - **link:** https://arxiv.org/pdf/2512.24240
  - **contributions:** 1. Provides a comprehensive, evidence-based visual guide on the impact of the Uncanny Valley in medical VR training. 2. Synthesizes multidisciplinary perspectives from computer graphics, VR, and medical education to analyze the phenomenon. 3. Reviews and illustrates the state of photorealism and physically based rendering in the context of interactive VR for training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0529156f8e982b0e22d29913cff03007a4f314a7a2cb96b137a263c9f28feae2_w640_q70.webp
  - **Simple LLM Summary:** This review article analyzes the "Uncanny Valley" phenomenon and its critical influence on medical virtual reality simulation-based training. It synthesizes evidence and provides a visual guide from a multidisciplinary perspective, concluding that understanding and addressing this discomfort is crucial for effective, immersive medical training where realism is key.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["The Uncanny Valley in medical simulation-based training: a visual summary<br/>医疗模拟训练中的恐怖谷：视觉总结"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br/>Uncanny Valley causes discomfort in medical VR training<br/>恐怖谷在医疗VR训练中引发不适"] --> P1["影响/Impact<br/>Affects realism and immersion for learning<br/>影响学习所需的真实感与沉浸感"]
        Method["主要方法/Method<br/>Multidisciplinary review & visual guide<br/>多学科综述与视觉指南"] --> M1["视角/Perspective<br/>Computer graphics, VR, medical education<br/>计算机图形学、VR、医学教育"]
        Results["关键结果/Results<br/>Understanding UV is crucial for effective training<br/>理解恐怖谷对有效训练至关重要"]
    ```

- **[arXiv260101] Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training**
  - **tags:** [cv], [image denoising], [Noise2Noise, Monte Carlo denoising, high dynamic range, tone mapping, Jensen gap]
  - **authors:** Andrew Tinits, Stephen Mann
  - **institution:** University of Waterloo
  - **link:** https://arxiv.org/pdf/2512.24794
  - **contributions:** 1. Identified that certain nonlinear functions can be applied to noisy targets in Noise2Noise training without introducing significant bias. 2. Developed a theoretical framework to analyze the effects of nonlinearities and described a class of functions with minimal bias. 3. Demonstrated the method's effectiveness for training Monte Carlo denoisers on HDR images using only noisy data, achieving results comparable to models trained with clean references.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a7ef23248abb9edf960ef0ea8dac0c52ee12d9db03ab8dd602dfd8c83c62645_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of Noise2Noise training where applying nonlinear functions to noisy targets introduces bias. The authors propose a theoretical framework to identify low-bias nonlinearities and apply this to denoise high dynamic range Monte Carlo renderings using tone mapping. Their method, trained only on noisy data, achieves performance close to models trained with clean reference images.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("Noise2Noise训练中非线性函数导致偏差/Bias from nonlinearities in Noise2Noise")
        Problem --> P2("HDR图像训练被异常值干扰/HDR training overwhelmed by outliers")
        Method --> M1("理论分析非线性影响/Theoretical analysis of nonlinear effects")
        Method --> M2("识别低偏差非线性函数类/Identify low-bias nonlinear function class")
        Method --> M3("特定损失与色调映射组合/Specific loss & tone mapping combination")
        Results --> R1("仅用噪声数据训练/Train with only noisy data")
        Results --> R2("性能接近干净数据训练模型/Performance approaches clean-data-trained model")
    ```

- **[arXiv260101] PhysTalk: Language-driven Real-time Physics in 3D Gaussian Scenes**
  - **tags:** [cv], [3D scene understanding and animation], [3D Gaussian Splatting, physics simulation, large language model, real-time animation, open-vocabulary]
  - **authors:** Luca Collorone, Mert Kiray, Indro Spinelli, Fabio Galasso, Benjamin Busam
  - **institution:** Sapienza University of Rome, Technical University of Munich, Munich Center for Machine Learning (MCML)
  - **link:** https://arxiv.org/pdf/2512.24986
  - **contributions:** 1. Introduces the first framework to directly couple 3D Gaussian Splatting with a physics simulator, bypassing slow mesh extraction. 2. Enables open-vocabulary, real-time, and interactive 4D animation through an LLM that generates executable code to modify scene parameters. 3. Presents a train-free and computationally lightweight pipeline, shifting animation workflows from offline rendering to interactive dialogue.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1113cf9009e210565f13d799d298867f98470a28066f31b961bce3b6577044fe_w640_q70.webp
  - **Simple LLM Summary:** The paper presents PhysTalk, a system that generates real-time, physics-based 4D animations from text prompts and 3D Gaussian Splatting scenes. It uses a large language model to produce code that manipulates scene proxies for physics simulation, enabling interactive and realistic motion without requiring model training. This approach makes physically realistic animation more accessible and interactive.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[PhysTalk: Language-driven Real-time Physics in 3D Gaussian Scenes] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有方法缺乏物理真实性和实时交互性/Current methods lack physical realism and real-time interaction]
        C --> C1[使用LLM将文本提示转化为可执行代码/Uses LLM to translate prompts into executable code]
        C --> C2[通过轻量级代理直接修改3DGS参数/Modifies 3DGS parameters via lightweight proxies]
        C --> C3[集成物理模拟器进行碰撞感知动画/Integrates physics simulator for collision-aware animation]
        D --> D1[实现实时、开集词汇的4D动画/Achieves real-time, open-vocabulary 4D animation]
        D --> D2[无需训练，计算轻量/Train-free and computationally lightweight]
        D --> D3[将工作流转向交互式对话/Shifts workflow to interactive dialogue]
    ```

- **[arXiv260101] Variational Quantum Brushes**
  - **tags:** [other], [quantum computing for art], [variational quantum algorithms, quantum geometric control, variational eigensolver, computational art, quantum brushes]
  - **authors:** Jui-Ting Lu, Henrique Ennes, Chih-Kang Huang, Ali Abbassi
  - **institution:** Université de Lorraine, CNRS, Inria, Université de Technologie de Troyes, Orange Research
  - **link:** https://arxiv.org/pdf/2512.24173
  - **code:** https://github.com/moth-quantum/QuantumBrush
  - **contributions:** 1. Introduces a mathematical framework for quantum brushes based on variational quantum algorithms. 2. Implements the "Steerable" brush, which uses quantum geometric control theory to merge two images. 3. Implements the "Chemical" brush, which mimics variational eigensolvers to evolve colors on a canvas.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d8a1ae2b1cfdee3a098d127a86fa773993bb3eab697781cc52c1e25f3f449b7_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces two new quantum brushes for computational art, built on variational quantum algorithms. The "Steerable" brush merges artworks using quantum geometric control, while the "Chemical" brush evolves colors by mimicking molecular energy estimation. The implementations are open-source and compatible with existing quantum brush software.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Variational Quantum Brushes] --> B[核心问题/Problem: Leveraging quantum behavior for novel artistic effects]
        A --> C[主要方法/Method: Two variational quantum algorithm-based brushes: Steerable and Chemical]
        A --> D[关键结果/Results: Open-source implementation, compatible with original quantum brushes]
    ```
