---
slug: /daily/cshc/20251222-20251228
---
# 20251222-20251228 (cs.HC)

## 2025-12-22

- **[arXiv251222] Adversarial VR: An Open-Source Testbed for Evaluating Adversarial Robustness of VR Cybersickness Detection and Mitigation**
  - **tags:** [mlsys], [others], [adversarial attacks, deep learning, cybersickness detection, visual tunneling, MI-FGSM, PGD, C&W, DeepTCN, Transformer]
  - **authors:** Istiak Ahmed, Ripan Kumar Kundu, Khaza Anuarul Hoque
  - **institution:** University of Missouri-Columbia
  - **link:** https://arxiv.org/pdf/2512.17029
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a313962e09ceaa54a617d0e446a38a50ffa44d10894d76830f87cd1e74c0749_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Adversarial-VR, an open-source Unity testbed that integrates DeepTCN and Transformer models for real-time cybersickness detection and mitigation, and evaluates their robustness against adversarial attacks like MI-FGSM, PGD, and C&W. The results show these attacks can successfully fool the system, significantly degrading model accuracy and preventing correct mitigation.

- **[arXiv251222] Bots Don't Sit Still: A Longitudinal Study of Bot Behaviour Change, Temporal Drift, and Feature-Structure Evolution**
  - **tags:** [ai], [social media analysis], [Augmented Dickey-Fuller test, KPSS test, Spearman correlation, Chi-square test, time series analysis, stationarity testing]
  - **authors:** Ohoud Alzahrani, Russell Beale, Bob Hendley
  - **institution:** University of Birmingham
  - **link:** https://arxiv.org/pdf/2512.17067
  - **Simple LLM Summary:** This paper conducts a longitudinal study analyzing the temporal behavior of promotional Twitter bots using time series analysis and statistical tests on ten content-based meta-features. It finds that bot behavior is non-stationary, with individual features and their interdependencies evolving systematically over time and across bot generations. The conclusion is that bot-detection systems must account for this dynamic adaptation and avoid treating behavioral features as static.

- **[arXiv251222] PILAR: Personalizing Augmented Reality Interactions with LLM-based Human-Centric and Trustworthy Explanations for Daily Use Cases**
  - **tags:** [mlsys], [llm inference], [large language model, explainable ai, augmented reality, personalized explanations, real-time object detection, user study]
  - **authors:** Ripan Kumar Kundu, Istiak Ahmed, Khaza Anuarul Hoque
  - **institution:** University of Missouri-Columbia
  - **link:** https://arxiv.org/pdf/2512.17172
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7767a7bc851a49f82148423782803913a5c377f60c4ce3a9cc7383c22a6d08a4_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes PILAR, a framework that uses a pre-trained large language model (LLM) to generate unified, context-aware, and personalized explanations for AI-driven augmented reality systems. A user study on a recipe recommendation prototype showed that the LLM-based explanation interface significantly improved user task performance and perceived transparency compared to a traditional template-based approach.

- **[arXiv251222] Learning Spatio-Temporal Feature Representations for Video-Based Gaze Estimation**
  - **tags:** [ai], [computer vision], [spatio-temporal feature representation, channel attention, self-attention, recurrent neural networks, video-based gaze estimation]
  - **authors:** Alexandre Personnic, Mihai Bâce
  - **institution:** KU Leuven
  - **link:** https://arxiv.org/pdf/2512.17673
  - **Simple LLM Summary:** The paper proposes the Spatio-Temporal Gaze Network (ST-Gaze), which combines a CNN backbone with channel and self-attention modules to fuse eye and face features, then models intra- and inter-frame dynamics by treating features as a spatial sequence propagated through time. The method achieves state-of-the-art performance on the EVE dataset, demonstrating that preserving intra-frame spatial context is superior to premature spatial pooling for robust video-based gaze estimation.

- **[arXiv251222] ShareChat: A Dataset of Chatbot Conversations in the Wild**
  - **tags:** [mlsys], [others], [dataset collection, multi-turn conversations, platform affordances, source citations, temporal analysis, cross-platform corpus]
  - **authors:** Yueru Yan, Tuc Nguyen, Bo Su, Melissa Lieffers, Thai Le
  - **institution:** Indiana University
  - **link:** https://arxiv.org/pdf/2512.17843
  - **Simple LLM Summary:** The paper introduces ShareChat, a large-scale dataset of real-world chatbot conversations collected from five major platforms, preserving interface-specific features like reasoning traces and source links. It demonstrates the dataset's utility through analyses of user intent satisfaction, citation behaviors, and evolving usage patterns, providing a resource for studying authentic user-LLM interactions.

- **[arXiv251222] Integrating Computational Methods and AI into Qualitative Studies of Aging and Later Life**
  - **tags:** [ai], [computational social science], [computational text analysis, machine learning (ML), natural language processing (NLP), ethnography, in-depth interviews, mixed-methods]
  - **authors:** Corey M. Abramson
  - **institution:** Rice University, UC San Francisco
  - **link:** https://arxiv.org/pdf/2512.17850
  - **Simple LLM Summary:** This paper demonstrates how computational social science tools like machine learning and natural language processing can be integrated with traditional qualitative methods (e.g., ethnography, interviews) to study aging. It concludes that these computational methods can broaden qualitative research by streamlining workflows, scaling up projects, and enabling new multi-method insights, rather than replacing its foundational approaches.

## 2025-12-23

- **[arXiv251223] Design and Integration of Thermal and Vibrotactile Feedback for Lifelike Touch in Social Robots**
  - **tags:** TBD
  - **authors:** Jacqueline Borgstedt, Jake Bhattacharyya, Matteo Iovino, Frank E. Pollick, Stephen Brewster
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18032
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab5ccc615f8631e1cb919fee6836987e7793d4803a41430b431092ecd0b25ec_w640_q70.webp
  - **Simple LLM Summary:** Design and Integration of Thermal and Vibrotactile Feedback for Lifelike Touch in Social Robots

- **[arXiv251223] From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems**
  - **tags:** TBD
  - **authors:** Marcos Ortiz, Justin Hill, Collin Overbay, Ingrida Semenec, Frederic Sauve-Hoover, Jim Schwoebel, Joel Shor
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18080
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0154cb62824a09bcbf4a6476b89c563b0f548b2e6721f62b4207082ab09ee544_w640_q70.webp
  - **Simple LLM Summary:** From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems

- **[arXiv251223] Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling**
  - **tags:** TBD
  - **authors:** Ohoud Alzahrani, Russell Beale, Robert J. Hendley
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18077
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ecf679a26dc73049a43a2ec8c3b4b9a5b43ae16a82684041393594d146210f5_w640_q70.webp
  - **Simple LLM Summary:** Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling

- **[arXiv251223] Dimensionality Reduction Considered Harmful (Some of the Time)**
  - **tags:** TBD
  - **authors:** Hyeon Jeon
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18230
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6c2d73af1d47933ab3fe41a060a175bd40e436f32af5added065941e07d0688_w640_q70.webp
  - **Simple LLM Summary:** Dimensionality Reduction Considered Harmful (Some of the Time)

- **[arXiv251223] The Social Blindspot in Human-AI Collaboration: How Undetected AI Personas Reshape Team Dynamics**
  - **tags:** TBD
  - **authors:** Lixiang Yan, Xibin Han, Yu Zhang, Samuel Greiff, Inge Molenaar, Roberto Martinez-Maldonado, Yizhou Fan, Linxuan Zhao, Xinyu Li, Yueqiao Jin, Dragan Gašević
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18234
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08ef726a4410ec8749e604356b03b8afe29560606553bd2e895fa2e42f8a4d5a_w640_q70.webp
  - **Simple LLM Summary:** The Social Blindspot in Human-AI Collaboration: How Undetected AI Personas Reshape Team Dynamics

- **[arXiv251223] Emergent Learner Agency in Implicit Human-AI Collaboration: How AI Personas Reshape Creative-Regulatory Interaction**
  - **tags:** TBD
  - **authors:** Yueqiao Jin, Roberto Martinez-Maldonado, Dragan Gašević, Lixiang Yan
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18239
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90be08528a89abf308b5f3179521424f35d5720259e534256a475d02ffe5b615_w640_q70.webp
  - **Simple LLM Summary:** Emergent Learner Agency in Implicit Human-AI Collaboration: How AI Personas Reshape Creative-Regulatory Interaction

- **[arXiv251223] Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective**
  - **tags:** TBD
  - **authors:** M. Mehdi Kholoosi, Triet Huynh Minh Le, M. Ali Babar
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18261
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c527700e49403d8d115fcd9b121714ac7cc66ca4c4917d88ae5eeb6712cf705e_w640_q70.webp
  - **Simple LLM Summary:** Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective

- **[arXiv251223] MORPHEUS: A Multidimensional Framework for Modeling, Measuring, and Mitigating Human Factors in Cybersecurity**
  - **tags:** TBD
  - **authors:** Giuseppe Desolda, Francesco Greco, Rosa Lanzilotti, Cesare Tucci
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18303
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/013fffaf0ed613ccbcc22a6990caf81327b42deac91bfb1c67c73cad88e1ab96_w640_q70.webp
  - **Simple LLM Summary:** MORPHEUS: A Multidimensional Framework for Modeling, Measuring, and Mitigating Human Factors in Cybersecurity

- **[arXiv251223] Leveraging Peer, Self, and Teacher Assessments for Generative AI-Enhanced Feedback**
  - **tags:** TBD
  - **authors:** Alvaro Becerra, Ruth Cobos
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18306
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5aea301733440fbfacf134ac6fba24972e030dde31a68ce5c51ab92a244cc90b_w640_q70.webp
  - **Simple LLM Summary:** Leveraging Peer, Self, and Teacher Assessments for Generative AI-Enhanced Feedback

- **[arXiv251223] Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models**
  - **tags:** TBD
  - **authors:** Chao Wen, Tung Phung, Pronita Mehrotra, Sumit Gulwani, Tomohiro Nagashima, Adish Singla
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18388
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26ae3275661776caa174169c0f345d17624c81b4d8a6d11a881528d1b3ebbea4_w640_q70.webp
  - **Simple LLM Summary:** Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models

- **[arXiv251223] Towards Scalable Visual Data Wrangling via Direct Manipulation**
  - **tags:** TBD
  - **authors:** El Kindi Rezig, Mir Mahathir Mohammad, Nicolas Baret, Ricardo Mayerhofer, Andrew McNutt, Paul Rosen
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18405
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/790118e217a177acb4ecd824d816066f84640176a4ebb5ada4193f1841afa44c_w640_q70.webp
  - **Simple LLM Summary:** Towards Scalable Visual Data Wrangling via Direct Manipulation

- **[arXiv251223] Listening to the Mind: Earable Acoustic Sensing of Cognitive Load**
  - **tags:** TBD
  - **authors:** Xijia Wei, Ting Dang, Khaldoon Al-Naimi, Yang Liu, Fahim Kawsar, Alessandro Montanari
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18413
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fe6c29fe2181ae377bd035ff882e6e32ace02c50f40c9f4359bd37cc647e34d7_w640_q70.webp
  - **Simple LLM Summary:** Listening to the Mind: Earable Acoustic Sensing of Cognitive Load

- **[arXiv251223] When Robots Say No: The Empathic Ethical Disobedience Benchmark**
  - **tags:** TBD
  - **authors:** Dmytro Kuzmenko, Nadiya Shvai
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18474
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/083ac27bf9c1ba565d26a4c6417b20f994336e4ffb3cb410b3b93d3ef36fb6aa_w640_q70.webp
  - **Simple LLM Summary:** When Robots Say No: The Empathic Ethical Disobedience Benchmark

- **[arXiv251223] From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation**
  - **tags:** TBD
  - **authors:** Amit Barman, Atanu Mandal, Sudip Kumar Naskar
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18593
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4841f825fcb7cf75a5d51e2769fdede7c9af6b25f2faafea290804903c41f40_w640_q70.webp
  - **Simple LLM Summary:** From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation

- **[arXiv251223] DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System**
  - **tags:** TBD
  - **authors:** Zelin Wan, Han Jun Yoon, Nithin Alluru, Terrence J. Moore, Frederica F. Nelson, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Jin-Hee Cho
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18616
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fabd2c171e25c623bc7edccb8e1ef0506a926726f1d2a534aaa0d5113899beef_w640_q70.webp
  - **Simple LLM Summary:** DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System

- **[arXiv251223] A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback**
  - **tags:** TBD
  - **authors:** Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18622
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp
  - **Simple LLM Summary:** A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback

- **[arXiv251223] "Even GPT Can Reject Me": Conceptualizing Abrupt Refusal Secondary Harm (ARSH) and Reimagining Psychological AI Safety with Compassionate Completion Standard (CCS)**
  - **tags:** TBD
  - **authors:** Yang Ni, Tong Yang
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18776
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4c436bec45a43d86e53531d2849399bd87e6bf3d4305bd5fa2744e56f7b83352_w640_q70.webp
  - **Simple LLM Summary:** "Even GPT Can Reject Me": Conceptualizing Abrupt Refusal Secondary Harm (ARSH) and Reimagining Psychological AI Safety with Compassionate Completion Standard (CCS)

- **[arXiv251223] VizDefender: Unmasking Visualization Tampering through Proactive Localization and Intent Inference**
  - **tags:** TBD
  - **authors:** Sicheng Song, Yanjie Zhang, Zixin Chen, Huamin Qu, Changbo Wang, Chenhui Li
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18853
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6df051754b8f594a7ef88a46e4855d2eb43c4c662b1afbca9997caf2b4fbad53_w640_q70.webp
  - **Simple LLM Summary:** VizDefender: Unmasking Visualization Tampering through Proactive Localization and Intent Inference

- **[arXiv251223] Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers**
  - **tags:** TBD
  - **authors:** Bruno Campello de Souza
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18871
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/446f3fb717e9b018a154458859c845d2583ea717613eb2a7397f53ffedb8700f_w640_q70.webp
  - **Simple LLM Summary:** Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers

- **[arXiv251223] Household Plastic Recycling: Empirical Insights and Design Explorations**
  - **tags:** TBD
  - **authors:** Ashley Colley, Emma Kirjavainen, Sari Tapio, Jonna Häkkilä
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18889
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e98f1d82cd1fbc384d43ddf57fd109888b3f5c78ff0d869daa0ef5d4c713eb3_w640_q70.webp
  - **Simple LLM Summary:** Household Plastic Recycling: Empirical Insights and Design Explorations

- **[arXiv251223] An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects**
  - **tags:** TBD
  - **authors:** Shaokang Jiang, Daye Nam
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18925
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2089c7618775b9b9cdc54e25f2f7b14898adbf8c1ce8308d624be1f22c566408_w640_q70.webp
  - **Simple LLM Summary:** An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects

- **[arXiv251223] Narrative Scaffolding: Transforming Data-Driven Sensemaking Through Narrative-First Exploration**
  - **tags:** TBD
  - **authors:** Oliver Huang, Muhammad Fatir, Steven Luo, Sangho Suh, Hariharan Subramonyam, Carolina Nobre
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18920
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a117e0515b80f1075c391fa0ed128ff0ec8754654d3747ba533f99d3d9311e6f_w640_q70.webp
  - **Simple LLM Summary:** Narrative Scaffolding: Transforming Data-Driven Sensemaking Through Narrative-First Exploration

- **[arXiv251223] Advancing Accessibility: Augmented Reality Solutions for the Blind and Disabled in Bangladesh**
  - **tags:** TBD
  - **authors:** Md Minhazul Islam Munna, Al Amin, Xin Wang, Hongbin Ma
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19047
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e57af16bdaba33a67888f0850a24ef71eead80c5314fcfb4dde2288280f7820e_w640_q70.webp
  - **Simple LLM Summary:** Advancing Accessibility: Augmented Reality Solutions for the Blind and Disabled in Bangladesh

- **[arXiv251223] Towards a collaborative digital platform for railway infrastructure projects**
  - **tags:** TBD
  - **authors:** Pierre Jehel, Pierre-Étienne Gautier, Judicaël Dehotin, Flavien Viguier
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19169
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3874b7105990b7eea9564e4b1e9114f5f53c8e95ba6b7ddfc4422d6b9542ed5a_w640_q70.webp
  - **Simple LLM Summary:** Towards a collaborative digital platform for railway infrastructure projects

- **[arXiv251223] Epistemological Fault Lines Between Human and Artificial Intelligence**
  - **tags:** TBD
  - **authors:** Walter Quattrociocchi, Valerio Capraro, Matjaž Perc
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19466
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e38aa1bf279d77f222964e2fa6eaf6b1a85cc9955ae786124894e9ed3fb93c1_w640_q70.webp
  - **Simple LLM Summary:** Epistemological Fault Lines Between Human and Artificial Intelligence

- **[arXiv251223] The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge**
  - **tags:** TBD
  - **authors:** Angjelin Hila
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19570
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14053cd17ec2f7fbfad183ca144e70fb650f93b135eca28453bda97a810f7db4_w640_q70.webp
  - **Simple LLM Summary:** The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge

- **[arXiv251223] More code, less validation: Risk factors for over-reliance on AI coding tools among scientists**
  - **tags:** TBD
  - **authors:** Gabrielle O'Brien, Alexis Parker, Nasir Eisty, Jeffrey Carver
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19644
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fa42c82b2739bd1b4c7111c0c7d29876d12dbca90ed48e9b300fd1778d6e033_w640_q70.webp
  - **Simple LLM Summary:** More code, less validation: Risk factors for over-reliance on AI coding tools among scientists

## 2025-12-24

- **[arXiv251224] Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance**
  - **tags:** TBD
  - **authors:** James K Ruffle, Samia Mohinta, Guilherme Pombo, Asthik Biswas, Alan Campbell, Indran Davagnanam, David Doig, Ahmed Hamman, Harpreet Hyare, Farrah Jabeen, Emma Lim, Dermot Mallon, Stephanie Owen, Sophie Wilkinson, Sebastian Brandner, Parashkev Nachev
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19707
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp
  - **Simple LLM Summary:** Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance

- **[arXiv251224] Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches**
  - **tags:** TBD
  - **authors:** Taoran Sheng, Manfred Huber
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19713
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8069c49480aa4056d903366d9a07ef262001809b60e89caaaab99b1ab6318bb6_w640_q70.webp
  - **Simple LLM Summary:** Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches

- **[arXiv251224] Predicting Student Actions in a Procedural Training Environment**
  - **tags:** TBD
  - **authors:** Diego Riofrío-Luzcando, Jaime Ramírez, Marta Berrocal-Lobo
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19810
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5170ec33c553e90c5b65d0bc5448598b91b9a44fd63a92b56fd0d690965f3002_w640_q70.webp
  - **Simple LLM Summary:** Predicting Student Actions in a Procedural Training Environment

- **[arXiv251224] How Tech Workers Contend with Hazards of Humanlikeness in Generative AI**
  - **tags:** TBD
  - **authors:** Mark Díaz, Renee Shelby, Eric Corbett, Andrew Smart
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19832
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8537a350df62ef095164c7748f634e18b0a4279fffa1f30668439646406288e2_w640_q70.webp
  - **Simple LLM Summary:** How Tech Workers Contend with Hazards of Humanlikeness in Generative AI

- **[arXiv251224] Visualizing a Collective Student Model for Procedural Training Environments**
  - **tags:** TBD
  - **authors:** Diego Riofrío-Luzcando, Jaime RamÍrez, Cristian Moral, Angélica de Antonio, Marta Berrocal-Lobo
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19885
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cdb96b3b8530271a31011b3f10e569cebea1d14b4385eb418b43cd79244a07f4_w640_q70.webp
  - **Simple LLM Summary:** Visualizing a Collective Student Model for Procedural Training Environments

- **[arXiv251224] Detecting cyberbullying in Spanish texts through deep learning techniques**
  - **tags:** TBD
  - **authors:** Paúl Cumba-Armijos, Diego Riofrío-Luzcando, Verónica Rodríguez-Arboleda, Joe Carrión-Jumbo
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19899
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d2f7ccac215958604ec2bafb628962c08cfada143b59dda8159af7e4af21661_w640_q70.webp
  - **Simple LLM Summary:** Detecting cyberbullying in Spanish texts through deep learning techniques

- **[arXiv251224] Free-Will vs Free-Wheel: Understanding Community Accessibility Requirements of Wheelchair Users through Interviews, Participatory Action, and Modeling**
  - **tags:** TBD
  - **authors:** Hanna Noyce, Emily Olejniczak, Vaskar Raychoudhury, Roger O. Smith, Md Osman Gani
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19898
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94f45bbd3f136fa9ca9486c93a06494dfae76a62569d1f5464b47a9b2a351451_w640_q70.webp
  - **Simple LLM Summary:** Free-Will vs Free-Wheel: Understanding Community Accessibility Requirements of Wheelchair Users through Interviews, Participatory Action, and Modeling

- **[arXiv251224] Developers' Experience with Generative AI -- First Insights from an Empirical Mixed-Methods Field Study**
  - **tags:** TBD
  - **authors:** Charlotte Brandebusemeyer, Tobias Schimmer, Bert Arnrich
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19926
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b805b7a034106a6a896aa4fa59536e4c24c1b4390bbad36d9762174995633c68_w640_q70.webp
  - **Simple LLM Summary:** Developers' Experience with Generative AI -- First Insights from an Empirical Mixed-Methods Field Study

- **[arXiv251224] Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems**
  - **tags:** TBD
  - **authors:** Heet Bodara, Md Masum Mushfiq, Isma Farah Siddiqui
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19950
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25282dd436ce0f7a5fabd0438ec9d8be57567585d626e71c9a9af6d0ac8451b9_w640_q70.webp
  - **Simple LLM Summary:** Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems

- **[arXiv251224] Stories That Teach: Eastern Wisdom for Human-AI Creative Partnerships**
  - **tags:** TBD
  - **authors:** Kexin Nie, Xin Tang, Mengyao Guo, Ze Gao
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19999
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/10e9f9340ffb8b63217712d4aa9b0cc137057244e1829ea40c95f6374ff796aa_w640_q70.webp
  - **Simple LLM Summary:** Stories That Teach: Eastern Wisdom for Human-AI Creative Partnerships

- **[arXiv251224] /UnmuteAll: Modeling Verbal Communication Patterns of Collaborative Contexts in MOBA Games**
  - **tags:** TBD
  - **authors:** Yongchan Son, Jahun Jang, Been An, Jimoon Kang, Eunji Park
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20116
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50853e5216c134f7f20eb67d59c4cc443da21824aa6454f1a64a094910c9658a_w640_q70.webp
  - **Simple LLM Summary:** /UnmuteAll: Modeling Verbal Communication Patterns of Collaborative Contexts in MOBA Games

- **[arXiv251224] Dreamcrafter: Immersive Editing of 3D Radiance Fields Through Flexible, Generative Inputs and Outputs**
  - **tags:** TBD
  - **authors:** Cyrus Vachha, Yixiao Kang, Zach Dive, Ashwat Chidambaram, Anik Gupta, Eunice Jun, Bjoern Hartmann
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20129
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8400f1033a93635b0a5b706c568585f557f04cf8533a2b77ce1c55f08e14bef6_w640_q70.webp
  - **Simple LLM Summary:** Dreamcrafter: Immersive Editing of 3D Radiance Fields Through Flexible, Generative Inputs and Outputs

- **[arXiv251224] Competing or Collaborating? The Role of Hackathon Formats in Shaping Team Dynamics and Project Choices**
  - **tags:** TBD
  - **authors:** Sadia Nasrin Tisha, Md Nazmus Sakib, Sanorita Dey
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20181
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dadc4f214409965b0df1005c180cb9f7bf76c16e776028372175b81d9eed7768_w640_q70.webp
  - **Simple LLM Summary:** Competing or Collaborating? The Role of Hackathon Formats in Shaping Team Dynamics and Project Choices

- **[arXiv251224] RESPOND: Risk-Enhanced Structured Pattern for LLM-driven Online Node-level Decision-making**
  - **tags:** TBD
  - **authors:** Dan Chen, Heye Huang, Tiantian Chen, Zheng Li, Yongji Li, Yuhui Xu, Sikai Chen
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20179
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba879d80c9d58b4f8d7942ebda77c8c4b993bb9018f484a08adfe360eb40c02c_w640_q70.webp
  - **Simple LLM Summary:** RESPOND: Risk-Enhanced Structured Pattern for LLM-driven Online Node-level Decision-making

- **[arXiv251224] The Effect of Empathic Expression Levels in Virtual Human Interaction: A Controlled Experiment**
  - **tags:** TBD
  - **authors:** Sung Park, Daeho Yoon, Jungmin Lee
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20221
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e8f259bc1362a522f2cf043a9f6b686f7f77b7e14bfd0671a5c5cba5ec63c8af_w640_q70.webp
  - **Simple LLM Summary:** The Effect of Empathic Expression Levels in Virtual Human Interaction: A Controlled Experiment

- **[arXiv251224] Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives**
  - **tags:** TBD
  - **authors:** Karolina Drożdż, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20298
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e46ae09622d9142a3896f2528685617edcbaae96bc105754e16929ed630e3f0_w640_q70.webp
  - **Simple LLM Summary:** Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives

- **[arXiv251224] Structured Visualization Design Knowledge for Grounding Generative Reasoning and Situated Feedback**
  - **tags:** TBD
  - **authors:** Péter Ferenc Gyarmati, Dominik Moritz, Torsten Möller, Laura Koesten
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20306
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e3c684df7664b2bee4d03afb8801d141ceb15c7e18014fd3e28b28a59515f72_w640_q70.webp
  - **Simple LLM Summary:** Structured Visualization Design Knowledge for Grounding Generative Reasoning and Situated Feedback

- **[arXiv251224] A human-centered approach to reframing job satisfaction in the BIM-enabled construction industry**
  - **tags:** TBD
  - **authors:** Sharareh Mirzaei, Stephanie Bunt, Susan M Bogus
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20584
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/510c6ffa270afe4e2d7d2de70c289fafe8fd64d4a4f5f29123b3c70e64963e1e_w640_q70.webp
  - **Simple LLM Summary:** A human-centered approach to reframing job satisfaction in the BIM-enabled construction industry

- **[arXiv251224] Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent**
  - **tags:** TBD
  - **authors:** Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20586
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39917d1df3de96bd690d947b78c3c6d1ac037b54cc0591faa464cbc08cd8c729_w640_q70.webp
  - **Simple LLM Summary:** Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent

## 2025-12-25

- **[arXiv251225] Cooperation Through Indirect Reciprocity in Child-Robot Interactions**
  - **tags:** [ai], [human-robot interaction], [indirect reciprocity, multi-armed bandit, coordination dilemmas]
  - **authors:** Isabel Neto, Alexandre S. Pires, Filipa Correia, Fernando P. Santos
  - **institution:** Universidade de Lisboa, University of Amsterdam, Instituto Superior Técnico
  - **link:** https://arxiv.org/pdf/2512.20621
  - **contributions:** 1. Demonstrated that the mechanism of indirect reciprocity can be successfully transposed from human-human interactions to child-robot interactions. 2. Showed that children's behavioral strategies provide a sufficient signal for multi-armed bandit algorithms to learn cooperative actions. 3. Analyzed how differences in learning algorithms impact the dynamics and outcomes of human-AI cooperation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4a49edd2299eeb19bce07b564c8061c35b829f55eb48557d15dbeabbbd028e0_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether indirect reciprocity, a mechanism for sustaining cooperation, applies to child-robot interactions. The authors combine laboratory experiments with theoretical modeling, using multi-armed bandit algorithms for the robots. They find that indirect reciprocity does extend to these interactions and that robots can learn to cooperate based on children's strategies, though this learning is highly dependent on the human strategies revealed.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Cooperation Through Indirect Reciprocity in Child-Robot Interactions] --> B(核心问题/Problem: Can indirect reciprocity enable cooperation between children and robots?)
    A --> C(主要方法/Method: Laboratory experiments and theoretical modeling with multi-armed bandit algorithms)
    A --> D(关键结果/Results: IR extends to child-robot groups; robots can learn cooperation from children's strategies)
    ```

- **[arXiv251225] Uncovering Patterns of Brain Activity from EEG Data Consistently Associated with Cybersickness Using Neural Network Interpretability Maps**
  - **tags:** [ai], [brain-computer interface], [EEG, cybersickness, interpretability maps, convolutional neural networks, event-related potentials]
  - **authors:** Jacqueline Yau, Katherine J. Mimnaugh, Evan G. Center, Timo Ojala, Steven M. LaValle, Wenzhen Yuan, Nancy Amato, Minje Kim, Kara Federmeier
  - **institution:** University of Illinois Urbana-Champaign, University of Oulu
  - **link:** https://arxiv.org/pdf/2512.20620
  - **contributions:** 1. Introduced a method using CNNs and transformers with interpretability maps (integrated gradients and class activation) to identify EEG features for cybersickness classification. 2. Identified a consistent and surprising pattern: amplitudes near the left prefrontal cortex electrode are important for cybersickness classification. 3. Proposed using the identified scalp location as a tagged feature for better real-time cybersickness classification with EEG.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5601623e3cdfb620242f065ddf726ad49d48b3d131d2e3cc1f6fa48032be9946_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of detecting cybersickness from EEG data by using event-related potentials to isolate sickness-related brain activity from visual stimulus confounds. The authors employ trained convolutional neural networks and transformer models with interpretability maps to identify key EEG features. The main finding is that amplitudes recorded near the left prefrontal cortex are consistently important for classification, suggesting this location as a valuable feature for real-time detection.
  - **Mindmap:**

    ```mermaid
    graph LR
        A[Uncovering Patterns of Brain Activity from EEG Data Consistently Associated with Cybersickness Using Neural Network Interpretability Maps] --> B(核心问题/Problem: Cybersickness detection in VR using EEG is confounded by visual stimulus processing.)
        A --> C(主要方法/Method: Use ERPs, CNNs/Transformers, and interpretability maps (integrated gradients/class activation) to analyze EEG data.)
        A --> D(关键结果/Results: Left prefrontal cortex electrode amplitudes are consistently important for cybersickness classification.)
    ```

- **[arXiv251225] Signal, Noise, and Burnout: A Human-Information Interaction Analysis of Voter Verification in a High-Volatility Environment**
  - **tags:** [other], [human-information interaction], [epistemic self-efficacy, information fatigue, algorithmic filtering theory]
  - **authors:** Kijung Lee
  - **institution:** (Institution not explicitly stated in provided content; author name "Kijung Lee" present but no affiliation/email domain. Based on data source, likely an academic institution collaborating with Pew Research Center.)
  - **link:** https://arxiv.org/pdf/2512.20679
  - **contributions:** 1. Empirically tests the relationship between information source (social media vs. mainstream news) and perceived verification difficulty (epistemic self-efficacy) during a high-volatility election. 2. Identifies perceived exposure to inaccurate information as a mediator and information fatigue as a key moderator in the verification process. 3. Challenges platform-deterministic theories by finding that demographics and universal information fatigue, not platform type, are primary drivers of epistemic burden in volatile environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e84ec2c80314744bb65f09fdbb5472f486e9a21a743399f645a4b93420c8f3_w640_q70.webp
  - **Simple LLM Summary:** This study analyzes how voters perceive their ability to verify news (epistemic self-efficacy) during the volatile 2024 U.S. election, using survey data to test hypotheses about information sources, misinformation exposure, and fatigue. Contrary to expectations, it finds no significant difference in verification difficulty between social media and mainstream news users, concluding that cognitive factors like universal information fatigue are more critical than platform choice.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Signal, Noise, and Burnout<br/>信号、噪声与倦怠] --> B(核心问题/Problem: Voter verification in high-volatility info environment<br/>高波动信息环境中的选民验证);
    A --> C(主要方法/Method: Survey analysis (Pew Research data), tests mediation & moderation<br/>调查分析，检验中介与调节效应);
    A --> D(关键结果/Results: No platform difference; burden driven by demographics & fatigue<br/>无平台差异；负担由人口统计与疲劳驱动);
    ```

- **[arXiv251225] From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education**
  - **tags:** [ai], [educational technology], [generative AI, personalization, adaptive learning, large language models, intelligent tutoring systems]
  - **authors:** Iman Reihanian, Yunfei Hou, Qingquan Sun
  - **institution:** California State University, San Bernardino
  - **link:** https://arxiv.org/pdf/2512.20714
  - **contributions:** 1. Identified and analyzed five key application domains for GenAI-enabled personalization in CS education: intelligent tutoring, personalized materials, formative feedback, AI-augmented assessment, and code review. 2. Synthesized four design patterns for successful implementations: context-aware tutoring anchored in student artifacts, multi-level hint structures, composition with traditional CS infrastructure, and human-in-the-loop quality assurance. 3. Proposed an exploration-first adoption framework for integrating GenAI, emphasizing piloting, instrumentation, learning-preserving defaults, and evidence-based scaling, while pairing recurrent risks with operational mitigations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e46f313e494a41a4a12873eddb6320db4cd59b6fb958bb008fd6f6512729af4_w640_q70.webp
  - **Simple LLM Summary:** This scoping review maps how generative AI enables personalized computer science education. It analyzes design choices across 32 studies and finds that structured implementations with explanation-first guidance and artifact grounding lead to more positive learning outcomes than unconstrained chat interfaces. The paper concludes that generative AI can provide precision scaffolding when embedded in audit-ready workflows that preserve productive struggle.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education] --> B[核心问题/Problem: Does GenAI personalization support or undermine CS learning?]
    A --> C[主要方法/Method: Scoping review of 32 studies; Analysis of design choices & patterns]
    A --> D[关键结果/Results: Structured designs (e.g., hint ladders, artifact grounding) are more effective; Proposes an exploration-first adoption framework]
    ```

- **[arXiv251225] YCB-Handovers Dataset: Analyzing Object Weight Impact on Human Handovers to Adapt Robotic Handover Motion**
  - **tags:** [cv], [human-robot interaction], [motion capture, dataset, handover, weight adaptation, YCB dataset]
  - **authors:** Parag Khanna, Karen Jane Dsouza, Chunyu Wang, Mårten Björkman, Christian Smith
  - **institution:** KTH Royal Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.20847
  - **contributions:** <1. Introduces the novel YCB-Handovers dataset, capturing 2771 human-human handover motions with varied object weights., 2. Provides an analysis of the impact of object weight on human reaching motion during handovers., 3. Bridges a gap in human-robot collaboration research by enabling data-driven, human-inspired models for weight-sensitive robotic motion planning.>
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af98ffe543cfd02847143e303696cbfb3dbc3991e06d43e1e59dda76a0ca8a49_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces the YCB-Handovers dataset, a motion capture dataset of human-human handovers with objects of varying weights. The dataset is built upon the YCB object set and aims to provide insights for developing intuitive, weight-adaptive robotic handover motions. The analysis shows that object weight significantly impacts human reaching motion, which can inform more natural and safe robotic handover behaviors.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[YCB-Handovers Dataset] --> B(核心问题/Problem: Lack of data on weight impact in handovers for HRI);
    A --> C(主要方法/Method: Capture human-human handover motions with varied weights);
    A --> D(关键结果/Results: Dataset & analysis for weight-adaptive robotic motion);
    ```

- **[arXiv251225] Pioneering Multimodal Emotion Recognition in the Era of Large Models: From Closed Sets to Open Vocabularies**
  - **tags:** [ai], [multimodal emotion recognition], [multimodal large language models, open-vocabulary, benchmarking, fusion strategies, prompt engineering]
  - **authors:** Jing Han, Zhiqiang Gao, Shihao Gao, Jialing Liu, Hongyu Chen, Zixing Zhang, Björn W. Schuller
  - **institution:** Hunan University, University of Cambridge, Imperial College London
  - **link:** https://arxiv.org/pdf/2512.20938
  - **contributions:** 1. Conducted the first large-scale benchmarking study of open-vocabulary multimodal emotion recognition (MER-OV) using 19 mainstream MLLMs. 2. Systematically analyzed key factors affecting MLLM performance in MER-OV, including reasoning capacity, fusion strategies, and prompt design. 3. Identified that a two-stage, trimodal (audio, video, text) fusion approach with video as the most critical modality yields optimal performance, and found a narrow performance gap between open- and closed-source LLMs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f45d32d66d378f46ef5f60f8b0f7b530f5e3f17019ab0a207910d809d72b3e5_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the underexplored potential of Multimodal Large Language Models (MLLMs) for fine-grained, open-vocabulary emotion recognition. It presents a comprehensive benchmark on the OV-MERD dataset, evaluating 19 MLLMs and analyzing factors like fusion strategies and prompt design. The key findings are that a two-stage trimodal fusion works best, video is the most critical modality, and the performance gap between open- and closed-source models is surprisingly small.
  - **Mindmap:**

    ```mermaid
    graph LR
        A[Pioneering Multimodal Emotion Recognition<br>多模态情感识别前沿] --> B(核心问题/Problem: MLLMs在细粒度开放词汇情感理解中潜力未充分探索<br>MLLMs' potential for fine-grained, open-vocabulary emotion understanding is underexplored)
        A --> C(主要方法/Method: 在OV-MERD数据集上对19个主流MLLMs进行首次大规模基准测试<br>First large-scale benchmark of 19 mainstream MLLMs on OV-MERD dataset)
        A --> D(关键结果/Results: 两阶段三模态融合最优，视频最关键，开源与闭源模型差距小<br>Two-stage trimodal fusion is optimal, video is most critical, narrow gap between open- and closed-source LLMs)
    ```

- **[arXiv251225] From Human Bias to Robot Choice: How Occupational Contexts and Racial Priming Shape Robot Selection**
  - **tags:** [other], [human-robot interaction], [racial bias, occupational stereotypes, stereotype priming, skin tone discrimination, anthropomorphism]
  - **authors:** Jiangen He, Wanqi Zhang, Jessica Barfield
  - **institution:** The University of Tennessee, University of Kentucky
  - **link:** https://arxiv.org/pdf/2512.20951
  - **contributions:** 1. Demonstrated that human occupational biases and skin-tone-based discrimination directly transfer to robot selection decisions. 2. Revealed distinct, context-dependent patterns of robot preference, with lighter-skinned agents favored in healthcare/education and darker-toned agents in construction/athletics. 3. Showed that exposure to human professionals of specific races can prime and systematically shift subsequent robot preferences in stereotype-consistent directions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e05e8cac9fadcb40ef8a6f45c93ec8405326df2cb55fbb423081a31a9baebd6a_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how societal biases influence human decisions when selecting robots for professional roles. Through two experiments with over 1000 participants, the study found that preferences for robots with different skin tones vary by occupational context and can be primed by exposure to human racial stereotypes. The main conclusion is that robotic deployment risks perpetuating existing social inequalities by inheriting human biases from human-human evaluation contexts.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[From Human Bias to Robot Choice<br>从人类偏见到机器人选择] --> B[核心问题/Problem<br>How societal biases influence robot selection<br>社会偏见如何影响机器人选择];
    A --> C[主要方法/Method<br>Two experiments (N=1038) across four occupational contexts<br>两个实验，涵盖四种职业场景];
    A --> D[关键结果/Results<br>Bias transfer & context-dependent preferences<br>偏见转移与情境依赖的偏好];
    ```

- **[arXiv251225] A Design Study Process Model for Medical Visualization**
  - **tags:** [other], [visualization], [design study, process model, medical visualization, visual analysis, interdisciplinary research]
  - **authors:** Mengjie Fan, Liang Zhou
  - **institution:** Peking University Health Science Center
  - **link:** https://arxiv.org/pdf/2512.21034
  - **contributions:** 1. Proposes a novel design study process model specifically tailored for medical visualization, emphasizing stakeholder distinction, stage differentiation by analytic logic, and task classification. 2. Refines previous general visualization design models by incorporating characteristics of medical problems and providing actionable guidance for each step. 3. Demonstrates the model's utility by applying it to guide a new visual analysis method design and by reanalyzing three existing works, validating its practical framework.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e5fe74c72d51a03dca133118f52d887d90317100c302c2b1d5fca972d1219ded_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a specialized design study process model for medical visualization, developed through literature review and interdisciplinary experience. The model emphasizes stakeholder analysis, task classification, and provides step-by-step guidance to make visualization design more targeted and adaptable to medical complexity. The authors demonstrate its application and argue it provides a systematic theoretical and practical framework for interdisciplinary medical visualization research.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[A Design Study Process Model for Medical Visualization<br>医学可视化设计研究过程模型] --> B(Problem: Lack of systematic methodology for medical visualization design<br>核心问题: 缺乏系统的医学可视化设计方法)
    A --> C(Method: Propose a tailored design study process model<br>主要方法: 提出定制的设计研究过程模型)
    A --> D(Results: Model provides theoretical framework and practical guidance<br>关键结果: 模型提供理论框架与实践指导)
    ```

- **[arXiv251225] When LLMs fall short in Deductive Coding: Model Comparison and Human AI Collaboration Workflow Design**
  - **tags:** [nlp], [text classification], [deductive coding, large language models, human-AI collaboration, BERT, learning analytics]
  - **authors:** Zijian Li, Luzhen Tang, Mengyu Xia, Xinyu Li, Naping Chen, Dragan Gašević, Yizhou Fan
  - **institution:** Peking University, Monash University, Shantou University
  - **link:** https://arxiv.org/pdf/2512.21041
  - **contributions:** 1. Conducted a comparative performance evaluation of LLMs and BERT-based models for deductive coding, revealing LLMs' limitations in handling imbalanced data and theoretical interpretation. 2. Identified systematic errors and biases exhibited by LLMs in theory-driven coding tasks, highlighting their difficulty with semantic similarity. 3. Designed and evaluated a novel human-AI collaborative workflow that improves coding efficiency while maintaining reliability, demonstrating a practical path for scaling such tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39f7b78a482db70949a4efca7f09dde7775d6e85ff7942e944bb807ed535f120_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the use of Large Language Models (LLMs) for automated, theory-driven (deductive) coding of educational dialogue data. It finds that LLMs do not outperform smaller BERT-based classifiers and exhibit systematic biases, leading to the design of a human-AI collaborative workflow. The main conclusion is that while LLMs have limitations in this specific task, a human-AI partnership offers a promising approach to maintain reliability while improving efficiency.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[当LLMs在演绎编码中表现不足<br/>When LLMs Fall Short in Deductive Coding] --> B(核心问题/Problem: 自动化编码难以处理稀有代码，人工编码效率低<br/>Auto-coding struggles with rare codes, human coding is inefficient)
    A --> C(主要方法/Method: 比较LLMs与BERT模型，设计人机协作工作流<br/>Compare LLMs vs. BERT, design Human-AI workflow)
    A --> D(关键结果/Results: LLMs未超越BERT，存在系统误差；人机协作提升效率与可靠性<br/>LLMs underperform BERT, have biases; Human-AI collaboration improves efficiency & reliability)
    ```

- **[arXiv251225] DexAvatar: 3D Sign Language Reconstruction with Hand and Body Pose Priors**
  - **tags:** [cv], [3D human pose estimation], [3D sign language reconstruction, biomechanical accuracy, hand and body pose priors, monocular video, SMPL-X]
  - **authors:** Kaustubh Kundu, Hrishav Bakul Barua, Lucy Robertson-Bell, Zhixi Cai, Kalin Stefanov
  - **institution:** Monash University, TCS Research
  - **link:** https://arxiv.org/pdf/2512.21054
  - **code:** https://github.com/kaustesseract/DexAvatar
  - **contributions:** 1. A novel framework (DexAvatar) for reconstructing biomechanically accurate 3D hand and body poses from monocular sign language videos. 2. The use of learned 3D hand and body pose priors to guide the reconstruction and overcome challenges like self-occlusion and motion blur. 3. Demonstrating strong performance on the SGNify benchmark, achieving a 35.11% improvement over the state-of-the-art.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/594bef871fe9a00d58a9f3f12c9a0b4bf4f66d3d738bd3f02dedcbad04bdcd25_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces DexAvatar, a framework that uses learned 3D hand and body pose priors to reconstruct accurate 3D sign language poses from monocular videos. It addresses the limitations of existing 2D datasets and noisy 3D estimations. The method significantly outperforms prior work on the SGNify motion capture benchmark.
  - **Mindmap:**

    ```mermaid
    graph LR
        A[DexAvatar] --> B[核心问题/Problem: 手语视频缺乏准确3D数据，现有3D姿态估计质量差]
        A --> C[主要方法/Method: 利用学习到的3D手部和身体姿态先验，从单目视频重建]
        A --> D[关键结果/Results: 在SGNify数据集上性能提升35.11%]
    ```

- **[arXiv251225] Making AI Work: An Autoethnography of a Workaround in Higher Education**
  - **tags:** [other], [Information Systems], [Autoethnography, Invisible Labour, Workaround, Sociotechnical Systems, User Innovation]
  - **authors:** Shang Chieh Lee, Bhuva Narayan, Simon Buckingham Shum, Stella Ng, A. Baki Kocaballi
  - **institution:** University of Technology Sydney
  - **link:** https://arxiv.org/pdf/2512.21055
  - **contributions:** 1. Provides an insider, autoethnographic account of the sociotechnical friction and "invisible labour" required to make enterprise GenAI functional in higher education. 2. Applies and extends Alter's theory of workarounds to interpret user-driven adaptations as integral acts of sociotechnical integration, not mere deviations. 3. Highlights the central paradox of GenAI workarounds: they enable functionality but can create unofficial "shadow" systems and obscure the crucial, politically charged labour involved.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c38d81a4b275e82620a51814d2cbc6d349963475ab4224ec58e70714de1ab37_w640_q70.webp
  - **Simple LLM Summary:** This study uses analytic autoethnography to examine a workaround developed when an institutional goal of empowering staff with GenAI clashed with technical and political constraints. It argues such workarounds are essential acts of sociotechnical integration that reveal the "invisible labour" needed to make AI functional, but this labour is often obscured, creating a paradox. The findings position this invisible labour as a core, rather than peripheral, component of practical GenAI implementation.
  - **Mindmap:**

    ```mermaid
    graph LR
        A[Making AI Work: An Autoethnography of a Workaround in Higher Education] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[GenAI实施中的社会技术摩擦与隐性劳动/Sociotechnical Friction & Invisible Labour in GenAI Implementation]
        C --> C1[分析性自我民族志与工作区理论/Analytic Autoethnography & Workaround Theory]
        D --> D1[工作区是核心的社会技术整合行为/Workarounds as Integral Sociotechnical Integration]
        D --> D2[揭示了GenAI的整合悖论/Reveals GenAI Integration Paradox]
    ```

- **[arXiv251225] Agentic Explainable Artificial Intelligence (Agentic XAI) Approach To Explore Better Explanation**
  - **tags:** [mlsys], [agent system], [Agentic AI, SHAP, Large Language Model, Iterative Refinement, Bias-Variance Trade-off]
  - **authors:** Tomoaki Yamaguchi, Yutong Zhou, Masahiro Ryo, Keisuke Katsura
  - **institution:** Gifu University, Leibniz Centre for Agricultural Landscape Research (ZALF), Brandenburg University of Technology Cottbus–Senftenberg, Kyoto University
  - **link:** https://arxiv.org/pdf/2512.21066
  - **contributions:** 1. Proposes a novel Agentic XAI framework integrating SHAP-based explainability with multimodal LLM-driven iterative refinement for generating progressively enhanced explanations. 2. Demonstrates the framework's application and evaluation in a real-world agricultural recommendation system using rice yield data. 3. Identifies a bias-variance trade-off in iterative refinement, showing that early stopping (regularization) is crucial for optimizing explanation quality, challenging assumptions of monotonic improvement.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76e69e3950a2d09bc883a9cee931300bdfbeacc4e1e6094150a08db35366449e_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes an Agentic Explainable AI (XAI) framework that combines SHAP analysis with iterative refinement by a multimodal Large Language Model (LLM) to generate better explanations. The framework was tested as an agricultural recommendation system, and evaluations by both human experts and LLMs showed that explanation quality improved over initial rounds but declined with excessive refinement, revealing a bias-variance trade-off. The findings indicate that strategic early stopping is necessary to optimize the practical utility of such agentic XAI systems.
  - **Mindmap:**

    ```mermaid
    graph LR
        A[Agentic XAI Approach] --> B[核心问题/Problem: 向非专业人士解释XAI输出困难/Hard to communicate XAI outputs to laypersons]
        A --> C[主要方法/Method: SHAP + 多模态LLM迭代优化/SHAP + Multimodal LLM Iterative Refinement]
        A --> D[关键结果/Results: 早期迭代提升质量，过度优化导致下降/Early rounds improve quality, excessive refinement causes drop]
    ```

- **[arXiv251225] Volatile Organic Compounds for Stress Detection: A Scoping Review and Exploratory Feasibility Study with Low-Cost Sensors**
  - **tags:** [other], [affective computing], [volatile organic compounds (VOCs), multimodal classification, low-cost sensors, stress detection, Random Forest]
  - **authors:** Nicolai Plintz, Marcus Vetter, Dirk Ifenthaler
  - **institution:** University of Mannheim, Technische Hochschule Mannheim, Curtis University
  - **link:** https://arxiv.org/pdf/2512.21105
  - **contributions:** 1. Comprehensive mapping of VOC biomarker evidence and technological gaps for emotion recognition. 2. Initial demonstration that low-cost sensors can capture stress-related VOC patterns in multimodal fusion. 3. Identification of key implementation challenges, such as interindividual variability and the need for individual calibration.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e1d1525e62afe978f13051c6114b1fe52c0caad526ab1d3c2dfb71cd0f5c3f29_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the use of volatile organic compounds (VOCs) for stress detection by conducting a scoping review and an exploratory feasibility study with low-cost sensors. The study combines low-cost TVOC sensors with physiological monitoring and uses Random Forest for multimodal classification to detect laboratory-induced stress. The results show that VOC sensors contribute to model performance, but substantial interindividual variability highlights the need for larger samples and individual calibration.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Volatile Organic Compounds for Stress Detection] --> B[核心问题/Problem: VOC-based emotion recognition is underexplored with low-cost sensors]
    A --> C[主要方法/Method: Scoping review + feasibility study with low-cost TVOC & physiological sensors, multimodal Random Forest]
    A --> D[关键结果/Results: VOC patterns detectable, 77.3% accuracy, high variability, need for individual calibration]
    ```

- **[arXiv251225] Learning Factors in AI-Augmented Education: A Comparative Study of Middle and High School Students**
  - **tags:** [ai], [educational technology], [learning analytics, correlation analysis, text mining, student perceptions, human-ai interaction]
  - **authors:** Gaia Ebli, Bianca Raimondi, Maurizio Gabbrielli
  - **institution:** University of Bologna
  - **link:** https://arxiv.org/pdf/2512.21246
  - **contributions:** 1. Investigated the interrelationships of four key learning factors (experience, clarity, comfort, motivation) in AI-augmented education, a gap in prior research. 2. Revealed a developmental moderator by comparing middle and high school students, finding holistic vs. differentiated evaluation patterns between age groups. 3. Established a foundation for age-specific AI integration strategies by showing perception dimensions actively mediate learning and their structure varies with developmental stage.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/37485735380aa9bf03e242b5a0fe4f8958c120a691a693af44376fb7f27c2b0b_w640_q70.webp
  - **Simple LLM Summary:** This study investigates how key learning factors relate to each other in AI-augmented programming education for middle and high school students. Using a multimethod analysis combining correlation analysis and text mining on classroom data, it finds that middle school students evaluate AI tools holistically, while high school students assess different factors independently. The conclusion is that the structure of student perceptions is moderated by developmental stage, which should inform age-appropriate AI integration strategies.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[论文标题: Learning Factors in AI-Augmented Education<br>Title: Learning Factors in AI-Augmented Education] --> B(核心问题/Problem: How do learning factor relationships vary by age in AI education?<br>核心问题/Problem: 学习因素关系在AI教育中如何随年龄变化？)
    A --> C(主要方法/Method: Multimethod quantitative analysis (correlation & text mining)<br>主要方法/Method: 多方法定量分析（相关性与文本挖掘）)
    A --> D(关键结果/Results: Middle school: holistic evaluation; High school: differentiated evaluation<br>关键结果/Results: 初中生: 整体性评估; 高中生: 差异性评估)
    ```

- **[arXiv251225] Quadrupped-Legged Robot Movement Plan Generation using Large Language Model**
  - **tags:** [mlsys], [agent system], [Large Language Model, quadruped robot, ROS navigation, sensor fusion, offloaded inference]
  - **authors:** Muhtadin, Vincentius Gusti Putu A. B. M., Ahmad Zaini, Mauridhi Hery Purnomo, I Ketut Eddy Purnama, Chastine Fatichah
  - **institution:** Institut Teknologi Sepuluh Nopember (ITS)
  - **link:** https://arxiv.org/pdf/2512.21293
  - **contributions:** 1. A novel distributed control architecture that offloads LLM-based high-level planning to an external server to overcome the computational constraints of a lightweight quadruped robot platform. 2. A system that grounds natural language instructions into executable ROS navigation commands using real-time sensor fusion (LiDAR, IMU, Odometry). 3. Experimental validation in a structured indoor environment demonstrating over 90% aggregate success rate, proving the feasibility of the offloaded LLM planning approach for real-world deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/70190e79023c7f7dad391e0e2059aa027ac578d23c266728acc6d3e205234b01_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a distributed control framework that uses a Large Language Model (LLM) to generate navigation plans for a quadruped robot from natural language commands. The computationally intensive LLM inference is offloaded to an external server, while the robot executes the plans locally using ROS and sensor data. Experiments in indoor environments showed the system is robust, achieving over 90% success rate and validating the approach for intuitive robot control.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Quadrupped-Legged Robot Movement Plan Generation using Large Language Model] --> B(核心问题/Problem: High barrier to entry for robot control)
    A --> C(主要方法/Method: Offloaded LLM planning + ROS navigation with sensor fusion)
    A --> D(关键结果/Results: >90% success rate in indoor navigation)
    ```

- **[arXiv251225] Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks**
  - **tags:** [ai], [large language models], [scaling laws, economic productivity, agentic workflows, compute scaling, algorithmic progress]
  - **authors:** Ali Merali
  - **institution:** Yale University
  - **link:** https://arxiv.org/pdf/2512.21316
  - **contributions:** 1. Derives empirical scaling laws linking LLM training compute to professional productivity gains. 2. Quantifies the relative contributions of increased compute (56%) versus algorithmic progress (44%) to annual productivity improvements. 3. Identifies a significant disparity in productivity gains between non-agentic analytical tasks and agentic workflows requiring tool use.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f148c34bb4d8aa66926afe66d00135fb826ae28f1253bfed833d9ff39c8b046d_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the relationship between LLM capabilities and professional productivity through a preregistered experiment with over 500 professionals. It finds that each year of AI progress reduces task time by 8%, driven by both compute and algorithmic scaling, but gains are larger for analytical tasks than for agentic ones. The results suggest continued model scaling could significantly boost U.S. productivity over the next decade.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Scaling Laws for Economic Productivity<br/>经济生产力缩放定律] --> B(核心问题/Problem: LLM compute vs. professional productivity<br/>LLM计算与专业生产力的关系);
    A --> C(主要方法/Method: Preregistered experiment with 500+ professionals using 13 LLMs<br/>使用13个LLM对500多名专业人员的预注册实验);
    A --> D(关键结果/Results: 8% annual time reduction, 56% compute vs. 44% algorithm gains, larger gains for non-agentic tasks<br/>每年任务时间减少8%，56%源于计算，44%源于算法，非智能体任务收益更大);
    ```
