---
slug: /daily/cshc/20251229-20260104
---
# 20251229-20260104 (cs.HC)

## 2025-12-29

- **[arXiv251229] MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding**
  - **tags:** [mlsys], [multi-modal training], [wearable sensing, actigraphy encoder, projection module, frozen LLM, behavioral summarization]
  - **authors:** Aiwei Zhang, Arvind Pillai, Andrew Campbell, Nicholas C. Jacobson
  - **institution:** Dartmouth College
  - **link:** https://arxiv.org/pdf/2512.21506
  - **contributions:** 1. Introduces MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs) for free-text generation of daily behavioral summaries. 2. Constructs a novel, large-scale dataset of 54,383 (actigraphy, text) pairs derived from real-world NHANES recordings. 3. Demonstrates superior performance over prompt-based baselines in semantic fidelity and lexical accuracy, with qualitative analysis showing the model captures circadian structure and behavioral transitions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of generating natural language summaries from raw physiological signals like actigraphy. It proposes MotionTeller, a framework that integrates a pretrained actigraphy encoder with a frozen LLM via a projection module. The model, trained on a novel dataset, outperforms baselines in generating fluent, human-centered descriptions of daily behavior.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs] --> B[核心问题/Problem: How to generate natural language summaries from raw physiological signals like actigraphy?]
        A --> C[主要方法/Method: Combines a pretrained actigraphy encoder and a projection module to map behavioral embeddings into a frozen LLM's token space.]
        A --> D[关键结果/Results: Achieves high semantic fidelity (BERTScore-F1=0.924) and lexical accuracy (ROUGE-1=0.722), outperforming baselines by 7%.]
    ```

- **[arXiv251229] Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures**
  - **tags:** [other], [human-ai interaction], [bidirectional alignment, value-centered design, interactive alignment]
  - **authors:** Hua Shen, Tiffany Knearem, Divy Thakkar, Pat Pataranutaporn, Anoop Sinha, Yike, Jenny T. Liang, Lama Ahmad, Tanu Mitra, Brad A. Myers, Yang Li
  - **institution:** NYU Shanghai, MBZUAI, Google, Massachusetts Institute of Technology, Carnegie Mellon University, OpenAI, University of Washington, Google DeepMind
  - **link:** https://arxiv.org/pdf/2512.21551
  - **contributions:** 1. Proposes a shift from unidirectional to bidirectional human-AI alignment, framing it as a dynamic, reciprocal co-adaptation process. 2. Emphasizes embedding human and societal values into AI alignment research through value-centered design. 3. Aims to establish an interdisciplinary research agenda for responsible, reciprocal human-AI futures through collaborative workshop activities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp
  - **Simple LLM Summary:** This workshop paper identifies the inadequacy of traditional, one-way AI alignment and proposes a bidirectional human-AI alignment framework where humans and AI co-adapt through interaction and value-centered design. It aims to bring together interdisciplinary researchers to explore methods for interactive alignment and societal impact evaluation. The main conclusion is the need for a shared agenda to advance responsible, reciprocal collaboration between humans and AI systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Human-AI Interaction Alignment] --> B[核心问题/Problem: Unidirectional AI alignment is inadequate for dynamic human-AI interaction]
        A --> C[主要方法/Method: Bidirectional alignment via value-centered design, interaction, and evaluation]
        A --> D[关键结果/Results: Establishes agenda for reciprocal, responsible human-AI futures]
    ```

- **[arXiv251229] Bidirectional Human-AI Alignment in Education for Trustworthy Learning Environments**
  - **tags:** [ai], [ai for education], [human-ai alignment, trustworthy ai, adaptive learning, educational technology, ai ethics]
  - **authors:** Hua Shen
  - **institution:** NYU Shanghai, New York University
  - **link:** https://arxiv.org/pdf/2512.21552
  - **contributions:** 1. Proposes the novel concept of "bidirectional human-AI alignment" for education, emphasizing mutual adaptation between humans and AI systems. 2. Explores the evolution of AI's role in education from a support tool to a collaborative partner, analyzing its impact on teacher roles and student agency. 3. Provides actionable strategies for policymakers, developers, and educators to ensure AI advances equity, transparency, and human flourishing in learning environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7f40fe114da7bae34b09e44db18fa32bb4f64e57bd01e75e96afc80c2ddc136_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the risks of AI in education, such as bias and loss of autonomy, by proposing the concept of bidirectional human-AI alignment. The method involves not only embedding human values into AI but also equipping educators and students to guide these technologies. It concludes that reframing AI adoption as a process of mutual adaptation is key to creating trustworthy learning environments where humans and AI can grow together.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题: Bidirectional Human-AI Alignment in Education] --> B[核心问题/Problem: AI in education introduces risks to equity, privacy, and autonomy.]
        A --> C[主要方法/Method: Proposes bidirectional alignment: embedding human values into AI and equipping humans to interpret/guide AI.]
        A --> D[关键结果/Results: Envisions a future of mutual adaptation where AI advances equity, transparency, and human flourishing.]
    ```

- **[arXiv251229] Emotion-Aware Smart Home Automation Based on the eBICA Model**
  - **tags:** [ai], [affective computing], [eBICA, emotion-aware automation, psychological safety, STAI-S, smart home]
  - **authors:** Masaaki Yamauchi, Yiyuan Liang, Hiroko Hara, Hideyuki Shimonishi, Masayuki Murata
  - **institution:** The University of Osaka
  - **link:** https://arxiv.org/pdf/2512.21589
  - **contributions:** 1. Proposed an emotion-aware smart home automation framework guided by the eBICA model for dynamic control based on emotional state. 2. Conducted a proof-of-concept experiment demonstrating a significant reduction in state anxiety (STAI-S) through comfort-inducing automation. 3. Found that individual personality and anxiety traits modulate the relief effect, indicating a pathway for personalized emotion-adaptive systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5260e7567742ea94b88d5dab934224f8814c9ad506e334dbc2220c01eec9093d_w640_q70.webp
  - **Simple LLM Summary:** This study proposes a smart home automation framework that uses the eBICA model to adapt to a user's emotional state. A proof-of-concept experiment showed that anxiety-inducing automation significantly reduced user anxiety, demonstrating the framework's effectiveness in promoting psychological safety and its potential for personalization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Emotion-Aware Smart Home Automation Based on the eBICA Model] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统自动化缺乏情感适应<br/>Traditional automation lacks emotional adaptation]
        C --> C1[基于eBICA的框架<br/>eBICA-based framework]
        C --> C2[概念验证实验<br/>Proof-of-concept experiment]
        D --> D1[焦虑显著降低<br/>Significant anxiety reduction]
        D --> D2[个性化潜力<br/>Personalization potential]
    ```

- **[arXiv251229] Ghostcrafting AI: Under the Rug of Platform Labor**
  - **tags:** [other], [human-computer interaction], [platform labor, ghostcrafting, ethnography, ethical AI, situated learning]
  - **authors:** ATM Mizanur Rahman, Sharifa Sultana
  - **institution:** University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2512.21649
  - **contributions:** 1. Proposes the novel conceptual framework of "Ghostcrafting AI" to describe the invisible and essential labor of platform workers in building and sustaining AI systems. 2. Provides an in-depth ethnographic account of the situated learning practices and coping tactics of platform workers in Bangladesh, revealing their resourcefulness and agency. 3. Highlights the structural precarity and exploitation faced by these workers, arguing for urgent design, policy, and governance interventions to ensure fairness and recognition.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49785e109f95da7d4a140badf3830b8bc2770c67e7d5e4a226476af7aecf0903_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the hidden labor of platform workers in the Global South who build and sustain AI systems. Through an eight-month ethnography in Bangladesh, it conceptualizes this as "Ghostcrafting AI" and documents how workers learn and cope with exploitative conditions. The study concludes that AI is fundamentally dependent on this invisible labor and calls for interventions to ensure fairness and sustainability in platform work.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Ghostcrafting AI: Under the Rug of Platform Labor"]
        Root --> Problem["核心问题/Problem: Platform laborers are indispensable yet invisible in building AI systems."]
        Root --> Method["主要方法/Method: Eight-month ethnography in Bangladesh's platform labor industry."]
        Root --> Results["关键结果/Results: Reveals workers' situated learning, coping tactics, and the need for fairness interventions."]
    ```

- **[arXiv251229] Modified TSception for Analyzing Driver Drowsiness and Mental Workload from EEG**
  - **tags:** [ai], [brain-computer interface (BCI)], [EEG, TSception, Adaptive Average Pooling, spatiotemporal features, drowsiness detection]
  - **authors:** Gourav Siddhad, Anurag Singh, Rajkumar Saini, Partha Pratim Roy
  - **institution:** Indian Institute of Technology Roorkee, OP Jindal University, Luleå University of Technology, Indian Institute of Technology Dhanbad
  - **link:** https://arxiv.org/pdf/2512.21747
  - **contributions:** 1. Proposed a Modified TSception architecture with a five-layer temporal refinement strategy to capture multi-scale brain dynamics. 2. Introduced Adaptive Average Pooling for structural flexibility to handle varying EEG input dimensions and a two-stage fusion mechanism for optimized spatiotemporal feature integration. 3. Demonstrated improved performance stability (reduced confidence interval) on the SEED-VIG dataset and state-of-the-art generalizability on the STEW mental workload dataset.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43d71afc9fcee5064adfe94f1fb1d9f8a1c55ccd8d1c759dcd1b5801b9d23f46_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a Modified TSception deep learning model for robust EEG-based detection of driver drowsiness and mental workload. The key modifications include a multi-layer temporal refinement strategy and Adaptive Average Pooling, which improve the model's stability and ability to handle varying input sizes. The model achieves comparable accuracy with significantly better stability on a drowsiness dataset and state-of-the-art results on a mental workload dataset, demonstrating its effectiveness for reliable cognitive state monitoring.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Modified TSception for Analyzing Driver Drowsiness and Mental Workload from EEG] --> B(核心问题/Problem: Driver drowsiness detection for road safety)
        A --> C(主要方法/Method: Modified TSception with temporal refinement & Adaptive Average Pooling)
        A --> D(关键结果/Results: Improved stability on SEED-VIG, SOTA on STEW)
    ```

- **[arXiv251229] Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning**
  - **tags:** [nlp], [image captioning], [scientific figure captioning, large-scale dataset, domain-specific training, human evaluation, large language models (LLMs)]
  - **authors:** Ting-Hao K.Huang, Ryan A. Rossi, Sungchul Kim, Tong Yu, Ting-Yao E. Hsu, Ho Yin, C. Lee Giles
  - **institution:** The Pennsylvania State University, Adobe Research
  - **link:** https://arxiv.org/pdf/2512.21789
  - **contributions:** 1. Creation and continuous updating of a large-scale, real-world dataset of scientific figure-caption pairs from arXiv papers. 2. Conducting extensive evaluations, both automatic and human, on generated and author-written captions to assess quality. 3. Developing interactive systems and launching annual challenges to advance the field and help scientists write better captions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp
  - **Simple LLM Summary:** This paper reviews the SciCap project's first five years, which focused on generating and evaluating captions for scientific figures. The core method involved building a large-scale dataset from arXiv and exploring domain-specific training, similar to models like SciBERT, for captioning. The conclusion outlines key lessons learned and proposes future research directions to address unsolved challenges in the field.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[科学图表说明质量差/Poor quality of scientific figure captions]
        Problem --> P2[缺乏大规模真实数据集/Lack of large-scale real-world dataset]
        Method --> M1[构建arXiv图表-说明对数据集/Construct arXiv figure-caption dataset]
        Method --> M2[领域特定训练与评估/Domain-specific training & evaluation]
        Method --> M3[应对大语言模型兴起/Navigate rise of LLMs]
        Results --> R1[总结技术方法经验/Summarize technical & methodological lessons]
        Results --> R2[提出未来挑战与方向/Outline future challenges & directions]
    ```

- **[arXiv251229] Generative Lecture: Making Lecture Videos Interactive with LLMs and AI Clone Instructors**
  - **tags:** [other], [Human-Computer Interaction (HCI)], [interactive videos, personalized learning, AI clone instructor, on-demand content generation, generative AI]
  - **authors:** Hye-Young Jo, Ada Zhao, Xiaoan Liu, Ryo Suzuki
  - **institution:** University of Colorado Boulder
  - **link:** https://arxiv.org/pdf/2512.21796
  - **contributions:** 1) Introduces the "Generative Lecture" concept for transforming passive lecture videos into interactive, two-way learning experiences using AI. 2) Proposes a system architecture that integrates an AI clone instructor (via HeyGen, ElevenLabs, GPT-5) with on-demand content generation to respond to student queries. 3) Identifies and implements eight key system features (e.g., on-demand clarification, adaptive quiz) based on a design study, and validates the system's usability and effectiveness through user studies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/047a789db6b06e8758007487ecf18eb3b59ea0d4d56a243c23b590b8ad50497f_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Generative Lecture, a system that uses generative AI and AI clone instructors to make existing lecture videos interactive, allowing students to ask questions and receive personalized, generated explanations. The system was developed based on user goals and features like on-demand clarification and adaptive quizzes. User studies suggest it enables effective two-way communication and supports personalized learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Generative Lecture<br>生成式讲座") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("Lecture videos are passive<br>讲座视频是被动的")
        Method --> M1("Use AI Clone Instructor & LLMs<br>使用AI克隆讲师和LLMs")
        Method --> M2("Generate on-demand content<br>生成按需内容")
        Results --> R1("Enables two-way communication<br>实现双向交流")
        Results --> R2("Supports personalized learning<br>支持个性化学习")
    ```

- **[arXiv251229] Conserved active information**
  - **tags:** [ai], [information theory], [conserved active information, No-Free-Lunch, KL divergence, search space, information conservation]
  - **authors:** Yanchen Chen, Daniel Andrés Díaz-Pachón
  - **institution:** University of Miami
  - **link:** https://arxiv.org/pdf/2512.21834
  - **contributions:** 1. Introduces conserved active information (I⊕), a symmetric measure of net information gain/loss across a search space that respects No-Free-Lunch conservation. 2. Demonstrates that I⊕ can reveal regimes (e.g., strong knowledge reducing global disorder) that are hidden from traditional measures like KL divergence. 3. Applies the framework to resolve a longstanding critique of active information and illustrates its utility in domains like Markov chains and cosmological fine-tuning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1371f9cf2f5be050a2495fc2f2b19865fddd5c4a8834df1cd98fc2da7eea7111_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new information-theoretic measure called conserved active information (I⊕) to quantify net information change in search problems while respecting conservation laws. It shows that I⊕ uncovers scenarios, such as strong knowledge imposing order, which are missed by standard divergence measures. The work resolves a key critique of active information and enables applications in search and optimization.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Conserved active information] --> Problem[核心问题/Problem: Limitations of average-focused information measures like KL divergence]
        Root --> Method[主要方法/Method: Introduce conserved active information I⊕, a symmetric extension respecting No-Free-Lunch]
        Root --> Results[关键结果/Results: I⊕ reveals hidden regimes (e.g., strong knowledge reduces disorder), resolves critique of active information]
    ```

- **[arXiv251229] Positive Narrativity Enhances Sense of Agency toward a VR Avatar**
  - **tags:** [other], [virtual reality and embodiment], [full-body illusion, sense of agency, avatar narrativity, Proteus effect, bodily self-consciousness]
  - **authors:** Kureha Hamagashira, Miyuki Azuma, Sotaro Shimada
  - **institution:** Meiji University
  - **link:** https://arxiv.org/pdf/2512.21968
  - **contributions:** 1. Investigated the explicit manipulation of avatar impressions using narrative context (positive vs. negative stories) to modulate the full-body illusion. 2. Demonstrated that positive narratives significantly enhance the sense of agency toward a VR avatar. 3. Found a positive correlation between the sense of agency and participants' perceived personal familiarity with the avatar.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d658df90fd7ef654f1504e1b44262071ad05b5dab0737598e4b949dd3f39383_w640_q70.webp
  - **Simple LLM Summary:** This study explores how narrative context affects embodiment in VR by having participants embody an avatar after hearing either a positive or negative story about it. The results show that positive narratives significantly increase the user's sense of agency over the avatar, and this feeling is linked to how familiar the avatar feels. This suggests that storytelling can be a tool to modulate virtual embodiment experiences.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Positive Narrativity Enhances Sense of Agency toward a VR Avatar] --> B(核心问题/Problem: How does narrative context affect the full-body illusion?);
        A --> C(主要方法/Method: Participants embodied an avatar after listening to a positive or negative narrative about it.);
        A --> D(关键结果/Results: Positive narratives enhanced sense of agency, which correlated with perceived familiarity.);
    ```

- **[arXiv251229] SketchPlay: Intuitive Creation of Physically Realistic VR Content with Gesture-Driven Sketching**
  - **tags:** [other], [Human-Computer Interaction (HCI)], [Gestural Interaction, Physics Simulation, Air-drawn Sketches, VR Content Creation]
  - **authors:** Xiangwen Zhang, Xiaowei Dai, Runnan Chen, Xiaoming Chen, Zeke Zexi Hu
  - **institution:** Beijing Technology and Business University, The University of Sydney
  - **link:** https://arxiv.org/pdf/2512.22016
  - **contributions:** 1. A novel VR interaction framework (SketchPlay) that combines air-drawn sketches and gestures to create dynamic, physically realistic scenes. 2. A method that uses sketches to capture object/scene structure and gestures to convey physical cues (velocity, force) for defining motion and behavior. 3. Enables the generation of complex physical phenomena (rigid body motion, elastic deformation, cloth dynamics) through an intuitive, controller-free creation process.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79eefb65bc566df3d83196a3500892e4d09f26b4aa064a68193142a9ec59b0c0_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes SketchPlay, a VR framework that allows users to create physically realistic dynamic scenes by sketching objects in the air and using gestures to define their motion. This method combines structural and dynamic intent to simulate phenomena like rigid body and cloth dynamics. The approach is shown to be more expressive and offer a better user experience than text-driven methods, lowering the barrier for non-expert creators.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SketchPlay: Intuitive Creation of Physically Realistic VR Content with Gesture-Driven Sketching] --> B[核心问题/Problem: Creating physically realistic VR content is complex and requires expert tools, creating barriers for non-expert users.]
        A --> C[主要方法/Method: A novel VR framework that transforms air-drawn sketches (for structure) and gestures (for physical cues like velocity/force) into dynamic, physically realistic scenes.]
        A --> D[关键结果/Results: Offers significant advantages in expressiveness and user experience over traditional methods, lowering the entry barrier and showing potential for education, art, and storytelling.]
    ```

- **[arXiv251229] Context-Aware Intelligent Chatbot Framework Leveraging Mobile Sensing**
  - **tags:** [mlsys], [agent system], [mobile sensing, context-aware, large language models, structured prompting, digital health]
  - **authors:** Ziyan Zhang, Nan Gao, Zhiqiang Nie, Shantanu Pal, Haining Zhang
  - **institution:** Nankai University, Tsinghua University, Deakin University
  - **link:** https://arxiv.org/pdf/2512.22032
  - **contributions:** 1. Proposes a context-sensitive conversational assistant framework that integrates mobile sensing data with large language models. 2. Abstracts raw mobile sensing signals into 16 contextual scenarios and translates them into natural language prompts. 3. Designs a structured prompting system to guide the LLM in generating personalized and contextually relevant dialogue.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ee41bc75f2109be1e0a7714aeb8ea0c7f389bba53adcab3bd17db8b8d415623_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of LLMs in understanding real-world user behavior by proposing a chatbot framework that uses mobile sensing data. The method abstracts sensor data into contextual scenarios and converts them into natural language prompts to guide the LLM. The work demonstrates the potential of passive behavioral data for creating personalized, context-aware conversational agents, particularly for digital health applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Context-Aware Intelligent Chatbot Framework<br>上下文感知智能聊天机器人框架] --> B[Problem: LLMs lack real-world user context<br>问题：大语言模型缺乏现实用户情境]
        A --> C[Method: Integrate mobile sensing & structured prompts<br>方法：集成移动感知与结构化提示]
        A --> D[Results: Personalized, context-relevant dialogue<br>结果：个性化、情境相关的对话]
    ```

- **[arXiv251229] StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars**
  - **tags:** [mlsys], [diffusion models], [autoregressive distillation, adversarial refinement, real-time streaming, reference-anchored positional re-encoding, consistency-aware discriminator]
  - **authors:** Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu
  - **institution:** Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University
  - **link:** https://arxiv.org/pdf/2512.22065
  - **code:** https://streamavatar.github.io
  - **contributions:** 1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Non-causal, high-cost diffusion models unsuitable for real-time streaming; Limited to head-and-shoulder, lacking gestures.]
        C[主要方法/Method<br>Two-stage autoregressive adaptation (distillation + refinement) with Reference Sink, RAPR, Consistency-Aware Discriminator.]
        D[关键结果/Results<br>State-of-the-art real-time, interactive full-body avatar with natural talking/listening and gestures.]
    ```

## 2025-12-30

- **[arXiv251230] SoDA: An Efficient Interaction Paradigm for the Agentic Web**
  - **tags:** [mlsys], [agent system], [Sovereign Digital Avatar, Intent-Permission Handshake, orthogonal decoupling, A2A protocols, dual-factor adaptive routing]
  - **authors:** Zicai Cui, Zhouyuan Jian, Weiwen Liu, Weinan Zhang
  - **institution:** Shanghai Jiao Tong University, Shanghai Innovation Institute
  - **link:** https://arxiv.org/pdf/2512.22135
  - **contributions:** 1. Proposes a user sovereignty interaction paradigm for the Agentic Web, decoupling memory from application logic to break data lock-in and shifting from explicit instruction to implicit intent alignment to reduce cognitive load. 2. Implements the paradigm via the Sovereign Digital Avatar (SoDA) with an orthogonal decoupling design of storage, computation, and interaction, establishing the principle of "data as a persistent asset, model as a transient tool". 3. Designs an Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor adaptive routing for active risk governance in zero-trust environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes the Sovereign Digital Avatar (SoDA), a new interaction paradigm for the Agentic Web that decouples user memory from applications and uses intent alignment to reduce cognitive load. It introduces an architecture with orthogonal decoupling and a secure handshake mechanism for zero-trust environments. Empirical results show it significantly reduces token consumption and user cognitive load compared to existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SoDA: An Efficient Interaction Paradigm for the Agentic Web] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[数据锁定/Data Lock-in]
        B --> B2[认知过载/Cognitive Overload]
        C --> C1[主权数字化身/Sovereign Digital Avatar (SoDA)]
        C --> C2[正交解耦设计/Orthogonal Decoupling Design]
        C --> C3[意图-权限握手机制/Intent-Permission Handshake Mechanism]
        D --> D1[降低令牌消耗/Reduces Token Consumption by 27-35%]
        D --> D2[降低认知负载/Reduces Cognitive Load by 72% vs RAG, 88% vs Manual]
    ```

- **[arXiv251230] Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware**
  - **tags:** [cv], [human activity recognition], [driver monitoring systems, edge AI, quantization, temporal decision head, confounder-aware labeling]
  - **authors:** Vesal Ahsani, Babak Hossein Khalaj
  - **institution:** Sharif University of Technology
  - **link:** https://arxiv.org/pdf/2512.22298
  - **contributions:** 1. A deployable single-camera driver behavior recognition pipeline optimized for low-cost edge hardware (Raspberry Pi 5 and Google Coral Edge TPU). 2. A confounder-aware label design to reduce false positives from visually similar actions. 3. A temporal decision head that generates stable alerts based on sustained, confident predictions rather than noisy per-frame outputs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bd52e06dc77080ab346fc3d6fe46b900bf06b5c1eaeb6ae89801ac125ee7c51_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a real-time driver behavior recognition system designed for low-cost edge hardware to address the challenges of compute, power, and cost constraints in vehicles. The method combines a compact vision model, confounder-aware labeling, and a temporal decision head to recognize 17 distraction and drowsiness-related behaviors. The optimized system achieves 16 FPS on a Raspberry Pi 5 and 25 FPS on a Coral Edge TPU, enabling practical deployment for in-cabin monitoring.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[实时DMS需求 / Real-time DMS needs low latency, low cost, low power]
        C --> C1[紧凑单摄像头系统 / Compact single-camera pipeline]
        C1 --> C2[紧凑视觉模型 / Compact per-frame vision model]
        C1 --> C3[抗混淆标签设计 / Confounder-aware label design]
        C1 --> C4[时序决策头 / Temporal decision head]
        D --> D1[性能: 16 FPS (RPi5), 25 FPS (Edge TPU) / Performance: 16 FPS (RPi5), 25 FPS (Edge TPU)]
        D --> D2[验证: 真实车辆测试 / Validation: Real in-vehicle tests]
    ```

- **[arXiv251230] Emotion classification using EEG headset signals and Random Forest**
  - **tags:** [ai], [affective computing], [EEG, Random Forest, emotion classification, brain-computer interface, real-time prediction]
  - **authors:** Ricardo Vasquez, Diego Riofrío-Luzcando, Joe Carrion-Jumbo, Cesar Guevara
  - **institution:** Universidad Internacional SEK, Universidad Indoamérica, The Institute of Mathematical Sciences (ICMAT-CSIC)
  - **link:** https://arxiv.org/pdf/2512.22333
  - **contributions:** 1. Developed a model for classifying human emotions (happiness, sadness, relaxation) using EEG signals from a consumer-grade headset (EMOTIV EPOC). 2. Applied the Random Forest algorithm to achieve high accuracy, particularly for happiness (97.21%). 3. Implemented a real-time emotion prediction system that captures EEG signals, processes them, and visually displays the predicted emotion.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e19385b22eca0965c66f7006e387468776c757a86a9b784693bc7b77b3c7533_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a system to classify human emotions (happiness, sadness, relaxation) from EEG signals using a Random Forest model. The model was trained on data from 50 participants and achieved high accuracy, especially for happiness. The work was extended to create a real-time prediction algorithm that outputs the result with representative images.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Emotion classification using EEG headset signals and Random Forest] --> B(核心问题/Problem: 如何从EEG信号中检测和分类情绪？/How to detect and classify emotions from EEG signals?)
        A --> C(主要方法/Method: 使用EMOTIV EPOC采集EEG数据，并应用随机森林模型进行分类/Use EMOTIV EPOC to collect EEG data and apply Random Forest model for classification)
        A --> D(关键结果/Results: 快乐分类准确率97.21%，实现实时情绪预测算法/Happiness classification accuracy 97.21%, implemented a real-time emotion prediction algorithm)
    ```

- **[arXiv251230] Human-like visual computing advances explainability and few-shot learning in deep neural networks for complex physiological data**
  - **tags:** [cv], [medical image analysis], [pseudo-colouring, few-shot learning, prototypical networks, ResNet-18, explainability]
  - **authors:** Alaa Alahmadi, Mohamed Hasan
  - **institution:** Newcastle University, University of Leeds
  - **link:** https://arxiv.org/pdf/2512.22349
  - **contributions:** 1. Introduces a perception-informed pseudo-colouring technique to encode clinically salient temporal ECG features (like QT-interval) into structured colour representations. 2. Demonstrates that this technique enables effective few-shot and one-shot learning for a complex physiological data task (drug-induced LQTS) using prototypical networks and ResNet-18. 3. Shows that the method improves model explainability by guiding attention to clinically meaningful features and that aggregating multiple cardiac cycles (mirroring human perceptual averaging) further boosts performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4573948678ad6f25faec7ec6be8baccee385ce760fef63e3980935e84e21be0_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problems of data inefficiency and poor interpretability in deep learning models for physiological signal analysis. It proposes a human-inspired pseudo-colouring technique to encode ECG features, enabling effective few-shot learning and improving model explainability by focusing on clinically relevant signal components. The results demonstrate that incorporating human-like perceptual encoding can bridge data efficiency and interpretability in medical AI.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Human-like visual computing advances explainability and few-shot learning in deep neural networks for complex physiological data] --> B1
        A --> B2
        A --> B3
        B1[核心问题/Problem] --> C1[数据效率低/Lack of data efficiency]
        B1 --> C2[可解释性差/Limited explainability]
        B1 --> C3[临床可靠性受限/Constrained clinical reliability]
        B2[主要方法/Method] --> D1[感知启发的伪着色技术/Perception-informed pseudo-colouring]
        D1 --> E1[编码临床特征/Encode clinical features (e.g., QT-interval)]
        D1 --> E2[结构化颜色表示/Structured colour representations]
        B2 --> D2[原型网络与ResNet-18/Prototypical networks & ResNet-18]
        B2 --> D3[聚合多个心跳周期/Aggregate multiple cardiac cycles]
        B3[关键结果/Results] --> F1[实现少样本与单样本学习/Achieve few-shot & one-shot learning]
        B3 --> F2[提升可解释性/Improve explainability (guide attention)]
        B3 --> F3[桥接数据效率与因果推理/Bridge data efficiency & causal reasoning]
    ```

- **[arXiv251230] Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection**
  - **tags:** [mlsys], [agent system], [multi-agent LLM framework, knowledge gap detection, student-AI dialogue analysis, QueryQuilt, educational technology]
  - **authors:** Quanzhi Fu, Qiyu Wu, Dan Williams
  - **institution:** Virginia Tech
  - **link:** https://arxiv.org/pdf/2512.22404
  - **contributions:** 1. Proposes QueryQuilt, a novel multi-agent LLM framework for automated detection of common student knowledge gaps in large lectures. 2. Introduces a two-agent design: a Dialogue Agent that engages students with probing questions and a Knowledge Gap Identification Agent that analyzes chat logs. 3. Demonstrates the system's potential with high accuracy (100%) on simulated data and high completeness (95%) on real student-AI dialogue data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/346f14200e9375ed815220f7c720c8952c5109e4bcf1c3f206a9c517e2f80947_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes QueryQuilt, a multi-agent LLM framework that analyzes student-AI chat logs to automatically identify common knowledge gaps in large-scale lectures. The system uses a Dialogue Agent to interact with students and a Knowledge Gap Identification Agent to analyze the dialogues, providing instructors with insights into class-wide understanding. Initial evaluation shows promising accuracy and completeness, indicating its potential for improving teaching in real classroom environments.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[大班教学难以及时发现学生的知识缺口/Large lectures make timely knowledge gap identification challenging]
    C --> C1[提出QueryQuilt: 一个多智能体LLM框架/Propose QueryQuilt: a multi-agent LLM framework]
    C1 --> C2[对话智能体: 回答并探查学生问题/Dialogue Agent: responds and probes student questions]
    C1 --> C3[知识缺口识别智能体: 分析对话识别共同缺口/Knowledge Gap Identification Agent: analyzes dialogues to identify common gaps]
    D --> D1[模拟学生数据: 100%准确率/Simulated student data: 100% accuracy]
    D --> D2[真实学生-AI对话数据: 95%完整性/Real student-AI dialogue data: 95% completeness]
    ```

- **[arXiv251230] Learning to Program != "One-Size-Fits-All": Exploring Variations of Parsons Problems as Scaffolding**
  - **tags:** [other], [computing education], [Parsons Problems, Scaffolding, Faded Parsons, Pseudocode Parsons, Codespec]
  - **authors:** Carl Christopher Haynes-Magyar
  - **institution:** University of Pittsburgh
  - **link:** https://arxiv.org/pdf/2512.22407
  - **contributions:** 1. Explored learner perceptions of two novel Parsons problem variations (Faded Parsons and Pseudocode Parsons) as optional scaffolding in a new programming environment called Codespec. 2. Provided empirical evidence that offering these optional scaffolds supports comprehension monitoring, strategy formation, and knowledge refinement, with learners selectively using them for different purposes (syntax/structure vs. high-level reasoning). 3. Identified both benefits (e.g., desirable challenge of Faded Parsons) and costs (e.g., time, potential confusion) of using these problem types as scaffolding techniques.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd341a2988c4238f96b98f47c543fa98eabbcc1469d134da8c7bac8729ea9026_w640_q70.webp
  - **Simple LLM Summary:** This study investigates how variations of Parsons problems can scaffold learning to program. It introduces the Codespec environment, offering optional Faded Parsons and Pseudocode Parsons problems, and finds through interviews that learners selectively use these scaffolds for different cognitive tasks, supporting learning but also noting some usability costs.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Learning to Program != 'One-Size-Fits-All'") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("如何有效搭建编程学习脚手架？/How to effectively scaffold programming learning?")
        Method --> M1("开发Codespec环境/Develop Codespec environment")
        Method --> M2("提供两种Parsons问题变体作为可选脚手架/Offer two Parsons problem variants as optional scaffolds")
        Method --> M3("进行回顾性有声思维访谈/Conduct retrospective think-aloud interviews")
        Results --> R1("脚手架支持理解监控与策略形成/Scaffolds support comprehension monitoring & strategy formation")
        Results --> R2("学习者选择性使用不同变体/Learners selectively use different variants")
        Results --> R3("Faded Parsons被视为理想挑战/Faded Parsons perceived as desirable challenge")
    ```

- **[arXiv251230] Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding**
  - **tags:** [se], [human aspects of software engineering], [vibe coding, large language models, grounded theory, prompt engineering, software development practices]
  - **authors:** Yi-Hung Chou, Boyuan Jiang, Yi Wen Chen, Mingyue Weng, Victoria Jackson, Thomas Zimmermann, James A. Jones
  - **institution:** University of California, Irvine
  - **link:** https://arxiv.org/pdf/2512.22418
  - **contributions:** 1. Conducted a grounded theory study of "vibe coding" practices through analysis of 20 videos, providing empirical data on this emerging phenomenon. 2. Identified a spectrum of developer behaviors, from full reliance on AI without code inspection to active examination and adaptation of generated outputs. 3. Revealed that developers must contend with the stochastic nature of LLM generation, framing debugging as "rolling the dice," and that divergent mental models influence prompting, evaluation, and trust.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eab8ec990fa93b887bf7f5945d43ce53b02d7e23a90f66d7421522c4fb50f07c_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the emerging practice of "vibe coding," where developers build software primarily by prompting LLMs. Through a qualitative grounded theory study of 20 videos, the research reveals a spectrum of developer behaviors and the central challenge of dealing with stochastic AI outputs, described as "rolling the dice." The findings highlight how developers' mental models shape their interaction with AI and point to new research directions for the future of software engineering.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM驱动的"氛围编码"实践如何定义与进行?/How is LLM-driven "vibe coding" defined and practiced?]
        C --> C1[对20个视频进行扎根理论研究/Grounded theory study of 20 videos]
        C --> C2[分析直播与观点视频/Analyze live-streamed & opinion videos]
        D --> D1[行为谱系: 从完全依赖到检查适配/Spectrum of behaviors: from full reliance to inspection & adaptation]
        D --> D2[核心挑战: 生成的随机性/"掷骰子"/Core challenge: stochastic generation / "rolling the dice"]
        D --> D3[心智模型影响策略与信任/Mental models influence strategies & trust]
    ```

- **[arXiv251230] Relational Mediators: LLM Chatbots as Boundary Objects in Psychotherapy**
  - **tags:** [nlp], [human-ai interaction], [boundary objects, relational mediation, marginalized clients, therapeutic systems, dynamic framework]
  - **authors:** Jiatao Quan, Ziyue Li, Tian Qi Zhu, Yuxuan Li, Baoying Wang, Wanda Pratt, Nan Gao
  - **institution:** University of Washington, The Hong Kong Polytechnic University, Nankai University
  - **link:** https://arxiv.org/pdf/2512.22462
  - **contributions:** 1. Identifies enduring relational challenges in psychotherapy for marginalized clients, such as trust-building and self-disclosure burdens. 2. Proposes the Dynamic Boundary Mediation Framework, which re-conceptualizes LLMs as adaptive boundary objects. 3. Delineates three specific forms of mediation (Epistemic, Relational, Contextual) to address knowledge gaps, power asymmetries, and therapy-life discontinuities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8695c76e0392473389276989f78ab825dab06f2e38bdd785d2418d8ca9a1d80_w640_q70.webp
  - **Simple LLM Summary:** This paper argues that current framings of LLMs in mental health overlook their potential to mediate complex therapeutic relationships. Based on interviews with therapists and marginalized clients in China, the authors propose the Dynamic Boundary Mediation Framework, which positions LLM chatbots as adaptive boundary objects to bridge knowledge, power, and contextual gaps. This offers a pathway for designing AI systems that more effectively and accountably support therapeutic relationships for marginalized users.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Relational Mediators: LLM Chatbots as Boundary Objects in Psychotherapy"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["现有视角的局限/Current Framing Limitations"]
        Problem --> P2["边缘化客户的关系挑战/Relational Challenges for Marginalized Clients"]
        Method --> M1["动态边界调解框架/Dynamic Boundary Mediation Framework"]
        Method --> M2["作为边界对象的LLM/LLMs as Boundary Objects"]
        Results --> R1["三种调解形式/Three Forms of Mediation"]
        Results --> R2["关系问责的AI系统/Relationally Accountable AI Systems"]
    ```

- **[arXiv251230] SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding for Fine-Grained sEMG-Based Movement Decoding**
  - **tags:** [ai], [biomedical signal processing], [self-supervised learning, surface electromyography, rotary position encoding, spectral pre-training, movement decoding]
  - **authors:** Zihan Weng, Chanlin Yi, Pouya Bashivan, Jing Lu, Fali Li, Dezhong Yao, Jingming Hou, Yangsong Zhang, Peng Xu
  - **institution:** University of Electronic Science and Technology of China
  - **link:** https://arxiv.org/pdf/2512.22481
  - **contributions:** 1. A novel self-supervised pre-training task that uses masked prediction of clustered STFT pseudo-labels to learn robust, physiologically relevant frequency patterns from sEMG signals. 2. A novel Cylindrical Rotary Position Embedding (CyRoPE) that factorizes embeddings along temporal and annular spatial dimensions to explicitly model the cylindrical topology of forearm electrode arrays. 3. The SPECTRE framework, which integrates these contributions to establish a new state-of-the-art for fine-grained movement decoding, validated on multiple datasets including data from individuals with amputation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5801cbdcbac93bf7df15e18531c5ff2653259e25003568da5b53b240d06d32c_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces SPECTRE, a domain-specific self-supervised learning framework for decoding fine-grained movements from surface electromyography (sEMG) signals. It proposes a spectral pre-training task using masked pseudo-label prediction and a novel cylindrical rotary position encoding to model sensor topology. Evaluations show SPECTRE significantly outperforms existing supervised and generic self-supervised baselines, providing a robust foundation for practical myoelectric interfaces.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Decoding fine-grained movement from noisy, non-stationary sEMG signals for prosthetic control]
        C[主要方法/Method: Domain-specific SSL with spectral pre-training and Cylindrical Rotary Position Embedding (CyRoPE)]
        D[关键结果/Results: New SOTA performance, outperforms supervised & generic SSL baselines, validated on amputation data]
    ```

- **[arXiv251230] Clinically Calibrated Machine Learning Benchmarks for Large-Scale Multi-Disorder EEG Classification**
  - **tags:** [ai], [medical signal processing], [electroencephalography, multi-disorder classification, sensitivity-oriented modeling, clinical calibration, feature importance analysis]
  - **authors:** Argha Kamal Samanta, Deepak Mewada, Monalisa Sarma, Debasis Samanta
  - **institution:** Indian Institute of Technology, Kharagpur
  - **link:** https://arxiv.org/pdf/2512.22656
  - **contributions:** 1. Proposes a clinically calibrated, sensitivity-prioritized machine learning framework for classifying eleven diverse neurological disorders from EEG data, addressing severe class imbalance. 2. Establishes realistic performance baselines for multi-disorder EEG classification, demonstrating recall exceeding 80% for most disorders with significant gains for low-prevalence conditions after threshold calibration. 3. Provides physiologically plausible feature importance analysis that aligns with established clinical EEG markers, validating the model's clinical relevance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/636894ed25045336665fcbac593a58130411dff99c5d2a3e5a0cd50067ee44ec_w640_q70.webp
  - **Simple LLM Summary:** This study addresses the challenge of automated, multi-disorder screening from clinical EEG data by developing disorder-aware machine learning models with decision thresholds explicitly calibrated to prioritize diagnostic sensitivity. The method uses a multi-domain feature set and is evaluated on a large, heterogeneous dataset, achieving high recall for most neurological disorder categories. The results establish performance baselines and demonstrate that sensitivity-prioritized automated analysis can support scalable EEG screening and triage in clinical practice.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Clinically Calibrated Machine Learning Benchmarks for Large-Scale Multi-Disorder EEG Classification] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Manual EEG interpretation is slow and variable; existing automation lacks multi-disorder support.]
        C[主要方法/Method: Use multi-domain EEG features and train sensitivity-calibrated models under class imbalance.]
        D[关键结果/Results: High recall (>80%) for most disorders; feature importance aligns with clinical knowledge.]
    ```

- **[arXiv251230] What do you say? A pilot study investigating student responses in Data Driven Classroom Interviews**
  - **tags:** [other], [educational data mining], [Data-Driven Classroom Interviews (DDCIs), Ordered Network Analysis (ONA), rhetorical strategies]
  - **authors:** Jaclyn Ocumpaugh, Zhanlan Wei, Amanda Barany, Xiner Liu, Andres Felipe Zambrano, Ryan Baker, Camille Gioradno
  - **institution:** University of Houston, University of Pennsylvania, Adelaide University
  - **link:** https://arxiv.org/pdf/2512.22747
  - **contributions:** 1. Proposes a novel method for analyzing interview sequences using Ordered Network Analysis (ONA) to re-examine data from a prior Epistemic Network Analysis study. 2. Investigates the relationship between interviewer rhetorical strategies and student response strategies in real-time classroom interviews. 3. Provides empirical evidence on how students with different levels of situational interest respond differently to interview prompts, confirming the reliability of interviewer protocols.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87056237d276d00b024d3b9369defa22ffde3d2c95bf0eaf093a1cbb2c5720c_w640_q70.webp
  - **Simple LLM Summary:** This study investigates student responses in Data-Driven Classroom Interviews (DDCIs) by applying Ordered Network Analysis (ONA) to analyze the sequence of rhetorical strategies used by interviewers and students. It finds minor differences in responses based on student situational interest but overall confirms that interviewer-driven differences are minimal and guidelines are followed.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[What do you say? A pilot study investigating student responses in Data Driven Classroom Interviews] --> B[核心问题/Problem: How do rhetorical strategies sequence in student interviews?]
        A --> C[主要方法/Method: Use Ordered Network Analysis (ONA) to reanalyze interview data]
        A --> D[关键结果/Results: Minor response differences by interest level; interviewers follow open-ended guidelines]
    ```

- **[arXiv251230] ChatGraPhT: A Visual Conversation Interface for Multi-Path Reflection with Agentic LLM Support**
  - **tags:** [ai], [human-computer interaction], [reflective practice, agentic llm, visual conversation interface, non-linear dialogue, multi-path reflection]
  - **authors:** Geoff Kimm, Linus Tan
  - **institution:** Swinburne University of Technology
  - **link:** https://arxiv.org/pdf/2512.22790
  - **contributions:** 1. The design of a node-link, agentic LLM interface for reflective dialogue. 2. Transferable design knowledge on balancing structure and AI support to sustain reflection in complex, open-ended tasks. 3. An interactive tool that visualizes dialogue as a map, enabling branching, merging, and editing of past messages.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0a7e3705fa584edc6bed6f2a636ce9e0b4f314e3e0c63213afc64d0d876a48f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of linear LLM interfaces in supporting reflective practice by introducing ChatGraPhT, a visual tool that represents dialogue as a non-linear, editable map and provides guidance from two agentic LLM assistants. The study finds that making conversation structure visible, allowing branching/merging, and suggesting idea combinations deepens user reflective engagement.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ChatGraPhT: A Visual Conversation Interface for Multi-Path Reflection with Agentic LLM Support] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[线性对话界面限制反思/Linear interfaces limit reflection support]
        C --> C1[可视化对话地图/Visual dialogue map]
        C --> C2[支持分支与合并/Supports branching & merging]
        C --> C3[智能体LLM提供指导/Agentic LLMs provide guidance]
        D --> D1[增强用户反思参与度/Deepened user reflective engagement]
        D --> D2[提供可转移的设计知识/Provides transferable design knowledge]
    ```

- **[arXiv251230] Towards the analysis of team members well-being**
  - **tags:** [se], [software development team well-being], [well-being, software development, team members, positive feedback, prototype]
  - **authors:** Zan Xu, Sari Nurfauziyyah, Anastasia Romanova, Kaamesh G S, Yiqun Gao, Maria Spichkova
  - **institution:** RMIT University
  - **link:** https://arxiv.org/pdf/2512.22845
  - **contributions:** 1. Presents the results of a project focused on analyzing the well-being of software development team members. 2. Identifies the feeling of being appreciated and acknowledged as a critical factor for team member well-being. 3. Describes the development of a prototype tool-supported framework aimed at providing personalized positive feedback without creating significant additional workload.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44b6ecf51f08897fa2d6ed662014dae0fe49b0c593bf9e815394b288ffd9d465_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the growing concern for the well-being of software development team members, emphasizing the importance of feeling appreciated. It presents a project that developed a prototype for a tool-supported, personalized framework to provide positive feedback. The goal is to improve well-being without adding substantial extra work for team members.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Towards the analysis of team members well-being] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[软件团队成员幸福感/Software Team Member Well-being]
        B1 --> B2[关键因素：被赞赏与认可/Critical Factor: Feeling Appreciated & Acknowledged]
        C --> C1[项目分析与原型开发/Project Analysis & Prototype Development]
        D --> D1[提出工具支持的个性化框架/Proposed Tool-supported Personalized Framework]
    ```

- **[arXiv251230] Differentiable Physics-Driven Human Representation for Millimeter-Wave Based Pose Estimation**
  - **tags:** [cv], [human pose estimation], [millimeter-wave, differentiable physics, Gaussian representation, human representation, pose estimation]
  - **authors:** Shuntian Zheng, Guangming Wang, Jiaqi Li, Minzhe Ni, Yu Guan
  - **institution:** University of Warwick, University of Cambridge
  - **link:** https://arxiv.org/pdf/2512.23054
  - **contributions:** 1. Proposes a novel Differentiable Physics-driven Human Representation (DIPR) as an alternative input paradigm for mmWave-based HPE, representing humans as an ensemble of Gaussian distributions. 2. Introduces a method to incorporate kinematic priors for DIPR initialization and multi-faceted optimization to ensure biomechanical validity. 3. Designs a strategy to simulate the mmWave processing pipeline and re-render a Heatmap from DIPR for comparison, preventing overfitting to kinematic constraints and spurious noise.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ace172569ea466a63abf72680293895dbb1d21feeae095f32ec879439596ed2f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of existing Heatmap and Point Cloud input paradigms for millimeter-wave-based human pose estimation by proposing a Differentiable Physics-driven Human Representation (DIPR). DIPR uses Gaussian distributions with kinematic and electromagnetic parameters, enhanced by kinematic priors and a physics-based re-rendering strategy to mitigate noise and improve feature quality. Experiments show that existing methods can easily integrate DIPR to achieve superior performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Differentiable Physics-Driven Human Representation for Millimeter-Wave Based Pose Estimation"] --> Problem["核心问题/Problem: Limitations of Heatmap (noise) and Point Cloud (sparsity) in mmWave-based HPE"]
        Root --> Method["主要方法/Method: Proposes Differentiable Physics-driven Human Representation (DIPR) using Gaussian distributions with kinematic priors and physics simulation"]
        Root --> Results["关键结果/Results: DIPR integrates with existing methods and achieves superior performance"]
    ```

- **[arXiv251230] Reimagining the Traditional Flight Computer: E6BJA as a Modern, Multi-Platform Tool for Flight Calculations and Training**
  - **tags:** [other], [human-computer interaction], [flight computer, multi-platform software, aviation training, educational monographs, weight and balance]
  - **authors:** Jamie J. Alnasir
  - **institution:** None (Inferred from author's email domain: al-nasir.com, which appears to be a personal domain)
  - **link:** https://arxiv.org/pdf/2512.23055
  - **contributions:** 1. Development of E6BJA, a modern, multi-platform (iOS, Android, Windows, web) software flight computer that replicates and extends traditional flight calculations. 2. Integration of enhanced modeling capabilities (e.g., 1976 International Standard Atmosphere, carburetor icing risk) and aircraft-specific calculators with embedded educational explanations. 3. A comparative analysis demonstrating the tool's improvements over traditional devices in accuracy, error reduction, discoverability, and educational value for pilot training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/728f903c57bf352d1339c863c7cb1986de9a626a56f8a15516317cf7068bcb83_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of traditional mechanical and electronic flight computers by proposing E6BJA, a modern multi-platform software tool. E6BJA replicates core flight calculations while adding enhanced models and embedded educational content. The work concludes that this approach represents a meaningful evolution in pilot tools, improving safety, intuition, and instructional value in aviation training contexts.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Reimagining the Traditional Flight Computer") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("传统飞行计算机的局限性/Limitations of Traditional Flight Computers")
        Method --> M1("开发多平台软件E6BJA/Develop Multi-Platform Software E6BJA")
        Method --> M2("扩展计算与教育功能/Extend Calculations & Educational Features")
        Results --> R1("证明在准确性等方面的改进/Demonstrate Improvements in Accuracy, etc.")
        Results --> R2("支持更安全的飞行规划/Support Safer Flight Planning")
    ```

- **[arXiv251230] Multimodal Functional Maximum Correlation for Emotion Recognition**
  - **tags:** [ai], [multimodal learning], [self-supervised learning, dual total correlation, functional maximum correlation analysis, affective computing, physiological signals]
  - **authors:** Deyang Zheng, Tianyi Zhang, Wenming Zheng, Shujian Yu
  - **institution:** Southeast University, Westlake University, Vrije Universiteit Amsterdam
  - **link:** https://arxiv.org/pdf/2512.23076
  - **code:** https://github.com/DY9910/MFMC
  - **contributions:** 1. Proposes a novel self-supervised learning framework (MFMC) that maximizes higher-order multimodal dependence using a Dual Total Correlation objective. 2. Derives a tight sandwich bound and optimizes it using a functional maximum correlation analysis-based trace surrogate to capture joint interactions. 3. Demonstrates state-of-the-art or competitive performance on affective computing benchmarks, showing robustness to inter-subject variability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/369b23e1c7a17085940402e88d2347afb3386819a237c48ac347be73127aea2a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of learning joint dynamics from scarce and subjective emotion labels by proposing a self-supervised learning framework called MFMC. It captures higher-order multimodal dependencies beyond pairwise alignment, leading to improved emotion recognition performance on physiological signal benchmarks. The results show significant accuracy gains, particularly in subject-independent settings, highlighting the method's effectiveness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MFMC for Emotion Recognition] --> B[核心问题/Problem: 情感状态表现为跨系统的协调但异质的生理反应，现有自监督方法难以捕捉多模态高阶交互。]
        A --> C[主要方法/Method: 提出MFMC框架，通过Dual Total Correlation目标和Functional Maximum Correlation Analysis最大化高阶多模态依赖性。]
        A --> D[关键结果/Results: 在多个基准测试中达到SOTA或竞争性性能，显著提升CEAP-360VR数据集上的准确率，对主体间变异性鲁棒。]
    ```

- **[arXiv251230] Cogniscope: Modeling Social Media Interactions as Digital Biomarkers for Early Detection of Cognitive Decline**
  - **tags:** [ai], [digital health / computational social science], [digital biomarkers, simulation framework, multimodal fusion, cognitive decline, social media interactions]
  - **authors:** Ananya Drishti, Mahfuza Farooque
  - **institution:** Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2512.23093
  - **contributions:** 1) A configurable simulation framework (Cogniscope) that generates social-media-style interaction data for studying digital biomarkers of cognitive health. 2) A method for modeling synthetic users with heterogeneous cognitive trajectories and embedding micro-tasks (e.g., video summarization, Q&A) into content streams to produce linguistic and behavioral signals. 3) The release of open-source tools, including generator code and synthetic datasets, to provide a controllable, ethically safe testbed for systematic investigation and benchmarking.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/512eb1289cb5884089bd596bddf1510fefedfecb88019690b90dd2e6b6c77243_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces Cogniscope, a simulation framework that generates synthetic social media interaction data to model digital biomarkers for early detection of cognitive decline. It fuses linguistic and behavioral signals from simulated user interactions to evaluate early detection models. The framework is released as an open-source tool to provide a benchmark for studying multimodal cognitive markers.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cogniscope: Modeling Social Media Interactions as Digital Biomarkers] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统诊断工具成本高、侵入性强/Traditional diagnostic tools are invasive and costly]
        B --> B2[需要大规模、生态有效的认知监测/Need for population-scale, ecologically valid monitoring]
        C --> C1[模拟生成社交媒体交互数据/Simulate social-media-style interaction data]
        C --> C2[嵌入微任务并提取多模态特征/Embed micro-tasks and extract multimodal features]
        C --> C3[构建可控的合成用户测试平台/Build a controllable synthetic user testbed]
        D --> D1[展示了检测性能的敏感性分析/Demonstrates sensitivity analysis of detection performance]
        D --> D2[发布代码与数据集以支持可复现性/Releases code and datasets for reproducibility]
        D --> D3[为社区提供基准资源/Provides a benchmark resource for the community]
    ```

- **[arXiv251230] ReHome Earth: A VR-Based Concept Validation for AI-Driven Space Homesickness Interventions**
  - **tags:** [other], [human-computer interaction], [virtual reality, AI-generated content, emotional support, extreme isolation, concept validation]
  - **authors:** Mengyao Guo, Kexin Nie, Jinda Han, Guanyou Li, Adrian Wong
  - **institution:** Harbin Institute of Technology, Shenzhen; The University of Sydney; University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2512.23118
  - **contributions:** 1) A technically feasible future-oriented installation concept integrating transparent OLED displays with spaceship windows for real-time Earth connectivity. 2) A functional VR prototype for simulating astronaut isolation to test AI-generated content effectiveness in space HCI research. 3) Empirical insights and validated design implications (emotional pacing, explainable biophysical feedback, collective affective infrastructure) for AI-driven emotional support systems in extreme isolation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/994a1c291c0ccdd72311f02214224ba7a2666234ccc35cb8193843b103cbd5ae_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses astronaut homesickness by proposing ReHome Earth, a dual-component approach featuring a futuristic space installation concept and a VR prototype for testing AI-generated emotional content. Since real astronauts were unavailable, the concept was validated with 84 terrestrial participants experiencing displacement, demonstrating strong emotional resonance and yielding key design principles for affective computing in isolated environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ReHome Earth: A VR-Based Concept Validation for AI-Driven Space Homesickness Interventions] --> B[核心问题/Problem: Emotional needs of astronauts on long-duration missions are underexplored.]
        A --> C[主要方法/Method: Dual-component design: 1) Future installation concept with transparent OLED displays. 2) Functional VR prototype for testing AI content.]
        A --> D[关键结果/Results: Strong emotional resonance validated with proxy participants. Three design implications identified.]
    ```

- **[arXiv251230] It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents**
  - **tags:** [sec], [prompt injection], [prompt injection, web agents, social-engineering, benchmark, autonomous agents]
  - **authors:** Karolina Korgul, Yushi Yang, Arkadiusz Drohomirecki, Piotr Błaszczyk, Will Howard, Lukas Aichberger, Chris Russell, Philip H.S. Torr, Adam Mahdi, Adel Bibi
  - **institution:** University of Oxford, SoftServe, Johannes Kepler University Linz
  - **link:** https://arxiv.org/pdf/2512.23128
  - **contributions:** 1. Introduces the Task-Redirecting Agent Persuasion Benchmark (TRAP) for evaluating prompt injection vulnerabilities in web-based LLM agents. 2. Provides a modular social-engineering injection framework for controlled experiments on high-fidelity website clones. 3. Demonstrates systemic vulnerabilities, showing agents are susceptible to injection in 25% of tasks on average, with small interface changes often doubling success rates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c246d5b23e99374a1d754ec870b203d23f214abac92f8d20d849cc98d00e86ca_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the vulnerability of web-based LLM agents to prompt injection attacks, where hidden adversarial instructions can divert agents from their tasks. It introduces the TRAP benchmark, built on realistic website clones, to evaluate these vulnerabilities. The study finds significant susceptibility across models, revealing systemic, psychologically driven weaknesses in current agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Web agents vulnerable to prompt injection attacks] --> Problem_Detail[问题详情/Problem Detail: Adversarial instructions in web content can divert agents from original tasks]
        Method[主要方法/Method: Introduce TRAP benchmark & modular injection framework] --> Method_Detail[方法详情/Method Detail: Evaluation on high-fidelity website clones using social-engineering techniques]
        Results[关键结果/Results: Agents susceptible in 25% of tasks on average] --> Results_Detail[结果详情/Results Detail: Small interface changes can double success rates, revealing systemic vulnerabilities]
    ```

- **[arXiv251230] Understanding EFL Learners' Code-Switching and Teachers' Pedagogical Approaches in LLM-Supported Speaking Practice**
  - **tags:** [nlp], [language education], [code-switching, large language models, pedagogical design, bilingual tutoring, scaffolding]
  - **authors:** Junyeong Park, Jieun Han, Yeon Su Park, Youngbin Lee, Suin Kim, Juho Kim, Alice Oh, So-Yeon Ahn
  - **institution:** KAIST, Elice Inc.
  - **link:** https://arxiv.org/pdf/2512.23136
  - **contributions:** 1. Conducted a six-week empirical study with 20 Korean EFL learners to understand their code-switching behaviors in LLM-mediated speaking practice. 2. Performed a qualitative study with nine English teachers to analyze and refine pedagogical strategies for responding to learner code-switching. 3. Derived design implications for bilingual LLM-powered tutors that leverage teacher expertise to transform code-switching into learning opportunities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98df50b7ead70be4f32b9ae0c16ed0921a98d1c0003ee904a7fa9763956c75ae_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how EFL learners use code-switching and how teachers can pedagogically respond within LLM-supported speaking practice. Through a six-week study with learners and a qualitative study with teachers, it finds learners use CSW for lexical, cultural, and emotional expression, prompting teachers to use selective and dynamic strategies. The work concludes with design implications for creating bilingual LLM tutors that effectively scaffold learning from code-switching.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Understanding EFL Learners' Code-Switching and Teachers' Pedagogical Approaches in LLM-Supported Speaking Practice] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[EFL学习者口语练习中代码转换(CSW)的教学设计不足/Underexplored pedagogical design for CSW in EFL speaking practice]
        C --> C1[对20名韩国EFL学习者进行为期六周的LLM中介口语实践研究/Six-week LLM-mediated speaking study with 20 Korean EFL learners]
        C --> C2[对9名英语教师进行定性研究，设计对CSW的回应/Qualitative study with 9 teachers designing responses to CSW]
        D --> D1[学习者使用CSW表达词汇、文化和情感细微差别/Learners use CSW for lexical, cultural, emotional nuance]
        D --> D2[教师采用选择性干预和动态支架策略/Teachers employ selective interventions & dynamic scaffolding]
        D --> D3[提出双语LLM导师的设计启示/Design implications for bilingual LLM-powered tutors]
    ```

- **[arXiv251230] A Design Space for Intelligent Agents in Mixed-Initiative Visual Analytics**
  - **tags:** [mlsys], [agent system], [mixed-initiative visual analytics, intelligent agents, design space, multi-agents, human-AI collaboration]
  - **authors:** Tobias Stähle, Matthijs Jansen op de Haar, Sophia Boyer, Rita Sevastjanova, Arpit Narechania, Mennatallah El-Assady
  - **institution:** ETH Zürich, The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.23372
  - **contributions:** 1. Conducted a systematic review of 90 mixed-initiative visual analytics systems and 207 unique agents. 2. Proposed a novel design space for intelligent agents characterized by six dimensions (Configuration and Logic, World Model, Observations, Communication, Actions, Infrastructure). 3. Provided a framework for researchers and designers to explore design choices and situate new systems within the existing landscape.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d494dd1a9aa6a9f007780b691ff276d02fbb3b9060ca4a9fe9bf8ae5bb1fd9d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of overarching design principles for intelligent agents in mixed-initiative visual analytics systems. Through a systematic review, the authors propose a six-dimensional design space that characterizes an agent's perception, understanding, action, and communication capabilities. They conclude by offering a framework for future system design and identifying research opportunities.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[A Design Space for Intelligent Agents in Mixed-Initiative Visual Analytics] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[缺乏智能代理的总体设计原则/Lack of overarching design principles for intelligent agents]
        Method[主要方法/Method] --> M1[对90个系统进行系统综述/Systematic review of 90 systems]
        Method --> M2[提出六维设计空间/Propose a six-dimensional design space]
        Results[关键结果/Results] --> R1[用于探索设计选择的框架/Framework for exploring design choices]
        Results --> R2[定位现有系统的景观/Situate systems in current landscape]
    ```

- **[arXiv251230] Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?**
  - **tags:** [sec], [AI Security], [AI supply chain, security taxonomy, distilBERT classifier]
  - **authors:** Anh Nguyen, Triet Huynh Minh Le, M. Ali Babar
  - **institution:** University of Adelaide
  - **link:** https://arxiv.org/pdf/2512.23385
  - **contributions:** 1. Developed a pipeline combining keyword matching with a fine-tuned distilBERT classifier to identify 312,868 security discussions from Hugging Face and GitHub. 2. Conducted a thematic analysis to create a fine-grained taxonomy of 32 security issues and 24 solutions across four themes (System/Software, External Tools/Ecosystem, Model, Data). 3. Provided empirical insights revealing that security issues stem from complex dependencies and black-box AI components, with Model and Data challenges often lacking concrete solutions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates security issues in the AI supply chain by analyzing developer discussions from Hugging Face and GitHub. The authors use a keyword and classifier pipeline to build a large dataset and perform a thematic analysis to create a taxonomy of issues and solutions. They conclude that many security problems arise from dependencies and the black-box nature of AI, with solutions for Model and Data issues being particularly scarce.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Securing the AI Supply Chain] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[AI供应链安全格局复杂/Complex AI supply chain security landscape]
        Problem --> P2[缺乏对常见问题与解决方案的了解/Lack of knowledge on common issues & solutions]
        Method[主要方法/Method] --> M1[实证调查/Empirical investigation]
        M1 --> M1_1[数据源: Hugging Face, GitHub/Data Sources: Hugging Face, GitHub]
        M1 --> M1_2[构建分类管道/Build classification pipeline]
        M1_2 --> M1_2_1[关键词匹配+微调distilBERT/Keyword matching + fine-tuned distilBERT]
        Results[关键结果/Results] --> R1[数据集: 312,868个安全讨论/Dataset: 312,868 security discussions]
        Results --> R2[分类法: 32个问题, 24个解决方案/Taxonomy: 32 issues, 24 solutions]
        Results --> R3[洞察: 依赖复杂性和黑盒性导致问题/Insight: Issues from dependencies & black-box nature]
    ```

- **[arXiv251230] Soft Robotic Technological Probe for Speculative Fashion Futures**
  - **tags:** [other], [human-robot interaction], [soft robotics, wearable technology, speculative design, pneumatic actuation, technological probe]
  - **authors:** Amy Ingold, Loong Yi Lee, Richard Suphapol Diteesawat, Ajmal Roshan, Yael Zekaria, Edith-Clare Hall, Enrico Werner, Nahian Rahman, Elaine Czech, Jonathan Rossiter
  - **institution:** University of Bristol
  - **link:** https://arxiv.org/pdf/2512.23570
  - **contributions:** 1. The design and fabrication of "Sumbrella," a novel soft robotic garment integrating origami-inspired bistable units, fabric pneumatic actuators, and computer vision. 2. The use of Sumbrella as a technological probe in a focus group study to explore public interpretation, interaction, and ethical concerns regarding future soft robotic wearables. 3. The contribution of key considerations for HRI, including kinesic communication, social dynamics, and ethical guidelines, and a reflection on the value of speculative design for evaluating social acceptability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/961ff66eaf860636f7951016c0465ba6020b516e266f501287c6b78b23a9fafa_w640_q70.webp
  - **Simple LLM Summary:** This paper presents "Sumbrella," a soft robotic garment designed as a speculative fashion probe to explore the social implications of wearable robotics. Through a focus group study, the authors used the prototype to gather insights on how people imagine future interactions with such technology, revealing both expressive potential and significant ethical concerns. The work contributes design considerations and a methodological reflection on using speculative design in Human-Robot Interaction research to address social meaning alongside functionality.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Soft Robotic Technological Probe for Speculative Fashion Futures] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[新兴可穿戴机器人需兼顾功能与社会意义/Emerging wearable robotics demand design addressing function and social meaning]
        C --> C1[设计并制造Sumbrella软体机器人服装/Design and fabricate Sumbrella soft robotic garment]
        C --> C2[作为技术探针进行焦点小组研究/Use as a technological probe in a focus group study]
        D --> D1[引发对表达潜力与伦理风险的丰富讨论/Surfaced discussions on expressive potential and ethical risks]
        D --> D2[为HRI贡献设计考量与伦理指南/Contributed HRI design considerations and ethical guidelines]
        D --> D3[反思推测性设计方法的价值/Reflected on the value of speculative design]
    ```

- **[arXiv251230] Training AI Co-Scientists Using Rubric Rewards**
  - **tags:** [ai], [reinforcement learning], [research plan generation, self-grading, rubric rewards]
  - **authors:** Shashwat Goel, Rishi Hazra, Dulhan Jayalath, Timon Willi, Parag Jain, William F. Shen, Ilias Leontiadis, Francesco Barbieri, Yoram Bachrach, Jonas Geiping, Chenxi Whitehouse
  - **institution:** Meta Superintelligence Labs, ELLIS Institute Tübingen, Max Planck Institute for Intelligent Systems, University of Oxford, University of Cambridge
  - **link:** https://arxiv.org/pdf/2512.23707
  - **contributions:** 1. A scalable method to automatically extract research goals and goal-specific grading rubrics from existing papers to build a training corpus. 2. A reinforcement learning framework with self-grading, where a frozen initial model acts as the grader using rubrics, enabling unsupervised improvement. 3. Demonstration of significant performance gains (12-22% relative improvement) and cross-domain generalization (e.g., to medical research) validated by human experts and frontier model juries.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of training language models to generate high-quality, constraint-following research plans. The proposed method uses reinforcement learning with self-grading, where rubrics automatically extracted from research papers provide reward signals. The approach shows significant improvements in plan quality and generalizes across domains like machine learning and medicine, validated by human expert preference.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Training AI Co-Scientists Using Rubric Rewards"] --> Problem["核心问题/Problem: LMs struggle to generate research plans that follow all constraints."]
        Root --> Method["主要方法/Method: RL with self-grading using automatically extracted rubrics."]
        Root --> Results["关键结果/Results: Human experts prefer finetuned model's plans; method generalizes across domains."]
    ```

## 2026-01-01

- **[arXiv260101] Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms**
  - **tags:** [nlp], [bias detection], [SHAP, transformer, interpretability, false positives, domain adaptation]
  - **authors:** Himel Ghosh
  - **institution:** Technical University of Munich, Sapienza University of Rome
  - **link:** https://arxiv.org/pdf/2512.23835
  - **contributions:** 1. Conducted a comparative interpretability study of two transformer-based bias detection models using SHAP to analyze their decision mechanisms. 2. Revealed that a standard bias detector model exhibits a misalignment between attribution strength and prediction correctness, leading to systematic over-flagging, while a domain-adapted model produces significantly fewer false positives. 3. Demonstrated that model errors, particularly false positives, arise from discourse-level ambiguity rather than explicit bias cues, highlighting distinct linguistic failure modes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cbe893cabdbb4c14e3f0b2a14a91011067d2ee0ee4225b0a232eb5591a1b743_w640_q70.webp
  - **Simple LLM Summary:** This paper compares how two transformer models detect bias in news text using SHAP-based explanations. It finds that while both models focus on similar evaluative language, a domain-adapted model integrates these signals more reliably, producing far fewer false positives than a standard bias detector. The study concludes that interpretability analysis is crucial for evaluating bias detection systems and that architectural choices critically impact their reliability for journalistic use.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Explaining News Bias Detection] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[How do bias detection models make decisions?]
        C --> C1[Comparative SHAP analysis of two transformer models]
        D --> D1[Domain-adapted model has better alignment and fewer false positives]
        D --> D2[False positives driven by discourse ambiguity]
    ```

- **[arXiv260101] From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering**
  - **tags:** [se], [Human-AI Collaboration], [AI Agent Evaluation, Behavioral Taxonomy, Context-Adaptive Behavior Framework]
  - **authors:** Tao Dong, Harini Sampath, Ja Young Lee, Sherry Y. Shi, Andrew Macvean
  - **institution:** Google LLC
  - **link:** https://arxiv.org/pdf/2512.23844
  - **contributions:** 1. A foundational taxonomy of desirable AI agent behaviors for enterprise software engineering, derived from an analysis of 91 sets of user-defined agent rules. 2. The Context-Adaptive Behavior (CAB) Framework, which models how behavioral expectations shift based on context. 3. An empirical derivation of two key axes (Time Horizon and Type of Work) that drive behavioral expectation shifts in the CAB Framework.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7ee9d0c9d0b72de4dc6af2921706818c987d2f7c644977698965be6b535d20c_w640_q70.webp
  - **Simple LLM Summary:** This paper argues that current AI evaluation benchmarks focus too narrowly on code correctness and fail to assess the collaborative behaviors needed for AI to be an effective partner in software engineering. To address this, the authors propose a taxonomy of desirable agent behaviors and a Context-Adaptive Behavior (CAB) Framework that models how these expectations change with context. These contributions provide a human-centered foundation for evaluating and designing collaborative AI agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering<br/>从正确性到协作：评估软件工程中AI智能体行为的人本框架"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["核心问题/Problem<br/>Current benchmarks fail to capture collaborative AI agent behavior.<br/>当前基准测试无法评估AI智能体的协作行为。"]
        Method["主要方法/Method<br/>1. Taxonomy of agent behaviors.<br/>智能体行为分类法。<br/>2. Context-Adaptive Behavior (CAB) Framework.<br/>上下文自适应行为框架。"]
        Results["关键结果/Results<br/>Provides a human-centered foundation for evaluating collaborative AI agents.<br/>为评估协作型AI智能体提供了人本基础。"]
    ```

- **[arXiv260101] Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis**
  - **tags:** [nlp], [conversational ai], [mental health crisis, stages of change model, human-AI interaction, testimonial survey, expert interviews]
  - **authors:** Leah Hope Ajmani, Arka Ghosh, Benjamin Kaveladze, Eugenia Kim, Keertana Namuduri, Theresa Nguyen, Ebele Okoli, Jessica Schleider, Denae Ford, Jina Suh
  - **institution:** University of Minnesota, Northwestern University, Dartmouth College, Microsoft, Microsoft Research, Mental Health America
  - **link:** https://arxiv.org/pdf/2512.23859
  - **contributions:** 1. Provides first-person experiential data on using conversational AI during mental health crises via a testimonial survey (n=53). 2. Contrasts user experiences with mental health expert perspectives (n=16) to highlight the essential role of human connection in crisis management. 3. Proposes a responsible design framework for AI crisis intervention, positioning AI as a bridge to human support using the stages of change model.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/557b0c2624da79d40758f334c7d781c4558951ee96a27d54b04a81b3f20ec2ea_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how people use conversational AI (e.g., ChatGPT) during mental health crises through a survey and expert interviews. It finds users turn to AI due to gaps in human support, but experts emphasize human connection is crucial. The study concludes that responsible AI should act as a bridge to human help, increasing preparedness for positive action and de-escalating crises.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis] --> B(核心问题/Problem: Can conversational AI responsibly support mental health crises?)
        A --> C(主要方法/Method: Testimonial survey (n=53) & expert interviews (n=16))
        A --> D(关键结果/Results: AI fills gaps in human support; Human connection is essential; Design AI as a bridge to human help)
    ```

- **[arXiv260101] Deletion Considered Harmful**
  - **tags:** [other], [Personal Information Management], [deletion, filing, retrieval success, user behaviour, knowledge workers]
  - **authors:** Paul Englefield, Russell Beale
  - **institution:** University of Birmingham
  - **link:** https://arxiv.org/pdf/2512.23907
  - **contributions:** 1. An empirical study revealing that deletion is consistently under-adopted compared to other Personal Information Management (PIM) tactics like Filing, Coverage, Ontology, and Timeliness. 2. Statistical evidence demonstrating that the practice of deletion is detrimental to retrieval success and user satisfaction, challenging the intuitive belief that decluttering is beneficial. 3. A detailed analysis and clustering of user behaviors that provides insights into the relationship between deletion and other information management strategies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/344b922727ad08c44db409e5d258a91eb23a5dd268f6314fc4a64df943271db6_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the effectiveness of deletion as a Personal Information Management (PIM) tactic through a study of 51 knowledge workers using questionnaires and interviews. The study finds that deletion is less commonly used than other tactics and, contrary to common belief, empirical data shows it harms retrieval success and satisfaction. The authors conclude that deletion has adverse effects on information management outcomes.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deletion Considered Harmful] --> B[核心问题/Problem: Is deletion helpful for managing information overload?]
        A --> C[主要方法/Method: Study of 51 knowledge workers via questionnaires & interviews]
        A --> D[关键结果/Results: Deletion is under-adopted and detrimental to retrieval]
    ```

- **[arXiv260101] Evaluation of Impression Difference of a Domestic Mobile Manipulator with Autonomous and/or Remote Control in Fetch-and-Carry Tasks**
  - **tags:** [ai], [human-robot interaction], [autonomous remote control, user-robot-operator triad, mobile manipulation, affinity, fetch-and-carry]
  - **authors:** Takashi Yamamoto, Hiroaki Yaguchi, Shohei Kato, Hiroyuki Okada
  - **institution:** Toyota Motor Corporation, Nagoya Institute of Technology, Tamagawa University, Kushinada Tech. Co., Ltd.
  - **link:** https://arxiv.org/pdf/2512.24029
  - **contributions:** 1. Formalized the dual-agency structure of a service robot as a User-Robot-Operator triad in an autonomous remote-control setting. 2. Developed and evaluated an early-stage prototype interface combining natural-language text chat with freehand sketch annotations over a robot's live camera view for remote intervention. 3. Provided empirical evidence from controlled experiments showing systematic, mode-dependent differences in user-rated affinity (autonomous &gt; hybrid &gt; remote) and perceived security.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dd22c33e4c17332f65c8a5900aaa77e84ca89593caec86ae9813719341843f2_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how different control modes (autonomous, remote, hybrid) of a domestic mobile manipulator affect user impressions in fetch-and-carry tasks. The authors formalize the robot's dual agency and evaluate a prototype interface for remote intervention. The results show that user affinity is highest for autonomous mode, followed by hybrid and then remote control, offering guidance for designing human-in-the-loop mobile manipulation.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Evaluation of Impression Difference of a Domestic Mobile Manipulator") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("用户对自主/遥控/混合模式机器人的印象差异/User impression differences across robot control modes")
        Method --> M1("形式化用户-机器人-操作员三元组/Formalize User-Robot-Operator triad")
        Method --> M2("开发文本聊天+草图标注远程干预原型/Develop text chat + sketch annotation prototype")
        Method --> M3("在WRS测试场进行受控实验/Conduct controlled experiments on WRS test field")
        Results --> R1("亲和力评级: 自主 > 混合 > 遥控/Affinity rating: Autonomous > Hybrid > Remote")
        Results --> R2("感知安全性存在模式差异/Perceived security differs by mode")
    ```

- **[arXiv260101] External Human-Machine Interface based on Intent Recognition: Framework Design and Experimental Validation**
  - **tags:** [cv], [human-vehicle interaction], [external human-machine interface, intent recognition, virtual reality, adaptive interaction, pedestrian crossing]
  - **authors:** Boya Sun, Haotian Shi, Ying Ni, Shaocheng Jia, Haoyang Liang
  - **institution:** Tongji University, National University of Singapore
  - **link:** https://arxiv.org/pdf/2512.24166
  - **contributions:** 1. Proposes IR-eHMI, an adaptive external human-machine interface framework that dynamically recognizes pedestrian and AV intent to improve interaction. 2. Introduces a mechanism to identify cooperation states between AVs and pedestrians for real-time intent inference. 3. Validates the framework using a VR experimental platform, showing significant improvements in crossing efficiency and reduced gaze distraction compared to traditional fixed eHMIs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a5c67d9a5913ccbcc68501e3dadf9e83996015c48d390f03d584b668ea07ea8_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes IR-eHMI, an adaptive external interface for autonomous vehicles that recognizes pedestrian intent to improve interaction. The framework dynamically infers cooperation states and adjusts communication cues. Experimental validation in VR shows it enhances crossing efficiency and reduces distraction while maintaining safety.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("External Human-Machine Interface based on Intent Recognition: Framework Design and Experimental Validation") --> Problem("核心问题/Problem: Ineffective AV-pedestrian interaction leads to safety risks and inefficiency")
        Root --> Method("主要方法/Method: Propose IR-eHMI, an adaptive interface using intent recognition and cooperation state detection")
        Root --> Results("关键结果/Results: Improves crossing efficiency, reduces gaze distraction, maintains safety")
    ```

- **[arXiv260101] A Framing and Analysis of Applicative Tangible Interfaces**
  - **tags:** [other], [Human-Computer Interaction (HCI)], [tangible user interfaces, tangible components, interaction model, taxonomy, roles]
  - **authors:** Guillaume Riviere
  - **institution:** Univ. Bordeaux, ESTIA Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.24237
  - **contributions:** 1. Proposes a new interaction model for applicative tangible user interfaces based on four distinct component roles. 2. Successfully classifies 159 physical items from 35 representative applications into the proposed four-role framework. 3. Identifies three main future research paths to realize the commercial potential of tangible interfaces, aligning with historical phases of the field.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b4a0690743a298ebd026c9ac78b0d5d8de9878f07808bbf252b930b5fb1e309_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a component-based analysis for applicative tangible user interfaces (TUIs), introducing a new interaction model with four roles to categorize physical items. The model is validated by classifying items from 35 applications, and the analysis identifies key future research directions to advance the field towards commercialization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Framing and Analysis of Applicative Tangible Interfaces] --> B[核心问题/Problem: TUI领域成熟，需探索商业化潜力/TUI field is mature, need to explore commercial potential]
        A --> C[主要方法/Method: 提出基于四角色的交互模型和组件化分析/Propose a four-role interaction model and component-based analysis]
        A --> D[关键结果/Results: 成功分类159个物品，识别未来三大研究方向/Successfully classified 159 items, identified three main future research paths]
    ```

- **[arXiv260101] Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service**
  - **tags:** [mlsys], [agent system], [prompt injection attack, customer-service agents, cross-domain benchmark, uncertainty reporting]
  - **authors:** Jingyu Zhang
  - **institution:** University of Washington
  - **link:** https://arxiv.org/pdf/2512.24415
  - **contributions:** 1. Introduced a cross-domain benchmark for evaluating profit-seeking direct prompt injection attacks against customer-service LLM agents, spanning 10 service domains and 100 realistic attack scripts. 2. Conducted a systematic evaluation across five widely used models, revealing that attack success is highly dependent on both the service domain and the specific attack technique used. 3. Released data and evaluation code to support reproducible auditing and to inform the design of oversight and recovery workflows for more trustworthy agent interfaces.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6779572a24da1e0c74a9dfbfb9709e2eded3ecfb7b6ce939ef10467a1fe6647f_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how customer-service LLM agents can be exploited through direct prompt injection attacks to obtain unauthorized concessions. The authors propose a cross-domain benchmark to evaluate these attacks and find that their success varies significantly by domain and technique, with airline support being most vulnerable. The study concludes by releasing resources to help audit and build more robust, human-centered agent systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Language Model Agents Under Attack<br>语言模型智能体攻击研究"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Customer-service LLM agents can be exploited for unauthorized profit<br>客服LLM智能体可能被利用谋取不当利益"]
        Method["主要方法/Method<br>Cross-domain benchmark of direct prompt injection attacks<br>跨领域直接提示注入攻击基准"]
        Results["关键结果/Results<br>Attacks are domain & technique dependent; Airline support most exploitable<br>攻击效果因领域和技术而异；航空客服最易受攻击"]
    ```

- **[arXiv260101] IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback**
  - **tags:** [nlp], [automated essay scoring], [DistilBERT, regression head, Design-Based Research (DBR), adaptive feedback, transformer model]
  - **authors:** Titas Ramancauskas, Kotryna Ramancauske
  - **institution:** (Institution not explicitly stated in provided content; inferred from author names as potentially independent researchers)
  - **link:** https://arxiv.org/pdf/2512.24460
  - **contributions:** 1. Development of an IELTS writing revision platform with a dedicated UI that separates conversational guidance from the writing interface to reduce cognitive load. 2. Implementation of an Automated Essay Scoring (AES) system using a DistilBERT transformer model with a regression head, achieving improved scoring accuracy (MAE 0.66, positive R²) over rule-based methods. 3. Design and evaluation of adaptive feedback tailored to the IELTS rubric, which demonstrated statistically significant score improvements (mean +0.060 bands) and identified conservative surface-level corrections as more reliable than aggressive structural interventions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cd49db97d083a1a08542b5c9894656f76ab161b46611cfa6c1b0426b21442e9_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of personalized feedback in IELTS writing preparation by developing a revision platform featuring an Automated Essay Scoring system and adaptive feedback. The core method involves iterative Design-Based Research, transitioning from rule-based scoring to a more accurate DistilBERT transformer model with a regression head. The main conclusion is that such automated feedback is best used as a supplement to human instruction, with surface-level corrections proving more effective for IELTS contexts than deep structural interventions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统方法缺乏个性化反馈/Traditional methods lack personalized feedback]
        C --> C1[基于设计的研究迭代/Iterative Design-Based Research (DBR)]
        C1 --> C2[从规则到Transformer/From rule-based to transformer-based (DistilBERT)]
        C2 --> C3[带回归头的评分模型/Scoring model with regression head]
        C --> C4[自适应反馈系统/Adaptive feedback system]
        D --> D1[评分准确率提升/Improved scoring accuracy (MAE 0.66, positive R²)]
        D --> D2[分数显著提高/Statistically significant score improvement (mean +0.060 bands)]
        D --> D3[结论: 自动化反馈是人工教学的补充/Conclusion: Automated feedback is a supplement to human instruction]
    ```

- **[arXiv260101] ReflecToMeet: An AI-Assisted Reflection Based System to Enhance Collaborative Preparedness**
  - **tags:** [other], [human-computer interaction], [AI-assisted interface, reflective prompting, collaborative preparedness, structured reflection, mixed-method study]
  - **authors:** Md Nazmus Sakib, Naga Manogna Rayasam, Ishika Tarin, Sanorita Dey
  - **institution:** University of Maryland, Baltimore County
  - **link:** https://arxiv.org/pdf/2512.24632
  - **contributions:** 1. The design and development of ReflecToMeet, an AI-assisted system that integrates theory-driven reflective prompts with a mechanism for sharing teammates' reflections to enhance collaborative preparedness. 2. The execution of a formative interview study and a five-day mixed-method user study comparing three reflection conditions (deeper, regular, control) to evaluate the system's impact. 3. The identification of key findings that structured reflection improves organization and progress, while deeper reflection boosts confidence and teamwork at the cost of higher cognitive load, leading to design implications for AI agents in collaborative settings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7da9ba42bc2107a047b7b9218f6722321d70aa36bc6752ceb5bb9701a0247d1_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of task drift and reduced preparedness between collaborative meetings. It proposes ReflecToMeet, an AI-assisted system that uses structured reflective prompts and shared reflections. The study found that structured reflection improves team organization and progress, with deeper reflection further enhancing confidence and idea generation, albeit with increased cognitive load.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ReflecToMeet: An AI-Assisted Reflection Based System to Enhance Collaborative Preparedness] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[任务漂移与准备不足/Task Drift & Reduced Preparedness]
        C --> C1[AI辅助反思系统/AI-Assisted Reflection System]
        C --> C2[结构化反思提示/Structured Reflective Prompts]
        C --> C3[共享队友反思/Sharing Teammates' Reflections]
        D --> D1[结构化反思改善组织与进度/Structured Reflection Improves Organization & Progress]
        D --> D2[深度反思提升信心与团队合作/Deeper Reflection Boosts Confidence & Teamwork]
        D --> D3[深度反思增加认知负荷/Deeper Reflection Increases Cognitive Load]
    ```

- **[arXiv260101] Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences**
  - **tags:** [ai], [human-robot interaction], [object rearrangement, human preference modeling, Monte Carlo Tree Search, psychological constructs, user study]
  - **authors:** Emmanuel Fashae, Michael Burke, Leimin Tian, Lingheng Meng, Pamela Carreno-Medrano
  - **institution:** Monash University, CSIRO Robotics
  - **link:** https://arxiv.org/pdf/2512.24829
  - **contributions:** 1. Proposes a novel, interpretable formulation of human object arrangement preferences based on four psychological constructs (spatial practicality, habitual convenience, semantic coherence, commonsense appropriateness). 2. Designs and validates a self-report questionnaire to capture these constructs through a 63-participant online study. 3. Demonstrates the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner to generate arrangements that align with human preferences.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0c9201484194f4f746f05eae7a288356c0e53c3a3a9d4683db5313924455a5a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of interpretability in robotic object rearrangement models by identifying four explicit psychological constructs that guide human organizational preferences. The authors designed a questionnaire to measure these constructs and integrated them into a Monte Carlo Tree Search planner. The results show that the planner, guided by these interpretable preferences, can generate arrangements closely matching those created by human participants.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Explaining Why Things Go Where They Go<br>解释物品为何归位] --> B(Problem: 机器人重排模型缺乏可解释性<br>Problem: Robotic rearrangement models lack interpretability)
        A --> C(Method: 提出四个可解释偏好构念与问卷<br>Method: Four interpretable preference constructs & questionnaire)
        A --> D(Results: 基于MCTS的规划器能生成符合人类偏好的布局<br>Results: MCTS planner generates human-aligned arrangements)
    ```

- **[arXiv260101] Vibe Coding, Interface Flattening**
  - **tags:** [se], [human-computer interaction], [large language models, interface flattening, vibe coding, Model Context Protocol, symbolic labour]
  - **authors:** Hongrui Jin
  - **institution:** University of Amsterdam
  - **link:** https://arxiv.org/pdf/2512.24939
  - **contributions:** 1. Proposes a critical framework for understanding "vibe coding" as "interface flattening," where distinct modalities converge into a conversational surface while the underlying translation chain thickens. 2. Conducts a materialist reconstruction of the vibe-coding stack, analyzing how remote compute, structured outputs, and protocols like MCP relocate control to model providers. 3. Demonstrates how LLM-mediated development redistributes symbolic power, obscures responsibility, and privatizes competencies, offering a critical lens on the political economy of AI-mediated interaction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7d80b187b5915d1a8220a2cb617bff9a959789d5181355291a3d22991715d25_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the phenomenon of "vibe coding," where software is developed through natural language interaction with LLMs. It conceptualizes this as "interface flattening," arguing that while the user experience appears simplified, the underlying infrastructure and dependencies become more complex and concentrated. The main conclusion is that this apparent democratization of programming creates new dependencies, redistributes power to model providers, and privatizes competencies previously held by the programming community.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Vibe Coding, Interface Flattening] --> B[核心问题/Problem: How to understand the shift in programming via LLMs?]
        A --> C[主要方法/Method: Critical analysis using media theory & materialist reconstruction of the stack]
        A --> D[关键结果/Results: Interface flattening obscures complexity, redistributes power, creates new dependencies]
    ```

- **[arXiv260101] ShowUI-$π$: Flow-based Generative Models as GUI Dexterous Hands**
  - **tags:** [ai], [human-computer interaction], [flow-based generative model, GUI automation, continuous trajectory prediction, unified discrete-continuous actions, ScreenDrag benchmark]
  - **authors:** Siyuan Hu, Kevin Qinghong Lin, Mike Zheng Shou
  - **institution:** Show Lab, National University of Singapore
  - **link:** https://arxiv.org/pdf/2512.24965
  - **code:** https://github.com/showlab/showui-pi
  - **contributions:** 1. Proposed ShowUI-π, the first flow-based generative model for GUI dexterous manipulation, unifying discrete clicks and continuous drags in a shared model. 2. Introduced a flow-based action generation method for drag modeling, predicting incremental cursor adjustments from continuous visual observations. 3. Created ScreenDrag, a benchmark with 20K drag trajectories across five domains and comprehensive evaluation protocols to assess GUI agents' drag capabilities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd6391f609bd9b67bc717f5e3756501bf8f4dedd5a207352ff5b4f02bc902207_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of existing GUI agents that only perform discrete clicks, lacking the ability for continuous, closed-loop drag interactions. The authors propose ShowUI-π, a flow-based generative model that unifies discrete and continuous actions and generates smooth drag trajectories from visual observations. Experiments show ShowUI-π outperforms proprietary GUI agents on the new ScreenDrag benchmark, demonstrating effective dexterous control for GUI automation.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[ShowUI-π: Flow-based Generative Models as GUI Dexterous Hands] --> B[核心问题/Problem: Existing GUI agents only support discrete clicks, lacking continuous drag capability for closed-loop trajectories]
    A --> C[主要方法/Method: Flow-based generative model with unified discrete-continuous actions and incremental trajectory prediction]
    A --> D[关键结果/Results: Outperforms proprietary agents on ScreenDrag benchmark (score 26.98), demonstrating effective dexterous control]
    ```

- **[arXiv260101] Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings**
  - **tags:** [mlsys], [agent system], [Large Language Model, Building Energy Management System, AI Agents, Human-Building Interaction, Context-aware]
  - **authors:** Tianzhi He, Farrokh Jazizadeh
  - **institution:** The University of Texas at San Antonio, Virginia Polytechnic Institute and State University
  - **link:** https://arxiv.org/pdf/2512.25055
  - **contributions:** 1. Proposes a conceptual framework for LLM-based AI agents in BEMS, featuring a closed-loop system with perception, central control, and action modules. 2. Develops and benchmarks a prototype using real-world datasets and diverse metrics (latency, functionality, accuracy, cost-effectiveness), formalizing the assessment of such agents. 3. Demonstrates the framework's performance and generalizability, identifying strengths (e.g., high accuracy in device control) and areas for improvement (e.g., complex cost estimation).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d46efc47f789043b6987c8068e21aecb4ec53b645c2c1a61c1880ed06029103b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a framework for LLM-based AI agents to manage energy in smart buildings through natural language. The agent uses a closed-loop system to analyze data and control devices, and its evaluation shows promising accuracy in tasks like device control but highlights challenges in complex cost estimation.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings"] --> Problem["核心问题/Problem: Existing BEMS lack context-aware, natural language interaction for energy management"]
        Root --> Method["主要方法/Method: Proposes a three-module LLM-based AI agent framework (perception, central control, action) for closed-loop management"]
        Root --> Results["关键结果/Results: Prototype shows high accuracy in device control (86%) and memory tasks (97%), but lower accuracy in cost estimation (49%)"]
    ```

- **[arXiv260101] Power Analysis is Essential: High-Powered Tests Suggest Minimal to No Effect of Rounded Shapes on Click-Through Rates**
  - **tags:** [other], [experimental methodology], [A/B testing, statistical power, effect size, replication, confidence intervals]
  - **authors:** Ron Kohavi, Jakub Linowski, Lukas Vermeer, Fabrice Boisseranc, Joachim Furuseth, Andrew Gelman, Guido Imbens, Ravikiran Rajagopal
  - **institution:** Columbia University, Stanford University, Kameleoon, Coop Norway, United Parks & Resorts, Linowski Interaction Design, Inc.
  - **link:** https://arxiv.org/pdf/2512.24521
  - **contributions:** 1. Conducted three high-powered A/B tests with massive sample sizes to rigorously evaluate a prior claim. 2. Demonstrated that the originally reported large effect of rounded button corners on click-through rates is likely a statistical artifact of an underpowered study. 3. Emphasized the critical importance of power analysis and experimental design for ensuring result reproducibility and trust in digital experimentation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ec6e142f87864b111174c551c26259c2ffd929885b106bd50ef48d9a1e2b9b8_w640_q70.webp
  - **Simple LLM Summary:** This paper critiques a prior study that claimed a 55% increase in click-through rates from rounding button corners, arguing the finding is implausible due to low statistical power. The authors conducted three much larger, high-powered A/B tests, finding effect sizes nearly 100 times smaller and statistically insignificant. The main conclusion is that underpowered studies exaggerate effects, highlighting the essential role of power analysis for reliable and reproducible research.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Power Analysis is Essential<br>高功率测试表明圆角形状对点击率影响甚微"]
        Root --> Problem["核心问题/Problem<br>Underpowered studies exaggerate effects<br>低统计功效研究夸大效应"]
        Root --> Method["主要方法/Method<br>Conduct high-powered A/B tests<br>进行高统计功效的A/B测试"]
        Root --> Results["关键结果/Results<br>Effect is two orders of magnitude smaller & not significant<br>效应小两个数量级且不显著"]
    ```

- **[arXiv260101] No Vision, No Wearables: 5G-based 2D Human Pose Recognition with Integrated Sensing and Communications**
  - **tags:** [sys], [wireless sensing], [Integrated Sensing and Communication (ISAC), 5G, human pose recognition (HPR), sounding reference signals (SRS), multi-domain feature fusion]
  - **authors:** Haojin Li, Dongzhe Li, Anbang Zhang, Wenqi Zhang, Chen Sun, Haijun Zhang
  - **institution:** University of Science and Technology Beijing, Sony China Research Laboratory, Shandong University
  - **link:** https://arxiv.org/pdf/2512.24923
  - **contributions:** 1. Proposes a practical 5G-based ISAC system for 2D human pose recognition using standard uplink SRS signals, eliminating the need for vision or dedicated sensing hardware. 2. Introduces a method to extract and align rich features from multiple domains into a unified latent space representation for pose inference. 3. Demonstrates through experiments that the proposed system significantly outperforms current mainstream baseline solutions (e.g., vision-based, WiFi-based, radar-based) in HPR performance in typical indoor environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9561da2eb11d118db62da20265273bb621f421eae2106c649b1696a1a1a243d6_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of current contactless human pose recognition methods (e.g., privacy, occlusion) by proposing a novel system that leverages 5G Integrated Sensing and Communication (ISAC) technology. The method infers 2D human poses from standard 5G uplink reference signals by extracting and fusing multi-domain features. Experimental results show the system outperforms existing vision and RF-based solutions, providing a foundation for universal human-computer interaction.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[No Vision, No Wearables: 5G-based 2D Human Pose Recognition] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[现有方案挑战/Challenges of Existing Solutions]
        P1 --> P1_1[隐私担忧/Privacy Concerns]
        P1 --> P1_2[易受遮挡/Susceptible to Occlusion]
        P1 --> P1_3[专用设备/Dedicated Equipment]
        Method[主要方法/Method] --> M1[5G ISAC 系统/5G ISAC System]
        M1 --> M1_1[使用上行探测参考信号/Uses Uplink SRS]
        M1 --> M1_2[多域特征提取与对齐/Multi-domain Feature Extraction & Alignment]
        M1 --> M1_3[低维特征融合/Low-dim Feature Fusion]
        Results[关键结果/Results] --> R1[显著优于主流基线/Significantly Outperforms Baselines]
        R1 --> R1_1[为普适人机交互奠基/Foundation for Universal HCI]
    ```
