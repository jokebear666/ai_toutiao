---
slug: /daily/cshc/20251229-20260104
---
# 20251229-20260104 (cs.HC)

## 2025-12-29

- **[arXiv251229] MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding**
  - **tags:** [mlsys], [multi-modal training], [wearable sensing, actigraphy encoder, projection module, frozen LLM, behavioral summarization]
  - **authors:** Aiwei Zhang, Arvind Pillai, Andrew Campbell, Nicholas C. Jacobson
  - **institution:** Dartmouth College
  - **link:** https://arxiv.org/pdf/2512.21506
  - **contributions:** 1. Introduces MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs) for free-text generation of daily behavioral summaries. 2. Constructs a novel, large-scale dataset of 54,383 (actigraphy, text) pairs derived from real-world NHANES recordings. 3. Demonstrates superior performance over prompt-based baselines in semantic fidelity and lexical accuracy, with qualitative analysis showing the model captures circadian structure and behavioral transitions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of generating natural language summaries from raw physiological signals like actigraphy. It proposes MotionTeller, a framework that integrates a pretrained actigraphy encoder with a frozen LLM via a projection module. The model, trained on a novel dataset, outperforms baselines in generating fluent, human-centered descriptions of daily behavior.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs] --> B[核心问题/Problem: How to generate natural language summaries from raw physiological signals like actigraphy?]
        A --> C[主要方法/Method: Combines a pretrained actigraphy encoder and a projection module to map behavioral embeddings into a frozen LLM's token space.]
        A --> D[关键结果/Results: Achieves high semantic fidelity (BERTScore-F1=0.924) and lexical accuracy (ROUGE-1=0.722), outperforming baselines by 7%.]
    ```

- **[arXiv251229] Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures**
  - **tags:** [other], [human-ai interaction], [bidirectional alignment, value-centered design, interactive alignment]
  - **authors:** Hua Shen, Tiffany Knearem, Divy Thakkar, Pat Pataranutaporn, Anoop Sinha, Yike, Jenny T. Liang, Lama Ahmad, Tanu Mitra, Brad A. Myers, Yang Li
  - **institution:** NYU Shanghai, MBZUAI, Google, Massachusetts Institute of Technology, Carnegie Mellon University, OpenAI, University of Washington, Google DeepMind
  - **link:** https://arxiv.org/pdf/2512.21551
  - **contributions:** 1. Proposes a shift from unidirectional to bidirectional human-AI alignment, framing it as a dynamic, reciprocal co-adaptation process. 2. Emphasizes embedding human and societal values into AI alignment research through value-centered design. 3. Aims to establish an interdisciplinary research agenda for responsible, reciprocal human-AI futures through collaborative workshop activities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp
  - **Simple LLM Summary:** This workshop paper identifies the inadequacy of traditional, one-way AI alignment and proposes a bidirectional human-AI alignment framework where humans and AI co-adapt through interaction and value-centered design. It aims to bring together interdisciplinary researchers to explore methods for interactive alignment and societal impact evaluation. The main conclusion is the need for a shared agenda to advance responsible, reciprocal collaboration between humans and AI systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Human-AI Interaction Alignment] --> B[核心问题/Problem: Unidirectional AI alignment is inadequate for dynamic human-AI interaction]
        A --> C[主要方法/Method: Bidirectional alignment via value-centered design, interaction, and evaluation]
        A --> D[关键结果/Results: Establishes agenda for reciprocal, responsible human-AI futures]
    ```

- **[arXiv251229] Bidirectional Human-AI Alignment in Education for Trustworthy Learning Environments**
  - **tags:** [ai], [ai for education], [human-ai alignment, trustworthy ai, adaptive learning, educational technology, ai ethics]
  - **authors:** Hua Shen
  - **institution:** NYU Shanghai, New York University
  - **link:** https://arxiv.org/pdf/2512.21552
  - **contributions:** 1. Proposes the novel concept of "bidirectional human-AI alignment" for education, emphasizing mutual adaptation between humans and AI systems. 2. Explores the evolution of AI's role in education from a support tool to a collaborative partner, analyzing its impact on teacher roles and student agency. 3. Provides actionable strategies for policymakers, developers, and educators to ensure AI advances equity, transparency, and human flourishing in learning environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7f40fe114da7bae34b09e44db18fa32bb4f64e57bd01e75e96afc80c2ddc136_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the risks of AI in education, such as bias and loss of autonomy, by proposing the concept of bidirectional human-AI alignment. The method involves not only embedding human values into AI but also equipping educators and students to guide these technologies. It concludes that reframing AI adoption as a process of mutual adaptation is key to creating trustworthy learning environments where humans and AI can grow together.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题: Bidirectional Human-AI Alignment in Education] --> B[核心问题/Problem: AI in education introduces risks to equity, privacy, and autonomy.]
        A --> C[主要方法/Method: Proposes bidirectional alignment: embedding human values into AI and equipping humans to interpret/guide AI.]
        A --> D[关键结果/Results: Envisions a future of mutual adaptation where AI advances equity, transparency, and human flourishing.]
    ```

- **[arXiv251229] Emotion-Aware Smart Home Automation Based on the eBICA Model**
  - **tags:** [ai], [affective computing], [eBICA, emotion-aware automation, psychological safety, STAI-S, smart home]
  - **authors:** Masaaki Yamauchi, Yiyuan Liang, Hiroko Hara, Hideyuki Shimonishi, Masayuki Murata
  - **institution:** The University of Osaka
  - **link:** https://arxiv.org/pdf/2512.21589
  - **contributions:** 1. Proposed an emotion-aware smart home automation framework guided by the eBICA model for dynamic control based on emotional state. 2. Conducted a proof-of-concept experiment demonstrating a significant reduction in state anxiety (STAI-S) through comfort-inducing automation. 3. Found that individual personality and anxiety traits modulate the relief effect, indicating a pathway for personalized emotion-adaptive systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5260e7567742ea94b88d5dab934224f8814c9ad506e334dbc2220c01eec9093d_w640_q70.webp
  - **Simple LLM Summary:** This study proposes a smart home automation framework that uses the eBICA model to adapt to a user's emotional state. A proof-of-concept experiment showed that anxiety-inducing automation significantly reduced user anxiety, demonstrating the framework's effectiveness in promoting psychological safety and its potential for personalization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Emotion-Aware Smart Home Automation Based on the eBICA Model] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统自动化缺乏情感适应<br/>Traditional automation lacks emotional adaptation]
        C --> C1[基于eBICA的框架<br/>eBICA-based framework]
        C --> C2[概念验证实验<br/>Proof-of-concept experiment]
        D --> D1[焦虑显著降低<br/>Significant anxiety reduction]
        D --> D2[个性化潜力<br/>Personalization potential]
    ```

- **[arXiv251229] Ghostcrafting AI: Under the Rug of Platform Labor**
  - **tags:** [other], [human-computer interaction], [platform labor, ghostcrafting, ethnography, ethical AI, situated learning]
  - **authors:** ATM Mizanur Rahman, Sharifa Sultana
  - **institution:** University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2512.21649
  - **contributions:** 1. Proposes the novel conceptual framework of "Ghostcrafting AI" to describe the invisible and essential labor of platform workers in building and sustaining AI systems. 2. Provides an in-depth ethnographic account of the situated learning practices and coping tactics of platform workers in Bangladesh, revealing their resourcefulness and agency. 3. Highlights the structural precarity and exploitation faced by these workers, arguing for urgent design, policy, and governance interventions to ensure fairness and recognition.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49785e109f95da7d4a140badf3830b8bc2770c67e7d5e4a226476af7aecf0903_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the hidden labor of platform workers in the Global South who build and sustain AI systems. Through an eight-month ethnography in Bangladesh, it conceptualizes this as "Ghostcrafting AI" and documents how workers learn and cope with exploitative conditions. The study concludes that AI is fundamentally dependent on this invisible labor and calls for interventions to ensure fairness and sustainability in platform work.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Ghostcrafting AI: Under the Rug of Platform Labor"]
        Root --> Problem["核心问题/Problem: Platform laborers are indispensable yet invisible in building AI systems."]
        Root --> Method["主要方法/Method: Eight-month ethnography in Bangladesh's platform labor industry."]
        Root --> Results["关键结果/Results: Reveals workers' situated learning, coping tactics, and the need for fairness interventions."]
    ```

- **[arXiv251229] Modified TSception for Analyzing Driver Drowsiness and Mental Workload from EEG**
  - **tags:** [ai], [brain-computer interface (BCI)], [EEG, TSception, Adaptive Average Pooling, spatiotemporal features, drowsiness detection]
  - **authors:** Gourav Siddhad, Anurag Singh, Rajkumar Saini, Partha Pratim Roy
  - **institution:** Indian Institute of Technology Roorkee, OP Jindal University, Luleå University of Technology, Indian Institute of Technology Dhanbad
  - **link:** https://arxiv.org/pdf/2512.21747
  - **contributions:** 1. Proposed a Modified TSception architecture with a five-layer temporal refinement strategy to capture multi-scale brain dynamics. 2. Introduced Adaptive Average Pooling for structural flexibility to handle varying EEG input dimensions and a two-stage fusion mechanism for optimized spatiotemporal feature integration. 3. Demonstrated improved performance stability (reduced confidence interval) on the SEED-VIG dataset and state-of-the-art generalizability on the STEW mental workload dataset.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43d71afc9fcee5064adfe94f1fb1d9f8a1c55ccd8d1c759dcd1b5801b9d23f46_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a Modified TSception deep learning model for robust EEG-based detection of driver drowsiness and mental workload. The key modifications include a multi-layer temporal refinement strategy and Adaptive Average Pooling, which improve the model's stability and ability to handle varying input sizes. The model achieves comparable accuracy with significantly better stability on a drowsiness dataset and state-of-the-art results on a mental workload dataset, demonstrating its effectiveness for reliable cognitive state monitoring.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Modified TSception for Analyzing Driver Drowsiness and Mental Workload from EEG] --> B(核心问题/Problem: Driver drowsiness detection for road safety)
        A --> C(主要方法/Method: Modified TSception with temporal refinement & Adaptive Average Pooling)
        A --> D(关键结果/Results: Improved stability on SEED-VIG, SOTA on STEW)
    ```

- **[arXiv251229] Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning**
  - **tags:** [nlp], [image captioning], [scientific figure captioning, large-scale dataset, domain-specific training, human evaluation, large language models (LLMs)]
  - **authors:** Ting-Hao K.Huang, Ryan A. Rossi, Sungchul Kim, Tong Yu, Ting-Yao E. Hsu, Ho Yin, C. Lee Giles
  - **institution:** The Pennsylvania State University, Adobe Research
  - **link:** https://arxiv.org/pdf/2512.21789
  - **contributions:** 1. Creation and continuous updating of a large-scale, real-world dataset of scientific figure-caption pairs from arXiv papers. 2. Conducting extensive evaluations, both automatic and human, on generated and author-written captions to assess quality. 3. Developing interactive systems and launching annual challenges to advance the field and help scientists write better captions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp
  - **Simple LLM Summary:** This paper reviews the SciCap project's first five years, which focused on generating and evaluating captions for scientific figures. The core method involved building a large-scale dataset from arXiv and exploring domain-specific training, similar to models like SciBERT, for captioning. The conclusion outlines key lessons learned and proposes future research directions to address unsolved challenges in the field.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[科学图表说明质量差/Poor quality of scientific figure captions]
        Problem --> P2[缺乏大规模真实数据集/Lack of large-scale real-world dataset]
        Method --> M1[构建arXiv图表-说明对数据集/Construct arXiv figure-caption dataset]
        Method --> M2[领域特定训练与评估/Domain-specific training & evaluation]
        Method --> M3[应对大语言模型兴起/Navigate rise of LLMs]
        Results --> R1[总结技术方法经验/Summarize technical & methodological lessons]
        Results --> R2[提出未来挑战与方向/Outline future challenges & directions]
    ```

- **[arXiv251229] Generative Lecture: Making Lecture Videos Interactive with LLMs and AI Clone Instructors**
  - **tags:** [other], [Human-Computer Interaction (HCI)], [interactive videos, personalized learning, AI clone instructor, on-demand content generation, generative AI]
  - **authors:** Hye-Young Jo, Ada Zhao, Xiaoan Liu, Ryo Suzuki
  - **institution:** University of Colorado Boulder
  - **link:** https://arxiv.org/pdf/2512.21796
  - **contributions:** 1) Introduces the "Generative Lecture" concept for transforming passive lecture videos into interactive, two-way learning experiences using AI. 2) Proposes a system architecture that integrates an AI clone instructor (via HeyGen, ElevenLabs, GPT-5) with on-demand content generation to respond to student queries. 3) Identifies and implements eight key system features (e.g., on-demand clarification, adaptive quiz) based on a design study, and validates the system's usability and effectiveness through user studies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/047a789db6b06e8758007487ecf18eb3b59ea0d4d56a243c23b590b8ad50497f_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Generative Lecture, a system that uses generative AI and AI clone instructors to make existing lecture videos interactive, allowing students to ask questions and receive personalized, generated explanations. The system was developed based on user goals and features like on-demand clarification and adaptive quizzes. User studies suggest it enables effective two-way communication and supports personalized learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Generative Lecture<br>生成式讲座") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("Lecture videos are passive<br>讲座视频是被动的")
        Method --> M1("Use AI Clone Instructor & LLMs<br>使用AI克隆讲师和LLMs")
        Method --> M2("Generate on-demand content<br>生成按需内容")
        Results --> R1("Enables two-way communication<br>实现双向交流")
        Results --> R2("Supports personalized learning<br>支持个性化学习")
    ```

- **[arXiv251229] Conserved active information**
  - **tags:** [ai], [information theory], [conserved active information, No-Free-Lunch, KL divergence, search space, information conservation]
  - **authors:** Yanchen Chen, Daniel Andrés Díaz-Pachón
  - **institution:** University of Miami
  - **link:** https://arxiv.org/pdf/2512.21834
  - **contributions:** 1. Introduces conserved active information (I⊕), a symmetric measure of net information gain/loss across a search space that respects No-Free-Lunch conservation. 2. Demonstrates that I⊕ can reveal regimes (e.g., strong knowledge reducing global disorder) that are hidden from traditional measures like KL divergence. 3. Applies the framework to resolve a longstanding critique of active information and illustrates its utility in domains like Markov chains and cosmological fine-tuning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1371f9cf2f5be050a2495fc2f2b19865fddd5c4a8834df1cd98fc2da7eea7111_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new information-theoretic measure called conserved active information (I⊕) to quantify net information change in search problems while respecting conservation laws. It shows that I⊕ uncovers scenarios, such as strong knowledge imposing order, which are missed by standard divergence measures. The work resolves a key critique of active information and enables applications in search and optimization.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Conserved active information] --> Problem[核心问题/Problem: Limitations of average-focused information measures like KL divergence]
        Root --> Method[主要方法/Method: Introduce conserved active information I⊕, a symmetric extension respecting No-Free-Lunch]
        Root --> Results[关键结果/Results: I⊕ reveals hidden regimes (e.g., strong knowledge reduces disorder), resolves critique of active information]
    ```

- **[arXiv251229] Positive Narrativity Enhances Sense of Agency toward a VR Avatar**
  - **tags:** [other], [virtual reality and embodiment], [full-body illusion, sense of agency, avatar narrativity, Proteus effect, bodily self-consciousness]
  - **authors:** Kureha Hamagashira, Miyuki Azuma, Sotaro Shimada
  - **institution:** Meiji University
  - **link:** https://arxiv.org/pdf/2512.21968
  - **contributions:** 1. Investigated the explicit manipulation of avatar impressions using narrative context (positive vs. negative stories) to modulate the full-body illusion. 2. Demonstrated that positive narratives significantly enhance the sense of agency toward a VR avatar. 3. Found a positive correlation between the sense of agency and participants' perceived personal familiarity with the avatar.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d658df90fd7ef654f1504e1b44262071ad05b5dab0737598e4b949dd3f39383_w640_q70.webp
  - **Simple LLM Summary:** This study explores how narrative context affects embodiment in VR by having participants embody an avatar after hearing either a positive or negative story about it. The results show that positive narratives significantly increase the user's sense of agency over the avatar, and this feeling is linked to how familiar the avatar feels. This suggests that storytelling can be a tool to modulate virtual embodiment experiences.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Positive Narrativity Enhances Sense of Agency toward a VR Avatar] --> B(核心问题/Problem: How does narrative context affect the full-body illusion?);
        A --> C(主要方法/Method: Participants embodied an avatar after listening to a positive or negative narrative about it.);
        A --> D(关键结果/Results: Positive narratives enhanced sense of agency, which correlated with perceived familiarity.);
    ```

- **[arXiv251229] SketchPlay: Intuitive Creation of Physically Realistic VR Content with Gesture-Driven Sketching**
  - **tags:** [other], [Human-Computer Interaction (HCI)], [Gestural Interaction, Physics Simulation, Air-drawn Sketches, VR Content Creation]
  - **authors:** Xiangwen Zhang, Xiaowei Dai, Runnan Chen, Xiaoming Chen, Zeke Zexi Hu
  - **institution:** Beijing Technology and Business University, The University of Sydney
  - **link:** https://arxiv.org/pdf/2512.22016
  - **contributions:** 1. A novel VR interaction framework (SketchPlay) that combines air-drawn sketches and gestures to create dynamic, physically realistic scenes. 2. A method that uses sketches to capture object/scene structure and gestures to convey physical cues (velocity, force) for defining motion and behavior. 3. Enables the generation of complex physical phenomena (rigid body motion, elastic deformation, cloth dynamics) through an intuitive, controller-free creation process.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79eefb65bc566df3d83196a3500892e4d09f26b4aa064a68193142a9ec59b0c0_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes SketchPlay, a VR framework that allows users to create physically realistic dynamic scenes by sketching objects in the air and using gestures to define their motion. This method combines structural and dynamic intent to simulate phenomena like rigid body and cloth dynamics. The approach is shown to be more expressive and offer a better user experience than text-driven methods, lowering the barrier for non-expert creators.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SketchPlay: Intuitive Creation of Physically Realistic VR Content with Gesture-Driven Sketching] --> B[核心问题/Problem: Creating physically realistic VR content is complex and requires expert tools, creating barriers for non-expert users.]
        A --> C[主要方法/Method: A novel VR framework that transforms air-drawn sketches (for structure) and gestures (for physical cues like velocity/force) into dynamic, physically realistic scenes.]
        A --> D[关键结果/Results: Offers significant advantages in expressiveness and user experience over traditional methods, lowering the entry barrier and showing potential for education, art, and storytelling.]
    ```

- **[arXiv251229] Context-Aware Intelligent Chatbot Framework Leveraging Mobile Sensing**
  - **tags:** [mlsys], [agent system], [mobile sensing, context-aware, large language models, structured prompting, digital health]
  - **authors:** Ziyan Zhang, Nan Gao, Zhiqiang Nie, Shantanu Pal, Haining Zhang
  - **institution:** Nankai University, Tsinghua University, Deakin University
  - **link:** https://arxiv.org/pdf/2512.22032
  - **contributions:** 1. Proposes a context-sensitive conversational assistant framework that integrates mobile sensing data with large language models. 2. Abstracts raw mobile sensing signals into 16 contextual scenarios and translates them into natural language prompts. 3. Designs a structured prompting system to guide the LLM in generating personalized and contextually relevant dialogue.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ee41bc75f2109be1e0a7714aeb8ea0c7f389bba53adcab3bd17db8b8d415623_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of LLMs in understanding real-world user behavior by proposing a chatbot framework that uses mobile sensing data. The method abstracts sensor data into contextual scenarios and converts them into natural language prompts to guide the LLM. The work demonstrates the potential of passive behavioral data for creating personalized, context-aware conversational agents, particularly for digital health applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Context-Aware Intelligent Chatbot Framework<br>上下文感知智能聊天机器人框架] --> B[Problem: LLMs lack real-world user context<br>问题：大语言模型缺乏现实用户情境]
        A --> C[Method: Integrate mobile sensing & structured prompts<br>方法：集成移动感知与结构化提示]
        A --> D[Results: Personalized, context-relevant dialogue<br>结果：个性化、情境相关的对话]
    ```

- **[arXiv251229] StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars**
  - **tags:** [mlsys], [diffusion models], [autoregressive distillation, adversarial refinement, real-time streaming, reference-anchored positional re-encoding, consistency-aware discriminator]
  - **authors:** Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu
  - **institution:** Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University
  - **link:** https://arxiv.org/pdf/2512.22065
  - **code:** https://streamavatar.github.io
  - **contributions:** 1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Non-causal, high-cost diffusion models unsuitable for real-time streaming; Limited to head-and-shoulder, lacking gestures.]
        C[主要方法/Method<br>Two-stage autoregressive adaptation (distillation + refinement) with Reference Sink, RAPR, Consistency-Aware Discriminator.]
        D[关键结果/Results<br>State-of-the-art real-time, interactive full-body avatar with natural talking/listening and gestures.]
    ```

## 2025-12-30

- **[arXiv251230] SoDA: An Efficient Interaction Paradigm for the Agentic Web**
  - **tags:** [mlsys], [agent system], [Sovereign Digital Avatar, Intent-Permission Handshake, orthogonal decoupling, A2A protocols, dual-factor adaptive routing]
  - **authors:** Zicai Cui, Zhouyuan Jian, Weiwen Liu, Weinan Zhang
  - **institution:** Shanghai Jiao Tong University, Shanghai Innovation Institute
  - **link:** https://arxiv.org/pdf/2512.22135
  - **contributions:** 1. Proposes a user sovereignty interaction paradigm for the Agentic Web, decoupling memory from application logic to break data lock-in and shifting from explicit instruction to implicit intent alignment to reduce cognitive load. 2. Implements the paradigm via the Sovereign Digital Avatar (SoDA) with an orthogonal decoupling design of storage, computation, and interaction, establishing the principle of "data as a persistent asset, model as a transient tool". 3. Designs an Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor adaptive routing for active risk governance in zero-trust environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes the Sovereign Digital Avatar (SoDA), a new interaction paradigm for the Agentic Web that decouples user memory from applications and uses intent alignment to reduce cognitive load. It introduces an architecture with orthogonal decoupling and a secure handshake mechanism for zero-trust environments. Empirical results show it significantly reduces token consumption and user cognitive load compared to existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SoDA: An Efficient Interaction Paradigm for the Agentic Web] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[数据锁定/Data Lock-in]
        B --> B2[认知过载/Cognitive Overload]
        C --> C1[主权数字化身/Sovereign Digital Avatar (SoDA)]
        C --> C2[正交解耦设计/Orthogonal Decoupling Design]
        C --> C3[意图-权限握手机制/Intent-Permission Handshake Mechanism]
        D --> D1[降低令牌消耗/Reduces Token Consumption by 27-35%]
        D --> D2[降低认知负载/Reduces Cognitive Load by 72% vs RAG, 88% vs Manual]
    ```

- **[arXiv251230] Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware**
  - **tags:** [cv], [human activity recognition], [driver monitoring systems, edge AI, quantization, temporal decision head, confounder-aware labeling]
  - **authors:** Vesal Ahsani, Babak Hossein Khalaj
  - **institution:** Sharif University of Technology
  - **link:** https://arxiv.org/pdf/2512.22298
  - **contributions:** 1. A deployable single-camera driver behavior recognition pipeline optimized for low-cost edge hardware (Raspberry Pi 5 and Google Coral Edge TPU). 2. A confounder-aware label design to reduce false positives from visually similar actions. 3. A temporal decision head that generates stable alerts based on sustained, confident predictions rather than noisy per-frame outputs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bd52e06dc77080ab346fc3d6fe46b900bf06b5c1eaeb6ae89801ac125ee7c51_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a real-time driver behavior recognition system designed for low-cost edge hardware to address the challenges of compute, power, and cost constraints in vehicles. The method combines a compact vision model, confounder-aware labeling, and a temporal decision head to recognize 17 distraction and drowsiness-related behaviors. The optimized system achieves 16 FPS on a Raspberry Pi 5 and 25 FPS on a Coral Edge TPU, enabling practical deployment for in-cabin monitoring.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[实时DMS需求 / Real-time DMS needs low latency, low cost, low power]
        C --> C1[紧凑单摄像头系统 / Compact single-camera pipeline]
        C1 --> C2[紧凑视觉模型 / Compact per-frame vision model]
        C1 --> C3[抗混淆标签设计 / Confounder-aware label design]
        C1 --> C4[时序决策头 / Temporal decision head]
        D --> D1[性能: 16 FPS (RPi5), 25 FPS (Edge TPU) / Performance: 16 FPS (RPi5), 25 FPS (Edge TPU)]
        D --> D2[验证: 真实车辆测试 / Validation: Real in-vehicle tests]
    ```

- **[arXiv251230] Emotion classification using EEG headset signals and Random Forest**
  - **tags:** [ai], [affective computing], [EEG, Random Forest, emotion classification, brain-computer interface, real-time prediction]
  - **authors:** Ricardo Vasquez, Diego Riofrío-Luzcando, Joe Carrion-Jumbo, Cesar Guevara
  - **institution:** Universidad Internacional SEK, Universidad Indoamérica, The Institute of Mathematical Sciences (ICMAT-CSIC)
  - **link:** https://arxiv.org/pdf/2512.22333
  - **contributions:** 1. Developed a model for classifying human emotions (happiness, sadness, relaxation) using EEG signals from a consumer-grade headset (EMOTIV EPOC). 2. Applied the Random Forest algorithm to achieve high accuracy, particularly for happiness (97.21%). 3. Implemented a real-time emotion prediction system that captures EEG signals, processes them, and visually displays the predicted emotion.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e19385b22eca0965c66f7006e387468776c757a86a9b784693bc7b77b3c7533_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a system to classify human emotions (happiness, sadness, relaxation) from EEG signals using a Random Forest model. The model was trained on data from 50 participants and achieved high accuracy, especially for happiness. The work was extended to create a real-time prediction algorithm that outputs the result with representative images.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Emotion classification using EEG headset signals and Random Forest] --> B(核心问题/Problem: 如何从EEG信号中检测和分类情绪？/How to detect and classify emotions from EEG signals?)
        A --> C(主要方法/Method: 使用EMOTIV EPOC采集EEG数据，并应用随机森林模型进行分类/Use EMOTIV EPOC to collect EEG data and apply Random Forest model for classification)
        A --> D(关键结果/Results: 快乐分类准确率97.21%，实现实时情绪预测算法/Happiness classification accuracy 97.21%, implemented a real-time emotion prediction algorithm)
    ```

- **[arXiv251230] Human-like visual computing advances explainability and few-shot learning in deep neural networks for complex physiological data**
  - **tags:** [cv], [medical image analysis], [pseudo-colouring, few-shot learning, prototypical networks, ResNet-18, explainability]
  - **authors:** Alaa Alahmadi, Mohamed Hasan
  - **institution:** Newcastle University, University of Leeds
  - **link:** https://arxiv.org/pdf/2512.22349
  - **contributions:** 1. Introduces a perception-informed pseudo-colouring technique to encode clinically salient temporal ECG features (like QT-interval) into structured colour representations. 2. Demonstrates that this technique enables effective few-shot and one-shot learning for a complex physiological data task (drug-induced LQTS) using prototypical networks and ResNet-18. 3. Shows that the method improves model explainability by guiding attention to clinically meaningful features and that aggregating multiple cardiac cycles (mirroring human perceptual averaging) further boosts performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4573948678ad6f25faec7ec6be8baccee385ce760fef63e3980935e84e21be0_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problems of data inefficiency and poor interpretability in deep learning models for physiological signal analysis. It proposes a human-inspired pseudo-colouring technique to encode ECG features, enabling effective few-shot learning and improving model explainability by focusing on clinically relevant signal components. The results demonstrate that incorporating human-like perceptual encoding can bridge data efficiency and interpretability in medical AI.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Human-like visual computing advances explainability and few-shot learning in deep neural networks for complex physiological data] --> B1
        A --> B2
        A --> B3
        B1[核心问题/Problem] --> C1[数据效率低/Lack of data efficiency]
        B1 --> C2[可解释性差/Limited explainability]
        B1 --> C3[临床可靠性受限/Constrained clinical reliability]
        B2[主要方法/Method] --> D1[感知启发的伪着色技术/Perception-informed pseudo-colouring]
        D1 --> E1[编码临床特征/Encode clinical features (e.g., QT-interval)]
        D1 --> E2[结构化颜色表示/Structured colour representations]
        B2 --> D2[原型网络与ResNet-18/Prototypical networks & ResNet-18]
        B2 --> D3[聚合多个心跳周期/Aggregate multiple cardiac cycles]
        B3[关键结果/Results] --> F1[实现少样本与单样本学习/Achieve few-shot & one-shot learning]
        B3 --> F2[提升可解释性/Improve explainability (guide attention)]
        B3 --> F3[桥接数据效率与因果推理/Bridge data efficiency & causal reasoning]
    ```

- **[arXiv251230] Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection**
  - **tags:** [mlsys], [agent system], [multi-agent LLM framework, knowledge gap detection, student-AI dialogue analysis, QueryQuilt, educational technology]
  - **authors:** Quanzhi Fu, Qiyu Wu, Dan Williams
  - **institution:** Virginia Tech
  - **link:** https://arxiv.org/pdf/2512.22404
  - **contributions:** 1. Proposes QueryQuilt, a novel multi-agent LLM framework for automated detection of common student knowledge gaps in large lectures. 2. Introduces a two-agent design: a Dialogue Agent that engages students with probing questions and a Knowledge Gap Identification Agent that analyzes chat logs. 3. Demonstrates the system's potential with high accuracy (100%) on simulated data and high completeness (95%) on real student-AI dialogue data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/346f14200e9375ed815220f7c720c8952c5109e4bcf1c3f206a9c517e2f80947_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes QueryQuilt, a multi-agent LLM framework that analyzes student-AI chat logs to automatically identify common knowledge gaps in large-scale lectures. The system uses a Dialogue Agent to interact with students and a Knowledge Gap Identification Agent to analyze the dialogues, providing instructors with insights into class-wide understanding. Initial evaluation shows promising accuracy and completeness, indicating its potential for improving teaching in real classroom environments.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[大班教学难以及时发现学生的知识缺口/Large lectures make timely knowledge gap identification challenging]
    C --> C1[提出QueryQuilt: 一个多智能体LLM框架/Propose QueryQuilt: a multi-agent LLM framework]
    C1 --> C2[对话智能体: 回答并探查学生问题/Dialogue Agent: responds and probes student questions]
    C1 --> C3[知识缺口识别智能体: 分析对话识别共同缺口/Knowledge Gap Identification Agent: analyzes dialogues to identify common gaps]
    D --> D1[模拟学生数据: 100%准确率/Simulated student data: 100% accuracy]
    D --> D2[真实学生-AI对话数据: 95%完整性/Real student-AI dialogue data: 95% completeness]
    ```

- **[arXiv251230] Learning to Program != "One-Size-Fits-All": Exploring Variations of Parsons Problems as Scaffolding**
  - **tags:** [other], [computing education], [Parsons Problems, Scaffolding, Faded Parsons, Pseudocode Parsons, Codespec]
  - **authors:** Carl Christopher Haynes-Magyar
  - **institution:** University of Pittsburgh
  - **link:** https://arxiv.org/pdf/2512.22407
  - **contributions:** 1. Explored learner perceptions of two novel Parsons problem variations (Faded Parsons and Pseudocode Parsons) as optional scaffolding in a new programming environment called Codespec. 2. Provided empirical evidence that offering these optional scaffolds supports comprehension monitoring, strategy formation, and knowledge refinement, with learners selectively using them for different purposes (syntax/structure vs. high-level reasoning). 3. Identified both benefits (e.g., desirable challenge of Faded Parsons) and costs (e.g., time, potential confusion) of using these problem types as scaffolding techniques.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd341a2988c4238f96b98f47c543fa98eabbcc1469d134da8c7bac8729ea9026_w640_q70.webp
  - **Simple LLM Summary:** This study investigates how variations of Parsons problems can scaffold learning to program. It introduces the Codespec environment, offering optional Faded Parsons and Pseudocode Parsons problems, and finds through interviews that learners selectively use these scaffolds for different cognitive tasks, supporting learning but also noting some usability costs.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Learning to Program != 'One-Size-Fits-All'") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("如何有效搭建编程学习脚手架？/How to effectively scaffold programming learning?")
        Method --> M1("开发Codespec环境/Develop Codespec environment")
        Method --> M2("提供两种Parsons问题变体作为可选脚手架/Offer two Parsons problem variants as optional scaffolds")
        Method --> M3("进行回顾性有声思维访谈/Conduct retrospective think-aloud interviews")
        Results --> R1("脚手架支持理解监控与策略形成/Scaffolds support comprehension monitoring & strategy formation")
        Results --> R2("学习者选择性使用不同变体/Learners selectively use different variants")
        Results --> R3("Faded Parsons被视为理想挑战/Faded Parsons perceived as desirable challenge")
    ```

- **[arXiv251230] Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding**
  - **tags:** [se], [human aspects of software engineering], [vibe coding, large language models, grounded theory, prompt engineering, software development practices]
  - **authors:** Yi-Hung Chou, Boyuan Jiang, Yi Wen Chen, Mingyue Weng, Victoria Jackson, Thomas Zimmermann, James A. Jones
  - **institution:** University of California, Irvine
  - **link:** https://arxiv.org/pdf/2512.22418
  - **contributions:** 1. Conducted a grounded theory study of "vibe coding" practices through analysis of 20 videos, providing empirical data on this emerging phenomenon. 2. Identified a spectrum of developer behaviors, from full reliance on AI without code inspection to active examination and adaptation of generated outputs. 3. Revealed that developers must contend with the stochastic nature of LLM generation, framing debugging as "rolling the dice," and that divergent mental models influence prompting, evaluation, and trust.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eab8ec990fa93b887bf7f5945d43ce53b02d7e23a90f66d7421522c4fb50f07c_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the emerging practice of "vibe coding," where developers build software primarily by prompting LLMs. Through a qualitative grounded theory study of 20 videos, the research reveals a spectrum of developer behaviors and the central challenge of dealing with stochastic AI outputs, described as "rolling the dice." The findings highlight how developers' mental models shape their interaction with AI and point to new research directions for the future of software engineering.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM驱动的"氛围编码"实践如何定义与进行?/How is LLM-driven "vibe coding" defined and practiced?]
        C --> C1[对20个视频进行扎根理论研究/Grounded theory study of 20 videos]
        C --> C2[分析直播与观点视频/Analyze live-streamed & opinion videos]
        D --> D1[行为谱系: 从完全依赖到检查适配/Spectrum of behaviors: from full reliance to inspection & adaptation]
        D --> D2[核心挑战: 生成的随机性/"掷骰子"/Core challenge: stochastic generation / "rolling the dice"]
        D --> D3[心智模型影响策略与信任/Mental models influence strategies & trust]
    ```

- **[arXiv251230] Relational Mediators: LLM Chatbots as Boundary Objects in Psychotherapy**
  - **tags:** [nlp], [human-ai interaction], [boundary objects, relational mediation, marginalized clients, therapeutic systems, dynamic framework]
  - **authors:** Jiatao Quan, Ziyue Li, Tian Qi Zhu, Yuxuan Li, Baoying Wang, Wanda Pratt, Nan Gao
  - **institution:** University of Washington, The Hong Kong Polytechnic University, Nankai University
  - **link:** https://arxiv.org/pdf/2512.22462
  - **contributions:** 1. Identifies enduring relational challenges in psychotherapy for marginalized clients, such as trust-building and self-disclosure burdens. 2. Proposes the Dynamic Boundary Mediation Framework, which re-conceptualizes LLMs as adaptive boundary objects. 3. Delineates three specific forms of mediation (Epistemic, Relational, Contextual) to address knowledge gaps, power asymmetries, and therapy-life discontinuities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8695c76e0392473389276989f78ab825dab06f2e38bdd785d2418d8ca9a1d80_w640_q70.webp
  - **Simple LLM Summary:** This paper argues that current framings of LLMs in mental health overlook their potential to mediate complex therapeutic relationships. Based on interviews with therapists and marginalized clients in China, the authors propose the Dynamic Boundary Mediation Framework, which positions LLM chatbots as adaptive boundary objects to bridge knowledge, power, and contextual gaps. This offers a pathway for designing AI systems that more effectively and accountably support therapeutic relationships for marginalized users.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Relational Mediators: LLM Chatbots as Boundary Objects in Psychotherapy"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["现有视角的局限/Current Framing Limitations"]
        Problem --> P2["边缘化客户的关系挑战/Relational Challenges for Marginalized Clients"]
        Method --> M1["动态边界调解框架/Dynamic Boundary Mediation Framework"]
        Method --> M2["作为边界对象的LLM/LLMs as Boundary Objects"]
        Results --> R1["三种调解形式/Three Forms of Mediation"]
        Results --> R2["关系问责的AI系统/Relationally Accountable AI Systems"]
    ```

- **[arXiv251230] SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding for Fine-Grained sEMG-Based Movement Decoding**
  - **tags:** [ai], [biomedical signal processing], [self-supervised learning, surface electromyography, rotary position encoding, spectral pre-training, movement decoding]
  - **authors:** Zihan Weng, Chanlin Yi, Pouya Bashivan, Jing Lu, Fali Li, Dezhong Yao, Jingming Hou, Yangsong Zhang, Peng Xu
  - **institution:** University of Electronic Science and Technology of China
  - **link:** https://arxiv.org/pdf/2512.22481
  - **contributions:** 1. A novel self-supervised pre-training task that uses masked prediction of clustered STFT pseudo-labels to learn robust, physiologically relevant frequency patterns from sEMG signals. 2. A novel Cylindrical Rotary Position Embedding (CyRoPE) that factorizes embeddings along temporal and annular spatial dimensions to explicitly model the cylindrical topology of forearm electrode arrays. 3. The SPECTRE framework, which integrates these contributions to establish a new state-of-the-art for fine-grained movement decoding, validated on multiple datasets including data from individuals with amputation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5801cbdcbac93bf7df15e18531c5ff2653259e25003568da5b53b240d06d32c_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces SPECTRE, a domain-specific self-supervised learning framework for decoding fine-grained movements from surface electromyography (sEMG) signals. It proposes a spectral pre-training task using masked pseudo-label prediction and a novel cylindrical rotary position encoding to model sensor topology. Evaluations show SPECTRE significantly outperforms existing supervised and generic self-supervised baselines, providing a robust foundation for practical myoelectric interfaces.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Decoding fine-grained movement from noisy, non-stationary sEMG signals for prosthetic control]
        C[主要方法/Method: Domain-specific SSL with spectral pre-training and Cylindrical Rotary Position Embedding (CyRoPE)]
        D[关键结果/Results: New SOTA performance, outperforms supervised & generic SSL baselines, validated on amputation data]
    ```

- **[arXiv251230] Clinically Calibrated Machine Learning Benchmarks for Large-Scale Multi-Disorder EEG Classification**
  - **tags:** [ai], [medical signal processing], [electroencephalography, multi-disorder classification, sensitivity-oriented modeling, clinical calibration, feature importance analysis]
  - **authors:** Argha Kamal Samanta, Deepak Mewada, Monalisa Sarma, Debasis Samanta
  - **institution:** Indian Institute of Technology, Kharagpur
  - **link:** https://arxiv.org/pdf/2512.22656
  - **contributions:** 1. Proposes a clinically calibrated, sensitivity-prioritized machine learning framework for classifying eleven diverse neurological disorders from EEG data, addressing severe class imbalance. 2. Establishes realistic performance baselines for multi-disorder EEG classification, demonstrating recall exceeding 80% for most disorders with significant gains for low-prevalence conditions after threshold calibration. 3. Provides physiologically plausible feature importance analysis that aligns with established clinical EEG markers, validating the model's clinical relevance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/636894ed25045336665fcbac593a58130411dff99c5d2a3e5a0cd50067ee44ec_w640_q70.webp
  - **Simple LLM Summary:** This study addresses the challenge of automated, multi-disorder screening from clinical EEG data by developing disorder-aware machine learning models with decision thresholds explicitly calibrated to prioritize diagnostic sensitivity. The method uses a multi-domain feature set and is evaluated on a large, heterogeneous dataset, achieving high recall for most neurological disorder categories. The results establish performance baselines and demonstrate that sensitivity-prioritized automated analysis can support scalable EEG screening and triage in clinical practice.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Clinically Calibrated Machine Learning Benchmarks for Large-Scale Multi-Disorder EEG Classification] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Manual EEG interpretation is slow and variable; existing automation lacks multi-disorder support.]
        C[主要方法/Method: Use multi-domain EEG features and train sensitivity-calibrated models under class imbalance.]
        D[关键结果/Results: High recall (>80%) for most disorders; feature importance aligns with clinical knowledge.]
    ```

- **[arXiv251230] What do you say? A pilot study investigating student responses in Data Driven Classroom Interviews**
  - **tags:** [other], [educational data mining], [Data-Driven Classroom Interviews (DDCIs), Ordered Network Analysis (ONA), rhetorical strategies]
  - **authors:** Jaclyn Ocumpaugh, Zhanlan Wei, Amanda Barany, Xiner Liu, Andres Felipe Zambrano, Ryan Baker, Camille Gioradno
  - **institution:** University of Houston, University of Pennsylvania, Adelaide University
  - **link:** https://arxiv.org/pdf/2512.22747
  - **contributions:** 1. Proposes a novel method for analyzing interview sequences using Ordered Network Analysis (ONA) to re-examine data from a prior Epistemic Network Analysis study. 2. Investigates the relationship between interviewer rhetorical strategies and student response strategies in real-time classroom interviews. 3. Provides empirical evidence on how students with different levels of situational interest respond differently to interview prompts, confirming the reliability of interviewer protocols.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87056237d276d00b024d3b9369defa22ffde3d2c95bf0eaf093a1cbb2c5720c_w640_q70.webp
  - **Simple LLM Summary:** This study investigates student responses in Data-Driven Classroom Interviews (DDCIs) by applying Ordered Network Analysis (ONA) to analyze the sequence of rhetorical strategies used by interviewers and students. It finds minor differences in responses based on student situational interest but overall confirms that interviewer-driven differences are minimal and guidelines are followed.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[What do you say? A pilot study investigating student responses in Data Driven Classroom Interviews] --> B[核心问题/Problem: How do rhetorical strategies sequence in student interviews?]
        A --> C[主要方法/Method: Use Ordered Network Analysis (ONA) to reanalyze interview data]
        A --> D[关键结果/Results: Minor response differences by interest level; interviewers follow open-ended guidelines]
    ```

- **[arXiv251230] ChatGraPhT: A Visual Conversation Interface for Multi-Path Reflection with Agentic LLM Support**
  - **tags:** [ai], [human-computer interaction], [reflective practice, agentic llm, visual conversation interface, non-linear dialogue, multi-path reflection]
  - **authors:** Geoff Kimm, Linus Tan
  - **institution:** Swinburne University of Technology
  - **link:** https://arxiv.org/pdf/2512.22790
  - **contributions:** 1. The design of a node-link, agentic LLM interface for reflective dialogue. 2. Transferable design knowledge on balancing structure and AI support to sustain reflection in complex, open-ended tasks. 3. An interactive tool that visualizes dialogue as a map, enabling branching, merging, and editing of past messages.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0a7e3705fa584edc6bed6f2a636ce9e0b4f314e3e0c63213afc64d0d876a48f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of linear LLM interfaces in supporting reflective practice by introducing ChatGraPhT, a visual tool that represents dialogue as a non-linear, editable map and provides guidance from two agentic LLM assistants. The study finds that making conversation structure visible, allowing branching/merging, and suggesting idea combinations deepens user reflective engagement.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ChatGraPhT: A Visual Conversation Interface for Multi-Path Reflection with Agentic LLM Support] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[线性对话界面限制反思/Linear interfaces limit reflection support]
        C --> C1[可视化对话地图/Visual dialogue map]
        C --> C2[支持分支与合并/Supports branching & merging]
        C --> C3[智能体LLM提供指导/Agentic LLMs provide guidance]
        D --> D1[增强用户反思参与度/Deepened user reflective engagement]
        D --> D2[提供可转移的设计知识/Provides transferable design knowledge]
    ```

- **[arXiv251230] Towards the analysis of team members well-being**
  - **tags:** [se], [software development team well-being], [well-being, software development, team members, positive feedback, prototype]
  - **authors:** Zan Xu, Sari Nurfauziyyah, Anastasia Romanova, Kaamesh G S, Yiqun Gao, Maria Spichkova
  - **institution:** RMIT University
  - **link:** https://arxiv.org/pdf/2512.22845
  - **contributions:** 1. Presents the results of a project focused on analyzing the well-being of software development team members. 2. Identifies the feeling of being appreciated and acknowledged as a critical factor for team member well-being. 3. Describes the development of a prototype tool-supported framework aimed at providing personalized positive feedback without creating significant additional workload.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44b6ecf51f08897fa2d6ed662014dae0fe49b0c593bf9e815394b288ffd9d465_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the growing concern for the well-being of software development team members, emphasizing the importance of feeling appreciated. It presents a project that developed a prototype for a tool-supported, personalized framework to provide positive feedback. The goal is to improve well-being without adding substantial extra work for team members.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Towards the analysis of team members well-being] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[软件团队成员幸福感/Software Team Member Well-being]
        B1 --> B2[关键因素：被赞赏与认可/Critical Factor: Feeling Appreciated & Acknowledged]
        C --> C1[项目分析与原型开发/Project Analysis & Prototype Development]
        D --> D1[提出工具支持的个性化框架/Proposed Tool-supported Personalized Framework]
    ```

- **[arXiv251230] Differentiable Physics-Driven Human Representation for Millimeter-Wave Based Pose Estimation**
  - **tags:** [cv], [human pose estimation], [millimeter-wave, differentiable physics, Gaussian representation, human representation, pose estimation]
  - **authors:** Shuntian Zheng, Guangming Wang, Jiaqi Li, Minzhe Ni, Yu Guan
  - **institution:** University of Warwick, University of Cambridge
  - **link:** https://arxiv.org/pdf/2512.23054
  - **contributions:** 1. Proposes a novel Differentiable Physics-driven Human Representation (DIPR) as an alternative input paradigm for mmWave-based HPE, representing humans as an ensemble of Gaussian distributions. 2. Introduces a method to incorporate kinematic priors for DIPR initialization and multi-faceted optimization to ensure biomechanical validity. 3. Designs a strategy to simulate the mmWave processing pipeline and re-render a Heatmap from DIPR for comparison, preventing overfitting to kinematic constraints and spurious noise.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ace172569ea466a63abf72680293895dbb1d21feeae095f32ec879439596ed2f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of existing Heatmap and Point Cloud input paradigms for millimeter-wave-based human pose estimation by proposing a Differentiable Physics-driven Human Representation (DIPR). DIPR uses Gaussian distributions with kinematic and electromagnetic parameters, enhanced by kinematic priors and a physics-based re-rendering strategy to mitigate noise and improve feature quality. Experiments show that existing methods can easily integrate DIPR to achieve superior performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Differentiable Physics-Driven Human Representation for Millimeter-Wave Based Pose Estimation"] --> Problem["核心问题/Problem: Limitations of Heatmap (noise) and Point Cloud (sparsity) in mmWave-based HPE"]
        Root --> Method["主要方法/Method: Proposes Differentiable Physics-driven Human Representation (DIPR) using Gaussian distributions with kinematic priors and physics simulation"]
        Root --> Results["关键结果/Results: DIPR integrates with existing methods and achieves superior performance"]
    ```

- **[arXiv251230] Reimagining the Traditional Flight Computer: E6BJA as a Modern, Multi-Platform Tool for Flight Calculations and Training**
  - **tags:** [other], [human-computer interaction], [flight computer, multi-platform software, aviation training, educational monographs, weight and balance]
  - **authors:** Jamie J. Alnasir
  - **institution:** None (Inferred from author's email domain: al-nasir.com, which appears to be a personal domain)
  - **link:** https://arxiv.org/pdf/2512.23055
  - **contributions:** 1. Development of E6BJA, a modern, multi-platform (iOS, Android, Windows, web) software flight computer that replicates and extends traditional flight calculations. 2. Integration of enhanced modeling capabilities (e.g., 1976 International Standard Atmosphere, carburetor icing risk) and aircraft-specific calculators with embedded educational explanations. 3. A comparative analysis demonstrating the tool's improvements over traditional devices in accuracy, error reduction, discoverability, and educational value for pilot training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/728f903c57bf352d1339c863c7cb1986de9a626a56f8a15516317cf7068bcb83_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of traditional mechanical and electronic flight computers by proposing E6BJA, a modern multi-platform software tool. E6BJA replicates core flight calculations while adding enhanced models and embedded educational content. The work concludes that this approach represents a meaningful evolution in pilot tools, improving safety, intuition, and instructional value in aviation training contexts.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Reimagining the Traditional Flight Computer") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("传统飞行计算机的局限性/Limitations of Traditional Flight Computers")
        Method --> M1("开发多平台软件E6BJA/Develop Multi-Platform Software E6BJA")
        Method --> M2("扩展计算与教育功能/Extend Calculations & Educational Features")
        Results --> R1("证明在准确性等方面的改进/Demonstrate Improvements in Accuracy, etc.")
        Results --> R2("支持更安全的飞行规划/Support Safer Flight Planning")
    ```

- **[arXiv251230] Multimodal Functional Maximum Correlation for Emotion Recognition**
  - **tags:** [ai], [multimodal learning], [self-supervised learning, dual total correlation, functional maximum correlation analysis, affective computing, physiological signals]
  - **authors:** Deyang Zheng, Tianyi Zhang, Wenming Zheng, Shujian Yu
  - **institution:** Southeast University, Westlake University, Vrije Universiteit Amsterdam
  - **link:** https://arxiv.org/pdf/2512.23076
  - **code:** https://github.com/DY9910/MFMC
  - **contributions:** 1. Proposes a novel self-supervised learning framework (MFMC) that maximizes higher-order multimodal dependence using a Dual Total Correlation objective. 2. Derives a tight sandwich bound and optimizes it using a functional maximum correlation analysis-based trace surrogate to capture joint interactions. 3. Demonstrates state-of-the-art or competitive performance on affective computing benchmarks, showing robustness to inter-subject variability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/369b23e1c7a17085940402e88d2347afb3386819a237c48ac347be73127aea2a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of learning joint dynamics from scarce and subjective emotion labels by proposing a self-supervised learning framework called MFMC. It captures higher-order multimodal dependencies beyond pairwise alignment, leading to improved emotion recognition performance on physiological signal benchmarks. The results show significant accuracy gains, particularly in subject-independent settings, highlighting the method's effectiveness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MFMC for Emotion Recognition] --> B[核心问题/Problem: 情感状态表现为跨系统的协调但异质的生理反应，现有自监督方法难以捕捉多模态高阶交互。]
        A --> C[主要方法/Method: 提出MFMC框架，通过Dual Total Correlation目标和Functional Maximum Correlation Analysis最大化高阶多模态依赖性。]
        A --> D[关键结果/Results: 在多个基准测试中达到SOTA或竞争性性能，显著提升CEAP-360VR数据集上的准确率，对主体间变异性鲁棒。]
    ```

- **[arXiv251230] Cogniscope: Modeling Social Media Interactions as Digital Biomarkers for Early Detection of Cognitive Decline**
  - **tags:** [ai], [digital health / computational social science], [digital biomarkers, simulation framework, multimodal fusion, cognitive decline, social media interactions]
  - **authors:** Ananya Drishti, Mahfuza Farooque
  - **institution:** Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2512.23093
  - **contributions:** 1) A configurable simulation framework (Cogniscope) that generates social-media-style interaction data for studying digital biomarkers of cognitive health. 2) A method for modeling synthetic users with heterogeneous cognitive trajectories and embedding micro-tasks (e.g., video summarization, Q&A) into content streams to produce linguistic and behavioral signals. 3) The release of open-source tools, including generator code and synthetic datasets, to provide a controllable, ethically safe testbed for systematic investigation and benchmarking.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/512eb1289cb5884089bd596bddf1510fefedfecb88019690b90dd2e6b6c77243_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces Cogniscope, a simulation framework that generates synthetic social media interaction data to model digital biomarkers for early detection of cognitive decline. It fuses linguistic and behavioral signals from simulated user interactions to evaluate early detection models. The framework is released as an open-source tool to provide a benchmark for studying multimodal cognitive markers.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cogniscope: Modeling Social Media Interactions as Digital Biomarkers] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统诊断工具成本高、侵入性强/Traditional diagnostic tools are invasive and costly]
        B --> B2[需要大规模、生态有效的认知监测/Need for population-scale, ecologically valid monitoring]
        C --> C1[模拟生成社交媒体交互数据/Simulate social-media-style interaction data]
        C --> C2[嵌入微任务并提取多模态特征/Embed micro-tasks and extract multimodal features]
        C --> C3[构建可控的合成用户测试平台/Build a controllable synthetic user testbed]
        D --> D1[展示了检测性能的敏感性分析/Demonstrates sensitivity analysis of detection performance]
        D --> D2[发布代码与数据集以支持可复现性/Releases code and datasets for reproducibility]
        D --> D3[为社区提供基准资源/Provides a benchmark resource for the community]
    ```

- **[arXiv251230] ReHome Earth: A VR-Based Concept Validation for AI-Driven Space Homesickness Interventions**
  - **tags:** [other], [human-computer interaction], [virtual reality, AI-generated content, emotional support, extreme isolation, concept validation]
  - **authors:** Mengyao Guo, Kexin Nie, Jinda Han, Guanyou Li, Adrian Wong
  - **institution:** Harbin Institute of Technology, Shenzhen; The University of Sydney; University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2512.23118
  - **contributions:** 1) A technically feasible future-oriented installation concept integrating transparent OLED displays with spaceship windows for real-time Earth connectivity. 2) A functional VR prototype for simulating astronaut isolation to test AI-generated content effectiveness in space HCI research. 3) Empirical insights and validated design implications (emotional pacing, explainable biophysical feedback, collective affective infrastructure) for AI-driven emotional support systems in extreme isolation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/994a1c291c0ccdd72311f02214224ba7a2666234ccc35cb8193843b103cbd5ae_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses astronaut homesickness by proposing ReHome Earth, a dual-component approach featuring a futuristic space installation concept and a VR prototype for testing AI-generated emotional content. Since real astronauts were unavailable, the concept was validated with 84 terrestrial participants experiencing displacement, demonstrating strong emotional resonance and yielding key design principles for affective computing in isolated environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ReHome Earth: A VR-Based Concept Validation for AI-Driven Space Homesickness Interventions] --> B[核心问题/Problem: Emotional needs of astronauts on long-duration missions are underexplored.]
        A --> C[主要方法/Method: Dual-component design: 1) Future installation concept with transparent OLED displays. 2) Functional VR prototype for testing AI content.]
        A --> D[关键结果/Results: Strong emotional resonance validated with proxy participants. Three design implications identified.]
    ```

- **[arXiv251230] It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents**
  - **tags:** [sec], [prompt injection], [prompt injection, web agents, social-engineering, benchmark, autonomous agents]
  - **authors:** Karolina Korgul, Yushi Yang, Arkadiusz Drohomirecki, Piotr Błaszczyk, Will Howard, Lukas Aichberger, Chris Russell, Philip H.S. Torr, Adam Mahdi, Adel Bibi
  - **institution:** University of Oxford, SoftServe, Johannes Kepler University Linz
  - **link:** https://arxiv.org/pdf/2512.23128
  - **contributions:** 1. Introduces the Task-Redirecting Agent Persuasion Benchmark (TRAP) for evaluating prompt injection vulnerabilities in web-based LLM agents. 2. Provides a modular social-engineering injection framework for controlled experiments on high-fidelity website clones. 3. Demonstrates systemic vulnerabilities, showing agents are susceptible to injection in 25% of tasks on average, with small interface changes often doubling success rates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c246d5b23e99374a1d754ec870b203d23f214abac92f8d20d849cc98d00e86ca_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the vulnerability of web-based LLM agents to prompt injection attacks, where hidden adversarial instructions can divert agents from their tasks. It introduces the TRAP benchmark, built on realistic website clones, to evaluate these vulnerabilities. The study finds significant susceptibility across models, revealing systemic, psychologically driven weaknesses in current agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Web agents vulnerable to prompt injection attacks] --> Problem_Detail[问题详情/Problem Detail: Adversarial instructions in web content can divert agents from original tasks]
        Method[主要方法/Method: Introduce TRAP benchmark & modular injection framework] --> Method_Detail[方法详情/Method Detail: Evaluation on high-fidelity website clones using social-engineering techniques]
        Results[关键结果/Results: Agents susceptible in 25% of tasks on average] --> Results_Detail[结果详情/Results Detail: Small interface changes can double success rates, revealing systemic vulnerabilities]
    ```

- **[arXiv251230] Understanding EFL Learners' Code-Switching and Teachers' Pedagogical Approaches in LLM-Supported Speaking Practice**
  - **tags:** [nlp], [language education], [code-switching, large language models, pedagogical design, bilingual tutoring, scaffolding]
  - **authors:** Junyeong Park, Jieun Han, Yeon Su Park, Youngbin Lee, Suin Kim, Juho Kim, Alice Oh, So-Yeon Ahn
  - **institution:** KAIST, Elice Inc.
  - **link:** https://arxiv.org/pdf/2512.23136
  - **contributions:** 1. Conducted a six-week empirical study with 20 Korean EFL learners to understand their code-switching behaviors in LLM-mediated speaking practice. 2. Performed a qualitative study with nine English teachers to analyze and refine pedagogical strategies for responding to learner code-switching. 3. Derived design implications for bilingual LLM-powered tutors that leverage teacher expertise to transform code-switching into learning opportunities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98df50b7ead70be4f32b9ae0c16ed0921a98d1c0003ee904a7fa9763956c75ae_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how EFL learners use code-switching and how teachers can pedagogically respond within LLM-supported speaking practice. Through a six-week study with learners and a qualitative study with teachers, it finds learners use CSW for lexical, cultural, and emotional expression, prompting teachers to use selective and dynamic strategies. The work concludes with design implications for creating bilingual LLM tutors that effectively scaffold learning from code-switching.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Understanding EFL Learners' Code-Switching and Teachers' Pedagogical Approaches in LLM-Supported Speaking Practice] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[EFL学习者口语练习中代码转换(CSW)的教学设计不足/Underexplored pedagogical design for CSW in EFL speaking practice]
        C --> C1[对20名韩国EFL学习者进行为期六周的LLM中介口语实践研究/Six-week LLM-mediated speaking study with 20 Korean EFL learners]
        C --> C2[对9名英语教师进行定性研究，设计对CSW的回应/Qualitative study with 9 teachers designing responses to CSW]
        D --> D1[学习者使用CSW表达词汇、文化和情感细微差别/Learners use CSW for lexical, cultural, emotional nuance]
        D --> D2[教师采用选择性干预和动态支架策略/Teachers employ selective interventions & dynamic scaffolding]
        D --> D3[提出双语LLM导师的设计启示/Design implications for bilingual LLM-powered tutors]
    ```

- **[arXiv251230] A Design Space for Intelligent Agents in Mixed-Initiative Visual Analytics**
  - **tags:** [mlsys], [agent system], [mixed-initiative visual analytics, intelligent agents, design space, multi-agents, human-AI collaboration]
  - **authors:** Tobias Stähle, Matthijs Jansen op de Haar, Sophia Boyer, Rita Sevastjanova, Arpit Narechania, Mennatallah El-Assady
  - **institution:** ETH Zürich, The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.23372
  - **contributions:** 1. Conducted a systematic review of 90 mixed-initiative visual analytics systems and 207 unique agents. 2. Proposed a novel design space for intelligent agents characterized by six dimensions (Configuration and Logic, World Model, Observations, Communication, Actions, Infrastructure). 3. Provided a framework for researchers and designers to explore design choices and situate new systems within the existing landscape.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d494dd1a9aa6a9f007780b691ff276d02fbb3b9060ca4a9fe9bf8ae5bb1fd9d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of overarching design principles for intelligent agents in mixed-initiative visual analytics systems. Through a systematic review, the authors propose a six-dimensional design space that characterizes an agent's perception, understanding, action, and communication capabilities. They conclude by offering a framework for future system design and identifying research opportunities.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[A Design Space for Intelligent Agents in Mixed-Initiative Visual Analytics] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[缺乏智能代理的总体设计原则/Lack of overarching design principles for intelligent agents]
        Method[主要方法/Method] --> M1[对90个系统进行系统综述/Systematic review of 90 systems]
        Method --> M2[提出六维设计空间/Propose a six-dimensional design space]
        Results[关键结果/Results] --> R1[用于探索设计选择的框架/Framework for exploring design choices]
        Results --> R2[定位现有系统的景观/Situate systems in current landscape]
    ```

- **[arXiv251230] Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?**
  - **tags:** [sec], [AI Security], [AI supply chain, security taxonomy, distilBERT classifier]
  - **authors:** Anh Nguyen, Triet Huynh Minh Le, M. Ali Babar
  - **institution:** University of Adelaide
  - **link:** https://arxiv.org/pdf/2512.23385
  - **contributions:** 1. Developed a pipeline combining keyword matching with a fine-tuned distilBERT classifier to identify 312,868 security discussions from Hugging Face and GitHub. 2. Conducted a thematic analysis to create a fine-grained taxonomy of 32 security issues and 24 solutions across four themes (System/Software, External Tools/Ecosystem, Model, Data). 3. Provided empirical insights revealing that security issues stem from complex dependencies and black-box AI components, with Model and Data challenges often lacking concrete solutions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates security issues in the AI supply chain by analyzing developer discussions from Hugging Face and GitHub. The authors use a keyword and classifier pipeline to build a large dataset and perform a thematic analysis to create a taxonomy of issues and solutions. They conclude that many security problems arise from dependencies and the black-box nature of AI, with solutions for Model and Data issues being particularly scarce.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Securing the AI Supply Chain] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[AI供应链安全格局复杂/Complex AI supply chain security landscape]
        Problem --> P2[缺乏对常见问题与解决方案的了解/Lack of knowledge on common issues & solutions]
        Method[主要方法/Method] --> M1[实证调查/Empirical investigation]
        M1 --> M1_1[数据源: Hugging Face, GitHub/Data Sources: Hugging Face, GitHub]
        M1 --> M1_2[构建分类管道/Build classification pipeline]
        M1_2 --> M1_2_1[关键词匹配+微调distilBERT/Keyword matching + fine-tuned distilBERT]
        Results[关键结果/Results] --> R1[数据集: 312,868个安全讨论/Dataset: 312,868 security discussions]
        Results --> R2[分类法: 32个问题, 24个解决方案/Taxonomy: 32 issues, 24 solutions]
        Results --> R3[洞察: 依赖复杂性和黑盒性导致问题/Insight: Issues from dependencies & black-box nature]
    ```

- **[arXiv251230] Soft Robotic Technological Probe for Speculative Fashion Futures**
  - **tags:** [other], [human-robot interaction], [soft robotics, wearable technology, speculative design, pneumatic actuation, technological probe]
  - **authors:** Amy Ingold, Loong Yi Lee, Richard Suphapol Diteesawat, Ajmal Roshan, Yael Zekaria, Edith-Clare Hall, Enrico Werner, Nahian Rahman, Elaine Czech, Jonathan Rossiter
  - **institution:** University of Bristol
  - **link:** https://arxiv.org/pdf/2512.23570
  - **contributions:** 1. The design and fabrication of "Sumbrella," a novel soft robotic garment integrating origami-inspired bistable units, fabric pneumatic actuators, and computer vision. 2. The use of Sumbrella as a technological probe in a focus group study to explore public interpretation, interaction, and ethical concerns regarding future soft robotic wearables. 3. The contribution of key considerations for HRI, including kinesic communication, social dynamics, and ethical guidelines, and a reflection on the value of speculative design for evaluating social acceptability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/961ff66eaf860636f7951016c0465ba6020b516e266f501287c6b78b23a9fafa_w640_q70.webp
  - **Simple LLM Summary:** This paper presents "Sumbrella," a soft robotic garment designed as a speculative fashion probe to explore the social implications of wearable robotics. Through a focus group study, the authors used the prototype to gather insights on how people imagine future interactions with such technology, revealing both expressive potential and significant ethical concerns. The work contributes design considerations and a methodological reflection on using speculative design in Human-Robot Interaction research to address social meaning alongside functionality.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Soft Robotic Technological Probe for Speculative Fashion Futures] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[新兴可穿戴机器人需兼顾功能与社会意义/Emerging wearable robotics demand design addressing function and social meaning]
        C --> C1[设计并制造Sumbrella软体机器人服装/Design and fabricate Sumbrella soft robotic garment]
        C --> C2[作为技术探针进行焦点小组研究/Use as a technological probe in a focus group study]
        D --> D1[引发对表达潜力与伦理风险的丰富讨论/Surfaced discussions on expressive potential and ethical risks]
        D --> D2[为HRI贡献设计考量与伦理指南/Contributed HRI design considerations and ethical guidelines]
        D --> D3[反思推测性设计方法的价值/Reflected on the value of speculative design]
    ```

- **[arXiv251230] Training AI Co-Scientists Using Rubric Rewards**
  - **tags:** [ai], [reinforcement learning], [research plan generation, self-grading, rubric rewards]
  - **authors:** Shashwat Goel, Rishi Hazra, Dulhan Jayalath, Timon Willi, Parag Jain, William F. Shen, Ilias Leontiadis, Francesco Barbieri, Yoram Bachrach, Jonas Geiping, Chenxi Whitehouse
  - **institution:** Meta Superintelligence Labs, ELLIS Institute Tübingen, Max Planck Institute for Intelligent Systems, University of Oxford, University of Cambridge
  - **link:** https://arxiv.org/pdf/2512.23707
  - **contributions:** 1. A scalable method to automatically extract research goals and goal-specific grading rubrics from existing papers to build a training corpus. 2. A reinforcement learning framework with self-grading, where a frozen initial model acts as the grader using rubrics, enabling unsupervised improvement. 3. Demonstration of significant performance gains (12-22% relative improvement) and cross-domain generalization (e.g., to medical research) validated by human experts and frontier model juries.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of training language models to generate high-quality, constraint-following research plans. The proposed method uses reinforcement learning with self-grading, where rubrics automatically extracted from research papers provide reward signals. The approach shows significant improvements in plan quality and generalizes across domains like machine learning and medicine, validated by human expert preference.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Training AI Co-Scientists Using Rubric Rewards"] --> Problem["核心问题/Problem: LMs struggle to generate research plans that follow all constraints."]
        Root --> Method["主要方法/Method: RL with self-grading using automatically extracted rubrics."]
        Root --> Results["关键结果/Results: Human experts prefer finetuned model's plans; method generalizes across domains."]
    ```
