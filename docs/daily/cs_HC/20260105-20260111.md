---
slug: /daily/cshc/20260105-20260111
---
# 20260105-20260111 (cs.HC)

## 2026-01-05

- **[arXiv260105] Augmented Reality Indoor Wayfinding in Hospital Environments An Empirical Study on Navigation Efficiency, User Experience, and Cognitive Load**
  - **tags:** [other], [human-computer interaction], [augmented reality, indoor navigation, cognitive load, NASA-TLX, spatial memory]
  - **authors:** Kai Liu, Michelle L. Aebersold, Mark Lindquist, Haoting Gao
  - **institution:** University of Michigan
  - **link:** https://arxiv.org/pdf/2601.00001
  - **contributions:** 1. Conducted an empirical comparison demonstrating that an AR-based handheld navigation system significantly improves navigation efficiency (faster completion, fewer errors) and reduces user anxiety and cognitive workload compared to traditional paper maps in a hospital environment. 2. Identified a key trade-off, showing that while AR aids real-time performance, paper map users exhibited stronger long-term spatial memory and learning from sketch-based recall tasks. 3. Provided actionable design implications and strategies for developing adaptive, inclusive AR navigation tools that balance efficiency with spatial learning, specifically for complex healthcare settings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/00a9a145b7058f86aae71f0dd0c3dff386c152551ef3abf79f2283cfd3290d2e_w640_q70.webp
  - **Simple LLM Summary:** This study investigates the effectiveness of an augmented reality (AR) handheld navigation system versus paper maps for wayfinding in a complex hospital. Through a mixed-methods experiment with 32 participants, it was found that AR users navigated faster with fewer errors and lower anxiety and workload, but paper map users demonstrated better spatial memory retention. The results highlight a trade-off between real-time navigation efficiency and long-term spatial learning, offering design strategies for adaptive AR tools in healthcare.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Augmented Reality Indoor Wayfinding in Hospital Environments<br/>增强现实医院室内寻路] --> B
        A --> C
        A --> D
        B[Problem: Cognitively demanding hospital navigation for unfamiliar users<br/>核心问题: 对陌生用户而言医院导航认知负荷高]
        C[Method: Empirical study comparing AR handheld system vs. paper maps<br/>主要方法: 对比AR手持系统与纸质地图的实证研究]
        D[Results: AR faster, fewer errors, lower anxiety/workload; Paper maps better for spatial memory<br/>关键结果: AR更快、错误更少、焦虑/负荷更低；纸质地图空间记忆更强]
    ```

- **[arXiv260105] The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs**
  - **tags:** [ai], [causal reasoning], [fuzzy cognitive maps, large-language-model agent, causal feedback, equilibrium limit cycles, agentic leash]
  - **authors:** Akash Kumar Panda, Olaoluwa Adigun, Bart Kosko
  - **institution:** University of Southern California, Florida International University
  - **link:** https://arxiv.org/pdf/2601.00097
  - **contributions:** 1. A novel LLM agent designed to autonomously extract and construct causal feedback Fuzzy Cognitive Maps (FCMs) from raw text. 2. A three-step instruction-guided process for systematically extracting key concepts and causal edges to build the FCM dynamical system. 3. Demonstration that the LLM-generated FCMs converge to the same equilibrium dynamics as human-generated ones and that mixed FCMs from different LLMs can create new equilibria.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc61a9c25939c9840dd408a24d27f4650c47178c297c4db425bc560882426f60_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes an LLM agent to autonomously extract causal feedback Fuzzy Cognitive Maps from text. The agent uses a three-step process to identify concepts and causal edges, forming a dynamical system. The generated FCMs matched human-generated equilibrium dynamics and mixing models from different LLMs produced new equilibria for better causal approximation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs] --> B[核心问题/Problem: How to autonomously extract causal structures from text?]
        A --> C[主要方法/Method: Design an LLM agent with a three-step instruction process to build FCMs from text.]
        A --> D[关键结果/Results: LLM-generated FCMs match human equilibrium dynamics; mixed FCMs create new equilibria.]
    ```

- **[arXiv260105] Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control**
  - **tags:** [mlsys], [agent system], [hybrid agentic framework, hallucination tax, Human Imitator, stochastic reasoning, inventory optimization]
  - **authors:** Yaqi Duan, Yichun Hu, Jiashuo Jiang
  - **institution:** New York University, Cornell University, Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2601.00121
  - **contributions:** 1. Identifies and quantifies the "hallucination tax" when using LLMs as end-to-end solvers for inventory control, highlighting their limitation in grounded stochastic reasoning. 2. Proposes a novel hybrid agentic framework that decouples semantic reasoning (handled by LLM) from mathematical calculation (handled by rigorous algorithms) to create an intelligent interface for optimization. 3. Introduces the "Human Imitator," a fine-tuned digital twin of a boundedly rational manager, to enable scalable and reproducible stress-testing of interactive systems against ambiguous real-world dialogue.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5522adbd58df6d202685913f2a038b91f8e5b3730f51d9964297ad57db17174e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of using LLMs for inventory management by showing that direct application incurs a "hallucination tax" due to poor stochastic reasoning. To solve this, the authors propose a hybrid agentic framework where the LLM acts as a natural-language interface that calls rigorous optimization algorithms. The framework reduces inventory costs by 32.1% compared to an LLM-only baseline, demonstrating that LLMs are best used as interfaces to make expert methods accessible, not as replacements for them.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Ask, Clarify, Optimize<br>Human-LLM Agent Collaboration] --> B[核心问题/Problem<br>LLMs as end-to-end solvers incur "hallucination tax"<br>LLMs无法进行可靠的随机推理]
        A --> C[主要方法/Method<br>Hybrid Agentic Framework<br>LLM作为接口，调用严格算法<br>语义推理与数学计算解耦]
        A --> D[关键结果/Results<br>Cost reduced by 32.1% vs baseline<br>LLMs are interfaces, not replacements<br>瓶颈是计算而非信息]
    ```

- **[arXiv260105] The Generative AI Paradox: GenAI and the Erosion of Trust, the Corrosion of Information Verification, and the Demise of Truth**
  - **tags:** [ai], [ai safety & alignment], [synthetic reality, epistemic security, provenance, trust erosion, generative AI harms]
  - **authors:** Emilio Ferrara
  - **institution:** University of Southern California (USC)
  - **link:** https://arxiv.org/pdf/2601.00306
  - **contributions:** 1. Formalizes the concept of "synthetic reality" as a layered socio-technical stack comprising content, identity, interaction, and institutions. 2. Expands a taxonomy of Generative AI harms and articulates the qualitative shifts it introduces, such as cost collapse and provenance gaps. 3. Proposes a complementary mitigation stack and a research agenda focused on measuring epistemic security, culminating in the articulation of the "Generative AI Paradox".
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88b42a2aa0b289b69471dcaa3b08e187b14ded4070e26848bb4917fcc12b2427_w640_q70.webp
  - **Simple LLM Summary:** This paper argues that the primary risk of Generative AI is not just creating fake content, but the systemic erosion of shared truth and verification practices as it enables the easy creation of synthetic content, identities, and interactions. The authors formalize this as "synthetic reality," analyze its risks, and propose a multi-layered mitigation approach. They conclude with the "Generative AI Paradox": the potential for societies to rationally discount all digital evidence as synthetic media becomes ubiquitous.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Generative AI Paradox<br>生成式AI悖论] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[GenAI erodes shared truth & verification<br>GenAI侵蚀共同认知与验证]
        C --> C1[Formalize synthetic reality stack & harms taxonomy<br>形式化合成现实栈与危害分类]
        C --> C2[Propose mitigation stack & research agenda<br>提出缓解栈与研究议程]
        D --> D1[Generative AI Paradox: discount digital evidence<br>生成式AI悖论：质疑数字证据]
    ```

- **[arXiv260105] MR-DAW: Towards Collaborative Digital Audio Workstations in Mixed Reality**
  - **tags:** [other], [Human-Computer Interaction (HCI) / Computer-Supported Cooperative Work (CSCW)], [Mixed Reality, Digital Audio Workstation, Collaborative Looping, Musical Metaverse, Speculative Design]
  - **authors:** Torin Hopkins, Shih-Yu Ma, Suibi Che-Chuan Weng, Ming-Yuan Pai, Ellen Yi-Luen Do, Luca Turchet
  - **institution:** University of Colorado Boulder, University of Trento, SolJAMM Research
  - **link:** https://arxiv.org/pdf/2601.00326
  - **contributions:** 1. Proposed and developed MR-DAW, a novel Mixed Reality system enabling multiple remote users to control a single, shared DAW instance while moving freely in their physical space. 2. Introduced a hands-free, collaborative interaction paradigm using physical foot pedals for remote, real-time looping control within the shared virtual session. 3. Conducted a qualitative study with 20 musicians to analyze current DAW practices, evaluate the MR-DAW system's usability, and provide a speculative outlook on the future of collaborative music-making in the "Musical Metaverse".
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aca28144427dc6983d2e29776070b060b46281ee589677349257b7b925ad500c_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates using Mixed Reality (MR) to overcome the limitations of traditional Digital Audio Workstations (DAWs), which tether musicians to a desk and hinder remote collaboration. The authors propose MR-DAW, a networked MR system that allows geographically dispersed musicians to control a shared DAW and use foot pedals for collaborative looping. The study with 20 musicians highlights MR's potential for unencumbered musical interaction and provides a speculative vision for future remote collaborative DAWs in the Musical Metaverse.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[MR-DAW: Towards Collaborative Digital Audio Workstations in Mixed Reality] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[DAWs束缚音乐家工作流/DAWs encumber musician workflow]
        Problem --> P2[远程协作困难/Remote collaboration is challenging]
        Method[主要方法/Method] --> M1[开发MR-DAW设计探针/Developed MR-DAW design probe]
        Method --> M2[使用脚踏板进行协作循环/Used foot pedal for collaborative looping]
        Method --> M3[定性研究与系统评估/Qualitative study & system evaluation]
        Results[关键结果/Results] --> R1[MR支持无束缚交互/MR affords unencumbered interaction]
        Results --> R2[展望音乐元宇宙未来/Speculative outlook on Musical Metaverse]
    ```

- **[arXiv260105] Effects of Limited Field of View on Musical Collaboration Experience with Avatars in Extended Reality**
  - **tags:** [other], [human-computer interaction], [extended reality, field of view, musical collaboration, co-presence, gesture recognition]
  - **authors:** Suibi Che-Chuan Weng, Torin Hopkins, Shih-Yu Ma, Amy Banic, Ellen Yi-Luen Do
  - **institution:** University of Colorado Boulder, University of Wyoming, SolJAMM Research
  - **link:** https://arxiv.org/pdf/2601.00333
  - **contributions:** 1. Conducted a comparative study investigating the specific impact of a limited field of view (FOV) on key aspects of musical collaboration in XR, such as co-presence and reaction time. 2. Proposed and evaluated a novel notification system ("Mini Musicians") designed to mitigate the negative effects of a limited FOV in AR-based musical collaboration. 3. Provided empirical evidence that while limited FOV degrades the collaborative experience, interface interventions like notifications can improve performance metrics like reaction time.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b86b1bc6e18987027d6a96d6343c561f4f8304599001862d66c5108a3cb6f3ad_w640_q70.webp
  - **Simple LLM Summary:** This paper studies how the limited field of view (FOV) in XR head-mounted displays affects musical collaboration. It compares an unrestricted holographic setup (HoloJam) with a limited-FOV AR setup and tests a notification system (Mini Musicians) to improve awareness. The results show that limited FOV reduces co-presence and enjoyment, but notification systems can help improve reaction times.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Effects of Limited FOV on Musical Collaboration in XR<br/>XR中有限视场对音乐协作的影响] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Limited FOV in XR disrupts visual cues for musicians<br/>XR中的有限视场干扰了音乐家的视觉线索]
        C --> C1[Compared HoloJam (unrestricted FOV) vs. AR glasses (52° FOV)<br/>比较HoloJam(无限制视场)与AR眼镜(52°视场)]
        C --> C2[Tested AR notification system "Mini Musicians"<br/>测试AR通知系统"Mini Musicians"]
        D --> D1[HoloJam: higher co-presence & enjoyment<br/>HoloJam: 更高的共在感与愉悦度]
        D --> D2[Mini Musicians: reduced reaction time<br/>Mini Musicians: 降低了反应时间]
    ```

- **[arXiv260105] Unseen Risks of Clinical Speech-to-Text Systems: Transparency, Privacy, and Reliability Challenges in AI-Driven Documentation**
  - **tags:** [other], [human-computer interaction (HCI) in healthcare], [speech-to-text (STT), socio-technical framework, clinical documentation, governance, patient autonomy]
  - **authors:** Nelly Elsayed
  - **institution:** University of Cincinnati
  - **link:** https://arxiv.org/pdf/2601.00382
  - **contributions:** 1. Synthesis of interdisciplinary evidence to identify key socio-technical risks of clinical STT systems. 2. Development of a multi-layered socio-technical conceptual framework for evaluating and governing STT systems. 3. Provision of a structured implementation roadmap for responsible and equitable STT adoption in healthcare.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/627d7cc2565b3e0e4364bcbd09fce3b63a8dceb715f9b162a42b7c6ff653b67c_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the socio-technical risks of AI-driven speech-to-text systems in clinical settings, such as transparency and reliability issues. It proposes a governance framework and implementation roadmap by synthesizing evidence from technical, ethical, and workflow studies. The main conclusion is that safe integration requires addressing the interdependence of model performance, clinician oversight, patient rights, and institutional governance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Unseen Risks of Clinical Speech-to-Text Systems<br/>临床语音转文本系统的未知风险] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[AI STT 部署快于风险理解<br/>AI STT Deployment Outpaces Risk Understanding]
        C --> C1[综合多学科证据<br/>Synthesize Interdisciplinary Evidence]
        D --> D1[提出治理框架与路线图<br/>Propose Governance Framework & Roadmap]
    ```

- **[arXiv260105] Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation**
  - **tags:** [mlsys], [agent system], [agentic AI, distributed agents, human-AI co-creation, progressive ideation, meta-cognitive workflow]
  - **authors:** Sankar B, Srinidhi Ranjini Girish, Aadya Bharti, Dibakar Sen
  - **institution:** Indian Institute of Science (IISc)
  - **link:** https://arxiv.org/pdf/2601.00475
  - **contributions:** 1. Proposes MIDAS, a novel framework that replaces single-AI systems with a distributed team of specialized AI agents for ideation. 2. Emulates a human meta-cognitive workflow to progressively refine ideas and assess them for both global and local novelty. 3. Establishes a new paradigm for human-AI co-creation, elevating the human from a passive filter to an active collaborative partner.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dee9a17774f8f69cd3f3a19a0507461cd7a05a21b3f1dec4db23b9a0a1c9bfa_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of AI systems generating semantically clustered ideas that hinder novel ideation in engineering design. It proposes the MIDAS framework, which uses a distributed team of specialized AI agents to progressively refine and assess ideas for novelty. This approach enables true human-AI co-creation, making the human designer an active partner rather than a passive filter.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Progressive Ideation using an Agentic AI Framework<br>渐进式构思的智能体AI框架] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[AI生成想法语义聚类<br>AI-generated ideas are semantically clustered]
        B --> B2[新手设计师构思困难<br>Ideation is challenging for novice designers]
        C --> C1[提出MIDAS框架<br>Propose MIDAS framework]
        C1 --> C2[分布式专业AI智能体团队<br>Distributed team of specialized AI agents]
        C2 --> C3[模拟元认知工作流<br>Emulate meta-cognitive workflow]
        D --> D1[渐进式提炼与评估想法<br>Progressively refines and assesses ideas]
        D --> D2[实现人-AI协同创造<br>Enables true human-AI co-creation]
    ```

- **[arXiv260105] User Perceptions of an LLM-Based Chatbot for Cognitive Reappraisal of Stress: Feasibility Study**
  - **tags:** [nlp], [conversational ai for mental health], [cognitive reappraisal, single-session intervention (SSI), GPT-4o, RoBERTa classifiers, thematic analysis]
  - **authors:** Ananya Bhattacharjee, Jina Suh, Mohit Chandra, Javier Hernandez
  - **institution:** Stanford University, University of Toronto, Microsoft Research, Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.00570
  - **contributions:** 1. Developed and evaluated an LLM-based chatbot for delivering a structured cognitive reappraisal intervention for workplace stress, demonstrating its feasibility. 2. Employed a multi-method analysis combining quantitative self-reports, automated sentiment/stress trajectory analysis, and qualitative thematic analysis to assess outcomes and user experience. 3. Identified key design tensions in LLM-based DMH tools, such as scriptedness vs. flexibility, interaction length, and reactions to AI-driven empathy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/93f7db6a0dc26c21ee37cc461c2756b2a35d6c50c897f26162c9abb735305bf9_w640_q70.webp
  - **Simple LLM Summary:** This study developed a GPT-4o-based chatbot to deliver a single-session cognitive reappraisal intervention for workplace stress. The feasibility study with 100 employees showed significant short-term reductions in perceived stress intensity and improvements in stress mindset, while also revealing user-perceived design tensions. The findings highlight the potential and constraints of using conversational LLMs in structured digital mental health tools.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[User Perceptions of an LLM-Based Chatbot for Cognitive Reappraisal of Stress: Feasibility Study] --> B[核心问题/Problem: DMH tools struggle with rigid scripts for flexible stress reappraisal]
        A --> C[主要方法/Method: GPT-4o chatbot delivers structured SSI; Multi-method analysis (pre-post tests, RoBERTa/LLM classifiers, thematic analysis)]
        A --> D[关键结果/Results: Stress intensity ↓, mindset ↑; Sentiment/stress decline during chat; Tensions around scriptedness & AI empathy]
    ```

- **[arXiv260105] The AI Invisibility Effect: Understanding Human-AI Interaction When Users Don't Recognize Artificial Intelligence**
  - **tags:** [ai], [human-ai interaction], [sentiment classification, topic modeling, concern-benefit categorization]
  - **authors:** Obada Kraishan
  - **institution:** Texas Tech University
  - **link:** https://arxiv.org/pdf/2601.00579
  - **contributions:** 1. Identified the "AI invisibility effect": a major disconnect where only 11.9% of reviews mention AI despite 47.4% of apps featuring it, suggesting AI often operates below user awareness. 2. Revealed a hidden pattern where AI's negative impact on app ratings reverses when users explicitly recognize it, indicating recognition, not mere presence, drives negative evaluations. 3. Quantified category-specific effects and user concerns, showing privacy as the dominant concern (34.8%) and efficiency as the primary benefit (42.3%), with effects varying from positive for Assistant apps to negative for Entertainment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1c4b615742aa54b3187cdf8aa78760299e2e2352b5db6bec86f259ad28dfcb4_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how users perceive AI in mobile apps through a large-scale analysis of 1.5 million app reviews. Using sentiment classification, topic modeling, and categorization, it finds that AI features are often unrecognized by users, and it is this explicit recognition, not the AI's presence, that correlates with negative evaluations, challenging assumptions about technology acceptance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["The AI Invisibility Effect"] --> Problem["核心问题/Problem: User perception of AI in mobile apps is poorly understood."]
        Root --> Method["主要方法/Method: Large-scale analysis of app reviews using sentiment classification, topic modeling, and categorization."]
        Root --> Results["关键结果/Results: AI often invisible; recognition drives negative ratings; privacy top concern, efficiency top benefit."]
    ```

- **[arXiv260105] Evaluating Web Accessibility and Usability in Bangladesh: A Comparative Analysis of Government and Non-Government Websites**
  - **tags:** [other], [web accessibility evaluation], [WCAG 2.2, automated accessibility assessment, user survey, digital inclusion, usability evaluation]
  - **authors:** Sanjida Islam Era, Ishika Tarin Ime, A. B. M. Alim Al Islam
  - **institution:** Bangladesh University of Engineering and Technology
  - **link:** https://arxiv.org/pdf/2601.00592
  - **contributions:** 1. Conducted a large-scale comparative evaluation of 212 Bangladeshi government and non-government websites for accessibility and usability. 2. Combined automated WCAG 2.2 compliance testing with user-reported feedback from 103 participants for a holistic assessment. 3. Identified and analyzed specific disparities and persistent barriers (e.g., navigation complexity, accessibility feature adoption) between the two website categories.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1dcc467092506358305a3271b80be39333c5a6f1a26c2602953cbd607b99e44_w640_q70.webp
  - **Simple LLM Summary:** This study evaluates the accessibility and usability of Bangladeshi government and non-government websites by combining automated WCAG 2.2 assessments with a user survey. The results show significant disparities, with non-government sites generally performing better on usability but both categories having inconsistent accessibility support. The findings highlight the need for regular audits and user-centered design to improve digital inclusivity.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Evaluating Web Accessibility and Usability in Bangladesh<br>评估孟加拉国的网络可访问性与可用性] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Critical websites have accessibility & usability barriers<br>关键网站存在可访问性和可用性障碍]
        C[主要方法/Method<br>Automated WCAG 2.2 tests + User survey (103 users)<br>自动化WCAG 2.2测试 + 用户调查(103人)]
        D[关键结果/Results<br>Disparities between gov/non-gov sites, inconsistent accessibility<br>政府与非政府网站存在差异，可访问性支持不一致]
    ```

- **[arXiv260105] Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation**
  - **tags:** [cv], [talking head generation], [diffusion forcing, direct preference optimization, real-time interaction, low latency, multimodal inputs]
  - **authors:** Taekyung Ki, Sangwon Jang, Jaehyeong Jo, Jaehong Yoon, Sung Ju Hwang
  - **institution:** KAIST, NTU Singapore, DeepAuto.ai
  - **link:** https://arxiv.org/pdf/2601.00664
  - **code:** https://taekyungki.github.io/AvatarForcing
  - **contributions:** 1. Proposes Avatar Forcing, a framework using diffusion forcing for real-time interactive head avatar generation that processes multimodal user inputs with low latency. 2. Introduces a label-free direct preference optimization method using synthetic losing samples to learn expressive interactions. 3. Demonstrates real-time performance (~500ms latency, 6.8x speedup) and generates avatars preferred over 80% against the baseline for expressiveness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17340b71396da059acb45bce5718d0e4a786ccf313c43918ba84c25b9384bb11_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of truly interactive and emotionally engaging talking head avatars by proposing Avatar Forcing, a framework that uses diffusion forcing for real-time, low-latency generation and a direct preference optimization method for label-free learning of expressive reactions. The method achieves a significant speedup and produces avatar motions that are strongly preferred by users in evaluations.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Avatar Forcing: Real-Time Interactive Head Avatar Generation] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[缺乏真正互动/Lacks truly interactive communication]
        Problem --> P2[单向反应缺乏情感/One-way responses lack emotional engagement]
        Method[主要方法/Method] --> M1[扩散驱动框架/Diffusion forcing framework]
        Method --> M2[无标签直接偏好优化/Label-free direct preference optimization]
        Results[关键结果/Results] --> R1[低延迟实时交互/Low-latency real-time interaction (~500ms)]
        Results --> R2[6.8倍加速/6.8x speedup]
        Results --> R3[80%用户偏好/Over 80% user preference]
    ```

- **[arXiv260105] Wave2Word: A Multimodal Transformer Framework for Joint EEG-Text Alignment and Multi-Task Representation Learning in Neurocritical Care**
  - **tags:** [ai], [multimodal learning], [EEG-text alignment, contrastive learning, transformer encoders, time-frequency representation, neurocritical care]
  - **authors:** Argha Kamal Samanta, Deepak Mewada, Monalisa Sarma, Debasis Samanta
  - **institution:** Indian Institute of Technology Kharagpur
  - **link:** https://arxiv.org/pdf/2601.00670
  - **contributions:** 1. Proposed a multimodal framework that aligns EEG signal embeddings with structured clinical text descriptions using a contrastive objective. 2. Introduced dual transformer-based encoders for complementary temporal and frequency-centric modeling, fused via an adaptive gating mechanism. 3. Introduced an EEG-conditioned text reconstruction loss as a representation-level constraint alongside classification, demonstrating that classification accuracy alone is insufficient for evaluating clinically meaningful EEG representations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/234d66f4587d5e7ce5f9b2130c03b8b16a9d880449f62b6335ed7f836b7e49ca_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Wave2Word, a multimodal transformer framework that learns EEG representations by aligning them with clinical text descriptions using contrastive learning and a text reconstruction task. It achieves high classification accuracy (0.9797) but crucially shows that removing the alignment component drastically harms cross-modal retrieval performance, proving that standard accuracy metrics do not reflect representation quality for clinical EEG modeling.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Wave2Word: A Multimodal Transformer Framework] --> B[核心问题/Problem: Weak correspondence between learned EEG representations and clinical interpretation]
        A --> C[主要方法/Method: Dual transformer encoders + EEG-text contrastive alignment + EEG-conditioned text reconstruction]
        A --> D[关键结果/Results: High classification accuracy (0.9797); Ablation shows contrastive alignment is critical for cross-modal retrieval (Recall@10 drops from 0.3390 to 0.0045)]
    ```

- **[arXiv260105] Calling for Backup: How Children Navigate Successive Robot Communication Failures**
  - **tags:** [other], [human-robot interaction], [successive robot error, child-robot interaction, error recovery, performance error, social error]
  - **authors:** Maria Teresa Parreira, Isabel Neto, Filipa Rocha, Wendy Ju
  - **institution:** Cornell University, Universidade de Lisboa
  - **link:** https://arxiv.org/pdf/2601.00754
  - **contributions:** 1. Reproduced the successive robot failure paradigm with children (ages 8-10) to explore their unique responses to repeated conversational errors. 2. Identified key behavioral differences between children and adults, such as children's increased disengagement (e.g., ignoring the robot, seeking adult help) and more flexible conversational expectations. 3. Provided empirical findings to inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6516606de03da03b1c7297f4e0a7fcb61612ec1bea932c4290e5d1ba746ac52a_w640_q70.webp
  - **Simple LLM Summary:** This study investigates how children respond to repeated robot communication failures by reproducing an adult-focused error paradigm with child participants. The method involved children interacting with a robot that failed to understand their prompts three times, with their behavioral responses recorded and analyzed. The main conclusion is that while children share some error-response strategies with adults, they exhibit more disengagement behaviors and maintain a stable perception of the robot, suggesting different interaction needs that should guide robot design for young users.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Calling for Backup: How Children Navigate Successive Robot Communication Failures] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[儿童对连续机器人错误的反应/Children's response to successive robot errors]
        C --> C1[复制成人研究范式，与儿童进行机器人交互/Reproduce adult study paradigm, child-robot interaction]
        C --> C2[分析行为视频记录/Analyze behavioral video recordings]
        D --> D1[儿童与成人反应的异同/Similarities and differences vs. adult responses]
        D --> D2[更多脱离行为，如寻求成人帮助/More disengagement, e.g., seeking adult help]
        D --> D3[对机器人的感知未受影响/Robot perception unaffected]
    ```

- **[arXiv260105] The Effect of Transparency on Students' Perceptions of AI Graders**
  - **tags:** [nlp], [automated short answer grading], [autograding, transparency, student perceptions, natural language processing, educational technology]
  - **authors:** Joslyn Orgill, Andra Rice, Max Fowler, Seth Poulsen
  - **institution:** University of Illinois Urbana-Champaign, Utah State University
  - **link:** https://arxiv.org/pdf/2601.00765
  - **contributions:** 1. Investigated the effect of transparency on student attitudes towards AI-based autograders. 2. Found that transparency specifically increased perceptions of accuracy and willingness to discuss the autograder. 3. Provided evidence that baseline trust levels may moderate the impact of transparency interventions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbaf43a4643b4004e18e00c3c13ff6e5941b23fdbb39e479514e725d1f9ab0bb_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether making AI autograders more transparent improves students' perceptions of them. The study found that transparency increased students' views on the autograder's accuracy and their willingness to comment on it, but did not improve other attitudes like willingness to be graded by it on a test, possibly due to high baseline trust.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Effect of Transparency on Students' Perceptions of AI Graders] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[学生不总是喜欢或信任自动评分器/Students do not always like or trust autograders]
        C --> C1[测试透明度对态度的影响/Test effect of transparency on attitudes]
        D --> D1[透明度提高了准确性感知和讨论意愿/Transparency increased perceived accuracy & willingness to discuss]
        D --> D2[未改善其他态度如测试评分意愿/Did not improve other attitudes e.g., willingness for test grading]
        D --> D3[高初始信任可能削弱影响/High initial trust may weaken impact]
    ```
