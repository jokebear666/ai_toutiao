---
slug: /daily/csir/20251222-20251228
---
# 20251222-20251228 (cs.IR)

## 2025-12-22

- **[arXiv251222] V-Agent: An Interactive Video Search System Using Vision-Language Models**
  - **tags:** [mlsys], [multi-modal inference], [vision-language model, fine-tuning, retrieval vector, re-ranking, multi-agent system]
  - **authors:** SunYoung Park, Jong-Hyeon Lee, Youngjune Kim, Daegyu Sung, Younghyun Yu, Young-rok Cha, Jeongho Ju
  - **institution:** NC AI, Kakao, Korea Advanced Institute of Science and Technology (KAIST)
  - **link:** https://arxiv.org/pdf/2512.16925
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e827044257e239766415ac9500a06f7ddb67bfc47c517c041d42cc61ac33ad18_w640_q70.webp
  - **Simple LLM Summary:** V-Agent is a multi-agent video search system that fine-tunes a vision-language model with a small video preference dataset and enhances it with a retrieval vector to embed video frames and audio transcriptions into a shared multimodal space. It uses three agents—routing, search, and chat—to refine searches and interact with users, achieving state-of-the-art zero-shot performance on the MultiVENT 2.0 benchmark.

- **[arXiv251222] Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations**
  - **tags:** [mlsys], [others], [search engine audit, semantic alignment, topical annotation, trajectory analysis]
  - **authors:** Erica Coppolillo, Simone Mungari
  - **institution:** University of Calabria, ICAR-CNR, University of Southern California
  - **link:** https://arxiv.org/pdf/2512.17027
  - **Simple LLM Summary:** The paper conducts a comparative audit of search engine recommendations on Wikipedia and Grokipedia by analyzing over 70,000 results from nearly 10,000 neutral English word queries. It finds that both platforms frequently generate weakly related or unexpected results from innocuous queries, though their recommendation sets often differ substantially in topical distribution and exploration trajectories.

- **[arXiv251222] ABE-CLIP: Training-Free Attribute Binding Enhancement for Compositional Image-Text Matching**
  - **tags:** [mlsys], [multi-modal inference], [CLIP, semantic refinement mechanism, local token-patch alignment, attribute-object binding, compositional image-text matching]
  - **authors:** Qi Zhang, Yuxu Chen, Lei Deng, Lili Shen
  - **institution:** Sichuan University
  - **link:** https://arxiv.org/pdf/2512.17178
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea9a6c4b5b64bc9b1ed96212005ee492c3fd2ae615fc413250d7a6ef7c3bc712_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes ABE-CLIP, a training-free method to enhance attribute-object binding in CLIP models. It uses a semantic refinement mechanism to improve text token embeddings and a local token-patch alignment strategy to compute image-text similarity. Experiments show the method significantly improves compositional matching performance, even surpassing some trained approaches.

- **[arXiv251222] Warmer for Less: A Cost-Efficient Strategy for Cold-Start Recommendations at Pinterest**
  - **tags:** [mlsys], [others], [residual connection, score regularization, manifold mixup]
  - **authors:** Saeed Ebrahimi, Weijie Jiang, Jaewon Yang, Olafur Gudmundsson, Yucheng Tu, Huizhong Duan
  - **institution:** Pinterest
  - **link:** https://arxiv.org/pdf/2512.17277
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f351bf91dbfa3f8f187d67a36cb3c88f1014690a13606c70e860bd376621c71f_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes a cost-efficient strategy to improve cold-start recommendations by introducing lightweight techniques: a residual connection for non-historical features, a score regularization term, and manifold mixup for data sparsity. These methods collectively increased fresh content engagement by 10% without harming overall engagement or cost, and have been deployed at Pinterest.

- **[arXiv251222] A Systematic Reproducibility Study of BSARec for Sequential Recommendation**
  - **tags:** [ai], [sequential recommendation], [BSARec, Transformer, Fourier transform, discrete wavelet transform, padding strategies, frequency rescaling]
  - **authors:** Jan Hutter, Hua Chang Bakker, Stan Fris, Madelon Bernardy, Yuanna Liu
  - **institution:** University of Amsterdam
  - **link:** https://arxiv.org/pdf/2512.17442
  - **Simple LLM Summary:** This paper reproduces and evaluates BSARec, a sequential recommendation method that enhances Transformer encoders with a frequency layer using Fourier transforms to capture high-frequency signals. The study finds that BSARec outperforms other methods on some datasets, but digital signal processing techniques like discrete wavelet transform offer only marginal improvements over Fourier transforms, and non-constant padding significantly boosts performance while constant padding hinders high-frequency signal capture.

- **[arXiv251222] Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application**
  - **tags:** [ai], [marketing personalisation], [randomised controlled trial, agentic messaging, rule-based campaign, causal inference, contextual bandits]
  - **authors:** Olivier Jeunen, Schaun Wheeler
  - **institution:** aampe
  - **link:** https://arxiv.org/pdf/2512.17462
  - **Simple LLM Summary:** This paper evaluates an agentic messaging approach for customer communication, comparing it against a traditional rule-based system in a financial service application via a randomized controlled trial. The results show that the agentic system reduced unsubscribe events by 21% and encouraged earlier tax filing, demonstrating its effectiveness in improving user engagement and retention.

- **[arXiv251222] Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure**
  - **tags:** [ai], [recommendation systems], [causal deconfounding, LightGCN, Unbiased Asymmetric Co-purchase Relationship (UACR), counterfactual exposure, BPR loss]
  - **authors:** Jingmao Zhang, Zhiting Zhao, Yunqi Lin, Jianghong Ma, Tianjun Wei, Haijun Zhang, Xiaofeng Zhang
  - **institution:** Harbin Institute of Technology (Shenzhen), Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.17733
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d0101cc9ad451bf594fefde69475b9ae7433ae4f0ec8954e841150d68840d01_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Cadence, a plug-and-play framework built on LightGCN that uses causal deconfounding to compute unbiased item-item relationships and counterfactual exposure simulation to enhance recommendation diversity. The method constructs a deconfounded directed item graph and identifies diverse, causally relevant items a user has not interacted with. Experiments show it outperforms state-of-the-art models in both diversity and accuracy.

- **[arXiv251222] Intelligent Knowledge Mining Framework: Bridging AI Analysis and Trustworthy Preservation**
  - **tags:** [mlsys], [others], [Knowledge Mining, Digital Preservation, Semantic Web, Data Integration, Dual-Stream Architecture]
  - **authors:** Binh Vu
  - **institution:** FernUniversität in Hagen
  - **link:** https://arxiv.org/pdf/2512.17795
  - **Simple LLM Summary:** The paper proposes the Intelligent Knowledge Mining Framework (IKMF), a conceptual dual-stream architecture that combines a horizontal AI-driven mining process with a parallel trustworthy archiving stream. It aims to bridge the gap between dynamic analysis and long-term preservation, transforming static data repositories into living, actionable knowledge ecosystems.

## 2025-12-23

- **[arXiv251223] Factorized Transport Alignment for Multimodal and Multiview E-commerce Representation Learning**
  - **tags:** TBD
  - **authors:** Xiwen Chen, Yen-Chieh Lien, Susan Liu, María Castaños, Abolfazl Razi, Xiaoting Zhao, Congzhe Su
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18117
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54d34ab26112b6d842aa7d95d121b9688afb4448ef70a36cd3b95fb4d5a05c30_w640_q70.webp
  - **Simple LLM Summary:** Factorized Transport Alignment for Multimodal and Multiview E-commerce Representation Learning

- **[arXiv251223] Improving Data Reusability in Interactive Information Retrieval: Insights from the Community**
  - **tags:** TBD
  - **authors:** Tianji Jiang, Wenqi Li, Jiqun Liu
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18283
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad5fd35b3eb397c1cdccdf1de651dbc282de84bed1120a1a715ed8c742a75b03_w640_q70.webp
  - **Simple LLM Summary:** Improving Data Reusability in Interactive Information Retrieval: Insights from the Community

- **[arXiv251223] Datasets for machine learning and for assessing the intelligence level of automatic patent search systems**
  - **tags:** TBD
  - **authors:** Boris Genin, Alexander Gorbunov, Dmitry Zolkin, Igor Nekrasov
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18384
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac80e35326c113d249d5bd28c4aafe01da23a8e0c681cde84257daab6b92b651_w640_q70.webp
  - **Simple LLM Summary:** Datasets for machine learning and for assessing the intelligence level of automatic patent search systems

- **[arXiv251223] Efficient Optimization of Hierarchical Identifiers for Generative Recommendation**
  - **tags:** TBD
  - **authors:** Federica Valeau, Odysseas Boufalis, Polytimi Gkotsi, Joshua Rosenthal, David Vos
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18434
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9351bb1bdc8edb2cb50c73d61a8cbfe17eefd091e911a8e3f3f3df8e19c8ee7_w640_q70.webp
  - **Simple LLM Summary:** Efficient Optimization of Hierarchical Identifiers for Generative Recommendation

- **[arXiv251223] CIRR: Causal-Invariant Retrieval-Augmented Recommendation with Faithful Explanations under Distribution Shift**
  - **tags:** TBD
  - **authors:** Sebastian Sun
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18683
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/774fd9266a894d1c9a35161bf04dd7ead5c3acad03d8d090d9728f6f69f12262_w640_q70.webp
  - **Simple LLM Summary:** CIRR: Causal-Invariant Retrieval-Augmented Recommendation with Faithful Explanations under Distribution Shift

- **[arXiv251223] Modular Layout Synthesis (MLS): Front-end Code via Structure Normalization and Constrained Generation**
  - **tags:** TBD
  - **authors:** Chong Liu, Ming Zhang, Fei Li, Hao Zhou, Xiaoshuang Chen, Ye Yuan
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18996
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bc934518ca031428cca5fd8c00520837bb98e48a55a7433a62c9c6ec593d172_w640_q70.webp
  - **Simple LLM Summary:** Modular Layout Synthesis (MLS): Front-end Code via Structure Normalization and Constrained Generation

- **[arXiv251223] QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation**
  - **tags:** TBD
  - **authors:** Dehai Min, Kailin Zhang, Tongtong Wu, Lu Cheng
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19134
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/829ce6a74a55abeea6f6d10fec5338ad05441e95283687a525b0f2525bbf8a12_w640_q70.webp
  - **Simple LLM Summary:** QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation

- **[arXiv251223] Generative vector search to improve pathology foundation models across multimodal vision-language tasks**
  - **tags:** TBD
  - **authors:** Markus Ekvall, Ludvig Bergenstråhle, Patrick Truong, Ben Murrell, Joakim Lundeberg
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19360
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e4366142df495ffd095e4dff889e4df1f04fade9bef7320147bdd655dab870fd_w640_q70.webp
  - **Simple LLM Summary:** Generative vector search to improve pathology foundation models across multimodal vision-language tasks

## 2025-12-24

- **[arXiv251224] Towards Analysing Invoices and Receipts with Amazon Textract**
  - **tags:** TBD
  - **authors:** Sneha Oommen, Gabby Sanchez, Cassandra T. Britto, Di Wang, Jordan Chiou, Maria Spichkova
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19958
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8027409d62cb78b143f7d21e2c36fb093ab6a4978dfa9fe88c1a8339d40565fd_w640_q70.webp
  - **Simple LLM Summary:** Towards Analysing Invoices and Receipts with Amazon Textract

- **[arXiv251224] IGDMRec: Behavior Conditioned Item Graph Diffusion for Multimodal Recommendation**
  - **tags:** TBD
  - **authors:** Ziyuan Guo, Jie Guo, Zhenghao Chen, Bin Song, Fei Richard Yu
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19983
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d1b0c632ea03f65951be60ec7a07744efabc63fd50bc3718c0feceaf6929db4_w640_q70.webp
  - **Simple LLM Summary:** IGDMRec: Behavior Conditioned Item Graph Diffusion for Multimodal Recommendation

- **[arXiv251224] LLM-Assisted Abstract Screening with OLIVER: Evaluating Calibration and Single-Model vs. Actor-Critic Configurations in Literature Reviews**
  - **tags:** TBD
  - **authors:** Kian Godhwani, David Benrimoh
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20022
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd553d2c8dfa3e24074d8dc0752a5348a2dc9e7e83526071de4a16c28bb018b6_w640_q70.png
  - **Simple LLM Summary:** LLM-Assisted Abstract Screening with OLIVER: Evaluating Calibration and Single-Model vs. Actor-Critic Configurations in Literature Reviews

- **[arXiv251224] VSA:Visual-Structural Alignment for UI-to-Code**
  - **tags:** TBD
  - **authors:** Xian Wu, Ming Zhang, Zhiyu Fang, Fei Li, Bin Wang, Yong Jiang, Hao Zhou
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20034
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96d552b0d871e15200119995d18b2c4223e07f8d868c7cc4caaa9ee14883b636_w640_q70.webp
  - **Simple LLM Summary:** VSA:Visual-Structural Alignment for UI-to-Code

- **[arXiv251224] Retrieval-augmented Prompt Learning for Pre-trained Foundation Models**
  - **tags:** TBD
  - **authors:** Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20145
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028ab8e7171d7f497cbdc48e136d419e8642bf876111786382aee29b15d0992_w640_q70.webp
  - **Simple LLM Summary:** Retrieval-augmented Prompt Learning for Pre-trained Foundation Models

- **[arXiv251224] Collaborative Group-Aware Hashing for Fast Recommender Systems**
  - **tags:** TBD
  - **authors:** Yan Zhang, Li Deng, Lixin Duan, Ivor W. Tsang, Guowu Yang
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20172
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88ca67dd050ef45a91576d3d9023639ade9c0749505763fab48ef17a2472cf5d_w640_q70.webp
  - **Simple LLM Summary:** Collaborative Group-Aware Hashing for Fast Recommender Systems

- **[arXiv251224] Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark**
  - **tags:** TBD
  - **authors:** Hao Guo, Xugong Qin, Jun Jie Ou Yang, Peng Zhang, Gangyan Zeng, Yubo Li, Hailun Lin
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20174
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a74295652803d99c4b0631ef38e9684d12032ddd9797f217033f356497ff647_w640_q70.webp
  - **Simple LLM Summary:** Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark

- **[arXiv251224] Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds**
  - **tags:** TBD
  - **authors:** Tarik Houichime, Abdelghani Souhar, Younes El Amrani
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20245
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1001e3781e678219db00950fa667bbe46bbaa2f98cd7e5064d91ede9a2cbc6fe_w640_q70.webp
  - **Simple LLM Summary:** Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds

- **[arXiv251224] Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register**
  - **tags:** TBD
  - **authors:** Shuting Wang, Qiaolin Xia, Hao Wang, Yu Lu, Bobsimons, Zhicheng Dou
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20458
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a13a1563c00a3e27fe1f913d8759ce111fa71a7790c6903507a37b4af30d53cf_w640_q70.webp
  - **Simple LLM Summary:** Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register

- **[arXiv251224] Making Large Language Models Efficient Dense Retrievers**
  - **tags:** TBD
  - **authors:** Yibin Lei, Shwai He, Ang Li, Andrew Yates
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.20612
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40238eef858f9a1a1327758d04b0c4c31e71fbbf6df6898a51ccf0f7ff9a8f36_w640_q70.webp
  - **Simple LLM Summary:** Making Large Language Models Efficient Dense Retrievers

- **[arXiv251224] ASK: Adaptive Self-improving Knowledge Framework for Audio Text Retrieval**
  - **tags:** TBD
  - **authors:** Siyuan Fu, Xuchen Guo, Mingjun Liu, Hongxiang Li, Boyin Tan, Gongxi Zhu, Xianwei Zhuang, Jinghan Ru, Yuxin Xie, Yuguo Yin
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19703
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ac2c582d6058b0a98adaddd2fc52e7fcb4b2f111f05471b7984fd691dc97aed_w640_q70.webp
  - **Simple LLM Summary:** ASK: Adaptive Self-improving Knowledge Framework for Audio Text Retrieval

- **[arXiv251224] Towards a point-to-point CV-QKD system: Implementation challenges and perspectives**
  - **tags:** TBD
  - **authors:** Davi Juvêncio Gomes de Sousa, Nelson Alves Ferreira Neto, Christiano M. S. Nascimento, Lucas Q. Galvão, Mauro Queiroz Nooblath Neto, Micael Andrade Dias, Cássio de Castro Silva, Braian Pinheiro da Silva, Alexandre B. Tacla, Valéria Loureiro da Silva
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19834
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfa7fbf5acad2dd0ae547f58bc198ca67d3b36ccc31ad024285f0358a08cb6c9_w640_q70.webp
  - **Simple LLM Summary:** Towards a point-to-point CV-QKD system: Implementation challenges and perspectives

## 2025-12-25

- **[arXiv251225] MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [multimodal knowledge graph, cross-modal reasoning, visual document understanding, retrieval-augmented generation, entity-centric structure]
  - **authors:** Chi-Hsiang Hsiao, Yi-Cheng Wang, Tzung-Sheng Lin, Yi-Ren Yeh, Chu-Song Chen
  - **institution:** National Taiwan University, E.SUN Financial Holding Co., Ltd., National Kaohsiung Normal University
  - **link:** https://arxiv.org/pdf/2512.20626
  - **contributions:** 1. Proposes a multimodal knowledge graph-based RAG framework that integrates visual cues into KG construction, retrieval, and answer generation for cross-modal reasoning. 2. Addresses the limitation of existing text-only KG-RAG methods by automatically building KGs that capture text-to-figure and figure-to-figure relationships. 3. Demonstrates superior performance over existing RAG approaches on both textual and multimodal question-answering tasks through comprehensive experiments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/425d6eb853edb40749e686474d27dc018d8a86017a4cd69160f9ac2081d36385_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces MegaRAG, a multimodal knowledge graph-based retrieval-augmented generation method designed to overcome the limitations of text-only RAG systems in understanding complex, long-form visual documents. It integrates visual information into the knowledge graph construction and retrieval process to enable better cross-modal reasoning. Experimental results show it consistently outperforms existing RAG methods on various question-answering tasks.
  - **Mindmap:**

    ```mermaid
    graph LR
        A[MegaRAG: 多模态知识图谱检索增强生成 / MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有RAG方法在长文档、多模态内容上理解不足 / Existing RAG struggles with long-form, multimodal document understanding]
        C --> C1[构建融合视觉线索的多模态知识图谱 / Construct multimodal KG incorporating visual cues]
        C --> C2[在多模态检索与生成中利用图谱 / Utilize KG in multimodal retrieval & generation]
        D --> D1[在全局与细粒度QA任务上超越现有方法 / Outperforms existing methods on global & fine-grained QA]
    ```

- **[arXiv251225] Soft Filtering: Guiding Zero-shot Composed Image Retrieval with Prescriptive and Proscriptive Constraints**
  - **tags:** [cv], [image retrieval], [composed image retrieval, zero-shot, multimodal llm, semantic filtering, re-ranking]
  - **authors:** Youjin Jung, Seongwoo Cho, Hyun-seok Min, Sungchul Choi
  - **institution:** Pukyong National University, Tomocube Inc.
  - **link:** https://arxiv.org/pdf/2512.20781
  - **code:** https://github.com/jjungyujin/SoFT
  - **contributions:** 1. Proposes SoFT, a training-free, plug-and-play filtering module for ZS-CIR that uses multimodal LLMs to extract prescriptive and proscriptive constraints for re-ranking. 2. Introduces a two-stage dataset pipeline to refine CIR benchmarks by constructing multi-target triplets and rewriting modification texts to handle ambiguity. 3. Demonstrates significant performance improvements on multiple CIR benchmarks (CIRR, CIRCO, FashionIQ) without modifying the base retrieval model.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1143c63f4b8369d6ea6c4b9a2d3107b565118e12056bbcf37eb527e47bc75cca_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses limitations in Zero-shot Composed Image Retrieval (ZS-CIR), where fused queries dilute information and benchmarks ignore text ambiguity. The authors propose SoFT, a method that uses multimodal LLMs to extract "must-have" and "must-avoid" constraints to filter and re-rank candidate images, and they refine evaluation datasets to better capture user intent. The approach significantly boosts retrieval performance on standard benchmarks without requiring additional training.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[SoFT: 软过滤 / Soft Filtering] --> B[问题: ZS-CIR查询信息稀释 & 文本歧义 / Problem: Query Info Dilution & Text Ambiguity]
    A --> C[方法: LLM提取指令性与禁止性约束进行重排序 / Method: LLM extracts Prescriptive & Proscriptive Constraints for Re-ranking]
    A --> D[结果: 在多个基准上性能显著提升 / Results: Significant Performance Gains on Benchmarks]
    ```

- **[arXiv251225] How important is Recall for Measuring Retrieval Quality?**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [retrieval quality, recall estimation, LLM-based evaluation, nDCG, RAG]
  - **authors:** Shelly Schwartz, Oleg Vasilyev, Randy Sawaya
  - **institution:** Primer Technologies Inc.
  - **link:** https://arxiv.org/pdf/2512.20854
  - **contributions:** 1. Evaluates established strategies for measuring retrieval quality when the total number of relevant documents (and thus recall) is unknown, by correlating metrics with LLM-based judgments of response quality. 2. Conducts experiments across multiple datasets with a low number of relevant documents (2-15) to assess these strategies. 3. Introduces a new, simple retrieval quality measure that performs well without requiring knowledge of the total number of relevant documents.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8385a132c621f6e8d9e71274fc95535412aa2b9f0d0f40e834705d3548f0a601_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of evaluating retrieval quality in realistic settings where the total number of relevant documents is unknown, making recall uncomputable. It evaluates existing strategies and proposes a new simple metric by measuring their correlation with LLM-generated response quality. The main conclusion is that a simple measure can perform effectively without needing to know the total relevant documents, offering a practical solution for dynamic knowledge bases.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[How important is Recall for Measuring Retrieval Quality?] --> B[核心问题/Problem: Realistic retrieval with unknown total relevant docs]
    A --> C[主要方法/Method: Correlate metrics with LLM response quality; propose new measure]
    A --> D[关键结果/Results: Simple measure works well without recall]
    ```

- **[arXiv251225] Accurate and Diverse Recommendations via Propensity-Weighted Linear Autoencoders**
  - **tags:** [ai], [recommender systems], [Inverse Propensity Scoring, Missing Not At Random, Linear Autoencoder, Diversity, Propensity Score]
  - **authors:** Kazuma Onishi, Katsuhiko Hayashi, Hidetaka Kamigaito
  - **institution:** Hokkaido University, The University of Tokyo, Nara Institute of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.20896
  - **code:** https://github.com/cars1015/IPS-LAE
  - **contributions:** 1. Identified that standard power-law-based Inverse Propensity Scoring (IPS) overly penalizes popular items, harming recommendation performance. 2. Proposed a novel propensity score definition using a sigmoid function on the log of item observation frequency, offering a flexible correction for popularity bias. 3. Successfully integrated the redefined propensity score into a linear autoencoder model to improve recommendation diversity without sacrificing accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3366553060af980681971cfbf2bdb6b5845b43caacef978c0195bc0df1fe29f6_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of popularity bias in recommender systems caused by Missing Not At Random (MNAR) data. It proposes a new propensity score formulation using a sigmoid function to correct for this bias more flexibly than traditional power-law methods and integrates it into a linear autoencoder. Experiments show this method significantly improves recommendation diversity while maintaining accuracy.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Accurate and Diverse Recommendations via Propensity-Weighted Linear Autoencoders] --> B[核心问题/Problem: MNAR数据导致推荐偏向热门项目，降低多样性/MNAR data causes bias towards popular items, reducing diversity]
    A --> C[主要方法/Method: 用Sigmoid函数重定义倾向性分数，并集成到线性自编码器/Redefine propensity score with sigmoid, integrate into linear autoencoder]
    A --> D[关键结果/Results: 在不牺牲准确性的前提下显著提升推荐列表多样性/Substantially improves diversity without sacrificing accuracy]
    ```

- **[arXiv251225] MMSRARec: Summarization and Retrieval Augumented Sequential Recommendation Based on Multimodal Large Language Model**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [multimodal large language model, sequential recommendation, retrieval-augmented generation, supervised fine-tuning, multi-task learning]
  - **authors:** Haoyu Wang, Yitong Wang, Jining Wang
  - **institution:** Fudan University
  - **link:** https://arxiv.org/pdf/2512.20916
  - **contributions:** 1. Proposes a method to use MLLMs to adaptively summarize multimodal items into concise keywords via fine-tuning with a custom reward function. 2. Integrates collaborative signals into the recommendation process by transforming them into keywords and using them as supplementary context, inspired by RAG. 3. Aligns the MLLM for multimodal sequential recommendation through supervised fine-tuning with multi-task learning, balancing performance, interpretability, and computational cost.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24628be848ba62fad6bf4a863ec676471dac0625d17315b1ad3a57018467d1d9_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes MMSRARec, a method that uses a Multimodal Large Language Model (MLLM) to summarize user behavior sequences and integrate collaborative signals for sequential recommendation. The approach fine-tunes the MLLM with adaptive summarization and retrieval-augmented context to improve efficiency and interpretability. Evaluations show it effectively understands user histories for accurate recommendations.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[MMSRARec] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[现有MLLM推荐方法存在局限性/Existing MLLM Rec Methods Have Limitations]
    C --> C1[自适应多模态摘要/Adaptive Multimodal Summarization]
    C --> C2[检索增强协同信号/Retrieval-Augmented Collaborative Signals]
    C --> C3[监督微调与多任务学习/Supervised Fine-Tuning & Multi-Task Learning]
    D --> D1[高效且可解释的推荐/Effective & Interpretable Recommendation]
    ```

- **[arXiv251225] MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment**
  - **tags:** [nlp], [crosslingual information retrieval], [dual-encoder, contrastive learning, hard negative sampling, data augmentation, multi-source alignment]
  - **authors:** Mohammad Mahdi Abootorabi, Alireza Ghahramani Kure, Mohammadali Mohammadkhani, Sina Elahimanesh, Mohammad Ali Ali Panah
  - **institution:** Based on the provided email domains (gmail.com), no specific institution can be reliably inferred. The team name is "MultiMind".
  - **link:** https://arxiv.org/pdf/2512.20950
  - **contributions:** 1. Introduces TriAligner, a novel dual-encoder architecture with contrastive learning for crosslingual claim retrieval. 2. Proposes a method to learn the relative importance of different information sources (e.g., native text, English translations) for alignment. 3. Enhances robustness through LLM-based data preprocessing/augmentation and hard negative sampling strategies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccb6e1762a9617f640573a86ea65e0e68afff48d53006aa74213e0a557970889_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of retrieving fact-checked claims across multiple languages to combat misinformation. The proposed TriAligner system uses a dual-encoder with contrastive learning and multi-source alignment, enhanced by LLM-based data processing. The method shows significant improvements in retrieval accuracy on monolingual and crosslingual benchmarks.
  - **Mindmap:**

    ```mermaid
    graph LR
        A[MultiMind at SemEval-2025 Task 7<br>Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment] --> B(核心问题/Problem: Rapid spread of multilingual misinformation);
        A --> C(主要方法/Method: TriAligner - dual-encoder with contrastive learning & multi-source alignment);
        A --> D(关键结果/Results: Improved retrieval accuracy on benchmarks);
    ```

- **[arXiv251225] Towards Better Search with Domain-Aware Text Embeddings for C2C Marketplaces**
  - **tags:** [nlp], [text embeddings], [Matryoshka Representation Learning, role-specific prefixes, purchase-driven fine-tuning]
  - **authors:** Andre Rusli, Miao Cao, Shoma Ishimoto, Sho Akiyama, Max Frenzel
  - **institution:** Mercari, Inc.
  - **link:** https://arxiv.org/pdf/2512.21021
  - **contributions:** 1. Proposed a domain-aware Japanese text-embedding model fine-tuned on purchase-driven query-title pairs for C2C marketplace search. 2. Introduced the use of role-specific prefixes to model the query-item asymmetry inherent in search tasks. 3. Applied Matryoshka Representation Learning to create compact, truncation-robust embeddings that meet production latency and throughput constraints.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9f78c022541a8ea7125744d1404efda5d54f335700045da22b53146a30bf9632_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of improving search relevance in noisy, user-generated C2C marketplaces by fine-tuning a Japanese text-embedding model with role-specific prefixes and Matryoshka Representation Learning. The method produces compact embeddings that are robust to truncation for efficiency. Offline and online evaluations show significant improvements in retrieval quality and business metrics, providing a practical foundation for enhanced search experiences.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[Towards Better Search with Domain-Aware Text Embeddings for C2C Marketplaces] --> B[核心问题/Problem: C2C搜索挑战<br>Short queries, Noisy listings, Production constraints]
    A --> C[主要方法/Method: 领域感知嵌入<br>Domain-aware embeddings via fine-tuning, Role prefixes, Matryoshka Learning]
    A --> D[关键结果/Results: 离线与在线提升<br>Offline gains, Online revenue & efficiency improvements]
    ```

- **[arXiv251225] Agentic Multi-Persona Framework for Evidence-Aware Fake News Detection**
  - **tags:** [nlp], [misinformation detection], [multi-persona agent, LLM-SLM synergy, evidence-grounded, multimodal fusion, credibility fusion]
  - **authors:** Roopa Bukke, Soumya Pandey, Suraj Kumar, Soumi Chattopadhyay, Chandranath Adak
  - **institution:** Indian Institute of Technology (Indore, Patna)
  - **link:** https://arxiv.org/pdf/2512.21039
  - **contributions:** 1. Proposed AMPEND-LS, an agentic multi-persona framework that integrates textual, visual, and contextual evidence through a structured LLM reasoning pipeline. 2. Introduced a credibility fusion mechanism combining semantic similarity, domain trustworthiness, and temporal context to improve reliability. 3. Designed a complementary SLM classifier to mitigate LLM uncertainty and hallucinations, enhancing robustness and explainability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e8f4708c11ed1d6f5c25e0cab8a4e68e02e81ca73057ce067c85265f0213b46_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of multimodal fake news detection by proposing AMPEND-LS, a framework that synergizes LLMs and SLMs within a multi-persona agent structure to reason over diverse evidence. It demonstrates superior performance over state-of-the-art baselines in accuracy and robustness across multiple datasets. The work contributes to developing more adaptive and explainable systems for combating online misinformation.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[AMPEND-LS] --> B[核心问题/Problem: 虚假新闻检测的挑战/Fake News Detection Challenges];
    A --> C[主要方法/Method: 多角色智能体与证据融合/Agentic Multi-Persona & Evidence Fusion];
    A --> D[关键结果/Results: 性能超越基线/Outperforms SOTA Baselines];
    B --> B1[多模态内容/Multimodal Content];
    B --> B2[领域泛化/Domain Generalization];
    B --> B3[可解释性/Explainability];
    C --> C1[LLM-SLM协同/LLM-SLM Synergy];
    C --> C2[可信度融合/Credibility Fusion];
    C --> C3[结构化推理/Structured Reasoning];
    D --> D1[高准确率与F1/High Accuracy & F1];
    D --> D2[强鲁棒性/Robustness];
    D --> D3[透明推理/Transparent Reasoning];
    ```

- **[arXiv251225] Blurb-Refined Inference from Crowdsourced Book Reviews using Hierarchical Genre Mining with Dual-Path Graph Convolutions**
  - **tags:** [nlp], [text classification], [hierarchical genre classification, zero-shot semantic alignment, dual-path graph convolution, label co-occurrence graph, blurb-refined inference]
  - **authors:** Suraj Kumar, Utsav Kumar Nareti, Soumi Chattopadhyay, Chandranath Adak, Prolay Mallick
  - **institution:** Indian Institute of Technology Indore, Indian Institute of Technology Patna
  - **link:** https://arxiv.org/pdf/2512.21076
  - **contributions:** 1. Proposes a two-phase hierarchical genre mining framework (HiGeMine) that integrates noisy user reviews with authoritative blurbs using a zero-shot semantic alignment strategy to filter reviews. 2. Introduces a dual-path, two-level graph-based classification architecture that models inter-genre dependencies via a label co-occurrence graph for coarse and fine-grained prediction. 3. Curates a new hierarchical book genre dataset to facilitate systematic evaluation of the proposed method.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3afc3f4ebea9058118426cd2d72f37e4c09ae5bcc05f191e73c452f78fc501af_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of noisy and unreliable book genre classification by proposing HiGeMine, a framework that filters user reviews using semantic alignment with book blurbs and then performs hierarchical classification using a dual-path graph-based model. The method outperforms baselines on a newly curated dataset, demonstrating an effective solution for leveraging structured and unstructured text in hierarchical genre analysis.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[HiGeMine: Blurb-Refined Inference from Crowdsourced Book Reviews] --> B[核心问题/Problem: Noisy reviews & flat genre classification degrade reliability]
    A --> C[主要方法/Method: Two-phase framework: 1. Zero-shot review filtering 2. Dual-path graph classification]
    A --> D[关键结果/Results: Outperforms baselines on new hierarchical dataset]
    ```

- **[arXiv251225] ClarifyMT-Bench: Benchmarking and Improving Multi-Turn Clarification for Conversational Large Language Models**
  - **tags:** [nlp], [conversational ai], [multi-turn clarification, ambiguity taxonomy, agentic approach]
  - **authors:** Sichun Luo, Yi Huang, Mukai Li, Shichang Meng, Fengyuan Liu, Zefa Hu, Junlan Feng, Qi Liu
  - **institution:** The University of Hong Kong, JIUTIAN Research (China Mobile), City University of Hong Kong
  - **link:** https://arxiv.org/pdf/2512.21120
  - **contributions:** 1. Introduces ClarifyMT-Bench, a novel benchmark for multi-turn clarification featuring a five-dimensional ambiguity taxonomy and diverse simulated user personas. 2. Uncovers a consistent "under-clarification bias" in LLMs, where they answer prematurely and performance degrades with dialogue depth. 3. Proposes ClarifyAgent, an agentic framework that decomposes clarification into perception, forecasting, tracking, and planning to improve robustness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c251a364522d772d4c0ccb3f8108c9a5bafb4d76316e5783c96374fcd1c4488_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem that LLMs tend to answer ambiguous user queries prematurely in multi-turn conversations. To study this, the authors introduce ClarifyMT-Bench, a multi-turn clarification benchmark, and propose ClarifyAgent, an agentic method that improves clarification robustness. The main finding is that current LLMs have an under-clarification bias, which the proposed agentic approach helps mitigate.
  - **Mindmap:**

    ```mermaid
    graph LR
    A[ClarifyMT-Bench] --> B[核心问题/Problem: LLMs under-clarify in multi-turn dialogues]
    A --> C[主要方法/Method: Benchmark + ClarifyAgent]
    C --> D[Benchmark: 多轮对话基准/Multi-turn Benchmark]
    C --> E[Agent: 代理方法/Agentic Approach]
    A --> F[关键结果/Results: Bias identified, Agent improves robustness]
    ```

- **[arXiv251225] ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling**
  - **tags:** [mlsys], [agent system], [sequential modeling, chain-of-thought reasoning, diffusion large language models, multi-agent collaboration, world knowledge]
  - **authors:** Chuan Wang, Gaoming Yang, Han Wu, Jiakai Tang, Jiahao Yu, Jian Wu, Jianwu Hu, Junjun Zheng, Shuwen Xiao, Yeqiu Yang, Yuning Jiang, Ahjol Nurlanbek, Binbin Cao, Bo Zheng, Fangmei Zhu, Gaoming Zhou, Huimin Yi, Huiping Chu, Jin Huang, Jinzhe Shan, Kenan Cui, Longbin Li, Silu Zhou, Wen Chen, Xia Ming, Xiang Gao, Xin Yao, Xingyu Wen, Yan Zhang, Yiwen Hu, Yulin Wang, Ziheng Bao, Zongyuan Wu
  - **institution:** TaoRank Team (Alibaba Group / Taobao)
  - **link:** https://arxiv.org/pdf/2512.21257
  - **contributions:** 1. Proposes ReaSeq, a reasoning-enhanced framework that leverages LLM world knowledge to overcome limitations of log-driven recommender systems. 2. Introduces explicit Chain-of-Thought reasoning via multi-agent collaboration to distill structured product knowledge into enriched item representations. 3. Employs latent reasoning via Diffusion LLMs to infer plausible beyond-log user behaviors, enhancing interest modeling.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f98d5c26b79acf6e7c20219639988198127de51ba1227ceaeb063216243ba42_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces ReaSeq, a framework that uses Large Language Models' world knowledge for explicit and implicit reasoning to address knowledge poverty and systemic blindness in log-driven industrial recommender systems. It enhances item representations and infers beyond-log user behaviors. Deployed on Taobao, it achieved significant improvements in key business metrics like CTR and GMV.
  - **Mindmap:**

    ```mermaid
    graph LR
        A[ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[知识贫乏/Knowledge Poverty in ID-based Representations]
        B --> B2[系统盲区/Systemic Blindness to Beyond-Log Interests]
        C --> C1[显式推理/Explicit Chain-of-Thought Reasoning via Multi-Agent]
        C --> C2[隐式推理/Latent Reasoning via Diffusion LLMs]
        D --> D1[IPV & CTR提升 >6.0%/IPV & CTR Gain >6.0%]
        D --> D2[订单提升 >2.9%/Orders Gain >2.9%]
        D --> D3[GMV提升 >2.5%/GMV Gain >2.5%]
    ```
