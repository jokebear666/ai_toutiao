---
slug: /daily/cslg/20251229-20260104
---
# 20251229-20260104 (cs.LG)

## 2025-12-29

- **[arXiv251229] Harnessing Data Spaces to Build Intelligent Smart City Infrastructures Across the Cloud-Edge Continuum**
  - **tags:** [mlsys], [on-device ai], [data spaces, cloud-edge continuum, containerized microservices, edge AI, intelligent infrastructure monitoring]
  - **authors:** Dimitrios Amaxilatis, Themistoklis Sarantakos, Nikolaos Tsironis, Souvik Sengupta, Kostas Ramantas, Jhofre Ojeda
  - **institution:** Spark Works Ltd., IONOS SE, Iquadrat Informática S.L.
  - **link:** https://arxiv.org/pdf/2512.21340
  - **contributions:** 1. A real-world implementation of intelligent infrastructure monitoring within a data space-enabled cloud-edge framework, demonstrating practical integration. 2. Leveraging edge computing, containerized microservices, and interoperable data sharing to address challenges like sensor integration, data privacy, and scalability. 3. Showcasing the training and deployment of AI/ML services directly at the edge for optimized resource use and timely decision-making in smart city applications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a real-world use case for smart cities, implementing an intelligent climate monitoring system within a cloud-edge continuum framework enabled by data spaces. The method combines edge computing, containerized microservices, and secure data sharing to facilitate localized analytics and AI deployment. The conclusion highlights the transformative potential of integrating AI, edge computing, and data spaces for building efficient and resilient smart city infrastructures.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Harnessing Data Spaces for Smart City Infrastructures] --> B[核心问题/Problem: Enhancing smart city efficiency, sustainability, and resilience with secure, interoperable data exchange]
        A --> C[主要方法/Method: Data space-enabled cloud-edge framework with edge computing, containerized microservices, and edge AI/ML]
        A --> D[关键结果/Results: Demonstrates practical use case for intelligent monitoring, enabling localized analytics, real-time inference, and trusted data collaboration]
    ```

- **[arXiv251229] Physics-Informed Neural Solvers for Periodic Quantum Eigenproblems**
  - **tags:** [ai], [physics-informed machine learning], [physics-informed neural networks, Floquet-Bloch eigenvalue problem, honeycomb lattice, band structure, transfer learning]
  - **authors:** Haaris Mian
  - **institution:** Columbia University (Program in Applied Mathematics, Department of Applied Physics and Applied Mathematics)
  - **link:** https://arxiv.org/pdf/2512.21349
  - **contributions:** 1. A physics-informed machine learning framework for solving the Floquet-Bloch eigenvalue problem for particles in 2D periodic potentials, using neural networks to learn Bloch functions and eigenvalues simultaneously. 2. A mesh-free solver that enforces the Schrödinger equation, Bloch periodicity, and normalization via a composite loss function without supervision. 3. Demonstration of transfer learning to adapt the solver from nearly-free to strongly varying potentials, capturing changes in band topology.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18928753702626417cc700c2238d86a4711adfe422a6c1995a68fbcbf3401d4f_w640_q70.webp
  - **Simple LLM Summary:** This thesis proposes a physics-informed neural network framework to solve quantum eigenproblems for particles in periodic potentials, specifically targeting the honeycomb lattice. The method learns Bloch wavefunctions and their energies by training over the Brillouin zone with a loss function that encodes the governing physics. It is validated against traditional methods and shows promise for exploring band structure topology through transfer learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Physics-Informed Neural Solvers for Periodic Quantum Eigenproblems] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[求解二维周期势中的Floquet-Bloch本征值问题/Solve Floquet-Bloch eigenvalue problem in 2D periodic potentials]
        B --> B2[关注石墨烯等材料的蜂窝晶格和能带拓扑/Focus on honeycomb lattice & band topology for materials like graphene]
        C --> C1[使用神经网络同时学习布洛赫函数和本征值/Use neural networks to learn Bloch functions & eigenvalues]
        C --> C2[通过复合损失函数强制执行薛定谔方程和周期性/Enforce Schrödinger eq. & periodicity via composite loss]
        C --> C3[在布里渊区训练并探索迁移学习/Train over Brillouin zone & explore transfer learning]
        D --> D1[数值验证与传统方法一致/Numerical validation against traditional methods]
        D --> D2[迁移学习捕捉能带拓扑变化/Transfer learning captures changes in band topology]
    ```

- **[arXiv251229] A Reinforcement Learning Approach to Synthetic Data Generation**
  - **tags:** [ai], [reinforcement learning], [synthetic data generation, reinforcement learning, proximal policy optimization, privacy, biomedical data]
  - **authors:** Natalia Espinosa-Dice, Nicholas J. Jackson, Chao Yan, Aaron Lee, Bradley A. Malin
  - **institution:** Princeton University, Vanderbilt University Medical Center, Washington University in St. Louis
  - **link:** https://arxiv.org/pdf/2512.21395
  - **contributions:** 1. Reframes synthetic data generation (SDG) as a reinforcement learning problem, introducing a novel perspective. 2. Proposes RLSyn, a framework that models the data generator as a stochastic policy optimized via Proximal Policy Optimization with discriminator-derived rewards for stable, data-efficient training. 3. Demonstrates the effectiveness of the RL approach, showing it performs comparably to or better than GANs and diffusion models, especially in data-scarce regimes on biomedical datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75d9e0c3d2cba88654d16f9652042680f0037508065d6d94fba27208a6199969_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes RLSyn, a reinforcement learning framework for generating synthetic biomedical data by modeling the generator as a policy optimized with PPO. It shows that this approach achieves performance comparable to or better than GANs and diffusion models, particularly when training data is limited, offering a stable and data-efficient alternative for privacy-preserving data sharing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Reinforcement Learning Approach to Synthetic Data Generation] --> B
        A --> C
        A --> D
        B[核心问题/Problem: State-of-the-art generative models need large datasets and complex training, limiting use in small-sample settings.]
        C[主要方法/Method: Reframe SDG as RL; introduce RLSyn (stochastic policy optimized via PPO with discriminator rewards).]
        D[关键结果/Results: RLSyn performs comparably to/better than GANs & diffusion models, especially on smaller datasets.]
    ```

- **[arXiv251229] Learning to Reconfigure: Using Device Status to Select the Right Constrained Coding Scheme**
  - **tags:** [sys], [storage systems], [constrained coding, LOCO codes, linear programming, code reconfiguration, two-dimensional magnetic recording (TDMR)]
  - **authors:** Doğukan Özbayrak, Ahmed Hareedy
  - **institution:** Middle East Technical University
  - **link:** https://arxiv.org/pdf/2512.21396
  - **contributions:** 1. Proposes offline and online learning methods to reconfigure constrained coding schemes based on actual device status, moving beyond predetermined time stamps. 2. Models the reconfiguration problem as a linear programming optimization to maximize storage capacity and/or minimize decoding complexity, proving global optimality. 3. Demonstrates the effectiveness of the approach through experimental results in Two-Dimensional Magnetic Recording (TDMR) systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/602c83173fa9054dd0b0d4fea2c1b1c7d235aa475323c43a09847363ee851c20_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of optimally reconfiguring constrained coding schemes in storage devices as they age. The authors propose offline and online learning methods that fit device status data to polynomial models and formulate the reconfiguration decision as a linear programming problem to maximize capacity or minimize complexity. Experimental results show the proposed method is effective for TDMR systems and can be extended to other storage or transmission systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Learning to Reconfigure: Using Device Status to Select the Right Constrained Coding Scheme") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("设备老化需要不同等级的数据保护/Device aging requires different levels of data protection")
        Problem --> P2("基于预定时间戳的重配置忽略实际状态/Reconfiguration based on timestamps neglects actual device status")
        Method --> M1("提出离线和在线学习方法/Propose offline and online learning methods")
        Method --> M2("将训练数据拟合为多项式方程/Fit training data to polynomial equations")
        Method --> M3("将重配置建模为线性规划问题/Model reconfiguration as a linear programming problem")
        Results --> R1("解决方案是全局最优的/Solution is globally optimal")
        Results --> R2("实验证明在TDMR系统中有效/Experiments demonstrate effectiveness in TDMR systems")
    ```

- **[arXiv251229] kooplearn: A Scikit-Learn Compatible Library of Algorithms for Evolution Operator Learning**
  - **tags:** [ai], [dynamical systems learning], [Koopman operator, transfer operator, spectral decomposition, scikit-learn API, reduced-order models]
  - **authors:** Giacomo Turri, Grégoire Pacreau, Giacomo Meanti, Timothée Devergne, Daniel Ordonez, Erfan Mirzaei, Bruno Belucci, Karim Lounici, Vladimir Kostic, Massimiliano Pontil, Pietro Novelli
  - **institution:** Italian Institute of Technology, École Polytechnique, Inria, University College London
  - **link:** https://arxiv.org/pdf/2512.21409
  - **code:** https://github.com/Machine-Learning-Dynamical-Systems/kooplearn
  - **contributions:** 1. Provides a unified library implementing linear, kernel, and deep-learning estimators for both discrete-time (Koopman/Transfer) and continuous-time evolution operators. 2. Offers a scikit-learn compatible API for easy integration into existing ML workflows. 3. Includes curated benchmark datasets to support experimentation, reproducibility, and fair algorithm comparison.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6abf4d9f1d18bb64fbf627b5a4cc8d5b0c12b9f7fda20d8f6811df3f96602779_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces kooplearn, a Python library for learning evolution operators (like Koopman and transfer operators) from dynamical systems data. It provides a suite of estimators and a scikit-learn compatible interface to enable spectral analysis, reduced-order modeling, and forecasting. The library aims to standardize and facilitate research in data-driven dynamical systems modeling.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[kooplearn: A Scikit-Learn Compatible Library] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Need for a unified, easy-to-use library for learning evolution operators from dynamical systems data] --> Problem_Sub1[应用/Application: Analyze systems, forecast, reduce model dimension]
        Method[主要方法/Method: Implement linear, kernel, and deep-learning estimators] --> Method_Sub1[接口/Interface: Scikit-learn compatible API]
        Method --> Method_Sub2[模型/Model: Discrete-time (Koopman/Transfer) & continuous-time operators]
        Results[关键结果/Results: kooplearn library released] --> Results_Sub1[特性/Features: Includes benchmark datasets for fair comparison]
        Results --> Results_Sub2[目标/Goal: Facilitate integration, experimentation, and reproducibility]
    ```

- **[arXiv251229] A Tool Bottleneck Framework for Clinically-Informed and Interpretable Medical Image Understanding**
  - **tags:** [cv], [medical image analysis], [tool-use framework, vision-language model, interpretability, data-efficiency, tool bottleneck model]
  - **authors:** Christina Liu, Alan Q. Wang, Joy Hsu, Jiajun Wu, Ehsan Adeli
  - **institution:** California Institute of Technology, Stanford University
  - **link:** https://arxiv.org/pdf/2512.21414
  - **code:** https://github.com/christinaliu2020/tool-bottleneck-framework
  - **contributions:** 1. Proposed the Tool Bottleneck Framework (TBF) for medical image understanding, which uses a learned Tool Bottleneck Model (TBM) to compose tool outputs instead of text-based composition. 2. Introduced a strategy for the TBM to handle arbitrary VLM tool selections, enabling flexible and robust prediction. 3. Demonstrated that the framework improves performance, interpretability, and data-efficiency, matching or surpassing deep learning classifiers and other tool-use frameworks, especially in data-limited scenarios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/005a0b27c7be7243a18042195a924af5ace8e6d74a858ee50cacd288da25307e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem that existing tool-use frameworks for image understanding perform poorly on medical images due to their reliance on text to compose specialized tools. The authors propose the Tool Bottleneck Framework (TBF), which uses a vision-language model to select tools and a learned neural network (the Tool Bottleneck Model) to fuse their outputs. Evaluations on histopathology and dermatology tasks show TBF performs on par with or better than existing methods, offering gains in data-limited settings and more interpretable predictions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Tool Bottleneck Framework for Medical Image Understanding] --> B[核心问题/Problem: Text-based tool composition fails for medical images with localized features]
        A --> C[主要方法/Method: TBF uses VLM to select tools, TBM (neural network) to fuse outputs]
        A --> D[关键结果/Results: Matches or beats baselines, more interpretable, data-efficient]
    ```

- **[arXiv251229] A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning**
  - **tags:** [sys], [wireless networking], [Age of Information (AoI), reinforcement learning, freshness optimization, wireless networks, multi-agent systems]
  - **authors:** Alimu Alibotaiken, Suyang Wang, Oluwaseun T. Ajayi, Yu Cheng
  - **institution:** Illinois Institute of Technology, California State University, San Bernardino
  - **link:** https://arxiv.org/pdf/2512.21412
  - **contributions:** 1. Proposes a novel taxonomy for Age of Information (AoI) and its variants, categorizing them into native, function-based, and application-oriented families to clarify freshness modeling for B5G/6G systems. 2. Introduces a policy-centric taxonomy for reinforcement learning in freshness-aware networks, consisting of update-control RL, medium-access RL, risk-sensitive RL, and multi-agent RL. 3. Synthesizes recent RL-driven freshness control progress and highlights open challenges like delayed decision processes and cross-layer design to establish a unified foundation for learning-based freshness optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b58e6fe193d4299ab0beca4eb949d8b13e21e8198c223c3dd6c0ca64896bbf7d_w640_q70.webp
  - **Simple LLM Summary:** This survey addresses the gap between classical Age of Information (AoI) studies and broad reinforcement learning (RL) discussions in wireless networks by examining RL specifically for freshness optimization. It organizes AoI variants and introduces a policy-centric RL taxonomy to provide a coherent framework for freshness-aware decision-making in next-generation wireless systems. The paper aims to establish a unified foundation for learning-based freshness control and highlights key open challenges for future research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有综述的不足: 经典AoI与泛化RL研究分离 / Gap: Classical AoI vs. Broad RL]
        C --> C1[提出以AoI为中心的RL综述框架 / Propose AoI-centric RL Survey Framework]
        C --> C2[构建AoI变体分类与策略中心分类法 / Build AoI Variant & Policy-Centric Taxonomies]
        D --> D1[为B5G/6G建立学习式新鲜度优化的统一基础 / Establish Unified Foundation for Learning-based Freshness Optimization]
        D --> D2[识别开放挑战: 延迟决策、随机性、跨层设计 / Identify Open Challenges: Delayed Decisions, Stochasticity, Cross-layer]
    ```

- **[arXiv251229] Scalable Deep Subspace Clustering Network**
  - **tags:** [ai], [subspace clustering], [landmark-based approximation, self-expression, spectral clustering, linear complexity, convolutional auto-encoder]
  - **authors:** Nairouz Mrabah, Mohamed Bouguessa, Sihem Sami
  - **institution:** University of Quebec at Montreal
  - **link:** https://arxiv.org/pdf/2512.21434
  - **contributions:** 1. Proposes a deep subspace clustering framework (SDSNet) that achieves linear O(n) computational complexity, breaking the traditional O(n^3) bottleneck. 2. Introduces a landmark-based approximation to avoid constructing the full n×n affinity matrix, combined with joint optimization of auto-encoder reconstruction and self-expression objectives. 3. Enables direct spectral clustering on factorized representations, integrating convolutional auto-encoders with subspace-preserving constraints for efficient and accurate clustering.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7769a2896887c34d8a77b8e69c13ab64ec5b8827cb1b9e3ff0d7fff7982196e4_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high computational cost (O(n^3)) of traditional subspace clustering methods. It proposes SDSNet, a scalable deep learning framework that uses landmark approximation and joint optimization to achieve linear O(n) complexity. Experiments show SDSNet maintains clustering quality comparable to state-of-the-art methods while being significantly more efficient.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Scalable Deep Subspace Clustering Network"] --> Problem["核心问题/Problem: O(n^3) 计算复杂度 / O(n^3) Computational Complexity"]
        Root --> Method["主要方法/Method: 地标近似与联合优化 / Landmark Approximation & Joint Optimization"]
        Root --> Results["关键结果/Results: 线性复杂度与可比性能 / Linear Complexity & Comparable Performance"]
    ```

- **[arXiv251229] Cerberus: Multi-Agent Reasoning and Coverage-Guided Exploration for Static Detection of Runtime Errors**
  - **tags:** [se], [software testing], [runtime error detection, coverage-guided testing, multi-agent reasoning, large language models, static analysis]
  - **authors:** Hridya Dhulipala, Xiaokai Rong, Tien N. Nguyen
  - **institution:** University of Texas at Dallas
  - **link:** https://arxiv.org/pdf/2512.21431
  - **contributions:** 1. Proposes Cerberus, a novel predictive, execution-free coverage-guided testing framework that uses LLMs for input generation, coverage prediction, and error detection without code execution. 2. Introduces a two-phase feedback loop that first maximizes code coverage and detects errors, then focuses solely on error detection after coverage is maximized, improving performance over single-phase prompting. 3. Empirically demonstrates that Cerberus outperforms conventional and learning-based testing frameworks for both complete and incomplete code snippets by generating high-coverage test cases more efficiently and discovering more runtime errors.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d41379a4c8476f7ed1a8a02b193c5fe427e6a274d56beccd85313ce47ba5e76_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes Cerberus, a framework that uses Large Language Models (LLMs) to statically detect runtime errors in code snippets without execution. It employs a multi-agent reasoning approach with a two-phase, coverage-guided feedback loop to generate test inputs and predict errors. The evaluation shows Cerberus is more efficient and effective at finding runtime errors than existing testing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cerberus: Multi-Agent Reasoning and Coverage-Guided Exploration for Static Detection of Runtime Errors] --> B(核心问题/Problem: Detecting runtime errors in code snippets without execution is crucial for software safety.)
        A --> C(主要方法/Method: Uses LLMs for execution-free, coverage-guided testing with a two-phase feedback loop.)
        A --> D(关键结果/Results: Outperforms conventional and learning-based frameworks by generating high-coverage tests and finding more errors.)
    ```

- **[arXiv251229] DeepCQ: General-Purpose Deep-Surrogate Framework for Lossy Compression Quality Prediction**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [lossy compression, quality prediction, deep-surrogate, mixture-of-experts, feature-extraction]
  - **authors:** Khondoker Mirazul Mumenin, Robert Underwood, Dong Dai, Jinzhen Wang, Sheng Di, Zarija Lukić, Franck Cappello
  - **institution:** University of North Carolina at Charlotte, Argonne National Laboratory, University of Delaware, Lawrence Berkeley National Laboratory
  - **link:** https://arxiv.org/pdf/2512.21433
  - **contributions:** 1) A generalizable surrogate model for predicting compression quality across different compressors, quality metrics, and datasets. 2) A novel two-stage design that decouples expensive feature extraction from lightweight prediction for efficient training and modular inference. 3) A mixture-of-experts design to optimize performance and robustness for time-evolving scientific data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06e831f83754144a92a117a184fdcc51da0584d4163390cf94b34d4175b77a1_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes DeepCQ, a deep-surrogate framework to efficiently predict the quality of data after lossy compression, which is traditionally computationally expensive to assess. The method uses a two-stage and mixture-of-experts design for generalizability and robustness across different compressors, metrics, and time-evolving datasets. The framework achieves high predictive accuracy (errors under 10%) on real-world applications, enabling informed compression decisions and reducing I/O and computational overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DeepCQ: 通用深度代理框架用于有损压缩质量预测] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[评估压缩后数据质量的计算成本高/Expensive to assess post-compression data quality]
        C --> C1[两阶段设计: 特征提取 + 轻量预测/Two-stage design: feature extraction + lightweight prediction]
        C --> C2[专家混合设计处理时变数据/Mixture-of-experts for time-evolving data]
        D --> D1[预测误差普遍低于10%/Prediction errors generally under 10%]
        D --> D2[显著优于现有方法/Significantly outperforms existing methods]
    ```

- **[arXiv251229] Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models**
  - **tags:** [nlp], [computational ethics], [moral context, probabilistic clustering, LLM semantics, interpretable prediction, human judgment]
  - **authors:** Geoffroy Morlat, Marceau Nahon, Augustin Chartouny, Raja Chatila, Ismael T. Freire, Mehdi Khamassi
  - **institution:** Institute of Intelligent Systems and Robotics, Sorbonne University
  - **link:** https://arxiv.org/pdf/2512.21439
  - **contributions:** 1. An empirically grounded dataset of 300 moral scenarios with human ternary judgments. 2. A reproducible pipeline (COMETH) combining human judgments, probabilistic context learning, and LLM-based semantic abstraction. 3. An interpretable, context-sensitive moral prediction model that outperforms end-to-end LLM prompting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f4abc9f666c2d29dadd77869bddf3f159d0bbc8839c7c0f65bbdb4c29ad40c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem that moral judgments depend heavily on context. It proposes the COMETH framework, which uses probabilistic clustering on human judgment data and LLM-based semantic abstraction to learn and explain action-specific moral contexts. The main conclusion is that COMETH significantly outperforms direct LLM prompting in aligning with human majority judgments while providing interpretable predictions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[COMETH: Learning Interpretable Moral Contexts] --> B[核心问题/Problem: Moral judgments are context-dependent]
        A --> C[主要方法/Method: Probabilistic clustering + LLM semantics + Human judgments]
        A --> D[关键结果/Results: Doubles alignment with human judgments vs. LLM prompting]
    ```

- **[arXiv251229] Fuzzwise: Intelligent Initial Corpus Generation for Fuzzing**
  - **tags:** [se], [fuzz testing], [initial corpus generation, large language models, multi-agent framework, predictive code coverage, mutation-based fuzzing]
  - **authors:** Hridya Dhulipala, Xiaokai Rong, Aashish Yadavally, Tien N. Nguyen
  - **institution:** University of Texas at Dallas
  - **link:** https://arxiv.org/pdf/2512.21440
  - **contributions:** 1. Proposes FuzzWise, a novel method that integrates initial corpus generation and minimization into a single, streamlined process using an LLM-based multi-agent framework., 2. Introduces a predictive code coverage module (an LLM agent) that assesses new test cases without requiring actual program execution, saving computational resources., 3. Demonstrates empirically that FuzzWise generates a smaller, higher-quality initial corpus that achieves higher code coverage and triggers more runtime errors more efficiently than baseline methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcb8eafec283e39ae04e0274dc4688aced924346193560581e8469f1151507f6_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of generating a high-quality initial seed corpus for mutation-based fuzzing. It proposes FuzzWise, a method that uses a multi-agent LLM framework to generate and intelligently select test cases based on predicted coverage without execution. The evaluation shows FuzzWise produces a smaller, more effective corpus that achieves higher coverage and finds more bugs efficiently.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FuzzWise: Intelligent Initial Corpus Generation for Fuzzing] --> B[核心问题/Problem: 为模糊测试生成高质量的初始种子语料库/Generating high-quality initial seed corpus for fuzzing]
        A --> C[主要方法/Method: 基于LLM的多智能体框架，集成生成与预测性覆盖评估/LLM-based multi-agent framework integrating generation and predictive coverage assessment]
        A --> D[关键结果/Results: 用更少的测试用例实现更高的代码覆盖率和错误发现率/Achieves higher code coverage and bug detection with fewer test cases]
    ```

- **[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning**
  - **tags:** [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]
  - **authors:** Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu
  - **institution:** University of Washington, University of California, Berkeley
  - **link:** https://arxiv.org/pdf/2512.21446
  - **contributions:** 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards "diffusion supremacy" over autoregressive models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[MDLMs解码慢，速度优势有限/MDLMs decode slowly, limiting speed advantage]
        C --> C1[基于GRPO的在线强化学习框架/On-policy RL framework based on GRPO]
        C --> C2[联合优化扩散模型与解掩码规划器/Jointly optimize diffusion model & unmasking planner]
        D --> D1[提升精度-效率权衡/Improves accuracy-efficiency trade-off]
        D --> D2[迈向"扩散霸权"/Moving towards "diffusion supremacy"]
    ```

- **[arXiv251229] An Equivariance Toolbox for Learning Dynamics**
  - **tags:** [ai], [learning theory], [equivariance, Noether's theorem, Hessian constraints, learning dynamics, symmetry]
  - **authors:** Yongyi Yang, Liu Ziyin
  - **institution:** University of Michigan, Massachusetts Institute of Technology, NTT Research
  - **link:** https://arxiv.org/pdf/2512.21447
  - **contributions:** 1. Developed a general equivariance framework that unifies first-order constraints (conservation laws, implicit bias) into a single identity. 2. Extended the analysis to second-order, providing structural predictions about curvature, flat/sharp directions, and gradient-Hessian alignment. 3. Generalized classical symmetry analyses from continuous transformations to include general equivariance and discrete transformations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69f03ddf87a64feb67cd904eadbbfc83a393f0b282be28c74e5bfeac489db50b_w640_q70.webp
  - **Simple LLM Summary:** The paper develops a unified equivariance toolbox for analyzing learning dynamics in neural networks. It extends classical symmetry-based analyses to derive coupled first- and second-order constraints, connecting transformation structure to loss landscape geometry. The framework recovers known results and provides new characterizations linking equivariance to modern optimization phenomena.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[An Equivariance Toolbox for Learning Dynamics] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[现有分析是特定问题的/Existing analyses are problem-specific]
        Problem --> P2[二阶结构理解不足/Second-order structure less understood]
        Method[主要方法/Method] --> M1[构建等变性工具箱/Build general equivariance toolbox]
        Method --> M2[扩展诺特定理分析/Extend Noether-type analyses]
        Results[关键结果/Results] --> R1[统一一阶约束/Unify first-order constraints]
        Results --> R2[提供二阶结构预测/Provide second-order structural predictions]
        Results --> R3[连接变换结构与几何/Connect transformation structure to geometry]
    ```

- **[arXiv251229] RLLaVA: An RL-central Framework for Language and Vision Assistants**
  - **tags:** [mlsys], [multi-modal training], [reinforcement learning, vision-language models, Markov decision process, resource-efficient training, modular framework]
  - **authors:** Lei Zhao, Zihao Ma, Boyu Lin, Yuhe Liu, Wenjun Wu, Lei Huang
  - **institution:** Beihang University
  - **link:** https://arxiv.org/pdf/2512.21450
  - **code:** https://github.com/TinyLoopX/RLLaVA
  - **contributions:** 1. Proposes a modular RL framework (RLLaVA) that decouples algorithmic logic from model architecture and distributed execution, enabling easy implementation of new RL algorithms. 2. Formulates the joint visual-textual sequential decision of VLMs as a unified Markov Decision Process (MDP), providing a principled foundation for multi-modal RL. 3. Achieves resource-efficient training, enabling end-to-end full-parameter updates for up to 4B-scale models on a single 24GB GPU.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69c1815245107c8b5c717a57c722eeb64e0b9b4b77c5a989f0d2b9f4353b36df_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces RLLaVA, a lightweight and modular reinforcement learning framework specifically designed for training vision-language models. It decouples RL logic from system components to simplify algorithm development and enables efficient training of large models on common GPUs. Experiments show that models trained with RLLaVA improve over base models and are competitive with other specialized RL frameworks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RLLaVA: An RL-central Framework for Language and Vision Assistants] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[缺乏专门的多模态RL框架 / Lack of specialized multi-modal RL framework]
        B --> B2[现有框架资源消耗大 / Existing frameworks are resource-intensive]
        C --> C1[解耦RL逻辑与架构 / Decouple RL logic from architecture & execution]
        C --> C2[统一MDP建模 / Unified MDP formulation for VLMs]
        C --> C3[支持多种算法与模型 / Supports broad RL methods & VLMs]
        D --> D1[资源高效训练 / Resource-efficient training (e.g., 4B model on 24GB GPU)]
        D --> D2[性能提升 / Models show improved performance]
        D --> D3[任务可扩展性 / Task extensibility demonstrated]
    ```

- **[arXiv251229] CCAD: Compressed Global Feature Conditioned Anomaly Detection**
  - **tags:** [cv], [anomaly detection], [global feature conditioning, adaptive compression, reconstruction-based anomaly detection]
  - **authors:** Xiao Jin, Liang Diao, Qixin Xiao, Yifan Hu, Ziqi Zhang, Yuchen Liu, Haisong Gu
  - **institution:** Columbia University, University of Michigan, University of California at Berkeley, Stevens Institute of Technology, VisionX LLC
  - **link:** https://arxiv.org/pdf/2512.21459
  - **code:** https://github.com/chloeqxq/CCAD
  - **contributions:** 1. Proposes CCAD, a novel method that synergizes reconstruction-based and representation-based anomaly detection by using compressed global features as a conditioning modality for the reconstruction model. 2. Introduces an adaptive compression mechanism to enhance model generalization and training efficiency. 3. Contributes a reorganized and re-annotated version of the DAGM 2007 dataset to validate the method's effectiveness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6719cd2f5873e49e54895c9bbfc91fe99e3e4a74eaf10b87fc908258f60c443d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenges of anomaly detection in industrial settings with limited anomalous data by proposing CCAD, a method that combines the strengths of reconstruction-based and representation-based approaches. CCAD conditions a reconstruction model on adaptively compressed global features, leading to improved generalization and training efficiency. Experiments show that CCAD outperforms state-of-the-art methods in AUC and achieves faster convergence.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CCAD: Compressed Global Feature Conditioned Anomaly Detection] --> B[核心问题/Problem: 异常检测在有限异常数据下的挑战，现有方法在泛化性、效率和约束上的不足]
        A --> C[主要方法/Method: 提出CCAD，融合重建与表征方法，使用压缩的全局特征作为重建模型的条件]
        A --> D[关键结果/Results: 在AUC上超越SOTA，收敛更快，贡献了重新标注的DAGM 2007数据集]
    ```

- **[arXiv251229] Statistical vs. Deep Learning Models for Estimating Substance Overdose Excess Mortality in the US**
  - **tags:** [ai], [time series forecasting], [LSTM, SARIMA, conformal prediction, counterfactual estimation, uncertainty quantification]
  - **authors:** Sukanya Krishna, Marie-Laure Charpignon, Maimuna Majumder
  - **institution:** Harvard University, Boston Children's Hospital, Broad Institute of MIT and Harvard, Massachusetts Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.21456
  - **contributions:** 1. Conducted a systematic empirical comparison showing LSTM outperforms SARIMA in point estimation and uncertainty calibration for counterfactual mortality projection under regime change. 2. Provided analysis that attention-based models (Seq2Seq, Transformer) underperform in this task due to overfitting to historical means. 3. Developed a reproducible pipeline incorporating conformal prediction intervals and extensive convergence analysis, providing an open-source framework deployable for public health planning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f7ae15bb7d75d1d53ce8df2d4924f6311b8bfce998ef81244521cd5679c4225_w640_q70.webp
  - **Simple LLM Summary:** This paper compares traditional statistical (SARIMA) and deep learning models (LSTM, Seq2Seq, Transformer) for estimating substance overdose excess mortality in the US during the COVID-19 pandemic. The study finds that LSTM provides more accurate and better-calibrated counterfactual estimates than SARIMA, establishing that carefully validated deep learning models can be more reliable for public health planning under structural disruptions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Statistical vs. Deep Learning Models for Estimating Substance Overdose Excess Mortality in the US] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[估计疫情导致的药物过量超额死亡率/Estimating pandemic-attributable excess mortality]
        B --> B2[传统方法在结构性变化下可能失效/Traditional methods may fail under structural change]
        C --> C1[系统比较SARIMA与深度学习模型/Systematic comparison of SARIMA vs. DL models]
        C --> C2[使用CDC数据(2015-2019)进行训练/Using CDC data (2015-2019) for training]
        C --> C3[预测2020-2023年的反事实轨迹/Projecting counterfactual trajectories for 2020-2023]
        D --> D1[LSTM在点估计和不确定性校准上表现最佳/LSTM achieves best point estimation & uncertainty calibration]
        D --> D2[注意力模型因过拟合历史均值而表现不佳/Attention models underperform due to overfitting to historical means]
        D --> D3[提供可部署的开源框架/Providing a deployable open-source framework]
    ```

- **[arXiv251229] When Bayesian Tensor Completion Meets Multioutput Gaussian Processes: Functional Universality and Rank Learning**
  - **tags:** [ai], [tensor decomposition], [Bayesian tensor completion, multioutput Gaussian processes, variational inference, rank learning, functional universality]
  - **authors:** Siyuan Li, Shikai Fang, Lei Cheng, Feng Yin, Yik-Chung Wu, Peter Gerstoft, Sergios Theodoridis
  - **institution:** Zhejiang University, The Chinese University of Hong Kong, Shenzhen, The University of Hong Kong, Technical University of Denmark, University of California, San Diego, Athena R.C.
  - **link:** https://arxiv.org/pdf/2512.21486
  - **code:** https://github.com/OceanSTARLab/RR-FBTC
  - **contributions:** 1. Proposes a rank-revealing functional Bayesian tensor completion (RR-FBTC) method that handles tensors with real-valued indices and automatically determines the tensor rank during inference. 2. Establishes the universal approximation property of the model, demonstrating its expressive power for continuous multi-dimensional signals. 3. Derives an efficient variational inference algorithm with closed-form updates for learning the model.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac46f14d99db0300a24117fcc6a1f29a54c4ad4ae1586354da1e156d0b048995_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of determining the optimal rank in functional tensor decomposition, which is NP-hard. It proposes a new method called RR-FBTC that uses multioutput Gaussian processes to model latent functions, enabling automatic rank learning and functional universality. Experiments show the method is effective and superior to state-of-the-art approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[When Bayesian Tensor Completion Meets Multioutput Gaussian Processes: Functional Universality and Rank Learning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有方法需已知张量秩/Existing methods require known tensor rank]
        B --> B2[确定最优秩是NP难问题/Determining optimal rank is NP-hard]
        C --> C1[提出RR-FBTC方法/Propose RR-FBTC method]
        C --> C2[使用多输出高斯过程建模/Model with multioutput Gaussian processes]
        C --> C3[变分推断与闭式更新/Variational inference with closed-form updates]
        D --> D1[证明泛函逼近能力/Prove functional universal approximation]
        D --> D2[实现自动秩学习/Achieve automatic rank learning]
        D --> D3[实验验证有效性/Experiments validate effectiveness]
    ```

- **[arXiv251229] MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding**
  - **tags:** [mlsys], [multi-modal training], [wearable sensing, actigraphy encoder, projection module, frozen LLM, behavioral summarization]
  - **authors:** Aiwei Zhang, Arvind Pillai, Andrew Campbell, Nicholas C. Jacobson
  - **institution:** Dartmouth College
  - **link:** https://arxiv.org/pdf/2512.21506
  - **contributions:** 1. Introduces MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs) for free-text generation of daily behavioral summaries. 2. Constructs a novel, large-scale dataset of 54,383 (actigraphy, text) pairs derived from real-world NHANES recordings. 3. Demonstrates superior performance over prompt-based baselines in semantic fidelity and lexical accuracy, with qualitative analysis showing the model captures circadian structure and behavioral transitions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of generating natural language summaries from raw physiological signals like actigraphy. It proposes MotionTeller, a framework that integrates a pretrained actigraphy encoder with a frozen LLM via a projection module. The model, trained on a novel dataset, outperforms baselines in generating fluent, human-centered descriptions of daily behavior.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs] --> B[核心问题/Problem: How to generate natural language summaries from raw physiological signals like actigraphy?]
        A --> C[主要方法/Method: Combines a pretrained actigraphy encoder and a projection module to map behavioral embeddings into a frozen LLM's token space.]
        A --> D[关键结果/Results: Achieves high semantic fidelity (BERTScore-F1=0.924) and lexical accuracy (ROUGE-1=0.722), outperforming baselines by 7%.]
    ```

- **[arXiv251229] Missing Pattern Tree based Decision Grouping and Ensemble for Deep Incomplete Multi-View Clustering**
  - **tags:** [ai], [multi-view clustering], [incomplete multi-view clustering, missing pattern tree, decision ensemble, knowledge distillation]
  - **authors:** Wenyuan Yang, Jie Xu, Hongqing He, Jiangzhang Gan, Xiaofeng Zhu
  - **institution:** University of Electronic Science and Technology of China, Hainan University, Singapore University of Technology and Design, Guangxi Normal University
  - **link:** https://arxiv.org/pdf/2512.21510
  - **contributions:** 1. Proposes a missing-pattern tree model to group data into decision sets for fully utilizing available multi-view pairs, addressing the pair under-utilization issue. 2. Introduces a multi-view decision ensemble module that uses uncertainty-based weighting to aggregate robust clustering decisions from different sets. 3. Designs an ensemble-to-individual knowledge distillation module to transfer ensemble knowledge to view-specific models, promoting mutual optimization between ensemble and individual modules.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/407ccf539edc974ed5d25aba6f5889d28e73dcff5d62d962f118ffbc46c8c49c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of incomplete multi-view clustering (IMVC) where inconsistent missing patterns hinder performance. It proposes a framework called TreeEIC that groups data by missing pattern, performs clustering within each group, ensembles the results with uncertainty weighting, and uses knowledge distillation to refine individual models. Experiments show TreeEIC achieves state-of-the-art performance and robustness.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Missing Pattern Tree based Decision Grouping and Ensemble for Deep Incomplete Multi-View Clustering"] --> Problem["核心问题/Problem: Inconsistent missing patterns in multi-view data limit clustering performance."]
        Root --> Method["主要方法/Method: TreeEIC framework with missing-pattern tree grouping, decision ensemble, and knowledge distillation."]
        Root --> Results["关键结果/Results: Achieves state-of-the-art IMVC performance and superior robustness."]
    ```

- **[arXiv251229] First Provable Guarantees for Practical Private FL: Beyond Restrictive Assumptions**
  - **tags:** [mlsys], [federated learning], [differential privacy, convergence guarantees, partial client participation, local updates, clipping bias]
  - **authors:** Egor Shulgin, Grigory Malinovsky, Sarit Khirirat, Peter Richtárik
  - **institution:** King Abdullah University of Science and Technology (KAUST)
  - **link:** https://arxiv.org/pdf/2512.21521
  - **contributions:** 1. Introduces Fed-α-NormEC, the first DP FL framework with provable convergence under standard assumptions (without bounded gradients or heterogeneity). 2. Fully supports practical FL features like multiple local updates and, crucially, partial client participation. 3. Provides theoretical analysis showing how partial client participation is essential for real-world deployment and vital for privacy amplification.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ffad28b47b2302842557d1ba4a799ee36a241e4ab2529611ee61b38dd671f76d_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the gap between theoretical private federated learning methods, which rely on unrealistic assumptions, and practical deployment needs. It proposes Fed-α-NormEC, a new framework that provides provable differential privacy and convergence guarantees while supporting key practical features like local updates and partial client participation. Experiments on private deep learning tasks validate the theoretical findings.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[First Provable Guarantees for Practical Private FL] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[现有私有FL方法依赖不现实假设/Existing private FL relies on unrealistic assumptions]
        Problem --> P2[忽略本地更新与部分客户端参与/Neglects local updates & partial participation]
        Method[主要方法/Method] --> M1[提出Fed-α-NormEC框架/Propose Fed-α-NormEC framework]
        Method --> M2[集成本地更新与独立学习率/Integrates local updates & separate stepsizes]
        Method --> M3[支持部分客户端参与/Supports partial client participation]
        Results[关键结果/Results] --> R1[提供可证明的收敛与DP保证/Provides provable convergence & DP guarantees]
        Results --> R2[实验验证理论/Experiments corroborate theory]
    ```

- **[arXiv251229] Perplexity-Aware Data Scaling Law: Perplexity Landscapes Predict Performance for Continual Pre-training**
  - **tags:** [mlsys], [llm training], [continual pre-training, scaling laws, perplexity, data selection, knowledge gap]
  - **authors:** Lei Liu, Hao Zhu, Yue Shen, Zhixuan Chu, Jian Wang, Jinjie Gu, Kui Ren
  - **institution:** Ant Group, Zhejiang University
  - **link:** https://arxiv.org/pdf/2512.21515
  - **contributions:** 1. Proposes a novel perplexity-aware data scaling law that predicts model test loss from the perplexity landscape of domain data, moving beyond dataset size. 2. Introduces the concept of "perplexity landscapes" to quantify the informational value and knowledge gap of candidate training samples. 3. Enables adaptive selection of high-utility data subsets for Continual Pre-training, improving efficiency and performance by prioritizing informative content and reducing redundancy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d01b1cad6e908309c7e813cb1d98f2c41345aa1e4d78cbdaf163996c5d111b4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the inefficiency of scaling data for Continual Pre-training (CPT) of LLMs, where simply adding more data yields diminishing returns. The authors propose a new scaling law that uses the model's perplexity on domain data as a proxy for the knowledge gap, allowing for the predictive selection of optimal training subsets. Experiments show this method consistently identifies high-utility data, leading to superior performance on domain-specific benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Perplexity-Aware Data Scaling Law<br>困惑度感知数据缩放定律] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[CPT中单纯增加数据收益递减<br>Diminishing returns from scaling data in CPT]
        C --> C1[提出基于困惑度景观的缩放定律<br>Propose perplexity-landscape-based scaling law]
        C1 --> C2[利用困惑度量化知识差距<br>Use perplexity to quantify knowledge gap]
        C2 --> C3[自适应选择高价值数据子集<br>Adaptively select high-utility data subsets]
        D --> D1[识别接近最优的训练子集<br>Identifies near-optimal training subsets]
        D1 --> D2[在领域基准上取得优越性能<br>Achieves superior performance on domain benchmarks]
    ```

- **[arXiv251229] Global-Graph Guided and Local-Graph Weighted Contrastive Learning for Unified Clustering on Incomplete and Noise Multi-View Data**
  - **tags:** [ai], [multi-view clustering], [contrastive learning, incomplete multi-view data, noise-robust clustering, graph-guided learning, imputation-free]
  - **authors:** Hongqing He, Jie Xu, Wenyuan Yang, Yonghua Zhu, Guoqiu Wen, Xiaofeng Zhu
  - **institution:** Guangxi Normal University, University of Electronic Science and Technology of China, Singapore University of Technology and Design, Hainan University
  - **link:** https://arxiv.org/pdf/2512.21516
  - **contributions:** 1. Proposes a global-graph guided contrastive learning strategy to address the rare-paired sample issue in incomplete multi-view data by constructing a global affinity graph to form new sample pairs. 2. Introduces a local-graph weighted contrastive learning mechanism to mitigate the mis-paired sample issue caused by noise, using local neighbors to generate adaptive weights for pair-wise contrast. 3. Integrates these strategies into a unified, imputation-free framework for effective clustering on both incomplete and noisy multi-view data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/529caa0e85beab1a6519998120519b076cf7e6e2b9527a44331340cb6dd9574a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenges of rare-paired and mis-paired samples in contrastive learning for multi-view clustering on incomplete and noisy data. It proposes a unified framework combining global-graph guided contrastive learning to explore complementary information and local-graph weighted contrastive learning to adaptively handle noisy pairs. Experiments show the method outperforms state-of-the-art approaches on both incomplete and noisy data settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Global-Graph Guided and Local-Graph Weighted Contrastive Learning<br/>全局-局部图引导对比学习] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br/>Rare-paired & Mis-paired Samples<br/>样本配对稀少与错误] --> B1[Incomplete & Noise Multi-View Data<br/>不完整与噪声多视图数据]
        C[主要方法/Method<br/>Unified Contrastive Learning Framework<br/>统一对比学习框架] --> C1[Global-Graph Guided CL<br/>全局图引导对比学习]
        C --> C2[Local-Graph Weighted CL<br/>局部图加权对比学习]
        C1 --> C1a[Construct Global Affinity Graph<br/>构建全局亲和力图]
        C2 --> C2a[Generate Adaptive Weights<br/>生成自适应权重]
        D[关键结果/Results<br/>Superior Clustering Performance<br/>优越的聚类性能] --> D1[Outperforms SOTA Methods<br/>超越现有最佳方法]
        D --> D2[Effective on Incomplete & Noise Data<br/>在不完整与噪声数据上有效]
    ```

- **[arXiv251229] Generative Actor Critic**
  - **tags:** [ai], [reinforcement learning], [generative modeling, policy evaluation, latent plan, offline-to-online, actor-critic]
  - **authors:** Aoyang Qin, Deqian Kong, Wei Wang, Ying Nian Wu, Song-Chun Zhu, Sirui Xie
  - **institution:** Tsinghua University, Beijing Institute of General Artificial Intelligence (BIGAI), UCLA, Peking University
  - **link:** https://arxiv.org/pdf/2512.21527
  - **code:** github.com/qayqaq/Generative-Actor-Critic
  - **contributions:** 1. Proposes the Generative Actor Critic (GAC) framework that reframes policy evaluation as learning a generative model of the joint distribution over trajectories and returns, decoupling decision-making. 2. Introduces a specific instantiation using a latent variable model with continuous latent plan vectors and novel inference strategies for exploitation and exploration. 3. Demonstrates strong offline performance and significantly enhanced offline-to-online improvement on benchmarks, even without step-wise rewards.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62b697a3a1c4a1b559c19af7d65fd19d2eed0bb097eccecdd9008a509a0456c0_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Generative Actor Critic (GAC), a novel reinforcement learning framework that decouples sequential decision-making by learning a generative model of trajectories and returns and then performing inference on it. It shows strong performance in offline learning and significantly improves when fine-tuned online, even in sparse-reward environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Generative Actor Critic] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统RL在线改进离线预训练模型存在挑战/Challenges in refining offline models online]
        C --> C1[将策略评估重构为学习轨迹与回报的联合生成模型/Reframe policy evaluation as learning p(τ, y)]
        C --> C2[将策略改进重构为在模型上进行多样化推理/Reframe policy improvement as versatile inference]
        C --> C3[基于潜变量模型的实例化与新颖推理策略/Instantiation with latent plans & novel inference]
        D --> D1[离线性能强大/Strong offline performance]
        D --> D2[离线到在线改进显著/Enhanced offline-to-online improvement]
    ```

- **[arXiv251229] AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage Antiviral Peptide Identification**
  - **tags:** [ai], [bioinformatics], [adaptive gating mechanism, contrastive learning, transfer learning]
  - **authors:** Xinru Wen, Weizhong Lin, Xuan Xiao
  - **institution:** JCI (inferred from email domain `jci.edu.cn`)
  - **link:** https://arxiv.org/pdf/2512.21544
  - **contributions:** 1. Proposes a two-stage deep learning framework (AVP-Fusion) for antiviral peptide identification and subclass prediction. 2. Introduces an Adaptive Gating Mechanism to dynamically fuse local (CNN) and global (BiLSTM) sequence features. 3. Employs a contrastive learning strategy with OHEM and BLOSUM62-based data augmentation to sharpen decision boundaries and handle hard samples.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72c58b1c8ae5a53950bfc6d9e8fcca6dc27fc849f514d47d4a2cdff795cb10b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes AVP-Fusion, a two-stage deep learning framework that integrates adaptive feature fusion and contrastive learning for identifying antiviral peptides (AVPs). The method dynamically fuses multi-modal sequence features and uses contrastive learning to improve classification, achieving state-of-the-art accuracy and enabling precise prediction of antiviral activity against specific viral families.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[AVP-Fusion: 抗病毒肽识别 / Antiviral Peptide Identification] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题 / Problem] --> P1[现有方法难以捕捉复杂序列依赖 / Current methods struggle with sequence dependencies]
        Problem --> P2[难以处理模糊样本 / Hard to handle ambiguous samples]
        Method[主要方法 / Method] --> M1[构建全景特征空间 / Construct panoramic feature space]
        Method --> M2[自适应门控机制融合特征 / Adaptive Gating Mechanism for feature fusion]
        Method --> M3[对比学习与数据增强 / Contrastive learning & data augmentation]
        Results[关键结果 / Results] --> R1[准确率0.9531, MCC 0.9064 / Accuracy 0.9531, MCC 0.9064]
        Results --> R2[优于现有方法 / Outperforms SOTA]
        Results --> R3[实现病毒家族亚类预测 / Enables viral family subclass prediction]
    ```

- **[arXiv251229] Discovering Sparse Recovery Algorithms Using Neural Architecture Search**
  - **tags:** [ai], [sparse recovery], [neural architecture search, meta-learning, iterative shrinkage thresholding algorithm, sparse optimization, algorithm discovery]
  - **authors:** Patrick Yubeaton, Sarthak Gupta, M. Salman Asif, Chinmay Hegde
  - **institution:** New York University, University of California, Riverside
  - **link:** https://arxiv.org/pdf/2512.21563
  - **contributions:** 1. Proposes a meta-learning framework using Neural Architecture Search (NAS) for automated discovery of sparse recovery algorithms. 2. Demonstrates the framework's capability to rediscover key elements of ISTA and FISTA from a search space of over 50,000 variables. 3. Shows the framework's applicability to various data distributions and algorithms beyond ISTA/FISTA.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49f1d5d0a89c3d52b36f1e443675494175442f0930725fc8a763e525ca05243a_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a meta-learning framework that uses Neural Architecture Search (NAS) to automatically discover sparse recovery algorithms. It successfully rediscovers components of ISTA and FISTA from a large search space and demonstrates generalizability to other algorithms and data distributions.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Discovering Sparse Recovery Algorithms Using Neural Architecture Search] --> B[核心问题/Problem: Automated discovery of sparse optimization algorithms is difficult and heuristic-driven]
    A --> C[主要方法/Method: Meta-learning framework using Neural Architecture Search (NAS) for algorithm rediscovery]
    A --> D[关键结果/Results: Rediscovered ISTA/FISTA elements; framework applies to various data and algorithms]
    ```

- **[arXiv251229] AnchorGK: Anchor-based Incremental and Stratified Graph Learning Framework for Inductive Spatio-Temporal Kriging**
  - **tags:** [ai], [spatio-temporal kriging], [graph neural networks, incremental learning, data stratification, anchor locations, incomplete features]
  - **authors:** Xiaobin Ren, Kaiqi Zhao, Katerina Taškova, Patricia Riddle
  - **institution:** University of Auckland, Harbin Institute of Technology, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.21569
  - **code:** https://github.com/xren451/Spatial-interpolation
  - **contributions:** 1. Introduces an anchor-based stratification framework to handle sparse spatial distributions and heterogeneous feature availability in sensor networks. 2. Proposes a dual-view graph learning layer that jointly aggregates feature-relevant and location-relevant information to learn stratum-specific representations. 3. Designs an incremental representation mechanism that systematically utilizes all available features across different strata to mitigate feature incompleteness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c757748db9cf59d7295a4cdf698c5e194dc4ae79ec767aa6f7c71c0e78243768_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes AnchorGK, a graph learning framework for inductive spatio-temporal kriging that addresses sparse sensor deployment and incomplete features. It uses anchor-based stratification and a dual-view graph learning layer to model correlations and incrementally integrate features. Experiments show it outperforms existing state-of-the-art methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AnchorGK: Anchor-based Incremental and Stratified Graph Learning Framework for Inductive Spatio-Temporal Kriging] --> B(核心问题/Problem: Sparse sensor distribution and incomplete features hinder accurate spatio-temporal kriging)
        A --> C(主要方法/Method: Anchor-based stratification and dual-view graph learning for incremental feature integration)
        A --> D(关键结果/Results: Outperforms state-of-the-art baselines on multiple benchmark datasets)
    ```

- **[arXiv251229] nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures**
  - **tags:** [mlsys], [compiler & ir], [e-graph, term rewriting, phase ordering, NUMA abstraction, auto vectorize]
  - **authors:** Hui Guo, Qihang Zheng, Chenghai Huo, Dongliang Guo, Haoqi Yang, Yang Zhang
  - **institution:** Canaan Inc.
  - **link:** https://arxiv.org/pdf/2512.21571
  - **code:** https://github.com/kendryte/nncase
  - **contributions:** 1. Proposes an end-to-end compilation framework (nncase) that unifies LLM deployment across heterogeneous memory architectures using a NUMA abstraction for a "compile once, adapt everywhere" capability. 2. Introduces an e-graph-based term rewriting engine with equality saturation to mitigate the phase ordering problem and enable global optimization of computation and data movement. 3. Integrates three key automated optimization modules: Auto Vectorize for heterogeneous computing units, Auto Distribution for parallel strategies with communication optimization, and Auto Schedule for on-chip cache locality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a555b38ecd80e8c11606362e5402405bbf0053e11754e06f720d50ce213ee0d_w640_q70.webp
  - **Simple LLM Summary:** The paper presents nncase, an end-to-end compiler framework designed to tackle the challenge of efficiently deploying large language models on heterogeneous memory architectures. Its core innovation is an e-graph-based rewriting engine that avoids the phase ordering problem, enabling unified optimization across diverse hardware targets. Evaluations show nncase outperforms frameworks like MLC LLM and Intel IPEX, achieving performance close to hand-optimized llama.cpp, demonstrating the viability of automated compilation for high-performance LLM deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures] --> B[核心问题/Problem: LLM部署受限于内存架构异构性，传统编译器流程碎片化/Memory architecture heterogeneity hinders efficient LLM deployment, traditional compilers have fragmented workflows.]
        A --> C[主要方法/Method: 基于e-graph的项重写引擎，统一NUMA抽象，集成自动向量化、分布、调度模块/E-graph-based term rewriting engine, unified NUMA abstraction, integrates Auto Vectorize, Distribution, Schedule modules.]
        A --> D[关键结果/Results: 性能超越MLC LLM和Intel IPEX，接近手工优化的llama.cpp/Outperforms MLC LLM & Intel IPEX, achieves performance comparable to hand-optimized llama.cpp.]
    ```

- **[arXiv251229] A Unified Definition of Hallucination, Or: It's the World Model, Stupid**
  - **tags:** [nlp], [hallucination detection & evaluation], [hallucination, world modeling, knowledge conflict, benchmark, language model evaluation]
  - **authors:** Emmy Liu, Varun Gangal, Chelsea Zou, Xiaoqi Huang, Michael Yu, Alex Chang, Zhuofu Tao, Sachin Kumar, Steven Y. Feng
  - **institution:** Carnegie Mellon University, Stanford University, The Ohio State University, Patronus AI, DegenAI Labs, Independent Researchers
  - **link:** https://arxiv.org/pdf/2512.21577
  - **contributions:** 1. Proposes a unified definition of hallucination as inaccurate internal world modeling that is observable to the user, synthesizing prior definitions. 2. Provides a framework for analyzing hallucinations by varying the reference world model and knowledge conflict policy, clarifying what constitutes a hallucination versus other error types. 3. Outlines plans for a family of benchmarks based on synthetic, fully-specified world models to stress-test and improve the world modeling components of language models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e2cc31121f769cca7464239d4aa27b26c8c4bc903970a4833fbebac56dc9b85_w640_q70.webp
  - **Simple LLM Summary:** This paper argues that the persistent problem of hallucination in language models stems from inaccurate internal world modeling. It unifies various historical definitions under this core concept and proposes a framework for clearer evaluation. The authors conclude by sketching plans for new benchmarks to rigorously test and improve language models' world modeling capabilities.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Unified Definition of Hallucination / 幻觉的统一定义"] --> Problem["核心问题/Problem"]
        Root["A Unified Definition of Hallucination / 幻觉的统一定义"] --> Method["主要方法/Method"]
        Root["A Unified Definition of Hallucination / 幻觉的统一定义"] --> Results["关键结果/Results"]
        Problem --> P1["Hallucination persists in LLMs / 幻觉在LLM中持续存在"]
        Method --> M1["Unified definition: inaccurate world modeling / 统一定义：不准确的世界建模"]
        Method --> M2["Framework: reference world & conflict policy / 框架：参考世界与冲突策略"]
        Results --> R1["Clarifies evaluation & terminology / 澄清评估与术语"]
        Results --> R2["Proposes new benchmark plans / 提出新基准计划"]
    ```

- **[arXiv251229] RefineBridge: Generative Bridge Models Improve Financial Forecasting by Foundation Models**
  - **tags:** [ai], [time series forecasting], [Schrödinger Bridge, Low-rank Adaptation, Time Series Foundation Models, Financial Forecasting, Generative Refinement]
  - **authors:** Anthony Bolton, Wuyang Zhou, Zehua Chen, Giorgos Iacovides, Danilo Mandic
  - **institution:** Imperial College London
  - **link:** https://arxiv.org/pdf/2512.21572
  - **contributions:** 1. Proposes RefineBridge, a novel post-processing module built on a tractable Schrödinger Bridge framework to refine TSFM forecasts. 2. Introduces a paradigm that treats TSFM predictions as a generative prior and learns context-conditioned stochastic transport maps to iteratively improve them. 3. Demonstrates consistent performance improvements over state-of-the-art TSFMs on multiple financial benchmarks, addressing challenges like non-stationarity and noise.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d984f91104f06a2169d1d04626078f4bd0698ade16094c7642b5b47c5a1a6198_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of applying Time Series Foundation Models (TSFMs) to financial forecasting, where data properties like non-stationarity degrade performance. It proposes RefineBridge, a generative refinement module based on Schrödinger Bridges that iteratively transports TSFM predictions toward ground truths. Experiments show RefineBridge consistently enhances TSFM forecasts across various financial benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RefineBridge: Generative Bridge Models Improve Financial Forecasting by Foundation Models] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[TSFMs在金融预测中表现不佳<br/>TSFMs underperform in financial forecasting]
        B --> B2[LoRA等适应方法存在局限<br/>Limitations of adaptation methods like LoRA]
        C --> C1[提出基于薛定谔桥的RefineBridge模块<br/>Propose RefineBridge based on Schrödinger Bridge]
        C --> C2[将TSFM预测作为先验进行迭代优化<br/>Iteratively refine TSFM predictions as prior]
        D --> D1[在多个基准上提升TSFM性能<br/>Improves TSFM performance on multiple benchmarks]
        D --> D2[对不同预测范围均有效<br/>Effective across different prediction horizons]
    ```

- **[arXiv251229] Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations**
  - **tags:** [ai], [imitation learning], [behavior cloning, latent representation, self-supervised learning, sample efficiency]
  - **authors:** Xin Liu, Haoran Li, Dongbin Zhao
  - **institution:** Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences
  - **link:** https://arxiv.org/pdf/2512.21586
  - **contributions:** 1. Proposes a novel, unsupervised framework (BCV-LR) for imitation learning from videos (ILV) that learns latent actions from visual inputs. 2. Introduces an iterative policy improvement loop that aligns pre-trained latent actions with the real action space online, enabling highly sample-efficient learning. 3. Demonstrates state-of-the-art sample efficiency, outperforming existing ILV and RL methods on a wide range of visual control tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c96d71be701998ebf55ef6ed2a0c0a001a306b44f3555239559ced527b17559_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes BCV-LR, a framework for learning policies from videos without action labels. It uses self-supervised learning to extract latent actions and an iterative alignment process for sample-efficient behavior cloning. The method achieves expert-level performance on many tasks with minimal interaction, showing videos can be highly effective supervision for policy learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1["从视频模仿学习的挑战 / Challenges of Imitation Learning from Videos"]
        C --> C1["BCV-LR框架 / BCV-LR Framework"]
        C1 --> C2["自监督提取潜在特征 / Self-supervised Latent Feature Extraction"]
        C1 --> C3["基于动态的潜在动作预测 / Dynamics-based Latent Action Prediction"]
        C1 --> C4["在线对齐与迭代策略改进 / Online Alignment & Iterative Policy Improvement"]
        D --> D1["高样本效率 / High Sample Efficiency"]
        D --> D2["超越SOTA方法 / Outperforms SOTA Baselines"]
        D --> D3["首次证明视频可作为高效监督 / First to Show Videos as Efficient Supervision"]
    ```

- **[arXiv251229] Quantitative Verification of Omega-regular Properties in Probabilistic Programming**
  - **tags:** [other], [probabilistic programming and verification], [temporal posterior inference, omega-regular properties, stochastic barrier certificates, Rabin automata, quantitative verification]
  - **authors:** Peixin Wang, Jianhao Bai, Min Zhang, C.-H. Luke Ong
  - **institution:** East China Normal University, Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.21596
  - **contributions:** 1. Introduces Temporal Posterior Inference (TPI), a new framework unifying probabilistic programming with temporal logic to compute posterior distributions over execution traces satisfying omega-regular properties. 2. Develops a novel method for computing rigorous upper and lower bounds on satisfaction probabilities by decomposing Rabin acceptance conditions and constructing sound stochastic barrier certificates. 3. Implements the approach in a prototype tool named TPInfer and demonstrates its effectiveness and efficiency on a suite of benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c111a01f9d5e96a85d9b5c62645dae0f5bb40053d723e34cb57dc7f31554dcda_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of standard probabilistic program inference, which fails to capture temporal behavior, by proposing Temporal Posterior Inference (TPI). TPI computes posterior distributions over program traces that satisfy omega-regular temporal specifications, using a method based on stochastic barrier certificates to provide quantitative verification bounds. The approach is implemented in the TPInfer tool and shown to be effective for inference over rich temporal properties.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Quantitative Verification of Omega-regular Properties in Probabilistic Programming") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("标准后验推断的局限/Limitation of Standard Posterior Inference")
        P1 --> P2("无法捕捉程序执行的时间演化/Fails to capture temporal evolution")
        Method --> M1("提出时间后验推断框架/Propose Temporal Posterior Inference (TPI)")
        M1 --> M2("统一概率编程与时序逻辑/Unifies Probabilistic Programming & Temporal Logic")
        M2 --> M3("基于随机屏障证书的定量验证方法/Quantitative Verification via Stochastic Barrier Certificates")
        Results --> R1("实现原型工具 TPInfer/Implement Prototype Tool TPInfer")
        Results --> R2("在基准测试中展示有效性与效率/Demonstrates Effectiveness & Efficiency on Benchmarks")
    ```

- **[arXiv251229] Robustness and Scalability Of Machine Learning for Imbalanced Clinical Data in Emergency and Critical Care**
  - **tags:** [ai], [imbalanced classification], [XGBoost, TabNet, TabResNet, Bayesian hyperparameter search, class imbalance]
  - **authors:** Yusuf Brima, Marcellin Atemkeng
  - **institution:** Osnabrück University, Rhodes University, National Institute for Theoretical and Computational Sciences (NITheCS)
  - **link:** https://arxiv.org/pdf/2512.21602
  - **contributions:** 1. Systematic evaluation of robustness and scalability for classical ML and deep learning models on imbalanced clinical tabular data. 2. Introduction of TabResNet, a custom lightweight residual network designed as a computationally efficient alternative to TabNet for real-time clinical use. 3. Evidence-based finding that tree-based ensemble methods (especially XGBoost) offer the most stable and scalable performance for high-stakes, time-sensitive clinical environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44b64e154deeb74ff2b3607779dfb325b743068924af0e0b1b55c3172d889db8_w640_q70.webp
  - **Simple LLM Summary:** This paper evaluates the robustness and scalability of machine learning models on imbalanced clinical data from emergency and critical care settings. It proposes TabResNet, a lightweight deep learning alternative to TabNet, and compares it against tree-based methods like XGBoost. The main conclusion is that tree-based ensemble models, particularly XGBoost, provide the most stable performance and computational scalability for practical clinical deployment, outperforming more complex deep learning architectures in these environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Robustness and Scalability Of Machine Learning for Imbalanced Clinical Data<br>不平衡临床数据中机器学习的鲁棒性与可扩展性] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Imbalanced clinical data in emergency/critical care<br>急诊/重症监护中的不平衡临床数据]
        C[主要方法/Method<br>Systematic evaluation of tree-based models, TabNet, and proposed TabResNet<br>系统评估树模型、TabNet及提出的TabResNet]
        D[关键结果/Results<br>XGBoost most robust & scalable; deep models degrade under imbalance<br>XGBoost最鲁棒且可扩展；深度学习模型在不平衡下性能下降]
    ```

- **[arXiv251229] A Data-Driven Multi-Objective Approach for Predicting Mechanical Performance, Flowability, and Porosity in Ultra-High-Performance Concrete (UHPC)**
  - **tags:** [ai], [predictive modeling], [XGBoost, SHAP analysis, K-Fold Cross-Validation, Isolation Forest, hyperparameter tuning]
  - **authors:** Jagaran Chakma, Zhiguang Zhou, Jyoti Chakma, Cao YuSen
  - **institution:** Tongji University, University of Chittagong
  - **link:** https://arxiv.org/pdf/2512.21610
  - **contributions:** 1. Developed a two-stage data-driven framework for UHPC property prediction, integrating model selection, data cleaning (multicollinearity removal, outlier detection), and feature importance analysis. 2. Demonstrated the superior performance of the XGBoost model after rigorous hyperparameter tuning and validation, achieving high accuracy across multiple objectives (mechanical performance, flowability, porosity). 3. Created a practical graphical user interface (GUI) to facilitate the application of the predictive model by material designers, reducing reliance on extensive experimental testing.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/988c9f68c148fb1ef37ff8e292bf9a2cab1878ea08a2f5baee1a1a47f095be23_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a data-driven, multi-objective machine learning framework to predict the mechanical performance, flowability, and porosity of Ultra-High-Performance Concrete (UHPC). The method involves testing 21 algorithms, selecting and tuning XGBoost, and refining the dataset through multicollinearity removal, outlier detection, and SHAP-based feature selection. The final model achieves high prediction accuracy, and a supporting GUI is developed to aid in UHPC mix design, reducing the need for experimental tests.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["A Data-Driven Multi-Objective Approach for Predicting UHPC Properties<br>预测UHPC性能的数据驱动多目标方法"] --> B["Problem: Predicting UHPC mechanical performance, flowability, porosity<br>核心问题: 预测UHPC的力学性能、流动性和孔隙率"]
        A --> C["Method: Two-stage ML framework with XGBoost, data cleaning, SHAP<br>主要方法: 两阶段ML框架，使用XGBoost、数据清洗和SHAP"]
        A --> D["Results: High prediction accuracy, developed GUI for designers<br>关键结果: 高预测精度，为设计师开发了GUI"]
    ```

- **[arXiv251229] MAD-NG: Meta-Auto-Decoder Neural Galerkin Method for Solving Parametric Partial Differential Equations**
  - **tags:** [ai], [scientific machine learning], [Neural Galerkin Method, meta-learning, parametric PDEs, space-time decoupling, randomized sparse updates]
  - **authors:** Qiuqi Li, Yiting Liu, Jin Zhao, Wencan Zhu
  - **institution:** Hunan University, Capital Normal University
  - **link:** https://arxiv.org/pdf/2512.21633
  - **contributions:** 1. Proposes a novel framework that enhances the Neural Galerkin Method by integrating the Meta-Auto-Decoder paradigm for solving parametric PDEs. 2. Introduces space-time decoupling to enable more stable and efficient time integration compared to full space-time approximations. 3. Employs meta-learning for rapid adaptation to new parameters and randomized sparse updates to reduce computational cost without sacrificing accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8574d601c121a7a53ef19693b53d019c5139f87d5ae2dd641aec204463aa59c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenges of generalization and efficiency in neural network-based solvers for parametric PDEs. It proposes MAD-NG, a framework that combines the Neural Galerkin Method with meta-learning and space-time decoupling to achieve stable, efficient, and accurate long-term predictions. Numerical experiments show the method performs well in accuracy, robustness, and adaptability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MAD-NG: Meta-Auto-Decoder Neural Galerkin Method<br>MAD-NG: 元自解码器神经伽辽金方法] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统神经求解器泛化与效率挑战<br>Traditional Neural Solvers' Generalization & Efficiency Challenges]
        C --> C1[空间-时间解耦与元学习<br>Space-Time Decoupling & Meta-Learning]
        C --> C2[随机稀疏更新<br>Randomized Sparse Updates]
        D --> D1[物理一致的长时预测<br>Physically Consistent Long-Horizon Predictions]
        D --> D2[较低计算开销<br>Lower Computational Overhead]
    ```

- **[arXiv251229] Mechanical Strength Prediction of Steel-Polypropylene Fiber-based High-Performance Concrete Using Hybrid Machine Learning Algorithms**
  - **tags:** [ai], [materials informatics], [hybrid machine learning, SHAP analysis, uncertainty quantification, strength prediction, high-performance concrete]
  - **authors:** Jagaran Chakma, Zhiguang Zhou, Badhan Chakma
  - **institution:** Tongji University, Chongqing Jiaotong University
  - **link:** https://arxiv.org/pdf/2512.21638
  - **contributions:** 1. Developed and evaluated three novel hybrid machine learning model families (ET-XGB, RF-LGBM, Transformer-XGB) for predicting the mechanical properties of fiber-reinforced concrete. 2. Conducted a comprehensive evaluation including k-fold cross-validation, hyperparameter optimization, SHAP analysis for interpretability, and uncertainty quantification for robustness assessment. 3. Identified key influential material parameters (fiber aspect ratios, silica fume, steel fiber content) and negative factors (water content, water-binder ratio) on concrete strength through SHAP analysis.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76eefc8193c0d98df6f997d7ae3134d34a448f8aba255f28a39044233c1f3bb8_w640_q70.webp
  - **Simple LLM Summary:** This research develops hybrid machine learning models to predict the compressive, flexural, and tensile strength of steel-polypropylene fiber-reinforced high-performance concrete. The study compares three hybrid models (ET-XGB, RF-LGBM, Transformer-XGB) and finds that the ET-XGB model achieved the highest overall accuracy, while SHAP analysis reveals the most influential material factors. The findings confirm that these ML models provide accurate and interpretable tools for optimizing concrete mix design in engineering applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Mechanical Strength Prediction of Steel-Polypropylene Fiber-based High-Performance Concrete Using Hybrid Machine Learning Algorithms] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Predict mechanical properties (CS, FS, TS) of fiber-reinforced HPC]
        C[主要方法/Method<br>Develop & evaluate hybrid ML models (ET-XGB, RF-LGBM, Transformer-XGB) with SHAP & uncertainty analysis]
        D[关键结果/Results<br>ET-XGB most accurate, RF-LGBM most stable for FS, key influential factors identified via SHAP]
    ```

- **[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search**
  - **tags:** [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]
  - **authors:** Maximilian Weichart
  - **institution:** University of Regensburg
  - **link:** https://arxiv.org/pdf/2512.21648
  - **code:** https://github.com/Max-We/inverse-rpo
  - **contributions:** 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Variance-Aware Prior-Based Tree Policies for MCTS] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Extending prior-based UCTs from other UCBs is challenging]
        C[主要方法/Method: Propose Inverse-RPO to derive prior-based UCTs; apply to UCB-V]
        D[关键结果/Results: New policies outperform PUCT without extra cost]
    ```

- **[arXiv251229] Causal-HM: Restoring Physical Generative Logic in Multimodal Anomaly Detection via Hierarchical Modulation**
  - **tags:** [cv], [anomaly detection], [multimodal fusion, causal modeling, hierarchical modulation, sensor guidance, unsupervised learning]
  - **authors:** Xiao Liu, Junchen Jin, Yanjie Zhao, Zhixuan Xing
  - **institution:** Chongqing University
  - **link:** https://arxiv.org/pdf/2512.21650
  - **contributions:** 1. Proposes a unified multimodal UAD framework (Causal-HM) that explicitly models the physical Process→Result dependency to address causal blindness. 2. Introduces a Sensor-Guided CHM Modulation mechanism that uses low-dimensional sensor signals as context to guide high-dimensional audio-visual feature extraction. 3. Designs a Causal-Hierarchical Architecture that enforces a unidirectional generative mapping to identify anomalies violating physical consistency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05f0b7760ac76038dd08b0ccd2890cb2628906dcf233282246d08ee584093193_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of causal blindness and the heterogeneity gap in multimodal anomaly detection for industrial processes like welding. It proposes the Causal-HM framework, which models the physical generative logic from process to result modalities using sensor-guided modulation and a causal-hierarchical architecture. The method achieves state-of-the-art performance on a new Weld-4M benchmark, demonstrating its effectiveness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Causal-HM: Restoring Physical Generative Logic in Multimodal Anomaly Detection via Hierarchical Modulation] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[因果盲区/Causal Blindness]
        B --> B2[模态异质性/Modality Heterogeneity]
        C --> C1[传感器引导调制/Sensor-Guided CHM Modulation]
        C --> C2[因果分层架构/Causal-Hierarchical Architecture]
        D --> D1[新基准/Weld-4M Benchmark]
        D --> D2[SOTA性能/SOTA I-AUROC 90.7%]
    ```

- **[arXiv251229] Semantic Codebooks as Effective Priors for Neural Speech Compression**
  - **tags:** [ai], [speech compression], [semantic codebooks, residual vector quantization (RVQ), HuBERT, FiLM-conditioned decoder, neural audio codec]
  - **authors:** Liuyang Bai, Weiyi Lu, Li Guo
  - **institution:** NYU Shanghai
  - **link:** https://arxiv.org/pdf/2512.21653
  - **contributions:** 1. Proposes SemDAC, a semantic-aware neural audio codec that uses semantic codebooks as priors for compression., 2. Introduces a design where the first RVQ quantizer is distilled from HuBERT to capture phonetic content, and a FiLM-conditioned decoder uses these semantic tokens., 3. Demonstrates superior performance over baseline DAC in perceptual metrics and ASR (Whisper) WER at significantly lower bitrates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a14c953c6c23139c4473b8d6e59b36c7615f79f4316119e168deb19de30eced_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes SemDAC, a neural speech codec that uses semantic codebooks distilled from HuBERT as priors within an RVQ framework to separate phonetic from acoustic information. This method achieves better perceptual quality and lower word error rates for speech recognition at much lower bitrates compared to traditional neural codecs. The results show that semantic priors provide an effective inductive bias for efficient, recognition-friendly speech compression.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Semantic Codebooks as Effective Priors for Neural Speech Compression"] --> Problem["核心问题/Problem: Traditional codecs inefficiently allocate bits for acoustic detail, neglecting linguistic structure."]
        Root --> Method["主要方法/Method: Propose SemDAC, using HuBERT-distilled semantic codebooks in RVQ and a FiLM-conditioned decoder."]
        Root --> Results["关键结果/Results: Outperforms DAC in perceptual metrics & ASR WER at lower bitrates (e.g., 0.95 vs 2.5 kbps)."]
    ```

- **[arXiv251229] Rethinking Output Alignment For 1-bit Post-Training Quantization of Large Language Models**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [1-bit quantization, post-training quantization, output alignment, activation error, large language models]
  - **authors:** Dung Anh Hoang, Cuong Pham, Cuong Nguyen, Trung le, Jianfei Cai, Thanh-Toan Do
  - **institution:** Monash University, University of Surrey
  - **link:** https://arxiv.org/pdf/2512.21651
  - **contributions:** 1. Investigates the failure conditions of naive output-matching in 1-bit LLM quantization, 2. Proposes a novel data-aware PTQ approach that explicitly accounts for activation error accumulation, 3. Demonstrates consistent performance improvements over existing 1-bit PTQ methods with minimal overhead
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0357717d29d733787933b581fbbb292b187b9fbc651fbc0f15bb04ef03e619eb_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the significant performance degradation in 1-bit post-training quantization (PTQ) of Large Language Models. The authors propose a new data-aware PTQ method that efficiently accounts for activation error accumulation. Their solution is shown to consistently outperform existing 1-bit PTQ approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Rethinking Output Alignment For 1-bit PTQ of LLMs<br>重新思考大语言模型1比特训练后量化的输出对齐"] --> Problem
        Root --> Method
        Root --> Results
        Problem["1-bit PTQ causes significant performance drop<br>1比特训练后量化导致性能显著下降"] --> P1["Focus on weight alignment, not output<br>关注权重对齐而非输出"]
        Problem --> P2["Naive output-matching fails<br>简单的输出匹配方法失败"]
        Method["Propose a data-aware PTQ approach<br>提出一种数据感知的训练后量化方法"] --> M1["Accounts for activation error accumulation<br>考虑激活误差累积"]
        Method --> M2["Keeps optimization efficient<br>保持优化高效"]
        Results["Consistently outperforms existing 1-bit PTQ methods<br>持续优于现有1比特训练后量化方法"] --> R1["Minimal overhead<br>开销极小"]
    ```

- **[arXiv251229] The Deepfake Detective: Interpreting Neural Forensics Through Sparse Features and Manifolds**
  - **tags:** [cv], [deepfake detection], [mechanistic interpretability, sparse autoencoder, forensic manifold analysis, feature selectivity, vision-language model]
  - **authors:** Subramanyam Sahoo, Jared Junkin
  - **institution:** University of California, Berkeley, Johns Hopkins University
  - **link:** https://arxiv.org/pdf/2512.21670
  - **code:** https://github.com/SubramanyamSahoo/The-Deepfake-Detective
  - **contributions:** 1. Introduces a novel mechanistic interpretability framework specifically for deepfake detection, combining sparse autoencoder analysis with forensic manifold analysis. 2. Demonstrates that only a small fraction of latent features are actively used in each layer of the model for detection. 3. Shows that geometric properties of the model's feature manifold (e.g., intrinsic dimensionality, curvature) vary systematically with different types of deepfake artifacts, linking learned features to specific forensic cues.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fe0975c346afcfa8a9faf58f7e59aefe76bd1a40a3922d1a230951ff391c9a39_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the "black box" nature of deepfake detectors by proposing a mechanistic interpretability framework that analyzes a vision-language model's internal representations. The method uses sparse autoencoders and a novel forensic manifold analysis to probe how the model's features respond to forensic artifacts. The key findings are that detection relies on a sparse set of features and that the geometry of the feature manifold correlates with specific artifact types, providing a step towards more interpretable and robust detectors.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Deepfake Detective: Interpreting Neural Forensics Through Sparse Features and Manifolds] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[深度伪造检测器是黑盒模型/Deepfake detectors are black boxes]
        C --> C1[稀疏自编码器分析/Sparse Autoencoder (SAE) Analysis]
        C --> C2[法证流形分析/Forensic Manifold Analysis]
        D --> D1[潜在特征稀疏使用/Latent features are sparsely used]
        D --> D2[流形几何特性揭示伪影/Manifold geometry reveals artifacts]
    ```

- **[arXiv251229] Comparative Analysis of Deep Learning Models for Perception in Autonomous Vehicles**
  - **tags:** [cv], [object detection], [YOLO-NAS, YOLOv8, perception, autonomous vehicles, custom dataset]
  - **authors:** Jalal Khan
  - **institution:** United Arab Emirates University
  - **link:** https://arxiv.org/pdf/2512.21673
  - **contributions:** 1. Conducted a comparative performance analysis of two emerging deep learning models, YOLO-NAS and YOLOv8, for object detection in autonomous vehicle perception. 2. Created and utilized a custom dataset to evaluate the models under real-world use case scenarios. 3. Provided empirical results showing YOLOv8s offers a 75% reduction in training time and a 2% higher object detection accuracy (83% vs 81%) compared to YOLO-NAS.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4a67f4b1902039d3a0f1a96acadea1a1625b1870da583b146bb58337f3c0561_w640_q70.webp
  - **Simple LLM Summary:** This paper compares the performance of YOLO-NAS and YOLOv8 deep learning models for object detection in autonomous vehicle perception using a custom dataset. The analysis finds that the YOLOv8s model is significantly faster to train and achieves slightly higher detection accuracy than the YOLO-NAS model.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Comparative Analysis of Deep Learning Models for Perception in Autonomous Vehicles] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[评估自动驾驶感知中深度学习模型的性能/Evaluate DL model performance for AV perception]
    C --> C1[使用自定义数据集比较YOLO-NAS与YOLOv8/Compare YOLO-NAS and YOLOv8 using a custom dataset]
    D --> D1[YOLOv8s训练时间减少75%/YOLOv8s saves 75% training time]
    D --> D2[YOLOv8s准确率更高(83% vs 81%)/YOLOv8s has higher accuracy (83% vs 81%)]
    ```

- **[arXiv251229] Dictionary-Transform Generative Adversarial Networks**
  - **tags:** [ai], [generative adversarial networks], [dictionary learning, transform learning, sparse modeling, adversarial learning, nash equilibrium]
  - **authors:** Angshul Majumdar
  - **institution:** Indraprastha Institute of Information Technology Delhi (IIIT-D)
  - **link:** https://arxiv.org/pdf/2512.21677
  - **contributions:** 1. Introduces DT-GAN, a fully model-based adversarial framework with a sparse synthesis dictionary generator and an analysis transform discriminator, enabling rigorous theoretical analysis. 2. Proves the adversarial game is well-posed, admits at least one Nash equilibrium, and that equilibrium solutions are identifiable under a sparse generative model. 3. Establishes finite-sample stability and consistency of empirical equilibria, demonstrating reliable convergence and robustness, validated on synthetic data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e368966cab749cb3ef0799abfb9a31d801a73291e7a5d2b4a5b81fd185a9d25_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the theoretical fragility and instability of classical GANs by proposing DT-GAN, a model-based adversarial framework where the generator and discriminator are constrained linear operators (a sparse synthesis dictionary and an analysis transform). The authors prove the framework is well-posed, has identifiable equilibria, and converges reliably, demonstrating that adversarial learning can be made interpretable and provably correct for data with sparse structure.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Dictionary-Transform GANs] --> B[核心问题/Problem: Classical GANs are theoretically fragile, with ill-posed objectives and unstable training.]
        A --> C[主要方法/Method: Propose DT-GAN, a model-based framework with a sparse synthesis dictionary generator and an analysis transform discriminator.]
        A --> D[关键结果/Results: Game is well-posed with Nash equilibrium; solutions are identifiable and stable; framework is interpretable and provably correct.]
    ```

- **[arXiv251229] RIPCN: A Road Impedance Principal Component Network for Probabilistic Traffic Flow Forecasting**
  - **tags:** [ai], [spatiotemporal forecasting], [probabilistic forecasting, uncertainty estimation, principal component analysis, road impedance, traffic flow]
  - **authors:** Haochen Lv, Yan Lin, Shengnan Guo, Xiaowei Mao, Hong Nie, Letian Gong, Youfang Lin, Huaiyu Wan
  - **institution:** Beijing Jiaotong University, Aalborg University
  - **link:** https://arxiv.org/pdf/2512.21685
  - **contributions:** 1. Proposes a dynamic impedance evolution network to model directional traffic transfer patterns driven by congestion and flow variability, revealing causes of uncertainty and enhancing reliability and interpretability. 2. Designs a principal component network to forecast the dominant eigenvectors of future flow covariance, enabling the capture of spatiotemporal uncertainty correlations. 3. Integrates domain-specific transportation theory with spatiotemporal principal component learning for probabilistic traffic flow forecasting, achieving superior performance over existing methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f835b2051524d67481fbf9f4479086a541b29307c2876046f2c3ee4eec60f92_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes RIPCN, a Road Impedance Principal Component Network for probabilistic traffic flow forecasting. It integrates transportation theory with principal component learning to model the causes of uncertainty and capture spatiotemporal uncertainty correlations. Experimental results show it outperforms existing probabilistic forecasting methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RIPCN: A Road Impedance Principal Component Network for Probabilistic Traffic Flow Forecasting] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1(如何建模交通流不确定性的成因? / How to model the causes of traffic flow uncertainty?)
        B --> B2(如何捕捉不确定性的时空相关性? / How to capture spatiotemporal correlations of uncertainty?)
        C --> C1(动态阻抗演化网络 / Dynamic Impedance Evolution Network)
        C --> C2(主成分网络 / Principal Component Network)
        D --> D1(超越现有概率预测方法 / Outperforms existing probabilistic forecasting methods)
    ```

- **[arXiv251229] Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities**
  - **tags:** [sys], [communication & networking], [multiconnectivity, SAGIN, resource allocation, agentic reinforcement learning, heterogeneous networks]
  - **authors:** Abd Ullah Khan, Adnan Shahid, Haejoon Jung, Hyundong Shin
  - **institution:** Kyung Hee University, Ghent University
  - **link:** https://arxiv.org/pdf/2512.21717
  - **contributions:** 1. Provides a comprehensive review of current developments and key implementation challenges in SAGIN-enabled multiconnectivity. 2. Highlights the transformative potential of AI-driven approaches, particularly agentic reinforcement learning, for resource optimization in heterogeneous SAGIN environments. 3. Presents a case study demonstrating that learning-based methods can effectively enhance network performance (latency, capacity) with a moderate trade-off in power consumption.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp
  - **Simple LLM Summary:** This paper reviews the challenges of implementing multiconnectivity in heterogeneous Space-Air-Ground Integrated Networks (SAGIN) and proposes AI-driven solutions, specifically agentic reinforcement learning, for optimal resource allocation. A case study shows these methods significantly improve latency and capacity, albeit with a moderate increase in power consumption as a trade-off. The work concludes by outlining open research problems for realizing efficient SAGIN-enabled multiconnectivity.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem: Heterogeneous SAGIN complicates multiconnectivity and resource allocation"]
        Method["主要方法/Method: Use AI-driven approaches, specifically agentic reinforcement learning"]
        Results["关键结果/Results: Enhanced network performance (latency, capacity) with moderate power trade-off"]
    ```

- **[arXiv251229] An Information Theoretic Perspective on Agentic System Design**
  - **tags:** [mlsys], [agent system], [mutual information, noisy channel, compressor-predictor, on-device AI, information-theoretic]
  - **authors:** Shizhe He, Avanika Narayan, Ishan S. Khare, Scott W. Linderman, Christopher Ré, Dan Biderman
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2512.21720
  - **contributions:** 1. Proposes an information-theoretic framework for analyzing agentic LM systems, viewing the compressor as a noisy channel. 2. Introduces a task-independent estimator of mutual information between context and compression to quantify compression quality. 3. Empirically demonstrates that scaling compressor models is more effective than scaling predictors for performance and cost, enabling efficient on-device compression.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124535642e159e8f7a123525ffbf3cb5f163a7ae4a7876a4d1e71e7e6c885ace_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the ad-hoc design of agentic LM systems that use a compressor LM to summarize context for a predictor LM. It proposes an information-theoretic framework using mutual information to evaluate compressors, finding that larger compressors are more accurate, concise, and information-dense, making scaling compressors more effective than scaling predictors for cost-efficient performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[An Information Theoretic Perspective on Agentic System Design] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1("Agentic系统设计缺乏理论指导<br/>Agentic system design lacks theoretical guidance")
        C --> C1("提出信息论框架与互信息估计器<br/>Propose information-theoretic framework & mutual information estimator")
        D --> D1("更大压缩器更高效、更准确<br/>Larger compressors are more efficient and accurate")
        D --> D2("扩展压缩器优于扩展预测器<br/>Scaling compressors outperforms scaling predictors")
    ```

- **[arXiv251229] HELP: Hierarchical Embodied Language Planner for Household Tasks**
  - **tags:** [mlsys], [agent system], [embodied agent, hierarchical planning, large language model, household tasks, open source LLM]
  - **authors:** Alexandr V. Korchemnyi, Anatoly O. Onishchenko, Eva A. Bakaeva, Alexey K. Kovalev, Aleksandr I. Panov
  - **institution:** MIRAI, Cognitive AI Systems Lab
  - **link:** https://arxiv.org/pdf/2512.21723
  - **contributions:** 1. Proposes a Hierarchical Embodied Language Planner (HELP) architecture using multiple LLM-based agents for decomposing and grounding natural language instructions. 2. Demonstrates the approach on a real-world household task using an embodied agent. 3. Focuses on the use of relatively small, open-source LLMs to enable autonomous deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d5e8ef0910254268525eec44918d2562afe5a6df81ece96ba720311313fef5b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of planning for embodied agents following ambiguous natural language instructions in complex environments. It proposes HELP, a hierarchical planner using multiple LLM-based agents to decompose high-level instructions into grounded, executable subtasks. The method is evaluated on a household task with a real robot, showing the feasibility of using smaller, open-source LLMs for autonomous operation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HELP: Hierarchical Embodied Language Planner for Household Tasks] --> B[核心问题/Problem: Embodied agents need robust planning for ambiguous natural language instructions in complex environments.]
        A --> C[主要方法/Method: Hierarchical planner with multiple LLM-based agents to decompose and ground instructions into executable steps.]
        A --> D[关键结果/Results: Evaluated on real-world household task; demonstrates use of smaller open-source LLMs for autonomous deployment.]
    ```

- **[arXiv251229] A Model of Causal Explanation on Neural Networks for Tabular Data**
  - **tags:** [ai], [explainable ai], [CENNET, structural causal models, entropy, causal explanation, tabular data]
  - **authors:** Takashi Isozaki, Masahiro Yamamoto, Atsushi Noda
  - **institution:** Sony Computer Science Laboratories, Inc., Sony Corporation of America
  - **link:** https://arxiv.org/pdf/2512.21746
  - **contributions:** 1. Proposes CENNET, a novel causal explanation method for neural network predictions on tabular data. 2. Introduces a new explanation power index based on entropy for evaluating the proposed method. 3. Demonstrates the method's effectiveness by combining structural causal models with neural networks for causal explanations, validated on synthetic and quasi-real data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02e8ba8968728eba560984773ed8ba2b124e42c46e3c839dec8a1ca2a5975ce1_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of providing causal explanations for neural network predictions on tabular data, where pseudo-correlations can mislead. The authors propose a method called CENNET, which integrates structural causal models with neural networks to generate causal explanations and introduces an entropy-based index to measure explanation power. Experiments on synthetic and quasi-real data show that CENNET effectively provides causal explanations compared to existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Model of Causal Explanation on Neural Networks for Tabular Data] --> B[核心问题/Problem: Explaining NN predictions on tabular data, addressing pseudo-correlation and causality]
        A --> C[主要方法/Method: Propose CENNET, a causal explanation method using SCMs and an entropy-based index]
        A --> D[关键结果/Results: CENNET provides causal explanations, validated via comparative experiments]
    ```

- **[arXiv251229] Dynamic Feedback Engines: Layer-Wise Control for Self-Regulating Continual Learning**
  - **tags:** [ai], [continual learning], [entropy scaling, catastrophic forgetting, stability-plasticity dilemma, dynamic feedback, layer-wise control]
  - **authors:** Hengyi Wu, Zhenyi Wang, Heng Huang
  - **institution:** University of Maryland, College Park, University of Central Florida
  - **link:** https://arxiv.org/pdf/2512.21743
  - **contributions:** 1. Proposes a novel entropy-aware continual learning method that uses a dynamic feedback mechanism to regulate each layer based on its entropy, addressing underfitting and overfitting. 2. Introduces Self-Adaptive Entropy Scaling, which adaptively adjusts regularization strength per layer to encourage convergence to wider local minima for better generalization. 3. Presents a complementary adaptive training mechanism that modulates layer plasticity based on performance, preserving knowledge in high-performing layers while amplifying updates in underperforming ones.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c3fa04d7e7b67fc322ddb75e74ec87a46fd273db39fd194f1fd2bb36fb01c0ec_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses catastrophic forgetting in continual learning by proposing a dynamic feedback mechanism that regulates each neural network layer based on its entropy. This entropy-aware method reduces entropy in high-entropy layers to prevent underfitting and increases it in low-entropy layers to prevent overfitting, promoting convergence to wider minima for improved generalization. The approach is general and integrates with existing replay- and regularization-based methods, showing substantial performance gains over state-of-the-art baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Dynamic Feedback Engines: Layer-Wise Control for Self-Regulating Continual Learning] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Catastrophic forgetting in continual learning due to uniform layer treatment] --> P1[高熵层欠拟合/High-entropy layers underfit]
        Problem --> P2[低熵层过拟合/Low-entropy layers overfit]
        Method[主要方法/Method: Entropy-aware dynamic feedback for layer-wise control] --> M1[减少高熵层熵值/Reduce entropy in high-entropy layers]
        Method --> M2[增加低熵层熵值/Increase entropy in low-entropy layers]
        Results[关键结果/Results: Improved generalization and performance] --> R1[收敛到更宽的局部极小值/Converge to wider local minima]
        Results --> R2[超越现有基线方法/Outperforms state-of-the-art baselines]
    ```

- **[arXiv251229] Approximation Capabilities of Feedforward Neural Networks with GELU Activations**
  - **tags:** [ai], [neural network approximation theory], [GELU activation, feedforward neural networks, approximation error bounds, derivative approximation, constructive approximation]
  - **authors:** Konstantin Yakovlev, Nikita Puchkin
  - **institution:** HSE University
  - **link:** https://arxiv.org/pdf/2512.21749
  - **contributions:** 1. Derivation of simultaneous approximation error bounds for a function and all its derivatives up to any prescribed order using GELU networks. 2. Constructive approximation guarantees for elementary operations (multiplication, division, exponential) with control over network size, weight magnitudes, and behavior at infinity. 3. Extension of approximation results to multivariate polynomials and other elementary functions, ensuring global boundedness of higher-order derivatives of the approximators.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af63acd2ab9f3e42763901f23d1762f6658fd25b72daf9e1f1f73e7b30ce1173_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the approximation capabilities of feedforward neural networks using the GELU activation function. The authors provide constructive methods to approximate elementary functions and their derivatives, proving simultaneous error bounds for the function and all its higher-order derivatives. The main conclusion is that GELU networks can effectively approximate key operations like multiplication, division, and exponentiation with controlled network complexity and globally bounded derivatives.
  - **Mindmap:**

    ```mermaid
    graph TB
    Root("Approximation Capabilities of Feedforward Neural Networks with GELU Activations<br>GELU激活前馈神经网络的逼近能力") --> Problem("核心问题/Problem")
    Root --> Method("主要方法/Method")
    Root --> Results("关键结果/Results")
    Problem --> P1("逼近函数及其导数<br>Approximating functions and their derivatives")
    Method --> M1("构造性乘法逼近<br>Constructive multiplication approximation")
    Method --> M2("扩展到除法和指数<br>Extension to division and exponent")
    Results --> R1("同时误差界<br>Simultaneous error bounds")
    Results --> R2("全局有界导数<br>Globally bounded derivatives")
    Results --> R3("网络规模控制<br>Network size control")
    ```

- **[arXiv251229] Assessing the Effectiveness of Membership Inference on Generative Music**
  - **tags:** [sec], [membership inference attacks], [membership inference attack (MIA), generative music, MuseGAN, privacy, copyright]
  - **authors:** Kurtis Chow, Omar Samiullah, Vinesh Sridhar, Hewen Zhang
  - **institution:** University of California, Irvine
  - **link:** https://arxiv.org/pdf/2512.21762
  - **contributions:** 1. Conducts the first preliminary study on the effectiveness of membership inference attacks (MIAs) specifically on generative music models., 2. Evaluates several existing MIA techniques on the popular MuseGAN model to assess their performance in this domain., 3. Provides empirical evidence suggesting that generative music data is relatively resilient to known membership inference techniques, aligning with prior findings in generative audio.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b7176fccbb69c4f0a15bfa6bcbb6ff59b09cf6ac02e0f524334f306ce4041f_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether membership inference attacks (MIAs) are effective against generative music models. The authors conduct a preliminary study by applying several existing MIA techniques to the MuseGAN model. Their findings indicate that generative music data is fairly resilient to these known attacks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Assessing the Effectiveness of Membership Inference on Generative Music"] --> Problem["核心问题/Problem: Lack of MIA study on generative music, privacy & copyright concerns"]
        Root --> Method["主要方法/Method: Apply existing MIAs to MuseGAN model"]
        Root --> Results["关键结果/Results: Music data is resilient to known MIAs"]
    ```

- **[arXiv251229] BertsWin: Resolving Topological Sparsity in 3D Masked Autoencoders via Component-Balanced Structural Optimization**
  - **tags:** [cv], [3d medical image analysis], [Masked Autoencoder, Swin Transformer, Self-Supervised Learning, 3D Vision Transformer, Structural Priority Loss]
  - **authors:** Evgeny Alves Limarenko, Anastasiia Studenikina
  - **institution:** Moscow Institute of Physics and Technology
  - **link:** https://arxiv.org/pdf/2512.21769
  - **contributions:** 1. Proposed BertsWin, a hybrid architecture combining full BERT-style token masking with Swin Transformer windows to preserve 3D spatial topology during SSL pre-training. 2. Introduced a structural priority loss function to enhance learning. 3. Demonstrated significant acceleration in semantic convergence (5.8x) and a 15-fold reduction in training epochs to reach SOTA fidelity when combined with the GradientConductor optimizer, without increasing computational FLOPs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18d8b6d7f8a20f3bce77706daf18b554423899bdff962eb21fde56292e0c3fde_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the difficulty of applying standard Masked Autoencoders to 3D medical images, which lose spatial context. It proposes BertsWin, a hybrid architecture that maintains a full 3D token grid using Swin Transformer windows and a structural loss. The method achieves much faster convergence and state-of-the-art reconstruction fidelity for 3D CBCT scans without extra computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("BertsWin: 3D MAE优化") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("3D MAE拓扑稀疏性/Topological Sparsity in 3D MAE")
        Problem --> P2("破坏空间关系/Destroys Spatial Context")
        Method --> M1("BertsWin混合架构/BertsWin Hybrid Architecture")
        Method --> M2("完整3D令牌网格/Full 3D Token Grid")
        Method --> M3("Swin窗口 & 结构损失/Swin Windows & Structural Loss")
        Results --> R1("5.8x语义收敛加速/5.8x Faster Convergence")
        Results --> R2("15倍训练轮次减少/15x Fewer Epochs")
        Results --> R3("FLOPs持平，总资源减少/FLOP Parity, Net Resource Reduction")
    ```

- **[arXiv251229] Accelerating Scientific Discovery with Autonomous Goal-evolving Agents**
  - **tags:** [ai], [scientific discovery agents], [autonomous goal evolution, bi-level optimization, LLM agents, objective function design, scientific discovery]
  - **authors:** Yuanqi Du, Botao Yu, Tianyu Liu, Tony Shen, Junwu Chen, Jan G. Rittig, Kunyang Sun, Yikun Zhang, Zhangde Song, Bo Zhou, Cassandra Masschelein, Yingze Wang, Haorui Wang, Haojun Jia, Chao Zhang, Hongyu Zhao, Martin Ester, Teresa Head-Gordon, Carla P. Gomes, Huan Sun, Chenru Duan, Philippe Schwaller, Wengong Jin
  - **institution:** Cornell University, The Ohio State University, Yale University, Simon Fraser University, École Polytechnique Fédérale de Lausanne, University of California Berkeley, Northeastern University, Deep Principle, University of Illinois Chicago, Georgia Institute of Technology, Broad Institute of MIT and Harvard
  - **link:** https://arxiv.org/pdf/2512.21782
  - **contributions:** 1. Identifies and addresses the unmet requirement of automating objective function design for scientific discovery agents, moving beyond fixed, imperfect proxies. 2. Proposes the SAGA framework, a novel bi-level architecture where an outer loop of LLM agents evolves objectives and an inner loop optimizes solutions under them. 3. Demonstrates the framework's effectiveness across diverse scientific domains (antibiotic, materials, DNA, chemical process design), showing improved discovery outcomes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9035dcf8fd16c34c235e39c8960c63fa826c45df283663a01722181f7ab419d8_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces SAGA, a framework for scientific discovery where LLM agents autonomously evolve and refine the objective functions used to guide optimization, rather than relying on fixed human-specified goals. This bi-level architecture enables systematic exploration of objective spaces and their trade-offs. The method is shown to substantially improve the effectiveness of discovery agents across multiple application domains.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Accelerating Scientific Discovery with Autonomous Goal-evolving Agents] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[Fixed objectives are imperfect proxies for grand scientific challenges / 固定的目标函数是科学重大挑战的不完美代理]
        Method[主要方法/Method] --> M1[Proposes SAGA: Scientific Autonomous Goal-evolving Agent / 提出SAGA: 科学自主目标演化智能体]
        M1 --> M2[Bi-level architecture: LLM outer loop evolves objectives, inner loop optimizes solutions / 双层架构: LLM外循环演化目标，内循环优化解]
        Results[关键结果/Results] --> R1[Applied to antibiotic, materials, DNA, chemical process design / 应用于抗生素、材料、DNA、化工过程设计]
        R1 --> R2[Automating objective formulation improves discovery effectiveness / 自动化目标制定提升了发现效能]
    ```

- **[arXiv251229] Synthetic Financial Data Generation for Enhanced Financial Modelling**
  - **tags:** [ai], [synthetic data generation], [synthetic financial data, TimeGAN, ARIMA-GARCH, VAE, Maximum Mean Discrepancy]
  - **authors:** Christophe D. Hounwanou, Yae Ulrich Gaba, Pierre Ntakirutimana
  - **institution:** AIMS Rwanda, Carnegie Mellon University, Sefako Makgatho Health Sciences University
  - **link:** https://arxiv.org/pdf/2512.21791
  - **contributions:** 1. Proposes a unified multi-criteria evaluation framework for synthetic financial data. 2. Empirically compares three generative paradigms (ARIMA-GARCH, VAE, TimeGAN) on fidelity, temporal structure, and downstream utility. 3. Provides practical guidelines for model selection and releases a reproducible codebase to standardize benchmarking.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3f9e4bbcf426a2c32c05089e0964e9937c0becca521cac8a83b48c652d0d86c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses data scarcity in finance by proposing a unified evaluation framework for synthetic financial data generation. It compares ARIMA-GARCH, VAE, and TimeGAN models using S&P 500 data, finding that TimeGAN offers the best trade-off between realism and temporal coherence. The work concludes with practical guidelines and aims to standardize benchmarking in the field.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Synthetic Financial Data Generation for Enhanced Financial Modelling"] --> Problem
        Root --> Method
        Root --> Results
        Problem["数据稀缺与保密性<br/>Data Scarcity & Confidentiality"]
        Method["统一评估框架与三种生成模型<br/>Unified Evaluation Framework & Three Generative Models"]
        Results["TimeGAN最佳权衡与实用指南<br/>TimeGAN Best Trade-off & Practical Guidelines"]
    ```

- **[arXiv251229] Multi-agent Adaptive Mechanism Design**
  - **tags:** [ai], [mechanism design], [distributionally robust optimization, online learning, incentive compatibility, adaptive mechanism, regret analysis]
  - **authors:** Qiushi Han, David Simchi-Levi, Renfei Tan, Zishuo Zhao
  - **institution:** Massachusetts Institute of Technology, University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2512.21794
  - **contributions:** 1. Introduces DRAM, a novel framework combining mechanism design and online learning to handle unknown agent beliefs. 2. Provides theoretical guarantees of high-probability truthfulness and achieves optimal $\tilde\{O\}(\sqrt\{T\})$ cumulative regret with a matching lower bound. 3. Generalizes the framework (DRAM+) to support plug-in estimators, structured priors, and delayed feedback.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c99ece7d8b60855735e1eee48c51256eacf5f3997d56ced3396434f12a30ad44_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of designing a truthful mechanism when the principal has no prior knowledge of agents' beliefs. It proposes the Distributionally Robust Adaptive Mechanism (DRAM), which iteratively learns beliefs and updates a robust optimization problem to minimize cost while ensuring truthfulness. The mechanism is proven to achieve optimal regret, and the framework is the first to maintain truthfulness under these general learning conditions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multi-agent Adaptive Mechanism Design] --> B[核心问题/Problem: Elicit truthful reports with no prior knowledge of agent beliefs]
        A --> C[主要方法/Method: Distributionally Robust Adaptive Mechanism (DRAM)]
        A --> D[关键结果/Results: Guaranteed truthfulness & optimal $\tilde{O}(\sqrt{T})$ regret]
    ```

- **[arXiv251229] VAMP-Net: An Interpretable Multi-Path Framework of Genomic Permutation-Invariant Set Attention and Quality-Aware 1D-CNN for MTB Drug Resistance**
  - **tags:** [ai], [bioinformatics], [Set Attention Transformer, 1D-CNN, Multi-Path Network, Interpretable Machine Learning, Genomic Variant Analysis]
  - **authors:** Aicha Boutorh, Kamar Hibatallah Baghdadi, Anais Daoud
  - **institution:** National School of Artificial Intelligence (ENSIA)
  - **link:** https://arxiv.org/pdf/2512.21786
  - **contributions:** 1. Proposes a novel multi-path deep learning architecture (VAMP-Net) that combines a permutation-invariant Set Attention Transformer for capturing epistatic interactions and a 1D-CNN for analyzing sequencing quality metrics. 2. Introduces a comparative evaluation of unmasked vs. padding-masked Set Attention Blocks within the architecture. 3. Provides dual-layer interpretability through attention weight analysis for epistatic networks and gradient-based methods for feature importance on both genetic variants and quality metrics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bf587b5249dfee9f3a9866a887e3d791367588c15a447d0c86619ea9c8df8a45_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces VAMP-Net, a multi-path deep learning framework designed to predict drug resistance in Mycobacterium tuberculosis. It combines a Set Attention Transformer to model genetic interactions and a 1D-CNN to assess data quality, achieving high accuracy and AUC. The work concludes that this approach offers superior predictive performance and dual-layer interpretability for clinical genomics.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[VAMP-Net: Interpretable Multi-Path Framework] --> Problem
        Root --> Method
        Root --> Results
    
        Problem[核心问题/Problem<br>Challenges in MTB Drug Resistance Prediction] --> P1[复杂的上位性相互作用/Complex Epistatic Interactions]
        Problem --> P2[测序数据质量多变/Variable Sequencing Data Quality]
    
        Method[主要方法/Method<br>VAMP-Net Multi-Path Architecture] --> M1[路径1: 集合注意力变换器/Path-1: Set Attention Transformer]
        Method --> M2[路径2: 质量感知1D-CNN/Path-2: Quality-Aware 1D-CNN]
        Method --> M3[融合模块/Fusion Module]
        M1 --> M1_Detail[处理变异集合/Processes Variant Sets]
        M2 --> M2_Detail[分析质量指标/Analyzes Quality Metrics]
    
        Results[关键结果/Results<br>Superior Performance & Interpretability] --> R1[性能: >95% 准确率, ~97% AUC/Performance: >95% Acc, ~97% AUC]
        Results --> R2[可解释性: 双层面分析/Interpretability: Dual-Layer Analysis]
        R2 --> R2_1[注意力权重揭示上位网络/Attention Weights Reveal Epistatic Networks]
        R2 --> R2_2[梯度分析识别关键位点与质量指标/Gradient Analysis Identifies Key Loci & Quality Metrics]
    ```

- **[arXiv251229] Smart IoT-Based Leak Forecasting and Detection for Energy-Efficient Liquid Cooling in AI Data Centers**
  - **tags:** [mlsys], [cluster infrastructure], [LSTM, Random Forest, MQTT, InfluxDB, Streamlit]
  - **authors:** Krishna Chaitanya Sunkara, Rambabu Konakanchi
  - **institution:** Oracle, Charles Schwab
  - **link:** https://arxiv.org/pdf/2512.21801
  - **contributions:** 1. Probabilistic LSTM forecasting validated within ±30-minute windows for coolant leaks, 2. 96.5% F1-score Random Forest detection for immediate leak identification, 3. Integrated smart IoT architecture design with MQTT streaming, InfluxDB storage, and Streamlit dashboards for energy-efficient data center operations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa113d59b2dc6ec7a3bf00f9eebc8541689a6235867cf59ce376cdcfa30a2a5c_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes a smart IoT monitoring system combining LSTM neural networks for probabilistic leak forecasting and Random Forest classifiers for instant detection in liquid-cooled AI data centers. The system, tested on synthetic data, achieves 96.5% detection accuracy and 87% forecasting accuracy, potentially preventing significant energy waste through proactive maintenance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Smart IoT-Based Leak Forecasting and Detection] --> B[核心问题/Problem: Coolant leaks cause energy loss in AI data centers]
        A --> C[主要方法/Method: LSTM for forecasting + Random Forest for detection with IoT sensors]
        A --> D[关键结果/Results: 96.5% detection accuracy, 87% forecasting accuracy, 1,500 kWh energy saved]
    ```

- **[arXiv251229] Few Tokens Matter: Entropy Guided Attacks on Vision-Language Models**
  - **tags:** [sec], [adversarial attacks], [entropy-guided attacks, vision-language models, adversarial robustness, harmful content generation, transferability]
  - **authors:** Mengqi He, Xinyu Tian, Xin Shen, Jinhong Ni, Shu Zou, Zhaoyuan Yang, Jing Zhang
  - **institution:** Australian National University, The University of Queensland, GE Research
  - **link:** https://arxiv.org/pdf/2512.21815
  - **contributions:** 1. Identifies that only a small fraction (~20%) of high-entropy tokens (critical decision points) disproportionately govern output trajectories in autoregressive VLMs, challenging the prior assumption of equal token importance. 2. Proposes a selective attack strategy that concentrates adversarial perturbations on these high-entropy positions, achieving strong semantic degradation with a smaller perturbation budget and inducing 35-49% of benign outputs to become harmful. 3. Demonstrates that vulnerable high-entropy forks recur across diverse VLMs, enabling feasible transferable attacks (17-26% harmful rates), and proposes the Entropy-bank Guided Adversarial attack (EGA) method which achieves high attack success rates (93-95%) while exposing new safety weaknesses.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af10d81c75765690cdb206c6e6e648f14a6dcb054a6ac03725ba3a7f9ce27608_w640_q70.webp
  - **Simple LLM Summary:** This paper reveals that adversarial attacks on Vision-Language Models (VLMs) can be made more efficient and dangerous by targeting only the critical high-entropy tokens during autoregressive generation, rather than all tokens. The proposed Entropy-bank Guided Adversarial attack (EGA) concentrates perturbations on these positions, achieving high attack success and converting many benign outputs into harmful ones, while also showing significant transferability across models. This exposes a critical and previously overlooked vulnerability in current VLM safety mechanisms.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Few Tokens Matter: Entropy Guided Attacks on Vision-Language Models] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[VLMs易受对抗攻击/VLMs are vulnerable to adversarial attacks]
        Problem --> P2[先验攻击假设所有token同等重要/Prior attacks assume all tokens are equally important]
        Method[主要方法/Method] --> M1[识别高熵关键决策点/Identify high-entropy critical decision points]
        Method --> M2[提出熵库引导对抗攻击(EGA)/Propose Entropy-bank Guided Adversarial attack (EGA)]
        Results[关键结果/Results] --> R1[高效攻击:小预算实现强语义退化/Efficient attack: strong degradation with small budget]
        Results --> R2[高有害转化率:35-49%/High harmful conversion: 35-49%]
        Results --> R3[可行迁移性:17-26%/Feasible transferability: 17-26%]
    ```

- **[arXiv251229] Scalable Class-Incremental Learning Based on Parametric Neural Collapse**
  - **tags:** [cv], [class-incremental learning], [parametric neural collapse, equiangular tight frame, knowledge distillation, adaptive expansion, feature alignment]
  - **authors:** Chuangxin Zhang, Guangfeng Lin, Enhui Zhao, Kaiyang Liao, Yajun Chen
  - **institution:** Not explicitly stated in the provided content. Affiliation information is not included.
  - **link:** https://arxiv.org/pdf/2512.21845
  - **code:** this https URLETF2
  - **contributions:** 1. Proposes a scalable class-incremental learning method (SCL-PNC) based on parametric neural collapse, enabling demand-driven, minimal-cost backbone expansion via an adapt-layer. 2. Introduces a dynamic parametric Equiangular Tight Frame (ETF) classifier to address class misalignment caused by evolving class distributions. 3. Presents a parallel expansion framework with a knowledge distillation algorithm to counteract feature drift and ensure feature consistency across expansion modules.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6233749e62b8335ab812fd2f0b2690d70bb8f1a822bd796c2c3cfa9d1a402cf3_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses challenges in class-incremental learning, such as overfitting and catastrophic forgetting, by proposing SCL-PNC. This method uses a parametric neural collapse framework with an adaptive backbone expansion and a dynamic ETF classifier to efficiently handle growing categories while maintaining feature consistency via distillation. Experiments show the method is effective and efficient.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Scalable Class-Incremental Learning Based on Parametric Neural Collapse"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["核心问题 / Problem"] --> P1["过拟合新数据 / Overfitting to new data"]
        Problem --> P2["灾难性遗忘旧数据 / Catastrophic forgetting of old data"]
        Problem --> P3["特征差异与类别错位 / Feature difference & Class misalignment"]
    
        Method["主要方法 / Method"] --> M1["SCL-PNC方法 / SCL-PNC Method"]
        M1 --> M1_1["自适应层扩展主干 / Adapt-layer for backbone expansion"]
        M1 --> M1_2["动态参数化ETF分类器 / Dynamic Parametric ETF Classifier"]
        M1 --> M1_3["并行扩展与知识蒸馏 / Parallel expansion & Knowledge distillation"]
    
        Results["关键结果 / Results"] --> R1["高效处理类别增长 / Efficiently handles increasing categories"]
        Results --> R2["解决类别错位 / Addresses class misalignment"]
        Results --> R3["确保特征一致性 / Ensures feature consistency"]
    ```

- **[arXiv251229] A Comedy of Estimators: On KL Regularization in RL Training of LLMs**
  - **tags:** [ai], [reinforcement learning], [KL divergence, policy gradient, on-policy sampling, off-policy training, gradient bias]
  - **authors:** Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, Nikolay Malkin, Moksh Jain, Siddarth Venkatraman, Aaron Courville
  - **institution:** Mila – Quebec AI Institute, Université de Montréal, McGill University, LLNL, University of Edinburgh, CIFAR
  - **link:** https://arxiv.org/pdf/2512.21852
  - **contributions:** 1. Systematic analysis of KL divergence estimator configurations in RL for LLMs, revealing how design choices introduce gradient bias. 2. Empirical demonstration that estimator configurations with unbiased gradients lead to better and more stable performance on both in-domain and out-of-domain tasks. 3. Investigation showing KL regularization can stabilize off-policy RL training in asynchronous setups.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the use of various estimators for the KL divergence regularization term in RL fine-tuning of LLMs, finding that common practices introduce biased gradients. Through experiments on models like Qwen2.5-7B, the study shows that using estimator configurations with unbiased gradients improves training stability and downstream task performance. The work also finds that KL regularization helps stabilize off-policy RL training.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Comedy of Estimators: On KL Regularization in RL Training of LLMs<br>论文标题"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>KL正则化估计器配置缺乏系统研究，梯度存在偏差"] --> P1["实践问题/Practical Issue<br>广泛使用但实现与目标不一致"]
        Problem --> P2["理论问题/Theoretical Issue<br>梯度偏差影响训练稳定性"]
        Method["主要方法/Method<br>分析梯度偏差并进行实证验证"] --> M1["分析/Analysis<br>研究多种估计器配置的梯度"]
        Method --> M2["实验/Experiments<br>RL微调多个LLM并评估性能"]
        Results["关键结果/Results<br>无偏梯度配置带来更好性能"] --> R1["在线策略/On-Policy<br>无偏梯度配置提升稳定性和性能"]
        Results --> R2["离线策略/Off-Policy<br>KL正则化有助于稳定异步训练"]
    ```

- **[arXiv251229] Balancing Accuracy and Efficiency: CNN Fusion Models for Diabetic Retinopathy Screening**
  - **tags:** [cv], [medical image classification], [feature-level fusion, convolutional neural networks, diabetic retinopathy screening, EfficientNet, DenseNet]
  - **authors:** Md Rafid Islam, Rafsan Jany, Akib Ahmed, Mohammad Ashrafuzzaman Khan
  - **institution:** North South University, Korea Institute of Oriental Medicine, American International University–Bangladesh
  - **link:** https://arxiv.org/pdf/2512.21861
  - **contributions:** 1. Proposes and evaluates feature-level fusion of complementary CNN backbones (ResNet50, EfficientNet-B0, DenseNet121) for binary diabetic retinopathy screening. 2. Demonstrates that fusion models consistently outperform single backbones in accuracy and generalization across a large, heterogeneous dataset pooled from five public sources. 3. Provides a practical analysis of the accuracy-efficiency trade-off, identifying the EfficientNet-B0 + DenseNet121 fusion as offering the best balance between performance and computational latency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d879fd7c14baee1110e20d8ebdaec476df8f8819b2fc9a74154be1d0a91d7963_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates feature-level fusion of CNN models to improve binary diabetic retinopathy screening. It finds that fusing EfficientNet-B0 and DenseNet121 achieves the best accuracy (82.89%) with a favorable balance of performance and inference speed, demonstrating that lightweight fusion enhances generalization across diverse datasets for scalable screening.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Balancing Accuracy and Efficiency: CNN Fusion Models for Diabetic Retinopathy Screening] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Large-scale DR screening is constrained by limited specialists and variable image quality.]
        C[主要方法/Method<br>Feature-level fusion of complementary CNN backbones (e.g., EfficientNet, DenseNet) on pooled fundus images.]
        D[关键结果/Results<br>Fusion outperforms single models. Eff+Den fusion offers best accuracy-latency balance.]
    ```

- **[arXiv251229] Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation**
  - **tags:** [sec], [Privacy-preserving machine learning], [dataset distillation, random forest, synthetic data generation, explainable AI, membership-inference attack]
  - **authors:** Yiming Qian, Thorsten Neumann, Xueyining Huang, David Hardoon, Fei Gao, Yong Liu, Siow Mong Rick Goh
  - **institution:** Institute of High Performance Computing (A*STAR), Standard Chartered Bank, Xi’an Jiaotong–Liverpool University
  - **link:** https://arxiv.org/pdf/2512.21866
  - **contributions:** 1. Proposes a privacy-preserving dataset distillation framework that converts a trained random forest into transparent rule regions and generates synthetic data by uniform sampling within these regions, creating a compact, auditable surrogate dataset. 2. Enables explainable AI by providing both global pattern summaries (e.g., support, lift) from aggregated rules and local, human-readable rationales with calibrated uncertainty for individual cases based on tree-vote disagreement. 3. Demonstrates strong utility-privacy trade-offs, showing the distilled data maintains competitive model performance (e.g., precision, F1) with significant data reduction (85-93%), improves cross-institution learning, and resists membership-inference attacks (AUC ~0.5), indicating low memorization risk.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6994d363f1e76d7cc78ab02d48685c11199b353aab61b3eb5297064b1df9b722_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a dataset distillation method for financial fraud detection that converts a random forest model into interpretable rule regions to generate synthetic data, preserving privacy and model utility. The approach produces a compact, explainable dataset that supports collaborative learning across institutions while resisting privacy attacks. Experiments show it reduces data volume by over 85% with minimal performance loss and enhances cross-cluster fraud detection.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("需要隐私保护的协作式欺诈检测/Need for privacy-preserving collaborative fraud detection")
        Problem --> P2("模型需要可解释性/Model needs explainability")
        Method --> M1("将随机森林转换为规则区域/Convert random forest to rule regions")
        Method --> M2("在区域内均匀采样生成合成数据/Uniformly sample within regions to generate synthetic data")
        Results --> R1("数据量减少85-93%/Data volume reduced by 85-93%")
        Results --> R2("保持竞争性性能/Maintains competitive performance")
        Results --> R3("抵抗成员推理攻击/Resists membership-inference attacks")
    ```

- **[arXiv251229] MMCTOP: A Multimodal Textualization and Mixture-of-Experts Framework for Clinical Trial Outcome Prediction**
  - **tags:** [mlsys], [multi-modal training], [multimodal fusion, sparse mixture-of-experts, schema-guided textualization, clinical trial prediction, temperature scaling]
  - **authors:** Carolina Aparício, Qi Shi, Bo Wen, Tesfaye Yadete, Qiwei Han
  - **institution:** Nova School of Business and Economics, Hogarthian Technologies, IBM Research, Cleveland Clinic, Oregon Health & Science University
  - **link:** https://arxiv.org/pdf/2512.21897
  - **contributions:** 1. A multimodal framework (MMCTOP) that integrates molecular structures, protocol metadata, eligibility narratives, and disease ontologies for clinical trial outcome prediction. 2. A novel architecture combining schema-guided textualization for data normalization and a drug-disease-conditioned sparse Mixture-of-Experts (SMoE) for context-aware, specialized multimodal fusion. 3. Demonstrates improved prediction performance (precision, F1, AUC) over baselines and incorporates operational safeguards like temperature scaling for calibrated probabilities to enhance auditability and reproducibility.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb552211ea905d5cbf8e190ead9078caf65c5d200327a02c7a6dab156a030645_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes MMCTOP, a multimodal framework for predicting clinical trial outcomes. It uses schema-guided textualization to normalize heterogeneous data and a sparse Mixture-of-Experts model for specialized fusion, achieving better performance than existing methods and providing calibrated risk estimates.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[MMCTOP: 多模态文本化与专家混合框架<br>MMCTOP: Multimodal Textualization and Mixture-of-Experts Framework] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br>多模态数据融合挑战<br>Multimodal Data Fusion Challenge] --> P1[高维生物医学信息学<br>High-Dim Biomedical Informatics]
        Method[主要方法/Method<br>多模态框架<br>Multimodal Framework] --> M1[模式感知表征学习<br>Modality-Aware Representation Learning]
        Method --> M2[架构设计/Architecture Design]
        M1 --> M1_1[领域特定编码器<br>Domain-Specific Encoders]
        M2 --> M2_1[模式感知表征学习<br>Modality-Aware Representation Learning]
        M2 --> M2_2[稀疏专家混合<br>Sparse Mixture-of-Experts (SMoE)]
        M2 --> M2_3[模式感知表征学习<br>Modality-Aware Representation Learning]
        Results[关键结果/Results<br>性能提升与校准<br>Performance & Calibration] --> R1[指标改进<br>Metric Improvements]
        Results --> R2[消融研究<br>Ablation Studies]
        Results --> R3[概率校准<br>Probability Calibration]
    ```

- **[arXiv251229] GQ-VAE: A gated quantized VAE for learning variable length tokens**
  - **tags:** [nlp], [tokenization], [GQ-VAE, variable-length tokens, VQ-VAE, neural tokenizer, byte-pair encoding]
  - **authors:** Theo Datta, Kayla Huang, Sham Kakade, David Brandfonbrener
  - **institution:** Kempner Institute, Harvard University
  - **link:** https://arxiv.org/pdf/2512.21913
  - **code:** https://github.com/Theo-Datta-115/gq-vae
  - **contributions:** 1. Proposes GQ-VAE, a novel gated quantized variational autoencoder architecture for learning discrete, variable-length tokens. 2. Demonstrates the model can serve as a standalone, pre-trained drop-in replacement for existing tokenizers, improving over fixed-chunk baselines. 3. Shows that with equivalent compression, GQ-VAE improves downstream language model learning compared to BPE.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49412452efda1a18023f64f968f3406b217d747381b47a09694b7d37c61c918a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limitations of traditional tokenizers like BPE and complex neural tokenizers by proposing GQ-VAE, a novel architecture that learns variable-length discrete tokens. GQ-VAE can be independently pre-trained as a drop-in replacement, approaching BPE's performance and, under equivalent compression, improving downstream language model learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[GQ-VAE: A gated quantized VAE for learning variable length tokens] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[传统分词器如BPE是确定性的/Traditional tokenizers like BPE are deterministic]
        Problem --> P2[神经分词器复杂且难集成/Neural tokenizers are complex and hard to integrate]
        Method[主要方法/Method] --> M1[提出GQ-VAE架构/Propose GQ-VAE architecture]
        Method --> M2[学习变长离散令牌/Learn variable-length discrete tokens]
        Method --> M3[可独立预训练/Can be independently pre-trained]
        Results[关键结果/Results] --> R1[压缩和语言建模性能接近BPE/Compression & LM performance approaches BPE]
        Results --> R2[在同等压缩下提升下游LM学习/Improves downstream LM learning at equivalent compression]
    ```

- **[arXiv251229] Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs**
  - **tags:** [mlsys], [others], [Tabular Data Generation, Large Language Models, Multi-Arm Bandit, Data Diversity, In-context Learning]
  - **authors:** Yafeng Tang, Xiaoou Ding, Jianzhuo Du, Zishuo Yan, Zhuang Ma, Zheng Liang, Zekai Qian, Hongzhi Wang
  - **institution:** Harbin Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.21915
  - **code:** https://github.com/windblow32/DATE
  - **contributions:** 1. Introduces DATE, a framework that partitions heterogeneous tabular data into diverse subsets to prepare high-quality examples for in-context learning. 2. Proves the selection problem in heterogeneous data generation lacks the greedy-choice property and designs a Multi-Arm Bandit-based sampling algorithm to balance diversity and quality. 3. Demonstrates that DATE-generated data improves downstream tasks like Direct Preference Optimization (DPO) and enhances LLM reasoning on target data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d8fa8039f8a5fa0717fc5e4a9c7ba2cf1fd158e44821059f4a767bc88790eaf_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of generating high-quality synthetic tabular data from heterogeneous distributions. It proposes DATE, a framework that uses LLMs with decision tree feedback for subset-specific generation and a Multi-Arm Bandit algorithm for data selection. Experiments show DATE outperforms existing methods, reducing error rates and improving downstream model performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs"] --> Problem["核心问题/Problem: Real-world tabular data is heterogeneous, making universal generation models challenging"]
        Root --> Method["主要方法/Method: DATE framework partitions data, uses LLMs with decision tree feedback, and applies Multi-Arm Bandit for selection"]
        Root --> Results["关键结果/Results: Outperforms SOTA methods, reduces error rate by 23.75%, improves DPO and LLM reasoning"]
    ```

- **[arXiv251229] Semiparametric Preference Optimization: Your Language Model is Secretly a Single-Index Model**
  - **tags:** [ai], [reinforcement learning from human feedback (rlhf)], [preference optimization, single-index model, semiparametric, link function, policy learning]
  - **authors:** Nathan Kallus
  - **institution:** Netflix, Cornell University
  - **link:** https://arxiv.org/pdf/2512.21917
  - **contributions:** 1. Formulates policy alignment as a semiparametric single-index model problem, relaxing the need for a known link function between preferences and rewards. 2. Develops novel policy learners based on profiling, orthogonalizing, and link-agnostic ranking objectives, providing theoretical error bounds. 3. Proposes practical first-order optimization implementations that are robust to unknown preference noise and scale, enabling direct policy optimization without explicit reward fitting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/378875cc0ef0eb142c184d960e479724ea3df83c84cf81e185efea5469a4387e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of bias in aligning language models when the assumed link function between human preferences and latent rewards is misspecified. It proposes a semiparametric framework that treats the link function as unknown, develops several robust policy learning algorithms, and provides theoretical guarantees. The main conclusion is that this approach enables more reliable policy alignment without needing to correctly specify the preference noise distribution.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Semiparametric Preference Optimization<br>你的语言模型是一个单指标模型"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["核心问题/Problem<br>已知链接函数错误导致策略偏差<br>Misspecified link function causes policy misalignment"]
        Method["主要方法/Method<br>将链接函数视为未知的半参数单指标模型<br>Treat link as unknown semiparametric single-index model"]
        Results["关键结果/Results<br>开发鲁棒的策略学习器并提供理论保证<br>Develop robust policy learners with theoretical guarantees"]
    ```

- **[arXiv251229] AutoPP: Towards Automated Product Poster Generation and Optimization**
  - **tags:** [cv], [image generation], [product poster generation, click-through rate optimization, isolated direct preference optimization, AutoPP1M dataset, unified design module]
  - **authors:** Jiahao Fan, Yuxin Qin, Wei Feng, Yanyin Chen, Yaoyu Li, Ao Ma, Yixiu Li, Li Zhuang, Haoyi Bian, Zheng Zhang, Jingjing Lv, Junjie Shen, Ching Law
  - **institution:** JD.COM
  - **link:** https://arxiv.org/pdf/2512.21921
  - **code:** https://github.com/JD-GenX/AutoPP
  - **contributions:** 1. An automated pipeline (AutoPP) for end-to-end product poster generation and optimization, requiring only basic product information as input. 2. A novel optimization method that uses systematic element replacement and Isolated Direct Preference Optimization (IDPO) to attribute CTR gains to specific poster elements. 3. The creation and release of AutoPP1M, the largest dataset for product poster generation and optimization, containing one million posters and user feedback.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f18700c508d46682b8040947d4af38f1b6c821d269a8518370be8bf9c574fe71_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces AutoPP, an automated pipeline that generates product posters from basic product information and then optimizes them for higher Click-Through Rate (CTR) using online feedback and a novel Isolated Direct Preference Optimization technique. It is supported by a large-scale dataset, AutoPP1M. Experiments show that AutoPP achieves state-of-the-art performance in both offline and online evaluations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AutoPP: Towards Automated Product Poster Generation and Optimization] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[人工制作与优化海报耗时耗力/Manual poster creation and optimization is laborious]
        C --> C1[自动化生成与优化管道/Automated generation and optimization pipeline]
        C1 --> C1_1[生成器: 统一设计模块与元素渲染/Generator: Unified design & element rendering]
        C1 --> C1_2[优化器: 元素替换与IDPO/Optimizer: Element replacement & IDPO]
        C --> C2[数据集: AutoPP1M/Dataset: AutoPP1M]
        D --> D1[离线和在线SOTA结果/Offline and online SOTA results]
        D --> D2[代码与数据集公开/Code & dataset released]
    ```

- **[arXiv251229] Data relativistic uncertainty framework for low-illumination anime scenery image enhancement**
  - **tags:** [cv], [low-light image enhancement], [Data Relativistic Uncertainty, Unsupervised Learning, EnlightenGAN, Anime Scenery, Domain Gap]
  - **authors:** Yiquan Gao, John See
  - **institution:** Heriot-Watt University
  - **link:** https://arxiv.org/pdf/2512.21944
  - **contributions:** 1. Constructed an unpaired anime scenery dataset to address data scarcity for the underexplored task of low-illumination anime image enhancement. 2. Proposed a Data Relativistic Uncertainty (DRU) framework, inspired by Relativistic GAN, to interpretably define and quantify illumination uncertainty. 3. Demonstrated that dynamically adjusting objective functions based on data uncertainty leads to superior perceptual and aesthetic quality compared to state-of-the-art methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/884273bf5357a2746f38f8b7d66727daf4d692ca1d5b3c247dfd4e89a209fdef_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of enhancing low-illumination anime scenery images, a task with a domain gap from natural image enhancement. The authors propose a Data Relativistic Uncertainty (DRU) framework that quantifies illumination uncertainty to dynamically recalibrate model learning. Experiments show their method, applied to EnlightenGAN variants, outperforms existing methods in perceptual and aesthetic quality.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Data relativistic uncertainty framework for low-illumination anime scenery image enhancement") --> Problem
        Root --> Method
        Root --> Results
        Problem("核心问题/Problem: Low-illumination quality degradation in anime scenery images, an underexplored task with a domain gap from natural images.")
        Method("主要方法/Method: Propose a Data Relativistic Uncertainty (DRU) framework to quantify illumination uncertainty and dynamically adjust objective functions for model recalibration.")
        Results("关键结果/Results: DRU framework yields superior perceptual and aesthetic qualities beyond state-of-the-art methods.")
    ```

- **[arXiv251229] Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms**
  - **tags:** [ai], [multi-armed bandits], [combinatorial multi-armed bandits, probabilistically triggered arms, hybrid learning, offline data, online interaction]
  - **authors:** Kongchang Zhou, Tingyu Zhang, Wei Chen, Fang Kong
  - **institution:** Southern University of Science and Technology, Microsoft Research
  - **link:** https://arxiv.org/pdf/2512.21925
  - **contributions:** 1. Proposes a new hybrid CMAB-T framework that integrates offline data with online interaction to address the complementary weaknesses of purely online or offline methods. 2. Introduces the hybrid CUCB algorithm, which leverages offline data to guide exploration and strategically uses online interactions to correct dataset bias. 3. Provides theoretical regret guarantees and empirical results demonstrating the algorithm's consistent advantage over purely online or offline baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e97b8cf09a0691d48238a8272fecd32791ddc20b9ba00115a757d778b1e2017f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a hybrid framework for combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) that combines offline data with online interaction. The core method is the hybrid CUCB algorithm, which uses offline data to accelerate learning and online interaction to correct for dataset limitations. Theoretical and empirical results show this hybrid approach outperforms purely online or offline methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Hybrid CMAB-T<br>混合组合多臂老虎机") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("在线方法成本高、适应慢<br>Online: High Cost, Slow")
        Problem --> P2("离线方法受数据质量限制<br>Offline: Data Quality Limits")
        Method --> M1("提出混合CMAB-T框架<br>Propose Hybrid CMAB-T Framework")
        Method --> M2("设计混合CUCB算法<br>Design Hybrid CUCB Algorithm")
        M2 --> M2a("利用离线数据引导探索<br>Use Offline Data to Guide")
        M2 --> M2b("结合在线交互纠正偏差<br>Use Online to Correct Bias")
        Results --> R1("理论悔恨界保证<br>Theoretical Regret Guarantee")
        Results --> R2("实验显示一致优势<br>Empirical Consistent Advantage")
    ```

- **[arXiv251229] Look Closer! An Adversarial Parametric Editing Framework for Hallucination Mitigation in VLMs**
  - **tags:** [mlsys], [multi-modal training], [hallucination mitigation, adversarial parametric editing, parameter clustering, visual-language models, activation dataset]
  - **authors:** Jiayu Hu, Beibei Li, Jiangwei Xia, Yanjun Qin, Bing Ji, Zhongshi He
  - **institution:** Chongqing University, Xinjiang University
  - **link:** https://arxiv.org/pdf/2512.21999
  - **code:** https://github.com/hujiayu1223/ALEAHallu
  - **contributions:** 1. Proposes a novel adversarial parametric editing framework (ALEAHallu) following an Activate-Locate-Edit Adversarially paradigm for mitigating hallucinations in VLMs. 2. Introduces a method to construct an activation dataset with grounded and hallucinatory response pairs and identifies critical hallucination-prone parameter clusters via differential hidden state analysis. 3. Demonstrates the framework's effectiveness by fine-tuning identified parameter clusters with adversarially tuned prefixes to force the model to prioritize visual evidence over linguistic priors.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d0943d59c080a6d39ec6bf82dc20b417033bcda2fee9178d9a845e37b90a47c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the hallucination problem in Vision-Language Models (VLMs), where models generate content misaligned with visual inputs due to over-reliance on linguistic priors. The authors propose ALEAHallu, an adversarial parametric editing framework that identifies and fine-tunes hallucination-prone parameter clusters using adversarially optimized prompts to enhance visual grounding. Evaluations show the method significantly reduces hallucinations in both generative and discriminative VLM tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Look Closer! An Adversarial Parametric Editing Framework for Hallucination Mitigation in VLMs] --> B
        A --> C
        A --> D
        B[核心问题/Problem: VLM幻觉问题/VLM Hallucination Issue]
        C[主要方法/Method: ALEAHallu框架/ALEAHallu Framework]
        D[关键结果/Results: 有效缓解幻觉/Effectively Mitigates Hallucinations]
        C --> C1[激活数据集/Activation Dataset]
        C --> C2[定位关键参数/Locate Critical Parameters]
        C --> C3[对抗性编辑/Adversarial Editing]
    ```

- **[arXiv251229] DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction**
  - **tags:** [ai], [computational biology], [protein language model, ESM-2, dual-stream architecture, 1D CNN, transformer encoder]
  - **authors:** Aicha Boutorh, Soumia Bouyahiaoui, Sara Belhadj, Nour El Yakine Guendouz, Manel Kara Laouar
  - **institution:** National School of Artificial Intelligence (ENSIA)
  - **link:** https://arxiv.org/pdf/2512.22007
  - **contributions:** 1. Proposes DuaDeep-SeqAffinity, a novel sequence-only deep learning framework for antigen-antibody affinity prediction using a dual-stream hybrid architecture. 2. Integrates pre-trained ESM-2 embeddings with 1D CNNs for local motifs and Transformer encoders for global context, followed by a fusion module. 3. Demonstrates superior performance over single-branch models and existing SOTA methods, even surpassing some structure-sequence hybrid models, proving the efficacy of sequence-only high-fidelity embeddings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1985304be62407b10b5e5be53aea80fe4ff1468be03e261847b49774ddd937a8_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces DuaDeep-SeqAffinity, a deep learning framework that predicts antigen-antibody binding affinity using only amino acid sequences. It combines ESM-2 embeddings with a dual-stream architecture of 1D CNNs and Transformers to capture local and global features. The model outperforms existing methods, showing that sequence-only models can effectively capture binding patterns and accelerate therapeutic discovery.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DuaDeep-SeqAffinity: 序列抗原-抗体亲和力预测 / Sequence-Only Antigen-Antibody Affinity Prediction] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统方法依赖稀缺的3D结构 / Traditional methods rely on scarce 3D structures]
        C --> C1[双流混合架构 / Dual-Stream Hybrid Architecture]
        C1 --> C2[使用ESM-2嵌入 / Uses ESM-2 Embeddings]
        C1 --> C3[1D CNN检测局部模式 / 1D CNN for Local Motifs]
        C1 --> C4[Transformer编码全局上下文 / Transformer for Global Context]
        C1 --> C5[融合模块整合特征 / Fusion Module Integrates Features]
        D --> D1[性能超越SOTA / Outperforms SOTA]
        D --> D2[皮尔逊相关: 0.688 / Pearson: 0.688]
        D --> D3[AUC: 0.890]
        D --> D4[证明序列嵌入的有效性 / Proves Efficacy of Sequence Embeddings]
    ```

- **[arXiv251229] HWL-HIN: A Hypergraph-Level Hypergraph Isomorphism Network as Powerful as the Hypergraph Weisfeiler-Lehman Test with Application to Higher-Order Network Robustness**
  - **tags:** [ai], [graph neural networks], [hypergraph isomorphism network, hypergraph weisfeiler-lehman test, higher-order network robustness, hypergraph neural networks]
  - **authors:** Chengyu Tian, Wenbin Pei
  - **institution:** Not explicitly stated in the provided content.
  - **link:** https://arxiv.org/pdf/2512.22014
  - **contributions:** 1. Proposes a hypergraph-level Hypergraph Isomorphism Network (HWL-HIN) framework for hypergraph learning. 2. Theoretically proves the model's expressive power is strictly equivalent to the Hypergraph Weisfeiler-Lehman test. 3. Successfully applies the model to predict hypergraph robustness, demonstrating superior performance and efficiency over existing graph-based and conventional HGNN models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3b228ae57b3d7937d8586b0c60419df83b49466ba7ca3b946109dd8186f827c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the computational overhead of traditional robustness assessment and the limited expressive power of existing hypergraph neural networks by proposing a hypergraph-level Hypergraph Isomorphism Network (HWL-HIN). The method is proven theoretically to be as powerful as the Hypergraph Weisfeiler-Lehman test and is applied to predict hypergraph robustness. Experiments show it outperforms existing graph-based models and conventional HGNNs in tasks prioritizing topological structure while maintaining high efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HWL-HIN: Hypergraph-Level Hypergraph Isomorphism Network] --> B(核心问题/Problem: High computational cost of robustness assessment; Limited expressive power of HGNNs)
        A --> C(主要方法/Method: Propose HWL-HIN framework inspired by GIN; Prove expressive power equivalent to Hypergraph WL test)
        A --> D(关键结果/Results: Outperforms graph-based models and HGNNs; Maintains superior efficiency)
    ```

- **[arXiv251229] From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation**
  - **tags:** [ai], [generative models for drug discovery], [hit-like molecule generation, autoregressive models, diffusion models, docking scores, multi-stage filtering]
  - **authors:** Nagham Osman, Vittorio Lembo, Giovanni Bottegoni, Laura Toni
  - **institution:** University College London, University of Urbino Carlo Bo
  - **link:** https://arxiv.org/pdf/2512.22031
  - **contributions:** 1. Framing hit-like molecule generation as a standalone task for generative models. 2. Proposing a tailored evaluation framework integrating physicochemical, structural, and bioactivity criteria. 3. Benchmarking autoregressive and diffusion models, with synthesized GSK-3β hits confirmed active in vitro.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2a0d0d188f2e13e0f8561de5950d5637586c871a0ee36935ebfbd5bb2bad540_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether generative models can replace the hit identification step in drug discovery. It proposes a multi-stage evaluation framework and benchmarks autoregressive and diffusion models, showing they can generate valid, diverse, and biologically relevant compounds, with some synthesized hits confirmed active in vitro.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("Hit identification is resource-intensive/命中识别资源密集")
        Method --> M1("Propose tailored evaluation framework/提出定制评估框架")
        Method --> M2("Benchmark autoregressive & diffusion models/基准测试自回归和扩散模型")
        Results --> R1("Models generate valid, diverse, bioactive compounds/模型生成有效、多样、有生物活性的化合物")
        Results --> R2("Selected hits synthesized & confirmed active/选定命中物被合成并确认有效")
    ```

- **[arXiv251229] Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing**
  - **tags:** [other], [signal processing], [DOA estimation, sparse arrays, coarrays, spatial smoothing, MUSIC]
  - **authors:** Wesley S. Leite, Rodrigo C. de Lamare, Yuriy Zakharov, Wei Liu, Martin Haardt
  - **institution:** University of York, Pontifical Catholic University of Rio de Janeiro, University of York, University of York, Ilmenau University of Technology
  - **link:** https://arxiv.org/pdf/2512.22024
  - **contributions:** 1. Introduces a variable window size (VWS) spatial smoothing framework for coarray-based DOA estimation with sparse linear arrays. 2. Proposes the VWS-CA-MUSIC and VWS-CA-rMUSIC algorithms that replace perturbed data terms with unperturbed ones to improve signal-noise subspace separation. 3. Derives theoretical bounds for the compression parameter to guarantee identifiability and demonstrates performance improvements and complexity savings over fixed-window methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/20bb39a95f66255cc62bbe7ee6e002de101d9a346c703b72e27fc3d3b08e1d30_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of direction-of-arrival (DOA) estimation for correlated sources using sparse linear arrays. It proposes a variable window size spatial smoothing framework and new VWS-CA-MUSIC algorithms that enhance estimation accuracy by compressing the smoothing aperture. Simulations show the method provides significant performance gains and reduced computational complexity compared to standard fixed-window coarray MUSIC.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[DOA估计精度下降/DOA estimation accuracy degrades for correlated/coherent sources]
        C --> C1[可变窗口空间平滑/Variable Window Size Spatial Smoothing]
        C --> C2[压缩平滑孔径/Compressing the smoothing aperture]
        C --> C3[VWS-CA-MUSIC算法/VWS-CA-MUSIC algorithm]
        D --> D1[提高信噪子空间分离/Increased signal-noise subspace separation]
        D --> D2[性能提升与复杂度降低/Performance improvements and complexity savings]
    ```

- **[arXiv251229] LibContinual: A Comprehensive Library towards Realistic Continual Learning**
  - **tags:** [mlsys], [others], [catastrophic forgetting, stability-plasticity dilemma, modular architecture, memory budget, online continual learning]
  - **authors:** Wenbin Li, Shangge Liu, Borui Kang, Yiyang Chen, KaXuan Lew, Yang Chen, Yinghuan Shi, Lei Wang, Yang Gao, Jiebo Luo
  - **institution:** Nanjing University, University of Wollongong, University of Rochester
  - **link:** https://arxiv.org/pdf/2512.22029
  - **code:** https://github.com/RL-VIG/LibContinual
  - **contributions:** 1. Proposed LibContinual, a unified, modular, and reproducible library for Continual Learning (CL) that integrates 19 representative algorithms across five methodological categories. 2. Systematically identified and investigated three unrealistic implicit assumptions (offline data accessibility, unregulated memory, intra-task semantic homogeneity) prevalent in mainstream CL evaluation. 3. Conducted a comprehensive analysis under stricter, more realistic settings (strict online CL, unified memory budget, category-randomized tasks), revealing significant performance drops in many existing methods and highlighting the need for resource-aware and semantically robust CL strategies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a733a967f663a216bbd5fb0cee657ed8bb70a4e6f0205d669f983cbf9bb6fd_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces LibContinual, a comprehensive library designed to unify and standardize research in Continual Learning (CL). By using this framework to evaluate existing methods under more realistic constraints, the study shows that many current CL algorithms suffer significant performance drops, underscoring the gap between common evaluation practices and real-world applicability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LibContinual: A Comprehensive Library towards Realistic Continual Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[研究碎片化，缺乏统一框架/Fragmented research landscape, lack of unified framework]
        B --> B2[评估存在不现实的隐含假设/Unrealistic implicit assumptions in evaluation]
        C --> C1[构建模块化、可复现的库/Build a modular, reproducible library]
        C --> C2[集成19种代表性算法/Integrate 19 representative algorithms]
        C --> C3[在更现实的设定下系统评估/Systematically evaluate under more realistic settings]
        D --> D1[现有方法在现实约束下性能显著下降/Existing methods show significant performance drop under realistic constraints]
        D --> D2[强调资源感知和语义鲁棒策略的必要性/Highlight the necessity of resource-aware and semantically robust strategies]
    ```

- **[arXiv251229] Why Smooth Stability Assumptions Fail for ReLU Learning**
  - **tags:** [ai], [optimization theory], [ReLU networks, nonsmooth optimization, stability analysis, generalized derivatives, learning dynamics]
  - **authors:** Ronald Katende
  - **institution:** Kabale University
  - **link:** https://arxiv.org/pdf/2512.22055
  - **contributions:** 1. Demonstrates that no uniform smoothness-based stability proxy (e.g., gradient Lipschitzness) can hold globally for ReLU networks, even in simple, empirically stable settings. 2. Provides a concrete counterexample showing the failure of classical stability bounds for ReLU learning dynamics. 3. Identifies a minimal generalized derivative condition under which stability statements can be meaningfully restored for nonsmooth learning systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3150186f6ab289f5e6db87d8ca89851af409290b0b4c37667d493ee4b7e894b_w640_q70.webp
  - **Simple LLM Summary:** The paper shows that smoothness assumptions like gradient Lipschitzness, commonly used in stability analyses, fail globally for ReLU networks due to their inherent nonsmoothness. It provides a counterexample to classical bounds and proposes a minimal condition based on generalized derivatives to restore meaningful stability analysis. This clarifies the limitations of smooth approximations and motivates nonsmooth-aware frameworks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Why Smooth Stability Assumptions Fail for ReLU Learning] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Smooth stability assumptions are violated by ReLU networks.]
        C[主要方法/Method<br>Provide counterexample and identify minimal generalized derivative condition.]
        D[关键结果/Results<br>Classical bounds fail; stability can be restored under nonsmooth-aware condition.]
    ```

- **[arXiv251229] Scaling Adversarial Training via Data Selection**
  - **tags:** [ai], [adversarial robustness], [adversarial training, PGD, sample selection, gradient matching, margin-based sampling]
  - **authors:** Youran Ye, Dejin Wang, Ajinkya Bhandare
  - **institution:** Northeastern University
  - **link:** https://arxiv.org/pdf/2512.22069
  - **code:** https://github.com/youranye/Selective-Adversarial-Training
  - **contributions:** 1. Proposes Selective Adversarial Training, which perturbs only a critical subset of samples per minibatch to reduce computational cost., 2. Introduces two novel sample selection criteria: margin-based sampling and gradient-matching sampling., 3. Demonstrates that the method achieves comparable or superior robustness to full PGD adversarial training while reducing adversarial computation by up to 50%.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad822d1db3ef050d2caa84f51828c7b48f93eee442f9a9f954f4f36b07929f44_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high computational cost of Projected Gradient Descent (PGD) in adversarial training. It proposes Selective Adversarial Training, which uses principled criteria to select and perturb only critical samples in each batch. Experiments show the method maintains robustness while cutting adversarial computation by up to 50%.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Scaling Adversarial Training via Data Selection] --> B[核心问题/Problem: PGD计算成本高/High PGD Computational Cost]
        A --> C[主要方法/Method: 选择性对抗训练/Selective Adversarial Training]
        C --> D[选择标准1: 基于边界的采样/Margin-based Sampling]
        C --> E[选择标准2: 梯度匹配采样/Gradient-matching Sampling]
        A --> F[关键结果/Results: 鲁棒性相当，计算减少50%/Comparable Robustness, 50% Computation Reduction]
    ```

- **[arXiv251229] Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling**
  - **tags:** [mlsys], [llm inference], [SRAM, frequency scaling, energy-delay product, systolic array, memory bandwidth]
  - **authors:** Hannah Atmer, Yuan Yao, Thiemo Voigt, Stefanos Kaxiras
  - **institution:** Uppsala University
  - **link:** https://arxiv.org/pdf/2512.22066
  - **contributions:** 1. Quantified the distinct energy and performance impacts of SRAM size and operating frequency on the compute-bound prefill and memory-bound decode phases of LLM inference. 2. Demonstrated a counter-intuitive result: high compute frequency can reduce total energy by shortening execution time and reducing static energy more than the dynamic power increase. 3. Identified an optimal hardware configuration (high frequency, small SRAM buffer) that minimizes the energy-delay product, providing concrete design insights for energy-efficient accelerators.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how on-chip SRAM size and operating frequency affect the energy efficiency of LLM inference. Using a simulation methodology combining OpenRAM, LLMCompass, and ScaleSIM, it finds that a high-frequency, small-SRAM configuration optimizes the energy-delay product, as memory bandwidth caps decode phase improvements. The analysis provides architectural guidance for designing efficient LLM accelerators.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>LLM推理能耗高，Prefill与Decode阶段瓶颈不同"] --> Problem_Sub1["SRAM大小与频率如何影响能效？"]
        Problem --> Problem_Sub2["内存带宽如何限制性能？"]
        Method["主要方法/Method<br>结合OpenRAM, LLMCompass, ScaleSIM的模拟方法"] --> Method_Sub1["能耗建模/Energy Modeling"]
        Method --> Method_Sub2["延迟模拟/Latency Simulation"]
        Method --> Method_Sub3["操作强度分析/Operational Intensity"]
        Results["关键结果/Results"] --> Results_Sub1["总能耗主要由SRAM大小决定<br>大缓存增加静态能耗"]
        Results --> Results_Sub2["高频可降低总能耗<br>（减少静态能耗）"]
        Results --> Results_Sub3["最优配置：高频(1200-1400MHz) + 小缓存(32-64KB)"]
    ```

- **[arXiv251229] Unifying Learning Dynamics and Generalization in Transformers Scaling Law**
  - **tags:** [ai], [learning theory], [scaling law, learning dynamics, generalization error, transformer, stochastic gradient descent]
  - **authors:** Chiwun Yang
  - **institution:** Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.22088
  - **contributions:** 1. Formalizes the learning dynamics of transformers as an ODE system and approximates it to kernel behaviors, moving beyond toy models to analyze SGD on multi-layer transformers with arbitrary data distributions. 2. Establishes a theoretical upper bound on excess risk with a distinct phase transition: exponential decay in the optimization phase and a power-law decay of Θ(C^\{-1/6\}) in the statistical phase. 3. Derives isolated scaling laws for model size, training time, and dataset size, explaining how each variable independently governs generalization bounds.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9b067b56202cd4607e684058e78ac331373bf12bf6848ca444276e2dcafe9f9_w640_q70.webp
  - **Simple LLM Summary:** This paper provides a theoretical foundation for the empirical scaling laws of large language models. It models transformer learning dynamics as an ODE system and analyzes SGD training on realistic data. The main result is a unified theory showing a phase transition in generalization error, from exponential to power-law decay, as computational resources scale.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Unifying Learning Dynamics and Generalization in Transformers Scaling Law] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Scaling Law理论原理不清 / Poorly understood theoretical underpinnings of scaling laws]
        C --> C1[形式化学习动态为ODE系统 / Formalize learning dynamics as ODE system]
        C --> C2[近似为核行为 / Approximate to kernel behaviors]
        C --> C3[分析SGD训练真实Transformer / Analyze SGD training for real transformers]
        D --> D1[泛化误差上界与相变 / Upper bound on excess risk with phase transition]
        D --> D2[优化相:指数衰减 / Optimization phase: Exponential decay]
        D --> D3[统计相:幂律衰减 Θ(C^{-1/6}) / Statistical phase: Power-law decay Θ(C^{-1/6})]
        D --> D4[分离的规模定律 / Isolated scaling laws for model size, time, data]
    ```

- **[arXiv251229] A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting**
  - **tags:** [mlsys], [agent system], [multi-agent pipeline, automated data analysis, insight generation, report synthesis, visual analytics]
  - **authors:** Shuyu Gan, Renxiang Wang, James Mooney, Dongyeop Kang
  - **institution:** University of Minnesota
  - **link:** https://arxiv.org/pdf/2512.22101
  - **contributions:** 1. A Data Analyzer agent that orchestrates data profiling, generates diverse visualizations, filters low-quality charts, and automatically scores candidate insights for depth, correctness, and actionability. 2. A Presenter agent that sequences topics, composes chart-grounded narratives from top insights, writes transitions, and revises the document to produce a coherent, publication-ready report. 3. An end-to-end Analyzer-to-Presenter (A2P) pipeline that operationalizes co-analysis by coupling quality-assured analysis with narrative synthesis, improving the real-world usefulness of automated data analysis.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92651ded84480402816f8db1df902e28dd62cce1b0958cece60e0f518bdd7e1c_w640_q70.webp
  - **Simple LLM Summary:** This paper presents A2P-Vis, a two-part multi-agent pipeline designed to automate the generation of data visualization reports. The system uses a Data Analyzer to create and vet visual insights and a Presenter to assemble them into a coherent narrative. The authors claim this end-to-end approach improves the practical utility of automated data analysis for practitioners.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A2P-Vis] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[自动化数据科学流程的瓶颈/Gaps in automating data science]
        B1 --> B2[生成有洞察力的可视化/Generating insightful visual evidence]
        B1 --> B3[组装成专业报告/Assembling coherent professional report]
        C --> C1[两部分多智能体管道/Two-part multi-agent pipeline]
        C1 --> C2[数据分析器/Data Analyzer]
        C2 --> C3[生成并评估图表与洞察/Generates & evaluates charts & insights]
        C1 --> C4[报告呈现器/Presenter]
        C4 --> C5[编排主题并撰写叙述/Orders topics & composes narrative]
        D --> D1[端到端协同分析/End-to-end co-analysis]
        D1 --> D2[提高自动化数据分析的实用性/Improves usefulness of automated analysis]
    ```

- **[arXiv251229] Explainable Multimodal Regression via Information Decomposition**
  - **tags:** [ai], [multimodal machine learning], [Partial Information Decomposition (PID), multimodal regression, interpretability, Gaussianity assumption, conditional independence regularizer]
  - **authors:** Zhaozhao Ma, Shujian Yu
  - **institution:** Zhejiang University, Georgia Institute of Technology, Vrije Universiteit Amsterdam, UiT - The Arctic University of Norway
  - **link:** https://arxiv.org/pdf/2512.22102
  - **code:** https://github.com/xxx/PIDReg (URL placeholder from abstract)
  - **contributions:** 1. A novel multimodal regression framework based on Partial Information Decomposition (PID) to quantify unique, redundant, and synergistic information from modalities. 2. Introduction of a Gaussianity assumption to resolve the underdetermined nature of PID, enabling analytical computation of its terms. 3. Derivation of a closed-form conditional independence regularizer to isolate unique information within each modality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a07cab8b6bb765060f8a015e46e79e686a9acb69bac3aa8045cf96acec9f61e6_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of interpretability in multimodal regression by proposing a new framework based on Partial Information Decomposition (PID). The method resolves PID's underdetermination by enforcing Gaussianity and uses a conditional independence regularizer to isolate unique modality information. Experiments on six datasets, including brain age prediction, show the framework outperforms state-of-the-art methods in both accuracy and interpretability, while aiding modality selection.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Explainable Multimodal Regression via Information Decomposition<br/>可解释多模态回归与信息分解] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有方法缺乏量化模态贡献与交互的工具<br/>Existing methods lack tools to quantify modality contributions & interactions]
        C --> C1[基于PID分解模态信息<br/>Decompose modality info via PID]
        C --> C2[引入高斯性假设与正则化<br/>Introduce Gaussianity & regularizer]
        D --> D1[在6个数据集上超越SOTA<br/>Outperforms SOTA on 6 datasets]
        D --> D2[提升预测精度与可解释性<br/>Improves predictive accuracy & interpretability]
    ```

- **[arXiv251229] Sensitivity Analysis of the Consistency Assumption**
  - **tags:** [other], [causal inference], [consistency assumption, sensitivity analysis, hidden versions of treatment, partial identification, stable unit treatment value assumption (SUTVA)]
  - **authors:** Brian Knaeble, Qinyun Lin, Erich Kummerfeld, Kenneth A. Frank
  - **institution:** Utah Valley University, University of Gothenburg, University of Minnesota, Michigan State University
  - **link:** https://arxiv.org/pdf/2512.21379
  - **contributions:** 1. A formal mathematical framework for analyzing violations of the consistency assumption. 2. A novel sensitivity parameter to quantify bias induced by hidden versions of treatment. 3. Methods for specifying bounds on this parameter to enable partial identification of causal effects.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0816c25e8631081977ffb91ecadbb3f527cfd99c7daf15f81c3f18a332125fcc_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses violations of the consistency assumption in causal inference, which posits no hidden versions of treatment. It proposes a new sensitivity analysis method focused on confounding by hidden treatment versions, introducing a formal framework and a novel sensitivity parameter. The work enables researchers to assess and bound the bias from consistency violations when interpreting causal estimates.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Sensitivity Analysis of the Consistency Assumption] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[一致性假设可能被违反/Consistency Assumption May Be Violated]
        B1 --> B2[存在隐藏的治疗版本/Hidden Versions of Treatment Exist]
        C --> C1[新颖的敏感性分析方法/Novel Sensitivity Analysis Method]
        C1 --> C2[专注于隐藏版本导致的混杂/Focus on Confounding by Hidden Versions]
        C2 --> C3[引入新的数学符号/Introduces New Mathematical Notation]
        D --> D1[提出新的敏感性参数/Proposes New Sensitivity Parameter]
        D1 --> D2[便于部分识别因果估计量/Facilitates Partial Identification of Causal Estimands]
    ```

- **[arXiv251229] Dynamic Attention (DynAttn): Interpretable High-Dimensional Spatio-Temporal Forecasting (with Application to Conflict Fatalities)**
  - **tags:** [ai], [spatio-temporal forecasting], [dynamic attention, zero-inflated negative binomial, elastic-net gating]
  - **authors:** Stefano M. Iacus, Haodong Qi, Marcello Carammia, Thomas Juneau
  - **institution:** Harvard University, Stockholm University, Malmö University, University of Catania, University of Toronto
  - **link:** https://arxiv.org/pdf/2512.21435
  - **contributions:** 1. Introduces DynAttn, an interpretable dynamic-attention framework for high-dimensional spatio-temporal count processes. 2. Combines rolling-window estimation, shared elastic-net feature gating, a compact self-attention encoder, and a ZINB likelihood for calibrated forecasts. 3. Demonstrates superior predictive accuracy and enables structured interpretation of regional conflict dynamics, showing the roles of persistence, diffusion, and climate stress.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad96b82177be36f56ddfe0b4e4d6be51396aa49723cdabef2c85f538301f2e0e_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces DynAttn, an interpretable forecasting framework for sparse, high-dimensional spatio-temporal data like conflict fatalities. It combines dynamic attention, feature gating, and a specialized likelihood to produce accurate, multi-horizon forecasts and probabilities. The method outperforms benchmarks, particularly in sparse settings, and provides interpretable insights into conflict drivers such as persistence, spatial diffusion, and conditional climate effects.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DynAttn: Interpretable Spatio-Temporal Forecasting] --> B(核心问题/Problem: Forecasting sparse, bursty conflict fatalities)
        A --> C(主要方法/Method: Dynamic attention, elastic-net gating, ZINB likelihood)
        A --> D(关键结果/Results: Higher accuracy, interpretable regional dynamics)
    ```

- **[arXiv251229] Atomistic Simulation Guided Convolutional Neural Networks for Thermal Modeling of Friction Stir Welding**
  - **tags:** [ai], [physics-informed machine learning], [molecular dynamics, convolutional neural network, friction stir welding, explainable AI, LAMMPS]
  - **authors:** Akshansh Mishra
  - **institution:** Politecnico di Milano, AI Fab Lab
  - **link:** https://arxiv.org/pdf/2512.21344
  - **contributions:** 1. Developed a novel method to transform atomistic simulation data (atomic positions and velocities) into physics-based 2D spatial grids for deep learning input. 2. Created and optimized a 2D CNN model to directly predict temperature evolution from spatially resolved atomistic data, achieving high accuracy (R²=0.94). 3. Used Class Activation Map analysis to provide explainability, showing the model's focus aligns with physical mechanisms (e.g., tool-material interface).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34d6f71500319f52aecac1e95e1951a537fdc504134a8ba43851f31acc2e41c6_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a method that combines molecular dynamics simulations with convolutional neural networks for thermal modeling in friction stir welding. The method transforms atomic-scale simulation data into spatial grids and uses a CNN to accurately predict temperature, with results validated against physical mechanisms. The approach demonstrates that deep learning can effectively learn from atomistic data to model complex thermomechanical processes.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Atomistic Simulation Guided CNNs for Thermal Modeling of FSW / 原子模拟引导的CNN用于搅拌摩擦焊热建模"]
        Root --> Problem["准确预测温度演化对于理解搅拌摩擦焊的热机械行为至关重要 / Accurate prediction of temperature evolution is essential for understanding thermomechanical behavior in FSW"]
        Root --> Method["使用LAMMPS进行分子动力学模拟，将原子数据转换为物理二维空间网格，并开发2D CNN进行预测 / Use LAMMPS for MD simulations, transform atomic data into physics-based 2D spatial grids, and develop a 2D CNN for prediction"]
        Root --> Results["模型预测精度高（R²=0.94），CAM分析表明模型关注与剧烈变形和生热相关的区域 / Model achieves high predictive accuracy (R²=0.94), CAM analysis shows model focuses on regions associated with intense deformation and heat generation"]
    ```

- **[arXiv251229] An approach to Fisher-Rao metric for infinite dimensional non-parametric information geometry**
  - **tags:** [ai], [information geometry], [Fisher-Rao metric, non-parametric, G-entropy, Covariate Fisher Information Matrix (cFIM), intrinsic dimensionality]
  - **authors:** Bing Cheng, Howell Tong
  - **institution:** Not explicitly stated in provided content. Affiliation likely inferred from author names or arXiv metadata, but not present in the given text.
  - **link:** https://arxiv.org/pdf/2512.21451
  - **contributions:** 1. Introduces an orthogonal decomposition of the tangent space to derive a finite-dimensional, computable Covariate Fisher Information Matrix (cFIM) from the infinite-dimensional Fisher-Rao metric. 2. Establishes the geometric foundation of G-entropy via a Trace Theorem, linking it to total explainable statistical information. 3. Connects the cFIM to the Cramér-Rao Lower Bound and the Manifold Hypothesis, providing a method for estimating intrinsic dimensionality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a8f179358a2d0d118621b506d45d051ad949b1cc0acfe723d3c3268c4390e5a_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the intractability of the infinite-dimensional Fisher-Rao metric in non-parametric information geometry by proposing an orthogonal decomposition of the tangent space. This decomposition yields a finite-dimensional Covariate Fisher Information Matrix (cFIM), which serves as a computable geometric object for analyzing statistical information and model efficiency. The framework rigorously grounds G-entropy, links to fundamental statistical bounds, and provides a testable condition for the Manifold Hypothesis, bridging abstract geometry with explainable AI.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[An approach to Fisher-Rao metric for infinite dimensional non-parametric information geometry] --> B(核心问题/Problem: Intractability of infinite-dimensional Fisher-Rao metric)
        A --> C(主要方法/Method: Orthogonal decomposition of tangent space to derive Covariate Fisher Information Matrix (cFIM))
        A --> D(关键结果/Results: Trace Theorem for G-entropy, link to CRLB, testable Manifold Hypothesis via cFIM rank)
    ```

- **[arXiv251229] Deep learning-enhanced dual-mode multiplexed optical sensor for point-of-care diagnostics of cardiovascular diseases**
  - **tags:** [other], [biomedical sensing and diagnostics], [vertical flow assay, dual-mode detection, neural network-based quantification, multiplexed optical sensor, point-of-care diagnostics]
  - **authors:** Gyeo-Re Han, Merve Eryilmaz, Artem Goncharov, Yuzhu Li, Shun Ye, Aoi Tomoeda, Emily Ngo, Margherita Scussat, Xiao Wang, Zixiang Ji, Max Zhang, Jeffrey J. Hsu, Omai B. Garner, Dino Di Carlo, Aydogan Ozcan
  - **institution:** University of California, Los Angeles (UCLA)
  - **link:** https://arxiv.org/pdf/2512.21389
  - **contributions:** 1. Developed a dual-mode (colorimetric and chemiluminescent) multiplexed vertical flow assay (xVFA) for simultaneous detection of three cardiac biomarkers, achieving a wide dynamic range of ~6 orders of magnitude. 2. Integrated a deep learning-based quantification pipeline with a portable optical reader to automate analysis and enhance accuracy, achieving high correlation (Pearson's r > 0.96) with reference assays. 3. Created a compact, cost-effective, and rapid (23 min) point-of-care diagnostic system for cardiovascular diseases using only 50 µL of serum.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6eb23e46dc346744879ce56ec8c667b82f8cab434c54e4a4922a2eb842bf77d_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a deep learning-enhanced, dual-mode optical sensor for point-of-care cardiovascular diagnostics. The system uses a multiplexed vertical flow assay with colorimetric and chemiluminescent detection to simultaneously measure three key biomarkers with high sensitivity across a wide dynamic range, and a neural network pipeline for accurate quantification. The result is a rapid, portable, and automated diagnostic tool validated on patient samples.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deep learning-enhanced dual-mode multiplexed optical sensor<br>深度学习增强的双模式多重光学传感器] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Current POC tests: long turnaround, narrow range, single-analyte<br>当前POC测试：耗时长、范围窄、单分析物]
        C[主要方法/Method<br>Dual-mode (colorimetric+chemiluminescent) xVFA + Neural Network<br>双模式(比色+化学发光)xVFA + 神经网络]
        D[关键结果/Results<br>Simultaneous 3-analyte quant in 23 min, wide dynamic range, r>0.96<br>23分钟同步3分析物定量，宽动态范围，r>0.96]
    ```

- **[arXiv251229] Quantum Nondecimated Wavelet Transform: Theory, Circuits, and Applications**
  - **tags:** [other], [quantum signal processing], [quantum nondecimated wavelet transform, epsilon decimation, Hadamard test, quantum wavelet shrinkage, shift invariance]
  - **authors:** Brani Vidakovic
  - **institution:** Texas A&M University
  - **link:** https://arxiv.org/pdf/2512.21478
  - **contributions:** 1. Developed a quantum formulation of the Nondecimated Wavelet Transform (NDWT) based on epsilon-decimation, using a quantum register for shift indices and controlled circular shifts to realize all shifted transforms simultaneously. 2. Proposed an alternative quantum NDWT formulation using the Hadamard test and diagonal phase operators to directly access shift-invariant energy scalograms without full coefficient reconstruction. 3. Demonstrated that quantum redundancy and translation invariance can be exploited for applications like denoising and feature extraction, providing a foundation for multiscale quantum signal processing.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01489d687d6b4e38b42c82e3054e553beab66883e073aec7483d40c87388a47a_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces two quantum formulations of the classical Nondecimated Wavelet Transform (NDWT) to achieve shift invariance and redundancy in quantum computation. The first uses controlled shifts and a wavelet analysis unitary, while the second employs the Hadamard test with phase operators for direct energy measurement. The work shows these quantum NDWTs enable coherent multiscale signal processing tasks like denoising and feature extraction.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Quantum Nondecimated Wavelet Transform<br/>量子非抽取小波变换] --> B(核心问题/Problem: How to embed classical NDWT's redundancy and shift invariance into quantum computation?<br/>如何将经典NDWT的冗余性和平移不变性嵌入量子计算？)
        A --> C(主要方法/Method: Two complementary quantum formulations.<br/>两种互补的量子形式。)
        C --> C1(Formulation 1: Epsilon-decimated, uses controlled circular shifts & wavelet unitary.<br/>方法一：基于ε抽取，使用受控循环移位和小波酉变换。)
        C --> C2(Formulation 2: Hadamard test, uses diagonal phase operators for interference.<br/>方法二：基于Hadamard测试，使用对角相位算子进行干涉。)
        A --> D(关键结果/Results: Quantum NDWTs enable coherent postprocessing (e.g., shrinkage) and direct access to scalograms/spectra for applications like denoising.<br/>量子NDWT支持相干后处理并可直接获取尺度图/频谱，用于去噪等应用。)
    ```

- **[arXiv251229] Residual Prior Diffusion: A Probabilistic Framework Integrating Coarse Latent Priors with Diffusion Models**
  - **tags:** [ai], [diffusion models], [diffusion models, generative modeling, evidence lower bound, residual learning, two-stage framework]
  - **authors:** Takuro Kutsuna
  - **institution:** Toyota Central R&D Labs., Inc.
  - **link:** https://arxiv.org/pdf/2512.21593
  - **contributions:** 1. Proposes Residual Prior Diffusion (RPD), a two-stage probabilistic framework that integrates a coarse prior model with a diffusion model to capture large-scale structure and fine-scale details separately. 2. Formulates RPD with a tractable evidence lower bound, showing optimization reduces to familiar noise/velocity prediction objectives, and introduces auxiliary variables to leverage prior information and theoretically reduce prediction difficulty. 3. Demonstrates experimentally that RPD outperforms standard diffusion models on synthetic datasets with fine local structure and matches or exceeds baselines on natural image generation, maintaining performance with few inference steps.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08078ea833fb6d000def6c1e69b08b734ff7e29a1c3014bf3ec3e8b313815438_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a problem where standard diffusion models struggle to simultaneously model global structure and fine local details. It proposes Residual Prior Diffusion (RPD), a two-stage framework that first learns a coarse prior and then a diffusion model for the residual. Experiments show RPD captures fine details better than standard models and maintains strong performance with fewer inference steps.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Residual Prior Diffusion (RPD) / 残差先验扩散模型"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["单一扩散模型难以同时捕捉全局结构和局部细节 / Single diffusion model struggles with global structure and local details"]
        Method --> M1["两阶段框架: 粗粒度先验 + 残差扩散模型 / Two-stage framework: coarse prior + residual diffusion model"]
        Method --> M2["概率模型与可处理ELBO / Probabilistic model with tractable ELBO"]
        Results --> R1["在合成数据上准确捕捉细节 / Accurately captures details on synthetic data"]
        Results --> R2["自然图像生成匹配或超越基线 / Natural image generation matches or exceeds baselines"]
        Results --> R3["少步推理保持性能 / Maintains performance with few inference steps"]
    ```

- **[arXiv251229] Incorporating rank-free coupling and external field via an amplitude-only modulated spatial photonic Ising machine**
  - **tags:** [other], [photonic computing], [spatial photonic Ising machine, Hadamard product, amplitude-only modulation, rank-free coupling, incoherent light field]
  - **authors:** Ze Zheng, Yuegang Li, Hang Xu, Jingzheng Huang, Tailong Xiao, Guihua Zeng
  - **institution:** Shanghai Jiao Tong University, Hefei National Laboratory, Shanghai Research Center for Quantum Sciences
  - **link:** https://arxiv.org/pdf/2512.21587
  - **contributions:** 1. Proposes an amplitude-only modulated, rank-free spatial photonic Ising machine (AR-SPIM) that eliminates the need for repeated/auxiliary operations by reformulating the Ising Hamiltonian as a sum of Hadamard products. 2. Demonstrates direct mapping of a 797-spin Ising model with external fields into an incoherent light field using aligned amplitude modulators, achieving high encoding accuracy (correlation >0.98). 3. Shows the system's capability for ground-state search with &lt;0.3% error, complex phase transition observation, and scalable spin counts for sparse problems by removing zero-valued terms.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fe8a02df2acd50923ce3480e4b3fb28b68540ae3331e12dd83853a5b046a5c_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a new spatial photonic Ising machine (AR-SPIM) that uses an amplitude-only modulation scheme to encode arbitrary-rank spin-spin couplings and external fields directly into an incoherent light field. The method reformulates the Ising Hamiltonian as a sum of Hadamard products, enabling efficient and accurate computation. The demonstrated system achieves high-speed iterations, low error rates for optimization problems, and offers scalability for practical applications in optimization and quantum simulations.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Incorporating rank-free coupling and external field via an amplitude-only modulated spatial photonic Ising machine<br>振幅调制空间光子伊辛机"]
        Root --> Problem["核心问题/Problem<br>Existing SPIMs sacrifice efficiency or scale to encode high-rank coupling and external fields.<br>现有SPIM编码高秩耦合和外场时牺牲效率或规模。"]
        Root --> Method["主要方法/Method<br>Reformulate Hamiltonian as sum of Hadamard products; map to incoherent light via amplitude modulators.<br>将哈密顿量重写为哈达玛积之和；通过振幅调制器映射到非相干光场。"]
        Root --> Results["关键结果/Results<br>797 spins, >0.98 correlation, <0.3% error rate, enables phase transition observation.<br>797个自旋，>0.98相关性，<0.3%错误率，支持相变观测。"]
    ```

- **[arXiv251229] Tilt Matching for Scalable Sampling and Fine-Tuning**
  - **tags:** [mlsys], [diffusion models], [Tilt Matching, stochastic interpolants, flow matching, unnormalized densities, fine-tuning]
  - **authors:** Peter Potaptchik, Cheuk-Kit Lee, Michael S. Albergo
  - **institution:** Harvard University, University of Oxford, Kempner Institute, IAIFI
  - **link:** https://arxiv.org/pdf/2512.21829
  - **contributions:** 1. Proposes Tilt Matching, a simple, scalable algorithm for sampling and fine-tuning based on stochastic interpolants and an implicit stochastic optimal control solution., 2. Demonstrates that the method has strictly lower variance than standard flow matching and does not require gradients of the reward or backpropagation through trajectories., 3. Empirically shows state-of-the-art results on sampling under Lennard-Jones potentials and competitive performance on fine-tuning Stable Diffusion without reward multipliers.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cc2b096f1ad1f69d17a5fbdbac71d5ccac470d3cc86a47d74fed9dba5202c88_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces Tilt Matching, a new algorithm for sampling from complex distributions and fine-tuning generative models. It works by deriving a velocity field from stochastic interpolants to target a "tilted" distribution, offering lower variance than flow matching and avoiding gradient computations. The method is shown to be scalable and effective, achieving strong results on molecular sampling and image generation tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Tilt Matching for Scalable Sampling and Fine-Tuning] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Sampling from unnormalized densities and fine-tuning generative models] --> Problem_Detail[挑战/Challenges: Requires scalable, low-variance methods without reward gradients]
        Method[主要方法/Method: Tilt Matching] --> Method_Detail1[基础/Basis: Dynamical equation relating flow matching velocity to tilted distribution]
        Method_Detail1 --> Method_Detail2[特性/Properties: Implicitly solves stochastic optimal control, lower variance, no reward gradients needed]
        Results[关键结果/Results: Empirical Verification] --> Results_Detail1[应用/Applications: State-of-the-art on Lennard-Jones potentials, competitive on Stable Diffusion fine-tuning]
    ```

- **[arXiv251229] Modeling high dimensional point clouds with the spherical cluster model**
  - **tags:** [ai], [clustering], [spherical cluster model, high-dimensional median, non-smooth optimization, Clarke gradient, stratified cell complex]
  - **authors:** Frédéric Cazals, Antoine Commaret, Louis Goldenberg
  - **institution:** Université Côte d'Azur, Inria, Ecole Polytechnique
  - **link:** https://arxiv.org/pdf/2512.21960
  - **contributions:** 1. Showed that fitting a spherical cluster model is a strictly convex but non-smooth combinatorial optimization problem. 2. Presented an exact solver using the Clarke gradient on a stratified cell complex derived from an arrangement of hyperspheres. 3. Demonstrated through experiments that the exact solver is significantly faster than BFGS heuristics for many datasets and that the model's center behaves as a parameterized high-dimensional median.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c9618adf1a45723b5b136e8c21eaa91dc645be7664e2fae293ae569f2adde20_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces the Spherical Cluster (SC) model for approximating high-dimensional point clouds with a sphere. It proposes an exact solver for this non-smooth optimization problem, which is shown to be much faster than heuristic methods for many datasets, especially in high dimensions. The model's center is found to act as a robust, parameterized median.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Modeling high dimensional point clouds with the spherical cluster model] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[为高维点云建模/Modeling high-dimensional point clouds]
        C --> C1[球形聚类模型/Spherical Cluster Model]
        C --> C2[精确求解器使用Clarke梯度/Exact solver using Clarke gradient]
        D --> D1[精确算法比BFGS快得多/Exact algorithm much faster than BFGS]
        D --> D2[中心表现为参数化高维中位数/Center acts as parameterized high-dimensional median]
    ```

- **[arXiv251229] A Frobenius-Optimal Projection for Enforcing Linear Conservation in Learned Dynamical Models**
  - **tags:** [other], [dynamical systems, numerical linear algebra], [linear conservation laws, Frobenius norm, orthogonal projection, matrix correction, data-driven models]
  - **authors:** John M. Mango, Ronald Katende
  - **institution:** Makerere University, Kabale University
  - **link:** https://arxiv.org/pdf/2512.22084
  - **contributions:**  1. Provides a closed-form, Frobenius-norm optimal projection to enforce linear conservation laws on any learned linear dynamical operator. 2. Proves that the correction is uniquely defined, low-rank, and fully determined by the constraint violation, reducing to a rank-one update for a single invariant. 3. Demonstrates that the method enforces exact conservation while minimally perturbing the learned dynamics, verified with a numerical example.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff37179b43efd7a7b64ff062f4e49c8aeaa1dc0b65febe24067b7ddd46dba12c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of learned linear dynamical models violating known linear conservation laws. It proposes a closed-form orthogonal projection that minimally perturbs a learned operator in the Frobenius norm to exactly satisfy the constraints. The method provides a general, optimal post-processing step for embedding invariants into data-driven linear models.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Frobenius-Optimal Projection for Enforcing Linear Conservation in Learned Dynamical Models"] --> Problem["核心问题/Problem: Learned linear models violate known linear conservation laws."]
        Root --> Method["主要方法/Method: Apply orthogonal projection A* = Â - C(CᵀC)⁻¹CᵀÂ to enforce CᵀA=0."]
        Root --> Results["关键结果/Results: Enforces exact conservation with minimal perturbation; correction is unique and low-rank."]
    ```

## 2025-12-30

- **[arXiv251230] Pruning Graphs by Adversarial Robustness Evaluation to Strengthen GNN Defenses**
  - **tags:** [ai], [graph neural networks], [adversarial robustness, graph pruning, message passing, spurious connections, graph defense]
  - **authors:** Yongyu Wang
  - **institution:** Michigan Technological University
  - **link:** https://arxiv.org/pdf/2512.22128
  - **contributions:** 1. Introduces a novel graph pruning framework that uses adversarial robustness evaluation to identify fragile graph components. 2. Proposes a method that selectively prunes edges based on robustness scores to improve model reliability and resilience. 3. Validates the framework by instantiating it on three representative GNN architectures and demonstrating significant defense enhancement in high-perturbation regimes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d658f9bc62a6d2a57e4602f69b9d0c69056551601abd2ba0336e97d592bae1dc_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the vulnerability of Graph Neural Networks (GNNs) to adversarial attacks and noise in graph structure. It proposes a pruning framework that uses adversarial robustness scores to identify and remove detrimental edges, resulting in cleaner and more resilient graph representations. Experiments show this method significantly strengthens GNN defenses against high levels of perturbation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Pruning Graphs by Adversarial Robustness Evaluation to Strengthen GNN Defenses] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1(GNNs对图结构和特征的扰动敏感/GNNs vulnerable to graph & feature perturbations)
        C --> C1(基于对抗鲁棒性评分的剪枝框架/Pruning framework guided by adversarial robustness scores)
        D --> D1(显著增强高扰动下的防御能力/Significantly enhances GNN defense in high-perturbation regime)
    ```

- **[arXiv251230] ReCollab: Retrieval-Augmented LLMs for Cooperative Ad-hoc Teammate Modeling**
  - **tags:** [ai], [multi-agent reinforcement learning], [ad-hoc teamwork, retrieval-augmented generation, teammate modeling, Overcooked]
  - **authors:** Conor Wallace, Umer Siddique, Yongcan Cao
  - **institution:** University of Texas at San Antonio
  - **link:** https://arxiv.org/pdf/2512.22129
  - **contributions:** 1. Introduces COLLAB, a novel language-based framework that uses LLMs as behavioral world models to classify unseen teammate types in ad-hoc teamwork. 2. Extends COLLAB to RECOLLAB by incorporating retrieval-augmented generation (RAG) with exemplar trajectories to stabilize inference and improve adaptation. 3. Demonstrates empirically in the Overcooked environment that RECOLLAB achieves Pareto-optimal trade-offs between classification accuracy and episodic return, highlighting the value of retrieval grounding.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/078fe396118022eaa0d391e86072d08c5b6617a143aba1478029ca3185af6472_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of ad-hoc teamwork, where an agent must collaborate with unseen teammates. It proposes RECOLLAB, a framework that uses retrieval-augmented LLMs to model and classify teammate behavior from short interaction traces. The method is shown to effectively improve adaptation and coordination in the cooperative Overcooked environment.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("RECOLLAB: Retrieval-Augmented LLMs for Cooperative Ad-hoc Teammate Modeling") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("Ad-hoc Teammate Modeling<br>Ad-hoc队友建模")
        Problem --> P2("Brittle Conventional Models<br>传统模型脆弱性")
        Method --> M1("COLLAB: LLM-based Framework<br>基于LLM的框架")
        Method --> M2("RECOLLAB: Adds RAG<br>增加RAG检索")
        Results --> R1("Improved Adaptation<br>提升适应性")
        Results --> R2("Pareto-Optimal Trade-offs<br>帕累托最优权衡")
    ```

- **[arXiv251230] On Harnessing Idle Compute at the Edge for Foundation Model Training**
  - **tags:** [mlsys], [llm training], [edge computing, tensor parallelism, parameter server, device heterogeneity, fault-tolerance]
  - **authors:** Leyang Xue, Meghana Madhyastha, Myungjin Lee, Amos Storkey, Randal Burns, Mahesh K. Marina
  - **institution:** The University of Edinburgh, Johns Hopkins University, Cisco Research
  - **link:** https://arxiv.org/pdf/2512.22142
  - **contributions:** 1. A novel selective hybrid tensor parallelism method to finely partition training operations for edge devices. 2. A parameter server-centric training framework to cope with device memory limits and avoid communication bottlenecks. 3. A cost optimization model to guide device selection and workload distribution, effectively handling device heterogeneity and churn.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fefe0f72fa70ae7be2cad54f15e74f96fd08cc506630060214e298521278148_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of decentralized foundation model training on edge devices, which is hindered by memory limits, communication overhead, and device heterogeneity. It proposes Cleave, a new paradigm that uses selective hybrid tensor parallelism and a parameter server framework to partition training efficiently. The evaluation shows Cleave matches cloud-based training performance, scales to thousands of devices, and handles failures with much faster recovery than prior methods.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[On Harnessing Idle Compute at the Edge for Foundation Model Training] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[现有边缘训练方法性能不足/Existing edge training falls short]
    B --> B2[设备内存与通信瓶颈/Device memory & communication bottlenecks]
    B --> B3[设备异构性与动态性/Device heterogeneity & dynamism]
    C --> C1[选择性混合张量并行/Selective hybrid tensor parallelism]
    C --> C2[参数服务器框架/Parameter server framework]
    C --> C3[成本优化模型/Cost optimization model]
    D --> D1[匹配云端训练性能/Matches cloud-based training]
    D --> D2[扩展至数千设备/Scales to thousands of devices]
    D --> D3[快速故障恢复/Fast failure recovery]
    ```

- **[arXiv251230] GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs**
  - **tags:** [hpc], [gpu kernels], [Minimal Executable Program (MEP), Automatic Error Repair, Performance Pattern Inheritance, iterative optimization, cross-platform]
  - **authors:** Ruifan Chu, Anbang Wang, Xiuxiu Bai, Shuai Liu, Xiaoshe Dong
  - **institution:** School of Software Engineering, Xi’an Jiaotong University
  - **link:** https://arxiv.org/pdf/2512.22147
  - **contributions:** 1. Proposes an end-to-end LLM framework that optimizes GPU kernels by constructing Minimal Executable Programs (MEPs) to avoid expensive full application builds and executions. 2. Introduces Automatic Error Repair and Performance Pattern Inheritance to automatically fix faults and reuse effective optimization strategies, reducing search cost. 3. Demonstrates cross-platform portability and effectiveness on NVIDIA GPUs and the Haiguang DCU platform, achieving significant speedups over direct LLM optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fd593bd3569f30bdbf11d361054f51142863fb91e592b76bc4eb2f600850c5e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high cost of full builds for GPU kernel optimization in large HPC applications by proposing an LLM framework that uses Minimal Executable Programs (MEPs) for iterative optimization. The method integrates automatic error repair and performance pattern inheritance to maintain correctness and reuse strategies. It achieves substantial speedups across different hardware platforms without requiring full-source dependencies.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Full builds & runs are expensive in large applications/大型应用中完整构建与运行成本高]
        C --> C1[Construct Minimal Executable Program (MEP) for kernel/为内核构建最小可执行程序]
        C --> C2[Multi-round iterative optimization with LLM feedback/基于LLM反馈的多轮迭代优化]
        C --> C3[Integrate Automatic Error Repair & Performance Pattern Inheritance/集成自动错误修复与性能模式继承]
        D --> D1[Achieves significant speedups (e.g., 5.05x, 7.77x)/获得显著加速比]
        D --> D2[Cross-platform portability (NVIDIA, DCU)/跨平台可移植性]
        D --> D3[Surpasses direct LLM optimization/超越直接LLM优化]
    ```

- **[arXiv251230] Towards Unsupervised Causal Representation Learning via Latent Additive Noise Model Causal Autoencoders**
  - **tags:** [ai], [causal representation learning], [additive noise model, Wasserstein auto-encoder, identifiability, unsupervised learning, causal discovery]
  - **authors:** Hans Jarett J. Ong, Brian Godwin S. Lim, Dominic Dayta, Renzo Roel P. Tan, Kazushi Ikeda
  - **institution:** Nara Institute of Science and Technology, Kyoto University, Ateneo de Manila University
  - **link:** https://arxiv.org/pdf/2512.22150
  - **contributions:** 1. Proposed LANCA, a novel autoencoder framework that operationalizes the Additive Noise Model (ANM) as an inductive bias for unsupervised causal representation learning., 2. Provided a theoretical analysis showing that the ANM constraint restricts admissible transformations to the affine class, resolving component-wise indeterminacy., 3. Introduced a deterministic WAE architecture with a differentiable ANM layer to explicitly optimize for residual independence, overcoming limitations of stochastic VAEs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/383ef9534443c860dced6678ba459335afb022e411bf183cc7f2e3dbad2bb385_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of unsupervised causal representation learning by proposing LANCA, a method that uses the Additive Noise Model as an inductive bias within a deterministic autoencoder framework. Theoretically, it shows this constraint narrows down the solution space, and empirically, LANCA outperforms existing methods on synthetic and photorealistic benchmarks by being more robust to spurious correlations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Towards Unsupervised Causal Representation Learning via LANCA] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[无监督因果表示学习的可识别性挑战/Identifiability Challenge in Unsupervised Causal Representation Learning]
        C --> C1[提出LANCA：使用ANM作为归纳偏置/Propose LANCA: Using ANM as Inductive Bias]
        C --> C2[确定性WAE与可微ANM层/Deterministic WAE with Differentiable ANM Layer]
        D --> D1[理论：限制变换为仿射类/Theory: Restricts Transformations to Affine Class]
        D --> D2[实证：在基准测试中优于SOTA/Empirical: Outperforms SOTA on Benchmarks]
    ```

- **[arXiv251230] SoliReward: Mitigating Susceptibility to Reward Hacking and Annotation Noise in Video Generation Reward Models**
  - **tags:** [ai], [reinforcement learning from human feedback (rlhf)], [reward model, video generation, reward hacking, bradley-terry loss, hierarchical attention]
  - **authors:** Jiesong Lian, Ruizhe Zhong, Zixiang Zhou, Xiaoyue Mi, Yixue Hao, Yuan Zhou, Qinglin Lu, Long Hu, Junchi Yan
  - **institution:** Huazhong University of Science and Technology, Shanghai Jiao Tong University, Tencent Hunyuan, University of Chinese Academy of Sciences
  - **link:** https://arxiv.org/pdf/2512.22170
  - **contributions:** 1. A data collection and pairing strategy using single-item binary annotations and cross-prompt pairing to reduce labeling noise. 2. A Hierarchical Progressive Query Attention mechanism for better feature aggregation in the reward model architecture. 3. A modified Bradley-Terry loss function that accommodates win-tie scenarios to regularize the score distribution and mitigate reward hacking.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04ea37599d144feb85d3d1e8303d5d59adfabb579e172f06aef976d3783ee4ef_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes SoliReward, a systematic framework to improve reward models for video generation alignment. It addresses data noise and reward hacking through a new data annotation strategy, a hierarchical attention architecture, and a modified loss function. The approach shows improved performance on benchmarks for video quality and enhances the effectiveness of post-training video models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SoliReward: Mitigating Susceptibility to Reward Hacking and Annotation Noise in Video Generation Reward Models] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[数据标注噪声/Annotation Noise]
        B --> B2[奖励黑客攻击/Reward Hacking]
        B --> B3[模型架构设计不足/Under-explored RM Architecture]
        C --> C1[单项目二元标注与跨提示配对/Single-item Binary Annotations & Cross-prompt Pairing]
        C --> C2[分层渐进查询注意力/Hierarchical Progressive Query Attention]
        C --> C3[改进的BT损失函数/Modified BT Loss for Win-Tie]
        D --> D1[奖励模型评估指标提升/Improved Direct RM Evaluation Metrics]
        D --> D2[视频生成后训练效果增强/Enhanced Efficacy of Post-training on Video Generation Models]
    ```

- **[arXiv251230] Wireless Traffic Prediction with Large Language Model**
  - **tags:** [ai], [spatio-temporal forecasting], [large language model, wireless traffic prediction, spatial-temporal correlation, prompt engineering, fine-tuning]
  - **authors:** Chuanting Zhang, Haixia Zhang, Jingping Qiao, Zongzhang Li, Mohamed-Slim Alouini
  - **institution:** Shandong University, Shandong Normal University, China Mobile Communications Group Shandong Co., Ltd, King Abdullah University of Science and Technology (KAUST)
  - **link:** https://arxiv.org/pdf/2512.22178
  - **contributions:** 1. Proposes TIDES, an LLM-based framework that captures spatial-temporal correlations for urban wireless traffic prediction. 2. Introduces a prompt engineering scheme to bridge the domain gap between numerical traffic data and language models by embedding statistical features as structured inputs. 3. Designs a DeepSeek module enabling spatial alignment via cross-domain attention, allowing the LLM to leverage information from related regions, and employs efficient fine-tuning of lightweight components.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/402a3d6681d9c203daf7e8ef09e0d0af8998f3eba780abc404c945025563d6a8_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes TIDES, a novel framework that uses a large language model (LLM) enhanced with spatial awareness for urban wireless traffic prediction. It addresses the lack of spatial modeling in existing LLM-based predictors through region clustering, prompt engineering, and a spatial alignment module, achieving superior accuracy and robustness on real-world datasets, which is key for intelligent 6G network management.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Wireless Traffic Prediction with Large Language Model] --> B(核心问题/Problem: LLMs overlook spatial dependencies in city-scale wireless traffic)
        A --> C(主要方法/Method: TIDES framework with clustering, prompt engineering, and DeepSeek spatial alignment module)
        A --> D(关键结果/Results: Outperforms SOTA baselines in accuracy and robustness for 6G network management)
    ```

- **[arXiv251230] Latent Sculpting for Zero-Shot Generalization: A Manifold Learning Approach to Out-of-Distribution Anomaly Detection**
  - **tags:** [sec], [anomaly detection], [manifold learning, normalizing flows, dual-centroid compactness loss, out-of-distribution detection, zero-shot generalization]
  - **authors:** Rajeeb Thapa Chhetri, Zhixiong Chen, Saurab Thapa
  - **institution:** Mercy University
  - **link:** https://arxiv.org/pdf/2512.22179
  - **contributions:** 1. Proposes Latent Sculpting, a novel two-stage framework that decouples manifold structure learning from density estimation for OOD anomaly detection. 2. Introduces the Dual-Centroid Compactness Loss (DCCL) to actively sculpt a compact, low-entropy latent manifold for benign data. 3. Demonstrates superior zero-shot generalization on the CIC-IDS-2017 benchmark, significantly outperforming supervised and unsupervised baselines on complex distribution shifts like "Infiltration".
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfcac5687161ad2a09f74eab3c1b7f91a350a2435fb71a0c791f2e305dff108c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of "Generalization Collapse" in supervised models when detecting Out-of-Distribution (OOD) anomalies. It proposes Latent Sculpting, a two-stage method that first uses a novel loss to sculpt a compact latent manifold for benign data and then applies a normalizing flow for density estimation. The results show this approach enables robust zero-shot anomaly detection, significantly outperforming existing methods on unseen attack scenarios.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Latent Sculpting for Zero-Shot Generalization] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[泛化崩溃 / Generalization Collapse]
        B --> B2[OOD异常检测失败 / OOD Anomaly Detection Failure]
        C --> C1[潜在空间雕刻 / Latent Sculpting]
        C1 --> C2[阶段1: DCCL损失 / Stage 1: DCCL Loss]
        C1 --> C3[阶段2: MAF密度估计 / Stage 2: MAF Density Estimation]
        D --> D1[零样本F1分数0.87 / Zero-Shot F1-Score 0.87]
        D --> D2[渗透攻击检测率88.89% / Infiltration Detection 88.89%]
    ```

- **[arXiv251230] Enhancing Medical Data Analysis through AI-Enhanced Locally Linear Embedding: Applications in Medical Point Location and Imagery**
  - **tags:** [ai], [dimensionality reduction], [Locally Linear Embedding (LLE), AI-enhanced LLE, medical data analysis, medical billing, transcription]
  - **authors:** Hassan Khalid, Muhammad Mahad Khaliq, Muhammad Jawad Bashir
  - **institution:** National University of Science and Technology (NUST)
  - **link:** https://arxiv.org/pdf/2512.22182
  - **contributions:** 1. Proposes an innovative integration of AI with Locally Linear Embedding (LLE) to handle high-dimensional medical data. 2. Develops a comprehensive mathematical model for the AI-enhanced LLE technique. 3. Demonstrates the model's application in real-world healthcare scenarios, showing significant improvements in data processing accuracy and operational efficiency for medical billing and transcription.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d42fb5873195bf570514a88549054269194cfaa817a772eb3decd5c337e47e24_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces an AI-enhanced Locally Linear Embedding (LLE) model to improve the analysis of high-dimensional medical data. The method is applied to automate and enhance medical billing and transcription services. The results show significant improvements in processing accuracy and operational efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Enhancing Medical Data Analysis through AI-Enhanced LLE] --> B(核心问题/Problem: Handling complex high-dimensional medical data for billing and transcription)
    A --> C(主要方法/Method: Integrating AI with Locally Linear Embedding (LLE))
    A --> D(关键结果/Results: Improved data processing accuracy and operational efficiency)
    ```

- **[arXiv251230] Learning Tennis Strategy Through Curriculum-Based Dueling Double Deep Q-Networks**
  - **tags:** [ai], [reinforcement learning], [Dueling Double Deep Q-Network, curriculum learning, tennis simulation, sequential decision-making, sports analytics]
  - **authors:** Vishnu Mohan
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2512.22186
  - **contributions:** 1. Developed a custom tennis simulation environment that models hierarchical scoring, tactical decisions, fatigue, and opponent skill. 2. Integrated a Dueling Double Deep Q-Network (DDQN) with curriculum learning to enable stable and effective strategy learning in a long-horizon, stochastic domain. 3. Identified a key limitation of win-rate optimization, revealing a learned defensive bias and highlighting challenges in reward design for sports RL.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/543e2f9f07244abac63adfdbdefd7fccfefed9147b55aed87016c10657f91bae_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a reinforcement learning framework using a Dueling Double Deep Q-Network trained with curriculum learning to optimize tennis strategy in a custom simulation. The method achieves high win rates and demonstrates stable convergence, but analysis reveals the learned policy is overly defensive, pointing to a fundamental issue with reward design in sports simulations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Learning Tennis Strategy Through Curriculum-Based Dueling Double Deep Q-Networks] --> B(核心问题/Problem: Tennis strategy optimization as a sequential decision-making challenge with hierarchical scoring, stochasticity, and opponent adaptation)
        A --> C(主要方法/Method: Dueling Double Deep Q-Network (DDQN) trained with curriculum learning in a custom tennis simulation environment)
        A --> D(关键结果/Results: High win rates (98-100%) and stable convergence, but reveals a defensive policy bias, highlighting reward design limitations)
    ```

- **[arXiv251230] Physics-Informed Machine Learning for Transformer Condition Monitoring -- Part I: Basic Concepts, Neural Networks, and Variants**
  - **tags:** [ai], [prognostics & health management (phm)], [Neural Networks, Convolutional Neural Networks, Reinforcement Learning, Uncertainty Quantification, Physics-Informed Machine Learning]
  - **authors:** Jose I. Aizpurua
  - **institution:** University of the Basque Country (UPV/EHU)
  - **link:** https://arxiv.org/pdf/2512.22190
  - **contributions:** 1. Introduces the application of Neural Networks (NNs) and their variants, specifically Convolutional Neural Networks (CNNs), for transformer condition monitoring using diverse data modalities. 2. Discusses the integration of NN concepts within the Reinforcement Learning (RL) paradigm for decision-making and control in transformer health management. 3. Provides perspectives on emerging research directions at the intersection of physics-informed machine learning and transformer Prognostics & Health Management (PHM).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73f2611de029a059f651f47ffd6b707f684cdbc0c0f865e4c8568c2765f5fede_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of traditional, rule-based transformer condition monitoring by proposing the use of machine learning, particularly Neural Networks and their variants. It explores Convolutional Neural Networks for processing diverse sensor data and discusses Reinforcement Learning for control, concluding that physics-informed ML provides a powerful framework for more accurate diagnostics, prognostics, and decision-making in power transformer health management.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Physics-Informed ML for Transformer Condition Monitoring – Part I"] --> Problem["核心问题/Problem: Traditional monitoring struggles with uncertainty & complexity"]
        Root --> Method["主要方法/Method: Use Neural Networks, CNNs, and Reinforcement Learning"]
        Root --> Results["关键结果/Results: Enables accurate diagnostics, prognostics, and control"]
    ```

- **[arXiv251230] Physics-Informed Machine Learning for Transformer Condition Monitoring -- Part II: Physics-Informed Neural Networks and Uncertainty Quantification**
  - **tags:** [ai], [physics-informed machine learning], [Physics-Informed Neural Networks (PINNs), Bayesian PINNs, uncertainty quantification, Prognostics & Health Management (PHM), transformer condition monitoring]
  - **authors:** Jose I. Aizpurua
  - **institution:** University of the Basque Country (UPV/EHU)
  - **link:** https://arxiv.org/pdf/2512.22189
  - **contributions:** 1. Introduces Physics-Informed Neural Networks (PINNs) for integrating physics into neural network training for transformer applications like thermal modeling and insulation ageing. 2. Presents Bayesian PINNs as a framework to quantify epistemic uncertainty, enabling robust predictions under sparse data conditions. 3. Outlines emerging research directions for physics-aware and trustworthy machine learning in the management of critical power assets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d981ba5912467b9788cda82e843171a8af166b1ec965beb37ff22f102f1e02c8_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes using Physics-Informed Neural Networks (PINNs) and their Bayesian extension to improve transformer condition monitoring. The method integrates physical laws directly into the learning process and quantifies model uncertainty, aiming to deliver more reliable predictions with limited data. The work highlights the potential of physics-aware machine learning for robust prognostics and health management of critical power infrastructure.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Physics-Informed Machine Learning for Transformer Condition Monitoring – Part II] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统神经网络缺乏物理机制，数据稀疏下不可靠/Traditional NNs lack physics, unreliable with sparse data]
        C --> C1[物理信息神经网络/PINNs]
        C --> C2[贝叶斯PINNs量化认知不确定性/Bayesian PINNs for epistemic UQ]
        D --> D1[提高稀疏数据下的鲁棒性/Improved robustness under sparse data]
        D --> D2[为关键资产提供可信的机器学习/Trustworthy ML for critical assets]
    ```

- **[arXiv251230] Frequency Regularization: Unveiling the Spectral Inductive Bias of Deep Neural Networks**
  - **tags:** [ai], [regularization theory], [Spectral Bias, L2 Regularization, Frequency Principle, Spectral Suppression Ratio, Inductive Bias]
  - **authors:** Jiahao Lu
  - **institution:** The Chinese University of Hong Kong, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.22192
  - **code:** https://github.com/lujiahao760/FrequencyRegularization
  - **contributions:** 1. Introduced a Visual Diagnostic Framework to track the dynamic evolution of weight frequencies during CNN training. 2. Proposed a novel metric, the Spectral Suppression Ratio (SSR), to quantify the "low-pass filtering" intensity of different regularizers. 3. Empirically revealed a critical Accuracy-Robustness Trade-off in L2-regularized models, showing their sensitivity to broadband noise but superior robustness to high-frequency information loss.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7443604e19a6c972d6ac6ad332d345bd15a272d6f58a489ef07c494950a3d274_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the spectral inductive bias of deep neural networks, focusing on how regularization techniques like L2 affect feature frequency selection. The authors propose a visual diagnostic framework and a new metric to quantify spectral suppression, demonstrating that L2 regularization strongly suppresses high-frequency energy and leads to a trade-off between accuracy and robustness. The work confirms that regularization enforces a strong spectral bias towards low-frequency structures, providing a signal-processing perspective on generalization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Frequency Regularization: Unveiling the Spectral Inductive Bias of Deep Neural Networks] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[理解正则化的物理机制<br/>Understanding the physical mechanism of regularization]
        B --> B2[探索特征频率选择<br/>Exploring feature frequency selection]
        C --> C1[视觉诊断框架<br/>Visual Diagnostic Framework]
        C --> C2[谱抑制比 (SSR)<br/>Spectral Suppression Ratio (SSR)]
        D --> D1[L2正则化抑制高频能量<br/>L2 regularization suppresses high-frequency energy]
        D --> D2[揭示准确率-鲁棒性权衡<br/>Reveals Accuracy-Robustness Trade-off]
    ```

- **[arXiv251230] MatKV: Trading Compute for Flash Storage in LLM Inference**
  - **tags:** [mlsys], [llm inference], [retrieval-augmented generation, key-value cache, flash storage, prefill optimization, power efficiency]
  - **authors:** Kun-Woo Shin, Jay H. Park, Moonwook Oh, Yohan Jo, Jaeyoung Do, Sang-Won Lee
  - **institution:** Seoul National University, Samsung Electronics
  - **link:** https://arxiv.org/pdf/2512.22195
  - **code:** https://github.com/kunwooshin/MatKV
  - **contributions:** 1. Proposes MatKV, a scheme to precompute and materialize KV vectors of RAG documents in flash storage to avoid recomputation during inference. 2. Demonstrates that MatKV reduces inference time and power consumption by half for RAG workloads with minimal accuracy impact. 3. Shows MatKV enables additional optimizations like overlapping KV loading with decoding and enabling the use of low-end GPUs for decoding.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d47111ab2d615579a09c00ff5a99f391f035b974cc23e324cddfbabf4d23cec_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high compute and energy cost of the prefill phase in RAG-based LLM inference. It proposes MatKV, which precomputes and stores key-value vectors of documents in flash storage for reuse, trading compute for storage. Experiments show this approach halves inference time and power consumption while maintaining accuracy and enabling further hardware optimizations.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["MatKV: Trading Compute for Flash Storage in LLM Inference"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>RAG推理中prefill阶段计算开销大<br>High compute cost of prefill in RAG inference"]
        Method["主要方法/Method<br>预计算并物化KV向量到闪存<br>Precompute & materialize KVs to flash storage"]
        Results["关键结果/Results<br>推理时间与能耗减半<br>Halves inference time & power consumption"]
    ```

- **[arXiv251230] AETAS: Analysis of Evolving Temporal Affect and Semantics for Legal History**
  - **tags:** [nlp], [semantic change detection], [diachronic embeddings, orthogonal Procrustes, lexical drift]
  - **authors:** Qizhi Wang
  - **institution:** PingCAP, Data & AI-Innovation Lab
  - **link:** https://arxiv.org/pdf/2512.22196
  - **contributions:** 1. A reproducible, expert-system style pipeline for quantifying and visualizing lexical drift in historical corpora. 2. A method coupling interpretable semantic trajectories with legally meaningful axes (e.g., mercy-versus-retribution). 3. The application of the pipeline to the Old Bailey Corpus, exposing the evolution of legal concepts like justice and crime alongside historical events.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df36f3ea25509e1c01d661a7893c2b940f15cfeb346560d105c4488a5fba4140_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a reproducible pipeline for analyzing semantic drift in historical legal texts. The method involves training and aligning diachronic word embeddings to quantify and visualize lexical change. The analysis of the Old Bailey Corpus reveals how concepts of justice and crime evolved with penal reforms and societal debates.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AETAS: Analysis of Evolving Temporal Affect and Semantics for Legal History] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1("数字人文中语义变迁分析<br>Digital Humanities Semantic Shift Analysis")
        C --> C1("可复现的专家系统流程<br>Reproducible Expert-System Pipeline")
        C1 --> C2("分时段词嵌入与对齐<br>Temporal Embeddings & Alignment")
        C2 --> C3("几何位移与邻域变化度量<br>Geometric & Neighborhood Metrics")
        D --> D1("可视化法律概念演变<br>Visualizing Legal Concept Evolution")
        D1 --> D2("揭示与历史事件的关联<br>Revealing Links to Historical Events")
    ```

- **[arXiv251230] CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [dynamic routing, residual networks, cosine incompatibility, Gumbel-Softmax, FLOPs regularization]
  - **authors:** Yogeswar Reddy Thota
  - **institution:** University of Texas at Dallas
  - **link:** https://arxiv.org/pdf/2512.22206
  - **contributions:** 1. Introduces CosineGate, an end-to-end differentiable architecture for dynamic routing in residual networks using cosine incompatibility as a self-supervised skip signal. 2. Proposes the Cosine Incompatibility Ratio (CIR) to measure semantic redundancy and employs Gumbel-Softmax relaxation for per-sample, per-block gating during training. 3. Incorporates a progressive FLOPs regularization term to control average computational usage without destabilizing the optimization process.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed7e3fa1c114a73795152210d2b55ffe2541fede331ce04d228e11ca599688fa_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the computational inefficiency in residual networks, where all blocks are evaluated for every input. It proposes CosineGate, a method that uses the cosine incompatibility between identity and residual features to dynamically skip redundant blocks, achieving significant FLOPs savings on CIFAR-10 while maintaining or improving accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks] --> B[核心问题/Problem: Modern residual networks perform redundant computation for all inputs]
        A --> C[主要方法/Method: Uses cosine incompatibility ratio and Gumbel-Softmax for dynamic per-block gating]
        A --> D[关键结果/Results: Achieves accuracy-efficiency Pareto frontier on CIFAR-10 with significant FLOPs savings]
    ```

- **[arXiv251230] Emotion-Inspired Learning Signals (EILS): A Homeostatic Framework for Adaptive Autonomous Agents**
  - **tags:** [ai], [reinforcement learning], [intrinsic motivation, homeostatic control, adaptive optimization, non-stationary learning]
  - **authors:** Dhruv Tiwari
  - **institution:** Lovely Professional University
  - **link:** https://arxiv.org/pdf/2512.22200
  - **contributions:** 1. Proposes a novel framework, Emotion-Inspired Learning Signals (EILS), that models emotions as continuous, homeostatic appraisal signals (e.g., Curiosity, Stress, Confidence) for adaptive control. 2. Formalizes these signals as vector-valued internal states derived from interaction history to dynamically modulate the agent's optimization landscape in real-time. 3. Hypothesizes that this closed-loop homeostatic regulation enables superior sample efficiency and adaptation to non-stationary environments compared to standard baselines like PPO.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a45d2a56af1becf3eaddb05dbaeff3cf5453d19d41771b6d8ce1c1a70d3825c2_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies the fragility of standard AI agents that rely on static, external rewards in open-ended environments. It proposes the Emotion-Inspired Learning Signals (EILS) framework, which uses bio-inspired internal signals like curiosity and stress to dynamically control learning. The authors hypothesize this approach will lead to more robust, adaptive, and sample-efficient autonomous agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[EILS: A Homeostatic Framework] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[静态外部奖励/Static Extrinsic Reward]
        Problem --> P2[脆弱性，无法适应/Fragile, Non-Adaptive]
        Method[主要方法/Method] --> M1[情绪启发信号/Emotion-Inspired Signals]
        Method --> M2[动态稳态调节/Dynamic Homeostatic Control]
        Results[关键结果/Results] --> R1[假设: 更高样本效率/Hypothesis: Higher Sample Efficiency]
        Results --> R2[假设: 更好非平稳适应/Hypothesis: Better Non-Stationary Adaptation]
    ```

- **[arXiv251230] Open-Source Multimodal Moxin Models with Moxin-VLM and Moxin-VLA**
  - **tags:** [nlp], [multimodal large language models], [Moxin, open-source LLM, vision-language-action, Model Openness Framework, multimodal models]
  - **authors:** Pu Zhao, Xuan Shen, Zhenglun Kong, Yixin Shen, Sung-En Chang, Arash Akbari, Timothy Rupprecht, Lei Lu, Enfu Nan, Changdi Yang, Yumei He, Weiyan Shi, Xingchen Xu, Yu Huang, Wei Jiang, Wei Wang, Yue Chen, Yong He, Yanzhi Wang
  - **institution:** Northeastern University, Harvard University, Cornell University, Tulane University, University of Washington, Roboraction.ai, Futurewei, AIBAO LLC
  - **link:** https://arxiv.org/pdf/2512.22208
  - **code:** https://github.com/moxin-org/Moxin-LLM
  - **contributions:** 1. Introduces Moxin 7B, a fully open-source LLM developed under the Model Openness Framework, promoting transparency in training, datasets, and implementation. 2. Develops three specialized variants of Moxin: Moxin-VLM for vision-language tasks, Moxin-VLA for vision-language-action tasks, and Moxin-Chinese for Chinese language capabilities. 3. Demonstrates superior performance of the proposed models in various evaluations using open-source frameworks and data, with all models, code, and data publicly released.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79873d0c3143fc2b06f1be1be9b8bc80555fa0aefd4a6f2b8d6bda39bce5f227_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Moxin 7B, a fully transparent open-source large language model, and extends it into three multimodal variants for vision-language, vision-language-action, and Chinese tasks. The models are trained using open-source frameworks and data. The authors release the models, code, and data, reporting superior performance in evaluations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Open-Source Multimodal Moxin Models<br/>开源多模态Moxin模型] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Proprietary vs. Open-Source LLMs<br/>闭源与开源大语言模型]
        B --> B2[Need for transparent, capable open models<br/>需要透明、强大的开源模型]
        C --> C1[Develop Moxin 7B under Model Openness Framework<br/>基于模型开放框架开发Moxin 7B]
        C --> C2[Create variants: VLM, VLA, Chinese<br/>创建变体: VLM, VLA, 中文模型]
        D --> D1[Superior performance in evaluations<br/>在评估中表现优异]
        D --> D2[Full release of models, code, data<br/>完整发布模型、代码、数据]
    ```

- **[arXiv251230] Transformer Reconstructed with Dynamic Value Attention**
  - **tags:** [nlp], [transformer architecture], [dynamic value attention, single-head attention, feed forward network removal]
  - **authors:** Xiaowei Wang
  - **institution:** College of Artificial Intelligence, China University of Petroleum (Beijing)
  - **link:** https://arxiv.org/pdf/2512.22212
  - **contributions:** 1. Proposed Dynamic Value Attention (DVA), a method to dynamically decide a value for each query, addressing the limitation of static values in standard attention heads. 2. Enabled the removal of redundant multi-head attention, reducing the architecture to a single-head attention mechanism. 3. Demonstrated that the subsequent feed-forward network can be entirely removed, as the revised embeddings already capture sufficient contextual information.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79cd017ace993f77d704944ed5eeaa739c2f83168d5d9f241b0355966c04ea5f_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a limitation in the standard Transformer where static values are used for all queries within an attention head. It proposes Dynamic Value Attention (DVA), which computes a dynamic value per query, allowing the model to use only a single attention head and remove the feed-forward network entirely. Experiments show DVA reduces training time by 37.6% while improving learning capability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Transformer Reconstructed with Dynamic Value Attention") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("静态值/Static Value")
        Problem --> P2("多头冗余/Multi-head Redundancy")
        Method --> M1("动态值注意力/Dynamic Value Attention (DVA)")
        Method --> M2("单头架构/Single-head Architecture")
        Method --> M3("移除前馈网络/Remove Feed-Forward Network")
        Results --> R1("训练时间减少37.6%/37.6% Training Time Saved")
        Results --> R2("学习能力提升/Learning Capability Increased")
    ```

- **[arXiv251230] On the Existence and Behaviour of Secondary Attention Sinks**
  - **tags:** [mlsys], [llm inference], [attention sinks, transformer, mlp, attention mechanism, large language models]
  - **authors:** Jeffrey T.H. Wong, Cheng Zhang, Louis Mahon, Wayne Luk, Anton Isopoussu, Yiren Zhao
  - **institution:** Imperial College London, UnlikelyAI
  - **link:** https://arxiv.org/pdf/2512.22213
  - **contributions:** 1. Identifies and characterizes a new class of "secondary attention sinks" that arise in middle layers, have variable lifetimes, and draw moderate attention, differing from persistent primary sinks like BOS. 2. Shows that secondary sinks are formed by specific middle-layer MLP modules that map token representations to align with the primary sink's direction, with their L2-norm determining sink strength and lifetime. 3. Observes that in larger models, these sink patterns (sink levels) become more deterministic and frequent, with distinct levels identified in models like QwQ-32B and Qwen3-14B.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec1462ca646134f445eac98192ff5189abb63f37682802d695aadace9f83b0d3_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies a new phenomenon called "secondary attention sinks" in transformer LLMs, which are distinct from the known primary sinks (like BOS). The authors show these secondary sinks are created by middle-layer MLPs aligning tokens with the primary sink direction, and their properties (strength, lifetime) become more structured in larger models. This provides new insights into the internal mechanics of attention in large language models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["On the Existence and Behaviour of Secondary Attention Sinks<br/>二次注意力汇的存在与行为"] --> B["核心问题/Problem<br/>Prior work only studied persistent primary sinks (e.g., BOS)<br/>先前研究仅关注持久的主汇（如BOS）"]
        A --> C["主要方法/Method<br/>Extensive experiments across 11 model families<br/>对11个模型系列进行广泛实验"]
        A --> D["关键结果/Results<br/>1. Secondary sinks form via MLPs in middle layers<br/>次级汇通过中间层MLP形成<br/>2. L2-norm determines sink score & lifetime<br/>L2范数决定汇分数与寿命<br/>3. Sink levels are deterministic in large models<br/>大模型中汇层级更确定"]
    ```

- **[arXiv251230] Interpretable and Adaptive Node Classification on Heterophilic Graphs via Combinatorial Scoring and Hybrid Learning**
  - **tags:** [ai], [graph neural networks], [heterophily, interpretability, combinatorial inference, hybrid learning, node classification]
  - **authors:** Soroush Vahidi
  - **institution:** New Jersey Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.22221
  - **contributions:** 1. Proposes an interpretable, adaptive framework for node classification using explicit combinatorial inference instead of deep message passing, with a tunable scoring function. 2. Introduces a validation-gated hybrid strategy that optionally refines combinatorial predictions with a lightweight neural model only when beneficial. 3. Ensures a leakage-free evaluation protocol by computing all adaptation signals strictly from training data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31111cc9c8d13c529d7f271adf29c47c440b43adfaa3481dde88da7f87b76463_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of node classification on heterophilic graphs where standard GNNs struggle. It proposes an interpretable framework based on combinatorial scoring and a conditional hybrid learning strategy, achieving competitive performance with modern GNNs while offering better interpretability, tunability, and efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Interpretable and Adaptive Node Classification on Heterophilic Graphs via Combinatorial Scoring and Hybrid Learning") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("GNNs在异配图上表现不佳/GNNs struggle on heterophilic graphs")
        Method --> M1("组合推理与评分函数/Combinatorial Inference & Scoring")
        Method --> M2("验证门控混合策略/Validation-gated Hybrid Strategy")
        Results --> R1("性能有竞争力/Competitive Performance")
        Results --> R2("可解释性与高效性/Interpretability & Efficiency")
    ```

- **[arXiv251230] Mirage Persistent Kernel: A Compiler and Runtime for Mega-Kernelizing Tensor Programs**
  - **tags:** [mlsys], [llm inference], [megakernel, kernel fusion, SM-level graph, software pipelining, CUDA]
  - **authors:** Xinhao Cheng, Zhihao Zhang, Yu Zhou, Jianan Ji, Jinchen Jiang, Zepeng Zhao, Ziruo Xiao, Zihao Ye, Yingyi Huang, Ruihang Lai, Hongyi Jin, Bohan Hou, Mengdi Wu, Yixin Dong, Anthony Yip, Zihao Ye, Songting Wang, Wenqin Yang, Xupeng Miao, Tianqi Chen, Zhihao Jia
  - **institution:** Carnegie Mellon University, Tsinghua University, NVIDIA, University of Michigan, Purdue University
  - **link:** https://arxiv.org/pdf/2512.22219
  - **code:** https://github.com/mirage-project/mirage
  - **contributions:** 1. Introduces an SM-level graph representation for capturing fine-grained data dependencies across GPU streaming multiprocessors. 2. Develops a compiler and an in-kernel parallel runtime that automatically transforms multi-operator inference into a single, high-performance mega-kernel. 3. Enables previously infeasible GPU optimizations like cross-operator software pipelining and fine-grained kernel overlap, significantly reducing inference latency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f886cd06ce6c0f773c062fa38aae0fa982d862cc66ef54da9fbbfd6cf62dd86a_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces Mirage Persistent Kernel (MPK), a compiler and runtime system that automatically fuses multiple GPU kernels for model inference into a single, optimized mega-kernel. It achieves this by using a novel SM-level graph representation and decentralized scheduling to enable fine-grained optimizations like software pipelining. Evaluation shows MPK reduces LLM inference latency by up to 1.7x, pushing performance close to hardware limits.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Mirage Persistent Kernel<br>幻影持久内核] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Kernel-per-operator execution<br>limits GPU optimization<br>逐算子内核执行限制GPU优化]
        C --> C1[SM-level graph &<br>mega-kernel runtime<br>SM级图与巨型内核运行时]
        D --> D1[Reduces inference latency<br>by up to 1.7x<br>推理延迟降低高达1.7倍]
    ```

- **[arXiv251230] Müntz-Szász Networks: Neural Architectures with Learnable Power-Law Bases**
  - **tags:** [ai], [neural network architecture], [Müntz-Szász Networks, fractional power bases, physics-informed neural networks, universal approximation, singular function approximation]
  - **authors:** Gnankan Landry Regis N'guessan
  - **institution:** Axiom Research Group, The Nelson Mandela African Institution of Science and Technology (NM-AIST), African Institute for Mathematical Sciences (AIMS) Research and Innovation Centre
  - **link:** https://arxiv.org/pdf/2512.22222
  - **contributions:** 1. Introduces Müntz-Szász Networks (MSN), a novel neural architecture with learnable fractional power bases to approximate functions with singular or fractional power behavior. 2. Provides theoretical analysis proving MSN inherits universal approximation from the Müntz-Szász theorem and establishes superior approximation rates compared to standard MLPs for singular functions. 3. Demonstrates empirical superiority, achieving significantly lower error with fewer parameters in supervised regression and 3-6x improvement in physics-informed neural network benchmarks, while learning interpretable exponents.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c66c3ba4917449496481593b1432346dc5ef9301c3c66f4713e327bbb234969d_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces Müntz-Szász Networks (MSN), a neural architecture that replaces fixed activation functions with learnable fractional power bases to better approximate singular functions common in physics. It proves MSN's universal approximation capability and shows it achieves much lower error with fewer parameters than standard MLPs on regression and physics-informed tasks, demonstrating the value of theory-guided design.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Müntz-Szász Networks: Neural Architectures with Learnable Power-Law Bases] --> B[核心问题/Problem: Standard neural networks poorly approximate singular/fractional power functions common in physics]
    A --> C[主要方法/Method: Proposes MSN with learnable fractional power bases, replacing fixed activations]
    A --> D[关键结果/Results: MSN achieves superior approximation rates, lower error with fewer parameters, and significant improvement on PINN benchmarks]
    ```

- **[arXiv251230] VideoScaffold: Elastic-Scale Visual Hierarchies for Streaming Video Understanding in MLLMs**
  - **tags:** [cv], [video understanding], [streaming video, multimodal large language models, event segmentation, hierarchical representation, elastic-scale]
  - **authors:** Naishan Zheng, Jie Huang, Qingpei Guo, Feng Zhao
  - **institution:** University of Science and Technology of China, Ant Group
  - **link:** https://arxiv.org/pdf/2512.22226
  - **code:** https://github.com/zheng980629/VideoScaffold
  - **contributions:** 1. Proposes VideoScaffold, a dynamic representation framework for streaming video understanding in MLLMs that adaptively adjusts event granularity. 2. Introduces Elastic-Scale Event Segmentation (EES) for prediction-guided, dynamic boundary refinement. 3. Introduces Hierarchical Event Consolidation (HEC) for progressively aggregating segments into multi-level abstractions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ccc0f206a787899e1408b9c740b895e26c8c4847a2ecfbe5f88b48c25ce70ca_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of understanding long, streaming videos with MLLMs by proposing VideoScaffold, a framework that dynamically segments and hierarchically consolidates video events to adapt granularity and preserve semantics. It achieves state-of-the-art performance on benchmarks and can extend image-based MLLMs to video comprehension.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[VideoScaffold: Elastic-Scale Visual Hierarchies for Streaming Video Understanding in MLLMs] --> B[核心问题/Problem: Understanding long, streaming videos with MLLMs is challenging due to redundancy and need for temporal coherence.]
        A --> C[主要方法/Method: Proposes a dynamic framework with Elastic-Scale Event Segmentation (EES) and Hierarchical Event Consolidation (HEC).]
        A --> D[关键结果/Results: Achieves state-of-the-art performance; framework is modular and plug-and-play.]
    ```

- **[arXiv251230] ReGAIN: Retrieval-Grounded AI Framework for Network Traffic Analysis**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [retrieval-augmented generation (RAG), network traffic analysis, large language models (LLMs), hierarchical retrieval, explainable AI]
  - **authors:** Shaghayegh Shajarian, Kennedy Marsh, James Benson, Sajad Khorsandroo, Mahmoud Abdelsalam
  - **institution:** North Carolina A&T State University, University of Texas at San Antonio
  - **link:** https://arxiv.org/pdf/2512.22223
  - **code:** https://github.com/270771/llm-traffictraffic
  - **contributions:** 1. Proposes ReGAIN, a multi-stage framework combining traffic summarization, RAG, and LLM reasoning for transparent network traffic analysis. 2. Introduces a hierarchical retrieval pipeline with metadata filtering, MMR sampling, cross-encoder reranking, and an abstention mechanism to ground responses and reduce hallucinations. 3. Demonstrates high accuracy (95.95%-98.82%) on real-world attack traces and outperforms traditional baselines while providing explainable, evidence-cited outputs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/56c5ba03e3d4a510212509143bfecf0fa8b76f9171aa38dd765dadecc7b1ab32_w640_q70.webp
  - **Simple LLM Summary:** The paper presents ReGAIN, a framework that uses retrieval-augmented generation (RAG) and LLMs to analyze network traffic. It converts traffic into summaries, retrieves relevant evidence from a vector database, and generates interpretable, grounded analyses. The method achieves high accuracy on attack detection and provides explainable results, outperforming traditional rule-based and ML approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ReGAIN: Retrieval-Grounded AI Framework for Network Traffic Analysis] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Traditional traffic analysis systems have high false positives and lack interpretability.]
        C[主要方法/Method: Multi-stage framework using traffic summarization, RAG, and LLM reasoning with a hierarchical retrieval pipeline.]
        D[关键结果/Results: Achieves 95.95%-98.82% accuracy, outperforms baselines, and provides explainable, evidence-grounded responses.]
    ```

- **[arXiv251230] Hierarchical Geometry of Cognitive States in Transformer Embedding Spaces**
  - **tags:** [nlp], [representation analysis], [sentence embeddings, probing, hierarchical geometry, transformer models, cognitive states]
  - **authors:** Sophie Zhao
  - **institution:** Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.22227
  - **contributions:** 1. Constructed a novel dataset of 480 sentences annotated with continuous energy scores and discrete tier labels for seven ordered cognitive categories. 2. Demonstrated that both continuous scores and discrete tier labels are reliably decodable from fixed transformer sentence embeddings using linear and nonlinear probes, with nonlinear probes providing consistent gains. 3. Provided statistical and qualitative evidence (via permutation tests, UMAP visualizations, and confusion matrices) that the embedding space exhibits a hierarchical geometric organization aligned with human-defined cognitive attributes, beyond surface word statistics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fec0b31a0f9f75593cbc3cdadecae63f4a1a7b7b6d910165a358bc72dde0f1d7_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether transformer-based sentence embeddings encode a hierarchical structure aligned with cognitive states. The authors construct an annotated dataset and use linear and nonlinear probes to decode continuous scores and discrete labels from embeddings, finding reliable recoverability and a structured geometric gradient. The results show that transformer embedding spaces exhibit a systematic organization corresponding to interpretable cognitive attributes.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Hierarchical Geometry of Cognitive States in Transformer Embedding Spaces") --> Problem("核心问题/Problem: Do sentence embeddings encode hierarchical cognitive structure?")
        Root --> Method("主要方法/Method: Probe analysis on annotated dataset with linear/nonlinear classifiers")
        Root --> Results("关键结果/Results: Reliable decoding, hierarchical geometry aligned with cognitive attributes")
    ```

- **[arXiv251230] We are not able to identify AI-generated images**
  - **tags:** [cv], [image forensics], [AI-generated images, human evaluation, MidJourney, CC12M, synthetic media detection]
  - **authors:** Adrien Pavão
  - **institution:** (Institution not explicitly stated in provided content. Author name is Adrien Pavão; no affiliation or email domain is given. Therefore, institution cannot be reliably inferred.)
  - **link:** https://arxiv.org/pdf/2512.22236
  - **contributions:** 1. Conducted a controlled web-based experiment to empirically test human ability to distinguish real photographs from AI-generated portraits, finding performance near random chance (54% accuracy). 2. Created and released a curated, challenging dataset of 120 images (real from CC12M and AI-generated counterparts from MidJourney) designed to be difficult for humans. 3. Demonstrated that human judgment is insufficient for reliable detection of synthetic media, highlighting the need for greater public awareness and ethical guidelines as AI-generated content becomes more realistic.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60b100d4e4882d297b51639fb736da62f90b11f1d810da4b6665f9da69ef3f31_w640_q70.webp
  - **Simple LLM Summary:** The paper tests the assumption that humans can easily identify AI-generated images through an interactive web experiment where participants classified 20 images as real or AI-generated. Using a carefully curated dataset of 120 difficult portrait images (real from CC12M and AI-generated from MidJourney), the study found an average human accuracy of only 54%, barely above random guessing. The results show that humans struggle to reliably detect AI-generated content, indicating that human judgment alone is becoming insufficient and underscoring the need for awareness and ethical guidelines.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[We are not able to identify AI-generated images] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Can humans reliably distinguish AI-generated images from real photos?]
        Method[主要方法/Method: Interactive web experiment with a curated dataset of 120 difficult images (CC12M real vs. MidJourney AI-generated)]
        Results[关键结果/Results: Average human accuracy is 54% (near random), response time ~7.3s, highlighting human insufficiency and need for guidelines]
    ```

- **[arXiv251230] DiRL: An Efficient Post-Training Framework for Diffusion Language Models**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [Diffusion Language Models, FlexAttention, Group Relative Policy Optimization, LMDeploy, blockwise training]
  - **authors:** Ying Zhu, Jiaxin Wan, Xiaoran Liu, Siyanag He, Qiqi Wang, Xu Guo, Tianyi Liang, Zengfeng Huang, Ziwei He, Xipeng Qiu
  - **institution:** Fudan University, Shanghai Innovation Institute, OpenMoss Team
  - **link:** https://arxiv.org/pdf/2512.22234
  - **code:** https://github.com/OpenMOSS/DiRL
  - **contributions:** 1. Proposes DiRL, an efficient post-training framework for Diffusion Language Models (dLLMs) that integrates FlexAttention-accelerated blockwise training with LMDeploy-optimized inference. 2. Introduces DiPO, the first unbiased Group Relative Policy Optimization (GRPO) implementation specifically designed for dLLMs. 3. Demonstrates state-of-the-art math reasoning performance for dLLMs by training DiRL-8B-Instruct, surpassing comparable models like Qwen2.5 series on benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the underdeveloped and inefficient post-training landscape for Diffusion Language Models (dLLMs). It proposes DiRL, an efficient framework combining accelerated training and optimized inference, and introduces DiPO, a tailored reinforcement learning method. The resulting model, DiRL-8B-Instruct, achieves state-of-the-art math performance among dLLMs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DiRL: An Efficient Post-Training Framework for Diffusion Language Models] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[dLLMs后训练低效/Post-training for dLLMs is inefficient]
        B --> B2[训练与推理目标不匹配/Training-Inference objective mismatch]
        C --> C1[DiRL框架/DiRL Framework]
        C1 --> C1_1[整合FlexAttention与LMDeploy/Integrates FlexAttention & LMDeploy]
        C1 --> C1_2[两阶段后训练/Two-stage post-training (SFT+RL)]
        C --> C2[DiPO算法/DiPO Algorithm]
        C2 --> C2_1[无偏GRPO实现/Unbiased GRPO for dLLMs]
        D --> D1[高效训练与推理/Efficient Training & Inference]
        D --> D2[数学SOTA性能/Math SOTA Performance]
        D --> D3[超越Qwen2.5系列/Surpasses Qwen2.5 series]
    ```

- **[arXiv251230] Enhanced geometry prediction in laser directed energy deposition using meta-learning**
  - **tags:** [ai], [meta-learning], [meta-learning, model-agnostic meta-learning, reptile, laser-directed energy deposition, bead geometry prediction]
  - **authors:** Abdul Malik Al Mardhouf Al Saadi, Amrita Basak
  - **institution:** The Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2512.22241
  - **contributions:** 1. Proposed a cross-dataset knowledge transfer model for L-DED bead geometry prediction using meta-learning to address data scarcity and heterogeneity. 2. Investigated and applied two gradient-based meta-learning algorithms (MAML and Reptile) for rapid adaptation to new deposition conditions with limited data. 3. Demonstrated strong generalization performance of the meta-learning models across diverse L-DED processes (powder-fed, wire-fed, hybrid) using minimal training examples, outperforming conventional neural networks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4239294fb44dd0fe97ebc3a123162ba7aaa82e51c2805d4460072daeffe6de9_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of predicting bead geometry in laser-directed energy deposition (L-DED) where experimental data is scarce and heterogeneous. It proposes using meta-learning algorithms, specifically MAML and Reptile, to enable rapid model adaptation to new printing conditions with very few training examples. The results show that this approach achieves accurate predictions and outperforms traditional neural networks under similar data constraints, demonstrating effective knowledge transfer across different L-DED settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Enhanced geometry prediction in L-DED using meta-learning] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Data scarcity & heterogeneity in L-DED geometry prediction]
        C[主要方法/Method: Meta-learning (MAML & Reptile) for cross-dataset knowledge transfer]
        D[关键结果/Results: Accurate prediction with few examples, outperforms conventional NN]
    ```

- **[arXiv251230] Fairness Evaluation of Risk Estimation Models for Lung Cancer Screening**
  - **tags:** [cv], [medical imaging], [algorithmic fairness, subgroup performance analysis, JustEFAB framework]
  - **authors:** Shaurya Gaur, Michel Vitale, Alessa Hering, Johan Kwisthout, Colin Jacobs, Lena Philipp, Fennie van der Graaf
  - **institution:** Radboud University Medical Center, Radboud University
  - **link:** https://arxiv.org/pdf/2512.22242
  - **contributions:** 1. Conducted a fairness evaluation of three lung cancer risk estimation models (Sybil, Venkadesh21, PanCan2b) using the JustEFAB framework to assess ethically significant biases. 2. Identified and quantified statistically significant performance disparities across demographic subgroups (e.g., gender, race) that were not explained by available clinical confounders. 3. Highlighted the critical need for monitoring and improving model fairness in lung cancer screening AI to ensure equitable clinical application.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/783ab81ef53ced6c68b136e7001be4ece45c131979c45d04a04c21084cbf9888_w640_q70.webp
  - **Simple LLM Summary:** This study evaluates the fairness of AI models for lung cancer risk estimation from CT scans. Using the JustEFAB framework, it assessed performance disparities across demographic groups and found significant, unexplained biases in two deep learning models. The findings underscore the importance of algorithmic fairness in medical AI to ensure equitable screening outcomes.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Fairness Evaluation of Risk Estimation Models for Lung Cancer Screening<br/>肺癌筛查风险估计模型的公平性评估] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br/>AI肺癌风险模型在不同人口亚组中的性能表现是否公平？<br/>Is AI lung cancer risk model performance fair across demographic subgroups?]
        Method[主要方法/Method<br/>使用JustEFAB框架评估模型在NLST验证集上的性能差异<br/>Evaluate model performance disparities on NLST validation set using JustEFAB framework]
        Results[关键结果/Results<br/>发现Sybil和Venkadesh21模型存在显著的、无法用混杂因素解释的性能差异<br/>Found significant, unexplained performance disparities in Sybil and Venkadesh21 models]
    ```

- **[arXiv251230] Predicting Mycotoxin Contamination in Irish Oats Using Deep and Transfer Learning**
  - **tags:** [ai], [transfer learning], [TabPFN, FT-Transformer, permutation-based variable importance]
  - **authors:** Alan Inglis, Fiona Doohan, Subramani Natarajan, Breige McNulty, Chris Elliott, Anne Nugent, Julie Meneely, Brett Greer, Stephen Kildea, Diana Bucur, Martin Danaher, Melissa Di Rocco, Lisa Black, Adam Gauley, Naoise McKenna, Andrew Parnell
  - **institution:** Maynooth University, University College Dublin, Queen's University Belfast, Teagasc, Agri-Food and Biosciences Institute (AFBI)
  - **link:** https://arxiv.org/pdf/2512.22243
  - **contributions:** 1. Evaluated and compared the performance of multiple deep learning and transfer learning models (MLP, TabPFN, TabNet, FT-Transformer) for predicting mycotoxin contamination in oats. 2. Applied these models to a multi-response prediction task using a dataset of environmental, agronomic, and geographical predictors from Irish oat samples. 3. Conducted a permutation-based variable importance analysis, identifying weather history in the 90-day pre-harvest period and seed moisture content as the most influential predictors.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/64407e4c1b4c79c19f30f80502744b2e2eadb71d078c9e48b84cad3e1286130e_w640_q70.webp
  - **Simple LLM Summary:** This study uses neural networks and transfer learning to predict mycotoxin contamination in Irish oat crops. The models, including TabPFN, TabNet, and FT-Transformer, were evaluated on a multi-response task, with TabPFN achieving the best overall performance. The analysis found that weather patterns before harvest and seed moisture are the most critical factors for prediction.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Predicting Mycotoxin Contamination in Irish Oats<br>预测爱尔兰燕麦中的霉菌毒素污染] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Mycotoxin contamination risks food safety and agricultural productivity.<br>霉菌毒素污染威胁食品安全和农业生产力。]
        C[主要方法/Method<br>Use neural networks and transfer learning (TabPFN, TabNet, FT-Transformer) for multi-response prediction.<br>使用神经网络和迁移学习进行多响应预测。]
        D[关键结果/Results<br>TabPFN performed best; weather history and seed moisture are key predictors.<br>TabPFN表现最佳；天气历史和种子水分是关键预测因子。]
    ```

- **[arXiv251230] Masking Teacher and Reinforcing Student for Distilling Vision-Language Models**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [knowledge distillation, reinforcement learning, vision-language models, progressive masking, offline RL]
  - **authors:** Byung-Kwan Lee, Yu-Chiang Frank Wang, Ryo Hachiuma
  - **institution:** NVIDIA
  - **link:** https://arxiv.org/pdf/2512.22238
  - **contributions:** 1. Proposes Masters, a mask-progressive RL distillation framework that first masks non-dominant teacher weights to reduce complexity and then progressively restores them for stable student learning. 2. Introduces an offline RL stage with complementary accuracy and distillation rewards, leveraging pre-generated responses from masked teachers for efficient guidance. 3. Demonstrates that progressive teacher scaling (e.g., from 14B to 38B) yields smoother convergence and stronger generalization than one-shot distillation, providing a scalable path to efficient VLMs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72df4c6bab2069771a9955e5dac4af81d2f423474fdaf07bf9980aaea39edeaf_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of distilling large vision-language models (VLMs) into compact ones by proposing Masters, a framework that uses progressive masking of the teacher model and offline reinforcement learning. This method enables stable knowledge transfer and efficient training, resulting in small VLMs that achieve strong performance, sometimes surpassing larger models, while being far more efficient for deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Masking Teacher and Reinforcing Student for Distilling Vision-Language Models] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[大型VLM难以部署到移动/边缘设备/Large VLMs are impractical for mobile/edge deployment]
        B --> B2[师生模型尺寸差距导致知识蒸馏不稳定/Large size gap causes unstable distillation]
        C --> C1[掩码渐进式强化学习蒸馏框架/Mask-progressive RL distillation framework]
        C --> C2[先掩码教师非主导权重，再渐进恢复/First mask non-dominant teacher weights, then progressively restore]
        C --> C3[离线RL阶段使用准确性和蒸馏奖励/Offline RL stage with accuracy and distillation rewards]
        D --> D1[在多个基准测试中超越现有紧凑型VLM/Outperforms existing compact VLMs on diverse benchmarks]
        D --> D2[渐进增加教师尺寸带来更平滑收敛和更强泛化/Gradually increasing teacher size yields smoother convergence & stronger generalization]
        D --> D3[提供高效、可部署VLM的可扩展路径/Provides a scalable path toward efficient, deployable VLMs]
    ```

- **[arXiv251230] EvoXplain: When Machine Learning Models Agree on Predictions but Disagree on Why -- Measuring Mechanistic Multiplicity Across Training Runs**
  - **tags:** [ai], [interpretability], [mechanistic multiplicity, explanatory stability, stochastic optimization, model explanations, diagnostic framework]
  - **authors:** Chama Bensmail
  - **institution:** University of Hertfordshire, Omics Data Solutions LTD
  - **link:** https://arxiv.org/pdf/2512.22240
  - **code:** https://github.com/bensmailchama-boop/EvoXplain
  - **contributions:** 1. Introduces EvoXplain, a diagnostic framework for measuring the stability of model explanations across repeated training runs, treating explanations as samples from the optimization process. 2. Demonstrates that high-accuracy models (e.g., Logistic Regression, Random Forests) can rely on multiple distinct internal mechanisms, revealing explanatory multimodality not captured by single-model or averaged explanations. 3. Reframes interpretability as a property of a model class under repeated instantiation, challenging the assumption that a single high-accuracy model yields a unique or trustworthy explanation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a39d3b0c4608e98a5ffde3a753078019f45b0c48774cb02ee158633c35e823d2_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces EvoXplain, a framework to diagnose if models achieving similar high accuracy do so via the same or different internal mechanisms by analyzing explanation stability across training runs. It finds that even simple, stable models like Logistic Regression can exhibit multiple distinct explanatory modes on datasets like Breast Cancer and COMPAS, showing that single-model explanations can be misleading. This work highlights explanatory instability as a measurable property and reframes interpretability as a characteristic of a model class rather than a single trained instance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[EvoXplain Paper] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[高精度模型是否共享相同内部逻辑?<br/>Do high-accuracy models share the same internal logic?]
        C --> C1[跨重复训练测量解释稳定性<br/>Measure explanation stability across repeated training]
        C --> C2[将解释视为优化过程样本<br/>Treat explanations as samples from optimization]
        D --> D1[发现解释的多模态性<br/>Found explanatory multimodality]
        D --> D2[逻辑回归等模型也显示多种机制<br/>Models like Logistic Regression show multiple mechanisms]
        D --> D3[重新定义可解释性为模型类属性<br/>Reframe interpretability as model-class property]
    ```

- **[arXiv251230] Calibrating LLM Judges: Linear Probes for Fast and Reliable Uncertainty Estimation**
  - **tags:** [mlsys], [llm inference], [uncertainty estimation, calibration, linear probe, brier score, llm-as-judge]
  - **authors:** Bhaktipriya Radharapu, Eshika Saxena, Kenneth Li, Chenxi Whitehouse, Adina Williams, Nicola Cancedda
  - **institution:** Meta (FAIR at Meta, Meta Superintelligence Labs)
  - **link:** https://arxiv.org/pdf/2512.22245
  - **contributions:** 1. Introduces a method using linear probes on LLM hidden states to provide calibrated uncertainty estimates for LLM judges, requiring no additional model training. 2. Demonstrates superior calibration and ≈10x computational savings compared to baseline methods like verbalized confidence. 3. Shows the method generalizes robustly across different model architectures, training paradigms, and unseen evaluation domains.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33ea018b43295c51d076b3840537c861c2e2c7f22ca2bdd183164d1f1feed91d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of obtaining efficient and well-calibrated uncertainty estimates for LLM-based judges. It proposes using linear probes trained with a Brier score loss on the model's hidden states. The method achieves better calibration with significant computational savings and provides a practical plug-and-play solution for production deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Calibrating LLM Judges<br/>校准LLM法官] --> B[Problem: LLM judges lack efficient, calibrated uncertainty<br/>问题：LLM法官缺乏高效、校准的不确定性估计]
        A --> C[Method: Linear probes on hidden states with Brier score loss<br/>方法：基于Brier分数损失的隐状态线性探针]
        A --> D[Results: Better calibration, 10x speedup, robust generalization<br/>结果：更好的校准，10倍加速，鲁棒的泛化]
    ```

- **[arXiv251230] Amortized Inference for Model Rocket Aerodynamics: Learning to Estimate Physical Parameters from Simulation**
  - **tags:** [ai], [physics-informed machine learning], [amortized inference, sim-to-real transfer, model rocketry, neural network, parameter estimation]
  - **authors:** Rohit Pandey, Rohan Pandey
  - **institution:** Bellevue High School, University of Washington
  - **link:** https://arxiv.org/pdf/2512.22248
  - **contributions:** 1. Formulates model rocket parameter estimation as an amortized inference problem and demonstrates neural networks can invert physics simulations from sparse observations. 2. Proposes a simulation-based amortized inference approach that enables zero-shot sim-to-real transfer for aerodynamic parameter estimation. 3. Provides quantitative analysis of the sim-to-real gap and shows the learned model reduces apogee prediction error compared to a traditional baseline (OpenRocket).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59b12172a46941853e291b33e21d912e272992d414baf27e4495c7137fe4266c_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a simulation-based amortized inference method that trains a neural network on synthetic flight data to predict aerodynamic parameters like drag coefficient from a single apogee measurement. The trained model is applied directly to real flights without fine-tuning, achieving promising zero-shot sim-to-real transfer and reducing apogee prediction error compared to traditional tools.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Amortized Inference for Model Rocket Aerodynamics") --> Problem("核心问题/Problem: Estimating aerodynamic parameters from sparse real flight data is difficult and costly.")
        Root --> Method("主要方法/Method: Train neural network on synthetic data to invert physics simulator for amortized inference.")
        Root --> Results("关键结果/Results: Promising zero-shot sim-to-real transfer with reduced apogee prediction error.")
    ```

- **[arXiv251230] The Affine Divergence: Aligning Activation Updates Beyond Normalisation**
  - **tags:** [ai], [optimization theory], [activation updates, gradient descent, normalisation, PatchNorm, affine divergence]
  - **authors:** George Bird
  - **institution:** University of Manchester
  - **link:** https://arxiv.org/pdf/2512.22247
  - **contributions:** 1. Identifies a systematic mismatch between mathematically ideal and effective activation updates during gradient descent, providing a new theoretical framework for understanding optimization. 2. Derives normalisation from first principles as a solution to this mismatch and proposes a functionally distinct, non-scale-invariant alternative that outperforms conventional normalisers. 3. Introduces "PatchNorm", a new compositionally inseparable normaliser for convolutional layers, and argues for reframing normalisers as activation-function-like maps with parameterised scaling.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48ed42bcb2d9358f1931e9e0ea31246380c7ef78409f6004933a0fb2461eb9d1_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a mismatch between the ideal steepest-descent direction for activations and their effective updates during gradient descent. It proposes a theoretical framework that derives normalisation as a solution and introduces a new alternative, including "PatchNorm" for convolutions, which empirically outperforms standard normalisers. This reframes normalisation's role and questions the standard affine+nonlinear model-building approach.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[The Affine Divergence: Aligning Activation Updates Beyond Normalisation] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[激活更新不匹配/Activation update mismatch]
        P1 --> P2[非理想缩放/Non-ideal scaling]
        Method[主要方法/Method] --> M1[理论推导/Theoretical derivation]
        M1 --> M2[提出新方案/Propose new solutions]
        M2 --> M3[PatchNorm for convolution]
        Results[关键结果/Results] --> R1[重构归一化/Reframe normalisation]
        R1 --> R2[新方案有效/New methods outperform]
    ```

- **[arXiv251230] Analyzing Skill Element in Online Fantasy Cricket**
  - **tags:** [ai], [game theory and decision making], [statistical framework, team selection strategies, dynamic tournament model, softmax reweighting, IPL dataset]
  - **authors:** Sarthak Sarkar, Supratim Das, Purushottam Saha, Diganta Mukherjee, Tridib Mukherjee
  - **institution:** Indian Statistical Institute, Kolkata
  - **link:** https://arxiv.org/pdf/2512.22254
  - **contributions:** 1. Development of a statistical framework to assess the role of skill in online fantasy cricket. 2. Construction and analysis of a range of deterministic and stochastic team selection strategies. 3. Introduction of a dynamic tournament model with agent populations evolving via a softmax reweighting mechanism.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e92b7b67260659549974352e85a2e375a90fd015a5561a1d909fb586dcfd635_w640_q70.webp
  - **Simple LLM Summary:** This paper develops a statistical framework to analyze whether success in online fantasy cricket is driven by skill or chance. It constructs various team selection strategies and a dynamic tournament model, testing them on IPL 2024 data. The results provide quantitative evidence supporting the presence of a skill element in these platforms.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Analyzing Skill Element in Online Fantasy Cricket] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Fantasy sports: skill or chance?]
        C --> C1[Statistical framework]
        C1 --> C2[Team selection strategies]
        C2 --> C3[Deterministic & Stochastic]
        C1 --> C4[Dynamic tournament model]
        C4 --> C5[Softmax reweighting]
        C --> C6[Experiments on IPL 2024]
        D --> D1[Evidence for skill element]
    ```

- **[arXiv251230] Graph Attention-based Adaptive Transfer Learning for Link Prediction**
  - **tags:** [ai], [graph neural networks], [graph attention network, link prediction, transfer learning, graph transformer, contrastive loss]
  - **authors:** Huashen Lu, Wensheng Gan, Guoting Chen, Zhichao Huang, Philip S. Yu
  - **institution:** Jinan University, Great Bay University, JD Technology, University of Illinois Chicago
  - **link:** https://arxiv.org/pdf/2512.22252
  - **code:** https://github.com/DSI-Lab1/GAATNet
  - **contributions:** 1. Proposes GAATNet, a novel graph attention adaptive transfer network combining pre-training and fine-tuning for cross-dataset knowledge transfer in link prediction. 2. Incorporates distant neighbor embeddings as biases in self-attention to capture global node features. 3. Introduces a lightweight self-adapter module during fine-tuning to improve training efficiency and generalization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e9ea1091686509af1da226ce7553577b4005c5646524a5c6718473e451d3c39_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses challenges in link prediction on large-scale sparse graphs and cross-dataset transfer learning by proposing GAATNet, which integrates graph attention with adaptive transfer strategies. The method uses distant neighbor embeddings and a self-adapter module to enhance global feature capture and training efficiency. Experiments on seven datasets show state-of-the-art performance, offering a scalable solution for integrating GNNs with transfer learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Graph Attention-based Adaptive Transfer Learning for Link Prediction] --> B[核心问题/Problem: Challenges in large-scale sparse graphs and cross-dataset transfer learning for link prediction]
        A --> C[主要方法/Method: Proposes GAATNet with distant neighbor embeddings and lightweight self-adapter for adaptive transfer]
        A --> D[关键结果/Results: Achieves SOTA performance on seven datasets, provides scalable GNN-transfer learning solution]
    ```

- **[arXiv251230] Temporal Visual Semantics-Induced Human Motion Understanding with Large Language Models**
  - **tags:** [cv], [human motion segmentation], [temporal vision semantics, subspace clustering, large language model, temporal regularizer, feedback framework]
  - **authors:** Zheng Xing, Weibing Zhao
  - **institution:** Shenzhen University, Shenzhen MSU-BIT University
  - **link:** https://arxiv.org/pdf/2512.22249
  - **contributions:** 1. Proposes a novel method to learn Temporal Vision Semantics (TVS) from human motion sequences by querying a Large Language Model (LLM) to determine motion consistency between consecutive frames. 2. Develops a TVS-integrated subspace clustering framework that incorporates a temporal regularizer and constraint to enforce similarity among temporal neighbors in the subspace embedding and segmentation. 3. Introduces a feedback-enabled optimization framework that iteratively refines the subspace embedding based on the segmentation output to improve performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fce87220cc17109bbd9138b27d5aa353003bb134fb0924f68b7fc59fdfd3ee0d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of unsupervised human motion segmentation by integrating temporal semantic information into subspace clustering. The proposed method uses a Large Language Model to extract textual motion descriptions from consecutive frames and incorporates this learned temporal neighbor information as constraints within the clustering framework. Experimental results show the method outperforms state-of-the-art approaches on four benchmark datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题 / Paper Title: Temporal Visual Semantics-Induced Human Motion Understanding with Large Language Models] --> B(核心问题 / Problem: 传统无监督人体运动分割方法忽略了时序语义的作用 / Traditional unsupervised HMS overlooks temporal semantics)
        A --> C(主要方法 / Method: 利用LLM提取时序视觉语义，并融入子空间聚类框架 / Use LLM to extract TVS and integrate it into subspace clustering)
        A --> D(关键结果 / Results: 在四个基准数据集上性能超越现有方法 / Outperforms SOTA on four benchmark datasets)
        C --> C1(LLM查询 / LLM Query: 判断相邻帧是否描述相同运动 / Determine if consecutive frames depict the same motion)
        C --> C2(时序正则化 / Temporal Regularizer: 诱导相邻帧共享相似子空间嵌入 / Induces similar subspace embeddings for temporal neighbors)
        C --> C3(反馈优化 / Feedback Optimization: 基于分割结果迭代优化嵌入 / Iteratively optimizes embedding based on segmentation output)
    ```

- **[arXiv251230] Interpretable Perturbation Modeling Through Biomedical Knowledge Graphs**
  - **tags:** [ai], [graph neural networks], [biomedical knowledge graph, graph attention network, gene perturbation, multimodal embeddings, PrimeKG++]
  - **authors:** Pascal Passigan, Kevin zhu, Angelina Ning
  - **institution:** Massachusetts Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.22251
  - **contributions:** 1. Introduces a novel framework for gene perturbation prediction by merging PrimeKG++ with LINCS L1000 data into a heterogeneous biomedical knowledge graph, moving beyond binary drug-disease association tasks. 2. Demonstrates the application of a Graph Attention Network (GAT) to predict delta gene expression profiles for drug-cell pairs, outperforming MLP baselines. 3. Provides interpretability through ablation studies (edge shuffling, node feature randomization) showing the critical role of biomedical KG edges in enhancing perturbation-level prediction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a8b52522e1bdfc53ae9978a144c2011810eca2532cb9819ad999bf9b2b6cbb6_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the gap in predicting detailed gene expression changes (perturbations) caused by drugs by constructing a merged biomedical knowledge graph from PrimeKG++ and LINCS L1000 data. The proposed method uses a Graph Attention Network to predict delta expression profiles for drug-cell pairs, which outperforms baseline models and demonstrates the value of graph structure for mechanistic understanding.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Interpretable Perturbation Modeling Through Biomedical Knowledge Graphs] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Predicting granular gene expression changes (perturbations) from drugs, beyond binary drug-disease associations.]
        C[主要方法/Method: Merge PrimeKG++ & LINCS L1000 into a BKG; use Graph Attention Network (GAT) to predict delta expression.]
        D[关键结果/Results: Outperforms MLP baselines; ablation shows KG edges enhance prediction for mechanistic modeling.]
    ```

- **[arXiv251230] Logic Sketch Prompting (LSP): A Deterministic and Interpretable Prompting Method**
  - **tags:** [nlp], [prompt engineering], [Logic Sketch Prompting, deterministic prompting, interpretability, rule adherence, clinical decision support]
  - **authors:** Satvik Tripathi
  - **institution:** University of Pennsylvania
  - **link:** https://arxiv.org/pdf/2512.22258
  - **code:** https://github.com/satviktri/LSP
  - **contributions:** 1. Proposes Logic Sketch Prompting (LSP), a lightweight prompting framework that introduces typed variables and deterministic condition evaluators for structured reasoning., 2. Incorporates a rule-based validator to produce traceable and repeatable outputs, enhancing auditability., 3. Demonstrates significant performance gains over standard prompting methods (zero-shot, chain-of-thought, concise) on pharmacologic logic-compliance tasks across multiple open-weight LLMs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3b5d49d54027e4f7e6b110a48568a0255a45010197e26e8bc344e0cd3e1785a9_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the unreliability of LLMs on tasks requiring strict rule adherence and determinism. It proposes Logic Sketch Prompting (LSP), a framework using typed variables and rule-based validation to produce traceable outputs. Evaluations on clinical tasks show LSP significantly outperforms standard prompting methods in accuracy and F1 score, making it suitable for safety-critical systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Logic Sketch Prompting (LSP)] --> B[核心问题/Problem: LLMs unreliable on tasks needing strict rules & determinism]
        A --> C[主要方法/Method: Lightweight framework with typed variables, condition evaluators, rule validator]
        A --> D[关键结果/Results: Highest accuracy/F1 vs. baselines; suitable for clinical/safety-critical systems]
    ```

- **[arXiv251230] Shape of Thought: When Distribution Matters More than Correctness in Reasoning Tasks**
  - **tags:** [nlp], [reasoning], [chain-of-thought, synthetic data, distribution shift, fine-tuning, reasoning robustness]
  - **authors:** Abhranil Chandra, Ayush Agrawal, Arian Hosseini, Sebastian Fischmeister, Rishabh Agarwal, Navin Goyal, Aaron Courville
  - **institution:** University of Waterloo, University of Massachusetts Amherst, MILA - Quebec AI Institute, Université de Montréal, Microsoft Research India, Google DeepMind, Periodic Labs
  - **link:** https://arxiv.org/pdf/2512.22255
  - **contributions:** 1. Demonstrates that training on synthetic chain-of-thought traces from more capable models, even when they lead to incorrect final answers, can improve a language model's reasoning performance more than training on human-annotated datasets. 2. Proposes and validates two hypotheses for this phenomenon: the distributional alignment of synthetic data with the model, and the partial validity of reasoning steps within flawed traces. 3. Shows that paraphrasing human traces to align with the model's distribution improves performance, and investigates model tolerance to increasingly flawed reasoning steps.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf038d101bb93ad9f8c253c481419dec618655c74a6b867d0128b6358a3fa331_w640_q70.webp
  - **Simple LLM Summary:** This paper challenges the assumption that correctness is the primary determinant of data quality for training language models on reasoning tasks. It shows that fine-tuning on synthetic, incorrect chain-of-thought traces from stronger models can outperform training on correct human-annotated data, primarily because the synthetic data's distribution is closer to the model's own. The key conclusion is that aligning the training data distribution with the model's is more critical for performance than the correctness of the final answers.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Shape of Thought / 思维形态] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Correctness vs. Distribution / 正确性与数据分布]
        B1 --> B2{Does correctness guarantee better reasoning? / 正确性保证更好的推理吗?}
        C --> C1[Train on Incorrect Synthetic CoT / 使用错误的合成CoT训练]
        C --> C2[Paraphrase Human Traces / 改写人类标注的推理链]
        C --> C3[Introduce Flawed Steps / 引入有缺陷的推理步骤]
        D --> D1[Synthetic Incorrect > Human Correct / 错误的合成数据优于正确的人类数据]
        D --> D2[Distribution Alignment is Key / 数据分布对齐是关键]
        D --> D3[Final Answer ≠ Faithful Reasoning / 最终答案 ≠ 忠实推理过程]
    ```

- **[arXiv251230] Cardiac mortality prediction in patients undergoing PCI based on real and synthetic data**
  - **tags:** [ai], [clinical prediction], [synthetic data, class imbalance, permutation feature importance, tabular data, mortality prediction]
  - **authors:** Daniil Burakov, Ivan Petrov, Dmitrii Khelimskii, Ivan Bessonov, Mikhail Lazarev
  - **institution:** HSE University, Meshalkin National Medical Research Center, Tyumen Cardiology Research Center
  - **link:** https://arxiv.org/pdf/2512.22259
  - **contributions:** 1. Developed and evaluated machine learning models for predicting 3-year cardiac mortality after PCI using a dataset of patients with bifurcation lesions. 2. Demonstrated that augmenting the training set with synthetic samples effectively addresses class imbalance, improving minority-class recall and probability quality with minimal impact on AUROC. 3. Identified key clinical predictors (Age, Ejection Fraction, Peripheral Artery Disease, Cerebrovascular Disease) through feature importance analysis and highlighted the brittleness of models on external validation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8124ba060c0a4a10502266c7255b089103b4cb860b15006e80971c9e28cfdc68_w640_q70.webp
  - **Simple LLM Summary:** This study developed machine learning models to predict cardiac death within three years for patients undergoing percutaneous coronary intervention (PCI). To handle class imbalance, the authors augmented the real patient data with synthetic samples, which improved the models' ability to identify high-risk patients. The analysis identified key risk factors and demonstrated that data augmentation can reduce model brittleness in imbalanced clinical prediction tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cardiac mortality prediction in patients undergoing PCI based on real and synthetic data] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[预测PCI术后心脏死亡风险/Predict cardiac death risk post-PCI]
        B --> B2[类别不平衡问题/Class imbalance issue]
        C --> C1[应用多种机器学习模型/Apply multiple ML models]
        C --> C2[生成并添加合成数据/Generate & add synthetic data]
        C --> C3[使用排列特征重要性/Use permutation feature importance]
        D --> D1[合成数据提升少数类召回/Synthetic data improves minority-class recall]
        D --> D2[识别关键特征: 年龄, 射血分数等/Identify key features: Age, Ejection Fraction, etc.]
        D --> D3[外部验证性能下降/Performance drop on external validation]
    ```

- **[arXiv251230] The Physics Constraint Paradox: When Removing Explicit Constraints Improves Physics-Informed Data for Machine Learning**
  - **tags:** [ai], [physics-informed machine learning], [physics-constrained data generation, ablation study, grating coupler, Fabry-Perot oscillations, energy conservation]
  - **authors:** Rahul D Ray
  - **institution:** BITS Pilani, Hyderabad Campus
  - **link:** https://arxiv.org/pdf/2512.22261
  - **contributions:** 1. Identifies the "physics constraint paradox," demonstrating that explicit energy conservation enforcement can be mathematically redundant in physically consistent models. 2. Shows that removing Fabry-Perot oscillations significantly reduces bandwidth variability and improves downstream ML model accuracy for bandwidth prediction. 3. Reveals a subtle pitfall where standard noise-addition-and-renormalization pipelines can introduce unphysical negative absorption values.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c510a23d89c2ae438eca78e6b993f8ce6b30f94405a1290b3509d74226bafc1_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates physics-constrained data generation for machine learning through an ablation study of a grating coupler spectrum generator. It finds that explicitly enforcing certain physical constraints, like energy conservation, can be redundant, while others, like Fabry-Perot oscillations, can hinder machine learning performance for specific prediction tasks. The main conclusion is that increased physical realism in data generation does not always improve ML learnability, and ML performance can be used to diagnose the relevance of physical constraints.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["The Physics Constraint Paradox / 物理约束悖论"] --> Problem["核心问题/Problem: Physics-constrained data generation may over-constrain models. / 物理约束数据生成可能过度约束模型"]
        Root --> Method["主要方法/Method: Systematic ablation study of a physics-informed generator. / 对物理信息生成器进行系统消融研究"]
        Root --> Results["关键结果/Results: Explicit energy conservation is redundant; Removing Fabry-Perot oscillations improves ML learnability. / 显式能量守恒是冗余的；移除法布里-珀罗振荡可提升机器学习可学习性"]
    ```

- **[arXiv251230] LLMTM: Benchmarking and Optimizing LLMs for Temporal Motif Analysis in Dynamic Graphs**
  - **tags:** [ai], [graph representation learning], [temporal motifs, dynamic graphs, llm agent, structure-aware dispatcher, prompting techniques]
  - **authors:** Bing Hao, Minglai Shao, Zengyi Wo, Yunlong Chu, Yuhang Liu, Ruijie Wang
  - **institution:** Tianjin University, Beihang University, Guangxi Normal University
  - **link:** https://arxiv.org/pdf/2512.22266
  - **code:** https://github.com/Wjerry5/LLMTM
  - **contributions:** 1. Proposes LLMTM, a comprehensive benchmark for evaluating LLMs on six tasks across nine types of temporal motifs in dynamic graphs. 2. Develops a tool-augmented LLM agent that uses engineered prompts to achieve high accuracy on temporal motif analysis tasks. 3. Introduces a structure-aware dispatcher that intelligently routes queries between standard LLM prompting and the more powerful agent to balance accuracy and cost.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ebbb05fef920a296d5863029d0c69e932a75230132aa0658a09e6bd8d04010c_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the use of Large Language Models (LLMs) for analyzing temporal motifs in dynamic graphs, an area that is relatively unexplored. The authors propose a new benchmark (LLMTM), develop a high-accuracy but costly tool-augmented LLM agent, and then introduce a structure-aware dispatcher to reduce cost while maintaining performance. Their experiments show the dispatcher effectively maintains high accuracy while reducing cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LLMTM: Benchmarking and Optimizing LLMs for Temporal Motif Analysis] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLMs处理动态图时态模体分析能力未知/LLMs' capability for temporal motif analysis on dynamic graphs is unexplored]
        C --> C1[提出基准LLMTM与智能体/Propose benchmark LLMTM and an agent]
        C --> C2[提出结构感知调度器/Propose structure-aware dispatcher]
        D --> D1[调度器保持高精度并降低成本/Dispatcher maintains high accuracy while reducing cost]
    ```

- **[arXiv251230] Evaluating an Adaptive Multispectral Turret System for Autonomous Tracking Across Variable Illumination Conditions**
  - **tags:** [cv], [object detection], [RGB-LWIR fusion, multispectral imagery, YOLO, adaptive framework, illumination conditions]
  - **authors:** Aahan Sachdeva, Dhanvinkumar Ganeshkumar, James E. Gallagher, Tyler Treat, Edward J. Oughton
  - **institution:** George Mason University
  - **link:** https://arxiv.org/pdf/2512.22263
  - **contributions:** 1. An adaptive framework that dynamically selects the optimal RGB-LWIR fusion ratio and detection model based on real-time illumination conditions. 2. Creation of a comprehensive dataset and model set, training 33 YOLO models on over 22,000 annotated images across three light levels with eleven fusion ratios. 3. Demonstrated significant performance improvements over RGB-only and thermal-only baselines, particularly in full-light and dim-light conditions, enhancing detection reliability for autonomous systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9eac93c181b8ee533ee303243bd2258f5b332ba1744a5e93dc7fa00505d6c4e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of RGB and thermal-only object detection in variable lighting by proposing an adaptive framework that fuses RGB and LWIR video streams at multiple ratios and selects the best model for the current illumination. The method, evaluated on a large dataset, showed that optimized fusion models significantly outperformed baseline models in full and dim light, improving detection confidence and reliability for autonomous robotic vision.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Evaluating an Adaptive Multispectral Turret System] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[RGB在低光下表现差/RGB struggles in low-light]
        Problem --> P2[热成像缺乏颜色纹理/Thermal lacks color & texture]
        Method[主要方法/Method] --> M1[自适应RGB-LWIR融合框架/Adaptive RGB-LWIR fusion framework]
        Method --> M2[训练33个YOLO模型/Trained 33 YOLO models]
        Method --> M3[11种融合比例/11 fusion ratios]
        Results[关键结果/Results] --> R1[全光模型: 92.8%置信度/Full-light model: 92.8% confidence]
        Results --> R2[微光模型: 92.0%置信度/Dim-light model: 92.0% confidence]
        Results --> R3[无光模型: 71.0%置信度/No-light model: 71.0% confidence]
    ```

- **[arXiv251230] LuxIA: A Lightweight Unitary matriX-based Framework Built on an Iterative Algorithm for Photonic Neural Network Training**
  - **tags:** [mlsys], [on-device ai], [photonic neural networks, transfer matrix, Slicing method, back-propagation, simulation framework]
  - **authors:** Tzamn Melendez Carmona, Federico Marchesin, Marco P. Abrate, Peter Bienstman, Stefano Di Carlo, Alessandro Savino Senior
  - **institution:** Politecnico di Torino, Ghent University - imec, University College London
  - **link:** https://arxiv.org/pdf/2512.22264
  - **contributions:** 1. Proposes the Slicing method, an efficient transfer matrix computation approach compatible with back-propagation for training Photonic Neural Networks (PNNs). 2. Introduces LuxIA, a unified simulation and training framework that integrates the Slicing method to enable scalable PNN training. 3. Demonstrates through experiments that LuxIA surpasses existing tools in speed and scalability for training large-scale PNNs on standard datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/362a4190a58349fa96aae555a8a4643a7fdd50b962ff88817d9c12e4678fbe98_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the scalability challenges in simulating and training large-scale Photonic Neural Networks (PNNs) by introducing the Slicing method for efficient transfer matrix computation. The method is integrated into the LuxIA framework, which significantly reduces memory usage and training time. Experimental results show LuxIA outperforms existing tools, enabling the exploration of larger and more complex photonic architectures.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LuxIA: A Lightweight Unitary matriX-based Framework] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[当前PNN仿真工具可扩展性差<br>Current PNN simulation tools lack scalability]
        C --> C1[提出Slicing方法<br>Propose the Slicing method]
        C --> C2[构建LuxIA统一框架<br>Build the unified LuxIA framework]
        D --> D1[显著降低内存与时间消耗<br>Significantly reduces memory and time consumption]
        D --> D2[在速度与可扩展性上超越现有工具<br>Outperforms existing tools in speed and scalability]
    ```

- **[arXiv251230] Hierarchical Stacking Optimization Using Dirichlet's Process (SoDip): Towards Accelerated Design for Graft Polymerization**
  - **tags:** [ai], [bayesian optimization], [Dirichlet Process Mixture Model, Gaussian Process Regression, Transformer, TabNet, XGBoost]
  - **authors:** Amgad Ahmed Ali Ibrahim, Hein Htet, Ryoji Asahi
  - **institution:** Nagoya University
  - **link:** https://arxiv.org/pdf/2512.22279
  - **contributions:** 1. Proposed a hierarchical stacking optimization framework (SoDip) integrating a Transformer for text, TabNet/XGBoost for multimodal features, and GPR with DPMM for uncertainty. 2. Curated a diverse dataset for radiation-induced grafting using automated tools to handle numerical and textual variables. 3. Demonstrated ~33% performance improvement over standard GPR with calibrated confidence intervals for identifying low-reproducibility regimes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e1ff3feaf3b0e588ef295bb1595e516fbcdb32563ea40c93095217ac66e1fc5_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses reproducibility issues in radiation-induced graft polymerization by proposing SoDip, a hierarchical data-driven framework that combines Transformer encoders, multimodal feature models, and Bayesian optimization with uncertainty quantification. The method integrates sparse textual and numerical data, showing a 33% improvement over Gaussian Process Regression and providing reliable confidence estimates. This establishes a foundation for morphology-aware, reproducible design in polymer research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SoDip: Hierarchical Stacking Optimization] --> B(核心问题/Problem: Radiation-induced grafting reproducibility limited by unreported base-film morphology variability)
        A --> C(主要方法/Method: Hierarchical framework with Transformer (text), TabNet/XGBoost (features), GPR+DPMM (uncertainty), Bayesian Optimization)
        A --> D(关键结果/Results: ~33% improvement over GPR, calibrated confidence intervals, integrates sparse multimodal data)
    ```

- **[arXiv251230] Valori: A Deterministic Memory Substrate for AI Systems**
  - **tags:** [mlsys], [memory & caching], [deterministic memory, fixed-point arithmetic, vector embeddings, approximate nearest neighbor search, state machine]
  - **authors:** Varshith Gudur
  - **institution:** Independent Researcher (Valori Kernel Project)
  - **link:** https://arxiv.org/pdf/2512.22280
  - **code:** https://github.com/varshith-Git/Valori-Kernel
  - **contributions:** 1. Identifies and characterizes the fundamental non-determinism in AI memory systems caused by hardware-dependent floating-point arithmetic, which leads to divergent memory states and retrieval results. 2. Proposes Valori, a deterministic AI memory substrate that replaces floating-point operations with fixed-point arithmetic (Q16.16) and models memory as a replayable state machine. 3. Demonstrates that Valori guarantees bit-identical memory states, snapshots, and search results across different hardware platforms (e.g., x86 vs. ARM), establishing deterministic memory as a necessary primitive for trustworthy AI.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb7ed17a8a06e6a2b8760f08fa9345391995aee74a3542cacf55dd051b383f_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies non-determinism in AI memory systems due to hardware-dependent floating-point arithmetic, which compromises replayability and auditability. It proposes Valori, a memory substrate using fixed-point arithmetic and a state machine model to guarantee bit-identical behavior across platforms. The work concludes that deterministic memory is essential for building trustworthy AI systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Valori: A Deterministic Memory Substrate for AI Systems] --> B
        A --> C
        A --> D
        B[核心问题/Problem: AI内存非确定性/AI Memory Non-Determinism]
        C[主要方法/Method: 固定点算术与状态机/Fixed-Point Arithmetic & State Machine]
        D[关键结果/Results: 跨平台比特一致性/Cross-Platform Bit-Identical Results]
    ```

- **[arXiv251230] Cluster Aggregated GAN (CAG): A Cluster-Based Hybrid Model for Appliance Pattern Generation**
  - **tags:** [ai], [generative models], [Generative Adversarial Networks, Non-Intrusive Load Monitoring, Clustering, LSTM, Pattern Generation]
  - **authors:** Zikun Guoa, Adeyinka.P. Adedigbaa, Rammohan Mallipeddi
  - **institution:** Kyungpook National University
  - **link:** https://arxiv.org/pdf/2512.22287
  - **contributions:** 1. Proposes a hybrid GAN framework that routes appliances to specialized branches based on behavioral characteristics (intermittent vs. continuous). 2. Introduces a clustering module for intermittent appliances to group similar activation patterns and allocate dedicated generators, improving modeling of both common and rare modes. 3. Employs a separate LSTM-based generator branch for continuous appliances to capture gradual temporal evolution while maintaining training stability through sequence compression.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37f2c4c207022049ee869567d36df9e77e5a04d1beb0cc584dc57ee6ad1145b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes the Cluster Aggregated GAN (CAG), a hybrid generative model that synthesizes appliance load patterns by separating intermittent and continuous devices into specialized branches, using clustering for the former and an LSTM for the latter. Experiments on the UVIC dataset show it outperforms baselines in realism, diversity, and training stability. The integration of clustering as an active component also enhances the model's interpretability and scalability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Cluster Aggregated GAN (CAG)"] --> Problem["核心问题/Problem: 缺乏标记数据，现有GAN方法对所有设备一视同仁，忽略间歇性和持续性设备的行为差异，导致训练不稳定和保真度有限"]
        Root --> Method["主要方法/Method: 提出混合生成框架，根据设备行为特征路由到专门分支：间歇性设备使用聚类模块和专用生成器；持续性设备使用LSTM生成器"]
        Root --> Results["关键结果/Results: 在UVIC数据集上实验，在真实性、多样性和训练稳定性上优于基线方法，聚类作为主动生成组件提高了可解释性和可扩展性"]
    ```

- **[arXiv251230] When Algorithms Manage Humans: A Double Machine Learning Approach to Estimating Nonlinear Effects of Algorithmic Control on Gig Worker Performance and Wellbeing**
  - **tags:** [ai], [causal inference], [Double Machine Learning, Moderated Mediation, Algorithmic Control, Nonmonotonic Effects, Gig Economy]
  - **authors:** Arunkumar V, Nivethitha S, Sharan Srinivas, Gangadharan G.R
  - **institution:** Anna University, National Institute of Technology Tiruchirappalli, University of Missouri
  - **link:** https://arxiv.org/pdf/2512.22290
  - **contributions:** 1. Applied a Double Machine Learning framework to estimate a moderated mediation model without restrictive linear assumptions in organizational research. 2. Uncovered a nonmonotonic relationship between algorithmic oversight, worker wellbeing, and performance, highlighting a "murky middle" of confusing oversight. 3. Demonstrated that simple linear models can be misleading and provided practical insights for designing transparent and explainable algorithmic management systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ffeb8d364908888226033cff39cbb354772ae1044ba1a51632db140d81dca17_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the nonlinear effects of algorithmic control on gig workers. Using a Double Machine Learning approach on survey data, it finds that the link between supportive HR practices and worker performance weakens under opaque algorithmic oversight but strengthens again when the oversight is transparent and explainable.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["当算法管理人类: 估算算法控制对零工工人绩效和福祉非线性效应的双重机器学习方法 / When Algorithms Manage Humans: A Double Machine Learning Approach to Estimating Nonlinear Effects of Algorithmic Control on Gig Worker Performance and Wellbeing"]
        Root --> Problem["核心问题: 算法管理下，以人为本的管理能否持续？工人对算法的反应是非线性的 / Problem: Can person-centered management survive algorithmic management? Worker responses are nonlinear."]
        Root --> Method["主要方法: 使用双重机器学习框架估算有调节的中介模型，无严格函数形式限制 / Method: Double Machine Learning framework to estimate a moderated mediation model without restrictive functional forms."]
        Root --> Results["关键结果: 发现非单调模式。模糊的算法监督削弱绩效联系，透明可解释的监督则加强它 / Results: Found a nonmonotonic pattern. Murky oversight weakens the performance link, transparent and explainable oversight strengthens it."]
    ```

- **[arXiv251230] Co-GRPO: Co-Optimized Group Relative Policy Optimization for Masked Diffusion Model**
  - **tags:** [mlsys], [diffusion models], [Masked Diffusion Models, Markov Decision Process, Group Relative Policy Optimization, inference schedule optimization, trajectory-level training]
  - **authors:** Renping Zhou, Zanlin Ni, Tianyi Chen, Zeyu Liu, Yang Yue, Yulin Wang, Yuxuan Wang, Jingshu Liu, Gao Huang
  - **institution:** Tsinghua University (Leap Lab), Anyverse Dynamics
  - **link:** https://arxiv.org/pdf/2512.22288
  - **code:** https://co-grpo.github.io
  - **contributions:** 1. Identifies and addresses the discrepancy between the single-step training and multi-step inference of Masked Diffusion Models (MDMs). 2. Proposes Co-GRPO, a method that reformulates MDM generation as a unified Markov Decision Process to jointly optimize model parameters and inference schedule parameters. 3. Introduces a trajectory-level optimization using Group Relative Policy Optimization that avoids costly backpropagation through the multi-step generation process.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63c1159878e540d373846dba6e76fb918342cb837f6f15d4e79e21a40dad9e84_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the misalignment between the training and inference procedures of Masked Diffusion Models (MDMs). It proposes Co-GRPO, a method that jointly optimizes the MDM and its inference schedule as a unified Markov Decision Process using Group Relative Policy Optimization. The approach improves generation quality across multiple benchmarks without requiring expensive backpropagation through the full generation trajectory.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Co-GRPO: Co-Optimized Group Relative Policy Optimization for Masked Diffusion Model] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[训练与推理不匹配/Mismatch between Training & Inference]
        B1 --> B2[训练: 单步BERT式/Training: Single-step BERT-style]
        B1 --> B3[推理: 多步有调度/Inference: Multi-step with Schedule]
        C --> C1[统一MDP/Unified MDP]
        C1 --> C2[联合优化模型与调度/Jointly Optimize Model & Schedule]
        C2 --> C3[组相对策略优化/Group Relative Policy Optimization]
        D --> D1[提升生成质量/Improved Generation Quality]
        D1 --> D2[在四个基准上验证/Validated on Four Benchmarks]
    ```

- **[arXiv251230] DBAW-PIKAN: Dynamic Balance Adaptive Weight Kolmogorov-Arnold Neural Network for Solving Partial Differential Equations**
  - **tags:** [ai], [scientific machine learning], [Physics-informed neural networks, Kolmogorov-Arnold networks, Adaptive weighting, B-splines, Partial differential equations]
  - **authors:** Guokan Chen, Yao Xiao
  - **institution:** Fujian University of Technology
  - **link:** https://arxiv.org/pdf/2512.22283
  - **contributions:** 1. Proposes DBAW-PIKAN, a novel architecture combining a Kolmogorov-Arnold Network (KAN) with learnable B-splines for enhanced function representation in solving PDEs., 2. Introduces an adaptive weighting strategy with a dynamic decay upper bound to mitigate gradient flow stiffness and spectral bias, addressing key failure modes of PINNs., 3. Demonstrates significant improvements in convergence speed and solution accuracy (at least an order of magnitude) on benchmarks like Klein-Gordon, Burgers, and Helmholtz equations without added computational cost.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb9e65232c0c340c6072237e2ad1388255462aafca80cf91d4b7f3054eb9fe8c_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes DBAW-PIKAN, a novel neural network that integrates a Kolmogorov-Arnold architecture with an adaptive weighting strategy to overcome the stiffness and spectral bias challenges faced by Physics-Informed Neural Networks (PINNs) when solving multi-scale PDEs. The method accelerates convergence and improves solution accuracy by at least an order of magnitude on standard benchmarks without increasing computational complexity.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[DBAW-PIKAN: Dynamic Balance Adaptive Weight Kolmogorov-Arnold Neural Network for Solving Partial Differential Equations] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[PINNs struggle with multi-scale/high-frequency PDEs / PINNs在处理多尺度/高频PDE时遇到困难]
        P1 --> P2[Issues: Gradient flow stiffness & spectral bias / 问题: 梯度流刚度和谱偏差]
        Method[主要方法/Method] --> M1[Architecture: Kolmogorov-Arnold Network (KAN) with learnable B-splines / 架构: 基于可学习B样条的KAN]
        Method --> M2[Strategy: Adaptive weighting with dynamic decay upper bound / 策略: 带动态衰减上界的自适应加权]
        Results[关键结果/Results] --> R1[Faster convergence & higher accuracy / 更快的收敛和更高的精度]
        R1 --> R2[Improvement: At least one order of magnitude / 提升: 至少一个数量级]
        Results --> R3[Benchmarks: Klein-Gordon, Burgers, Helmholtz equations / 基准: Klein-Gordon, Burgers, Helmholtz方程]
    ```

- **[arXiv251230] Learning from Negative Examples: Why Warning-Framed Training Data Teaches What It Warns Against**
  - **tags:** [nlp], [language model safety], [sparse autoencoder, feature orthogonalization, stealth slip, pragmatic interpretation, statistical co-occurrence]
  - **authors:** Tsogt-Ochir Enkhbayar
  - **institution:** Mongol-AI (inferred from email domain)
  - **link:** https://arxiv.org/pdf/2512.22293
  - **contributions:** 1. Empirically demonstrates that warning-framed training data fails to teach language models to avoid warned-against behaviors, showing generation rates similar to direct exposure. 2. Provides a mechanistic interpretation using sparse autoencoders, identifying a failure of feature orthogonalization where "describing" and "performing" an action activate overlapping latent features. 3. Identifies and names the "stealth slip" phenomenon, where conversational preambles can rotate activations into subspaces undetectable by linear probes, and shows that training-time feature ablation, not prompting, is required to address the issue.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fddb803a434c3d49e04dd722184b33f238c4b81254540d6bb0d1961a3d09e1_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates why language models trained on warning-framed examples (e.g., "DO NOT USE") still learn to generate the warned-against content. Through behavioral experiments and sparse autoencoder analysis, it finds that models learn statistical co-occurrences rather than pragmatic intent, due to overlapping latent features for description and action. The core conclusion is that current architectures prioritize pattern completion over understanding speaker intent, requiring training-time interventions like feature ablation for correction.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Learning from Negative Examples: Why Warning-Framed Training Data Teaches What It Warns Against") --> Problem("核心问题/Problem: Do warning-framed examples teach models to avoid bad behavior?")
        Root --> Method("主要方法/Method: Behavioral analysis & Sparse Autoencoder mechanistic interpretability")
        Root --> Results("关键结果/Results: No. Models learn statistical co-occurrence, not pragmatic intent.")
    ```

- **[arXiv251230] Multi-Head Spectral-Adaptive Graph Anomaly Detection**
  - **tags:** [ai], [graph anomaly detection], [spectral graph neural network, hypernetwork, Chebyshev filter, teacher-student contrastive learning, Barlow Twins loss]
  - **authors:** Qingyue Cao, Bo Jin, Changwei Gong, Xin Tong, Wenzheng Li, Xiaodong Zhou
  - **institution:** People's Public Security University of China, Third Research Institute of the Ministry of Public Security, Shanghai Police College
  - **link:** https://arxiv.org/pdf/2512.22291
  - **contributions:** 1. Proposes a Multi-Head Spectral-Adaptive Graph Neural Network (MHSA-GNN) that uses a lightweight hypernetwork to dynamically generate instance-specific Chebyshev filter parameters based on a 'spectral fingerprint'. 2. Introduces a novel dual regularization strategy combining teacher-student contrastive learning (TSC) and Barlow Twins diversity loss (BTD) to prevent mode collapse and ensure representation accuracy and head orthogonality in the multi-head mechanism. 3. Demonstrates through extensive experiments that the method effectively preserves high-frequency anomaly signals and outperforms state-of-the-art methods, especially on highly heterogeneous datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9ad6dee88128393dc0036e3430c2763e19882412f9750f09622c52d9ae28dc6_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of graph anomaly detection where fixed filters in spectral GNNs cause over-smoothing and fail to adapt to varying graph structures. It proposes MHSA-GNN, which uses a hypernetwork to generate adaptive filters per instance and a dual regularization strategy to stabilize multi-head learning. Experiments show the method preserves critical high-frequency signals and achieves superior performance, particularly on heterogeneous graphs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multi-Head Spectral-Adaptive Graph Anomaly Detection] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[固定滤波器导致过平滑与缺乏适应性/Fixed filters cause over-smoothing & lack adaptability]
        C --> C1[基于谱指纹的轻量级超网络/Lightweight hypernetwork based on spectral fingerprint]
        C --> C2[动态生成切比雪夫滤波器参数/Dynamically generates Chebyshev filter parameters]
        C --> C3[双正则化策略防止模式崩溃/Dual regularization prevents mode collapse]
        D --> D1[有效保留高频异常信号/Effectively preserves high-frequency anomaly signals]
        D --> D2[在异构数据集上性能优越/Outperforms SOTA on heterogeneous datasets]
    ```

- **[arXiv251230] Hybrid Quantum-Classical Mixture of Experts: Unlocking Topological Advantage via Interference-Based Routing**
  - **tags:** [mlsys], [federated learning], [Quantum Machine Learning, Mixture-of-Experts, Parameterized Quantum Circuits, Quantum Router, Interference Hypothesis]
  - **authors:** Reda Heddad, Lamiae Bouanane
  - **institution:** Al Akhawayn University
  - **link:** https://arxiv.org/pdf/2512.22296
  - **contributions:** 1. Design of a Hybrid Quantum-Classical Mixture of Experts (QMoE) architecture with a Quantum Router for an ablation study to isolate the source of quantum advantage. 2. Validation of the Interference Hypothesis, demonstrating the Quantum Router's topological advantage and superior parameter efficiency on non-linearly separable data. 3. Empirical analysis of the architecture's robustness against quantum noise, confirming its feasibility for near-term (NISQ) hardware.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/407a17903b2360f889e7afbc3b5f776273cc33f5cf3daf0fa26caf69bc1ed179_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a Hybrid Quantum-Classical Mixture of Experts (QMoE) architecture that uses a Quantum Router to address limitations like expert imbalance in classical MoE systems. The core finding is that the Quantum Router, leveraging quantum interference, provides a topological advantage for routing complex data more efficiently than classical routers. The method is shown to be robust to noise and feasible for near-term quantum hardware.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Hybrid Quantum-Classical Mixture of Experts") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("MoE挑战:专家不平衡,路由复杂/MoE Challenges: Expert Imbalance, Routing Complexity")
        Method --> M1("混合量子-经典架构/Hybrid Quantum-Classical Architecture")
        Method --> M2("量子路由网络/Quantum Router")
        Method --> M3("利用量子干涉/Utilizes Quantum Interference")
        Results --> R1("验证干涉假说/Validates Interference Hypothesis")
        Results --> R2("拓扑优势,高效解耦数据/Topological Advantage, Efficiently Untangles Data")
        Results --> R3("NISQ硬件可行/Feasible for NISQ Hardware")
    ```

- **[arXiv251230] Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware**
  - **tags:** [cv], [human activity recognition], [driver monitoring systems, edge AI, quantization, temporal decision head, confounder-aware labeling]
  - **authors:** Vesal Ahsani, Babak Hossein Khalaj
  - **institution:** Sharif University of Technology
  - **link:** https://arxiv.org/pdf/2512.22298
  - **contributions:** 1. A deployable single-camera driver behavior recognition pipeline optimized for low-cost edge hardware (Raspberry Pi 5 and Google Coral Edge TPU). 2. A confounder-aware label design to reduce false positives from visually similar actions. 3. A temporal decision head that generates stable alerts based on sustained, confident predictions rather than noisy per-frame outputs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bd52e06dc77080ab346fc3d6fe46b900bf06b5c1eaeb6ae89801ac125ee7c51_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a real-time driver behavior recognition system designed for low-cost edge hardware to address the challenges of compute, power, and cost constraints in vehicles. The method combines a compact vision model, confounder-aware labeling, and a temporal decision head to recognize 17 distraction and drowsiness-related behaviors. The optimized system achieves 16 FPS on a Raspberry Pi 5 and 25 FPS on a Coral Edge TPU, enabling practical deployment for in-cabin monitoring.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[实时DMS需求 / Real-time DMS needs low latency, low cost, low power]
        C --> C1[紧凑单摄像头系统 / Compact single-camera pipeline]
        C1 --> C2[紧凑视觉模型 / Compact per-frame vision model]
        C1 --> C3[抗混淆标签设计 / Confounder-aware label design]
        C1 --> C4[时序决策头 / Temporal decision head]
        D --> D1[性能: 16 FPS (RPi5), 25 FPS (Edge TPU) / Performance: 16 FPS (RPi5), 25 FPS (Edge TPU)]
        D --> D2[验证: 真实车辆测试 / Validation: Real in-vehicle tests]
    ```

- **[arXiv251230] Statistical and Machine Learning Analysis of Traffic Accidents on US 158 in Currituck County: A Comparison with HSM Predictions**
  - **tags:** [other], [transportation safety analytics], [Random Forest, Kernel Density Estimation (KDE), Moran's I, Highway Safety Manual (HSM), Negative Binomial Regression]
  - **authors:** Jennifer Sawyer, Julian Allagan
  - **institution:** Elizabeth City State University
  - **link:** https://arxiv.org/pdf/2512.22302
  - **contributions:** 1. Applied and compared advanced statistical and machine learning methods (Random Forest, KDE, Negative Binomial Regression) to rural highway crash data, demonstrating a methodological advancement beyond basic techniques. 2. Validated spatial clustering of accidents using Moran's I test and identified specific crash hotspots via KDE, extending previous hotspot analysis. 3. Showed that a Random Forest classifier for injury severity prediction outperformed the standard Highway Safety Manual (HSM) Safety Performance Function (SPF) model.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87320e45eec3961a5ef58f2548cb06120fd2e4baee855440998207874d568dbe_w640_q70.webp
  - **Simple LLM Summary:** This study analyzes traffic accident data from a rural highway using advanced statistical and machine learning techniques, including Random Forest and spatial analysis. The proposed Random Forest model for predicting injury severity achieved 67% accuracy, outperforming the standard HSM model, and spatial analysis confirmed crash clustering near intersections. The results provide actionable insights for targeted safety interventions on US 158.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Statistical and Machine Learning Analysis of Traffic Accidents on US 158") --> Problem("核心问题/Problem: Rural highway traffic safety analysis")
        Root --> Method("主要方法/Method: KDE, Random Forest, Moran's I, HSM SPF comparison")
        Root --> Results("关键结果/Results: RF outperforms HSM, hotspots identified, clustering confirmed")
    ```

- **[arXiv251230] PDx -- Adaptive Credit Risk Forecasting Model in Digital Lending using Machine Learning Operations**
  - **tags:** [mlsys], [others], [MLOps, champion-challenger framework, out-of-time validation, probability of default, data drift]
  - **authors:** Sultan Amed, Chan Yu Hang, Sayantan Banerjee
  - **institution:** Indian Institute of Management Indore, National University of Singapore
  - **link:** https://arxiv.org/pdf/2512.22305
  - **contributions:** 1. Proposes PDx, an adaptive, MLOps-driven decision system for end-to-end lifecycle management of credit risk models. 2. Introduces a dynamic champion-challenger framework with regular model updates and out-of-time validation to combat data drift. 3. Empirically demonstrates that decision tree-based ensemble models perform best for default classification but require frequent retraining, and validates PDx's effectiveness across multiple lending datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c779eabc4c2fa3f75801b8b61c3eed3c105bd748ce6aa84ff37317acd929db3a_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes PDx, an adaptive credit risk forecasting system that uses an MLOps pipeline and a champion-challenger framework to continuously monitor, retrain, and validate models against data drift. The study finds decision tree ensembles are most effective but degrade without updates, and shows PDx mitigates value erosion in digital lending, especially for short-term loans.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[PDx - Adaptive Credit Risk Forecasting Model / PDx - 自适应信用风险预测模型] --> B[Problem: Static PD models degrade, hard to deploy & maintain / 问题: 静态PD模型性能下降，难以部署维护]
        A --> C[Method: MLOps pipeline with dynamic champion-challenger framework / 方法: 采用动态冠军-挑战者框架的MLOps流程]
        A --> D[Results: Decision tree ensembles best, PDx mitigates value erosion / 结果: 决策树集成效果最佳，PDx减少价值侵蚀]
    ```

- **[arXiv251230] LLMBoost: Make Large Language Models Stronger with Boosting**
  - **tags:** [mlsys], [llm inference], [ensemble learning, boosting, cross-model attention, chain training, near-parallel inference]
  - **authors:** Zehao Chen, Tianxiang Ai, Yifei Li, Gongxun Li, Yuyang Wei, Wang Zhou, Guanghui Li, Bin Yu, Zhijun Chen, Hailong Sun, Fuzhen Zhuang, Jianxin Li, Deqing Wang, Yikun Ban
  - **institution:** Beihang University, China Telecom eSurfing Cloud
  - **link:** https://arxiv.org/pdf/2512.22309
  - **contributions:** 1. A cross-model attention mechanism that allows successor models to access and fuse hidden states from predecessors for hierarchical error correction and knowledge transfer. 2. A chain training paradigm that progressively fine-tunes connected models with an error-suppression objective to rectify predecessor mispredictions efficiently. 3. A near-parallel inference paradigm that pipelines hidden states across models layer by layer, achieving inference efficiency close to single-model decoding.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb6a601c8d3bba7ec992d00772421c31e3e03d00d8a89a06f09ad3fe3c1b6ce1_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes LLMBoost, a novel ensemble fine-tuning framework for LLMs that leverages intermediate hidden states across models. Inspired by boosting, it introduces cross-model attention, chain training, and a near-parallel inference pipeline to improve accuracy and reduce latency. Experiments on reasoning tasks show it consistently boosts performance while maintaining efficient inference.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LLMBoost: Make Large Language Models Stronger with Boosting] --> B[核心问题/Problem: Existing LLM ensemble methods treat models as black boxes, ignoring internal representations.]
        A --> C[主要方法/Method: A boosting-inspired framework with cross-model attention, chain training, and near-parallel inference.]
        A --> D[关键结果/Results: Consistently boosts accuracy and reduces inference latency on reasoning tasks.]
    ```

- **[arXiv251230] LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators**
  - **tags:** [sec], [hardware security, model protection], [logic locking, intellectual property protection, hardware accelerator, model theft, supply chain security]
  - **authors:** You Li, Guannan Zhao, Yuhao Ju, Yunqi He, Jie Gu, Hai Zhou
  - **institution:** Northwestern University
  - **link:** https://arxiv.org/pdf/2512.22307
  - **contributions:** 1. Proposes LLA, a hardware-software co-design scheme for protecting generative AI models by embedding key bits into neurons and using invariance transformations to obscure them. 2. Integrates a lightweight, dataflow-compatible locking module into the AI accelerator, using the accelerator with a secret key as a license for model access. 3. Demonstrates that the approach is resilient against oracle-guided key optimization attacks while adding minimal computational overhead (&lt;0.1% for 7,168 key bits).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces LLA, a method to protect generative AI models from supply chain threats like theft and corruption by combining software-based key embedding in neurons with a hardware locking module in the accelerator. This approach uses the accelerator as a license key, ensuring only authorized hardware can run the model correctly. Evaluation shows it effectively resists attacks with negligible performance overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators] --> Problem(核心问题/Problem: Model IP Protection & Supply Chain Threats)
        Root --> Method(主要方法/Method: Hardware-Software Co-design with Logic Locking)
        Root --> Results(关键结果/Results: Resists Attacks, <0.1% Overhead)
        Problem --> P1(模型盗窃/Model Theft)
        Problem --> P2(模型破坏/Model Corruption)
        Problem --> P3(信息泄露/Information Leakage)
        Method --> M1(软件侧: 神经元嵌入密钥/Software: Key Embedding in Neurons)
        Method --> M2(硬件侧: 轻量级锁定模块/Hardware: Lightweight Locking Module)
        Results --> R1(抵御优化攻击/Withstands Oracle-Guided Attacks)
        Results --> R2(低计算开销/Low Computational Overhead)
    ```

- **[arXiv251230] Optimistic Feasible Search for Closed-Loop Fair Threshold Decision-Making**
  - **tags:** [ai], [reinforcement learning], [optimistic feasible search, closed-loop decision-making, demographic parity, bandit feedback, threshold policy]
  - **authors:** Wenzhang Du
  - **institution:** Mahanakorn University of Technology, International College (MUTIC)
  - **link:** https://arxiv.org/pdf/2512.22313
  - **contributions:** 1. Proposed Optimistic Feasible Search (OFS), a simple grid-based method for constrained closed-loop threshold learning using optimism under uncertainty. 2. Introduced synthetic and semi-synthetic closed-loop benchmarks with stable contraction dynamics and real-world datasets (German Credit, COMPAS) to evaluate feedback effects. 3. Demonstrated that OFS achieves near-oracle performance with higher reward and lower cumulative constraint violation compared to unconstrained and primal-dual bandit baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/baad942bfd56e4e5f21dcd74fbfaad4a484372898d0862f9bc3c15ebb2b11958_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses online learning of a threshold policy under fairness and service constraints in closed-loop decision systems with bandit feedback. It proposes Optimistic Feasible Search (OFS), which selects thresholds based on optimistic confidence bounds to maximize reward while minimizing constraint violations. Experiments show OFS outperforms baselines and achieves near-oracle performance across synthetic and real-world benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Optimistic Feasible Search for Closed-Loop Fair Threshold Decision-Making] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[Closed-loop decision-making with fairness constraints and feedback effects]
    C --> C1[Optimistic Feasible Search (OFS) using confidence bounds on a grid of thresholds]
    D --> D1[Higher reward, lower constraint violation, near-oracle performance]
    ```

- **[arXiv251230] LangPrecip: Language-Aware Multimodal Precipitation Nowcasting**
  - **tags:** [cv], [weather forecasting], [multimodal nowcasting, rectified flow, semantic motion constraint, latent space integration, large-scale dataset]
  - **authors:** Xudong Ling, Tianxi Huang, Qian Dong, Tao He, Chaorong Li, Guiduo Duan
  - **institution:** University of Electronic Science and Technology of China (UESTC), Chengdu Textile College, Yibin University
  - **link:** https://arxiv.org/pdf/2512.22317
  - **contributions:** 1. Proposed LangPrecip, a language-aware multimodal nowcasting framework that uses meteorological text as a semantic motion constraint to guide precipitation evolution. 2. Introduced LangPrecip-160k, a large-scale multimodal dataset with 160k paired radar sequences and motion descriptions. 3. Formulated nowcasting as a semantically constrained trajectory generation problem under the Rectified Flow paradigm for efficient and physically consistent multimodal integration.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff97192e450e6a7b03dee1e2aabdfe42754a4d8248f0398395932ec97689a42d_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes LangPrecip, a novel framework that integrates meteorological text descriptions with radar data to constrain precipitation nowcasting. By formulating the problem as semantically constrained trajectory generation using Rectified Flow, it achieves significant performance gains, especially for heavy rainfall at long lead times, as demonstrated on Swedish and MRMS datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[LangPrecip: Language-Aware Multimodal Precipitation Nowcasting] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: 短期降水临近预报存在不确定性，现有方法依赖视觉条件，未来运动约束弱]
        Method[主要方法/Method: 提出语言感知多模态框架，将气象文本作为语义运动约束，在Rectified Flow范式下进行潜空间集成]
        Results[关键结果/Results: 在瑞典和MRMS数据集上超越SOTA，在80分钟预见期，强降水CSI提升超60%和19%]
    ```

- **[arXiv251230] Decomposing Uncertainty in Probabilistic Knowledge Graph Embeddings: Why Entity Variance Is Not Enough**
  - **tags:** [ai], [knowledge graph embeddings], [probabilistic embeddings, uncertainty quantification, out-of-distribution detection, semantic uncertainty, structural uncertainty]
  - **authors:** Chorok Lee
  - **institution:** Korea Advanced Institute of Science and Technology (KAIST)
  - **link:** https://arxiv.org/pdf/2512.22318
  - **contributions:** 1. Identifies and formalizes the fundamental limitation of relation-agnostic uncertainty in probabilistic KG embeddings, proving an impossibility result for detecting novel relational contexts using only entity-level statistics. 2. Proposes a novel decomposition of uncertainty into complementary semantic (entity variance) and structural (entity-relation co-occurrence) components, proving their non-redundancy and the superiority of their combination. 3. Introduces the CAGP method that combines semantic and structural uncertainty with learned weights, achieving significant improvements (60-80% relative gain) in temporal OOD detection and selective prediction performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5efb28f1949226a86993ed6d92d592762282d32746964ad0c85ab5a6de90ee36_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that probabilistic knowledge graph embeddings use relation-agnostic entity variances, which conflates two distinct types of out-of-distribution data: emerging entities and novel relational contexts. To address this, the authors propose decomposing uncertainty into semantic and structural components and introduce the CAGP method to combine them. This approach achieves a 60-80% relative improvement in temporal OOD detection performance over existing baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Decomposing Uncertainty in Probabilistic KG Embeddings] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Relation-agnostic entity variance fails to detect novel relational contexts]
        C[主要方法/Method: Decompose uncertainty into semantic (entity variance) and structural (entity-relation co-occurrence) components]
        D[关键结果/Results: CAGP method achieves 60-80% relative improvement in OOD detection]
    ```

- **[arXiv251230] SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents**
  - **tags:** [mlsys], [agent system], [self-verifying agent, proactive evidence seeking, LLM-as-a-Judge, 3C Principles, agentic reinforcement learning]
  - **authors:** Shaofei Cai, Yulei Qin, Haojia Lin, Zihan Xu, Gang Li, Yuchen Shi, Zongyi Li, Yong Mao, Siqi Cai, Xiaoyu Tan, Yitao Liang, Ke Li, Xing Sun
  - **institution:** Peking University, Tencent
  - **link:** https://arxiv.org/pdf/2512.22322
  - **code:** https://huggingface.co/collections/yolay/smartsnap
  - **contributions:** 1. Proposed SmartSnap, a paradigm shift from passive, post-hoc task verification to proactive, in-situ self-verification by the agent itself. 2. Introduced the Self-Verifying Agent, a new agent type with dual missions to complete tasks and prove accomplishment via curated snapshot evidences guided by 3C Principles (Completeness, Conciseness, Creativity). 3. Demonstrated that the SmartSnap paradigm enables scalable training of LLM-driven agents, achieving significant performance gains (up to 26.08% and 16.66%) on mobile tasks and competitive results against larger models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the scalability bottleneck in agentic RL caused by costly and unreliable post-hoc task verification. It proposes SmartSnap, a paradigm where agents proactively seek minimal, decisive snapshot evidence to prove task completion during execution, guided by 3C Principles. Experiments show this approach significantly improves agent performance and enables scalable training, achieving competitive results with much larger models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Passive, post-hoc verification is costly and unreliable for agentic RL]
        C[主要方法/Method: Proactive self-verification via Self-Verifying Agent and 3C Principles]
        D[关键结果/Results: Performance gains up to 26.08%; competitive with larger models]
    ```

- **[arXiv251230] Expert System for Bitcoin Forecasting: Integrating Global Liquidity via TimeXer Transformers**
  - **tags:** [ai], [time series forecasting], [TimeXer, Global M2 Liquidity, exogenous variable, long-horizon forecasting]
  - **authors:** Sravan Karthick T
  - **institution:** RV College of Engineering (RVCE), Bengaluru, India
  - **link:** https://arxiv.org/pdf/2512.22326
  - **contributions:** 1. Introduces the integration of Global M2 Liquidity as a leading exogenous variable with a 12-week lag for Bitcoin price forecasting. 2. Proposes a liquidity-conditioned forecasting model (TimeXer-Exog) based on the TimeXer architecture. 3. Demonstrates that explicit macroeconomic conditioning significantly stabilizes and improves long-horizon forecasts, outperforming a univariate baseline by over 89% at a 70-day horizon.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38de8480bbb274bd2bcfff3317dfee4cd7813e42e3af4cc61efcd6d928a0ae36_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of long-horizon Bitcoin price forecasting by proposing a model that integrates Global M2 Liquidity as an exogenous variable into the TimeXer transformer architecture. The proposed TimeXer-Exog model significantly outperforms univariate benchmarks, showing that conditioning on global macroeconomic factors substantially improves forecast stability and accuracy over long horizons.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Expert System for Bitcoin Forecasting: Integrating Global Liquidity via TimeXer Transformers] --> B(核心问题/Problem: Bitcoin价格长期预测的极端波动性和非平稳性/Bitcoin's extreme volatility & non-stationarity for long-horizon forecasting)
        A --> C(主要方法/Method: 集成全球M2流动性作为外生变量，使用TimeXer架构/Integrate Global M2 Liquidity as exogenous variable using TimeXer architecture)
        A --> D(关键结果/Results: 在70天预测范围内，MSE降低超过89%/At 70-day horizon, MSE reduced by over 89%)
    ```

- **[arXiv251230] Emotion classification using EEG headset signals and Random Forest**
  - **tags:** [ai], [affective computing], [EEG, Random Forest, emotion classification, brain-computer interface, real-time prediction]
  - **authors:** Ricardo Vasquez, Diego Riofrío-Luzcando, Joe Carrion-Jumbo, Cesar Guevara
  - **institution:** Universidad Internacional SEK, Universidad Indoamérica, The Institute of Mathematical Sciences (ICMAT-CSIC)
  - **link:** https://arxiv.org/pdf/2512.22333
  - **contributions:** 1. Developed a model for classifying human emotions (happiness, sadness, relaxation) using EEG signals from a consumer-grade headset (EMOTIV EPOC). 2. Applied the Random Forest algorithm to achieve high accuracy, particularly for happiness (97.21%). 3. Implemented a real-time emotion prediction system that captures EEG signals, processes them, and visually displays the predicted emotion.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e19385b22eca0965c66f7006e387468776c757a86a9b784693bc7b77b3c7533_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a system to classify human emotions (happiness, sadness, relaxation) from EEG signals using a Random Forest model. The model was trained on data from 50 participants and achieved high accuracy, especially for happiness. The work was extended to create a real-time prediction algorithm that outputs the result with representative images.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Emotion classification using EEG headset signals and Random Forest] --> B(核心问题/Problem: 如何从EEG信号中检测和分类情绪？/How to detect and classify emotions from EEG signals?)
        A --> C(主要方法/Method: 使用EMOTIV EPOC采集EEG数据，并应用随机森林模型进行分类/Use EMOTIV EPOC to collect EEG data and apply Random Forest model for classification)
        A --> D(关键结果/Results: 快乐分类准确率97.21%，实现实时情绪预测算法/Happiness classification accuracy 97.21%, implemented a real-time emotion prediction algorithm)
    ```

- **[arXiv251230] The Effectiveness of Approximate Regularized Replay for Efficient Supervised Fine-Tuning of Large Language Models**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [LoRA, catastrophic forgetting, KL divergence, instruction-tuning, parameter-efficient fine-tuning]
  - **authors:** Matthew Riemer, Erik Miehling, Miao Liu, Djallel Bouneffouf, Murray Campbell
  - **institution:** IBM Research, Mila, Université de Montréal
  - **link:** https://arxiv.org/pdf/2512.22337
  - **contributions:** 1. Demonstrates that catastrophic forgetting is a severe problem even during parameter-efficient fine-tuning (LoRA) of LLMs on small datasets. 2. Proposes a simple, low-overhead regularized approximate replay method that penalizes KL divergence from the initial model and interleaves next-token prediction data. 3. Shows that this method effectively preserves the model's general knowledge while maintaining plasticity for new tasks, applied to Qwen models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2e24fadff03a1d6696f3147893642a90d9f500d5c68233669842e5792db7332_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies that catastrophic forgetting is a major issue during LoRA-based supervised fine-tuning of large language models, even with small datasets. To solve this, the authors propose a regularized approximate replay method that uses KL divergence regularization and interleaves general pre-training-like data. Their approach successfully preserves the model's original capabilities while allowing adaptation to new instructions, with minimal computational overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["论文标题: The Effectiveness of Approximate Regularized Replay for Efficient Supervised Fine-Tuning of Large Language Models"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem: LoRA微调导致灾难性遗忘/Catastrophic forgetting in LoRA fine-tuning"]
        Method["主要方法/Method: 正则化近似回放/Regularized Approximate Replay (KL惩罚+交错数据/KL penalty + interleaved data)"]
        Results["关键结果/Results: 保留通用知识，维持可塑性/Preserves general knowledge without hindering plasticity"]
    ```

- **[arXiv251230] Human-like visual computing advances explainability and few-shot learning in deep neural networks for complex physiological data**
  - **tags:** [cv], [medical image analysis], [pseudo-colouring, few-shot learning, prototypical networks, ResNet-18, explainability]
  - **authors:** Alaa Alahmadi, Mohamed Hasan
  - **institution:** Newcastle University, University of Leeds
  - **link:** https://arxiv.org/pdf/2512.22349
  - **contributions:** 1. Introduces a perception-informed pseudo-colouring technique to encode clinically salient temporal ECG features (like QT-interval) into structured colour representations. 2. Demonstrates that this technique enables effective few-shot and one-shot learning for a complex physiological data task (drug-induced LQTS) using prototypical networks and ResNet-18. 3. Shows that the method improves model explainability by guiding attention to clinically meaningful features and that aggregating multiple cardiac cycles (mirroring human perceptual averaging) further boosts performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4573948678ad6f25faec7ec6be8baccee385ce760fef63e3980935e84e21be0_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problems of data inefficiency and poor interpretability in deep learning models for physiological signal analysis. It proposes a human-inspired pseudo-colouring technique to encode ECG features, enabling effective few-shot learning and improving model explainability by focusing on clinically relevant signal components. The results demonstrate that incorporating human-like perceptual encoding can bridge data efficiency and interpretability in medical AI.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Human-like visual computing advances explainability and few-shot learning in deep neural networks for complex physiological data] --> B1
        A --> B2
        A --> B3
        B1[核心问题/Problem] --> C1[数据效率低/Lack of data efficiency]
        B1 --> C2[可解释性差/Limited explainability]
        B1 --> C3[临床可靠性受限/Constrained clinical reliability]
        B2[主要方法/Method] --> D1[感知启发的伪着色技术/Perception-informed pseudo-colouring]
        D1 --> E1[编码临床特征/Encode clinical features (e.g., QT-interval)]
        D1 --> E2[结构化颜色表示/Structured colour representations]
        B2 --> D2[原型网络与ResNet-18/Prototypical networks & ResNet-18]
        B2 --> D3[聚合多个心跳周期/Aggregate multiple cardiac cycles]
        B3[关键结果/Results] --> F1[实现少样本与单样本学习/Achieve few-shot & one-shot learning]
        B3 --> F2[提升可解释性/Improve explainability (guide attention)]
        B3 --> F3[桥接数据效率与因果推理/Bridge data efficiency & causal reasoning]
    ```

- **[arXiv251230] PHANTOM: Physics-Aware Adversarial Attacks against Federated Learning-Coordinated EV Charging Management System**
  - **tags:** [sec], [Cyber-Physical Systems Security], [False Data Injection (FDI), Physics-Informed Neural Network (PINN), Multi-Agent Reinforcement Learning (MARL)]
  - **authors:** Mohammad Zakaria Haider, Amit Kumar Podder, Prabin Mali, Aranya Chakrabortty, Sumit Paudyal, Mohammad Ashiqur Rahman
  - **institution:** Florida International University, North Carolina State University
  - **link:** https://arxiv.org/pdf/2512.22381
  - **contributions:** 1. Proposes PHANTOM, a physics-aware adversarial attack framework that integrates a federated learning-enabled PINN as a digital twin for accurate modeling of EV charging systems. 2. Develops a multi-agent RL environment using DQN and SAC to generate stealthy FDI attack strategies that bypass conventional detection. 3. Constructs a T&D co-simulation platform to demonstrate the cascading, cross-boundary grid impacts (e.g., load imbalance, voltage instability) of the learned attacks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc4a49b77c0e517eadb20d321d77564888677d1f33b27adf452e13f7c0ffcb8c_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes PHANTOM, a physics-aware adversarial attack framework against federated learning-coordinated EV charging management. It uses a PINN-based digital twin and multi-agent RL to generate stealthy false data injection attacks, which are shown through co-simulation to cause significant grid instability, highlighting the need for physics-aware cybersecurity in vehicle-grid integration.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[PHANTOM: Physics-Aware Adversarial Attacks] --> B(核心问题/Problem: EV Charging Grid Security)
        A --> C(主要方法/Method: PINN Digital Twin + Multi-Agent RL)
        A --> D(关键结果/Results: Stealthy Attacks Cause Grid Instability)
    ```

- **[arXiv251230] Self-Evaluation Unlocks Any-Step Text-to-Image Generation**
  - **tags:** [mlsys], [diffusion models], [text-to-image generation, flow matching, self-evaluation, any-step inference, from-scratch training]
  - **authors:** Xin Yu, Xiaojuan Qi, Zhengqi Li, Kai Zhang, Richard Zhang, Zhe Lin, Eli Shechtman, Tianyu Wang, Yotam Nitzan
  - **institution:** The University of Hong Kong, Adobe Research
  - **link:** https://arxiv.org/pdf/2512.22374
  - **contributions:** 1. Introduces the Self-Evaluating Model (Self-E), a novel from-scratch training framework that combines local flow matching with a self-evaluation mechanism, eliminating the need for a pretrained teacher model. 2. Enables "any-step" inference, allowing the same model to perform both high-quality few-step and many-step generation, bridging the gap between local supervision and global matching paradigms. 3. Demonstrates competitive performance with state-of-the-art flow matching models at high step counts while excelling at very low step counts, offering a unified and scalable solution.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8074c4ce26dcd6ff20416ce7ac5c3c013208374f66871d4f0a55abd9bb7e52e9_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem that traditional diffusion/flow models require many inference steps, and distillation methods need a pretrained teacher. It proposes Self-E, a model trained from scratch that uses self-evaluation as a dynamic teacher to enable high-quality generation at any number of steps. The results show Self-E excels at few-step generation and is competitive at many steps, providing a unified framework for efficient and scalable text-to-image synthesis.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Self-Evaluation Unlocks Any-Step Text-to-Image Generation] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Traditional models need many steps or a teacher model] --> Problem_Sub1[传统模型需要多步或教师模型/Traditional models need many steps or a teacher]
        Method[主要方法/Method: Self-Evaluating Model (Self-E)] --> Method_Sub1[结合流匹配与自评估/Combines Flow Matching & Self-Evaluation]
        Results[关键结果/Results: Unified any-step model] --> Results_Sub1[少步与多步均表现优异/Excels at both few-step and many-step]
    ```

- **[arXiv251230] Completed Hyperparameter Transfer across Modules, Width, Depth, Batch and Duration**
  - **tags:** [mlsys], [llm training], [hyperparameter transfer, Complete(d)P parameterisation, per-module hyperparameter optimisation, scaling laws, evolutionary strategy]
  - **authors:** Bruno Mlodozeniec, Pierre Ablin, Louis Béthune, Dan Busbridge, Michal Klein, Jason Ramapuram, Marco Cuturi
  - **institution:** Apple, University of Cambridge
  - **link:** https://arxiv.org/pdf/2512.22382
  - **contributions:** 1. Proposes the Complete(d)P parameterisation, a unified framework for scaling hyperparameters across model width, depth, batch size, and training duration. 2. Investigates and enables the transfer of per-module hyperparameters (e.g., learning rates, weight decay) across model scales, moving beyond global hyperparameter transfer. 3. Provides practical guidelines for navigating the high-dimensional per-module hyperparameter optimization landscape and demonstrates significant training speed improvements in Large Language Models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06e0593eb453191fce60eeebdd4eb6147ab462084db9eb8d81ea8e2486d468be_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of hyperparameter transfer across different model scales and configurations. It introduces the Complete(d)P parameterisation to unify scaling across width, depth, batch size, and duration, and demonstrates that with this method, even granular per-module hyperparameters can be optimized on a small model and successfully transferred to much larger models, leading to faster training and improved performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Completed Hyperparameter Transfer<br/>超参数迁移研究] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Hyperparameter tuning is critical for large models<br/>大模型超参数调优至关重要]
        B --> B2[Transferring optimal HPs across scales is challenging<br/>跨规模最优超参数迁移困难]
        C --> C1[Propose Complete(d)P parameterisation<br/>提出Complete(d)P参数化方法]
        C --> C2[Enable per-module HP optimisation & transfer<br/>实现模块级超参数优化与迁移]
        D --> D1[Direct HP transfer to ~600x larger scale<br/>超参数可直接迁移至约600倍规模]
        D --> D2[Per-module HPs yield training speedup<br/>模块级超参数带来训练加速]
    ```

- **[arXiv251230] BLISS: Bandit Layer Importance Sampling Strategy for Efficient Training of Graph Neural Networks**
  - **tags:** [mlsys], [others], [Graph Neural Networks, Multi-armed Bandits, Layer-wise Sampling, Node Importance, Efficient Training]
  - **authors:** Omar Alsaqa, Linh Thi Hoang, Muhammed Fatih Balin
  - **institution:** Wilfrid Laurier University, Singapore Management University, Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.22388
  - **contributions:** 1. Introduces BLISS, a novel adaptive sampling strategy using multi-armed bandits to dynamically select informative nodes at each GNN layer. 2. Balances exploration and exploitation to ensure comprehensive graph coverage and adapts to evolving node importance, unlike static methods. 3. Demonstrates versatility by integrating with different GNN architectures (GCNs and GATs) and maintaining or exceeding full-batch training accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1be93ab34a4af58594bc48c8d52cc9f7177c298fc314982c8ac7ae27b2086b70_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the computational bottleneck in training Graph Neural Networks (GNNs) on large graphs by proposing BLISS, a Bandit Layer Importance Sampling Strategy. BLISS uses multi-armed bandits to dynamically and adaptively sample the most informative nodes at each layer. Experiments show that this method maintains or even surpasses the accuracy of full-batch training while being more efficient.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[BLISS: Bandit Layer Importance Sampling Strategy] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[训练大型图神经网络的计算成本高/High computational cost for training GNNs on large graphs]
        C --> C1[使用多臂老虎机动态选择信息节点/Using multi-armed bandits to dynamically select informative nodes]
        C --> C2[平衡探索与利用，自适应节点重要性/Balancing exploration and exploitation, adapting to node importance]
        D --> D1[保持或超过全批次训练的精度/Maintains or exceeds full-batch training accuracy]
    ```

- **[arXiv251230] Differentiable Inverse Modeling with Physics-Constrained Latent Diffusion for Heterogeneous Subsurface Parameter Fields**
  - **tags:** [ai], [diffusion models], [latent diffusion model, differentiable physics, inverse problems, parameter estimation, flow in porous media]
  - **authors:** Zihan Lin, QiZhi He
  - **institution:** University of Minnesota
  - **link:** https://arxiv.org/pdf/2512.22421
  - **contributions:** 1. Proposes LD-DIM, a novel framework that integrates a pretrained latent diffusion prior with a differentiable PDE solver for high-dimensional inverse problems. 2. Enables stable gradient-based optimization in a low-dimensional latent space, improving numerical conditioning and preserving sharp discontinuities. 3. Demonstrates superior numerical stability and reconstruction accuracy compared to PINNs and physics-embedded VAE baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb75073de82d3659f4e40522fca5a1fe8743332c5df8e21ca285525b2a200bca_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces LD-DIM, a method that combines a latent diffusion model with a differentiable numerical solver to reconstruct heterogeneous parameter fields from sparse observations in PDE-constrained inverse problems. It shows improved stability and accuracy over existing baselines while maintaining sharp material interfaces.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Differentiable Inverse Modeling with Physics-Constrained Latent Diffusion for Heterogeneous Subsurface Parameter Fields] --> B(核心问题/Problem: High-dimensional, ill-posed PDE inverse problems with sparse observations)
    A --> C(主要方法/Method: LD-DIM integrates latent diffusion prior with differentiable PDE solver)
    A --> D(关键结果/Results: Improved stability & accuracy, preserves sharp interfaces, outperforms PINNs/VAE)
    ```

- **[arXiv251230] Bright 4B: Scaling Hyperspherical Learning for Segmentation in 3D Brightfield Microscopy**
  - **tags:** [cv], [medical image segmentation], [hyperspherical learning, native sparse attention, anisotropic patch embed]
  - **authors:** Amil Khan, Matheus Palhares Viana, Suraj Mishra, B.S. Manjunath
  - **institution:** UC Santa Barbara, Allen Institute for Cell Sciences
  - **link:** https://arxiv.org/pdf/2512.22423
  - **contributions:** 1. A 4B-parameter foundation model (Bright-4B) that learns on the unit hypersphere for segmenting subcellular structures directly from 3D brightfield volumes. 2. Novel architectural components: a hardware-aligned Native Sparse Attention mechanism, depth-width residual HyperConnections, and a soft Mixture-of-Experts for adaptive capacity. 3. A plug-and-play anisotropic patch embed that respects confocal point-spread and axial thinning for geometry-faithful 3D tokenization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7af1d13c6f2fcc3e8d27fe1157700eff79fd4e0fccc0c4ba8b37ebb62c2043fd_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces Bright-4B, a 4-billion parameter foundation model designed for volumetric segmentation of subcellular structures directly from label-free 3D brightfield microscopy images. It employs novel architectural components like hyperspherical learning, native sparse attention, and an anisotropic patch embed to handle 3D context and anisotropic sampling. The model outperforms contemporary baselines in preserving fine structural detail across depth and cell types without requiring fluorescence or heavy post-processing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Bright 4B: Scaling Hyperspherical Learning for Segmentation in 3D Brightfield Microscopy] --> B(核心问题/Problem: Robust 3D segmentation in brightfield microscopy depends on fluorescence or heavy post-processing.)
        A --> C(主要方法/Method: A 4B-parameter foundation model with hyperspherical learning, native sparse attention, hyperconnections, mixture-of-experts, and anisotropic patch embed.)
        A --> D(关键结果/Results: Produces accurate segmentations from brightfield alone, outperforms baselines, preserves detail across depth and cell types.)
    ```

- **[arXiv251230] Causality-Inspired Safe Residual Correction for Multivariate Time Series**
  - **tags:** [ai], [time series forecasting], [residual correction, causality-inspired encoder, non-degradation guarantee, safety mechanism, multivariate time series]
  - **authors:** Jianxiang Xie, Yuncheng Hua
  - **institution:** University of New South Wales, University of Science and Technology of China, The Hong Kong University of Science and Technology (Guangzhou)
  - **link:** https://arxiv.org/pdf/2512.22428
  - **contributions:** 1. Proposes CRC, a plug-and-play residual correction framework explicitly designed to guarantee non-degradation of model performance. 2. Introduces a causality-inspired encoder that decouples self- and cross-variable dynamics to expose direction-aware structure for safer correction. 3. Designs a strict four-fold safety mechanism to govern the correction process and prevent harmful updates, ensuring high non-degradation rates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c7659f53cdce63801de4caead558593caeed0c4662c0c76c85dae564f12a6d78_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that existing post-hoc residual correction methods for multivariate time series forecasting are greedy and can degrade performance. To solve this, it proposes CRC, a causality-inspired safe residual correction framework with a four-fold safety mechanism. Experiments show CRC consistently improves accuracy while ensuring exceptionally high non-degradation rates.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Causality-Inspired Safe Residual Correction for Multivariate Time Series] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有残差校正方法贪婪且可能导致性能下降/Existing greedy correction can degrade performance]
        C --> C1[因果启发的编码器分离变量动态/Causality-inspired encoder decouples dynamics]
        C --> C2[四重安全机制防止有害更新/Four-fold safety mechanism prevents harmful updates]
        D --> D1[CRC提升准确性并保证高非退化率/CRC improves accuracy & ensures high non-degradation rate]
    ```

- **[arXiv251230] AnalogSAGE: Self-evolving Analog Design Multi-Agents with Stratified Memory and Grounded Experience**
  - **tags:** [mlsys], [agent system], [analog circuit design, multi-agent framework, stratified memory, simulation-grounded feedback, self-evolving]
  - **authors:** Zining Wang, Jian Gao, Weimin Fu, Xiaolong Guo, Xuan Zhang
  - **institution:** Northeastern University, Kansas State University
  - **link:** https://arxiv.org/pdf/2512.22435
  - **contributions:** 1. Proposes AnalogSAGE, an open-source self-evolving multi-agent framework for analog circuit design that coordinates three-stage agent explorations through four stratified memory layers, enabling iterative refinement with simulation-grounded feedback. 2. Introduces a stratified context mechanism to selectively preserve stage-relevant information, enhancing long-horizon reasoning and reliability under stringent specifications. 3. Demonstrates significant improvements in pass rates and search space reduction through a benchmark of ten operational amplifier design problems using the open-source SKY130 PDK and ngspice.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf0a7cad048acb4f93f29281281d9e76543f81e5aa1dd6e183e005cda30a7c56_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of automating analog circuit design, which traditionally relies heavily on human intuition, by introducing AnalogSAGE, a self-evolving multi-agent framework with stratified memory and simulation-grounded feedback. This approach enables iterative refinement across topology selection, refinement, and parameter optimization stages. Evaluations show it achieves a 10x overall pass rate and 4x reduction in parameter search space compared to existing methods, enhancing reliability and autonomy in analog design automation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AnalogSAGE: Self-evolving Analog Design Multi-Agents with Stratified Memory and Grounded Experience] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Analog circuit design is knowledge-intensive and relies on human intuition]
        B --> B2[Existing LLM-based methods lack feedback and generalization]
        C --> C1[Self-evolving multi-agent framework]
        C --> C2[Three-stage agent explorations with stratified memory]
        C --> C3[Iterative refinement via simulation-grounded feedback]
        D --> D1[10x overall pass rate improvement]
        D --> D2[48x Pass@1 improvement]
        D --> D3[4x reduction in parameter search space]
    ```

- **[arXiv251230] HiFi-RAG: Hierarchical Content Filtering and Two-Pass Generation for Open-Domain RAG**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [hierarchical filtering, two-pass generation, citation verification, query formulation, model cascade]
  - **authors:** Cattalyya Nuengsigkapian
  - **institution:** Google
  - **link:** https://arxiv.org/pdf/2512.22442
  - **contributions:** 1. Proposes a hierarchical content filtering pipeline to replace standard vector similarity search, improving context precision. 2. Introduces a model cascade strategy using a cost-efficient model (Gemini 2.5 Flash) for filtering and a powerful model (Gemini 2.5 Pro) for final generation. 3. Demonstrates significant performance gains on the MMU-RAGent benchmark and a custom dataset for post-cutoff knowledge.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9840d615edee0e72c18b93838479ebb342195ea1805803858fb9effaf9ba2e95_w640_q70.webp
  - **Simple LLM Summary:** This paper presents HiFi-RAG, a system designed to improve open-domain RAG by addressing irrelevant retrieved information. The method uses a multi-stage pipeline with hierarchical filtering and a two-pass generation strategy employing different LLMs for efficiency and quality. The system won a NeurIPS 2025 competition and showed substantial improvements over baselines in evaluation metrics.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HiFi-RAG] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[开放域RAG中的无关信息与意图对齐/Open-domain RAG faces irrelevant info & intent misalignment]
        C --> C1[分层过滤与两阶段生成/Hierarchical Filtering & Two-Pass Generation]
        C1 --> C2[使用Gemini Flash进行过滤/Use Gemini Flash for filtering]
        C1 --> C3[使用Gemini Pro进行生成/Use Gemini Pro for generation]
        D --> D1[在MMU-RAGent上超越基线/Outperforms baseline on MMU-RAGent]
        D --> D2[在自定义测试集上显著提升/Substantial gains on custom test set]
    ```

- **[arXiv251230] AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [LoRA, Parameter-Efficient Fine-Tuning, Activation Function Annealing, Non-linear Adaptation, Model Merging]
  - **authors:** Jiacheng Li, Jianchao Tan, Zhidong Yang, Feiye Huo, Yerui Sun, Yuchen Xie, Xunliang Cai
  - **institution:** Meituan, Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.22455
  - **contributions:** 1. Proposes AFA-LoRA, a novel training strategy that introduces non-linear expressivity into LoRA while preserving its seamless mergeability., 2. Introduces an annealed activation function that transitions from non-linear to linear during training, enabling strong initial learning and final linear integration., 3. Demonstrates the method's effectiveness across multiple tasks, including supervised fine-tuning, reinforcement learning, and speculative decoding, reducing the performance gap with full-parameter training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a5573f75296283a39c5bdbbb0c94652e0aeb935ae378c12528544ca5e188deb_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limited expressive power of linear Low-Rank Adaptation (LoRA) by proposing AFA-LoRA, a method that uses an annealed activation function to enable non-linear training while ensuring the final adapter remains mergeable. This approach narrows the performance gap between LoRA and full-parameter fine-tuning across various tasks, offering a more powerful and practical parameter-efficient adaptation paradigm.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>LoRA线性适配的表达能力有限<br>LoRA's linear adaptation limits expressive power]
        C[主要方法/Method<br>引入退火激活函数<br>Introduce annealed activation function]
        D[关键结果/Results<br>缩小LoRA与全参数训练的差距<br>Reduces gap between LoRA and full-parameter training]
    ```

- **[arXiv251230] AMBIT: Augmenting Mobility Baselines with Interpretable Trees**
  - **tags:** [other], [urban computing, spatial data science], [origin-destination flow prediction, spatial interaction models, gradient-boosted trees, SHAP analysis, gray-box model]
  - **authors:** Qizhi Wang
  - **institution:** PingCAP, Data & AI-Innovation Lab
  - **link:** https://arxiv.org/pdf/2512.22466
  - **contributions:** 1. Conducts a comprehensive audit of classical spatial interaction models on high-resolution mobility data, identifying PPML gravity as the strongest physical baseline. 2. Proposes AMBIT, a gray-box framework that augments interpretable physical baselines with gradient-boosted trees to learn residuals, balancing accuracy and interpretability. 3. Demonstrates that physics-grounded and POI-anchored residual learners achieve competitive accuracy and robust spatial generalization, providing a reproducible pipeline with diagnostics for urban decision-making.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d0d9ab13b8b2f60e318c90f38821b29e87e0bdd9bf0d9bc963b48c5ac7c2759_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes AMBIT, a gray-box framework that combines interpretable physical mobility baselines with gradient-boosted trees to predict origin-destination flows. It shows that learning residuals on top of physics-based models can achieve accuracy close to strong black-box predictors while maintaining interpretable structure, with POI-anchored residuals being particularly robust for spatial generalization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AMBIT: Augmenting Mobility Baselines with Interpretable Trees] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Conflicting needs for high accuracy and clear interpretability in OD flow prediction]
        C[主要方法/Method: Gray-box framework augmenting physical baselines with interpretable tree models]
        D[关键结果/Results: Physics-grounded residuals approach black-box accuracy; POI-anchored residuals are most robust]
    ```

- **[arXiv251230] GLUE: Gradient-free Learning to Unify Experts**
  - **tags:** [mlsys], [others], [expert mixing, model initialization, gradient-free optimization, SPSA, transfer learning]
  - **authors:** Jong-Ik Park, Shreyas Chaudhari, Srinivasa Pranav, Carlee Joe-Wong, José M. F. Moura
  - **institution:** Carnegie Mellon University
  - **link:** https://arxiv.org/pdf/2512.22467
  - **contributions:** 1. Proposes GLUE, a gradient-free method to learn mixture coefficients for blending expert models into a single initialization prior for a target domain. 2. Introduces a two-point (SPSA) update rule that requires only two forward passes per step, avoiding expensive backpropagation through the full network. 3. Demonstrates that GLUE outperforms heuristic blending baselines and matches or outperforms gradient-based learning of mixture coefficients across multiple datasets and architectures.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58e1db10a62e7b3683bf994e8914b7bcb88a1d8d308b99746a86c5ebb6d9b5c6_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of initializing a model for a new target domain by blending multiple pretrained expert models. It proposes GLUE, a gradient-free method that learns the blending coefficients efficiently using only forward passes. Experiments show GLUE creates a better initialization prior, leading to higher fine-tuned accuracy than heuristic methods and comparable or better performance than gradient-based approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GLUE: Gradient-free Learning to Unify Experts] --> B[核心问题/Problem: 如何有效融合多个专家模型以初始化新目标域模型/How to effectively fuse multiple expert models to initialize a new target domain model]
        A --> C[主要方法/Method: 提出GLUE，一种基于梯度自由的两点SPSA更新学习混合系数的方法/Proposes GLUE, a gradient-free method using two-point SPSA updates to learn mixture coefficients]
        A --> D[关键结果/Results: GLUE在多个实验上超越了启发式基线，并与基于梯度的混合方法性能相当或更优/GLUE outperforms heuristic baselines and matches or outperforms gradient-based mixing across experiments]
    ```

- **[arXiv251230] The Bayesian Geometry of Transformer Attention**
  - **tags:** [ai], [interpretability], [Bayesian inference, transformer attention, mechanistic interpretability, Bayesian wind tunnels, geometric analysis]
  - **authors:** Naman Aggarwal, Siddhartha R. Dalal, Vishal Misra
  - **institution:** Columbia University, Dream Sports, Google DeepMind
  - **link:** https://arxiv.org/pdf/2512.22471
  - **contributions:** 1. Introduces "Bayesian wind tunnels" as controlled environments to rigorously test if transformers perform Bayesian inference, where true posteriors are known and memorization is impossible. 2. Demonstrates that small transformers implement Bayesian inference via a consistent geometric mechanism (residual streams as belief substrate, FFNs for updates, attention for routing), while MLPs fail. 3. Identifies specific geometric diagnostics (orthogonal key bases, query-key alignment, low-dimensional value manifold) and a frame-precision dissociation during training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5333e070f21cfd2abea4d13cddb84bf6d9f3c3124c93bf9142879f24f1e739b1_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether transformers perform genuine Bayesian inference. To test this, the authors create controlled "Bayesian wind tunnel" tasks with known posteriors and show that small transformers accurately reproduce Bayesian posteriors via a specific geometric mechanism, while MLPs fail, establishing attention as crucial for this capability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["The Bayesian Geometry of Transformer Attention<br/>Transformer注意力的贝叶斯几何"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br/>Do transformers perform genuine Bayesian inference or just pattern matching?<br/>Transformer是进行真正的贝叶斯推理还是仅仅模式匹配?"]
        Method["主要方法/Method<br/>Construct 'Bayesian wind tunnels' with known posteriors<br/>构建具有已知后验的'贝叶斯风洞'"]
        Results["关键结果/Results<br/>Transformers implement Bayesian inference via geometric mechanism; MLPs fail<br/>Transformer通过几何机制实现贝叶斯推理；MLP失败"]
    ```

- **[arXiv251230] Collaborative Optimization of Multiclass Imbalanced Learning: Density-Aware and Region-Guided Boosting**
  - **tags:** [ai], [imbalanced learning], [collaborative optimization, density-aware, region-guided boosting, sample weight update, dynamic sampling]
  - **authors:** Chuantao Li, Zhi Li, Jiahao Xu, Jie Li, Sheng Li
  - **institution:** Guangdong Ocean University, University of Electronic Science and Technology of China
  - **link:** https://arxiv.org/pdf/2512.22478
  - **code:** https://github.com/ChuantaoLi/DARG
  - **contributions:** 1. Proposes a collaborative optimization Boosting model for multiclass imbalanced learning that integrates imbalanced learning and model training. 2. Designs a noise-resistant weight update mechanism and a dynamic sampling strategy using density and confidence factors. 3. Achieves tight integration of modules for weight updates, sample region partitioning, and region-guided sampling to enhance performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d829fa49f320d741a98494ca09a1f6019a6cccef04a93af08effdf4810adc20_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of classification bias in multiclass imbalanced data by proposing a collaborative optimization Boosting model. The method integrates density-aware and region-guided techniques to update sample weights and perform dynamic sampling, achieving improved performance over existing baselines on 20 public datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Collaborative Optimization of Multiclass Imbalanced Learning: Density-Aware and Region-Guided Boosting] --> B[核心问题/Problem: 类别不平衡导致分类偏差，现有方法未协同优化不平衡学习与模型训练]
    A --> C[主要方法/Method: 提出协同优化Boosting模型，集成密度因子和置信度因子，设计抗噪声权重更新和动态采样策略]
    A --> D[关键结果/Results: 在20个公共不平衡数据集上显著优于8个先进基线模型]
    ```

- **[arXiv251230] SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding for Fine-Grained sEMG-Based Movement Decoding**
  - **tags:** [ai], [biomedical signal processing], [self-supervised learning, surface electromyography, rotary position encoding, spectral pre-training, movement decoding]
  - **authors:** Zihan Weng, Chanlin Yi, Pouya Bashivan, Jing Lu, Fali Li, Dezhong Yao, Jingming Hou, Yangsong Zhang, Peng Xu
  - **institution:** University of Electronic Science and Technology of China
  - **link:** https://arxiv.org/pdf/2512.22481
  - **contributions:** 1. A novel self-supervised pre-training task that uses masked prediction of clustered STFT pseudo-labels to learn robust, physiologically relevant frequency patterns from sEMG signals. 2. A novel Cylindrical Rotary Position Embedding (CyRoPE) that factorizes embeddings along temporal and annular spatial dimensions to explicitly model the cylindrical topology of forearm electrode arrays. 3. The SPECTRE framework, which integrates these contributions to establish a new state-of-the-art for fine-grained movement decoding, validated on multiple datasets including data from individuals with amputation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5801cbdcbac93bf7df15e18531c5ff2653259e25003568da5b53b240d06d32c_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces SPECTRE, a domain-specific self-supervised learning framework for decoding fine-grained movements from surface electromyography (sEMG) signals. It proposes a spectral pre-training task using masked pseudo-label prediction and a novel cylindrical rotary position encoding to model sensor topology. Evaluations show SPECTRE significantly outperforms existing supervised and generic self-supervised baselines, providing a robust foundation for practical myoelectric interfaces.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Decoding fine-grained movement from noisy, non-stationary sEMG signals for prosthetic control]
        C[主要方法/Method: Domain-specific SSL with spectral pre-training and Cylindrical Rotary Position Embedding (CyRoPE)]
        D[关键结果/Results: New SOTA performance, outperforms supervised & generic SSL baselines, validated on amputation data]
    ```

- **[arXiv251230] Toward Real-World IoT Security: Concept Drift-Resilient IoT Botnet Detection via Latent Space Representation Learning and Alignment**
  - **tags:** [sec], [network intrusion detection], [concept drift, latent space alignment, graph neural network (GNN), IoT botnet detection, variational autoencoder]
  - **authors:** Hassan Wasswa, Timothy Lynar
  - **institution:** University of New South Wales
  - **link:** https://arxiv.org/pdf/2512.22488
  - **contributions:** 1. Proposes a scalable framework for adaptive IoT threat detection that eliminates the need for continuous classifier retraining, reducing computational overhead and catastrophic forgetting. 2. Introduces a method using latent space representation learning and an alignment model to map new traffic to a historical latent space, preserving knowledge of past attacks. 3. Transforms latent representations into a graph structure and uses a Graph Attention Network (GAT) to capture inter-instance relationships among attack samples for improved detection.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4c1a80d42c79bd3adbbc2c072359068d65253efabadc2bd6d3617f632439f72_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of concept drift in IoT botnet detection by proposing a framework that trains a classifier once on historical traffic representations. It uses an alignment model to map new traffic to this learned latent space and a graph neural network to classify the data, maintaining robust performance without retraining. Experimental results on real-world datasets show the framework's effectiveness in dynamic IoT environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Toward Real-World IoT Security: Concept Drift-Resilient IoT Botnet Detection / 面向真实世界物联网安全：概念漂移鲁棒的物联网僵尸网络检测"]
        Root --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["AI模型依赖静态数据集 / AI models rely on stationary datasets"]
        Problem --> P2["真实流量存在概念漂移 / Real-world traffic suffers concept drift"]
        Problem --> P3["现有方案重训练开销大 / Existing solutions have high retraining cost"]
        Method --> M1["学习历史流量的潜在空间表示 / Learn latent space of historical traffic"]
        Method --> M2["对齐模型映射新流量 / Alignment model maps new traffic"]
        Method --> M3["图神经网络分类 / Graph Neural Network for classification"]
        Results --> R1["保持鲁棒检测性能 / Maintains robust detection performance"]
        Results --> R2["适用于动态大规模环境 / Suitable for dynamic, large-scale environments"]
    ```

- **[arXiv251230] The Quest for Winning Tickets in Low-Rank Adapters**
  - **tags:** [ai], [parameter-efficient fine-tuning], [Lottery Ticket Hypothesis, Low-Rank Adaptation, Parameter-Efficient Fine-Tuning, Sparse Subnetworks]
  - **authors:** Hamed Damirchi, Cristian Rodriguez-Opazo, Ehsan Abbasnejad, Zhen Zhang, Javen Shi
  - **institution:** Australian Institute for Machine Learning (Adelaide University), Monash University
  - **link:** https://arxiv.org/pdf/2512.22495
  - **contributions:** 1. Empirically validates that the Lottery Ticket Hypothesis (LTH) holds within Low-Rank Adaptation (LoRA) methods, revealing the existence of sparse, high-performing subnetworks ("winning tickets") in adapters. 2. Discovers that the effectiveness of these sparse subnetworks depends more on the sparsity distribution across layers than on the specific weights selected. 3. Proposes Partial-LoRA, a novel method to systematically identify and train these sparse low-rank adapters, achieving significant parameter reduction (up to 87%) while maintaining or improving performance across vision and language tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/19921047ca06f45b5a51cefcf5b1cd9502b9ad5650b66c746d8b15f622036ef0_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether the Lottery Ticket Hypothesis extends to parameter-efficient fine-tuning, specifically Low-Rank Adaptation (LoRA). The authors propose Partial-LoRA, a method to identify and train sparse, task-aligned subnetworks within LoRA adapters. Experiments show Partial-LoRA can reduce trainable parameters by up to 87% while matching or surpassing the performance of dense adapters.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Quest for Winning Tickets in Low-Rank Adapters] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Does LTH hold in PEFT/LoRA?<br>LTH是否适用于参数高效微调?]
        C[主要方法/Method<br>Propose Partial-LoRA<br>提出Partial-LoRA方法]
        D[关键结果/Results<br>Sparse adapters work,<br>up to 87% fewer params<br>稀疏适配器有效，参数减少高达87%]
    ```

- **[arXiv251230] Role-Based Fault Tolerance System for LLM RL Post-Training**
  - **tags:** [mlsys], [fault-tolerance], [role-based fault tolerance, RL post-training, UCX communication, warm standby, Effective Training Time Ratio (ETTR)]
  - **authors:** Zhenqian Chen, Baoquan Zhong, Xiang Li, Qing Dai, Xinkui Zhao, Miao Ye, Ren Cheng, Lufei Zhang, Jianwei Yin
  - **institution:** Zhejiang University, State Key Laboratory of Mathematical Engineering and Advanced Computing
  - **link:** https://arxiv.org/pdf/2512.22492
  - **contributions:** 1. Proposes a role-based fault isolation and recovery system (RobustRL) for RL post-training, enabling recovery of only the failed component (trainer, rollout) instead of restarting the entire task. 2. Introduces a role-aware monitoring mechanism to accurately detect failures and avoid false positives/delays specific to different RL roles. 3. Implements dynamic, UCX-based point-to-point communication to reconnect recovered roles and synchronize weights immediately, replacing static collective communication.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ceff77cfb9d0c7d7e763916b77716ee6534c3aa3d54d41253fef6ea4d9a86ec0_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of fault tolerance for RL post-training of LLMs, which interleaves training and inference workloads. It proposes RobustRL, a system that isolates and recovers failed roles (e.g., trainer, rollout) individually using a Detect-Restart-Reconnect paradigm, instead of restarting the entire job. This approach significantly improves the Effective Training Time Ratio and reduces end-to-end training time compared to baseline methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Role-Based Fault Tolerance System for LLM RL Post-Training] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[RL后训练混合训练与推理工作负载，易受双方故障影响/RL post-training mixes training & inference, vulnerable to faults from both]
        B --> B2[现有容错框架未针对RL的异步执行优化/Existing FT frameworks not optimized for RL's async execution]
        C --> C1[基于角色的故障隔离与恢复/Role-based fault isolation & recovery]
        C --> C2[检测-重启-重连范式/Detect-Restart-Reconnect paradigm]
        C2 --> C21[角色感知监控/Role-aware monitoring]
        C2 --> C22[非中断式重启/Non-disruptive restart with warm standbys]
        C2 --> C23[动态UCX点对点通信重连/Dynamic UCX P2P reconnection]
        D --> D1[ETTR超过80%，优于基线的60%/ETTR >80%, better than baseline 60%]
        D --> D2[端到端训练时间加快8.4%-17.4%/End-to-end training time 8.4%-17.4% faster]
    ```

- **[arXiv251230] Decomposing Task Vectors for Refined Model Editing**
  - **tags:** [ai], [model editing], [task vector, parameter decomposition, invariant subspace, concept interference, LoRA]
  - **authors:** Hamed Damirchi, Ehsan Abbasnejad, Zhen Zhang, Javen Shi
  - **institution:** Australian Institute for Machine Learning (University of Adelaide), Monash University
  - **link:** https://arxiv.org/pdf/2512.22511
  - **contributions:** 1. A principled decomposition method to separate a task vector into shared and unique components., 2. Application of the decomposition to improve multi-task merging in image classification, enable clean style mixing in diffusion models, and reduce toxicity in language models., 3. A new framework for understanding and controlling task vector arithmetic to address interference during concept composition.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e938f563a374559600295d0e58643d1a4f7e55e5b56e3e6aca0b3daec488d0b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of unpredictable outcomes when performing arithmetic operations on task vectors due to overlapping concepts. It proposes a method to decompose each task vector into shared and unique components using invariant subspaces. This enables more precise model editing, demonstrated by improved multi-task merging, clean style mixing, and significant toxicity reduction while preserving general knowledge.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Decomposing Task Vectors for Refined Model Editing"] --> Problem["核心问题/Problem: Task vector arithmetic causes unpredictable interference due to overlapping concepts."]
        Root --> Method["主要方法/Method: Decompose task vectors into shared and unique components via invariant subspaces."]
        Root --> Results["关键结果/Results: Improved multi-task merging, clean style mixing in diffusion models, and toxicity reduction in language models."]
    ```

- **[arXiv251230] Predicting LLM Correctness in Prosthodontics Using Metadata and Hallucination Signals**
  - **tags:** [nlp], [hallucination detection], [correctness prediction, metadata signals, prompting strategies, log probability, response consistency]
  - **authors:** Lucky Susanto, Anasta Pranawijayana, Cortino Sukotjo, Soni Prasad, Derry Wijaya
  - **institution:** Monash University Indonesia, University of Pittsburgh, University of North Carolina Adams School of Dentistry, Boston University
  - **link:** https://arxiv.org/pdf/2512.22508
  - **contributions:** 1. Proposes a novel method to predict LLM correctness (not just hallucination) using metadata and hallucination signals in a high-stakes medical domain (prosthodontics). 2. Demonstrates that metadata-based predictors can improve accuracy over a naive baseline and achieve high precision, but are not reliable for directly predicting hallucination. 3. Shows that prompting strategies significantly alter model internal behavior and the predictive utility of metadata, despite not changing overall task accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbe159260b97cf5e7a59edbee0a23b697a76a89a0fdbf6e0c9797739cc322b42_w640_q70.webp
  - **Simple LLM Summary:** This study investigates predicting the correctness of LLM answers on a prosthodontics exam using metadata (like log probability and consistency) and hallucination signals. The method, applied to GPT-4o and OSS-120B across different prompts, shows improved accuracy over a baseline but is not yet robust for high-stakes deployment. The research highlights that prompting strategies change model behavior and metadata utility, offering a direction for reliability signals.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Predicting LLM Correctness in Prosthodontics<br/>预测LLM在口腔修复学中的正确性] --> B(Problem/核心问题: LLM hallucinations in high-stakes healthcare domains<br/>高风险医疗领域中的LLM幻觉问题)
        A --> C(Method/主要方法: Use metadata & hallucination signals to build correctness predictors<br/>使用元数据和幻觉信号构建正确性预测器)
        A --> D(Results/关键结果: Improved accuracy & precision; metadata not reliable for hallucination prediction; prompting alters behavior<br/>提升准确率和精确度；元数据不能可靠预测幻觉；提示策略改变模型行为)
    ```

- **[arXiv251230] Towards Reliable Evaluation of Adversarial Robustness for Spiking Neural Networks**
  - **tags:** [ai], [adversarial robustness], [Spiking Neural Networks, surrogate gradient, adversarial attack, gradient vanishing, adaptive optimization]
  - **authors:** Jihang Wang, Dongcheng Zhao, Ruolin Chen, Qian Zhang, Yi Zeng
  - **institution:** Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Beijing Institute of AI Safety and Governance
  - **link:** https://arxiv.org/pdf/2512.22522
  - **contributions:** 1. Theoretical analysis of gradient vanishing in surrogate gradient methods for SNNs. 2. Proposal of Adaptive Sharpness Surrogate Gradient (ASSG) to adaptively adjust the surrogate function for more accurate gradients. 3. Design of Stable Adaptive Projected Gradient Descent (SA-PGD), an adversarial attack with adaptive step size for stable convergence under imprecise gradients.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7b10ed2a96f6e46c5c2afb21a8e1184dd9c5e1f342efdb93f3cd317a08c20ea_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the unreliable evaluation of adversarial robustness in Spiking Neural Networks (SNNs) caused by gradient vanishing from surrogate gradients. The authors propose a framework combining an adaptive surrogate gradient method (ASSG) and an adaptive-step attack (SA-PGD) to generate stronger attacks. Experiments show this framework significantly increases attack success rates, revealing that current SNN robustness is overestimated and highlighting the need for more reliable adversarial training.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Towards Reliable Evaluation of Adversarial Robustness for Spiking Neural Networks") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("梯度消失/Gradient Vanishing")
        Problem --> P2("对抗评估不可靠/Unreliable Adversarial Evaluation")
        Method --> M1("理论分析梯度消失/Theoretical Analysis of Gradient Vanishing")
        Method --> M2("自适应锐度替代梯度/Adaptive Sharpness Surrogate Gradient (ASSG)")
        Method --> M3("稳定自适应投影梯度下降/Stable Adaptive PGD (SA-PGD)")
        Results --> R1("攻击成功率大幅提升/Substantially Increased Attack Success Rate")
        Results --> R2("揭示鲁棒性被高估/Revealed Overestimated Robustness")
        Results --> R3("提供更可靠评估/Provided More Reliable Evaluation")
    ```

- **[arXiv251230] TimePerceiver: An Encoder-Decoder Framework for Generalized Time-Series Forecasting**
  - **tags:** [ai], [time-series forecasting], [encoder-decoder, latent bottleneck representations, learnable queries, generalized forecasting]
  - **authors:** Jaebin Lee, Hankook Lee
  - **institution:** Sungkyunkwan University
  - **link:** https://arxiv.org/pdf/2512.22550
  - **code:** https://github.com/efficient-learning-lab/TimePerceiver
  - **contributions:** 1. Generalizes the time-series forecasting task to include diverse objectives like extrapolation, interpolation, and imputation. 2. Proposes a novel encoder-decoder architecture with latent bottleneck representations to capture temporal and cross-channel dependencies. 3. Introduces learnable queries for decoding to effectively retrieve information for arbitrarily positioned target timestamps.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/091fdcd1058e0acfad18820d025c1fe50ff4315cbd5ec8a06f5d86eb9767513c_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes TimePerceiver, a unified encoder-decoder framework for generalized time-series forecasting. It handles diverse prediction objectives by using latent bottleneck encodings and learnable query-based decoding. Extensive experiments show it consistently outperforms prior state-of-the-art methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[TIMEPERCEIVER] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有方法侧重编码器，预测与训练分离/Prior work focuses on encoder, treats prediction & training separately]
        C --> C1[广义预测任务: 外推、插值、填补/Generalized forecasting: extrapolation, interpolation, imputation]
        C --> C2[编码: 潜在瓶颈表示/Encoding: Latent bottleneck representations]
        C --> C3[解码: 可学习查询/Decoding: Learnable queries]
        D --> D1[性能显著超越SOTA/Outperforms SOTAs significantly]
    ```

- **[arXiv251230] Computing Pure-Strategy Nash Equilibria in a Two-Party Policy Competition: Existence and Algorithmic Approaches**
  - **tags:** [ai], [game theory], [pure-strategy Nash equilibrium, continuous games, policy competition, gradient-based algorithm, grid-based search]
  - **authors:** Chuang-Chieh Lin, Chi-Jen Lu, Po-An Chen, Chih-Chieh Hung
  - **institution:** National Taiwan Ocean University, Academia Sinica, National Yang Ming Chiao Tung University, National Chung Hsing University
  - **link:** https://arxiv.org/pdf/2512.22552
  - **contributions:** 1. Formulated a two-party policy competition game and validated the isotonicity hypothesis of winning probability through simulations. 2. Proved the existence of a pure-strategy Nash equilibrium (PSNE) in both one- and multi-dimensional policy spaces. 3. Proposed and experimentally validated a decentralized gradient-based algorithm and a polynomial-time grid-based search algorithm for finding approximate PSNEs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ef0be95e6f7da168b174f0a6d600f4ee8f0f3d2bcaba49c996d43be6d1be4b7_w640_q70.webp
  - **Simple LLM Summary:** This paper models two-party policy competition as a continuous non-cooperative game where parties choose policy vectors and a party's payoff is the expected utility for its supporters. The authors prove the existence of a pure-strategy Nash equilibrium and propose two algorithms—a gradient-based method and a grid-based search—that efficiently find approximate equilibria.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Computing Pure-Strategy Nash Equilibria in a Two-Party Policy Competition] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[建模两党政策竞争/Model two-party policy competition]
        C --> C1[形式化为连续博弈/Formulate as continuous game]
        C --> C2[验证等渗性假设/Validate isotonicity hypothesis]
        C --> C3[设计梯度与网格算法/Design gradient & grid algorithms]
        D --> D1[证明纯策略纳什均衡存在性/Prove PSNE existence]
        D --> D2[算法快速收敛/Algorithm converges rapidly]
        D --> D3[找到近似均衡/Find approximate equilibrium]
    ```

- **[arXiv251230] RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure**
  - **tags:** [mlsys], [agent system], [disaggregated infrastructure, hardware-affinity mapping, fine-grained asynchrony]
  - **authors:** Wei Gao, Yuheng Zhao, Tianyuan Wu, Shaopan Xiong, Weixun Wang, Dakai An, Lunxi Cao, Dilxat Muhtar, Zichen Liu, Haizhou Zhao, Ju Huang, Siran Yang, Yongbin Li, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng, Wei Wang
  - **institution:** HKUST, Alibaba Group
  - **link:** https://arxiv.org/pdf/2512.22560
  - **code:** https://github.com/alibaba/ROLL
  - **contributions:** 1. A hardware-affinity workload mapping strategy that routes compute-bound and bandwidth-bound tasks to best-fit GPU devices. 2. A fine-grained asynchrony mechanism that manages execution at the trajectory level to mitigate resource bubbles and improve utilization. 3. A statefulness-aware computation design that offloads stateless components to serverless infrastructure for elastic scaling.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc8e408c613097b7b60bc32e41ec3137faa8dd94184658c8a802b65cbf57c593_w640_q70.webp
  - **Simple LLM Summary:** The paper presents RollArt, a distributed system designed to scale agentic reinforcement learning training on disaggregated infrastructure. It addresses the heterogeneity of agentic RL workloads by proposing three core techniques: hardware-affinity workload mapping, fine-grained asynchrony, and statefulness-aware computation. The system demonstrates significant improvements in training throughput, achieving 1.35-2.05x speedup over baselines, and scales to thousands of GPUs.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure"] --> Problem["核心问题/Problem: Agentic RL workloads are heterogeneous, causing inefficiency in monolithic infrastructure."]
        Root --> Method["主要方法/Method: Disaggregated system with hardware-affinity mapping, fine-grained asynchrony, and statefulness-aware computation."]
        Root --> Results["关键结果/Results: Achieves 1.35-2.05x training speedup and scales to >3000 GPUs."]
    ```

- **[arXiv251230] On Admissible Rank-based Input Normalization Operators**
  - **tags:** [ai], [machine learning theory], [rank-based normalization, differentiable sorting, monotone invariance, batch independence, Lipschitz continuity]
  - **authors:** Taeyun Kim
  - **institution:** Seoul National University
  - **link:** https://arxiv.org/pdf/2512.22587
  - **contributions:** 1. Identified and formalized three axioms (invariance and stability properties) that a valid rank-based input normalization operator must satisfy. 2. Proved a structural characterization theorem showing any admissible operator must factor into a feature-wise rank representation and a monotone-Lipschitz scalarization map. 3. Constructed a minimal operator meeting the proposed axioms, empirically demonstrating the non-triviality of the constraints and delineating the design space from existing differentiable sorting methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49ce297e3baab406a1befffbcf116551c1492e7a6451fb1af02514d5f1ddb86b_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that widely used differentiable sorting/ranking operators are structurally unstable under monotone transformations and batch variations. To address this, it proposes formal axioms for stable rank-based normalization and proves that any admissible operator must have a specific factored structure. The authors construct a minimal operator satisfying these axioms, formally separating valid normalization from existing differentiable sorting approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["On Admissible Rank-based Input Normalization Operators<br>可容许的基于排序的输入归一化算子"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["核心问题/Problem<br>Existing differentiable sorting/ranking operators are unstable under monotone transforms & batch shifts."]
        Method["主要方法/Method<br>Propose three axioms for invariance/stability; prove structural factorization theorem."]
        Results["关键结果/Results<br>Construct minimal admissible operator; delineate design space from prior methods."]
    ```

- **[arXiv251230] Data-Driven Analysis of Crash Patterns in SAE Level 2 and Level 4 Automated Vehicles Using K-means Clustering and Association Rule Mining**
  - **tags:** [ai], [data mining], [K-means clustering, Association Rule Mining, crash pattern analysis, automated vehicles, NHTSA data]
  - **authors:** Jewel Rana Palit, Vijayalakshmi K Kumarasamy, Osama A. Osman
  - **institution:** University of Tennessee at Chattanooga, Collier County Government
  - **link:** https://arxiv.org/pdf/2512.22589
  - **contributions:** 1. Developed a two-stage data mining framework combining K-means clustering and Association Rule Mining to analyze AV crash data. 2. Applied the framework to a large-scale dataset of over 2,500 AV crash records from NHTSA, covering SAE Levels 2 and 4. 3. Uncovered interpretable multivariate relationships between crash patterns and environmental/operational factors, providing actionable insights for AV safety.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07c3b11717362343c168a38a05a8cdd65b40a65cd3df1b048cfb816c2493f25b_w640_q70.webp
  - **Simple LLM Summary:** This study analyzes crash patterns in SAE Level 2 and 4 Automated Vehicles using a large-scale NHTSA dataset. It proposes a two-stage data mining framework: first using K-means clustering to segment crashes into behavioral clusters, then applying Association Rule Mining to find relationships between crash factors within each cluster. The results provide actionable guidance for improving AV safety and deployment strategies.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Data-Driven Analysis of Crash Patterns in SAE Level 2 and Level 4 Automated Vehicles Using K-means Clustering and Association Rule Mining<br/>论文标题"]
        Root --> Problem["AV safety concerns in mixed traffic; Limited analysis across SAE levels<br/>核心问题/Problem"]
        Root --> Method["Two-stage framework: K-means clustering + Association Rule Mining (ARM)<br/>主要方法/Method"]
        Root --> Results["Uncovered crash dynamics & multivariate relationships; Actionable guidance for stakeholders<br/>关键结果/Results"]
    ```

- **[arXiv251230] Cryptocurrency Price Prediction Using Parallel Gated Recurrent Units**
  - **tags:** [ai], [time series forecasting], [Gated Recurrent Units, parallel neural networks, cryptocurrency price prediction, mean absolute percentage error, recurrent neural networks]
  - **authors:** Milad Asadpour, Alireza Rezaee, Farshid Hajati
  - **institution:** University of Tehran, University of New England
  - **link:** https://arxiv.org/pdf/2512.22599
  - **contributions:** 1. Proposes a novel Parallel Gated Recurrent Units (PGRU) model for cryptocurrency price forecasting. 2. Employs parallel and independent recurrent neural networks with distinct price-related feature inputs. 3. Demonstrates higher accuracy and efficiency with lower computational cost and less input data compared to existing methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1b0d946f543a3b63440ffb89cc57536eb655abef18c7f847881484fd9e06122_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a new deep learning model called Parallel Gated Recurrent Units (PGRU) for predicting cryptocurrency prices. The model uses parallel recurrent neural networks that process different price features independently, and their outputs are combined by another neural network for the final forecast. Experimental results show the model achieves low prediction errors (e.g., 2.641% MAPE) with higher efficiency and lower computational cost than previous methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cryptocurrency Price Prediction Using Parallel Gated Recurrent Units] --> B[核心问题/Problem: Cryptocurrency price forecasting challenge]
        A --> C[主要方法/Method: Parallel Gated Recurrent Units (PGRU) model]
        A --> D[关键结果/Results: Achieves low MAPE (e.g., 2.641%), higher accuracy & efficiency]
    ```

- **[arXiv251230] Energy-Guided Flow Matching Enables Few-Step Conformer Generation and Ground-State Identification**
  - **tags:** [ai], [generative models], [flow matching, conformer generation, energy guidance, ground-state identification, molecular geometry]
  - **authors:** Guikun Xu, Xiaohan Yi, Peilin Zhao, Yatao Bian
  - **institution:** Shanghai Jiao Tong University, National University of Singapore, Tsinghua University
  - **link:** https://arxiv.org/pdf/2512.22597
  - **code:** https://github.com/Rich-XGK/EnFlow.git
  - **contributions:** 1. Proposes EnFlow, a unified framework that couples flow matching with an explicitly learned energy model for conformer generation. 2. Introduces an energy-guided sampling scheme along a non-Gaussian flow matching path to steer trajectories toward lower-energy regions, improving fidelity in few-step regimes. 3. Enables accurate ground-state identification by using the learned energy function to rank generated ensembles, reducing prediction errors.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8be1fad6f55102be97d0cd80a5b8da136a8f70c287b7f11b3a11156b5bc80a04_w640_q70.webp
  - **Simple LLM Summary:** The paper presents EnFlow, a method that integrates flow matching with an energy model to guide the generation of molecular conformers. By using energy-gradient guidance during sampling, it improves conformational accuracy with few steps and enables better identification of the ground-state structure. Experiments show it outperforms state-of-the-art methods on standard benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Energy-Guided Flow Matching Enables Few-Step Conformer Generation and Ground-State Identification] --> B[核心问题/Problem: Fragmented learning-based approaches for conformer generation lack reliable energy calibration or ensemble diversity.]
        A --> C[主要方法/Method: EnFlow couples flow matching with a learned energy model and uses energy-guided sampling along a non-Gaussian path.]
        A --> D[关键结果/Results: Improves generation metrics with 1-2 steps and reduces ground-state prediction errors on GEOM datasets.]
    ```

- **[arXiv251230] Gold Price Prediction Using Long Short-Term Memory and Multi-Layer Perceptron with Gray Wolf Optimizer**
  - **tags:** [ai], [time series forecasting], [LSTM, Multilayer Perceptron (MLP), Gray Wolf Optimizer (GWO), gold price prediction, trading strategy]
  - **authors:** Hesam Taghipour, Alireza Rezaee, Farshid Hajati
  - **institution:** University of Tehran, University of New England
  - **link:** https://arxiv.org/pdf/2512.22606
  - **contributions:** 1. Proposed a hybrid LSTM-MLP model for multi-timeframe (daily and monthly) gold price forecasting. 2. Utilized the Gray Wolf Optimizer (GWO) to optimize the number of neurons in the neural networks for improved accuracy. 3. Developed and backtested a trading strategy based on the model's predictions, reporting a high simulated return of 171% over three months.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/46725f71da8c268509e63f86ad823980c405c360b229a1a903d358d4d2dd61d5_w640_q70.webp
  - **Simple LLM Summary:** This paper presents an AI-based model for predicting gold prices. It uses two LSTM networks for daily and monthly forecasts, integrates their outputs with an MLP, and optimizes the network structure using the Gray Wolf Optimizer. The model achieved low prediction errors and a high simulated trading return, demonstrating its potential for financial forecasting.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Gold Price Prediction Using LSTM and MLP with GWO] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[金融市场预测复杂且具有挑战性/Financial market forecasting is complex and challenging]
        C --> C1[使用两个LSTM网络进行每日和每月预测/Use two LSTM networks for daily and monthly forecasting]
        C --> C2[通过MLP整合LSTM输出/Integrate LSTM outputs via MLP]
        C --> C3[使用灰狼优化器(GWO)优化网络神经元/Use Gray Wolf Optimizer (GWO) to optimize network neurons]
        D --> D1[日收盘价预测MAE为$0.21/Daily closing price prediction MAE is $0.21]
        D --> D2[月价格预测MAE为$22.23/Monthly price prediction MAE is $22.23]
        D --> D3[模拟交易策略三个月回报率171%/Simulated trading strategy achieved 171% return in three months]
    ```

- **[arXiv251230] Communication Compression for Distributed Learning with Aggregate and Server-Guided Feedback**
  - **tags:** [mlsys], [federated learning], [communication compression, error feedback, biased compression, control variates, distributed gradient descent]
  - **authors:** Tomas Ortega, Chun-Yin Huang, Xiaoxiao Li, Hamid Jafarkhani
  - **institution:** University of California, Irvine; University of British Columbia; Vector Institute
  - **link:** https://arxiv.org/pdf/2512.22623
  - **contributions:** 1. Proposed Compressed Aggregate Feedback (CAFe), a novel framework for biased compression in distributed learning that uses the previous round's aggregated update as a shared control variate, eliminating the need for client-side state. 2. Proposed Server-Guided Compressed Aggregate Feedback (CAFe-S), an extension that leverages a small server-side dataset to generate a more accurate predictor update, improving convergence when server data is representative. 3. Provided theoretical convergence guarantees for both CAFe and CAFe-S in non-convex settings, proving CAFe's superiority over standard distributed compressed gradient descent and showing CAFe-S's improved rate with more representative server data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/988420401d89faee52e66a7e209751875e33b7f833b8dc7f136f1f1d2650454d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the communication bottleneck and privacy issues in Federated Learning by proposing two novel compression frameworks, CAFe and CAFe-S, which enable biased compression without requiring client-side state. CAFe uses the previous aggregated update as a shared control variate, while CAFe-S leverages a small server dataset for a better predictor. Theoretical and experimental results demonstrate their superiority over existing compression schemes.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Communication Compression for Distributed Learning] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[通信瓶颈与隐私/Communication Bottleneck & Privacy]
    B1 --> B2[有偏压缩需要客户端状态/Biased Compression Needs Client State]
    C --> C1[CAFe: 聚合反馈/CAFe: Aggregate Feedback]
    C --> C2[CAFe-S: 服务器引导反馈/CAFe-S: Server-Guided Feedback]
    C1 --> C3[使用上一轮聚合更新作为共享控制变量/Use Previous Aggregate Update as Shared Control Variate]
    C2 --> C4[使用服务器数据生成预测器/Use Server Data to Generate Predictor]
    D --> D1[理论收敛保证/Theoretical Convergence Guarantees]
    D --> D2[优于现有方案/Superior to Existing Schemes]
    ```

- **[arXiv251230] Tree Meets Transformer: A Hybrid Architecture for Scalable Power Allocation in Cell-Free Networks**
  - **tags:** [mlsys], [llm inference], [binary tree compression, Transformer, scalable inference, power allocation, cell-free]
  - **authors:** Irched Chafaa, Giacomo Bacci, Luca Sanguinetti
  - **institution:** University of Pisa
  - **link:** https://arxiv.org/pdf/2512.22639
  - **contributions:** 1. Proposes a novel hybrid Tree-Transformer architecture for scalable per-user power allocation in wireless networks. 2. Introduces a method that compresses user features via a binary tree to a global root representation, applies a Transformer encoder only to the root, and decodes powers with a shared decoder, achieving logarithmic depth and linear total complexity. 3. Demonstrates that the model achieves near-optimal performance for the max-min fairness problem in cell-free massive MIMO systems while significantly reducing inference time compared to full-attention baselines, without needing retraining for different network sizes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/967237dcd593c2fe2d6f3b16cb72307d4ae0dbaa94a8031ad460a273da33c12a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high computational cost of Transformer models for power allocation in large-scale wireless networks. It proposes a hybrid Tree-Transformer architecture that compresses user features into a root node for processing, achieving linear complexity and scalable inference. The model demonstrates near-optimal performance with significantly reduced inference time for cell-free massive MIMO systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Tree Meets Transformer: A Hybrid Architecture for Scalable Power Allocation in Cell-Free Networks"]
        Root --> Problem["核心问题/Problem<br>Transformer计算成本高，难以扩展/Poor scalability of Transformer for power allocation"]
        Root --> Method["主要方法/Method<br>树-Transformer混合架构/Tree-Transformer hybrid architecture<br>（二叉树压缩，根节点处理/Binary tree compression, root processing）"]
        Root --> Results["关键结果/Results<br>接近最优性能，显著降低推理时间/Near-optimal performance, significantly reduced inference time"]
    ```

- **[arXiv251230] Scaling Unverifiable Rewards: A Case Study on Visual Insights**
  - **tags:** [mlsys], [agent system], [Test-Time Scaling, multi-agent pipeline, process-based refinement, LLM-as-Judge, unverifiable rewards]
  - **authors:** Shuyu Gan, James Mooney, Pan Hao, Renxiang Wang, Mingyi Hong, Qianwen Wang, Dongyeop Kang
  - **institution:** University of Minnesota
  - **link:** https://arxiv.org/pdf/2512.22650
  - **code:** https://minnesotanlp.github.io/insight-scaling-webpage
  - **contributions:** 1. Proposed Selective Test-Time Scaling, a process-based refinement framework that scales inference across stages in multi-agent pipelines instead of repeated refinement over time. 2. Designed a reliable LLM-based judge model aligned with human experts for evaluating visual insights. 3. Demonstrated improved insight quality under fixed compute budget in a data science pipeline application.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60e14b2c6ac8597444bea3610d692bad067ed798ec62c0920b0fe7c54b7fcd14_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of scaling LLM agents for tasks with unverifiable rewards by introducing Selective Test-Time Scaling, which distributes compute across pipeline stages and prunes low-quality branches early using process-specific judges. Applied to generating visual insights from datasets, the method increases mean quality scores and reduces variance compared to traditional time-based refinement. The work provides a foundation for scaling complex, open-ended tasks like scientific discovery and story generation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Scaling Unverifiable Rewards: A Case Study on Visual Insights] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[多阶段任务缺乏可验证奖励/Multi-stage tasks lack verifiable rewards]
        B --> B2[基于评判的优化易累积误差/Judge-based refinement prone to error accumulation]
        C --> C1[选择性测试时扩展/Selective Test-Time Scaling]
        C --> C2[跨阶段分配计算资源/Distribute compute across stages]
        C --> C3[早期剪枝低质量分支/Prune low-quality branches early]
        D --> D1[提升平均分数/Increased mean scores (61.64 to 65.86)]
        D --> D2[降低方差/Reduced variance]
        D --> D3[与人类专家对齐的评判模型/Judge model aligned with human experts]
    ```

- **[arXiv251230] Clinically Calibrated Machine Learning Benchmarks for Large-Scale Multi-Disorder EEG Classification**
  - **tags:** [ai], [medical signal processing], [electroencephalography, multi-disorder classification, sensitivity-oriented modeling, clinical calibration, feature importance analysis]
  - **authors:** Argha Kamal Samanta, Deepak Mewada, Monalisa Sarma, Debasis Samanta
  - **institution:** Indian Institute of Technology, Kharagpur
  - **link:** https://arxiv.org/pdf/2512.22656
  - **contributions:** 1. Proposes a clinically calibrated, sensitivity-prioritized machine learning framework for classifying eleven diverse neurological disorders from EEG data, addressing severe class imbalance. 2. Establishes realistic performance baselines for multi-disorder EEG classification, demonstrating recall exceeding 80% for most disorders with significant gains for low-prevalence conditions after threshold calibration. 3. Provides physiologically plausible feature importance analysis that aligns with established clinical EEG markers, validating the model's clinical relevance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/636894ed25045336665fcbac593a58130411dff99c5d2a3e5a0cd50067ee44ec_w640_q70.webp
  - **Simple LLM Summary:** This study addresses the challenge of automated, multi-disorder screening from clinical EEG data by developing disorder-aware machine learning models with decision thresholds explicitly calibrated to prioritize diagnostic sensitivity. The method uses a multi-domain feature set and is evaluated on a large, heterogeneous dataset, achieving high recall for most neurological disorder categories. The results establish performance baselines and demonstrate that sensitivity-prioritized automated analysis can support scalable EEG screening and triage in clinical practice.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Clinically Calibrated Machine Learning Benchmarks for Large-Scale Multi-Disorder EEG Classification] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Manual EEG interpretation is slow and variable; existing automation lacks multi-disorder support.]
        C[主要方法/Method: Use multi-domain EEG features and train sensitivity-calibrated models under class imbalance.]
        D[关键结果/Results: High recall (>80%) for most disorders; feature importance aligns with clinical knowledge.]
    ```

- **[arXiv251230] INTERACT-CMIL: Multi-Task Shared Learning and Inter-Task Consistency for Conjunctival Melanocytic Intraepithelial Lesion Grading**
  - **tags:** [cv], [medical image analysis], [multi-task learning, inter-task consistency, digital pathology, foundation models, combinatorial partial supervision]
  - **authors:** Mert Ikinci, Luna Toma, Karin U. Loeffler, Leticia Ussem, Daniela Süsskind, Julia M. Weller, Yousef Yeganeh, Martina C. Herwig-Carl, Shadi Albarqouni
  - **institution:** University Hospital Bonn, Technical University of Munich
  - **link:** https://arxiv.org/pdf/2512.22666
  - **contributions:** 1. Introduces INTERACT-CMIL, a multi-head deep learning framework for jointly predicting five histopathological axes for CMIL grading. 2. Proposes a Shared Feature Learning with Combinatorial Partial Supervision and an Inter-Dependence Loss to enforce cross-task consistency. 3. Curates and evaluates on a new multi-center dataset, showing significant performance improvements over baselines and providing a reproducible benchmark.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ed4ee67160f114b6db4089d38a1fbeae9ea01e9231d6d4df14bea6d6144469c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the difficult problem of grading Conjunctival Melanocytic Intraepithelial Lesions (CMIL) by introducing INTERACT-CMIL, a multi-task deep learning framework that uses shared feature learning and an inter-dependence loss to jointly and consistently predict five diagnostic criteria. Evaluated on a new multi-center dataset, the method outperforms CNN and foundation model baselines, offering a coherent and interpretable computational tool for standardized diagnosis.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["INTERACT-CMIL: CMIL分级<br>INTERACT-CMIL: CMIL Grading"]
        Root --> Problem["核心问题/Problem<br>CMIL分级困难，主观性强<br>CMIL grading is difficult and subjective"]
        Root --> Method["主要方法/Method<br>多任务共享学习与任务间一致性<br>Multi-task Shared Learning & Inter-Task Consistency"]
        Root --> Results["关键结果/Results<br>性能显著提升，提供可解释预测<br>Significant performance gains, interpretable predictions"]
    ```

- **[arXiv251230] Investigating Deep Learning Models for Ejection Fraction Estimation from Echocardiography Videos**
  - **tags:** [cv], [medical image analysis], [3D Inception, two-stream networks, CNN-RNN, EchoNet-Dynamic, video analysis]
  - **authors:** Shravan Saranyan, Pramit Saha
  - **institution:** Branham High School, University of Oxford
  - **link:** https://arxiv.org/pdf/2512.22657
  - **contributions:** 1. A systematic investigation and comparison of multiple deep learning architectures (3D Inception, two-stream, CNN-RNN) for automated LVEF estimation from echocardiography videos. 2. Identification that modified 3D Inception architectures achieve the best performance (RMSE of 6.79%) on the EchoNet-Dynamic dataset. 3. Key insights on model design, including the tendency for smaller, simpler models to generalize better and the high sensitivity of performance to hyperparameters like kernel size and normalization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80971653578a1ff466eaae0a7007615dc054e9d7579f8916b800791a4f77026e_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates deep learning models for automating the estimation of left ventricular ejection fraction (LVEF) from echocardiography videos to address the time-consuming and variable nature of manual assessment. The authors systematically evaluate and modify several architectures, including 3D Inception, two-stream, and CNN-RNN models, finding that a modified 3D Inception model performs best. The study concludes that while these models show promise, they are prone to overfitting and their performance is highly sensitive to specific hyperparameter choices.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Investigating Deep Learning Models for Ejection Fraction Estimation from Echocardiography Videos] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[手动评估LVEF耗时且存在观察者间差异/Manual LVEF assessment is time-consuming and has inter-observer variability]
        C --> C1[系统评估3D Inception、双流和CNN-RNN架构/Systematically evaluate 3D Inception, two-stream, and CNN-RNN architectures]
        C --> C2[在EchoNet-Dynamic数据集上训练和评估/Train and evaluate on the EchoNet-Dynamic dataset]
        D --> D1[改进的3D Inception架构表现最佳，RMSE为6.79%/Modified 3D Inception achieves best performance (RMSE 6.79%)]
        D --> D2[更小、更简单的模型泛化能力更好/Smaller, simpler models generalize better]
    ```

- **[arXiv251230] Quantum Generative Models for Computational Fluid Dynamics: A First Exploration of Latent Space Learning in Lattice Boltzmann Simulations**
  - **tags:** [mlsys], [others], [Quantum Generative Models, Computational Fluid Dynamics, Lattice Boltzmann Method, Vector Quantized Variational Autoencoder, Quantum Circuit Born Machine]
  - **authors:** Achraf Hsain, Fouad Mohammed Abbou
  - **institution:** Al Akhawayn University
  - **link:** https://arxiv.org/pdf/2512.22672
  - **contributions:** 1. A complete open-source pipeline bridging CFD simulation and quantum machine learning. 2. The first empirical study of quantum generative modeling on compressed latent representations of physics simulations. 3. A comparative analysis of quantum (QCBM, QGAN) and classical (LSTM) generative models for a physics-derived latent distribution.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6094a8215d7304400e5580e08cc0e81135106aaf9b51ef11b7f4c5d62734237e_w640_q70.webp
  - **Simple LLM Summary:** This paper explores the application of quantum generative models to Computational Fluid Dynamics (CFD) data. The authors compress fluid simulation data into a discrete latent space using a VQ-VAE and then compare quantum (QCBM, QGAN) and classical (LSTM) models for generating samples from this distribution. Under their experimental conditions, the quantum models, particularly the QCBM, outperformed the classical baseline in generating samples closer to the true distribution.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Quantum Generative Models for CFD: Latent Space Learning in LBM Simulations"] --> Problem["核心问题/Problem: Modeling compressed CFD latent distributions"]
        Root --> Method["主要方法/Method: VQ-VAE compression + QCBM/QGAN vs LSTM"]
        Root --> Results["关键结果/Results: Quantum models (QCBM best) outperformed classical LSTM"]
    ```

- **[arXiv251230] Fragile Knowledge, Robust Instruction-Following: The Width Pruning Dichotomy in Llama-3.2**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [width pruning, expansion ratio, Maximum Absolute Weight (MAW), GLU-MLP, instruction-following]
  - **authors:** Pere Martra
  - **institution:** Universidad Internacional Menéndez Pelayo (UIMP)
  - **link:** https://arxiv.org/pdf/2512.22671
  - **contributions:** 1. Systematically characterizes a capability dichotomy where structured width pruning degrades parametric knowledge (e.g., MMLU) but significantly improves instruction-following (e.g., IFEval). 2. Discovers and quantifies a robust inverse correlation between factual knowledge and truthfulness, linking knowledge degradation under pruning to improved misconception discrimination. 3. Identifies the expansion ratio as a critical architectural parameter that selectively modulates cognitive capabilities, rather than just a compression metric, and quantifies its context-dependent efficiency trade-offs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4df6003ce0dd5672f67ef0c36b943a93c7cbb475cc96f2c7592e1f230af17d53_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates structured width pruning of GLU-MLP layers in Llama-3.2 models using the Maximum Absolute Weight (MAW) criterion. It finds that pruning creates a dichotomy: while parametric knowledge degrades, instruction-following improves and multi-step reasoning remains robust, challenging the assumption of uniform degradation. The main conclusion is that width pruning acts as a selective filter, reducing knowledge but preserving or enhancing behavioral alignment, with identified trade-offs in efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Fragile Knowledge, Robust Instruction-Following: The Width Pruning Dichotomy in Llama-3.2] --> B
        A --> C
        A --> D
        B[核心问题/Problem: How does structured width pruning affect different LLM capabilities?]
        C[主要方法/Method: MAW-guided pruning of GLU-MLP layers, varying expansion ratio]
        D[关键结果/Results: Knowledge ↓, Instruction-following ↑, Truthfulness ↑, Efficiency trade-offs]
    ```

- **[arXiv251230] Beyond Centralization: Provable Communication Efficient Decentralized Multi-Task Learning**
  - **tags:** [mlsys], [federated learning], [decentralized learning, multi-task representation learning, low-rank structure, communication complexity, projected gradient descent]
  - **authors:** Donghwa Kang, Shana Moothedath
  - **institution:** Iowa State University
  - **link:** https://arxiv.org/pdf/2512.22675
  - **contributions:** 1. Proposes a new alternating projected gradient descent and minimization algorithm for decentralized multi-task representation learning with provable accuracy guarantees. 2. Provides comprehensive theoretical analysis of time, communication, and sample complexities, showing communication complexity is independent of target accuracy. 3. Identifies regimes (e.g., large number of nodes, low bandwidth) where the decentralized algorithm can outperform centralized federated learning approaches.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96a6cd15411863b0b8dc43a27acc5efd5e57130db256aae85b8195706d6a64ca_w640_q70.webp
  - **Simple LLM Summary:** This paper studies decentralized multi-task representation learning where tasks share a low-rank structure. The authors propose a new alternating projected gradient descent algorithm with provable guarantees, showing its communication cost is independent of the target accuracy. Numerical simulations validate the theory and demonstrate scenarios where decentralized learning outperforms centralized federated methods.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Beyond Centralization: Provable Communication Efficient Decentralized Multi-Task Learning] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[数据稀缺环境下的去中心化多任务表示学习/Decentralized Multi-Task Representation Learning in Data-Scarce Environments]
    C --> C1[交替投影梯度下降与最小化算法/Alternating Projected Gradient Descent and Minimization Algorithm]
    D --> D1[通信复杂度与目标精度无关/Communication Complexity Independent of Target Accuracy]
    D --> D2[去中心化算法在特定场景下优于中心化方法/Decentralized Algorithm Outperforms Centralized Counterpart in Certain Regimes]
    ```

- **[arXiv251230] Multimodal Diffeomorphic Registration with Neural ODEs and Structural Descriptors**
  - **tags:** [cv], [medical image registration], [Neural ODEs, Structural Descriptors, Diffeomorphic Registration, Multimodal, Local Mutual Information]
  - **authors:** Salvador Rodriguez-Sanz, Monica Hernandez
  - **institution:** University of Zaragoza, Aragon Institute for Engineering Research (I3A)
  - **link:** https://arxiv.org/pdf/2512.22689
  - **contributions:** 1. Proposes an instance-specific multimodal diffeomorphic registration framework using Neural ODEs, eliminating the need for large training datasets and avoiding performance drop on unseen modalities. 2. Introduces three method variants that integrate modality-agnostic structural descriptors (image-based or feature-based) with local mutual information for similarity measurement. 3. Demonstrates superior performance, robustness to varying regularization, suitability for different deformation scales, and computational efficiency compared to state-of-the-art baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/064c09ec95bfe97d740e2afb1b657324c426af97aabecb55dcfa4db080514f55_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of existing nonrigid registration methods, which often require intensity correlation and are limited to monomodal settings. It proposes a multimodal diffeomorphic registration method that combines Neural ODEs with structural descriptors and local mutual information. The method shows superior accuracy, robustness, and efficiency in aligning medical images from different modalities without requiring extensive training data.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multimodal Diffeomorphic Registration with Neural ODEs and Structural Descriptors] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统算法假设强度相关，限于单模态/Traditional methods assume intensity correlation, limited to monomodal]
        B --> B2[学习模型需要大量数据，泛化性差/Learning-based models need large datasets, poor generalization]
        C --> C1[基于实例的框架/Instance-specific framework]
        C --> C2[使用神经ODE与结构描述符/Using Neural ODEs & Structural Descriptors]
        C --> C3[整合局部互信息/Integrating Local Mutual Information]
        D --> D1[超越SOTA结果/Surpassing SOTA results]
        D --> D2[对正则化鲁棒/Robust to varying regularization]
        D --> D3[高效且适用于不同尺度/Efficient & suitable for varying scales]
    ```

- **[arXiv251230] Learning with the $p$-adics**
  - **tags:** [ai], [representation learning], [p-adic numbers, ultrametric space, hierarchical representation, non-archimedean geometry, semantic networks]
  - **authors:** André F. T. Martins
  - **institution:** Instituto Superior Técnico, Universidade de Lisboa; Instituto de Telecomunicações
  - **link:** https://arxiv.org/pdf/2512.22692
  - **contributions:** 1. Proposes using the p-adic number field (Q_p) as an alternative to real numbers for machine learning, leveraging its ultrametric and hierarchical structure. 2. Develops foundational building blocks for classification, regression, and representation learning models and algorithms within the p-adic framework. 3. Demonstrates a novel application by representing simple Quillian semantic networks as compact p-adic linear networks, which is not achievable with real numbers.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec090da18463864436ff27e6cb4651eb7e01719b66dcdae5d6644770e6a7b488_w640_q70.webp
  - **Simple LLM Summary:** This paper explores using p-adic numbers, an ultrametric and non-archimedean field, as an alternative to real numbers for machine learning. It introduces theoretical models and algorithms for classification, regression, and representation learning, showing that p-adics enable compact representations of hierarchical structures like semantic networks. The work opens new research directions by leveraging the unique geometric properties of p-adic spaces.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Learning with the p-adics] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[现有ML基于实数域/Existing ML uses real numbers]
    B --> B2[是否可用其他域?/Alternative fields possible?]
    C --> C1[研究p-adic数域/Study p-adic number field Q_p]
    C --> C2[利用超度量结构/Exploit ultrametric structure]
    D --> D1[构建分类回归模型/Build classification & regression models]
    D --> D2[表示学习与语义网络/Representation learning & semantic networks]
    D --> D3[开启新研究方向/Open new research directions]
    ```

- **[arXiv251230] Predictive Modeling of Power Outages during Extreme Events: Integrating Weather and Socio-Economic Factors**
  - **tags:** [ai], [predictive modeling], [power outage prediction, LSTM, socio-economic factors, machine learning, resilience]
  - **authors:** Antar Kumar Biswas, Masoud H. Nazari
  - **institution:** Wayne State University
  - **link:** https://arxiv.org/pdf/2512.22699
  - **contributions:** 1. Proposes a novel learning-based framework specifically for predicting low-probability, high-consequence (LPHC) power outages during extreme events. 2. Integrates a comprehensive set of features from public data, including weather, socio-economic, infrastructure, and seasonal event data, to reveal community vulnerability patterns. 3. Empirically validates the framework on a large-scale Michigan dataset, demonstrating that the LSTM model achieves the lowest prediction error and identifying correlations between economic/infrastructure factors and outage occurrence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3d66053b661eb55e66139efa4ce581315354dbf33b1490862dcf700576f9ef5_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a machine learning framework to predict power outages caused by extreme events by integrating weather, socio-economic, and infrastructure data. The authors evaluate four models (RF, SVM, AdaBoost, LSTM) on a dataset from Michigan and find that the LSTM performs best, with results showing that better economic conditions and infrastructure are linked to fewer outages.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Predictive Modeling of Power Outages during Extreme Events<br>极端事件下的停电预测建模] --> B(核心问题/Problem: Predicting LPHC power outages<br>预测低概率高后果停电)
        A --> C(主要方法/Method: ML framework integrating multi-source data<br>集成多源数据的机器学习框架)
        A --> D(关键结果/Results: LSTM best; Socio-economic factors matter<br>LSTM最优；社会经济因素重要)
        B --> E(Data: EAGLE-I, weather, socio-economic, infrastructure<br>数据: 停电记录、天气、社会经济、基础设施)
        C --> F(Models: RF, SVM, AdaBoost, LSTM<br>模型: 随机森林、支持向量机、自适应提升、长短期记忆网络)
        D --> G(Conclusion: Stronger economy & infrastructure → fewer outages<br>结论: 经济与基础设施更强→停电更少)
    ```

- **[arXiv251230] What Matters in Deep Learning for Time Series Forecasting?**
  - **tags:** [ai], [time series forecasting], [channel-independence, locality, globality, forecasting model card]
  - **authors:** Valentina Moretti, Andrea Cini, Ivan Marisca, Cesare Alippi
  - **institution:** IDSIA (Università della Svizzera italiana), Politecnico di Milano
  - **link:** https://arxiv.org/pdf/2512.22702
  - **contributions:** 1. Analyzes the design space of deep learning for time series forecasting, emphasizing principles like locality and globality over specific sequence modeling layers. 2. Highlights how overlooked implementation details (e.g., parameter sharing) fundamentally alter model classes and empirical results. 3. Proposes an auxiliary forecasting model card to systematically characterize architectures based on key design choices, advocating for improved benchmarking practices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97a34d1ef2fb71ea41bf423f0bb9c22a61efb8b9f97da7ec25666712a5fa044b_w640_q70.webp
  - **Simple LLM Summary:** This paper critically examines deep learning architectures for time series forecasting, arguing that foundational design principles (e.g., locality vs. globality) are more crucial for accuracy than complex sequence modeling layers. It shows that simple, well-designed models can match state-of-the-art performance and reveals how implementation details significantly impact results. The authors propose a forecasting model card to standardize architecture characterization and call for a rethink of benchmarking practices.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root(What Matters in Deep Learning for Time Series Forecasting?) --> Problem(核心问题/Problem)
        Root --> Method(主要方法/Method)
        Root --> Results(关键结果/Results)
        Problem --> P1(大量新架构与矛盾结果难以评估组件贡献/Many new architectures and contradictory results make it hard to assess component contributions)
        Method --> M1(基于时间序列预测原则设计模型/Grounding model design on forecasting principles)
        Method --> M2(分析局部性与全局性等概念/Analyzing concepts like locality and globality)
        Method --> M3(提出辅助预测模型卡/Proposing an auxiliary forecasting model card)
        Results --> R1(设计原则比特定序列层更重要/Design principles more relevant than specific sequence layers)
        Results --> R2(简单设计可匹配SOTA/Simple, well-designed architectures can match SOTA)
        Results --> R3(呼吁重新思考基准测试实践/Call for rethinking benchmarking practices)
    ```

- **[arXiv251230] GHaLIB: A Multilingual Framework for Hope Speech Detection in Low-Resource Languages**
  - **tags:** [nlp], [hope speech detection], [transformer models, multilingual classification, low-resource languages, XLM-RoBERTa, UrduBERT]
  - **authors:** Ahmed Abdullah, Sana Fatima, Haroon Mahmood
  - **institution:** FAST-National University, Al Ain University
  - **link:** https://arxiv.org/pdf/2512.22705
  - **contributions:** 1. Proposes a multilingual framework for hope speech detection, specifically addressing the underrepresentation of low-resource languages like Urdu. 2. Applies and evaluates multiple pretrained transformer models (XLM-RoBERTa, mBERT, EuroBERT, UrduBERT) on the PolyHope-M 2025 benchmark for this task. 3. Demonstrates strong performance, achieving high F1-scores for Urdu classification, validating the use of existing multilingual models in low-resource settings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c79c484e6d35762080aa8d6e1dbf075222d30335d656555a46ddf73380d7fe88_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of resources for hope speech detection in low-resource languages by proposing a multilingual framework using pretrained transformer models like XLM-RoBERTa and UrduBERT. The method involves simple preprocessing and training classifiers, which achieve high F1-scores on the PolyHope-M 2025 benchmark, particularly for Urdu. The results show that existing multilingual models can be effectively implemented to identify hope speech and foster positive digital discourse in low-resource environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GHaLIB: 多语言希望语音检测框架 / GHaLIB: Multilingual Hope Speech Detection Framework] --> B[核心问题 / Problem]
        A --> C[主要方法 / Method]
        A --> D[关键结果 / Results]
        B --> B1[希望语音在NLP中代表性不足 / Hope speech underrepresented in NLP]
        B --> B2[低资源语言(如乌尔都语)缺乏资源 / Lack of resources for low-resource languages (e.g., Urdu)]
        C --> C1[使用预训练多语言Transformer模型 / Use pretrained multilingual Transformer models]
        C --> C2[简单预处理与分类器训练 / Simple preprocessing & classifier training]
        D --> D1[乌尔都语二元分类F1: 95.2% / Urdu binary F1: 95.2%]
        D --> D2[乌尔都语多类分类F1: 65.2% / Urdu multi-class F1: 65.2%]
        D --> D3[多语言模型适用于低资源环境 / Multilingual models viable for low-resource settings]
    ```

- **[arXiv251230] Memento-II: Learning by Stateful Reflective Memory**
  - **tags:** [ai], [reinforcement learning], [stateful reflective decision process, episodic memory, policy iteration, continual learning, retrieval-augmented generation]
  - **authors:** Jun Wang
  - **institution:** University College London (UCL)
  - **link:** https://arxiv.org/pdf/2512.22716
  - **contributions:** 1. Introduces the Stateful Reflective Decision Process (SRDP), a formal theoretical framework that models continual learning in LLM agents as a two-stage read-write interaction with episodic memory, linking it to policy evaluation and improvement. 2. Provides a theoretical analysis showing that the reflective learning process induces an equivalent Markov Decision Process, enabling the use of classical dynamic programming and RL tools, and establishes convergence guarantees when instantiated with entropy-regularised policy iteration. 3. Unifies heuristic approaches like case-based reasoning and retrieval-augmented generation with principled reinforcement learning, offering a rigorous mathematical foundation for building memory-augmented agents capable of online adaptation without parameter updates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e8cff3c4a9f9d7b57c397010c69f5ae95897e34df30b8e86c43079e22a76db_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a theoretical framework for continual learning in LLM agents that uses episodic memory and reflection instead of back-propagation. The core method formalizes learning as a Stateful Reflective Decision Process, where writing to memory is policy evaluation and reading from it is policy improvement. The main conclusion is that this framework provides a principled, convergent foundation for agents to self-improve through interaction without fine-tuning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Memento-II: Learning by Stateful Reflective Memory] --> B[核心问题/Problem: 缺乏理论解释/Lack of theoretical explanation for memory-based continual learning in LLM agents]
        A --> C[主要方法/Method: 状态化反思决策过程/Stateful Reflective Decision Process (SRDP) with read-write episodic memory]
        A --> D[关键结果/Results: 提供理论框架与收敛保证/Provides theoretical framework and convergence guarantees for optimal policy]
        C --> E[写入对应策略评估/Writing corresponds to policy evaluation]
        C --> F[读取对应策略改进/Reading corresponds to policy improvement]
    ```

- **[arXiv251230] Data Augmentation for Classification of Negative Pregnancy Outcomes in Imbalanced Data**
  - **tags:** [nlp], [text classification], [data augmentation, imbalanced dataset, social media analysis, natural language processing, pregnancy outcome]
  - **authors:** Md Badsha Biswas
  - **institution:** George Mason University
  - **link:** https://arxiv.org/pdf/2512.22732
  - **contributions:** 1. Proposes a novel approach to use public social media data (e.g., Twitter) as an adjunctive resource for studying negative pregnancy outcomes, addressing data scarcity in traditional epidemiological research. 2. Constructs an NLP pipeline to automatically identify and classify pregnancy experiences from unstructured, noisy social media text, distinguishing between positive and negative outcomes. 3. Investigates and evaluates various data augmentation techniques specifically to address the severe class imbalance inherent in social media data for this sensitive health domain.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb9c28a95fb880100ca20beffad94909ef9e73c38a75789c38961258454c014a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of classifying negative pregnancy outcomes from imbalanced social media data. It proposes an NLP pipeline to extract and categorize pregnancy experiences from Twitter and investigates data augmentation techniques to balance the dataset. The research demonstrates the viability of social media data as a supplementary resource for epidemiological studies on pregnancy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Data Augmentation for Classification of Negative Pregnancy Outcomes in Imbalanced Data] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[婴儿死亡率高，负面妊娠结局数据稀缺 / High infant mortality, scarce data on negative pregnancy outcomes]
        B --> B2[社交媒体数据不平衡、有噪声 / Social media data is imbalanced and noisy]
        C --> C1[构建NLP流水线分类妊娠结局 / Build NLP pipeline to classify pregnancy outcomes]
        C --> C2[使用数据增强处理不平衡数据 / Use data augmentation for imbalanced data]
        D --> D1[验证社交媒体数据作为辅助资源的可行性 / Validate social media data as an adjunctive resource]
        D --> D2[为未来健康研究提供框架 / Provide a framework for future health studies]
    ```

- **[arXiv251230] FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents**
  - **tags:** [mlsys], [agent system], [context folding, long-horizon RL, non-stationary observation, gradient dilution, selective segment training]
  - **authors:** Jiaqi Shao, Yufeng Miao, Wei Zhang, Bing Luo
  - **institution:** Hong Kong University of Science and Technology, Duke Kunshan University, Microsoft AI
  - **link:** https://arxiv.org/pdf/2512.22733
  - **code:** https://github.com/SHAO-Jiaqi757/FoldAct
  - **contributions:** 1. Separated loss computation for independent gradient signals on summary and action tokens to address gradient dilution. 2. Full context consistency loss to reduce distribution shift caused by policy-dependent observation changes. 3. Selective segment training to reduce computational cost by processing unique contexts efficiently.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebdb4b7ca8ea3a44c0e368eed5fbbebfc656b663cf280d1891abfbf823c742fa_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that treating context folding (history summarization) as a standard action in long-horizon RL for LLMs creates a non-stationary observation distribution, leading to training instability and inefficiency. It proposes FoldAct, a framework with three innovations—separated loss, consistency loss, and selective training—to stabilize training and improve efficiency. The method achieves stable training and a 5.19× speedup.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents] --> B[核心问题 / Problem]
        A --> C[主要方法 / Method]
        A --> D[关键结果 / Results]
        B --> B1[非平稳观测分布 / Non-stationary Observation Distribution]
        B --> B2[梯度稀释 / Gradient Dilution]
        B --> B3[计算成本高 / High Computational Cost]
        C --> C1[分离损失计算 / Separated Loss Computation]
        C --> C2[全上下文一致性损失 / Full Context Consistency Loss]
        C --> C3[选择性片段训练 / Selective Segment Training]
        D --> D1[稳定训练 / Stable Training]
        D --> D2[5.19倍加速 / 5.19× Speedup]
    ```

- **[arXiv251230] When Does Multi-Task Learning Fail? Quantifying Data Imbalance and Task Independence in Metal Alloy Property Prediction**
  - **tags:** [ai], [multi-task learning], [negative transfer, data imbalance, task independence, metal alloys, property prediction]
  - **authors:** Sungwoo Kang
  - **institution:** Korea University
  - **link:** https://arxiv.org/pdf/2512.22740
  - **contributions:** 1. Empirical demonstration of a dichotomy where MTL degrades regression but improves classification for metal alloy property prediction. 2. Quantitative analysis linking MTL failure to severe data imbalance and near-zero inter-task dependencies. 3. Practical guidelines for materials informatics: use independent models for precise regression and MTL for classification tasks requiring high recall.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c5a4e5491f4e12b8112ec2efc4d5432ecc40f379be7394990c01d0cb507caab_w640_q70.webp
  - **Simple LLM Summary:** This paper tests the assumption of Multi-Task Learning (MTL) in materials informatics by predicting three metal alloy properties. The results show MTL harms regression performance due to negative transfer from data imbalance but improves classification recall, as the properties are found to be independent. The work concludes with recommendations for when to use or avoid MTL in material discovery.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[When Does Multi-Task Learning Fail? <br/>多任务学习何时失效？] --> B{核心问题/Problem};
        A --> C{主要方法/Method};
        A --> D{关键结果/Results};
        B --> B1[MTL Assumption in Materials <br/>材料中的MTL假设];
        C --> C1[Compare STL, MTL, Structured MTL <br/>比较单任务、标准MTL、结构化MTL];
        D --> D1[Regression Degrades <br/>回归性能下降];
        D --> D2[Classification Improves <br/>分类性能提升];
        D --> D3[Properties Independent <br/>属性相互独立];
    ```

- **[arXiv251230] Bridging Global Intent with Local Details: A Hierarchical Representation Approach for Semantic Validation in Text-to-SQL**
  - **tags:** [nlp], [text-to-sql], [semantic validation, hierarchical representation, logical plan, abstract syntax tree, nested message passing neural network]
  - **authors:** Rihong Qiu, Zhibang Yang, Xinke Jiang, Weibin Liao, Xin Gao, Xu Chu, Junfeng Zhao, Yasha Wang
  - **institution:** Peking University
  - **link:** https://arxiv.org/pdf/2512.22744
  - **contributions:** 1. Proposed HEROSQL, a hierarchical SQL representation approach that integrates global intent (via Logical Plans) and local details (via Abstract Syntax Trees) for semantic validation. 2. Employed a Nested Message Passing Neural Network (NMPNN) to capture relational information in SQL and aggregate schema-guided semantics across LPs and ASTs. 3. Introduced an AST-driven sub-SQL augmentation strategy to generate high-quality negative samples for robust optimization of fine-grained semantic inconsistencies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2268a4534cffc0a143786b6b8d80dbddb03e7bf7ffd9234c8d468b2a06e151f0_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of semantic validation in Text-to-SQL systems by proposing HEROSQL, a hierarchical representation method that combines global intent and local SQL details using Logical Plans and Abstract Syntax Trees, enhanced by a Nested Message Passing Neural Network. It also introduces an AST-driven augmentation strategy for generating negative samples. Experiments show that HEROSQL outperforms state-of-the-art methods in detecting semantic inconsistencies, improving AUPRC by 9.40% and AUROC by 12.35% on average.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HEROSQL: Bridging Global Intent with Local Details] --> B[核心问题/Problem: Semantic validation in Text-to-SQL, capturing global intent and local details]
        A --> C[主要方法/Method: Hierarchical representation (LP + AST), NMPNN, AST-driven augmentation]
        A --> D[关键结果/Results: Outperforms SOTA, +9.40% AUPRC, +12.35% AUROC]
    ```

- **[arXiv251230] From Confounding to Learning: Dynamic Service Fee Pricing on Third-Party Platforms**
  - **tags:** [ai], [reinforcement learning], [demand learning, instrumental variables, deep neural networks, regret bound, confounding]
  - **authors:** Rui Ai, David Simchi-Levi, Feng Zhu
  - **institution:** Massachusetts Institute of Technology (MIT)
  - **link:** https://arxiv.org/pdf/2512.22749
  - **contributions:** 1. Developed an algorithm for dynamic service fee pricing with optimal regret, showing a phase transition based on supply-side noise. 2. Demonstrated that non-i.i.d. actions can serve as instrumental variables to address confounding in demand learning. 3. Proposed a novel homeomorphic construction to establish estimation bounds for learning demand with deep neural networks without requiring star-shapedness assumptions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a53b1242a3048a4f1795be36eec0fe0875f0b532bc8001a000dcba26693c66da_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the problem of dynamic service fee pricing on third-party platforms, where only equilibrium price and quantity are observable, creating a confounding demand learning problem. The authors develop an algorithm with optimal regret, using non-i.i.d. actions as instrumental variables and a novel homeomorphic construction for deep neural network-based demand estimation. The results show that supply-side noise fundamentally impacts learnability and the method is validated with simulations and real-world data from Zomato and Lyft.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["From Confounding to Learning: Dynamic Service Fee Pricing on Third-Party Platforms"]
        Root --> Problem["核心问题/Problem: 在混杂因素下学习需求/Demand Learning under Confounding"]
        Root --> Method["主要方法/Method: 使用非独立同分布行动作为工具变量/Using non-i.i.d. actions as Instrumental Variables"]
        Root --> Results["关键结果/Results: 最优遗憾与相变/Optimal Regret & Phase Transition"]
    ```

- **[arXiv251230] A Micro-Macro Machine Learning Framework for Predicting Childhood Obesity Risk Using NHANES and Environmental Determinants**
  - **tags:** [ai], [public health informatics], [multi-level modeling, XGBoost, environmental vulnerability index, NHANES, machine learning]
  - **authors:** Eswarasanthosh Kumar Mamillapalli, Nishtha Sharma
  - **institution:** n/a (Inferred from email: nishtha sharma@nh.gov suggests potential affiliation with a state health department, but no clear academic/research institution is specified. The other author's email is a personal Gmail address.)
  - **link:** https://arxiv.org/pdf/2512.22758
  - **contributions:** 1. Proposed a novel micro-macro machine learning framework that integrates individual-level health data with macro-level environmental data to predict childhood obesity risk. 2. Constructed a composite environmental vulnerability index (EnvScore) from USDA and EPA data to quantify state-level structural risk factors. 3. Demonstrated a scalable, data-driven modeling pipeline that reveals geographic alignment between high environmental burden and predicted individual obesity risk, enabling identification of environment-driven health disparities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7578fbec69afd6c4e44bd1d6715e6f98a34a451a47c81c03388bed0ae331bd4c_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a machine learning framework that combines individual health data from NHANES with environmental data (food access, air quality) from USDA/EPA to predict childhood obesity. The best-performing model was XGBoost, and a state-level environmental risk score was created. The study found a strong geographic correlation between areas of high environmental burden and high predicted obesity risk, showing the value of multi-scale data integration for public health.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Micro-Macro Machine Learning Framework for Predicting Childhood Obesity Risk<br>预测儿童肥胖风险的微-宏观机器学习框架] --> B(Problem: Childhood obesity is influenced by multi-level factors, but studies often analyze them independently.<br>核心问题: 儿童肥胖受多层面因素影响，但研究常孤立分析)
        A --> C(Method: Integrated NHANES microdata with USDA/EPA macrodata. Used ML models (e.g., XGBoost) and created an EnvScore index.<br>主要方法: 整合NHANES微观数据与USDA/EPA宏观数据。使用ML模型并创建EnvScore指数)
        A --> D(Results: XGBoost performed best. High environmental burden states aligned with high predicted obesity risk.<br>关键结果: XGBoost表现最佳。高环境负担州与高预测肥胖风险分布一致)
    ```

- **[arXiv251230] Active Constraint Learning in High Dimensions from Demonstrations**
  - **tags:** [ai], [robot learning], [active learning, constraint inference, Gaussian processes, learning from demonstration]
  - **authors:** Zheng Qiu, Chih-Yuan Chiu, Glen Chou
  - **institution:** Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.22757
  - **contributions:** 1. Proposes an iterative active constraint learning (ACL) algorithm that intelligently queries for new demonstrations to reduce constraint uncertainty. 2. Integrates a Gaussian process (GP) model within the learning from demonstrations (LfD) paradigm to represent and infer unknown constraints. 3. Demonstrates superior performance over a random-sampling baseline in recovering nonlinear constraints from sparse, informative demonstrations in high-dimensional settings with nonlinear dynamics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5acbf135d5aa431114b6b72db2fb101427cb6bd1e55fb1a8afd3028c0874cb4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the data inefficiency of learning unknown constraints from demonstrations by proposing an active learning algorithm. The method iteratively trains a Gaussian process on demonstration data to model constraints and uses the model's uncertainty to query for new, informative start/goal states to generate more demonstrations. Experiments show the approach outperforms a random-sampling baseline in accurately inferring constraints from fewer demonstrations in high-dimensional, nonlinear environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Active Constraint Learning in High Dimensions from Demonstrations") --> Problem("核心问题/Problem: Data-inefficient constraint inference from demonstrations")
        Root --> Method("主要方法/Method: Iterative active learning with Gaussian Processes")
        Root --> Results("关键结果/Results: Outperforms baseline with sparse, informative demonstrations")
    ```

- **[arXiv251230] Understanding the Mechanisms of Fast Hyperparameter Transfer**
  - **tags:** [ai], [hyperparameter optimization], [hyperparameter transfer, scale-aware hyperparameters, Maximal Update Parameterization (μP), compute-optimal grid search]
  - **authors:** Nikhil Ghosh, Denny Wu, Alberto Bietti
  - **institution:** Flatiron Institute, New York University
  - **link:** https://arxiv.org/pdf/2512.22768
  - **contributions:** 1. Develops a formal conceptual framework defining "fast" hyperparameter transfer and proves its equivalence to "useful" transfer for compute-optimal grid search. 2. Demonstrates that the fast transfer property is not universal and depends critically on problem structure, showing synthetic cases where it succeeds or fails. 3. Proposes and provides empirical evidence for a mechanistic hypothesis explaining fast transfer, decomposing the loss reduction into width-stable and width-sensitive components.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b19c9825d64e8e70117e18cd478466aaf2627a7a5167d401bcac21353870d508_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the mechanisms behind fast hyperparameter transfer, a strategy to reduce tuning costs by transferring optimal hyperparameters from small to large models. It formally defines fast transfer and shows it is computationally advantageous, then explains the phenomenon by hypothesizing a decomposition of the optimization trajectory into stable and sensitive components, supported by empirical evidence.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Understanding the Mechanisms of Fast Hyperparameter Transfer<br>理解快速超参数迁移的机制"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Standard HP tuning is too expensive for large models.<br>标准HP调优对于大模型过于昂贵"] --> P1["子问题/Sub-problem<br>How to define and understand 'fast' HP transfer?<br>如何定义和理解'快速'HP迁移？"]
        Method["主要方法/Method<br>Develop a formal framework for HP transfer.<br>建立HP迁移的形式化框架"] --> M1["方法步骤/Step<br>Define 'fast' vs 'useful' transfer.<br>定义'快速'与'有用'迁移"]
        Method --> M2["方法步骤/Step<br>Analyze problem structure & µP.<br>分析问题结构与µP"]
        Method --> M3["方法步骤/Step<br>Propose trajectory decomposition hypothesis.<br>提出轨迹分解假设"]
        Results["关键结果/Results<br>Fast transfer is equivalent to useful transfer.<br>快速迁移等价于有用迁移"] --> R1["结果/Result<br>Transfer success depends on problem structure.<br>迁移成功取决于问题结构"]
        Results --> R2["结果/Result<br>Empirical evidence supports the hypothesis.<br>实证证据支持该假设"]
    ```

- **[arXiv251230] Adapting, Fast and Slow: Transportable Circuits for Few-Shot Learning**
  - **tags:** [ai], [causal inference], [causal transportability, domain adaptation, few-shot learning, circuit composition, distribution shift]
  - **authors:** Kasra Jalaldoust, Elias Bareinboim
  - **institution:** Columbia University
  - **link:** https://arxiv.org/pdf/2512.22777
  - **contributions:** 1. Proposed Circuit-TR, an algorithm for zero-shot compositional generalization based on causal transportability theory, using modules learned from source data. 2. Introduced a supervised domain adaptation scheme that leverages circuit transportability without requiring an explicit causal graph, using only limited target data. 3. Provided theoretical characterization of few-shot learnable tasks using graphical circuit transportability criteria, linking generalizability to circuit size complexity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5b025a886304d6097d2893ec4af3bb34a59528db65e22ddf5b4dfff4439a096_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of generalization under distribution shift by proposing a method based on causal transportability theory. The method, Circuit-TR, learns local predictors (modules) from source data and composes them into a circuit for prediction in a target domain, enabling both zero-shot and few-shot adaptation. The theoretical results connect few-shot learnability to circuit transportability criteria and complexity, which are supported by simulations.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Adapting, Fast and Slow: Transportable Circuits for Few-Shot Learning] --> B[核心问题/Problem: Generalization under distribution shift]
    A --> C[主要方法/Method: Circuit-TR algorithm based on causal transportability]
    A --> D[关键结果/Results: Theoretical characterization of few-shot learnability]
    B --> B1[领域泛化与适应/Domain Generalization & Adaptation]
    C --> C1[模块学习与电路组合/Module Learning & Circuit Composition]
    C --> C2[因果图与机制共享/Causal Graph & Mechanism Sharing]
    D --> D1[可迁移性标准/Transportability Criteria]
    D --> D2[电路规模复杂度/Circuit Size Complexity]
    ```

- **[arXiv251230] GRExplainer: A Universal Explanation Method for Temporal Graph Neural Networks**
  - **tags:** [ai], [graph neural networks], [temporal graph neural networks, explainable ai, graph explanation, recurrent neural networks, breadth-first search]
  - **authors:** Xuyan Li, Jie Wang, Zheng Yan
  - **institution:** Xidian University
  - **link:** https://arxiv.org/pdf/2512.22772
  - **contributions:** 1. Proposes GRExplainer, a universal explanation method applicable to both snapshot-based and event-based Temporal Graph Neural Networks (TGNNs). 2. Introduces an efficient approach using breadth-first search and temporal information to construct node sequences, reducing computational cost. 3. Designs a user-friendly generative model based on Recurrent Neural Networks (RNNs) for automated and continuous explanation generation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0722c64cfeebe092d7b253f417faaa51990e69198068745c39fe241716082408_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of explainability in Temporal Graph Neural Networks (TGNNs) by proposing GRExplainer, a universal and efficient method that uses node sequences and an RNN-based generative model to provide explanations. Experiments on six datasets with three TGNNs demonstrate that GRExplainer outperforms existing methods in generality, efficiency, and user-friendliness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GRExplainer: A Universal Explanation Method for Temporal Graph Neural Networks] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[TGNN缺乏透明度和可解释性/Lack of TGNN transparency & explainability]
        B --> B2[现有方法通用性差、效率低、不友好/Existing methods lack generality, efficiency, user-friendliness]
        C --> C1[提取节点序列作为统一特征/Extract node sequences as unified features]
        C --> C2[使用BFS和时间信息构建序列/Use BFS & temporal info to construct sequences]
        C --> C3[基于RNN的生成模型/RNN-based generative model]
        D --> D1[在6个数据集上实验/Experiments on 6 datasets]
        D --> D2[优于现有基线方法/Outperforms existing baselines]
        D --> D3[通用、高效、用户友好/Generality, efficiency, user-friendliness]
    ```

- **[arXiv251230] Schrodinger AI: A Unified Spectral-Dynamical Framework for Classification, Reasoning, and Operator-Based Generalization**
  - **tags:** [ai], [quantum-inspired machine learning], [spectral decomposition, Hamiltonian learning, semantic wavefunctions, operator calculus, emergent manifolds]
  - **authors:** Truong Son Nguyen
  - **institution:** Arizona State University
  - **link:** https://arxiv.org/pdf/2512.22774
  - **contributions:** 1. A unified spectral-dynamical framework for machine learning inspired by quantum mechanics, comprising a time-independent wave-energy solver, a time-dependent dynamical solver, and a low-rank operator calculus. 2. Demonstration of emergent semantic manifolds that reflect class relations without explicit supervision, dynamic reasoning that adapts to changing environments, and exact operator generalization on symbolic tasks. 3. Proposing a new foundational direction for ML where learning is cast as discovering and navigating an underlying semantic energy landscape, offering an alternative to cross-entropy training and transformer attention.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58825c1201e17641b4e19a581a742615913539c66fbf08e5c113620bf7eec6de_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Schrödinger AI, a novel machine learning framework inspired by quantum mechanics that treats perception as spectral decomposition and reasoning as wavefunction dynamics. The method demonstrates robust generalization, interpretable semantics, and emergent topology on tasks like classification, maze navigation, and modular arithmetic. The results suggest a promising new paradigm for AI that learns by discovering an underlying semantic energy landscape.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Schrödinger AI: A Unified Spectral-Dynamical Framework<br>薛定谔AI: 统一谱-动力学框架"] --> Problem["核心问题/Problem<br>Limitations of conventional ML<br>传统机器学习的局限"]
        Root --> Method["主要方法/Method<br>Quantum-inspired framework<br>量子启发的框架"]
        Root --> Results["关键结果/Results<br>Empirical demonstrations<br>实证演示"]
        Problem --> P1["Struggle with uncertainty & adaptation<br>难以处理不确定性与适应性"]
        Problem --> P2["Brittle symbolic reasoning<br>脆弱的符号推理"]
        Method --> M1["Time-independent wave-energy solver<br>时间无关波能求解器"]
        Method --> M2["Time-dependent dynamical solver<br>时间相关动力学求解器"]
        Method --> M3["Low-rank operator calculus<br>低秩算子演算"]
        Results --> R1["Emergent semantic manifolds<br>涌现的语义流形"]
        Results --> R2["Dynamic reasoning adaptation<br>动态推理适应"]
        Results --> R3["Exact operator generalization<br>精确算子泛化"]
    ```

- **[arXiv251230] Discovering Transmission Dynamics of COVID-19 in China**
  - **tags:** [nlp], [information extraction], [natural language processing, transmission chain, epidemiological analysis, data mining, statistical analysis]
  - **authors:** Zhou Yang, Edward Dougherty, Chen Zhang, Zhenhe Pan, Fang Jin
  - **institution:** George Washington University, Roger Williams University, Texas Tech University
  - **link:** https://arxiv.org/pdf/2512.22787
  - **contributions:** 1. Constructed transmission/tracking chains for COVID-19 in China by applying NLP and manual curation to data mined from diverse public sources. 2. Conducted a comprehensive spatiotemporal analysis by integrating case tracking data with population mobility data from Wuhan. 3. Quantified key transmission dynamics, revealing regional differences, hospitalization timelines, and the evolution of infection sources over the course of the pandemic.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eca2aa3a96ff37b70cb26e6ad2cfa0f84cc9a5cf8c76b6e1404ce5fa2474828e_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the transmission dynamics of COVID-19 in China by mining and processing public case reports using NLP to construct transmission chains. The analysis integrates these chains with mobility data to quantify spatiotemporal spread. Key findings include significant regional differences in infection rates, rapid hospitalization of symptomatic cases, and a shift in infection sources from travel to social activities over time.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Discovering Transmission Dynamics of COVID-19 in China] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[分析中国COVID-19传播机制/Analyze China COVID-19 transmission mechanisms]
        C --> C1[从多源收集病例数据/Collect case data from multiple sources]
        C --> C2[应用NLP构建传播链/Apply NLP to construct transmission chains]
        C --> C3[结合移动数据进行统计分析/Combine mobility data for statistical analysis]
        D --> D1[大城市感染更多，存在地区差异/Larger cities have more infections, regional differences exist]
        D --> D2[79%有症状者5天内住院/79% symptomatic hospitalized within 5 days]
        D --> D3[感染源从旅行转向社交活动/Infection source shifted from travel to social activities]
    ```

- **[arXiv251230] CNSight: Evaluation of Clinical Note Segmentation Tools**
  - **tags:** [nlp], [text segmentation], [clinical note segmentation, transformer models, large language models, MIMIC-IV, rule-based baselines]
  - **authors:** Risha Surana, Adrian Law, Sunwoo Kim, Rishab Sridhar, Angxiao Han, Peiyu Hong
  - **institution:** University of Southern California
  - **link:** https://arxiv.org/pdf/2512.22795
  - **contributions:** 1. A comprehensive evaluation of diverse methods (rule-based, domain-specific transformers, and large language models) for the task of clinical note segmentation. 2. The curation and use of a dataset of 1,000 notes from MIMIC-IV for benchmarking segmentation performance. 3. Empirical findings that large API-based models (e.g., GPT-5-mini) achieve the best overall performance, while lightweight baselines remain competitive only on structured tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be9738f44f0f558dc344bd32b267879341b566035c5dbe67f97ac2e4529b479_w640_q70.webp
  - **Simple LLM Summary:** This paper evaluates various methods for segmenting unstructured clinical notes into distinct sections. It compares rule-based baselines, domain-specific transformers, and large language models on a curated dataset from MIMIC-IV. The main conclusion is that large API-based models like GPT-5-mini achieve the best overall segmentation performance, providing guidance for method selection in downstream clinical applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[CNSight: 临床笔记分割工具评估 / CNSight: Evaluation of Clinical Note Segmentation Tools]
        Root --> Problem[临床笔记非结构化 / Clinical Notes Unstructured]
        Root --> Method[评估规则/变换器/大语言模型 / Evaluate Rule-based/Transformer/LLMs]
        Root --> Results[大模型性能最佳 / Large Models Best Performance]
    ```

- **[arXiv251230] SNM-Net: A Universal Framework for Robust Open-Set Gas Recognition via Spherical Normalization and Mahalanobis Distance**
  - **tags:** [ai], [open-set recognition], [spherical normalization, Mahalanobis distance, electronic nose, open-set recognition, feature drift]
  - **authors:** Shuai Chen, Chen Wang, Ziran Wang
  - **institution:** School of Mechanical Engineering, Shandong University
  - **link:** https://arxiv.org/pdf/2512.22792
  - **contributions:** 1. A geometric decoupling mechanism using cascaded batch normalization and L2 normalization to project features onto a unit hypersphere, eliminating signal intensity fluctuations. 2. The introduction of Mahalanobis distance as a scoring mechanism to construct adaptive ellipsoidal decision boundaries that account for anisotropic feature distributions. 3. A universal, architecture-agnostic framework (SNM-Net) that can be seamlessly integrated with various backbone networks (CNN, RNN, Transformer) for robust open-set gas recognition.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d69d593ebbfea881a49530f570b5c2a934cb8b5cd782c1d7e7c9fba99a92906_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes SNM-Net, a universal framework for robust open-set gas recognition in electronic nose systems. It addresses signal drift and unknown interference by projecting features onto a hypersphere for intensity normalization and using Mahalanobis distance for scoring. The method achieves state-of-the-art performance with high accuracy and exceptional robustness across different sensor conditions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["SNM-Net: A Universal Framework for Robust Open-Set Gas Recognition"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Feature drift & unknown gas interference in E-nose"] --> P1["信号漂移/Feature Distribution Shift"]
        Problem --> P2["未知气体干扰/Unknown Gas Interference"]
        Method["主要方法/Method<br>SNM-Net Framework"] --> M1["几何解耦/Geometric Decoupling<br>Cascaded Batch & L2 Norm"]
        Method --> M2["马氏距离评分/Mahalanobis Distance Scoring"]
        Method --> M3["架构无关/Architecture-Agnostic<br>CNN, RNN, Transformer"]
        Results["关键结果/Results<br>State-of-the-art performance"] --> R1["高AUROC/High AUROC: 0.9977"]
        Results --> R2["高未知气体检测率/High Unknown Detection: 99.57%"]
        Results --> R3["强鲁棒性/High Robustness<br>Low std. dev."]
    ```

- **[arXiv251230] ReDiF: Reinforced Distillation for Few Step Diffusion**
  - **tags:** [mlsys], [diffusion models], [reinforcement learning, knowledge distillation, policy optimization, denoising paths, model agnostic]
  - **authors:** Amirhossein Tighkhorshid, Zahra Dehghanian, Gholamali Aminian, Chengchun Shi, Hamid R. Rabiee
  - **institution:** Sharif University of Technology, Alan Turing Institute, London School of Economics
  - **link:** https://arxiv.org/pdf/2512.22802
  - **contributions:** 1. Proposes a novel reinforcement learning framework for distilling diffusion models, treating distillation as a policy optimization problem. 2. Introduces a reward signal based on alignment with teacher outputs, allowing the student model to explore multiple denoising paths and take longer, optimized steps. 3. Demonstrates a model-agnostic framework that achieves superior performance with fewer inference steps and computational resources compared to existing distillation techniques.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73d47eb5443f9f8848454e65825da3569c70d954239d9794e6cff086fa5bc17a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the slow sampling problem in diffusion models by proposing ReDiF, a reinforcement learning-based distillation framework. Instead of using fixed losses, it treats distillation as policy optimization, using a reward signal to guide the student to take longer, optimized steps. The method achieves better performance with fewer steps and is applicable to various diffusion models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ReDiF: Reinforced Distillation for Few Step Diffusion] --> B(核心问题/Problem: Diffusion模型采样慢/Slow sampling in diffusion models)
        A --> C(主要方法/Method: 基于强化学习的蒸馏框架/Reinforcement learning based distillation framework)
        A --> D(关键结果/Results: 更少步骤，性能更优/Fewer steps, superior performance)
    ```

- **[arXiv251230] MoR: Mixture Of Representations For Mixed-Precision Training**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [mixed-precision training, FP8, dynamic quantization, tensor representation, low-precision training]
  - **authors:** Bor-Yiing Su, Peter Dykas, Mike Chrzanowski, Jatin Chhugani
  - **institution:** Nvidia, Meta
  - **link:** https://arxiv.org/pdf/2512.22804
  - **contributions:** 1. Proposes Mixture-of-Representations (MoR), a novel per-tensor and sub-tensor level quantization framework that dynamically selects numerical representations based on tensor properties. 2. Introduces and experiments with concrete algorithms that dynamically choose between FP8 and BF16 representations at different granularities. 3. Demonstrates a universal approach that preserves model quality across datasets and achieves state-of-the-art results with 98.38% of tensors quantized to FP8, showing potential for even lower precision formats like NVFP4.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14c70a65c4f996e1c88d9996c77e4d780e13466bf11a0601ad82d27376753968_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces MoR, a dynamic quantization framework for mixed-precision training that analyzes tensor properties to select between representations like FP8 and BF16. It achieves high FP8 quantization rates (98.38%) while maintaining model quality, offering a robust approach for low-precision training that can be combined with other methods for even lower precision formats.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[MoR: Mixture Of Representations For Mixed-Precision Training] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br>Successful mixed-precision training requires the right combination of methods.]
        Method[主要方法/Method<br>Dynamic, property-aware quantization framework selecting between representations (e.g., FP8/BF16).]
        Results[关键结果/Results<br>Achieves 98.38% FP8 quantization, preserves model quality, enables lower precision formats.]
    ```

- **[arXiv251230] Long-Range Distillation: Distilling 10,000 Years of Simulated Climate into Long Timestep AI Weather Models**
  - **tags:** [ai], [climate informatics], [long-range distillation, synthetic training data, subseasonal-to-seasonal forecasting, probabilistic forecasting, autoregressive models]
  - **authors:** Scott A. Martin, Noah Brenowitz, Dale Durran, Michael Pritchard
  - **institution:** NVIDIA Research, University of Washington
  - **link:** https://arxiv.org/pdf/2512.22814
  - **contributions:** 1. Proposes long-range distillation, a method to train a long-timestep probabilistic model using massive synthetic data from an autoregressive teacher model. 2. Demonstrates the generation and use of over 10,000 years of simulated climate data from the DLESyM model for training. 3. Shows that distilled models achieve S2S forecast skill comparable to ECMWF ensembles after fine-tuning, with skill scaling with synthetic data volume.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4b3dd444e162236a7d1cc0aaa69d999407d7ebf78184fada39f979dccbd0692f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of long-range weather forecasting by introducing long-range distillation, a method that trains a single-step probabilistic model using a massive synthetic dataset generated by an autoregressive AI model. The distilled model, trained on over 10,000 years of simulated climate, achieves subseasonal-to-seasonal forecast skill comparable to state-of-the-art ensemble methods, demonstrating that AI-generated synthetic data can effectively scale long-range forecast skill.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Long-Range Distillation Paper] --> B(核心问题/Problem: Long-range AI weather forecasting is limited by error accumulation and scarce training data for slow climate modes.)
        A --> C(主要方法/Method: Distill a long-timestep probabilistic student model using 10,000+ years of synthetic data from an autoregressive teacher model (DLESyM).)
        A --> D(关键结果/Results: Student model skill scales with synthetic data, approaches teacher skill, and matches ECMWF ensemble skill after ERA5 fine-tuning.)
    ```

- **[arXiv251230] TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [curriculum learning, goal-conditioned reinforcement learning, temporal variance, student-teacher paradigm, Q-function]
  - **authors:** Gaurav Chaudhary, Laxmidhar Behera
  - **institution:** IIT Kanpur
  - **link:** https://arxiv.org/pdf/2512.22824
  - **contributions:** 1. Proposes a novel Student-Teacher learning paradigm with a Temporal Variance-Driven Curriculum for accelerating Goal-Conditioned RL. 2. Establishes a theoretical connection between the temporal variance of Q-values and policy evolution. 3. Demonstrates the algorithm-agnostic nature of the approach, showing consistent improvements across 11 robotic manipulation and maze navigation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the sample inefficiency of uniform goal selection in multi-goal reinforcement learning. It proposes a TEACH framework where a teacher module dynamically selects goals with the highest temporal variance in Q-values to create an adaptive curriculum. The method is shown to improve learning efficiency over state-of-the-art curriculum learning methods across diverse robotic tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Uniform goal selection is sample inefficient in multi-goal RL/多目标RL中均匀目标选择样本效率低]
        C --> C1[Student-Teacher paradigm with Temporal Variance-Driven Curriculum/基于时序方差的师生课程学习范式]
        C --> C2[Teacher prioritizes goals with highest Q-value temporal variance/教师模块优先选择Q值时序方差最高的目标]
        D --> D1[Consistent improvements over SOTA methods/相比SOTA方法取得一致改进]
        D --> D2[Evaluated on 11 robotic manipulation and navigation tasks/在11个机器人操作与导航任务上验证]
    ```

- **[arXiv251230] ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning**
  - **tags:** [cv], [video generation], [Human-Object Interaction, Diffusion Transformer, Relative Coordinate Maps, Progressive Curriculum Learning, Geometry Consistency]
  - **authors:** Bangya Liu, Xinyu Gong, Zelin Zhao, Ziyang Song, Yulei Lu, Suhui Wu, Jun Zhang, Suman Banerjee, Hao Zhang
  - **institution:** University of Wisconsin-Madison, ByteDance, Georgia Institute of Technology, The Hong Kong Polytechnic University
  - **link:** https://arxiv.org/pdf/2512.22854
  - **code:** https://neutrinoliu.github.io/byteloom/
  - **contributions:** 1. Proposes ByteLoom, a Diffusion Transformer-based framework for generating realistic HOI videos with geometrically consistent objects. 2. Introduces the RCM-cache mechanism using Relative Coordinate Maps to maintain object geometry consistency and control 6-DoF transformations. 3. Designs a progressive training curriculum to compensate for HOI dataset scarcity and relax the need for fine-grained hand mesh annotations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9f5ff16308904b889be6695aafd24bfc28b798f080cc6c723a25066bcdc2bdf_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenges of poor cross-view consistency and reliance on hand mesh annotations in Human-Object Interaction (HOI) video generation. It proposes ByteLoom, a framework that uses a novel RCM-cache mechanism for geometry consistency and a progressive curriculum learning strategy for training. The method effectively preserves human identity and object geometry while generating smooth motion.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有方法缺乏多视图信息注入机制/Existing methods lack multi-view injection]
        B --> B2[严重依赖手部网格标注/Heavy reliance on hand mesh annotations]
        C --> C1[提出RCM-cache机制/Propose RCM-cache mechanism]
        C --> C2[设计渐进式课程学习/Design progressive curriculum learning]
        D --> D1[保持物体几何一致性/Preserves object geometry consistency]
        D --> D2[生成平滑运动视频/Generates smooth motion videos]
    ```

- **[arXiv251230] Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks**
  - **tags:** [sec], [blockchain security, IoT security, adversarial machine learning], [Fully Homomorphic Encryption, Attribute-Based Access Control, Multi-Agent Reinforcement Learning, Byzantine Fault Tolerance, Trust-Based Consensus]
  - **authors:** Soham Padia, Dhananjay Vaidya, Ramchandra Mangrulkar
  - **institution:** Northeastern University, Dwarkadas J. Sanghvi College of Engineering
  - **link:** https://arxiv.org/pdf/2512.22860
  - **contributions:** 1. Proposes a novel trust-based delegated consensus framework for blockchain IoT that integrates Fully Homomorphic Encryption (FHE) with Attribute-Based Access Control (ABAC) for privacy-preserving policy evaluation. 2. Systematically compares the performance of three reinforcement learning approaches (RL, DRL, MARL) against five distinct and sophisticated adversarial attack families. 3. Empirically demonstrates that Multi-Agent RL (MARL) provides superior defense against collusive attacks and identifies the catastrophic vulnerability of all learning agents to Time-Delayed Poisoning (sleeper) attacks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373f990d6c218afb4f9e660bb84fd86dc8e9d7006d2b7bdef3d956a991960bff_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses securing blockchain-enabled IoT networks by proposing a trust-based consensus framework that combines privacy-preserving techniques (FHE and ABAC) with learning-based defenses. It compares RL, DRL, and MARL against five attack types, finding MARL most effective against collusive attacks but revealing that all methods are highly vulnerable to time-delayed poisoning attacks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Adaptive Trust Consensus for Blockchain IoT<br/>区块链物联网自适应信任共识"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["Securing Blockchain IoT Against Attacks<br/>保护区块链物联网免受攻击"] --> A1["Naive Malicious Attack (NMA)<br/>简单恶意攻击"]
        Problem --> A2["Collusive Rumor Attack (CRA)<br/>合谋谣言攻击"]
        Problem --> A3["Adaptive Adversarial Attack (AAA)<br/>自适应对抗攻击"]
        Problem --> A4["Byzantine Fault Injection (BFI)<br/>拜占庭故障注入"]
        Problem --> A5["Time-Delayed Poisoning (TDP)<br/>时间延迟投毒"]
    
        Method["Trust Framework with FHE & ABAC + Learning Defenses<br/>基于FHE和ABAC的信任框架与学习防御"] --> M1["Reinforcement Learning (RL)<br/>强化学习"]
        Method --> M2["Deep RL (DRL)<br/>深度强化学习"]
        Method --> M3["Multi-Agent RL (MARL)<br/>多智能体强化学习"]
    
        Results["Key Experimental Findings<br/>关键实验结果"] --> R1["MARL best vs. Collusive Attacks<br/>MARL对合谋攻击最佳"]
        Results --> R2["DRL & MARL perfect vs. Adaptive Attacks<br/>DRL和MARL完美防御自适应攻击"]
        Results --> R3["All agents fail vs. Time-Delayed Poisoning<br/>所有智能体在延迟投毒攻击下失效"]
    ```

- **[arXiv251230] Reinforcement Networks: novel framework for collaborative Multi-Agent Reinforcement Learning tasks**
  - **tags:** [ai], [multi-agent reinforcement learning], [Reinforcement Networks, directed acyclic graph (DAG), credit assignment, LevelEnv, hierarchical RL]
  - **authors:** Maksim Kryzhanovskiy, Svetlana Glazyrina, Roman Ischenko, Konstantin Vorontsov
  - **institution:** Lomonosov Moscow State University, Institute for Artificial Intelligence, Lomonosov Moscow State University
  - **link:** https://arxiv.org/pdf/2512.22876
  - **contributions:** 1. Introduces the Reinforcement Networks framework, a general approach for collaborative MARL that organizes agents as vertices in a directed acyclic graph (DAG)., 2. Formalizes training and inference methods for the framework and connects it to the LevelEnv concept for reproducible construction and evaluation., 3. Demonstrates improved performance over standard MARL baselines and unifies hierarchical, modular, and graph-structured views of MARL.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b613175c92e9bdddfbd57ed84d044a5846b7b8148cca8ab0405e69847f66c33a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of end-to-end training for AI systems with multiple learnable components. It proposes Reinforcement Networks, a framework that organizes agents in a directed acyclic graph for flexible credit assignment and coordination in multi-agent reinforcement learning. The method shows improved performance over baselines and provides a principled foundation for designing complex multi-agent systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Reinforcement Networks] --> B[核心问题/Problem: End-to-end training of multi-component AI systems]
        A --> C[主要方法/Method: MARL agents organized in a DAG (Reinforcement Networks)]
        A --> D[关键结果/Results: Improved performance, unified framework for structured MARL]
    ```

- **[arXiv251230] Fundamental Novel Consistency Theory: $H$-Consistency Bounds**
  - **tags:** [ai], [statistical learning theory], [H-consistency bounds, surrogate loss, minimizability gaps, adversarial robustness, comp-sum losses]
  - **authors:** Yutao Zhong
  - **institution:** New York University
  - **link:** https://arxiv.org/pdf/2512.22880
  - **contributions:**  1. Introduces a novel theoretical framework for deriving H-consistency bounds, which provide stronger and more informative guarantees than Bayes-consistency or H-calibration by accounting for the hypothesis set. 2. Establishes the first H-consistency bounds for a wide range of losses in binary and multi-class classification, including convex surrogates, max/sum/constrained losses, and comp-sum losses (e.g., cross-entropy), and extends the analysis to adversarial scenarios. 3. Analyzes the growth rates of H-consistency bounds, proving a universal square-root growth rate for smooth surrogates, and introduces the analysis of minimizability gaps to guide the selection of surrogate loss functions for learning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16541a1efc1f9f95010f468aecfaeb95d92c6aea20df9566f6ef60456e371fde_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a new theoretical framework for analyzing the estimation error of target losses using surrogate losses in machine learning. It introduces H-consistency bounds, which offer stronger guarantees by incorporating the hypothesis set, and derives these bounds for various loss functions in both standard and adversarial settings. The main conclusion is that these bounds provide a more precise tool for understanding surrogate loss performance and can guide the design of robust learning algorithms.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Fundamental Novel Consistency Theory: H-Consistency Bounds] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1("训练损失与目标损失不一致<br/>Surrogate vs. Target Loss Mismatch")
        C --> C1("提出H-一致性边界理论框架<br/>Propose H-Consistency Bounds Framework")
        C --> C2("分析二元/多类分类的损失函数<br/>Analyze Losses for Binary/Multi-class")
        C --> C3("扩展到对抗性场景<br/>Extend to Adversarial Setting")
        D --> D1("得到紧的分布依赖/独立边界<br/>Tight Distribution-Dependent/Independent Bounds")
        D --> D2("首次为多种损失推导H-一致性边界<br/>First H-Consistency Bounds for Various Losses")
        D --> D3("证明平滑代理的平方根增长速率<br/>Square-Root Growth Rate for Smooth Surrogates")
    ```

- **[arXiv251230] Theory and Algorithms for Learning with Multi-Class Abstention and Multi-Expert Deferral**
  - **tags:** [ai], [machine learning theory], [multi-expert deferral, abstention, H-consistency, surrogate losses, two-stage learning]
  - **authors:** Anqi Mao
  - **institution:** New York University
  - **link:** https://arxiv.org/pdf/2512.22886
  - **contributions:** 1. Introduced new surrogate loss families and proved strong consistency guarantees for multi-class learning with abstention, resolving open questions. 2. Designed new surrogate losses with H-consistency bounds for general multi-expert deferral in classification, leading to effective algorithms. 3. Proposed a novel framework and surrogate losses for regression with deferral, accommodating multiple experts and various cost structures.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed6952a3ce4104bfb4e2da48692fa87841baf950369a1d08640407f2002ece4c_w640_q70.webp
  - **Simple LLM Summary:** This thesis addresses the problems of learning with abstention and multi-expert deferral to improve the reliability and efficiency of models like LLMs. It proposes new surrogate loss formulations for classification and regression, proves strong theoretical consistency guarantees, and demonstrates the empirical effectiveness of the resulting algorithms on datasets like CIFAR-10 and CIFAR-100.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Theory and Algorithms for Learning with Multi-Class Abstention and Multi-Expert Deferral"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题 / Problem<br>LLMs face hallucinations & high cost<br>Need reliable & efficient prediction"] --> P1["子问题1 / Sub-Problem 1<br>Learning with Abstention"]
        Problem --> P2["子问题2 / Sub-Problem 2<br>Multi-Expert Deferral"]
        Problem --> P3["子问题3 / Sub-Problem 3<br>Regression with Deferral"]
        Method["主要方法 / Method<br>Design new surrogate losses<br>Prove H-consistency guarantees"] --> M1["方法1 / Method 1<br>For abstention (score-based & predictor-rejector)"]
        Method --> M2["方法2 / Method 2<br>For multi-expert deferral"]
        Method --> M3["方法3 / Method 3<br>For regression deferral framework"]
        Results["关键结果 / Results<br>Strong consistency guarantees<br>Superior empirical performance"] --> R1["结果1 / Result 1<br>Resolved open questions in abstention"]
        Results --> R2["结果2 / Result 2<br>New effective algorithms for deferral"]
        Results --> R3["结果3 / Result 3<br>Versatile framework for regression"]
    ```

- **[arXiv251230] Debugging Tabular Log as Dynamic Graphs**
  - **tags:** [mlsys], [others], [dynamic graph, graph neural network, tabular log, log debugging, heterogeneous nodes]
  - **authors:** Chumeng Liang, Zhanyang Jin, Zahaib Akhtar, Mona Pereira, Haofei Yu, Jiaxuan You
  - **institution:** University of Illinois Urbana-Champaign, Amazon
  - **link:** https://arxiv.org/pdf/2512.22903
  - **contributions:** 1. Proposes GraphLogDebugger, a novel framework that models tabular log data as dynamic graphs with heterogeneous nodes for objects and events, 2. Demonstrates that a simple dynamic GNN can outperform large language models (LLMs) in debugging tasks using this graph representation, 3. Validates the approach on real-world datasets from computer systems and academic papers, showing improved flexibility and scalability over LLM-based methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bfc0dd96717274f366abd002f1a9147f7afbdaba795d251628919a0d25289925_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces GraphLogDebugger, a framework that converts tabular log data into dynamic graphs to detect inconsistencies in real-world systems. By representing logs as evolving graphs with object and event nodes, a lightweight dynamic Graph Neural Network effectively debugs logs, outperforming larger LLM-based models in experiments on system and academic log datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DEBUGGING TABULAR LOG AS DYNAMIC GRAPHS] --> B[核心问题/Problem: LLMs and heavy models lack flexibility and scalability for tabular log debugging]
        A --> C[主要方法/Method: GraphLogDebugger models logs as dynamic graphs with heterogeneous nodes and edges]
        A --> D[关键结果/Results: Simple dynamic GNN outperforms LLMs in debugging on real-world datasets]
    ```

- **[arXiv251230] A Neural Network-Based Real-time Casing Collar Recognition System for Downhole Instruments**
  - **tags:** [mlsys], [on-device ai], [Casing Collar Locator (CCL), ARM Cortex-M7, Depthwise Separable Convolutions, MACs, Inference Latency]
  - **authors:** Si-Yu Xiao, Xin-Di Zhao, Xiang-Zhan Wang, Tian-Hao Mao, Ying-Kai Liao, Xing-Yu Liao, Yu-Qiao Chen, Jun-Jie Wang, Shuang Liu, Tu-Pei Chen, Yang Liu
  - **institution:** University of Electronic Science and Technology of China, China National Petroleum Corporation Logging Co., Ltd., Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.22901
  - **contributions:** 1. Proposes an in-situ, real-time collar recognition system using embedded neural networks to overcome signal degradation in traditional surface-based monitoring. 2. Introduces lightweight "Collar Recognition Nets" (CRNs) optimized for resource-constrained ARM Cortex-M7 microprocessors, using temporal and depthwise separable convolutions. 3. Demonstrates a highly efficient model achieving 8,208 MACs, an F1 score of 0.972, and an average inference latency of 343.2 µs, proving feasibility for downhole power/space constraints.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/235a8bd15d5c0da93f1ea31dd4b6da44b238cc7be57fd42a7bef3e629f9c6495_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of accurate downhole positioning in oil/gas operations by developing a real-time, embedded neural network system for casing collar recognition. The method introduces lightweight "Collar Recognition Nets" optimized for ARM Cortex-M7 processors, achieving high accuracy with minimal computational cost. The results demonstrate that robust, autonomous signal processing is feasible within the severe power and space limitations of downhole instrumentation.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Neural Network-Based Real-time Casing Collar Recognition System<br>基于神经网络的实时套管接箍识别系统"] --> Problem
        Root --> Method
        Root --> Results
        Problem["信号衰减导致井下定位不准确<br>Signal degradation compromises downhole positioning"]
        Method["为ARM Cortex-M7优化的轻量级CRN网络<br>Lightweight CRNs optimized for ARM Cortex-M7"]
        Results["8208 MACs, F1=0.972, 343.2µs延迟<br>8208 MACs, F1=0.972, 343.2µs latency"]
    ```

- **[arXiv251230] Federated Multi-Task Clustering**
  - **tags:** [mlsys], [federated learning], [federated clustering, spectral clustering, multi-task learning, tensor methods, ADMM]
  - **authors:** S. Dai, G. Sun, F. Li, X. Tang, Q. Wang, Y. Cong
  - **institution:** South China University of Technology, Dalian University of Technology, Xidian University
  - **link:** https://arxiv.org/pdf/2512.22897
  - **contributions:** 1. Proposes a novel Federated Multi-Task Clustering (FMTC) framework that learns personalized models for heterogeneous clients while capturing shared knowledge in a privacy-preserving manner. 2. Introduces a client-side parameterized mapping model for robust out-of-sample inference, eliminating the need for unreliable pseudo-labels. 3. Develops a server-side tensorial correlation module using low-rank regularization on a unified model tensor to explicitly discover common subspace across clients, solved via a privacy-preserving ADMM-based distributed algorithm.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e64c06637c228c53ac30a2069610927ac906eea1fc53a050d87f6f985e001ab_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes FMTC, a federated multi-task clustering framework that addresses the limitations of centralized spectral clustering and unreliable pseudo-labels in federated settings. It combines client-side personalized clustering models with a server-side tensorial module to capture shared knowledge, using an ADMM-based algorithm for efficient, privacy-preserving optimization. Experiments show FMTC outperforms existing federated clustering methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Federated Multi-Task Clustering] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Centralized models inapplicable to decentralized environments/集中式模型不适用于去中心化环境]
        B --> B2[Poor generalization due to unreliable pseudo-labels/伪标签不可靠导致泛化性能差]
        B --> B3[Failure to capture latent client correlations/未能捕获客户端间的潜在关联]
        C --> C1[Client-side personalized clustering module/客户端个性化聚类模块]
        C --> C2[Server-side tensorial correlation module/服务器端张量关联模块]
        C --> C3[ADMM-based distributed algorithm/基于ADMM的分布式算法]
        D --> D1[Outperforms baselines and SOTA/性能优于基线和前沿方法]
        D --> D2[Validated on real-world datasets/在真实数据集上得到验证]
    ```

- **[arXiv251230] MetaCD: A Meta Learning Framework for Cognitive Diagnosis based on Continual Learning**
  - **tags:** [ai], [educational data mining], [cognitive diagnosis, meta-learning, continual learning, long-tailed distribution, parameter protection mechanism]
  - **authors:** Jin Wu, Chanjin Zheng
  - **institution:** Shanghai Institute of Artificial Intelligence for Education, East China Normal University
  - **link:** https://arxiv.org/pdf/2512.22904
  - **contributions:** 1. Proposes MetaCD, a novel framework that integrates meta-learning and continual learning for cognitive diagnosis. 2. Uses meta-learning to learn an optimal initialization to alleviate the long-tailed data problem, enabling good performance with few samples. 3. Incorporates a continual learning parameter protection mechanism to adapt to dynamic data changes and new tasks while preventing catastrophic forgetting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d62de4bde455a8e131e7247a8b8ce8fa94feb82289f4b3dc1660955e7645dfa_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes MetaCD, a meta-learning framework based on continual learning, to address the challenges of long-tailed data distribution and dynamic changes in cognitive diagnosis for intelligent education. It uses meta-learning for optimal initialization and a parameter protection mechanism for continual adaptation, achieving superior accuracy and generalization on five real-world datasets compared to baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[MetaCD: A Meta Learning Framework for Cognitive Diagnosis based on Continual Learning] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[长尾数据分布/Long-tailed Data Distribution]
        Problem --> P2[数据的动态变化/Dynamic Data Changes]
        Method[主要方法/Method] --> M1[元学习最优初始化/Meta-learning for Optimal Initialization]
        Method --> M2[持续学习参数保护机制/Continual Learning Parameter Protection]
        Results[关键结果/Results] --> R1[提升单任务可塑性/Improves Single-task Plasticity]
        Results --> R2[确保序列任务稳定性与泛化性/Ensures Sequential Task Stability & Generalization]
        Results --> R3[在五个真实数据集上超越基线/Outperforms Baselines on Five Real-world Datasets]
    ```

- **[arXiv251230] Sat-EnQ: Satisficing Ensembles of Weak Q-Learners for Reliable and Compute-Efficient Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [Q-learning, ensemble learning, satisficing, distillation, bounded rationality]
  - **authors:** Ünver Çiftçi
  - **institution:** Tekirdağ Namık Kemal University
  - **link:** https://arxiv.org/pdf/2512.22910
  - **contributions:** 1. Proposes a two-phase framework (Sat-EnQ) that first trains an ensemble of lightweight Q-networks using a satisficing objective to limit early value growth and reduce variance. 2. Provides theoretical proof that the satisficing objective induces bounded updates and cannot increase target variance, with a corollary for substantial reduction. 3. Demonstrates empirical results including significant variance reduction, elimination of catastrophic failures, robustness to noise, and improved compute efficiency compared to baseline methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d12c2382ed5ee9e4da47d1775097d950b626f676e5d3552cd0ff19b6c385b2a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the instability of deep Q-learning, especially early in training, by introducing Sat-EnQ. This framework first trains a satisficing ensemble of weak Q-learners to produce stable, low-variance estimates, then distills and fine-tunes the ensemble. The method significantly improves training reliability, robustness, and computational efficiency compared to standard approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Sat-EnQ] --> B[核心问题/Problem: Deep Q-Learning Instability]
        A --> C[主要方法/Method: Two-Phase Satisficing Ensemble]
        A --> D[关键结果/Results: Variance Reduction & Robustness]
        B --> B1[早期训练不稳定/Early Training Instability]
        B --> B2[高方差与灾难性失败/High Variance & Catastrophic Failure]
        C --> C1[阶段1: 满足化集成训练/Phase 1: Satisficing Ensemble Training]
        C --> C2[阶段2: 蒸馏与微调/Phase 2: Distillation & Fine-tuning]
        D --> D1[3.8倍方差降低/3.8x Variance Reduction]
        D --> D2[0%灾难性失败/0% Catastrophic Failure]
        D --> D3[2.5倍计算效率提升/2.5x Compute Efficiency]
    ```

- **[arXiv251230] Geometric Structural Knowledge Graph Foundation Model**
  - **tags:** [ai], [knowledge graph reasoning], [structural foundation model, geometric attention, inductive link prediction, multi-head transformation, relational fusion]
  - **authors:** Ling Xin, Mojtaba Nayyeri, Zahra Makki Nayeri, Steffen Staab
  - **institution:** University of Stuttgart, University of Southampton, Shahrood University of Technology
  - **link:** https://arxiv.org/pdf/2512.22931
  - **contributions:** 1. Proposes Gamma, a novel structural KG foundation model that replaces the single relational transformation with multiple parallel geometric transformations (real, complex, split-complex, dual). 2. Introduces a relational conditioned attention fusion mechanism with entropy regularization to adaptively fuse these geometric representations at the link level. 3. Provides a full formalization of the algebraic message functions and demonstrates through extensive experiments on 56 KGs that Gamma consistently outperforms the prior state-of-the-art (Ultra) in zero-shot inductive link prediction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1926af9f65861ace968c86c6c18e3eaa892e2114d0d505e3fce8a7ae39975f1_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies a key limitation in existing structural knowledge graph foundation models: their reliance on a single relational transformation limits their ability to capture diverse relational patterns. To address this, the authors propose Gamma, a new model that employs multi-head geometric attention, using parallel transformations from different algebraic spaces and a fusion mechanism to adaptively combine them. Comprehensive experiments show that Gamma outperforms the previous best model, Ultra, in zero-shot inductive link prediction across diverse benchmarks, demonstrating the benefit of complementary geometric representations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Geometric Structural Knowledge Graph Foundation Model] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有方法依赖单一关系转换，表达能力受限/Existing methods rely on single relational transformation, limiting expressiveness]
        C --> C1[引入多头几何注意力/Multi-head geometric attention]
        C --> C2[并行多种几何变换/Parallel geometric transformations]
        C --> C3[关系条件注意力融合/Relational conditioned attention fusion]
        D --> D1[在56个KG上超越ULTRA/Outperforms ULTRA on 56 KGs]
        D --> D2[零样本归纳链接预测性能提升/Improves zero-shot inductive link prediction]
    ```

- **[arXiv251230] Multiple Token Divergence: Measuring and Steering In-Context Computation Density**
  - **tags:** [nlp], [language model interpretability], [in-context computation, KL divergence, decoding method, computational effort, prediction head]
  - **authors:** Vincent Herrmann, Eric Alcaide, Michael Wand, Jürgen Schmidhuber
  - **institution:** The Swiss AI Lab IDSIA/USI/SUPSI, King Abdullah University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.22944
  - **contributions:** 1. Proposes Multiple Token Divergence (MTD), a simple and non-invasive metric to measure a language model's in-context computational effort by comparing the output distributions of the full model and a shallow auxiliary head. 2. Introduces Divergence Steering, a novel decoding method that uses MTD to control the computational character of generated text. 3. Empirically demonstrates that MTD effectively distinguishes task complexity, correlates with problem difficulty, and that lower MTD is associated with more accurate reasoning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef98fdc1c198bde00876e87ff3cca172c3925998a10f9847042108bebc8c5e99_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of measuring the in-context computational effort of language models. It proposes Multiple Token Divergence (MTD), a lightweight metric based on KL divergence between output distributions, and a corresponding decoding method called Divergence Steering. The authors show that MTD effectively correlates with task difficulty and can be used to analyze and steer model computation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multiple Token Divergence<br/>多令牌散度] --> B[核心问题/Problem<br/>如何衡量语言模型的上下文计算努力？<br/>How to measure in-context computational effort?]
        A --> C[主要方法/Method<br/>提出多令牌散度(MTD)<br/>Propose Multiple Token Divergence (MTD)]
        A --> D[关键结果/Results<br/>MTD有效区分任务复杂度<br/>MTD effectively distinguishes task complexity]
        B --> B1[现有指标如下一令牌损失无效<br/>Metrics like next-token loss fail]
        C --> C1[计算完整模型与浅层辅助头的输出分布KL散度<br/>KL divergence between full model and shallow head outputs]
        C --> C2[提出散度引导解码方法<br/>Propose Divergence Steering decoding]
        D --> D1[MTD与问题难度正相关<br/>MTD correlates positively with problem difficulty]
        D --> D2[低MTD与更准确的推理相关<br/>Lower MTD associated with more accurate reasoning]
    ```

- **[arXiv251230] APO: Alpha-Divergence Preference Optimization**
  - **tags:** [ai], [reinforcement learning from human feedback (rlhf)], [alpha-divergence, preference optimization, mode collapse, anchored coordinates, gradient variance]
  - **authors:** Wang Zixian
  - **institution:** China Mobile Communications Group Shandong Co., Ltd. Tai’an Branch
  - **link:** https://arxiv.org/pdf/2512.22953
  - **contributions:** 1. Introduces APO, an anchored framework using Csiszár alpha-divergence to continuously interpolate between forward and reverse KL behavior for RLHF. 2. Derives unified gradient dynamics parameterized by alpha and analyzes gradient variance properties. 3. Proposes a practical reward-and-confidence-guarded alpha schedule to transition from mode-covering to mode-seeking behavior safely.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a407212dc95985ef8918d58e7c65f70fd3f6adf8764c95f85871cd1924b3528_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the trade-off between stable but under-exploitative mode-covering updates and high-reward but unstable mode-seeking updates in LLM alignment. It proposes APO, an anchored preference optimization framework that uses alpha-divergence to smoothly interpolate between these regimes via a guarded schedule. Experiments show APO achieves competitive performance while maintaining training stability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[APO: Alpha-Divergence Preference Optimization] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[两种分歧权衡 / Two Divergence Trade-off]
        P1 --> P2[前向KL覆盖但保守 / Forward KL: Mode-Covering but Conservative]
        P1 --> P3[反向KL寻求但易崩溃 / Reverse KL: Mode-Seeking but Collapses]
        Method[主要方法/Method] --> M1[锚定框架 / Anchored Framework]
        M1 --> M2[使用α-散度插值 / Use α-Divergence to Interpolate]
        M2 --> M3[调度α值 / Schedule α Value]
        Results[关键结果/Results] --> R1[竞争性性能 / Competitive Performance]
        Results --> R2[保持稳定性 / Maintains Training Stability]
    ```

- **[arXiv251230] FLOW: A Feedback-Driven Synthetic Longitudinal Dataset of Work and Wellbeing**
  - **tags:** [other], [synthetic data generation], [synthetic dataset, longitudinal data, feedback-driven simulation, behavioral modeling, benchmarking]
  - **authors:** Wafaa El Husseini
  - **institution:** Not explicitly stated. Affiliation inferred from email domain (gmail) is insufficient. Likely independent or institutional affiliation not provided in the excerpt.
  - **link:** https://arxiv.org/pdf/2512.22956
  - **contributions:** 1. Introduces FLOW, a novel synthetic longitudinal dataset modeling daily interactions between workload, lifestyle, and wellbeing. 2. Provides a configurable data generation tool for reproducible experimentation under adjustable assumptions. 3. Creates a publicly available, controlled experimental environment for methodological development and benchmarking where real-world data is inaccessible.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abeb0ef64c6a9a1178335cb2abf4717155e2b0e41b97fbf7173bb6448bdb8de9_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces FLOW, a synthetic longitudinal dataset generated via a rule-based, feedback-driven simulation to model daily interactions between work and wellbeing variables. It addresses the lack of accessible real-world data due to privacy and logistical constraints. The dataset and its configurable generation tool are released as a public resource to support reproducible research, methodological benchmarking, and education.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FLOW: A Feedback-Driven Synthetic Longitudinal Dataset of Work and Wellbeing] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[缺乏可访问的纵向工作与福祉数据/Lack of accessible longitudinal work-wellbeing data]
        B --> B2[隐私、伦理和后勤约束/Privacy, ethical, and logistical constraints]
        C --> C1[基于规则的反馈驱动模拟/Rule-based, feedback-driven simulation]
        C --> C2[生成合成数据集/Generate synthetic dataset]
        D --> D1[包含1000个个体的两年每日数据/2-year daily data for 1000 individuals]
        D --> D2[可配置的数据生成工具/Configurable data generation tool]
        D --> D3[公开可用的基准测试资源/Publicly available benchmarking resource]
    ```

- **[arXiv251230] A Context-Aware Temporal Modeling through Unified Multi-Scale Temporal Encoding and Hierarchical Sequence Learning for Single-Channel EEG Sleep Staging**
  - **tags:** [ai], [biomedical signal processing], [multi-scale feature extraction, hierarchical BiLSTM, class-weighted loss, temporal modeling, sleep staging]
  - **authors:** Amirali Vakili, Salar Jahanshiri, Armin Salimi-Badr
  - **institution:** Shahid Beheshti University
  - **link:** https://arxiv.org/pdf/2512.22976
  - **contributions:** 1. Proposes a context-aware and interpretable framework combining compact multi-scale feature extraction with hierarchical temporal modeling (BiLSTM) for single-channel EEG sleep staging. 2. Addresses class imbalance, especially for the N1 stage, using class-weighted loss functions and data augmentation techniques. 3. Introduces a sub-epoch chunking and probability averaging strategy to enhance contextual representation and robustness in predictions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c34e7add689f932eed2a6d2c02f530d1c09fc8e52104033716567656d05392d_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a novel deep learning framework for automatic sleep staging using single-channel EEG. The method integrates multi-scale feature extraction with hierarchical sequence learning (BiLSTM) and employs strategies like chunk-based probability averaging to handle class imbalance and improve context modeling. The approach achieves state-of-the-art performance on the SleepEDF datasets, with a significant improvement in detecting the challenging N1 sleep stage, while maintaining model interpretability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题: A Context-Aware Temporal Modeling for EEG Sleep Staging] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[睡眠分期/Sleep Staging]
        B --> B2[类别不平衡/Class Imbalance]
        B --> B3[模型可解释性/Interpretability]
        C --> C1[多尺度特征提取/Multi-scale Feature Extraction]
        C --> C2[分层时序建模/Hierarchical Temporal Modeling (BiLSTM)]
        C --> C3[数据增强与加权损失/Data Augmentation & Weighted Loss]
        D --> D1[总体准确率 89.72%/Overall Accuracy 89.72%]
        D --> D2[宏平均F1分数 85.46%/Macro F1-score 85.46%]
        D --> D3[N1阶段F1分数 61.7%/N1 Stage F1-score 61.7%]
    ```

- **[arXiv251230] Fusion or Confusion? Multimodal Complexity Is Not All You Need**
  - **tags:** [mlsys], [multi-modal training], [multimodal learning, late-fusion, hyperparameter tuning, empirical study, reliability checklist]
  - **authors:** Tillmann Rheude, Roland Eils, Benjamin Wild
  - **institution:** Berlin Institute of Health at Charité - Universitätsmedizin Berlin, Intelligent Medicine Institute at Fudan University, Freie Universität Berlin
  - **link:** https://arxiv.org/pdf/2512.22991
  - **contributions:** 1. A large-scale benchmark of 19 multimodal architectures under a unified experimental protocol across nine diverse datasets. 2. The proposal of SimBaMM, a simple late-fusion Transformer baseline, which performs comparably to more complex methods under standardized conditions. 3. The provision of a pragmatic reliability checklist to promote robust and trustworthy future evaluations in multimodal learning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d808ed59e8dc58198573816741433c5c0873c34c1d5fe67d63a8ffb9d40342a6_w640_q70.webp
  - **Simple LLM Summary:** This paper challenges the assumption that architectural complexity is necessary for performance in multimodal learning. Through a large-scale empirical study, it shows that a simple late-fusion Transformer baseline (SimBaMM) performs comparably to 19 more complex methods when all are rigorously tuned and evaluated under standardized conditions. The authors argue for a shift in research focus from architectural novelty to methodological rigor.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Fusion or Confusion? Multimodal Complexity Is Not All You Need] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 多模态学习中的架构复杂性是否必要？<br>Is architectural complexity necessary in multimodal learning?]
        C[主要方法/Method: 大规模实证研究，提出简单基线SimBaMM<br>Large-scale empirical study, propose simple baseline SimBaMM]
        D[关键结果/Results: 复杂方法并不稳定优于简单基线<br>Complex methods do not reliably outperform simple baseline]
    ```

- **[arXiv251230] Merge before Forget: A Single LoRA Continual Learning via Continual Merging**
  - **tags:** [mlsys], [llm training], [continual learning, LoRA, catastrophic forgetting, orthogonal basis, parameter-efficient]
  - **authors:** Fuli Qiao, Mehrdad Mahdavi
  - **institution:** The Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2512.23017
  - **contributions:** 1. Proposes a novel continual learning method that sequentially merges LoRA updates into a single unified LoRA, maintaining constant memory complexity with respect to the number of tasks. 2. Introduces orthogonal basis extraction from previous LoRA to initialize new task learning, minimizing task interference. 3. Employs a time-aware scaling mechanism to balance new and old knowledge during merging, improving performance over asymmetric LoRA merging.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68eb3af6647a5e47f9615997c14929688be663c5428838d0271ab503cc1b8c78_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the issues of memory growth and task interference in LoRA-based continual learning for LLMs. It proposes a method that orthogonally initializes and sequentially merges LoRAs into a single LoRA, using a time-aware scaling mechanism. The approach demonstrates effectiveness and efficiency in mitigating catastrophic forgetting while maintaining constant memory usage.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Merge before Forget: A Single LoRA Continual Learning via Continual Merging"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Catastrophic forgetting, memory growth, task interference in LoRA continual learning"] --> P1["参数增长/Parameter growth"]
        Problem --> P2["任务干扰/Task interference"]
        Method["主要方法/Method<br>Orthogonal initialization & sequential merging of LoRAs"] --> M1["正交初始化/Orthogonal basis initialization"]
        Method --> M2["持续合并/Continual merging"]
        Method --> M3["时间感知缩放/Time-aware scaling"]
        Results["关键结果/Results<br>Constant memory, minimized interference, improved performance"] --> R1["恒定内存/Constant memory complexity"]
        Results --> R2["最小化干扰/Minimized task interference"]
        Results --> R3["性能提升/Improved performance"]
    ```

- **[arXiv251230] Is Chain-of-Thought Really Not Explainability? Chain-of-Thought Can Be Faithful without Hint Verbalization**
  - **tags:** [nlp], [interpretability], [chain-of-thought, faithfulness, causal mediation analysis, biasing features, explainability]
  - **authors:** Kerem Zaman, Shashank Srivastava
  - **institution:** UNC Chapel Hill
  - **link:** https://arxiv.org/pdf/2512.23032
  - **contributions:** 1. Argues that the Biasing Features metric conflates unfaithfulness with incompleteness in Chain-of-Thought explanations. 2. Introduces a new faithful@k metric showing increased token budgets improve hint verbalization. 3. Uses Causal Mediation Analysis to show non-verbalized hints can still causally mediate predictions through the CoT.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/527440e442abe55ce371c5ad3ce8f49609f0398a6001b33523b6a3aa4bbc6e44_w640_q70.webp
  - **Simple LLM Summary:** This paper challenges the use of hint-verbalization metrics like Biasing Features for evaluating the faithfulness of Chain-of-Thought reasoning. It proposes that apparent unfaithfulness is often due to incompleteness from lossy compression and tight token limits, not a lack of alignment, and demonstrates this using new metrics and causal mediation analysis. The conclusion advocates for a broader interpretability toolkit beyond hint-based evaluations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Is Chain-of-Thought Really Not Explainability?<br/>Chain-of-Thought Can Be Faithful without Hint Verbalization] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Biasing Features 指标将不完整性误判为不忠实性<br/>Biasing Features metric mislabels incompleteness as unfaithfulness]
        C --> C1[提出 faithful@k 指标并增加推理令牌预算<br/>Propose faithful@k metric & increase inference token budget]
        C --> C2[使用因果中介分析<br/>Use Causal Mediation Analysis]
        D --> D1[许多被标记为不忠实的 CoT 被其他指标判定为忠实<br/>Many CoTs flagged unfaithful are judged faithful by other metrics]
        D --> D2[更大的令牌预算显著提高提示词显化率<br/>Larger token budgets greatly increase hint verbalization]
        D --> D3[未显化的提示词仍可通过 CoT 因果中介预测<br/>Non-verbalized hints can causally mediate predictions through CoT]
    ```

- **[arXiv251230] Mechanistic Analysis of Circuit Preservation in Federated Learning**
  - **tags:** [mlsys], [federated learning], [Mechanistic Interpretability, circuit collapse, weight sparsity, Intersection-over-Union, Non-IID data]
  - **authors:** Muhammad Haseeb, Salaar Masood, Muhammad Abdullah Sohail
  - **institution:** Lahore University of Management Sciences
  - **link:** https://arxiv.org/pdf/2512.23043
  - **code:** https://github.com/ha405/FedMI
  - **contributions:** 1. Proposes a novel mechanistic interpretability (MI) framework to analyze the internal failure mode of FedAvg under Non-IID data, introducing the concept of "circuit collapse". 2. Demonstrates the use of inherently interpretable, weight-sparse neural networks to identify and track functional circuits across clients and communication rounds in FL. 3. Provides the first mechanistic evidence, quantified via Intersection-over-Union (IoU), that Non-IID data causes structural circuit divergence and degradation, reframing statistical drift as a failure of mechanistic preservation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34be0814c16f6dee307b048c588d94abf81104abdb1f1491d1c23901df46fc7d_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates why Federated Learning (FedAvg) performance degrades under Non-IID data by applying Mechanistic Interpretability. The method uses weight-sparse networks to identify and track functional "circuits" across clients, measuring their preservation with IoU. The main conclusion is that Non-IID data causes "circuit collapse" due to conflicting updates, providing a mechanistic explanation for the accuracy drop.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Mechanistic Analysis of Circuit Preservation in Federated Learning] --> B
        A --> C
        A --> D
        B[核心问题/Problem: FL在Non-IID数据下性能下降的机制原因/Mechanistic cause of FL performance drop under Non-IID data]
        C[主要方法/Method: 使用可解释的稀疏网络识别和追踪电路/Using interpretable sparse networks to identify & track circuits]
        D[关键结果/Results: Non-IID数据导致电路崩溃，首次提供机制性证据/Non-IID data causes circuit collapse, first mechanistic evidence]
    ```

- **[arXiv251230] PI-MFM: Physics-informed multimodal foundation model for solving partial differential equations**
  - **tags:** [ai], [scientific machine learning], [physics-informed neural networks, multimodal foundation model, partial differential equations, multi-operator learning, zero-shot fine-tuning]
  - **authors:** Min Zhu, Jingmin Sun, Zecheng Zhang, Hayden Schaeffer, Lu Lu
  - **institution:** Yale University, Johns Hopkins University, University of Notre Dame, University of California Los Angeles
  - **link:** https://arxiv.org/pdf/2512.23056
  - **contributions:** 1. Proposes a physics-informed multimodal foundation model (PI-MFM) framework that directly enforces governing PDEs during both pretraining and adaptation, moving beyond purely data-driven approaches. 2. Introduces a method that takes symbolic PDE representations as input and automatically assembles PDE residual losses via vectorized derivative computation, enabling unified physics-informed training across diverse equation families. 3. Demonstrates effective zero-shot physics-informed fine-tuning to unseen PDE families, achieving low error using only PDE residuals and initial/boundary conditions without labeled solution data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db03e9853bb30e32977fcd1b0e24e9037354712e7841661bdbb52b955e3b2849_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes PI-MFM, a physics-informed multimodal foundation model framework for solving partial differential equations. It integrates governing equations directly into the training and adaptation process, enabling data-efficient and transferable learning of PDE solution operators. The method outperforms data-driven models, especially with sparse data, and shows strong zero-shot adaptation capabilities to new PDE families.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[PI-MFM: Physics-informed multimodal foundation model for solving PDEs] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有多算子学习方法数据依赖性强且忽略物理规律/Existing multi-operator learning is data-hungry and neglects physics]
        C --> C1[提出物理信息多模态基础模型框架/Propose physics-informed multimodal foundation model (PI-MFM) framework]
        C --> C2[输入符号PDE表示，自动组装残差损失/Input symbolic PDEs, auto-assemble residual losses]
        C --> C3[在预训练和适配中直接强制执行控制方程/Directly enforce governing equations in pretraining & adaptation]
        D --> D1[在13个PDE基准上优于纯数据驱动模型/Outperforms data-driven models on 13 PDE benchmarks]
        D --> D2[在稀疏数据、噪声下更鲁棒/More robust with sparse data & noise]
        D --> D3[实现零样本物理信息微调至未见PDE族/Achieves zero-shot physics-informed fine-tuning to unseen PDE families]
    ```

- **[arXiv251230] The Reward Model Selection Crisis in Personalized Alignment**
  - **tags:** [nlp], [alignment & personalization], [reward-guided decoding, policy accuracy, Pref-LaMP benchmark]
  - **authors:** Fady Rezk, Yuangang Pan, Chuan-Sheng Foo, Xun Xu, Nancy Chen, Henry Gouk, Timothy Hospedales
  - **institution:** University of Edinburgh, Agency for Science, Technology and Research (A*STAR)
  - **link:** https://arxiv.org/pdf/2512.23067
  - **contributions:** 1. Identifies and demonstrates the failure of standard reward model (RM) accuracy as a selection criterion for deployment-ready personalized alignment. 2. Introduces a new metric, policy accuracy, to evaluate the token-level discrimination ability of reward models under inference-time adaptation (reward-guided decoding). 3. Introduces Pref-LaMP, the first personalized alignment benchmark with ground-truth user completions, enabling direct behavioral evaluation and revealing a decoupling between reward discrimination and actual generation quality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1a0a1bd7d940db8c394f189ea84b7dbcfae7cd34b8e3662ea7c7a8babfdfefe_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies a crisis in personalized alignment, showing that optimizing reward models for preference ranking accuracy does not translate to effective behavioral adaptation under realistic deployment constraints like reward-guided decoding. The authors propose a new metric (policy accuracy) and a new benchmark (Pref-LaMP) to evaluate this gap, finding that reward model accuracy poorly predicts generation quality and that simple in-context learning often outperforms reward-guided methods for larger models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Reward Model Selection Crisis in Personalized Alignment] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Standard RM accuracy fails to predict deployment performance for personalized alignment]
        C[主要方法/Method<br>Introduce policy accuracy metric and Pref-LaMP benchmark for direct evaluation]
        D[关键结果/Results<br>Weak correlation between RM & policy accuracy; ICL outperforms reward-guided decoding]
    ```

- **[arXiv251230] Breaking the Memory Wall: Exact Analytical Differentiation via Tiled Operator-Space Evolution**
  - **tags:** [mlsys], [memory & caching], [Selective State Space Models, analytical differentiation, memory complexity, Tiled Operator-Space Evolution, Phase Gradient Flow]
  - **authors:** Shuhuan Wang, Yuzhen Xie, Jiayi Li, Yinliang Diao
  - **institution:** South China Agricultural University
  - **link:** https://arxiv.org/pdf/2512.23068
  - **contributions:** 1. Introduces Phase Gradient Flow (PGF), a framework for computing exact analytical derivatives for SSMs without materializing the intermediate computational graph. 2. Proposes Tiled Operator-Space Evolution (TOSE) to reframe SSM dynamics, achieving O(1) memory complexity relative to sequence length. 3. Demonstrates significant practical improvements, including a 94% reduction in peak VRAM and a 23x throughput increase, enabling chromosome-scale sensitivity analysis on a single GPU.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/821c684e39ce34e6f8c4157ec1cc31189105864e7ee30f0d13f0b32203a73fc5_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the O(L) memory bottleneck in gradient-based sensitivity analysis for Selective State Space Models (SSMs). It proposes Phase Gradient Flow (PGF), which uses Tiled Operator-Space Evolution (TOSE) to compute exact analytical derivatives with O(1) memory complexity. This enables the handling of extreme-length sequences (e.g., 128,000 steps) on consumer hardware, significantly reducing memory usage and increasing throughput compared to standard backpropagation.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Breaking the Memory Wall: Exact Analytical Differentiation via Tiled Operator-Space Evolution] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[SSM梯度分析存在O(L)内存墙/SSM Gradient Analysis has O(L) Memory Wall]
    C --> C1[相位梯度流 (PGF) 框架/Phase Gradient Flow (PGF) Framework]
    C --> C2[平铺算子空间演化 (TOSE)/Tiled Operator-Space Evolution (TOSE)]
    D --> D1[O(1) 内存复杂度/O(1) Memory Complexity]
    D --> D2[94% VRAM减少, 23x 吞吐提升/94% VRAM Reduction, 23x Throughput Gain]
    D --> D3[支持超长序列 (128k步) 分析/Enables Extreme-Length (128k-step) Analysis]
    ```

- **[arXiv251230] Rethinking Fine-Tuning: Unlocking Hidden Capabilities in Vision-Language Models**
  - **tags:** [ai], [vision-language models], [Mask Fine-Tuning (MFT), Parameter Efficient Fine-Tuning (PEFT), Low-Rank Adaptation (LoRA), structural reparameterization]
  - **authors:** Mingyuan Zhang, Yue Bai, Yifan Wang, Yiyang Huang, Yun Fu
  - **institution:** Northeastern University
  - **link:** https://arxiv.org/pdf/2512.23073
  - **code:** https://github.com/Ming-K9/MFT-VLM
  - **contributions:** 1. Proposes applying Mask Fine-Tuning (MFT), a structural reparameterization method, to Vision-Language Models (VLMs) for adaptation., 2. Demonstrates that MFT, which learns gating scores for weights instead of updating them, consistently outperforms LoRA variants and full fine-tuning., 3. Reveals that effective adaptation can emerge from reestablishing connections within a model's existing knowledge, not just from updating weights.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92b8916bd08492d9f9fbfd3b3a163d12c7de7a6a1fe0822bc6d711ca118dfb28_w640_q70.webp
  - **Simple LLM Summary:** This paper rethinks fine-tuning for Vision-Language Models (VLMs) by applying Mask Fine-Tuning (MFT), a method that learns to gate existing weights instead of updating them. Experiments show MFT surpasses both Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA and full fine-tuning, demonstrating that reorganizing internal subnetworks is a powerful alternative to weight updates.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Rethinking Fine-Tuning: Unlocking Hidden Capabilities in Vision-Language Models<br>重新思考微调：解锁视觉语言模型的隐藏能力"]
        Root --> Problem["Problem: Traditional fine-tuning overlooks underutilized structures in pre-trained VLMs.<br>核心问题：传统微调忽略了预训练VLM中未充分利用的结构。"]
        Root --> Method["Method: Apply Mask Fine-Tuning (MFT) to VLMs for structural reparameterization.<br>主要方法：将掩码微调（MFT）应用于VLM进行结构重参数化。"]
        Root --> Results["Results: MFT surpasses LoRA and full fine-tuning without altering the backbone.<br>关键结果：MFT超越了LoRA和全参数微调，且不改变主干网络。"]
    ```

- **[arXiv251230] FLEX-MoE: Federated Mixture-of-Experts with Load-balanced Expert Assignment**
  - **tags:** [mlsys], [federated learning], [Mixture-of-Experts, Federated Learning, Load Balancing, Expert Assignment, Non-IID Data]
  - **authors:** Boyang Zhang, Xiaobing Chen, Songyang Zhang, Shuai Zhang, Xiangwei Zhou, Mingxuan Sun
  - **institution:** The affiliations are not explicitly listed in the provided content. Based on the author names and common patterns, it is likely from a Chinese university or research institute (e.g., Tsinghua University, Peking University, Chinese Academy of Sciences). A specific institution cannot be reliably inferred.
  - **link:** https://arxiv.org/pdf/2512.23070
  - **contributions:** 1. Proposes FLEX-MoE, a novel federated MoE framework that jointly optimizes expert assignment and load balancing under limited client capacity. 2. Introduces client-expert fitness scores to quantify expert suitability for local datasets using training feedback. 3. Employs an optimization-based algorithm to maximize client-expert specialization while enforcing balanced expert utilization system-wide.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4afb2d6d1d993854d25c34b1c5c48d2b0479953fa05feac83a247dd11404202_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenges of deploying Mixture-of-Experts models in Federated Learning, specifically resource constraints on edge devices and expert load imbalance caused by non-IID data. It proposes FLEX-MoE, a framework that uses client-expert fitness scores and an optimization algorithm to assign experts to clients for specialization while balancing system-wide expert utilization. Experiments on three datasets show that FLEX-MoE achieves superior performance and maintains balanced expert utilization in resource-constrained scenarios.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[FLEX-MoE: Federated Mixture-of-Experts with Load-balanced Expert Assignment] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[资源受限设备/Resource-constrained Edge Devices]
        Problem --> P2[专家负载不均衡/Expert Load Imbalance]
        Method[主要方法/Method] --> M1[客户端-专家适应度分数/Client-Expert Fitness Scores]
        Method --> M2[基于优化的专家分配/Optimization-based Expert Assignment]
        Results[关键结果/Results] --> R1[性能优越/Superior Performance]
        Results --> R2[保持专家负载均衡/Maintains Balanced Expert Utilization]
    ```

- **[arXiv251230] Trust Region Masking for Long-Horizon LLM Reinforcement Learning**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [trust region, policy gradient, off-policy mismatch, KL divergence, sequence-level masking]
  - **authors:** Yingru Li, Jiacai Liu, Jiawei Xu, Yuxuan Tong, Ziniu Li, Baoxiang Wang
  - **institution:** (Institutions not explicitly listed in provided content; inferred from author names and common affiliations in the field, but not specified. Therefore, output is left blank.)
  - **link:** https://arxiv.org/pdf/2512.23075
  - **contributions:** 1. Deriving two novel, tighter theoretical bounds (Pinsker-Marginal and Mixed) on the approximation error in off-policy LLM-RL, scaling better with sequence length than classical O(T^2) bounds. 2. Identifying that these bounds depend on a sequence-level quantity (maximum token-level KL divergence) that cannot be controlled by token-independent methods like PPO clipping. 3. Proposing the Trust Region Masking (TRM) algorithm, which masks entire sequences from gradient updates to enforce the trust region, providing non-vacuous monotonic improvement guarantees for long-horizon tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74d8872516a568f2933a83e36b0cf25d414f3a25ffa113cd0cee809d2b39c6ac_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem that classical trust region bounds become vacuous for long-horizon LLM reinforcement learning due to unavoidable off-policy mismatch. It proposes Trust Region Masking (TRM), a method that excludes entire sequences from gradient computation if any token violates a trust region constraint. This approach, supported by new tighter theoretical bounds, provides the first non-vacuous monotonic improvement guarantees for long-horizon LLM-RL.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Trust Region Masking for Long-Horizon LLM RL] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Off-policy mismatch in LLM-RL<br/>导致经典信任域边界失效]
        C --> C1[提出信任域掩码(TRM)<br/>Propose Trust Region Masking (TRM)]
        C1 --> C2[序列级掩码<br/>Sequence-level Masking]
        D --> D1[推导更紧的理论边界<br/>Derive Tighter Bounds (O(T), O(T^{3/2}))]
        D --> D2[提供非平凡的单调改进保证<br/>Provide Non-vacuous Guarantees]
    ```

- **[arXiv251230] Multimodal Functional Maximum Correlation for Emotion Recognition**
  - **tags:** [ai], [multimodal learning], [self-supervised learning, dual total correlation, functional maximum correlation analysis, affective computing, physiological signals]
  - **authors:** Deyang Zheng, Tianyi Zhang, Wenming Zheng, Shujian Yu
  - **institution:** Southeast University, Westlake University, Vrije Universiteit Amsterdam
  - **link:** https://arxiv.org/pdf/2512.23076
  - **code:** https://github.com/DY9910/MFMC
  - **contributions:** 1. Proposes a novel self-supervised learning framework (MFMC) that maximizes higher-order multimodal dependence using a Dual Total Correlation objective. 2. Derives a tight sandwich bound and optimizes it using a functional maximum correlation analysis-based trace surrogate to capture joint interactions. 3. Demonstrates state-of-the-art or competitive performance on affective computing benchmarks, showing robustness to inter-subject variability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/369b23e1c7a17085940402e88d2347afb3386819a237c48ac347be73127aea2a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of learning joint dynamics from scarce and subjective emotion labels by proposing a self-supervised learning framework called MFMC. It captures higher-order multimodal dependencies beyond pairwise alignment, leading to improved emotion recognition performance on physiological signal benchmarks. The results show significant accuracy gains, particularly in subject-independent settings, highlighting the method's effectiveness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MFMC for Emotion Recognition] --> B[核心问题/Problem: 情感状态表现为跨系统的协调但异质的生理反应，现有自监督方法难以捕捉多模态高阶交互。]
        A --> C[主要方法/Method: 提出MFMC框架，通过Dual Total Correlation目标和Functional Maximum Correlation Analysis最大化高阶多模态依赖性。]
        A --> D[关键结果/Results: 在多个基准测试中达到SOTA或竞争性性能，显著提升CEAP-360VR数据集上的准确率，对主体间变异性鲁棒。]
    ```

- **[arXiv251230] Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning**
  - **tags:** [mlsys], [llm training], [reinforcement learning, training-inference mismatch, vocabulary pruning, gradient estimation, numerical stability]
  - **authors:** Yingru Li, Jiawei Xu, Jiacai Liu, Yuxuan Tong, Ziniu Li, Tianle Cai, Ge Zhang, Qian Liu, Baoxiang Wang
  - **institution:** (Institutions not explicitly listed in provided content. Affiliation inference requires author list with affiliations or email domains, which are not present in the given text. Therefore, cannot be determined from the provided snippet.)
  - **link:** https://arxiv.org/pdf/2512.23087
  - **contributions:** 1. Proves that the training-inference mismatch in LLM RL has an asymmetric effect, where the bound on log-probability mismatch scales with (1-p), making low-probability "tail" tokens the primary source of instability. 2. Proposes a novel method to stabilize RL training by dynamically pruning the vocabulary to exclude the extreme tail tokens, trading large, biased mismatches for a small, bounded optimization bias. 3. Provides both empirical demonstration of stable training and a theoretical bound on the optimization bias introduced by the proposed vocabulary pruning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83b750895381feb238b14991a4015088fa8d05eb24ab0374082f6c25fb3ddd7_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a fundamental training-inference mismatch in LLM reinforcement learning caused by differing numerical precision between high-throughput inference and stable training systems. To address this, the authors propose dynamically pruning low-probability "tail" tokens from the vocabulary during RL optimization, which stabilizes training by replacing large, biased errors with a small, bounded bias. Both theoretical analysis and empirical results support the effectiveness of this method.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[训练-推理不匹配 / Training-Inference Mismatch]
        B1 --> B2[尾部token导致梯度不稳定 / Tail tokens destabilize gradient estimation]
        C --> C1[动态剪枝词汇表 / Dynamic Vocabulary Pruning]
        C1 --> C2[排除极端尾部token / Exclude extreme tail tokens]
        D --> D1[实现稳定训练 / Achieves stable training]
        D --> D2[理论界定优化偏差 / Theoretically bounds optimization bias]
    ```

- **[arXiv251230] A Note on Hybrid Online Reinforcement and Imitation Learning for LLMs: Formulations and Algorithms**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [Imitation Learning, Reinforcement Learning, KL divergence, Dense Gradient, Sparse Gradient]
  - **authors:** Yingru Li, Ziniu Li, Jiacai Liu
  - **institution:** Not explicitly stated in provided content.
  - **link:** https://arxiv.org/pdf/2512.23097
  - **contributions:** 1. Derives the exact gradient decomposition of a unified KL+reward objective into analytic Dense and sampled Sparse terms. 2. Provides an efficient logit-level gradient formula for GPU implementation. 3. Establishes mathematical equivalence to KL-regularized RLHF and discusses training curriculum implications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a unified framework for fine-tuning LLMs that integrates Imitation Learning and Reinforcement Learning. It analyzes the gradient of a combined objective to decompose it into a token-level Dense Gradient and a long-horizon Sparse Gradient, enabling efficient implementation. The work clarifies its relationship to existing methods like RLHF and discusses practical training considerations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Hybrid Online RL and IL for LLMs] --> B[核心问题/Problem: Train-inference distribution mismatch in LLM fine-tuning]
        A --> C[主要方法/Method: Unified framework combining Imitation Learning and Reinforcement Learning]
        A --> D[关键结果/Results: Gradient decomposes into Dense Gradient (analytic) and Sparse Gradient (sampled)]
    ```

- **[arXiv251230] Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients**
  - **tags:** [ai], [reinforcement learning], [reinforcement learning, vision-language model, supervised fine-tuning, generalization paradox, cross-dataset transferability]
  - **authors:** Armin Berger, Manuela Bergau, Helen Schneider, Saad Ahmad, Tom Anglim Lagones, Gianluca Brugnara, Martha Foltyn-Dumitru, Kai Schlamp, Philipp Vollmuth, Rafet Sifa
  - **institution:** Fraunhofer IAIS, University of Bonn, Lamarr Institute, Department of Health Queensland, Griffith University, University Hospital Bonn
  - **link:** https://arxiv.org/pdf/2512.23090
  - **contributions:** 1. Introduced ChexReason, a resource-efficient vision-language model for medical imaging trained with an R1-style (SFT+GRPO) method using minimal data and compute. 2. Identified a fundamental tension where RL optimization (GRPO) improves in-distribution benchmark performance but significantly degrades cross-dataset generalization, a pattern also observed in high-resource models. 3. Discovered a generalization paradox where the SFT checkpoint uniquely improves cross-dataset performance, suggesting teacher-guided reasoning captures more institution-agnostic features than RL optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87b0b1a571aa28f5dd9685e96b13ff3420ed36b0e1d569fff8b1394d564751f_w640_q70.webp
  - **Simple LLM Summary:** The paper investigates applying reinforcement learning (RL) to vision-language models for medical imaging, finding that while RL improves performance on the training benchmark, it harms the model's ability to generalize to new datasets. The authors conclude that for clinical robustness, curated supervised fine-tuning may be more effective than aggressive RL optimization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Benchmark Success, Clinical Failure<br>基准成功，临床失败] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[RL优化提升基准性能但损害泛化<br>RL improves benchmarks but harms generalization]
        C --> C1[使用SFT+GRPO训练ChexReason VLM<br>Train ChexReason VLM with SFT+GRPO]
        D --> D1[GRPO提升CheXpert性能23%<br>GRPO improves CheXpert by 23%]
        D --> D2[GRPO导致NIH性能下降19%<br>GRPO degrades NIH by 19%]
        D --> D3[SFT检查点提升跨数据集泛化<br>SFT checkpoint improves cross-dataset generalization]
    ```

- **[arXiv251230] Osmotic Learning: A Self-Supervised Paradigm for Decentralized Contextual Data Representation**
  - **tags:** [mlsys], [federated learning], [self-supervised learning, representation learning, distributed learning, decentralized clustering, contextual data]
  - **authors:** Mario Colosi, Reza Farahani, Maria Fazio, Radu Prodan, Massimo Villari
  - **institution:** University of Messina, University of Klagenfurt, University of Innsbruck
  - **link:** https://arxiv.org/pdf/2512.23096
  - **contributions:** 1. Introduces Osmotic Learning (OSM-L), a novel self-supervised paradigm for learning from distributed data without raw data exchange. 2. Proposes an "osmosis" process that aligns local representations to converge to a dynamic equilibrium, capturing contextual patterns. 3. Demonstrates that OSM-L functions as a decentralized clustering mechanism, identifying correlated data groups during training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2b452fb94443ab9846af33524787f0bc6c709b6e90ae3be4e653738c6fe592b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Osmotic Learning (OSM-L), a self-supervised distributed learning paradigm that extracts higher-level latent knowledge from decentralized data sources without sharing raw data. It achieves this through an iterative "osmosis" process that aligns local representations to converge to a contextual equilibrium, also enabling decentralized clustering. Experimental results show OSM-L achieves high accuracy in local information alignment while preserving contextual integrity.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Osmotic Learning: A Self-Supervised Paradigm for Decentralized Contextual Data Representation] --> B[核心问题/Problem: Extracting meaningful knowledge from distributed, heterogeneous data without raw data exchange]
        A --> C[主要方法/Method: Osmotic Learning (OSM-L) - self-supervised paradigm using iterative alignment and "osmosis" for representation convergence]
        A --> D[关键结果/Results: Achieves >0.99 alignment accuracy and preserves contextual integrity; enables decentralized clustering]
    ```

- **[arXiv251230] How Much Data Is Enough? Uniform Convergence Bounds for Generative & Vision-Language Models under Low-Dimensional Structure**
  - **tags:** [ai], [statistical learning theory], [uniform convergence, calibration, low-dimensional structure, vision-language models, sample complexity]
  - **authors:** Paul M. Thompson
  - **institution:** Stevens Institute of Neuroimaging and Informatics, University of Southern California
  - **link:** https://arxiv.org/pdf/2512.23109
  - **contributions:** 1. Provides finite-sample uniform convergence bounds for accuracy and calibration of VLM-induced classifiers under Lipschitz stability assumptions. 2. Derives sample complexity bounds that depend on the intrinsic/effective dimension of the embedding space, not the ambient dimension. 3. Offers spectrum-dependent bounds that explicitly link eigenvalue decay in embedding covariance to data requirements, explaining reliable generalization with fewer samples.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dca56fb1537f7d92cc10d66ba9adb9e3272fcc872fe5fdbf475ccf92cc17e24_w640_q70.webp
  - **Simple LLM Summary:** This paper studies when generative and vision-language models can achieve uniformly accurate and calibrated predictions with practical sample sizes. By assuming model outputs depend smoothly on a low-dimensional semantic representation, it derives finite-sample uniform convergence bounds for VLM-induced classifiers. The main conclusion is that sample complexity depends on intrinsic dimension and eigenvalue decay, providing a framework to assess data sufficiency for reliable biomedical predictions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[How Much Data Is Enough? Uniform Convergence Bounds for Generative & Vision-Language Models under Low-Dimensional Structure] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现代生成和视觉语言模型在科学/医疗决策中需要准确且校准良好的概率预测 / Modern generative & VLMs need accurate, calibrated predictions for scientific/medical decisions]
        B --> B2[平均性能良好时，罕见情况或特定子群仍可能出现大误差 / Large errors can persist for rare conditions/subgroups despite low average loss]
        B --> B3[需要何种结构假设才能实现具有实用样本量的均匀泛化？ / What structural assumptions enable uniform generalization with practical sample sizes?]
        C --> C1[分析由提示或语义嵌入在受限表示空间中诱导出的分类器族 / Analyze induced families of classifiers from varying prompts/embeddings in a restricted space]
        C --> C2[假设模型输出对低维语义表示平滑依赖 / Assume model outputs depend smoothly on a low-dimensional semantic representation]
        C --> C3[应用经典均匀收敛工具 / Apply classical uniform convergence tools]
        D --> D1[在Lipschitz稳定性下，为VLM诱导分类器的准确性和校准功能提供有限样本均匀收敛界 / Provide finite-sample uniform convergence bounds for accuracy & calibration of VLM-induced classifiers under Lipschitz stability]
        D --> D2[样本复杂度取决于内在/有效维度，而非环境维度 / Sample complexity depends on intrinsic/effective dimension, not ambient dimension]
        D --> D3[谱相关边界阐明特征值衰减如何控制数据需求 / Spectrum-dependent bounds show how eigenvalue decay governs data requirements]
    ```

- **[arXiv251230] SE-MLP Model for Predicting Prior Acceleration Features in Penetration Signals**
  - **tags:** [ai], [regression], [squeeze and excitation, channel attention, residual connections, multi-layer perceptron, penetration acceleration]
  - **authors:** Yankang Li, Changsheng Li
  - **institution:** Nanjing University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.23131
  - **contributions:** 1. Proposed SE-MLP, a novel MLP architecture integrating a channel attention mechanism for feature prediction. 2. Incorporated residual connections into the MLP framework to enhance model stability and performance. 3. Demonstrated the model's superior accuracy, generalization, and engineering applicability for rapidly predicting penetration acceleration features.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dab35d2c00d22564e8f3e36c067728bb8b4d1bb60f2ed675bfe34288c07503a_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes SE-MLP, a multi-layer perceptron model enhanced with squeeze-and-excitation channel attention and residual connections, to rapidly predict prior acceleration features for penetration signals. The model establishes a nonlinear mapping from physical parameters to acceleration features, outperforming baseline models like MLP, XGBoost, and Transformer in accuracy and stability. The results validate its feasibility and provide a practical basis for engineering applications in penetration fuse design.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SE-MLP Model for Predicting Prior Acceleration Features in Penetration Signals] --> B[核心问题/Problem: 侵彻加速度先验特征获取耗时耗力/Prior acceleration features are expensive and time-consuming to obtain]
        A --> C[主要方法/Method: 提出SE-MLP模型，集成通道注意力与残差连接/Proposed SE-MLP integrating channel attention and residual connections]
        A --> D[关键结果/Results: 预测精度高，泛化性好，工程误差可接受/High prediction accuracy, good generalization, acceptable engineering error]
    ```

- **[arXiv251230] InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization**
  - **tags:** [ai], [reinforcement learning from human feedback (rlhf)], [preference optimization, direct preference optimization, self-reflection, invariance, bradley-terry model]
  - **authors:** Yu Li, Tian Lan, Zhengling Qi
  - **institution:** George Washington University
  - **link:** https://arxiv.org/pdf/2512.23126
  - **contributions:** 1. Identifies two fundamental limitations of DPO: lack of invariance to modeling choices and theoretical suboptimality due to ignoring comparative information in pairwise data. 2. Proposes Intrinsic Self-reflective Preference Optimization (InSPO), a novel family of methods that derives a globally optimal policy conditioned on both context and alternative responses, formalizing self-reflection. 3. Theoretically demonstrates InSPO's superiority over DPO/RLHF and its invariance properties, and practically shows it as a plug-and-play enhancement that improves win rates and length-controlled metrics without inference overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4933654befdce9d244a4f36811432e84021ec775f760f24a3cb71dec1951db76_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies limitations in Direct Preference Optimization (DPO), such as its sensitivity to modeling choices and failure to use comparative data fully. It proposes InSPO, a method that conditions the policy on both the context and the alternative response to enable intrinsic self-reflection. Experiments show InSPO consistently improves model alignment and robustness as a plug-and-play enhancement to DPO-family algorithms.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[DPO Limitations<br/>DPO的局限性]
        B1 --> B2[Lacks Invariance<br/>缺乏不变性]
        B1 --> B3[Suboptimal Use of Data<br/>数据利用次优]
        C --> C1[Propose InSPO<br/>提出InSPO]
        C1 --> C2[Globally Optimal Policy<br/>全局最优策略]
        C2 --> C3[Conditions on Context & Alternative<br/>基于上下文与备选答案]
        D --> D1[Theoretical Superiority<br/>理论优越性]
        D --> D2[Practical Improvement<br/>实际提升]
        D2 --> D3[Better Win Rates<br/>更高的胜率]
        D2 --> D4[No Inference Overhead<br/>无推理开销]
    ```

- **[arXiv251230] Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems**
  - **tags:** [sec], [machine learning security], [TTPs, threat graph, multi-agent RAG, model stealing, jailbreaking]
  - **authors:** Armstrong Foundjem, Lionel Nganyewou Tidjon, Leuson Da Silva, Foutse Khomh
  - **institution:** Polytechnique Montréal (based on author affiliations and sMIEEE notation)
  - **link:** https://arxiv.org/pdf/2512.23132
  - **contributions:** 1. Conducted a large-scale empirical analysis of ML security, extracting 93 distinct threats from multiple sources including real-world incidents and code repositories. 2. Developed a multi-agent RAG system to automatically build an ontology-driven threat graph linking TTPs, vulnerabilities, and lifecycle stages from over 300 articles. 3. Identified unreported threats and dominant attack patterns (e.g., commercial LLM API model stealing, preference-guided jailbreaks) and highlighted vulnerability clusters in ML libraries with poor patch propagation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3da226bc9e7639392b95f6f00808f162580d1a90050c1261b3a0703259e42cf_w640_q70.webp
  - **Simple LLM Summary:** This paper characterizes modern security risks in AI systems by analyzing threats from multiple sources and using a multi-agent RAG system to construct a threat graph. The analysis uncovers unreported attack vectors and dominant TTPs, concluding that adaptive, ML-specific security frameworks are urgently needed to mitigate supply-chain and inference-time risks.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[传统安全框架缺乏针对ML的威胁建模/Traditional cybersecurity lacks ML-specific threat modeling]
    C --> C1[多智能体RAG系统分析威胁/Multi-agent RAG system analyzes threats]
    C1 --> C2[构建本体驱动的威胁图谱/Builds ontology-driven threat graph]
    D --> D1[识别未报告的威胁/Identifies unreported threats]
    D --> D2[发现主要的攻击TTPs/Identifies dominant attack TTPs]
    D --> D3[强调自适应ML安全框架的必要性/Highlights need for adaptive ML security frameworks]
    ```

- **[arXiv251230] Principled Algorithms for Optimizing Generalized Metrics in Binary Classification**
  - **tags:** [ai], [binary classification], [metric optimization, H-consistency, surrogate loss, cost-sensitive learning, METRO]
  - **authors:** Anqi Mao, Mehryar Mohri, Yutao Zhong
  - **institution:** Courant Institute of Mathematical Sciences (NYU), Google Research
  - **link:** https://arxiv.org/pdf/2512.23133
  - **contributions:** 1. Reformulated the optimization of generalized classification metrics (e.g., Fβ, Jaccard) as a generalized cost-sensitive learning problem. 2. Designed novel surrogate loss functions with provable H-consistency guarantees for this problem. 3. Developed the METRO algorithm with strong finite-sample generalization bounds, offering a principled alternative to existing threshold-based methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57d73e082d311622a2b2e8ab3bd4da18cd359831ac4e0139fd4555ea2ba93861_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of directly optimizing non-decomposable binary classification metrics like the Fβ-measure. The authors propose a principled framework that reformulates metric optimization as a cost-sensitive learning problem, leading to new surrogate losses and the METRO algorithm. Experiments show the proposed method is effective and outperforms prior baseline approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Principled Algorithms for Optimizing Generalized Metrics in Binary Classification] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[优化不平衡/代价敏感指标如Fβ, Jaccard/Optimizing imbalanced/cost-sensitive metrics e.g., Fβ, Jaccard]
        B --> B2[现有基于阈值的方法缺乏理论保证/Existing threshold-based methods lack theoretical guarantees]
        C --> C1[将指标优化重构为代价敏感学习问题/Reformulate metric optimization as cost-sensitive learning]
        C --> C2[设计具有H-一致性的替代损失函数/Design surrogate losses with H-consistency]
        C --> C3[提出METRO算法/Propose METRO algorithm]
        D --> D1[提供有限样本泛化保证/Provide finite-sample generalization bounds]
        D --> D2[实验证明优于基线/Experiments show superiority over baselines]
    ```

- **[arXiv251230] Graph Neural Networks with Transformer Fusion of Brain Connectivity Dynamics and Tabular Data for Forecasting Future Tobacco Use**
  - **tags:** [ai], [graph neural networks], [graph neural networks, transformer, dynamic functional connectivity, longitudinal fMRI, multimodal fusion]
  - **authors:** Runzhi Zhou, Xi Luo
  - **institution:** The University of Texas Health Science Center at Houston
  - **link:** https://arxiv.org/pdf/2512.23137
  - **contributions:** 1. Proposes a novel time-aware Graph Neural Network model with Transformer Fusion (GNN-TF) for integrating non-Euclidean brain connectivity and Euclidean tabular data. 2. Introduces an end-to-end framework that leverages the temporal order of longitudinal data for forecasting future clinical outcomes. 3. Demonstrates superior predictive performance for forecasting future tobacco use compared to established machine learning and deep learning models on a longitudinal fMRI dataset.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6106dd6744068e14ed98be012be1d450afa8c685980d7b00ae696592ebd7665_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces GNN-TF, a time-aware model that integrates dynamic brain connectivity graphs and tabular data using a transformer for fusion, to forecast future tobacco use. It is evaluated on longitudinal fMRI data from the NCANDA study and is shown to outperform other state-of-the-art methods in predictive accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Graph Neural Networks with Transformer Fusion of Brain Connectivity Dynamics and Tabular Data for Forecasting Future Tobacco Use] --> B(核心问题/Problem: Integrating non-Euclidean brain imaging and Euclidean tabular data for forecasting future outcomes in longitudinal studies is challenging.)
        A --> C(主要方法/Method: Proposes a time-aware Graph Neural Network with Transformer Fusion (GNN-TF) to integrate dynamic brain connectivity and tabular data.)
        A --> D(关键结果/Results: GNN-TF outperforms state-of-the-art models in predicting future tobacco use on the NCANDA dataset.)
    ```

- **[arXiv251230] A Weak Signal Learning Dataset and Its Baseline Method**
  - **tags:** [ai], [weak signal learning], [weak signal learning, dual-view representation, class imbalance, low SNR, multi-source complementarity]
  - **authors:** Xianqi Liu, Xiangru Li, Lefeng He, Ziyu Fang
  - **institution:** South China Normal University
  - **link:** https://arxiv.org/pdf/2512.23160
  - **contributions:** 1. Constructed the first specialized dataset for weak signal feature learning, featuring low SNR dominance and extreme class imbalance., 2. Proposed a dual-view representation (vector + time-frequency map) and the PDVFN model tailored for low SNR, distribution skew, and dual imbalance., 3. Established a foundational benchmark for future weak signal learning (WSL) research, demonstrating improved accuracy and robustness in challenging scenarios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/426f082649cd556014218d670accdb2545dfd625d214b420b39fcce46739f01d_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of weak signal learning (WSL) by constructing the first dedicated dataset with low SNR and class imbalance, and proposes a dual-view PDVFN model to extract complementary features. The method shows higher accuracy and robustness in handling weak signals, noise, and imbalance. This work provides a dataset, baseline model, and foundation for future WSL research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Weak Signal Learning Dataset and Its Baseline Method<br>弱信号学习数据集及其基线方法] --> B(Problem: Lack of dedicated datasets for weak signal learning<br>核心问题: 缺乏专门的弱信号学习数据集)
        A --> C(Method: Propose dual-view representation & PDVFN model<br>主要方法: 提出双视图表示和PDVFN模型)
        A --> D(Results: Higher accuracy/robustness, provides dataset & baseline<br>关键结果: 更高准确率/鲁棒性，提供数据集和基线)
    ```

- **[arXiv251230] Diffusion-based Decentralized Federated Multi-Task Representation Learning**
  - **tags:** [mlsys], [federated learning], [decentralized learning, multi-task representation learning, projected gradient descent, diffusion-based consensus, sample complexity]
  - **authors:** Donghwa Kang, Shana Moothedath
  - **institution:** Iowa State University
  - **link:** https://arxiv.org/pdf/2512.23161
  - **contributions:** 1. Proposes a novel decentralized projected gradient descent-based algorithm for multi-task representation learning using a diffusion-based communication strategy. 2. Provides theoretical guarantees, including a lower bound on sample complexity and an upper bound on iteration complexity for the proposed algorithm. 3. Demonstrates through analysis and simulations that the algorithm is fast, communication-efficient, and outperforms benchmark methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb19ab164bf383bc246da4c65f212d69031d00619ab4c384a67af532a30b00e2_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of decentralized multi-task representation learning, where multiple linear regression models share a common low-dimensional representation across a network of nodes. The authors propose a diffusion-based decentralized algorithm using alternating projected gradient descent and minimization to recover the shared feature matrix. Theoretical analysis proves the algorithm's efficiency in terms of sample and iteration complexity, and numerical simulations validate its superior performance compared to benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Diffusion-based Decentralized Federated Multi-Task Representation Learning") --> Problem("核心问题/Problem: Decentralized Multi-Task Representation Learning is underexplored")
        Root --> Method("主要方法/Method: Diffusion-based Decentralized Projected Gradient Descent Algorithm")
        Root --> Results("关键结果/Results: Provable guarantees, Fast and communication-efficient")
    ```

- **[arXiv251230] Evaluating Parameter Efficient Methods for RLVR**
  - **tags:** [ai], [reinforcement learning], [Parameter-Efficient Fine-Tuning, Reinforcement Learning with Verifiable Rewards, LoRA, Spectral Collapse, Mathematical Reasoning]
  - **authors:** Qingyu Yin, Yulun Wu, Zhennan Shen, Sunbowen Li, Zhilin Wang, Yanshu Li, Chak Tou Leong, Jiale Kang, Jinjin Gu
  - **institution:** Zhejiang University, HKUST, WUST, USTC, Brown University, Hong Kong Polytechnic University, INSAIT
  - **link:** https://arxiv.org/pdf/2512.23165
  - **contributions:** 1. Conducted the first comprehensive evaluation of over 12 PEFT methods for RLVR, challenging the default use of standard LoRA. 2. Identified that structural PEFT variants (DoRA, AdaLoRA, MiSS) consistently outperform LoRA in this setting. 3. Discovered and explained the failure of SVD-informed initialization methods (e.g., PiSSA) due to a "spectral collapse" phenomenon and misalignment with RL optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87ad6f372a6a1a3b13e37f8468a6816e52a585402f7e4505a01391ffaed0621c_w640_q70.webp
  - **Simple LLM Summary:** This paper systematically evaluates Parameter-Efficient Fine-Tuning (PEFT) methods for Reinforcement Learning with Verifiable Rewards (RLVR) on mathematical reasoning tasks. It finds that structural variants like DoRA outperform standard LoRA, while SVD-based methods fail due to spectral collapse, and extreme parameter reduction bottlenecks performance. The work provides a guide for selecting PEFT methods in RLVR.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Evaluating Parameter Efficient Methods for RLVR] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[RLVR中最佳PEFT架构未知 / Optimal PEFT architecture for RLVR is unknown]
        C --> C1[系统评估12+种PEFT方法 / Systematically evaluate 12+ PEFT methods]
        C --> C2[在数学推理基准上测试 / Test on mathematical reasoning benchmarks]
        D --> D1[结构变体优于标准LoRA / Structural variants outperform standard LoRA]
        D --> D2[SVD初始化导致谱崩溃 / SVD initialization causes spectral collapse]
        D --> D3[极端参数减少损害推理能力 / Extreme parameter reduction harms reasoning]
    ```

- **[arXiv251230] SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search**
  - **tags:** [mlsys], [agent system], [LLM planning, Monte Carlo Tree Search (MCTS), multi-agent architecture, symbolic reasoning, self-correction]
  - **authors:** Yifan Zhang, Giridhar Ganapavarapu, Srideepika Jayaraman, Bhavna Agrawal, Dhaval Patel, Achille Fokoue
  - **institution:** IBM T.J. Watson Research Center, Vanderbilt University
  - **link:** https://arxiv.org/pdf/2512.23167
  - **code:** https://github.com/IBM/SPIRAL
  - **contributions:** 1. Introduces SPIRAL, a novel framework that embeds a cognitive architecture of three specialized LLM agents (Planner, Simulator, Critic) into an MCTS loop for planning. 2. Transforms MCTS from a brute-force search into a guided, self-correcting reasoning process by leveraging dense, semantic-aware feedback from the agents. 3. Demonstrates superior performance and token efficiency on benchmark datasets (e.g., DailyLifeAPIs) compared to Chain-of-Thought and other state-of-the-art planning agents.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c24b184565ce8e4c4a35d80f46a857779e111625dc4ea57e56333bef27bea7e6_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of LLMs struggling with complex planning tasks due to linear reasoning and lack of self-correction. It proposes SPIRAL, a framework that integrates three specialized LLM agents into a Monte Carlo Tree Search loop to create a guided, reflective, and grounded planning process. The method significantly outperforms existing planning approaches in accuracy and efficiency on benchmark datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search] --> B[核心问题/Problem: LLMs falter at complex planning, linear reasoning lacks self-correction]
        A --> C[主要方法/Method: Integrates three LLM agents (Planner, Simulator, Critic) into MCTS loop]
        A --> D[关键结果/Results: Outperforms SOTA agents, achieves 83.6% accuracy on DailyLifeAPIs, superior token efficiency]
    ```

- **[arXiv251230] Certifying the Right to Be Forgotten: Primal-Dual Optimization for Sample and Label Unlearning in Vertical Federated Learning**
  - **tags:** [mlsys], [federated learning], [vertical federated learning, machine unlearning, primal-dual optimization, sample unlearning, label unlearning]
  - **authors:** Yu Jiang, Xindi Tong, Ziyao Liu, Xiaoxi Zhang, Kwok-Yan Lam, Chee Wei Tan
  - **institution:** Nanyang Technological University, Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.23171
  - **contributions:** 1. Proposes FedORA, a primal-dual optimization framework for sample and label unlearning in Vertical Federated Learning (VFL). 2. Introduces a new unlearning loss function that promotes classification uncertainty instead of misclassification. 3. Employs an adaptive step size and an asymmetric batch design to enhance stability and reduce computational costs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05dcd254c3941fc5cbf6bc3c063f2a726b8607659a3f7b4a526ad900e9e2b5de_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of data removal (unlearning) in Vertical Federated Learning (VFL), where different parties hold different features of the same data samples. The authors propose FedORA, a method that formulates unlearning as a constrained optimization problem solved via a primal-dual algorithm. Experiments show FedORA achieves unlearning effectiveness and model utility comparable to retraining from scratch, but with lower computational and communication costs.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Certifying the Right to Be Forgotten: Primal-Dual Optimization for Sample and Label Unlearning in Vertical Federated Learning"]
        Root --> Problem["核心问题/Problem<br>Unlearning in VFL is challenging due to distributed features and cross-party coordination."]
        Root --> Method["主要方法/Method<br>Propose FedORA: a primal-dual optimization framework with a new uncertainty-promoting loss."]
        Root --> Results["关键结果/Results<br>Achieves effective unlearning & utility preservation with lower overhead vs. retraining."]
    ```

- **[arXiv251230] HELM-BERT: A Transformer for Medium-sized Peptide Property Prediction**
  - **tags:** [nlp], [molecular language modeling], [HELM notation, DeBERTa, cyclic peptide, membrane permeability, peptide-protein interaction]
  - **authors:** Seungeon Lee, Takuto Koyama, Itsuki Maeda, Shigeyuki Matsumoto, Yasushi Okuno
  - **institution:** Kyoto University
  - **link:** https://arxiv.org/pdf/2512.23175
  - **contributions:** 1. Proposes HELM-BERT, the first encoder-based peptide language model trained on HELM notation, designed to capture hierarchical dependencies. 2. Pre-trains the model on a curated corpus of 39,079 chemically diverse linear and cyclic peptides. 3. Demonstrates superior performance over SMILES-based models in downstream tasks like cyclic peptide membrane permeability and peptide-protein interaction prediction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83ec939e21fe471473f433077555782bca673e92ad1bfd3578b0fe729e20446_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces HELM-BERT, a transformer model based on DeBERTa and trained on HELM notation to better represent therapeutic peptides. It shows that this approach significantly outperforms existing SMILES-based models in predicting key peptide properties, demonstrating the data-efficiency advantages of topology-aware representations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HELM-BERT: A Transformer for Medium-sized Peptide Property Prediction] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有分子表示(如SMILES)无法有效捕捉肽的化学与拓扑复杂性/Existing molecular representations fail to capture peptide complexity]
        C --> C1[基于DeBERTa, 使用HELM符号训练首个编码器肽语言模型/Based on DeBERTa, first encoder peptide LM trained on HELM notation]
        C --> C2[在39,079个多样化肽的语料库上进行预训练/Pre-trained on a corpus of 39,079 diverse peptides]
        D --> D1[在膜渗透性和肽-蛋白相互作用预测上显著优于SMILES模型/Significantly outperforms SMILES models on permeability & interaction prediction]
        D --> D2[HELM表示提供数据效率优势/HELM representations offer data-efficiency advantages]
    ```

- **[arXiv251230] Machine Learning-Assisted Vocal Cord Ultrasound Examination: Project VIPR**
  - **tags:** [cv], [medical image classification], [vocal cord ultrasound, image segmentation, VIPRnet, vocal cord paralysis, classification model]
  - **authors:** Will Sebelik-Lassiter, Evan Schubert, Muhammad Alliyu, Quentin Robbins, Excel Olatunji, Mustafa Barry
  - **institution:** Milwaukee School of Engineering, Emory University
  - **link:** https://arxiv.org/pdf/2512.23177
  - **contributions:** 1. Developed a machine learning pipeline for automated analysis of vocal cord ultrasound (VCUS) videos. 2. Created a segmentation model to automatically identify vocal cords in ultrasound images with 96% validation accuracy. 3. Proposed VIPRnet, a classification model to distinguish normal vocal cords from vocal cord paralysis (VCP) with 99% validation accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5abcb457a7fbefffa7d7836af553a8db8fa248fdd34a0459a027299b3ce2ce44_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a machine learning-assisted system to automate the analysis of vocal cord ultrasound (VCUS) to reduce operator dependency. The method involves segmenting the vocal cords and classifying them as normal or paralyzed using models trained on frames from volunteer videos. The results show high validation accuracy (96% for segmentation, 99% for classification), indicating promise for improving diagnostic accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Project VIPR: Machine Learning-Assisted Vocal Cord Ultrasound Examination] --> B[核心问题/Problem: VCUS accuracy is operator-dependent]
    A --> C[主要方法/Method: Use ML models for vocal cord segmentation and VCP classification]
    A --> D[关键结果/Results: Segmentation accuracy 96%, VIPRnet classification accuracy 99%]
    ```

- **[arXiv251230] PGOT: A Physics-Geometry Operator Transformer for Complex PDEs**
  - **tags:** [ai], [neural operator learning], [Physics-Geometry Operator Transformer, Spectrum-Preserving Geometric Attention, geometric aliasing, linear complexity, spatially adaptive routing]
  - **authors:** Zhuo Zhang, Xi Yang, Yuan Zhao, Canqun Yang
  - **institution:** National University of Defense Technology, National SuperComputer Center in Tianjin
  - **link:** https://arxiv.org/pdf/2512.23192
  - **contributions:** 1. Proposes PGOT, a novel transformer architecture designed to reconstruct physical feature learning through explicit geometry awareness for solving PDEs on complex geometries. 2. Introduces Spectrum-Preserving Geometric Attention (SpecGeo-Attention), which uses a physics slicing-geometry injection mechanism to incorporate multi-scale geometric encodings, preserving critical boundary information while maintaining linear computational complexity. 3. Implements a dynamic routing mechanism that adaptively selects low-order linear paths for smooth regions and high-order non-linear paths for discontinuities, enabling high-precision, spatially adaptive modeling.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1247f066008cc6ba78670544cbf446b4e7c3e18fb9b55a53416b7a831c93e80f_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of modeling PDEs on large-scale unstructured meshes with complex geometries using transformers, where efficient architectures often lose critical boundary information due to geometric aliasing. It proposes the Physics-Geometry Operator Transformer (PGOT), which introduces a geometry-aware attention mechanism and adaptive computational routing to preserve multi-scale features and model shocks precisely. PGOT achieves state-of-the-art performance on standard benchmarks and excels in large-scale industrial design tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[PGOT: A Physics-Geometry Operator Transformer for Complex PDEs] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Transformers建模复杂几何PDEs的挑战/Challenge: Modeling PDEs on complex geometries]
        B --> B2[几何混叠导致边界信息丢失/Geometric Aliasing loses boundary info]
        C --> C1[提出PGOT框架/Propose PGOT framework]
        C --> C2[谱保持几何注意力/SpecGeo-Attention]
        C --> C3[动态路径路由/Dynamic path routing]
        D --> D1[四个基准测试SOTA/SOTA on four benchmarks]
        D --> D2[工业设计任务优异/Excels in industrial design tasks]
    ```

- **[arXiv251230] A Simple, Optimal and Efficient Algorithm for Online Exp-Concave Optimization**
  - **tags:** [ai], [online learning], [Online Newton Step, Mahalanobis projection, regret minimization, exp-concave optimization]
  - **authors:** Yi-Han Wang, Peng Zhao, Zhi-Hua Zhou
  - **institution:** National Key Laboratory for Novel Software Technology, Nanjing University; School of Artificial Intelligence, Nanjing University
  - **link:** https://arxiv.org/pdf/2512.23190
  - **contributions:** 1. Proposes LightONS, a simple variant of ONS that reduces computational cost by delaying expensive Mahalanobis projections via a hysteresis mechanism. 2. Achieves optimal O(d log T) regret with a total runtime of O(d²T + d^ω √(T log T)), improving over ONS's O(d^ω T) runtime. 3. Provides an SXO algorithm with runtime ~O(d³/ε), solving the COLT'13 open problem posed by Koren.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2632ee5796bfd9a4795aa8e1212d8f65e7f8732a96264f4ae4629a2216e3e5ba_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the computational bottleneck of the Online Newton Step (ONS) algorithm for online exp-concave optimization, where the Mahalanobis projection step is costly. The authors propose LightONS, a simple variant that introduces a hysteresis mechanism to delay expensive projections, preserving optimal regret while significantly reducing runtime. This leads to an efficient stochastic optimization method that resolves a long-standing open problem.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["A Simple, Optimal and Efficient Algorithm for Online Exp-Concave Optimization<br/>在线指数凹优化的简单、最优且高效算法"] --> B["核心问题/Problem"]
        A --> C["主要方法/Method"]
        A --> D["关键结果/Results"]
        B --> B1["在线指数凹优化(OXO)中，ONS算法的Mahalanobis投影计算成本高<br/>High computational cost of Mahalanobis projection in ONS for OXO"]
        B --> B2["随机指数凹优化(SXO)存在COLT'13开放问题<br/>COLT'13 open problem for SXO"]
        C --> C1["提出LightONS算法<br/>Propose LightONS algorithm"]
        C --> C2["利用迟滞机制延迟昂贵投影<br/>Delay expensive projections via hysteresis mechanism"]
        D --> D1["保持最优O(d log T)遗憾<br/>Preserves optimal O(d log T) regret"]
        D --> D2["总运行时间降至O(d²T + d^ω √(T log T))<br/>Total runtime reduced to O(d²T + d^ω √(T log T))"]
        D --> D3["解决SXO开放问题，运行时间~O(d³/ε)<br/>Solves SXO open problem with runtime ~O(d³/ε)"]
    ```

- **[arXiv251230] Energy and Memory-Efficient Federated Learning With Ordered Layer Freezing**
  - **tags:** [mlsys], [federated learning], [Ordered Layer Freezing, Tensor Operation Approximation, Non-IID Data, Edge Computing, Model Compression]
  - **authors:** Ziru Niu, Hai Dong, A.K. Qin, Tao Gu, Pengcheng Zhang
  - **institution:** RMIT University, Swinburne University of Technology, Macquarie University, Hohai University
  - **link:** https://arxiv.org/pdf/2512.23200
  - **contributions:** 1. Proposed Federated Learning with Ordered Layer Freezing (FedOLF), a method that freezes model layers in a predefined order before training to reduce computation and memory requirements. 2. Introduced Tensor Operation Approximation (TOA) as a lightweight alternative to conventional quantization to further reduce communication and energy costs while preserving model accuracy. 3. Demonstrated superior performance of FedOLF over non-IID data across multiple datasets and model architectures, achieving higher accuracy, energy efficiency, and lower memory footprint compared to existing works.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5cf67406a118e6d8eff8ded5d05e3b12c6eeded41300a0b8517fec19cbc8d930_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces FedOLF, a federated learning method that freezes model layers in a predefined order to reduce resource demands on edge devices, combined with a Tensor Operation Approximation technique for efficient communication. The proposed approach is shown to achieve higher accuracy and better energy/memory efficiency than existing methods when training on non-IID data across several benchmark datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Energy and Memory-Efficient Federated Learning with Ordered Layer Freezing] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[FL在资源受限的IoT设备上效率低/FL inefficiency on resource-constrained IoT devices]
        C --> C1[有序层冻结/FedOLF: Ordered Layer Freezing]
        C --> C2[张量操作近似/TOA: Tensor Operation Approximation]
        D --> D1[更高准确率/Higher accuracy on non-IID data]
        D --> D2[更高能效与更低内存占用/Higher energy efficiency & lower memory footprint]
    ```

- **[arXiv251230] Anka: A Domain-Specific Language for Reliable LLM Code Generation**
  - **tags:** [mlsys], [llm inference], [Domain-Specific Language, Constrained Syntax, Code Generation, Data Transformation Pipeline, In-Context Learning]
  - **authors:** Saif Khalfan Saif Al Mazrouei
  - **institution:** University of Wisconsin-Madison
  - **link:** https://arxiv.org/pdf/2512.23214
  - **contributions:** 1. Introduced Anka, a domain-specific language (DSL) with explicit, constrained syntax designed to reduce ambiguity in LLM code generation. 2. Demonstrated that LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy without prior training. 3. Showed that purposefully designed DSLs can outperform general-purpose languages (e.g., Python) on complex multi-step tasks, significantly reducing errors in operation sequencing and state management.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e450f3b6354a05c4c0dfa0c22c4f8b8dfc33c08282380080deb2d2f3a335d4_w640_q70.webp
  - **Simple LLM Summary:** This paper hypothesizes that the flexibility of general-purpose languages leads to systematic errors in LLM code generation for complex tasks. To test this, it introduces Anka, a constrained DSL for data transformation pipelines. The results show that LLMs can learn Anka from prompts and achieve significantly higher accuracy on multi-step tasks compared to Python, demonstrating the advantage of constrained syntax for reliable code generation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Anka: A Domain-Specific Language for Reliable LLM Code Generation] --> B[核心问题/Problem: LLMs make systematic errors in complex multi-step code generation]
        A --> C[主要方法/Method: Design Anka, a constrained DSL for data transformation pipelines]
        A --> D[关键结果/Results: High parse success & task accuracy; Anka outperforms Python on multi-step tasks]
    ```

- **[arXiv251230] FairGFL: Privacy-Preserving Fairness-Aware Federated Learning with Overlapping Subgraphs**
  - **tags:** [mlsys], [federated learning], [graph federated learning, fairness, overlapping subgraphs, privacy-preserving, weighted aggregation]
  - **authors:** Zihao Zhou, Shusen Yang, Fangyuan Zhao, Xuebin Ren
  - **institution:** Xi'an Jiaotong University
  - **link:** https://arxiv.org/pdf/2512.23235
  - **contributions:** 1. Uncover and theoretically analyze the unfairness issue in graph federated learning caused by imbalanced overlapping subgraphs across clients. 2. Propose FairGFL, a novel algorithm that uses a privacy-preserving estimation of overlapping ratios and an interpretable weighted aggregation approach to enhance cross-client fairness. 3. Improve the tradeoff between model utility and fairness by integrating a carefully crafted regularizer into the federated composite loss function.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c67614889dfdf1e0e6de4fd0bd950e8649eb4d988fb1661c29ef6c14b73bba25_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a fairness problem in graph federated learning when client subgraphs overlap in an imbalanced way. To solve this, it proposes FairGFL, a method that uses privacy-preserving overlap estimation and a fairness-aware regularizer to balance utility and fairness. Experiments show FairGFL outperforms baselines in both utility and fairness on benchmark datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
    A(FairGFL: Privacy-Preserving Fairness-Aware Federated Learning with Overlapping Subgraphs) --> B(核心问题/Problem: Imbalanced overlapping subgraphs cause unfairness in GFL)
    A --> C(主要方法/Method: FairGFL with privacy-preserving overlap estimation, weighted aggregation, and fairness regularizer)
    A --> D(关键结果/Results: Outperforms baselines in model utility and fairness)
    ```

- **[arXiv251230] KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta**
  - **tags:** [mlsys], [gpu kernels], [agentic kernel coding, heterogeneous accelerators, retrieval-augmented prompt synthesis, graph-based search, Triton/CuTe DSL]
  - **authors:** Gang Liao, Hongsen Qin, Ying Wang, Alicia Golden, Michael Kuchnik, Yavuz Yetim, Jia Jiunn Ang, Chunli Fu, Yihan He, Samuel Hsia, Zewei Jiang, Dianshi Li, Uladzimir Pashkevich, Varna Puvvada, Feng Shi, Matt Steiner, Ruichao Xiao, Nathan Yan, Xiayu Yu, Zhou Fang, Abdul Zainul-Abedin, Ketan Singh, Hongtao Yu, Wenyuan Chi, Barney Huang, Sean Zhang, Noah Weller, Zach Marine, Wyatt Cook, Carole-Jean Wu, Gaoxiang Liu
  - **institution:** Meta Platforms
  - **link:** https://arxiv.org/pdf/2512.23236
  - **contributions:** 1. Proposes KernelEvolve, an agentic framework that automates kernel generation and optimization for DLRMs across heterogeneous hardware (NVIDIA/AMD GPUs, Meta accelerators) by operating at multiple programming abstractions. 2. Introduces a kernel optimization process modeled as a graph-based search with dynamic adaptation to runtime context via retrieval-augmented prompt synthesis and a persistent hardware knowledge base. 3. Demonstrates the system's effectiveness by achieving 100% correctness on benchmark suites and substantial performance speedups (up to 17x) in production, reducing development time from weeks to hours and lowering the programmability barrier for new AI hardware.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp
  - **Simple LLM Summary:** This paper presents KernelEvolve, an agentic framework that automates the generation and optimization of compute kernels for deep learning recommendation models to address challenges posed by model, kernel, and hardware heterogeneity. The method uses a graph-based search process enhanced with retrieval-augmented prompts and operates across multiple programming abstractions. The system was validated on production models and benchmarks, showing significant performance improvements and reduced development time, effectively mitigating the programmability barrier for new AI accelerators.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[KernelEvolve: Scaling Agentic Kernel Coding] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[DLRM训练/推理效率<br/>DLRM Training/Inference Efficiency]
        B --> B2[模型、内核、硬件异构性<br/>Model, Kernel, Hardware Heterogeneity]
        C --> C1[智能内核编码框架<br/>Agentic Kernel Coding Framework]
        C --> C2[多抽象层: Triton, CuTe DSL<br/>Multi-Abstraction: Triton, CuTe DSL]
        C --> C3[图搜索与检索增强提示<br/>Graph Search & Retrieval-Augmented Prompt]
        D --> D1[100%正确率, 17倍加速<br/>100% Correctness, 17x Speedup]
        D --> D2[开发时间: 数周->数小时<br/>Dev Time: Weeks->Hours]
        D --> D3[降低新硬件编程壁垒<br/>Reduces New Hardware Programmability Barrier]
    ```

- **[arXiv251230] On the Inverse Flow Matching Problem in the One-Dimensional and Gaussian Cases**
  - **tags:** [ai], [generative models], [flow matching, inverse problem, uniqueness, generative AI, continuity equation]
  - **authors:** Alexander Korotin, Gudmund Pammer
  - **institution:** Applied AI Institute, Graz University of Technology
  - **link:** https://arxiv.org/pdf/2512.23265
  - **contributions:** 1. Formally defines the inverse problem of flow matching (FM) for distributions with finite exponential moment, 2. Establishes the uniqueness of the solution to the inverse FM problem in the one-dimensional (D=1) setting, 3. Establishes the uniqueness of the solution to the inverse FM problem in the Gaussian case.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3894b8881e76b35830e6504158fd61b8ec4e18f8adfb99a0b03911f3928bd297_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the inverse problem of flow matching, aiming to recover the original transport plan given the initial distribution and the learned velocity field. It proves that the solution to this inverse problem is unique in two specific cases: one-dimensional distributions and Gaussian distributions. The general multidimensional case remains an open problem for future research.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["On the Inverse Flow Matching Problem<br>逆流匹配问题"] --> Problem["研究逆流匹配问题<br>Inverse Flow Matching Problem"]
        Root --> Method["分析一维与高斯情形<br>Analyze 1D & Gaussian Cases"]
        Root --> Results["证明解的唯一性<br>Prove Solution Uniqueness"]
    ```

- **[arXiv251230] PFed-Signal: An ADR Prediction Model based on Federated Learning**
  - **tags:** [mlsys], [federated learning], [federated learning, transformer, euclidean distance, adverse drug reaction, data cleaning]
  - **authors:** Tao Li, Peilin Li, Kui Lu, Yilei Wang, Junliang Shang, Guangshun Li, Huiyu Zhou
  - **institution:** Qufu Normal University, University of Leicester
  - **link:** https://arxiv.org/pdf/2512.23262
  - **contributions:** 1. Proposed PFed-Split, a method to split the original FAERS dataset based on Adverse Drug Reactions (ADRs). 2. Introduced a federated learning-based biased data identification method that uses Euclidean distance to filter out noisy records and generate a clean dataset. 3. Developed an ADR prediction model based on the Transformer architecture, trained on the cleaned dataset, which achieves superior performance in accuracy and signal detection metrics (ROR, PRR) compared to traditional statistical methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c6bff5c67d3939353727926690ff57b0800331885e90983cf3850de46090975_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes PFed-Signal, a federated learning-based model for predicting Adverse Drug Reactions (ADRs). The method first cleans biased data from the FAERS database using Euclidean distance within a federated framework and then trains a Transformer model on the cleaned data for prediction. The results show that this approach outperforms traditional statistical methods in key metrics like accuracy, F1 score, and AUC.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[PFed-Signal: An ADR Prediction Model based on Federated Learning] --> B(核心问题/Problem: Biased data in FAERS leads to inaccurate ADR prediction)
        A --> C(主要方法/Method: Use federated learning & Euclidean distance to clean data, then train Transformer model)
        A --> D(关键结果/Results: Higher accuracy, F1, recall, AUC than baselines; improved ROR/PRR)
    ```

- **[arXiv251230] Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [Sparse Autoencoders (SAEs), Low-Rank Adaptation (LoRA), Safety Alignment, Interpretability, Parameter-efficient Fine-tuning (PEFT)]
  - **authors:** Dianyun Wang, Qingsen Ma, Yuhu Shang, Zhifeng Lu, Lechen Ning, Zhenbo Xu, Huijia Wu, Zhaofeng He
  - **institution:** Beijing University of Posts and Telecommunications
  - **link:** https://arxiv.org/pdf/2512.23260
  - **contributions:** 1. Proposes a novel method that uses pre-trained Sparse Autoencoders (SAEs) to construct an explicit, interpretable low-rank subspace for adapter initialization, addressing the black-box nature of traditional LoRA. 2. Provides theoretical analysis proving that SAE-based subspace identification achieves arbitrarily small recovery error under monosemanticity, while direct identification suffers an irreducible error floor due to polysemanticity. 3. Demonstrates state-of-the-art performance on safety alignment, achieving up to 99.6% safety rate while updating only 0.19-0.24% of parameters, and provides interpretable insights into the learned alignment subspace.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e615e6d561cef5b79dc991ed964fd9b6fb069427af26a4b7b42cd33cea4315a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of interpretability in standard Low-Rank Adaptation (LoRA) methods for fine-tuning large language models. The proposed method leverages Sparse Autoencoders (SAEs) to identify task-relevant features in a disentangled space and uses them to construct an explicit, interpretable low-rank subspace for adapter initialization. The approach achieves superior safety alignment performance and provides transparency into the learned adaptation process.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("LoRA缺乏可解释性/LoRA lacks interpretability")
        Problem --> P2("子空间学习是黑盒的/Subspace learning is black-box")
        Method --> M1("利用预训练SAE/Use pre-trained SAEs")
        Method --> M2("构建显式低秩子空间/Construct explicit low-rank subspace")
        Results --> R1("高安全率99.6%/High safety rate 99.6%")
        Results --> R2("参数高效0.19%/Parameter-efficient 0.19%")
        Results --> R3("提供可解释性/Provides interpretability")
    ```

- **[arXiv251230] Revealing design archetypes and flexibility in e-molecule import pathways using Modeling to Generate Alternatives and interpretable machine learning**
  - **tags:** [other], [Energy Systems Optimization], [Modeling to Generate Alternatives, Interpretable Machine Learning, Decision Trees, Energy System Optimization Model, E-molecules]
  - **authors:** Mahdi Kchaou, Francesco Contino, Diederik Coppitters
  - **institution:** Institute of Mechanics, Materials and Civil Engineering (iMMC), Université catholique de Louvain (UCLouvain)
  - **link:** https://arxiv.org/pdf/2512.23284
  - **contributions:** 1. Applied Modeling to Generate Alternatives (MGA) to produce a diverse set of near-cost-optimal e-molecule import pathway designs, moving beyond a single optimal solution. 2. Used interpretable machine learning (specifically decision trees) to extract high-level insights and design archetypes from the complex, multi-dimensional solution space generated by MGA. 3. Demonstrated the flexibility of hydrogen import pathways, showing that specific technologies (solar, wind, storage) are not strictly required to stay within a 10% cost margin, and revealed how constraints shift the preferred design archetypes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b329c74249d56df55cd55db503dedb7b277979173c0419ff415764d3a34be11_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of single cost-optimal designs for green e-molecule import pathways by using Modeling to Generate Alternatives to create diverse near-optimal solutions and then applying interpretable machine learning to analyze them. The method is applied to hydrogen import pathways considering different carriers. The main finding is a broad near-optimal space with significant flexibility, where specific renewable sources are not strictly necessary, and constraints shift preferences toward different carrier and technology combinations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[揭示电子分子进口路径的设计原型与灵活性<br>Revealing design archetypes and flexibility in e-molecule import pathways] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>单一成本最优解脆弱<br>Single cost-optimal solution is fragile]
        C[主要方法/Method<br>MGA与可解释机器学习<br>Modeling to Generate Alternatives & Interpretable ML]
        D[关键结果/Results<br>广阔的近优空间与灵活性<br>Broad near-optimal space with flexibility]
    ```

- **[arXiv251230] Spectral Analysis of Hard-Constraint PINNs: The Spatial Modulation Mechanism of Boundary Functions**
  - **tags:** [ai], [scientific machine learning], [Physics-Informed Neural Networks, Neural Tangent Kernel, spectral analysis, hard constraints, boundary functions]
  - **authors:** Yuchen Xie, Honghang Chi, Haopeng Quan, Yahui Wang, Wei Wang, Yu Ma
  - **institution:** Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.23295
  - **contributions:** 1. Established a rigorous Neural Tangent Kernel (NTK) framework for Hard-Constraint PINNs (HC-PINNs), deriving the explicit kernel composition law. 2. Revealed that the boundary function acts as a multiplicative spatial modulator and spectral filter, fundamentally altering the learning landscape and potentially causing spectral collapse. 3. Identified the effective rank of the residual kernel as a superior, deterministic predictor of training convergence compared to classical condition numbers.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/adb45ca3a4beb6281022392033c68aa10cb18c53e62610b8818daca2495a7eee_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the training dynamics of Physics-Informed Neural Networks with hard constraints (HC-PINNs). It establishes an NTK framework to show that the boundary function acts as a spectral filter, and identifies the kernel's effective rank as a key predictor of convergence. The work provides a theoretical foundation for designing boundary functions to avoid optimization stagnation.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Spectral Analysis of Hard-Constraint PINNs<br/>硬约束PINN的谱分析"] --> Problem["核心问题/Problem<br/>HC-PINN训练动态机制不明<br/>HC-PINN training dynamics unexplored"]
        Root --> Method["主要方法/Method<br/>建立NTK框架与谱分析<br/>Establish NTK framework & spectral analysis"]
        Root --> Results["关键结果/Results<br/>边界函数是谱滤波器<br/>有效秩预测收敛性<br/>Boundary function is spectral filter<br/>Effective rank predicts convergence"]
    ```

- **[arXiv251230] Agentic Physical AI toward a Domain-Specific Foundation Model for Nuclear Reactor Control**
  - **tags:** [ai], [reinforcement learning], [domain-specific foundation model, agentic physical ai, variance collapse, physics-based validation, policy distillation]
  - **authors:** Yoonpyo Lee, Kazuma Kobayashi, Sai Puppala, Sajedul Talukder, Seid Koric, Souvik Chakraborty, Syed Bahauddin Alam
  - **institution:** Hanyang University, University of Illinois Urbana-Champaign, Southern Illinois University, University of Texas at El Paso, National Center for Supercomputing Applications, Indian Institute of Technology Delhi
  - **link:** https://arxiv.org/pdf/2512.23292
  - **contributions:** 1. Proposes a new paradigm of Agentic Physical AI, where policy optimization is driven by physics-based outcome validation instead of perceptual inference, addressing the structural limitation of general-purpose models in control tasks. 2. Demonstrates that scaling data for a compact (360M parameter) model induces a sharp phase transition and variance collapse (&gt;500x reduction), leading to stable, execution-level behavior for safety-critical control. 3. Shows the model autonomously distills a robust policy (concentrating on a single strategy) and its learned representations transfer across different physics and input modalities without architectural changes, exhibiting early foundation-model properties.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb921102dfde629395ab8293510cb369a00c1199cadd4c88269dc076f8774a1a_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a fundamental limitation of general-purpose AI models in safety-critical physical control tasks, where they prioritize semantic plausibility over physical correctness. To address this, it introduces Agentic Physical AI, a paradigm using compact language models trained with physics-based validation on synthetic nuclear reactor control data. The key finding is that sufficient data scaling induces a sharp variance collapse, stabilizing the model's behavior and enabling it to autonomously distill a reliable control policy that generalizes across tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Agentic Physical AI for Nuclear Reactor Control") --> Problem
        Root --> Method
        Root --> Results
    
        Problem["核心问题/Problem<br>General-purpose models fail at physical control<br>通用模型在物理控制中失败"]
        Method["主要方法/Method<br>Agentic Physical AI with physics-based validation<br>基于物理验证的智能体物理AI"]
        Results["关键结果/Results<br>Variance collapse & emergent policy distillation<br>方差崩溃与策略蒸馏涌现"]
    
        Problem --> P1["Input unfaithfulness / 输入不忠实"]
        Problem --> P2["Semantic vs. physical correctness / 语义与物理正确性冲突"]
    
        Method --> M1["Compact LM (360M params) / 紧凑语言模型"]
        Method --> M2["Physics-driven optimization / 物理驱动优化"]
        Method --> M3["Synthetic data scaling (10^3 to 10^5) / 合成数据缩放"]
    
        Results --> R1["Phase transition & >500x variance collapse / 相变与方差崩溃"]
        Results --> R2["Autonomous policy distillation / 自主策略蒸馏"]
        Results --> R3["Transferable representations / 可迁移表征"]
    ```

- **[arXiv251230] Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL**
  - **tags:** [mlsys], [llm inference], [Lyapunov Optimization, Deep Reinforcement Learning, Edge-Cloud Partitioning, Transformer Decomposition, Queue Stability]
  - **authors:** Abolfazl Younesi, Abbas Shabrang Maryan, Elyas Oustad, Zahra Najafabadi Samani, Mohsen Ansari, Thomas Fahringer
  - **institution:** University of Innsbruck, Sharif University of Technology
  - **link:** https://arxiv.org/pdf/2512.23310
  - **contributions:** 1. Proposes a fine-grained, adaptive partitioning framework (Splitwise) that decomposes transformer layers into attention heads and feed-forward sub-blocks, enabling exponentially more partition choices than layer-wise schemes. 2. Introduces a hierarchical DRL policy guided by Lyapunov optimization to jointly optimize latency, energy, and accuracy while guaranteeing queue stability under stochastic workloads and variable bandwidth. 3. Ensures robustness through partition checkpoints with exponential backoff recovery for communication failures, validated on real edge devices with large models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/121b71aa214f4a7c1671c9df76bf67a9cd64f3cb9e74186606a380ce86f7634f_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes Splitwise, a Lyapunov-assisted DRL framework for dynamically partitioning LLM inference between edge and cloud at a fine-grained sub-layer level. It aims to minimize latency and energy while maintaining accuracy under fluctuating network conditions. Experiments show Splitwise significantly reduces latency and energy consumption compared to existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL] --> B[核心问题/Problem: LLMs are hard to deploy on edge devices; cloud-only is slow; static partitions fail with bandwidth changes.]
        A --> C[主要方法/Method: Fine-grained partition of transformer layers; Lyapunov-assisted DRL for adaptive optimization; checkpointing for robustness.]
        A --> D[关键结果/Results: Reduces latency 1.4x-2.8x; cuts energy up to 41%; lowers 95th-percentile latency by 53-61%.]
    ```

- **[arXiv251230] Deep learning for pedestrians: backpropagation in Transformers**
  - **tags:** [ai], [backpropagation], [backpropagation, transformers, gradient derivation, LoRA, PyTorch implementation]
  - **authors:** Laurent Boué
  - **institution:** Oracle, Microsoft
  - **link:** https://arxiv.org/pdf/2512.23329
  - **contributions:** 1. Provides a vectorized, index-free derivation of backpropagation for transformer architectures, extending previous work on CNNs. 2. Derives gradient expressions for key transformer components like embedding, multi-headed self-attention, layer normalization, and LoRA layers. 3. Includes a complete PyTorch implementation of a minimal GPT-like network alongside analytical gradient expressions for pedagogical clarity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d5ded3610ac31d4f19d95237254231c2e03d3870df7749cabfc471eeb5008ac_w640_q70.webp
  - **Simple LLM Summary:** This paper manually derives the backpropagation algorithm for transformer-based next-token-prediction models using a vectorized, index-free methodology. It provides gradient expressions for core layers (embedding, self-attention, layer norm) and LoRA, aiming to build deeper intuition for how operations influence the final output. A complete PyTorch implementation is also provided to illustrate the theoretical derivations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deep learning for pedestrians: backpropagation in Transformers] --> B[核心问题/Problem: Understanding the mechanics of backpropagation in transformers]
        A --> C[主要方法/Method: Apply lightweight, index-free methodology to derive gradients for embedding, self-attention, layer norm, and LoRA]
        A --> D[关键结果/Results: Provides analytical gradient expressions and a complete PyTorch implementation for a GPT-like network]
    ```

- **[arXiv251230] Visual Language Hypothesis**
  - **tags:** [cv], [representation learning], [visual language hypothesis, fiber bundle, semantic quotient, expand-and-snap, topology change]
  - **authors:** Xiu Li
  - **institution:** Bytedance
  - **link:** https://arxiv.org/pdf/2512.23335
  - **contributions:** 1. Proposes the "Visual Language Hypothesis," framing visual understanding as requiring a discrete semantic language, leading to a fiber-bundle-like structure for the observation space. 2. Derives a theoretical requirement for semantic invariance, arguing it necessitates a non-homeomorphic, discriminative target (e.g., supervised labels, multimodal alignment) rather than smooth deformation alone. 3. Identifies an architectural requirement for models, proposing an "expand-and-snap" process to achieve the necessary topology change for semantic abstraction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d70511c4d2f57ecb4e49170ed73c0a81de0fcfcdbdb84cc7bcbdca254140c3f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes the "Visual Language Hypothesis," which posits that visual understanding requires a discrete semantic structure, implying the visual observation space is organized like a fiber bundle. From this, the authors theoretically argue that achieving semantic invariance demands discriminative supervision and that model architectures must support a specific "expand-and-snap" process to change topology. The framework provides a topological interpretation for empirical patterns in large-scale discriminative and multimodal models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Visual Language Hypothesis] --> B[核心问题/Problem: What structural properties enable semantic abstraction in vision?]
        A --> C[主要方法/Method: Propose hypothesis of discrete semantic language, derive geometric (fiber bundle) structure]
        A --> D[关键结果/Results: Semantic invariance needs discriminative target; Model needs "expand-and-snap" for topology change]
    ```

- **[arXiv251230] The Law of Multi-Model Collaboration: Scaling Limits of Model Ensembling for Large Language Models**
  - **tags:** [ai], [scaling laws], [scaling laws, model ensembling, multi-model collaboration, cross-entropy loss, parameter budget]
  - **authors:** Dakuan Lu, Jiaqi Zhang, Cheng Yuan, Jiawei Shao, Chi Zhang, Xuelong Li
  - **institution:** Institute of Artificial Intelligence (TeleAI), China Telecom
  - **link:** https://arxiv.org/pdf/2512.23340
  - **contributions:** 1. Proposes the "Law of Multi-model Collaboration," a novel scaling law for predicting the performance limits of LLM ensembles based on aggregated parameters. 2. Establishes a method-agnostic theoretical framework using an idealized integration oracle to quantify the intrinsic upper bound of multi-model collaboration. 3. Empirically demonstrates that multi-model systems follow a power-law scaling with better trends and lower loss floors than single models, and that heterogeneous ensembles outperform homogeneous ones.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68212ad5f9cd50ef959cdd80f4b7274178d9a6b124904010fc5b0cf0834b21a1_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of a theoretical framework for scaling in multi-model LLM systems. It proposes the "Law of Multi-model Collaboration," a scaling law based on aggregated parameters, and finds that ensembles scale better and achieve lower loss than single models, with diversity being a key driver of gains.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["The Law of Multi-Model Collaboration<br>多模型协作定律"] --> Problem["核心问题/Problem<br>Lack of scaling theory for multi-model collaboration<br>缺乏多模型协作的扩展理论"]
        Root --> Method["主要方法/Method<br>Propose Law of Multi-model Collaboration<br>提出多模型协作定律"]
        Root --> Results["关键结果/Results<br>Ensembles scale better than single models<br>集成模型比单一模型扩展性更好"]
    ```

- **[arXiv251230] ECG-RAMBA: Zero-Shot ECG Generalization by Morphology-Rhythm Disentanglement and Long-Range Modeling**
  - **tags:** [ai], [medical signal processing], [ECG classification, morphology-rhythm disentanglement, Mamba, zero-shot generalization, Power Mean pooling]
  - **authors:** Hai Duong Nguyen, Xuan-The Tran
  - **institution:** HAI-Smartlink Research Lab (Anchi STE Company), Vietnam Maritime University
  - **link:** https://arxiv.org/pdf/2512.23347
  - **contributions:** 1. Proposes ECG-RAMBA, a framework that explicitly disentangles ECG morphology (via MiniRocket) and rhythm (via HRV descriptors) before fusing them for robust classification. 2. Introduces a numerically stable Power Mean pooling operator (Q=3) for windowed inference to emphasize high-evidence segments. 3. Demonstrates strong zero-shot cross-dataset generalization for ECG classification using a bi-directional Mamba backbone for long-range contextual modeling.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f9b49242e586cadf1889fa40730ea1652c1b4ef5b15cf15697b58832c4dbf6_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of poor generalization of deep learning models for ECG classification across different datasets. It proposes ECG-RAMBA, a method that separates and then fuses morphological and rhythm features, using a Mamba backbone and a novel pooling operator. The results show that this approach achieves robust zero-shot performance on external datasets, outperforming a baseline model.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ECG-RAMBA: Zero-Shot ECG Generalization] --> B[核心问题/Problem: Poor cross-dataset generalization in ECG classification]
        A --> C[主要方法/Method: Morphology-Rhythm Disentanglement & Long-Range Mamba Modeling]
        A --> D[关键结果/Results: Strong zero-shot AUC on CPSC-2021 & PTB-XL]
    ```

- **[arXiv251230] ISOPO: Proximal policy gradients without pi-old**
  - **tags:** [ai], [reinforcement learning], [natural policy gradient, proximal policy optimization, reinforcement learning fine-tuning, Fisher metric, neural tangent kernel]
  - **authors:** Nilin Abrahamsen
  - **institution:** None (No affiliation or email domain provided in the given content)
  - **link:** https://arxiv.org/pdf/2512.23353
  - **contributions:** 1. Introduces ISOPO, a method to approximate the natural policy gradient in a single gradient step, contrasting with existing methods like GRPO/PPO that require multiple steps. 2. Proposes a simple form of ISOPO that normalizes log-probability gradients in the Fisher metric before contracting with advantages. 3. Presents a variant that transforms microbatch advantages based on the neural tangent kernel layer-wise, enabling efficient implementation with negligible overhead compared to REINFORCE.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa80f3dc48bfe2cf2fc158ecc6c0bb7aefffb89047088c0b23d1d764889fea16_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Isometric Policy Optimization (ISOPO), a new method for approximating the natural policy gradient in reinforcement learning fine-tuning. Unlike existing proximal policy methods like GRPO/PPO which require multiple gradient steps with a reference policy, ISOPO performs the approximation in a single step by normalizing gradients or transforming advantages, achieving this with minimal computational overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ISOPO: Proximal policy gradients without pi-old] --> B[核心问题/Problem: Existing methods (GRPO/PPO) require multiple steps to approximate natural policy gradient]
        A --> C[主要方法/Method: ISOPO approximates natural gradient in single step via Fisher metric normalization or NTK-based advantage transformation]
        A --> D[关键结果/Results: Efficient single-step approximation with negligible overhead vs. REINFORCE]
    ```

- **[arXiv251230] Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [post-training quantization, W8A8, W4A8, Ascend NPU, Chain-of-Thought (CoT)]
  - **authors:** Yilun Luo, HuaQing Zheng, Haoqian Meng, Wenyuan Liu, Peng Zhang
  - **institution:** Tianjin University
  - **link:** https://arxiv.org/pdf/2512.23367
  - **contributions:** 1. Introduces a unified low-bit inference framework for openPangu-Embedded models, supporting INT8 (W8A8) and W4A8 quantization optimized for the Atlas A2 Ascend NPU. 2. Provides a comprehensive evaluation of quantization across three distinct CoT reasoning modes (slow_think, auto_think, no_think) on code generation benchmarks (HumanEval, MBPP). 3. Demonstrates that INT8 quantization preserves over 90% of FP16 accuracy with a 1.5x prefill speedup, while W4A8 significantly reduces memory consumption, enabling efficient CoT reasoning on edge NPUs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07e9cf3e7e8252aa7eae3fdf2e7647007d4786dd6ade9f5c4e940d1c74c4e2cd_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high memory and latency overhead of deploying Chain-of-Thought (CoT) enabled openPangu models on Ascend NPUs by applying post-training quantization (INT8 and W4A8). The proposed framework, optimized for the Atlas A2 hardware, maintains high accuracy for INT8 and reduces memory for W4A8, enabling efficient on-device CoT reasoning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[CoT推理带来高内存与延迟 / CoT reasoning causes high memory & latency]
        B --> B2[Ascend NPU部署挑战 / Deployment challenge on Ascend NPU]
        C --> C1[低比特量化 / Low-bit Quantization]
        C --> C2[统一推理框架 / Unified Inference Framework]
        C --> C3[支持W8A8与W4A8 / Supports W8A8 & W4A8]
        D --> D1[INT8保持>90%精度 / INT8 preserves >90% accuracy]
        D --> D2[1.5倍预填充加速 / 1.5x prefill speedup]
        D --> D3[W4A8显著减少内存 / W4A8 greatly reduces memory]
    ```

- **[arXiv251230] Diffusion priors enhanced velocity model building from time-lag images using a neural operator**
  - **tags:** [ai], [diffusion models], [neural operator, velocity model building, reverse time migration, diffusion model, automatic differentiation]
  - **authors:** Xiao Ma, Mohammad Hasyim Taufik, Tariq Alkhalifah
  - **institution:** King Abdullah University of Science and Technology (KAUST)
  - **link:** https://arxiv.org/pdf/2512.23375
  - **contributions:** 1. Proposes a novel framework that combines generative models (diffusion priors) with neural operators for velocity model building. 2. Uses a neural operator as a fast surrogate for the forward modeling and migration process to generate time-lag images from velocity models. 3. Employs the trained neural operator and automatic differentiation to update the migration velocity, enhanced by a generative model as a regularizer to produce high-resolution, cleaner predictions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f0c5cd7e3ef87aa48d65e94484e956e08ebef522c14cc7eee60600b85109e02a_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new deep learning framework for efficient, high-resolution velocity model building in seismic imaging. The method combines a neural operator, which acts as a fast surrogate for seismic modeling and migration, with a diffusion generative model that serves as a prior to regularize the solution. Experiments on synthetic and field data show the approach effectively builds cleaner, higher-resolution velocity models.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("扩散先验增强的基于神经算子的时滞图像速度建模<br>Diffusion priors enhanced velocity model building from time-lag images using a neural operator")
        Root --> Problem("核心问题/Problem: 传统速度建模方法计算成本高、耗时<br>Conventional VMB is computationally expensive and time-consuming")
        Root --> Method("主要方法/Method: 结合神经算子与生成模型（扩散先验）<br>Combines neural operator with generative model (diffusion prior)")
        Root --> Results("关键结果/Results: 合成与实地数据验证了方法的有效性<br>Synthetic and field data demonstrate effectiveness")
    ```

- **[arXiv251230] A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers**
  - **tags:** [sec], [log anomaly detection], [collaborative transformers, multi-head impressed attention, modality adaptation layer]
  - **authors:** Mohammad Nasirzadeh, Jafar Tahmoresnezhad, Parviz Rashidi-Khazaee
  - **institution:** Urmia University of Technology
  - **link:** https://arxiv.org/pdf/2512.23380
  - **code:** https://github.com/your-repo/CoLog (Note: The provided text states "We also provide the implementation of CoLog atthis https URL." but the specific URL is cut off in the input. Based on the placeholder, the typical format is used. If the exact URL is required, it would be the one following "atthis" in the original text.)
  - **contributions:** 1. Proposes CoLog, a unified framework for detecting both point and collective anomalies in OS logs by applying multimodal sentiment analysis concepts. 2. Introduces collaborative transformers and multi-head impressed attention to learn interactions between different log data modalities. 3. Incorporates a modality adaptation layer to handle heterogeneity and adapt representations from different log modalities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c23025b6b24d4efc5cb993659def89fe785700fbc818c9cc638fe55cdfc5b75e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of log anomaly detection, where existing methods struggle with the multimodal nature of log data and the interactions between these modalities. It proposes CoLog, a framework that uses collaborative transformers and a modality adaptation layer to learn nuanced patterns across log modalities for comprehensive anomaly detection. Extensive experiments show CoLog achieves state-of-the-art performance, with mean precision, recall, and F1 scores over 99.5% across seven benchmark datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers"] --> Problem["核心问题/Problem: Unimodal & multimodal methods fail to handle log data modalities and their interactions"]
        Root --> Method["主要方法/Method: CoLog framework with collaborative transformers, multi-head impressed attention, and modality adaptation layer"]
        Root --> Results["关键结果/Results: Achieves ~99.6% mean precision, recall, F1 on 7 datasets; superior to SOTA"]
    ```

- **[arXiv251230] Beyond-Diagonal Reconfigurable Intelligent Surfaces for 6G Networks: Principles, Challenges, and Quantum Horizons**
  - **tags:** [sys], [communication & networking], [beyond-diagonal RIS, passive beamforming, hybrid quantum-classical ML, 6G networks, reconfigurable intelligent surfaces]
  - **authors:** Abd Ullah Khan, Uman Khalid, Muhammad Tanveer, Trung Q. Duong, Hyundong Shin
  - **institution:** Kyung Hee University, University of Management and Technology, Memorial University of Newfoundland, Queen's University Belfast
  - **link:** https://arxiv.org/pdf/2512.23400
  - **contributions:** 1. Provides a systematic introduction to Beyond-Diagonal Reconfigurable Intelligent Surfaces (BD-RIS), detailing its principles, architecture, advantages, and classification. 2. Presents a case study comparing four beamforming algorithms for BD-RIS, analyzing their performance in terms of sum rate and computation cost. 3. Proposes and analyzes hybrid quantum-classical machine learning models to enhance beam prediction for 6G BD-RIS, validated using the real-world DeepSense 6G dataset.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4756534e0e202824dc7facc5a963e3a3205fc85e2596f60033bcdb6ae4cab497_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Beyond-Diagonal Reconfigurable Intelligent Surfaces (BD-RIS) as a key technology for 6G networks to overcome high-frequency propagation challenges. It systematically reviews BD-RIS principles, analyzes beamforming algorithms, and explores quantum-enhanced machine learning for beam prediction. The work concludes with insights into the practical implications and future potential of BD-RIS for advanced wireless communication.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Beyond-Diagonal RIS for 6G Networks<br/>超越对角可重构智能表面用于6G网络] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br/>6G高频段传播损耗与阻塞<br/>6G high-frequency propagation loss & blockage]
        C[主要方法/Method<br/>系统综述、波束赋形案例研究、量子-经典混合ML<br/>Systematic review, beamforming case study, hybrid quantum-classical ML]
        D[关键结果/Results<br/>获得BD-RIS实用见解与性能分析<br/>Derived practical insights & performance analysis for BD-RIS]
    ```

- **[arXiv251230] Task-driven Heterophilic Graph Structure Learning**
  - **tags:** [ai], [graph neural networks], [graph structure learning, heterophilic graphs, spectral filtering, topology inference, graph rewiring]
  - **authors:** Ayushman Raghuvanshi, Gonzalo Mateos, Sundeep Prabhakar Chepuri
  - **institution:** Indian Institute of Science, University of Rochester
  - **link:** https://arxiv.org/pdf/2512.23406
  - **contributions:** 1. Proposes FgGSL, an end-to-end framework that jointly learns complementary homophilic and heterophilic graph structures using a learnable masking function and processes them with low- and high-pass graph filter banks. 2. Introduces a label-based structural loss to explicitly promote the recovery of homophilic and heterophilic edges, enabling task-driven graph structure learning, and provides theoretical stability bounds for this loss and robustness guarantees for the filters. 3. Demonstrates through experiments on six heterophilic benchmarks that FgGSL consistently outperforms state-of-the-art GNNs and graph rewiring methods, validating the benefit of combining frequency information with supervised topology inference.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3fec9358f601e6c323ecab2e7bcfe1880fd9b9d4351503536e33c58d8cedb6e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of learning discriminative node representations on heterophilic graphs, where connected nodes often have dissimilar labels. The authors propose FgGSL, a framework that jointly learns homophilic and heterophilic graph structures using spectral filters and a task-driven structural loss. Experiments show FgGSL outperforms existing methods, highlighting the advantage of combining frequency guidance with supervised graph inference.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Task-driven Heterophilic Graph Structure Learning] --> B[核心问题/Problem: GNNs struggle on heterophilic graphs]
        A --> C[主要方法/Method: FgGSL - Jointly learns complementary graphs with spectral filters & label-based loss]
        A --> D[关键结果/Results: Outperforms SOTA on benchmarks, benefits of frequency-guided inference]
    ```

- **[arXiv251230] On the Sample Complexity of Learning for Blind Inverse Problems**
  - **tags:** [ai], [inverse problems], [blind inverse problems, Linear Minimum Mean Square Estimators (LMMSEs), Tikhonov regularization, random forward operators, error bounds]
  - **authors:** Nathan Buskulic, Luca Calatroni, Lorenzo Rosasco, Silvia Villa
  - **institution:** Università degli studi di Genova, Italian Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.23405
  - **contributions:** 1. Deriving closed-form expressions for optimal Linear Minimum Mean Square Estimators (LMMSEs) for blind inverse problems and establishing their equivalence with distribution-dependent Tikhonov regularization. 2. Proving convergence results for these estimators under source condition assumptions. 3. Deriving rigorous finite-sample error bounds that quantify the impact of operator randomness, noise level, and sample count on estimator performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/daa1ffc1715fdd9a990c7a6af28c2a415193fdef2bd99ec47e6ece431b0f3406_w640_q70.webp
  - **Simple LLM Summary:** This paper provides a theoretical analysis of learning for blind inverse problems, where the forward operator is unknown. It focuses on Linear Minimum Mean Square Estimators (LMMSEs), deriving their optimal forms and connecting them to Tikhonov regularization. The main conclusion is the establishment of rigorous error bounds and convergence rates that characterize how estimator performance depends on noise, problem conditioning, and the randomness of the forward operator.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[On the Sample Complexity of Learning for Blind Inverse Problems] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[盲逆问题缺乏理论保证/Blind inverse problems lack theoretical guarantees]
        C --> C1[线性最小均方误差估计器框架/LMMSE framework]
        C --> C2[连接吉洪诺夫正则化/Link to Tikhonov regularization]
        D --> D1[闭式最优估计器/Closed-form optimal estimators]
        D --> D2[有限样本误差界/Finite-sample error bounds]
        D --> D3[收敛率分析/Convergence rate analysis]
    ```

- **[arXiv251230] Theoretical Foundations of Scaling Law in Familial Models**
  - **tags:** [mlsys], [llm training], [familial models, scaling law, early exiting, IsoFLOP design, compute-optimal training]
  - **authors:** Huan Song, Qingfei Zhao, Ting Long, Shuyu Tian, Hongjun An, Jiawei Shao, Chi Zhang, Xuelong Li
  - **institution:** Institute of Artificial Intelligence (TeleAI), China Telecom
  - **link:** https://arxiv.org/pdf/2512.23407
  - **contributions:** 1. Theoretically and empirically extends the neural scaling law to the "familial models" paradigm by introducing granularity (G) as a new fundamental scaling variable alongside model size (N) and tokens (D). 2. Proposes a rigorous IsoFLOP experimental design to decouple architectural impact from computational scale, enabling high-fidelity parameterization of the unified scaling law L(N, D, G). 3. Quantifies that the granularity penalty follows a multiplicative power law with an extremely small exponent (γ≈0.041), validating the "train once, deploy many" paradigm without compromising compute-optimality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc66a2a88c82327d2e67ccabca47fcc7a15e81e139a0ed0135b0f3ea93534985_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of traditional neural scaling laws, which assume a single model, by extending them to familial models that generate multiple sub-models from one backbone. The authors propose a unified scaling law incorporating granularity (G) and validate it using a rigorous IsoFLOP experimental design. The key finding is that the performance penalty for increased granularity is very small, proving that deployment flexibility can be achieved efficiently.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Theoretical Foundations of Scaling Law in Familial Models] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统缩放定律忽略多模型范式/Traditional scaling laws overlook the multi-model paradigm]
        C --> C1[引入粒度作为新变量/Introduce Granularity (G) as a new variable]
        C --> C2[统一函数形式 L(N, D, G)/Unified functional form L(N, D, G)]
        C --> C3[采用IsoFLOP实验设计/Employ rigorous IsoFLOP experimental design]
        D --> D1[粒度惩罚遵循幂律/Granularity penalty follows a power law]
        D --> D2[指数极小 (γ≈0.041)/Exponent is extremely small]
        D --> D3[验证"一次训练，多次部署"/Validates "train once, deploy many"]
    ```

- **[arXiv251230] Directly Constructing Low-Dimensional Solution Subspaces in Deep Neural Networks**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [intrinsic dimension, low-rank approximation, subspace-native distillation, weight matrices, empirical spectral density]
  - **authors:** Yusuf Kalyoncuoglu
  - **institution:** RWTH Aachen University
  - **link:** https://arxiv.org/pdf/2512.23410
  - **contributions:** 1. Proposes a constructive method to decouple solution geometry from the ambient search space, bypassing the non-convex optimization bottleneck. 2. Empirically demonstrates significant compression (e.g., factor of 16) of classification heads in models like ResNet-50, ViT, and BERT with minimal performance loss. 3. Introduces "Subspace-Native Distillation" as a novel paradigm to provide a stable geometric coordinate system for student models, enabling "Train Big, Deploy Small".
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d34f960cfbb8a9db281aca58a1b30934c42fc68964647e8066a3754aeb92d38_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the redundancy in large neural networks by proposing a method to directly construct low-dimensional solution subspaces, decoupling the solution geometry from the high-dimensional optimization search space. It shows that classification heads can be heavily compressed without significant performance drops. This leads to a new distillation paradigm that allows student models to learn in a stable, low-dimensional subspace, potentially realizing efficient deployment of compact models.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Directly Constructing Low-Dimensional Solution Subspaces<br>直接构建低维解子空间"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Large models are redundant for representation but needed for optimization.<br>大模型对表示是冗余的，但对优化是必要的。"]
        Method["主要方法/Method<br>Construct low-dimensional subspaces, decouple solution geometry.<br>构建低维子空间，解耦解几何。"]
        Results["关键结果/Results<br>Head compression by 16x, Subspace-Native Distillation.<br>分类头压缩16倍，提出子空间原生蒸馏。"]
    ```

- **[arXiv251230] Towards Integrating Uncertainty for Domain-Agnostic Segmentation**
  - **tags:** [cv], [semantic segmentation], [uncertainty quantification, domain-agnostic, Segment Anything Model (SAM), Laplace approximation, benchmark]
  - **authors:** Jesse Brouwers, Xiaoyan Xing, Alexander Timans
  - **institution:** UvA-Bosch Delta Lab, University of Amsterdam
  - **link:** https://arxiv.org/pdf/2512.23427
  - **code:** https://github.com/JesseBrouw/UncertSAM
  - **contributions:** 1. Curated UncertSAM, a benchmark of eight datasets to stress-test segmentation models under challenging conditions like shadows and camouflage. 2. Evaluated a suite of lightweight, post-hoc uncertainty estimation methods for segmentation foundation models. 3. Assessed a preliminary uncertainty-guided prediction refinement step, finding that last-layer Laplace approximation yields uncertainty estimates well-correlated with segmentation errors.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15865ed74ed61443aa69769e51585f4a7341748fc10c0250eef9243be675f215_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether uncertainty quantification can improve the robustness of foundation segmentation models like SAM in domain-agnostic settings. The authors propose a benchmark (UncertSAM) and evaluate several post-hoc uncertainty estimation methods, finding that a last-layer Laplace approximation provides meaningful uncertainty signals. The results indicate the potential of integrating uncertainty to enhance model generalizability, though refinement benefits are preliminary.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Towards Integrating Uncertainty for Domain-Agnostic Segmentation] --> B[核心问题/Problem: SAM在域偏移或知识有限场景下脆弱/SAM vulnerable in shifted or limited-knowledge domains]
        A --> C[主要方法/Method: 构建UncertSAM基准，评估后验不确定性方法，尝试不确定性引导优化/Build UncertSAM benchmark, evaluate post-hoc UQ methods, attempt uncertainty-guided refinement]
        A --> D[关键结果/Results: 拉普拉斯近似不确定性估计与误差相关，初步验证不确定性整合潜力/Laplace approximation yields correlated uncertainty, preliminary potential of integrating UQ]
    ```

- **[arXiv251230] AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis**
  - **tags:** [mlsys], [gpu kernels], [kernel generation, multi-agent system, domain-specific languages (DSLs), performance tuning, Triton]
  - **authors:** Jinye Du, Quan Yuan, Zuyao Zhang, Yanzhi Yi, Jiahui Hu, Wangyi Chen, Yiyang Zhu, Qishui Zheng, Wenxiang Zou, Xiangyu Chang, Zuohe Zheng, Zichun Ye, Chao Liu, Shanni Li, Renwei Zhang, Yiping Deng, Xinwei Hu, Xuefeng Jin, Jie Zhao
  - **institution:** Huawei Technologies Co., Ltd., Hunan University
  - **link:** https://arxiv.org/pdf/2512.23424
  - **contributions:** 1. Proposed AKG kernel agent, a multi-agent framework that automates the generation, migration, and performance tuning of computational kernels for diverse hardware platforms. 2. Designed the system to support multiple Domain-Specific Languages (DSLs) like Triton, TileLang, CPP, and CUDA-C, enabling cross-platform portability and correctness. 3. Demonstrated the system's effectiveness through evaluation on KernelBench, achieving an average 1.46x speedup over PyTorch Eager baselines on GPU and NPU backends.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40d5942348375e7b86203ab7a7420bba7105494296f349fdd48174b020a1527e_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes AKG kernel agent, a multi-agent framework that automates the development and optimization of high-performance computational kernels for modern AI workloads across diverse hardware. The system supports multiple DSLs for portability and uses LLMs for code generation and tuning. Evaluation shows it achieves a 1.46x average speedup over baseline implementations, effectively accelerating kernel development.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AKG Kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[AI模型对高性能计算内核的需求 / AI Models Demand High-Performance Kernels]
        B --> B2[硬件多样性与手动优化的瓶颈 / Hardware Diversity & Manual Optimization Bottleneck]
        C --> C1[多智能体系统自动化内核生成与调优 / Multi-Agent System Automates Kernel Generation & Tuning]
        C --> C2[支持多种DSL以面向不同硬件后端 / Supports Multiple DSLs for Different Hardware Backends]
        D --> D1[在KernelBench上评估 / Evaluated on KernelBench]
        D --> D2[平均加速1.46倍 / Average 1.46x Speedup Achieved]
    ```

- **[arXiv251230] Stochastic Siamese MAE Pretraining for Longitudinal Medical Images**
  - **tags:** [cv], [medical image analysis], [masked autoencoder, siamese network, stochastic process, longitudinal data, variational inference]
  - **authors:** Taha Emre, Arunava Chakravarty, Thomas Pinetz, Dmitrii Lachinov, Martin J. Menten, Hendrik Scholl, Sobha Sivaprasad, Daniel Rueckert, Andrew Lotery, Stefan Sacu, Ursula Schmidt-Erfurth, Hrvoje Bogunović
  - **institution:** Medical University of Vienna, Imperial College London, Technical University of Munich, University College London, University of Southampton
  - **link:** https://arxiv.org/pdf/2512.23441
  - **contributions:** 1. Proposed STAMP, a novel Siamese MAE framework that incorporates temporal information by conditioning on the time difference between input volumes. 2. Introduced a stochastic learning approach by reframing the MAE reconstruction loss as a conditional variational inference objective to model the uncertainty in disease progression. 3. Demonstrated superior performance of STAMP-pretrained models over existing temporal MAE methods and foundation models on predicting progression of Age-Related Macular Degeneration and Alzheimer's Disease.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c93396b0ded8fc65364d5714bd12e652a23ffc22eb276cbbca01426ecd0db791_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of temporal awareness in self-supervised learning methods like MAE for longitudinal medical images. It proposes STAMP, a stochastic Siamese MAE framework that learns temporal dynamics by conditioning on time differences and using a variational inference objective. The method outperformed existing approaches on disease progression prediction tasks for OCT and MRI datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Stochastic Siamese MAE Pretraining for Longitudinal Medical Images] --> B[核心问题/Problem: MAE lacks temporal awareness for longitudinal medical data.]
        A --> C[主要方法/Method: STAMP - Stochastic Siamese MAE using conditional variational inference.]
        A --> D[关键结果/Results: Outperforms existing methods on AMD and AD progression prediction.]
    ```

- **[arXiv251230] Assessing behaviour coverage in a multi-agent system simulation for autonomous vehicle testing**
  - **tags:** [ai], [multi-agent systems], [Model Predictive Control, Coverage-Based Testing, Edge-Case Exploration, Multi-Agent Simulation, Behaviour Coverage]
  - **authors:** Manuel Franco-Vivo
  - **institution:** University of Bristol
  - **link:** https://arxiv.org/pdf/2512.23445
  - **contributions:** 1. A systematic approach to measure and assess behaviour coverage within a multi-agent simulation for autonomous vehicle testing. 2. The proposal of a Model Predictive Control (MPC) pedestrian agent designed to generate interesting tests and realistic behaviour. 3. Insights and analysis for improving and optimizing simulation frameworks through behaviour coverage metrics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/385ed91e6ca24b7cc0e8d369cc587a3dd677cf4643f89f27d85aaadf4cd4ea70_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the need for comprehensive testing of autonomous vehicles by analyzing behaviour coverage in multi-agent simulations. It proposes a systematic method to measure coverage and introduces an MPC-based pedestrian agent to generate more realistic and challenging test scenarios. The research concludes that assessing behaviour coverage is crucial for validating the robustness of autonomous systems and improving simulation frameworks.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Assessing Behaviour Coverage in a Multi-Agent System Simulation for Autonomous Vehicle Testing] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[如何全面评估自动驾驶系统在模拟环境中的行为覆盖度？/How to comprehensively evaluate behaviour coverage of AV systems in simulation?]
    C --> C1[定义场景与交互，提出MPC行人智能体/Define scenarios & interactions, propose MPC pedestrian agent]
    D --> D1[行为覆盖度对验证系统有效性至关重要/Behaviour coverage is crucial for validating system effectiveness]
    ```

- **[arXiv251230] Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss**
  - **tags:** [mlsys], [llm training], [Mixture-of-Experts, Router-Expert Coupling, Auxiliary Loss, Expert Specialization, Efficient Training]
  - **authors:** Ang Lv, Jin Ma, Yiyuan Ma, Siyuan Qiao
  - **institution:** ByteDance, Renmin University of China
  - **link:** https://arxiv.org/pdf/2512.23447
  - **contributions:** 1. Proposes a novel lightweight auxiliary loss (ERC loss) to explicitly couple router decisions with expert capabilities in MoE models. 2. Introduces a computationally efficient method that scales with the square of the number of experts (n^2), independent of batch size, unlike prior token-dependent methods. 3. Enables flexible control and quantitative tracking of expert specialization levels during training, providing new insights into MoE model dynamics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6534d4f2f88c89a450614cf67b57f76f33fc90a18f24833876fd8e55d3e326b9_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the misalignment between router decisions and expert capabilities in Mixture-of-Experts (MoE) models. It proposes an Expert-Router Coupling (ERC) loss, a lightweight auxiliary loss that enforces constraints via perturbed router embeddings to ensure each expert specializes in its routed tokens and each router embedding faithfully represents its expert. The method is shown to be effective and computationally efficient, enabling better control and analysis of expert specialization during large-scale pre-training.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[耦合专家与路由器<br/>Coupling Experts and Routers in Mixture-of-Experts] --> B[核心问题/Problem: 路由器决策与专家能力不匹配<br/>Router decisions misaligned with expert capabilities]
        A --> C[主要方法/Method: 提出专家-路由器耦合损失 (ERC Loss)<br/>Propose Expert-Router Coupling (ERC) Loss]
        A --> D[关键结果/Results: 提升模型性能，高效计算，可量化追踪专家专业化<br/>Improved performance, efficient computation, quantifiable tracking of specialization]
        C --> E[方法原理/Mechanism: 使用扰动路由器嵌入作为代理令牌<br/>Use perturbed router embeddings as proxy tokens]
        E --> F[约束/Constraints: 专家对自身代理令牌激活最高；代理令牌引发对应专家最强激活<br/>Expert highest activation for own proxy; Proxy elicits strongest activation from corresponding expert]
    ```

- **[arXiv251230] Dynamic Subspace Composition: Efficient Adaptation via Contractive Basis Expansion**
  - **tags:** [mlsys], [llm inference], [Mixture of Experts, Parameter-Efficient Fine-Tuning, Low-Rank Adaptation, Memory-Bandwidth Bottleneck, Dynamic Sparse Dictionary Learning]
  - **authors:** Vladimer Khasia
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2512.23448
  - **code:** https://github.com/VladimerKhasia/DSC
  - **contributions:** 1. Proposes Dynamic Subspace Composition (DSC), a framework that models weight updates as a residual trajectory within a Star-Shaped Domain using Magnitude-Gated Simplex Interpolation for continuity. 2. Decouples storage and adaptation rank, constructing compositional approximations from a shared basis bank to reduce parameter complexity from O(Mrd) to O(Md) and memory traffic to O(Kd). 3. Introduces Frame-Theoretic regularization and spectral constraints to provide rigorous worst-case bounds on the dynamic update, addressing representation collapse and gradient instability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/713ad8af3e30c492117d0d3f26babbf5fe909df2e68e0ab479fc866276a3d80c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the memory-bandwidth bottleneck and optimization instability in Mixture of Experts (MoE) models. It proposes Dynamic Subspace Composition (DSC), a method that approximates context-dependent weights via a sparse expansion of a shared basis, reducing parameter complexity and memory traffic while ensuring stable updates. The main conclusion is that DSC offers a more efficient and theoretically grounded alternative to standard approaches like Mixture-of-LoRAs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Dynamic Subspace Composition<br/>动态子空间组合] --> B[Problem<br/>核心问题]
        A --> C[Method<br/>主要方法]
        A --> D[Results<br/>关键结果]
        B --> B1[MoE suffers from<br/>representation collapse &<br/>memory bottleneck<br/>MoE存在表示崩溃与内存瓶颈]
        C --> C1[Dynamic Sparse Dictionary Learning<br/>动态稀疏字典学习]
        C1 --> C2[Star-Shaped Domain &<br/>Magnitude-Gated Simplex Interpolation<br/>星形域与幅度门控单纯形插值]
        D --> D1[Reduced complexity<br/>O(Md) & O(Kd)<br/>降低复杂度]
        D --> D2[Frame-Theoretic bounds<br/>框架理论边界]
    ```

- **[arXiv251230] Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following**
  - **tags:** [ai], [reinforcement learning], [instruction following, hindsight replay, sample-efficient RL]
  - **authors:** Kongcheng Zhang, Qi Yao, Shunyu Liu, Wenjian Zhang, Min Cen, Yang Zhou, Wenkai Fang, Yiru Zhao, Baisheng Lai, Mingli Song
  - **institution:** Zhejiang University, Cainiao Network, Nanyang Technological University, Dalian University of Technology, University of Science and Technology of China, Alibaba Cloud Computing, Chinese Academy of Sciences
  - **link:** https://arxiv.org/pdf/2512.23457
  - **code:** https://github.com/zhangkc97/HiR
  - **contributions:** 1. Proposes Hindsight instruction Replay (HiR), a novel RL framework that replays failed attempts as successes using a select-then-rewrite strategy to address sparse rewards. 2. Theoretically frames the RL objective as dual-preference learning at both instruction- and response-level, enabling efficient optimization with only binary rewards. 3. Demonstrates sample efficiency and promising results across various instruction following tasks with reduced computational budget.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of sparse rewards in RL for aligning LLMs to follow complex instructions. It proposes HiR, a sample-efficient framework that replays failed responses as successful ones based on partially satisfied constraints, framed as dual-preference learning. Experiments show HiR achieves strong performance on instruction-following tasks while being more computationally efficient.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Replay Failures as Successes: Sample-Efficient RL for Instruction Following] --> Problem
        Root --> Method
        Root --> Results
        Problem[稀疏/不可区分的奖励阻碍学习<br>Sparse/Indistinguishable Rewards Impede Learning]
        Method[后见指令重放 (HiR)<br>Hindsight instruction Replay (HiR)]
        Results[跨任务有效且计算高效<br>Effective Across Tasks & Computationally Efficient]
    ```

- **[arXiv251230] Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance**
  - **tags:** [ai], [reinforcement learning from human feedback (RLHF)], [reward model, inductive bias, information bottleneck, mutual information, reward hacking]
  - **authors:** Zhuo Li, Pengyu Cheng, Zhechao Yu, Feifei Tong, Anningzhe Gao, Tsung-Hui Chang, Xiang Wan, Erchao Zhao, Xiaoxi Jiang, Guanjun Jiang
  - **institution:** Alibaba, The Chinese University of Hong Kong, Shenzhen Research Institute of Big Data
  - **link:** https://arxiv.org/pdf/2512.23461
  - **code:** https://github.com/Qwen-Applications/DIR
  - **contributions:** 1. Proposes DIR, a novel information-theoretic debiasing method for reward models that maximizes mutual information with human preference while minimizing it with biased attributes. 2. Theoretically justifies the method's ability to handle complex, non-linear inductive biases, extending beyond simple linear correlation models. 3. Empirically demonstrates DIR's effectiveness in mitigating three types of biases (length, sycophancy, format) and shows it enhances RLHF performance and generalization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/522f5bbb5a5776cd8df024fb1b24faf19bb1a1ea6e0408c7951f37bfd1657846_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of inductive biases in reward models (RMs) for RLHF, which can lead to overfitting and reward hacking. It proposes DIR, an information-theoretic debiasing method inspired by the information bottleneck that optimizes mutual information to reduce bias. Experiments show DIR effectively mitigates multiple biases and improves RLHF performance and generalization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Eliminating Inductive Bias in Reward Models<br>消除奖励模型中的归纳偏差] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Low-quality RM data with inductive biases<br>导致过拟合和奖励攻击] --> B1[举例/Example<br>Response length bias<br>响应长度偏差]
        C[主要方法/Method<br>DIR: Information-theoretic debiasing<br>基于信息瓶颈优化互信息] --> C1[目标/Objective<br>Max MI with preference, Min MI with bias<br>最大化偏好互信息，最小化偏差互信息]
        D[关键结果/Results<br>Mitigates multiple biases & enhances RLHF<br>减轻多种偏差并提升RLHF性能] --> D1[验证的偏差/Verified Biases<br>Length, Sycophancy, Format<br>长度、迎合性、格式]
    ```

- **[arXiv251230] FRoD: Full-Rank Efficient Fine-Tuning with Rotational Degrees for Fast Convergence**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [Parameter-efficient fine-tuning, LoRA, full-rank adaptation, rotational degrees of freedom, hierarchical joint decomposition]
  - **authors:** Guoan Wan, Tianyu Chen, Fangzheng Feng, Haoyi Zhou, Runhua Xu
  - **institution:** Beihang University, Huazhong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.23485
  - **code:** https://github.com/Bane-Elvin/AAAI2026-FRoD
  - **contributions:** 1. Proposes FRoD, a novel PEFT method that combines hierarchical joint decomposition with rotational degrees of freedom for full-rank updates. 2. Introduces a globally shared basis and sparse, learnable perturbations to enhance expressiveness and efficiency beyond low-rank constraints. 3. Demonstrates that FRoD matches full fine-tuning accuracy on 20 benchmarks while using only 1.72% of trainable parameters and achieves faster convergence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e211fe6dc2d8e782c731fff29ba32c9fe2a1f958b475d5931d50f6e8fd04fdb8_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the slow convergence and limited capacity of low-rank PEFT methods like LoRA. It proposes FRoD, a method that enables full-rank updates via a shared basis and sparse perturbations, achieving faster convergence. The method matches full fine-tuning accuracy on diverse benchmarks while using only a tiny fraction of parameters.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FRoD: Full-Rank Efficient Fine-Tuning] --> B[核心问题/Problem: Low-rank PEFT methods suffer from slow convergence and limited adaptation capacity]
        A --> C[主要方法/Method: Hierarchical joint decomposition with rotational degrees of freedom for full-rank updates]
        A --> D[关键结果/Results: Matches full fine-tuning accuracy using only 1.72% parameters and achieves faster convergence]
    ```

- **[arXiv251230] ML Compass: Navigating Capability, Cost, and Compliance Trade-offs in AI Model Deployment**
  - **tags:** [mlsys], [llm inference], [model selection, capability-cost frontier, constrained optimization, deployment-aware leaderboards, compliance trade-offs]
  - **authors:** Vassilis Digalakis Jr, Ramayya Krishnan, Gonzalo Martin Fernandez, Agni Orfanoudaki
  - **institution:** Boston University, Carnegie Mellon University, Universitat Politècnica de Catalunya, Oxford University
  - **link:** https://arxiv.org/pdf/2512.23487
  - **contributions:** 1. Proposes ML Compass, a framework that treats AI model selection as constrained optimization over a capability-cost frontier to bridge the gap between capability leaderboards and deployment decisions. 2. Characterizes optimal model configurations theoretically, showing a three-regime structure in internal measures and deriving comparative statics for budget, regulation, and technology changes. 3. Implements a practical pipeline that extracts internal measures, estimates an empirical frontier, learns task-specific utility, and validates with case studies in conversational and healthcare settings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0c28f58754a80430c57b0351355d200ab9fbfde8dd5fafc1b0d5caf4dd85bbb_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the gap between AI model capability rankings and real-world deployment decisions by introducing ML Compass, a framework that formulates model selection as constrained optimization over a capability-cost frontier. It combines theoretical analysis of optimal configurations with an implementation pipeline for recommendation, validated in conversational and healthcare case studies. The framework shows that deployment-aware rankings can differ significantly from capability-only leaderboards, clarifying trade-offs between capability, cost, and compliance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("ML Compass: Navigating Capability, Cost, and Compliance Trade-offs in AI Model Deployment") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("能力排行榜与部署决策脱节/Capability-Deployment Gap")
        Problem --> P2("需平衡用户效用、成本、合规性/Balance Utility, Cost, Compliance")
        Method --> M1("理论: 基于前沿的约束优化/Theoretical Constrained Optimization")
        Method --> M2("实现: 提取、估计、学习、推荐/Pipeline: Extract, Estimate, Learn, Recommend")
        Results --> R1("最优配置呈现三区结构/Optimal Configurations Show Three-Regime Structure")
        Results --> R2("部署感知排名不同于能力排名/Deployment-Aware Rankings Differ from Capability-Only")
    ```

- **[arXiv251230] Joint Link Adaptation and Device Scheduling Approach for URLLC Industrial IoT Network: A DRL-based Method with Bayesian Optimization**
  - **tags:** [sys], [communication & networking], [URLLC, Link Adaptation, Device Scheduling, Deep Reinforcement Learning, Bayesian Optimization]
  - **authors:** Wei Gao, Paul Zheng, Peng Wu, Yulin Hu, Anke Schmeink
  - **institution:** Wuhan University, RWTH Aachen University
  - **link:** https://arxiv.org/pdf/2512.23493
  - **contributions:** 1. Proposes a joint link adaptation and device scheduling design for multi-device URLLC IIoT networks under imperfect CSI, aiming to maximize total transmission rate under strict BLER constraints. 2. Introduces a novel Bayesian Optimization-driven Twin Delayed Deep Deterministic Policy Gradient (BO-TD3) method to adaptively determine device serving order and MCS based on outdated CQI. 3. Develops a BO-based training mechanism to address issues of error sample imbalance and TD3 parameter sensitivity, improving convergence speed and learning reliability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa25685331ccee6042c70838d3438022f95490a2cc609beba627f444cba8cd7c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of joint link adaptation and device scheduling in URLLC IIoT networks with imperfect channel state information. It proposes a novel deep reinforcement learning method (BO-driven TD3) that adaptively selects the device serving order and modulation schemes, enhanced by Bayesian Optimization for faster and more reliable training. Simulation results show the proposed algorithm achieves faster convergence and higher sum-rate performance compared to existing solutions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Joint Link Adaptation and Device Scheduling Approach for URLLC Industrial IoT Network] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[URLLC IIoT网络的多设备动态调度与链路自适应/URLLC IIoT Multi-device Dynamic Scheduling & Link Adaptation]
        B --> B2[不完美的信道状态信息/Imperfect Channel State Information]
        B --> B3[严格的误块率约束/Strict Block Error Rate Constraints]
        C --> C1[贝叶斯优化驱动的TD3方法/BO-driven TD3 Method]
        C --> C2[自适应确定设备服务顺序与MCS/Adaptively Determine Device Order & MCS]
        C --> C3[BO训练机制改进收敛/BO-based Training for Convergence]
        D --> D1[更快的收敛速度/Faster Convergence]
        D --> D2[更高的总速率性能/Higher Sum-rate Performance]
    ```

- **[arXiv251230] Trustworthy Machine Learning under Distribution Shifts**
  - **tags:** [ai], [trustworthy machine learning], [distribution shift, robustness, explainability, adaptability]
  - **authors:** Zhuo Huang
  - **institution:** The University of Sydney
  - **link:** https://arxiv.org/pdf/2512.23524
  - **contributions:** 1. Proposes a systematic framework for studying Trustworthy Machine Learning by categorizing three common types of distribution shifts (Perturbation, Domain, Modality). 2. Rigorously investigates trustworthiness through three key aspects: Robustness, Explainability, and Adaptability. 3. Aims to provide effective solutions and fundamental insights to enhance critical ML problems like efficiency and safety under distribution shifts.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8153efa2ea5f1ee68438cc93b22e23dd850b2f55b7ebc99a5374a4a32aea0bb4_w640_q70.webp
  - **Simple LLM Summary:** This thesis addresses the core problem of distribution shift, which limits the reliability and trustworthiness of AI systems. The research proposes a framework that studies three types of distribution shifts and evaluates solutions through the lenses of robustness, explainability, and adaptability. The goal is to develop more reliable, versatile, and responsible machine learning models that can generalize effectively under real-world distribution shifts.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Trustworthy Machine Learning under Distribution Shifts<br>分布偏移下的可信机器学习"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Distribution shift limits AI reliability & trust<br>分布偏移限制AI可靠性与信任"] --> P1["扰动偏移/Perturbation Shift"]
        Problem --> P2["域偏移/Domain Shift"]
        Problem --> P3["模态偏移/Modality Shift"]
        Method["主要方法/Method<br>Study trustworthiness via three aspects<br>从三个维度研究可信度"] --> M1["鲁棒性/Robustness"]
        Method --> M2["可解释性/Explainability"]
        Method --> M3["适应性/Adaptability"]
        Results["关键结果/Results<br>Propose solutions & insights<br>提出解决方案与洞见"] --> R1["增强关键问题/Enhance critical problems"]
        R1 --> R1_Sub["效率, 适应性, 安全<br>Efficiency, Adaptability, Safety"]
    ```

- **[arXiv251230] EEG-based Graph-guided Domain Adaptation for Robust Cross-Session Emotion Recognition**
  - **tags:** [ai], [affective computing], [domain adaptation, graph regularization, EEG, emotion recognition, cross-session]
  - **authors:** Maryam Mirzaei, Farzaneh Shayegh, Hamed Narimani
  - **institution:** Based on author names and content, specific institution not provided. Could be inferred from typical academic affiliations in this field, but not explicitly stated in the given text.
  - **link:** https://arxiv.org/pdf/2512.23526
  - **contributions:** 1. Proposed EGDA, a novel framework integrating domain adaptation with graph-based regularization for cross-session EEG emotion recognition. 2. Introduced a method to jointly align both marginal and conditional distributions while preserving the intrinsic data structure. 3. Demonstrated the discriminative power of the Gamma frequency band and identified critical brain regions (central-parietal and prefrontal) for emotion recognition.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97864260ef21b4d340e353b5b1666e9df5860104730e726e9067386c78cadc72_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of cross-session EEG emotion recognition by proposing EGDA, a framework that reduces distribution discrepancies through joint marginal and conditional alignment while using graph regularization to preserve data structure. Experiments on the SEED-IV dataset show EGDA outperforms baselines, achieving robust accuracies. The analysis further identifies the Gamma band and specific brain regions as key for reliable emotion recognition.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[EEG-based Graph-guided Domain Adaptation for Robust Cross-Session Emotion Recognition] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Cross-session EEG distribution shifts hinder emotion recognition model generalization.]
        Method[主要方法/Method: EGDA framework aligns marginal & conditional distributions with graph regularization.]
        Results[关键结果/Results: Achieves robust accuracy on SEED-IV; Gamma band and central-parietal/prefrontal regions are most discriminative.]
    ```

- **[arXiv251230] VL-RouterBench: A Benchmark for Vision-Language Model Routing**
  - **tags:** [mlsys], [multi-modal inference], [vision-language model routing, benchmark, cost-accuracy trade-off, model selection, evaluation protocol]
  - **authors:** Zhehao Huang, Baijiong Lin, Jingyuan Zhang, Jingying Wang, Yuhang Liu, Ning Lu, Tao Li, Xiaolin Huang
  - **institution:** Shanghai Jiao Tong University, The Hong Kong University of Science and Technology (Guangzhou), The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.23562
  - **code:** https://github.com/K1nght/VL-RouterBench
  - **contributions:** 1. Proposes VL-RouterBench, the first systematic and reproducible benchmark for evaluating vision-language model (VLM) routing systems. 2. Constructs a large-scale evaluation foundation with quality and cost matrices over 519,180 sample-model pairs from 17 models and 14 datasets. 3. Introduces a comprehensive evaluation protocol that jointly measures accuracy, cost, and throughput, and uses a ranking score based on the harmonic mean for fair comparison across router configurations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/885d9087464eedead5301ad4cd041923ddee6d5773371e117abbd30fc4ae4f09_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces VL-RouterBench, a benchmark to systematically evaluate routing systems for vision-language models. It constructs matrices of quality and cost from extensive inference logs and uses a ranking score to compare routers. The evaluation shows current routers achieve significant gains but still fall short of an ideal Oracle, indicating room for improvement in router design.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[VL-RouterBench: A Benchmark for Vision-Language Model Routing] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br>缺乏系统化、可复现的<br>VLM路由评估基准<br>Lack of systematic, reproducible<br>benchmark for VLM routing]
        Method[主要方法/Method<br>基于原始推理日志构建<br>质量与成本矩阵<br>Construct quality & cost matrices<br>from raw inference logs]
        Results[关键结果/Results<br>观察到显著的路由增益<br>但与理想性能仍有差距<br>Observe significant routability gain<br>but clear gap to ideal Oracle]
    ```

- **[arXiv251230] Distribution-Free Process Monitoring with Conformal Prediction**
  - **tags:** [ai], [anomaly detection], [Conformal Prediction, Statistical Process Control, Control Charts, Anomaly Detection, Quality Management]
  - **authors:** Christopher Burger
  - **institution:** The University of Mississippi
  - **link:** https://arxiv.org/pdf/2512.23602
  - **contributions:** 1. A hybrid framework integrating Conformal Prediction's distribution-free guarantees into Statistical Process Control (SPC). 2. Conformal-Enhanced Control Charts that visualize process uncertainty and enable proactive signals like 'uncertainty spikes'. 3. Conformal-Enhanced Process Monitoring that reframes multivariate control as a formal anomaly detection problem using an intuitive p-value chart.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b25b4ce8de4803a0d1cc60a16d7221589651a9a271d92f85fb5b6426127e8b4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of traditional Statistical Process Control (SPC), which relies on often-violated statistical assumptions, by proposing a hybrid framework that integrates distribution-free Conformal Prediction. The method introduces two novel applications: enhanced control charts for visualizing uncertainty and a p-value chart for formal anomaly detection. The framework provides a more robust and statistically rigorous approach to quality control while maintaining the interpretability of classic methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Distribution-Free Process Monitoring with Conformal Prediction] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统SPC依赖统计假设，不可靠/Traditional SPC relies on statistical assumptions, unreliable]
        C --> C1[将保形预测与SPC结合的混合框架/Hybrid framework integrating Conformal Prediction with SPC]
        C1 --> C2[保形增强控制图/Conformal-Enhanced Control Charts]
        C1 --> C3[保形增强过程监控/Conformal-Enhanced Process Monitoring]
        D --> D1[更鲁棒、统计严谨的质量控制方法/More robust, statistically rigorous quality control]
        D --> D2[保持经典方法的可解释性和易用性/Maintains interpretability and ease of use of classic methods]
    ```

- **[arXiv251230] Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning**
  - **tags:** [ai], [transfer learning], [Le Cam Distortion, Deficiency Distance, Directional Simulability, Unsupervised Domain Adaptation, Negative Transfer]
  - **authors:** Deniz Akdemir
  - **institution:** None (Institution not specified in provided content)
  - **link:** https://arxiv.org/pdf/2512.23617
  - **contributions:** 1. Proposes a decision-theoretic framework for robust transfer learning based on Le Cam's theory, replacing symmetric invariance with directional simulability. 2. Introduces Le Cam Distortion, quantified by the Deficiency Distance, as a rigorous upper bound for transfer risk. 3. Demonstrates the framework's effectiveness across diverse experiments (genomics, vision, RL), showing it prevents source degradation and catastrophic negative transfer where traditional methods fail.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bd736028263c7eaaaaecae78f0df59f633374608f59295b1185c8385eea1e5_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a flaw in standard Unsupervised Domain Adaptation, which can cause harmful "negative transfer" by forcing invariance between unequally informative domains. It proposes a new framework based on Le Cam's theory, using directional simulability and a metric called Le Cam Distortion to enable safe transfer without degrading the source domain. Experiments show this method successfully prevents information loss and catastrophic failure in safety-critical applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[标准UDA的缺陷/Flaw of Standard UDA]
        Problem --> P2[负迁移与信息破坏/Negative Transfer & Information Destruction]
        Method --> M1[Le Cam理论/Le Cam's Theory]
        Method --> M2[方向可模拟性/Directional Simulability]
        Method --> M3[Le Cam Distortion度量/Le Cam Distortion Metric]
        Results --> R1[基因组学完美估计/Perfect Genomics Estimation]
        Results --> R2[零源域损失/Zero Source Utility Loss]
        Results --> R3[安全RL策略转移/Safe RL Policy Transfer]
    ```

- **[arXiv251230] Regret-Based Federated Causal Discovery with Unknown Interventions**
  - **tags:** [mlsys], [federated learning], [causal discovery, unknown interventions, differential privacy, Φ-CPDAG, regret-based]
  - **authors:** Federico Baldo, Charles K. Assaad
  - **institution:** Sorbonne Université, INSERM, Institut Pierre Louis d'Epidémiologie et de Santé Publique
  - **link:** https://arxiv.org/pdf/2512.23626
  - **contributions:** 1. Proposes I-PERI, a novel federated causal discovery algorithm that handles unknown client-level interventions, 2. Introduces the Φ-Markov Equivalence Class (Φ-CPDAG), a tighter equivalence class derived from structural differences across clients, 3. Provides theoretical guarantees on convergence and privacy-preserving properties (differential privacy).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373e2e9b4041d9efb71fbe2d1095901813d7f2551cdfe37d40d79c04d7aa235d_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses federated causal discovery where client data are subject to unknown, heterogeneous interventions, a common real-world scenario overlooked by prior work. It proposes the I-PERI algorithm, which first recovers the union CPDAG and then orients additional edges by exploiting intervention-induced structural differences across clients, resulting in a tighter equivalence class called the Φ-CPDAG. Theoretical and empirical results demonstrate the algorithm's effectiveness and privacy guarantees.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Regret-Based Federated Causal Discovery with Unknown Interventions] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 联邦因果发现中客户端存在未知异质干预/Federated causal discovery with unknown, heterogeneous client interventions]
        C[主要方法/Method: 提出I-PERI算法，利用干预差异定向边/Propose I-PERI algorithm, orienting edges using intervention differences]
        D[关键结果/Results: 定义Φ-CPDAG，提供理论与隐私保证/Define Φ-CPDAG, provide theoretical and privacy guarantees]
    ```

- **[arXiv251230] Memorization in 3D Shape Generation: An Empirical Study**
  - **tags:** [cv], [3D shape generation], [memorization, diffusion models, latent vector-set, evaluation framework, data leakage]
  - **authors:** Shu Pu, Boya Zeng, Kaichen Zhou, Mengyu Wang, Zhuang Liu
  - **institution:** Princeton University, Harvard University
  - **link:** https://arxiv.org/pdf/2512.23628
  - **code:** github.com/zlab-princeton/3d_mem
  - **contributions:** 1. Proposed a novel evaluation framework to quantify memorization in 3D generative models. 2. Applied the framework to benchmark and quantify memorization in existing 3D generation methods. 3. Conducted controlled experiments to identify how data and modeling factors (e.g., modality, guidance scale, augmentation) influence memorization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cca470d9a610f6e7172776f63b7bfed02850fdb4a843786976b699c63c87febc_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether 3D shape generative models memorize training data. The authors design an evaluation framework to measure memorization and conduct experiments with a latent vector-set diffusion model. They find memorization depends on data modality and diversity, peaks at moderate guidance, and can be reduced with longer latent vectors and rotation augmentation without harming quality.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Memorization in 3D Shape Generation: An Empirical Study] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1(3D生成模型是否记忆训练数据?/Do 3D generative models memorize training data?)
        C --> C1(设计量化框架/Design evaluation framework)
        C --> C2(使用Vecset扩散模型进行控制实验/Use Vecset diffusion model for controlled experiments)
        D --> D1(数据多样性和细粒度条件增加记忆/Data diversity & fine-grained conditioning increase memorization)
        D --> D2(适度引导规模峰值记忆/Moderate guidance scale peaks memorization)
        D --> D3(更长Vecsets和旋转增强可缓解记忆/Longer Vecsets & rotation augmentation mitigate memorization)
    ```

- **[arXiv251230] BOAD: Discovering Hierarchical Software Engineering Agents via Bandit Optimization**
  - **tags:** [mlsys], [agent system], [multi-agent systems, hierarchical agents, bandit optimization, software engineering agents, SWE-bench]
  - **authors:** Iris Xu, Guangtao Zeng, Zexue He, Charles Jin, Aldo Pareja, Dan Gutfreund, Chuang Gan, Zhang-Wei Hong
  - **institution:** Massachusetts Institute of Technology, MIT-IBM Watson AI Lab, Stanford University, University of Massachusetts Amherst
  - **link:** https://arxiv.org/pdf/2512.23631
  - **code:** https://github.com/iamxjy/BOAD-SWE-Agent
  - **contributions:** 1. Formulates the automatic discovery of effective hierarchical multi-agent systems for software engineering as a multi-armed bandit (MAB) problem, enabling efficient exploration under limited budgets. 2. Proposes the BOAD framework, which uses bandit optimization to coordinate specialized sub-agents (e.g., for localization, editing, validation) and attribute credit within a team. 3. Demonstrates that automatically discovered hierarchical agents outperform single-agent and manually designed multi-agent systems on challenging, out-of-distribution SWE benchmarks, including achieving second place on SWE-bench-Live with a 36B model.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67084d40c24e3869f47efa4b52c7ec1479016d613997e911c6730d7e7684254f_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the poor generalization of single-agent LLMs on long-horizon, out-of-distribution software engineering tasks by proposing a hierarchical multi-agent system. The core method, BOAD, automatically discovers effective agent hierarchies by formulating the search as a multi-armed bandit optimization problem. The results show that this approach significantly improves performance on SWE benchmarks, surpassing larger models like GPT-4 and Claude.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[BOAD: 发现分层软件工程代理 / BOAD: Discovering Hierarchical Software Engineering Agents] --> B
        A --> C
        A --> D
        B[核心问题 / Problem: 单一LLM代理在长视野、分布外软件工程任务上泛化能力差 / Single-agent LLMs generalize poorly on long-horizon, out-of-distribution SWE tasks]
        C[主要方法 / Method: 将分层发现建模为多臂老虎机问题，优化子代理协作 / Formulate hierarchy discovery as a multi-armed bandit problem to optimize sub-agent collaboration]
        D[关键结果 / Results: 在SWE-bench上超越单代理和手动设计的多代理系统，36B模型排名第二 / Outperforms single-agent and manual multi-agent systems on SWE-bench, 36B model ranks second]
    ```

- **[arXiv251230] AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms**
  - **tags:** [ai], [educational ai], [generative AI, fine-tuning, randomized controlled trial, Socratic questioning, pedagogical instruction]
  - **authors:** LearnLM Team Google, Eedi, Albert Wang, Aliya Rysbek, Andrea Huber, Anjali Nambiar, Anna Kenolty, Ben Caulfield, Beth Lilley-Draper, Bibi Groot, Brian Veprek, Chelsea Burdett, Claire Willis, Craig Barton, Digory Smith, George Mu, Harriet Walters, Irina Jurenka, Iris Hulls, James Stalley-Moores, Jonathan Caton, Julia Wilkowski, Kaiz Alarakyia, Kevin R. McKee, Liam McCafferty, Lucy Dalton, Markus Kunesch, Pauline Malubay, Rachel Kidson, Rich Wells, Sam Wheeler, Sara Wiltberger, Shakir Mohamed, Simon Woodhead, Vasco Brazão
  - **institution:** Google, Eedi
  - **link:** https://arxiv.org/pdf/2512.23633
  - **contributions:** 1. Conducted a rigorous, in-classroom exploratory RCT to evaluate the safety and efficacy of a generative AI tutor (LearnLM) in a real educational setting. 2. Demonstrated that a pedagogically fine-tuned AI model can reliably draft instructional content, with human tutors approving 76.4% of its messages with minimal or no edits. 3. Showed that AI-supported tutoring led to student performance at least equivalent to human-only tutoring, with a significant 5.5 percentage point improvement in solving novel problems on subsequent topics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b430e7c78534d660126208f226397ed95756e540bade56276301199a0114bc76_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether generative AI can scale effective one-to-one tutoring. The authors integrated LearnLM, a pedagogically fine-tuned AI model, into a math tutoring platform and conducted a randomized controlled trial where human tutors supervised its outputs. The results show that LearnLM was a reliable tutor, and students using it performed as well as or better than those with human tutors alone, suggesting AI can deliver effective, individualized learning support at scale.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[AI Tutoring RCT in UK Classrooms] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[个性化辅导成本高/High cost of 1-to-1 tutoring]
        Problem --> P2[AI辅导的有效性与安全性未知/Unproven efficacy & safety of AI tutoring]
        Method --> M1[整合LearnLM模型/Integrate LearnLM (pedagogically fine-tuned AI)]
        Method --> M2[在Eedi平台进行RCT/Conduct RCT on Eedi platform]
        Method --> M3[专家导师监督输出/Human tutors supervise AI drafts]
        Results --> R1[76.4%消息被直接批准/76.4% messages approved with minimal edits]
        Results --> R2[学生表现相当或更好/Student performance equal or better]
        Results --> R3[解决新问题能力提升5.5%/5.5% improvement on novel problems]
    ```

- **[arXiv251230] Simultaneous Approximation of the Score Function and Its Derivatives by Deep Neural Networks**
  - **tags:** [ai], [diffusion models], [score function, approximation theory, deep neural networks, curse of dimensionality, Ornstein-Uhlenbeck process]
  - **authors:** Konstantin Yakovlev, Nikita Puchkin
  - **institution:** HSE University
  - **link:** https://arxiv.org/pdf/2512.23643
  - **contributions:** 1. Presents a theory for simultaneous approximation of the score function and its derivatives, extending beyond the first-order setting. 2. Derives approximation error bounds that are free from the curse of dimensionality. 3. Relaxes the common assumption of bounded data support, enabling handling of distributions with low-dimensional structure and unbounded support.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3404ba95328f082dc11706309fc0e30ca110b3f842a24921698b46a1065bfda6_w640_q70.webp
  - **Simple LLM Summary:** This paper develops a theoretical framework for using deep neural networks to approximate the score function and its derivatives simultaneously. The method relaxes the typical bounded support assumption and provides error bounds that avoid the curse of dimensionality. The main conclusion is that this theory enables more efficient handling of complex data distributions, which is crucial for improving the convergence of diffusion and ODE-based generative models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Simultaneous Approximation of the Score Function and Its Derivatives by Deep Neural Networks] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[需要同时逼近分数函数及其导数/Need to approximate score function and its derivatives]
        B --> B2[处理无界支撑和低维结构数据/Handle data with unbounded support & low-dim structure]
        C --> C1[深度神经网络理论框架/Deep Neural Network theoretical framework]
        D --> D1[逼近误差无维度诅咒/Approximation bounds free from curse of dimensionality]
        D --> D2[放松有界支撑假设/Relaxes bounded support assumption]
        D --> D3[保证任意阶导数逼近/Guarantees for derivatives of any order]
    ```

- **[arXiv251230] Random Controlled Differential Equations**
  - **tags:** [ai], [time-series learning], [controlled differential equations, random features, signature kernels, reservoir computing, rough paths]
  - **authors:** Francesco Piatti, Thomas Cass, William F. Turner
  - **institution:** Imperial College London
  - **link:** https://arxiv.org/pdf/2512.23670
  - **code:** https://github.com/FrancescoPiatti/RandomSigJax
  - **contributions:** 1. A training-efficient framework combining random features with Controlled Differential Equations (CDEs) to create continuous-time reservoirs for time-series learning. 2. Two novel variants: Random Fourier CDEs (RF-CDEs) for kernel-free RBF approximation and Random Rough DEs (R-RDEs) for stable, efficient modeling of rough-path inputs. 3. Theoretical proof that these models induce the RBF-lifted and rough signature kernels in the infinite-width limit, unifying random-feature reservoirs, continuous-time architectures, and path-signature theory.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68926f52841c63ea8f7ccc6a25444c327f8f05d4f014a21ea65330e8b1d0af5a_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces a fast and scalable framework for time-series learning by using large, randomly parameterized Controlled Differential Equations (CDEs) as continuous-time reservoirs, with only a linear readout layer trained. Two specific model variants, RF-CDEs and R-RDEs, are proposed and shown to approximate powerful signature kernels. The methods achieve competitive or state-of-the-art performance on benchmarks, offering a practical alternative to explicit signature computations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Random Controlled Differential Equations] --> B(核心问题/Problem: Efficient learning for time-series data)
        A --> C(主要方法/Method: Random-feature CDE reservoirs with linear readout)
        C --> D[RF-CDEs: 随机傅里叶特征/Random Fourier Features]
        C --> E[R-RDEs: 随机粗糙微分方程/Random Rough DEs]
        A --> F(关键结果/Results: Competitive SOTA performance, induces signature kernels)
    ```

- **[arXiv251230] End-to-End Test-Time Training for Long Context**
  - **tags:** [mlsys], [llm inference], [test-time training, meta-learning, sliding-window attention, continual learning, long-context modeling]
  - **authors:** Arnuv Tandon, Karan Dalal, Xinhao Li, Daniel Koceja, Marcel Rød, Sam Buchanan, Xiaolong Wang, Jure Leskovec, Sanmi Koyejo, Tatsunori Hashimoto, Carlos Guestrin, Jed McCaleb, Yejin Choi, Yu Sun
  - **institution:** Stanford University, UC Berkeley, UC San Diego, Astera Institute, NVIDIA
  - **link:** https://arxiv.org/pdf/2512.23675
  - **contributions:** 1. Formulates long-context modeling as a continual learning problem, enabling a standard sliding-window Transformer to learn at test time via next-token prediction, 2. Uses meta-learning during training to optimize the model's initialization for efficient test-time learning, 3. Achieves scaling performance comparable to full-attention Transformers while maintaining constant inference latency like RNNs, resulting in significant speedups for long contexts.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a044c036c50d93caf06213291a7e5d53aecb58cc761c7738c635ddb4234a64d3_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes an end-to-end test-time training method for long-context language modeling. It uses a standard sliding-window attention Transformer that learns continuously at test time via next-token prediction, with its initialization optimized via meta-learning during training. The method matches the scaling performance of full-attention Transformers while offering constant inference latency, making it 2.7x faster for 128K contexts.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[End-to-End Test-Time Training for Long Context] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Long-context language modeling]
        C[主要方法/Method: Test-Time Training with meta-learning & sliding-window attention]
        D[关键结果/Results: Matches full-attention scaling, constant latency, 2.7x faster]
    ```

- **[arXiv251230] Eliciting Behaviors in Multi-Turn Conversations**
  - **tags:** [nlp], [llm evaluation], [behavior elicitation, multi-turn conversation, online methods, dynamic benchmarks, test case generation]
  - **authors:** Jing Huang, Shujian Zhang, Lun Wang, Andrew Hard, Rajiv Mathews, John Lambert
  - **institution:** Google DeepMind, Stanford University
  - **link:** https://arxiv.org/pdf/2512.23701
  - **contributions:** 1. Proposes an analytical framework categorizing behavior elicitation methods into three families based on their interaction with the target model (prior knowledge, offline, online). 2. Introduces a generalized multi-turn formulation for online behavior elicitation methods, unifying single-turn and multi-turn settings. 3. Demonstrates the superior efficiency of online methods in discovering failure cases in multi-turn conversations compared to static benchmarks, advocating for a shift to dynamic evaluation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afe3305263c3b509bdd6e846cce6501d101c0ecedb788ef025ac0c9405a28103_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the problem of efficiently eliciting specific behaviors from large language models in multi-turn conversational settings. It introduces a framework for categorizing existing elicitation methods and proposes a generalized online method for multi-turn interactions. The key finding is that online methods can discover many more failure cases with few queries than static benchmarks, highlighting the need for dynamic evaluation approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Eliciting Behaviors in Multi-Turn Conversations] --> B(核心问题/Problem: How to efficiently elicit specific behaviors from LLMs in multi-turn conversations?)
        A --> C(主要方法/Method: Categorizes methods into three families; Proposes a generalized multi-turn online formulation.)
        A --> D(关键结果/Results: Online methods achieve high success rates with few queries, outperforming static benchmarks.)
    ```

- **[arXiv251230] UniFi: Combining Irregularly Sampled CSI from Diverse Communication Packets and Frequency Bands for Wi-Fi Sensing**
  - **tags:** [mlsys], [on-device ai], [Integrated Sensing and Communication (ISAC), Channel State Information (CSI), Attention Model, Irregular Sampling, Wi-Fi Sensing]
  - **authors:** Gaofeng Dong, Kang Yang, Mani Srivastava
  - **institution:** University of California, Los Angeles (UCLA)
  - **link:** https://arxiv.org/pdf/2512.22143
  - **contributions:** 1. Proposes UniFi, the first Wi-Fi ISAC framework that eliminates intrusive packet injection by exploiting irregularly sampled CSI from diverse communication packets across multiple bands. 2. Introduces a CSI sanitization pipeline to harmonize heterogeneous packets and a time-aware attention model that learns directly from non-uniform CSI sequences. 3. Presents CommCSI-HAR, the first dataset with irregularly sampled CSI from real-world dual-band communication traffic.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d5e6f4970d32933635a3174be0b8ba23c4b996e18b04bd75310812bd1071737_w640_q70.webp
  - **Simple LLM Summary:** This paper presents UniFi, a Wi-Fi sensing framework that solves the problem of communication degradation caused by high-rate probing packets. It achieves this by directly using irregularly sampled Channel State Information from existing communication traffic across multiple frequency bands, combined with a novel sanitization pipeline and a time-aware attention model. Evaluations show that UniFi achieves state-of-the-art sensing accuracy while fully preserving communication throughput.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[UniFi: Wi-Fi Sensing] --> B[核心问题/Problem: 现有系统依赖注入探测包，降低通信性能/Existing systems rely on probing packets, degrading communication]
        A --> C[主要方法/Method: 利用多频段通信包的非均匀CSI，使用净化管道和注意力模型/Exploit irregular CSI from multi-band comm packets with sanitization & attention]
        A --> D[关键结果/Results: 消除包注入，保持通信吞吐量，实现SOTA精度/Eliminates packet injection, preserves throughput, achieves SOTA accuracy]
    ```

- **[arXiv251230] Training AI Co-Scientists Using Rubric Rewards**
  - **tags:** [ai], [reinforcement learning], [research plan generation, self-grading, rubric rewards]
  - **authors:** Shashwat Goel, Rishi Hazra, Dulhan Jayalath, Timon Willi, Parag Jain, William F. Shen, Ilias Leontiadis, Francesco Barbieri, Yoram Bachrach, Jonas Geiping, Chenxi Whitehouse
  - **institution:** Meta Superintelligence Labs, ELLIS Institute Tübingen, Max Planck Institute for Intelligent Systems, University of Oxford, University of Cambridge
  - **link:** https://arxiv.org/pdf/2512.23707
  - **contributions:** 1. A scalable method to automatically extract research goals and goal-specific grading rubrics from existing papers to build a training corpus. 2. A reinforcement learning framework with self-grading, where a frozen initial model acts as the grader using rubrics, enabling unsupervised improvement. 3. Demonstration of significant performance gains (12-22% relative improvement) and cross-domain generalization (e.g., to medical research) validated by human experts and frontier model juries.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of training language models to generate high-quality, constraint-following research plans. The proposed method uses reinforcement learning with self-grading, where rubrics automatically extracted from research papers provide reward signals. The approach shows significant improvements in plan quality and generalizes across domains like machine learning and medicine, validated by human expert preference.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Training AI Co-Scientists Using Rubric Rewards"] --> Problem["核心问题/Problem: LMs struggle to generate research plans that follow all constraints."]
        Root --> Method["主要方法/Method: RL with self-grading using automatically extracted rubrics."]
        Root --> Results["关键结果/Results: Human experts prefer finetuned model's plans; method generalizes across domains."]
    ```

- **[arXiv251230] EEG-to-Voice Decoding of Spoken and Imagined speech Using Non-Invasive EEG**
  - **tags:** [ai], [brain-computer interface], [EEG-to-Voice, mel-spectrogram, domain adaptation, automatic speech recognition, language model correction]
  - **authors:** Hanbeot Park, Yunjeong Cho, Hunhee Kim
  - **institution:** Pukyong National University
  - **link:** https://arxiv.org/pdf/2512.22146
  - **contributions:** 1. Proposed a direct, open-loop EEG-to-Voice reconstruction pipeline that generates mel-spectrograms from EEG without requiring dynamic time warping or explicit temporal alignment. 2. Applied transfer learning-based domain adaptation by pretraining a subject-specific generator on spoken speech and adapting it to imagined speech. 3. Integrated a minimal language model-based correction module to reduce ASR errors while preserving semantic structure, improving linguistic accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30fda90c01417e82377bfcdd82830a196b29afd74925e2009f1a1a1d02d4d2bd_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a direct EEG-to-Voice paradigm to reconstruct speech from non-invasive EEG signals for both spoken and imagined speech. The method uses a subject-specific generator to produce mel-spectrograms, followed by a vocoder and ASR, and employs domain adaptation from spoken to imagined speech. The results demonstrate the feasibility of open-loop speech reconstruction without explicit temporal alignment, with stable acoustic and linguistic performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[EEG-to-Voice Decoding of Spoken and Imagined speech] --> B
        A --> C
        A --> D
        B[核心问题/Problem: EEG-based speech reconstruction is challenging due to noise, low resolution, and lack of aligned targets for imagined speech.]
        C[主要方法/Method: Direct, open-loop EEG-to-mel-spectrogram generation with subject-specific generators, domain adaptation from spoken to imagined speech, and optional LM-based ASR correction.]
        D[关键结果/Results: Feasibility demonstrated for both speech types; stable acoustic/linguistic performance; LM correction reduces CER/WER without semantic distortion.]
    ```

- **[arXiv251230] Machine Learning-Based Basil Yield Prediction in IoT-Enabled Indoor Vertical Hydroponic Farms**
  - **tags:** [mlsys], [on-device ai], [indoor vertical hydroponics, IoT sensors, LSTM, DNN, Linear Regression]
  - **authors:** Emna Bouzid, Noura Baccar, Kamran Iqbal, Yassine Chaouch, Fares Ben Youssef, Amine Regayeg, Sarra Toumi, Houda Nsir, Amina Mseddi, Leila Costelle
  - **institution:** University of Arkansas, Little Rock; Mediterranean Institute of Technology, South Mediterranean University
  - **link:** https://arxiv.org/pdf/2512.22151
  - **contributions:** 1. Developed a prediction system for basil yield in IoT-enabled indoor vertical hydroponic farms using ML models. 2. Conducted a comparative performance analysis of Linear Regression, LSTM, and DNN models, evaluating accuracy, execution time, and RAM usage. 3. Identified DNN as offering an optimal balance between computational efficiency (speed/RAM) and high prediction accuracy (98%), making it suitable for real-world, resource-conscious deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db5f20edab19e2fc847a47e72931db82045d6fc345183bcd4be1eb31da0f25e0_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses water scarcity in agriculture by proposing a machine learning-based system to predict basil yield in IoT-enabled indoor vertical hydroponic farms. It compares Linear Regression, LSTM, and DNN models using sensor data, finding that DNN provides a good trade-off between high accuracy (98%) and computational efficiency, making it suitable for practical deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Paper Title: Machine Learning-Based Basil Yield Prediction in IoT-Enabled Indoor Vertical Hydroponic Farms] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Agriculture water scarcity, need for efficient solutions]
        C[主要方法/Method: ML models (LR, LSTM, DNN) trained on IoT sensor data from hydroponic farm]
        D[关键结果/Results: DNN balances accuracy (98%) and computational efficiency for real-life deployment]
    ```

- **[arXiv251230] The Complete Anatomy of the Madden-Julian Oscillation Revealed by Artificial Intelligence**
  - **tags:** [ai], [climate informatics], [similarity-preserving representation, latent space clustering, physics-coherent monitoring]
  - **authors:** Xiao Zhou, Yuze Sun, Jie Wu, Xiaomeng Huang
  - **institution:** Tsinghua University, National Climate Centre, China Meteorological Administration
  - **link:** https://arxiv.org/pdf/2512.22144
  - **contributions:** 1. Introduced an "AI-for-theory" paradigm using a deep learning model (PhysAnchor-MJO-AE) to learn a latent representation where distance corresponds to physical-feature similarity for the MJO. 2. Objectively discovered the first complete six-phase anatomical map of the MJO life cycle, isolating two long-hypothesized transitional phases. 3. Constructed a new physics-coherent monitoring framework that decouples location and intensity, drastically reducing spurious propagation and convective misplacement compared to classical methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b09901ad992d27215117f20984faf17d508a192bf9010cc39bd8b74553ff543_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of objectively defining the life cycle of the Madden-Julian Oscillation (MJO) by introducing an "AI-for-theory" paradigm. It develops a deep learning model to learn a similarity-preserving latent representation, enabling clustering that reveals a complete six-phase anatomy of the MJO. The derived new monitoring framework significantly outperforms the classical index, demonstrating AI's role as a discovery tool for complex systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Complete Anatomy of the Madden-Julian Oscillation Revealed by Artificial Intelligence] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Defining MJO lifecycle is challenging due to propagation; classical methods conflate artifacts with physics.]
        C[主要方法/Method<br>AI-for-theory paradigm; Deep learning model (PhysAnchor-MJO-AE) learns similarity-preserving latent representation for objective clustering.]
        D[关键结果/Results<br>First complete six-phase MJO anatomy; New physics-coherent monitoring framework reduces errors by an order of magnitude.]
    ```

- **[arXiv251230] Neural ocean forecasting from sparse satellite-derived observations: a case-study for SSH dynamics and altimetry data**
  - **tags:** [ai], [spatiotemporal forecasting], [4DVarNet, U-Net, sequence-to-sequence, sea level anomaly, neural forecast]
  - **authors:** Daria Botvynko, Pierre Haslée, Lucile Gaultier, Bertrand Chapron, Clement de Boyer Montégut, Anass El Aouni, Julien Le Sommer, Ronan Fablet
  - **institution:** IMT Atlantique, Ifremer, CNRS, Mercator Ocean International
  - **link:** https://arxiv.org/pdf/2512.22152
  - **contributions:** 1. Adapts U-Net and 4DVarNet architectures for short-term forecasting of ocean dynamics from sparse satellite data. 2. Formulates the forecasting task as a sequence-to-sequence mapping using partial SLA snapshots to predict future full-field maps. 3. Demonstrates that the end-to-end neural framework outperforms an operational baseline, especially in high-variability regions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b91a25a42a5dc1b5739ae5689c604765502ed07062eadaa473e043ec5a0d288f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes an end-to-end deep learning framework for 7-day forecasting of sea surface dynamics using sparse satellite altimetry data. It adapts U-Net and 4DVarNet models to perform sequence-to-sequence mapping from partial observations to full-field forecasts. The results show the neural model outperforms an operational ocean forecast product, demonstrating the feasibility of neural forecasting for operational oceanography under data-sparse conditions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Neural Ocean Forecasting from Sparse Observations] --> B(核心问题/Problem: 稀疏卫星数据下的短期海洋预报/Short-term ocean forecasting from sparse satellite data)
        A --> C(主要方法/Method: 基于U-Net和4DVarNet的端到端序列预测/End-to-end sequence forecasting using U-Net & 4DVarNet)
        A --> D(关键结果/Results: 神经模型超越业务化基线，在多变区域改进显著/Neural model outperforms operational baseline, notable improvements in high-variability regions)
    ```

- **[arXiv251230] Sampling with Shielded Langevin Monte Carlo Using Navigation Potentials**
  - **tags:** [ai], [constrained sampling], [Langevin Monte Carlo, navigation functions, constrained sampling, non-convex support, adaptive temperature]
  - **authors:** Nicolas Zilberstein, Santiago Segarra, Luiz Chamon
  - **institution:** Rice University, École Polytechnique (Institut Polytechnique de Paris)
  - **link:** https://arxiv.org/pdf/2512.22153
  - **contributions:** 1. Introduces shielded Langevin Monte Carlo (LMC) for sampling from distributions with non-convex supports defined by convex sets with convex holes. 2. Incorporates a navigation function-inspired approach using a spatially adaptive temperature and repulsive drift to keep samples within feasible regions. 3. Demonstrates effectiveness through experiments on 2D Gaussian mixture and MIMO symbol detection, showing advantages over unconstrained methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b94714cf81960de10c530b580016be757aee25e63d9344efa57a771bb15c9bc_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes shielded Langevin Monte Carlo, a constrained sampling method that uses navigation potentials to sample from unnormalized target distributions over punctured (non-convex) supports. It modifies the Langevin diffusion with adaptive temperature and repulsive drift to avoid holes. Experiments on Gaussian mixtures and MIMO detection show it outperforms unconstrained sampling.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Sampling with Shielded Langevin Monte Carlo Using Navigation Potentials") --> Problem("核心问题/Problem: Sampling from non-convex supports with convex holes")
        Root --> Method("主要方法/Method: Shielded LMC with adaptive temperature and repulsive drift")
        Root --> Results("关键结果/Results: Outperforms unconstrained sampling in 2D Gaussian mixture and MIMO detection")
    ```

- **[arXiv251230] PaperNet: Efficient Temporal Convolutions and Channel Residual Attention for EEG Epilepsy Detection**
  - **tags:** [ai], [brain-computer interface (BCI)], [temporal convolution, residual attention, recurrent networks]
  - **authors:** Md Shahriar Sajid, Abhijit Kumar Ghosh, Fariha Nusrat
  - **institution:** Rajshahi University of Engineering & Technology, BRAC University, University of Asia Pacific
  - **link:** https://arxiv.org/pdf/2512.22172
  - **contributions:** 1. Proposed PaperNet, a compact hybrid architecture combining temporal convolutions, channel-wise residual attention, and a lightweight bidirectional recurrent block for EEG classification. 2. Demonstrated high performance (macro-F1 0.96) on the BEED dataset with only ~0.6M parameters under a subject-independent protocol. 3. Provided interpretability through channel-wise attention weights to reveal electrode relevance and validated efficiency for deployment on resource-constrained systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42ceecec9d77194ecb3fce40cd41e394fe9fe473136aa06f3cec099aa5631ac0_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces PaperNet, a lightweight deep learning model that integrates temporal convolutions, channel residual attention, and a bidirectional recurrent block for efficient EEG epilepsy detection. It achieves a macro-F1 score of 0.96 on the BEED dataset with only about 0.6 million parameters, showing balanced performance across classes. The results indicate that combining temporal filtering, channel reweighting, and recurrent context modeling can deliver strong classification without high computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[PaperNet: EEG癫痫检测 / PaperNet: EEG Epilepsy Detection] --> B[核心问题/Problem: EEG信号噪声多、变异性大 / Problem: EEG signals are noisy and variable]
        A --> C[主要方法/Method: 时间卷积+通道残差注意力+轻量循环块 / Method: Temporal convolutions + Channel residual attention + Lightweight recurrent block]
        A --> D[关键结果/Results: 宏F1=0.96, 参数0.6M, 高效部署 / Results: Macro-F1=0.96, 0.6M params, efficient deployment]
    ```

- **[arXiv251230] On Fibonacci Ensembles: An Alternative Approach to Ensemble Learning Inspired by the Timeless Architecture of the Golden Ratio**
  - **tags:** [ai], [ensemble learning], [Fibonacci weighting, Rao-Blackwell optimization, variance reduction, recursive ensemble, orthogonalization]
  - **authors:** Ernest Fokoué
  - **institution:** Rochester Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.22284
  - **contributions:** 1. Introduces Fibonacci Ensembles, a novel ensemble learning framework using normalized Fibonacci weights optimized via orthogonalization and Rao-Blackwellization for systematic variance reduction. 2. Proposes a second-order recursive ensemble dynamic inspired by the Fibonacci sequence to enhance representational depth beyond classical boosting. 3. Develops a General Weighting Theory that unifies various ensemble methods (bagging, boosting, stacking, etc.) under a single mathematical framework as distributional operators.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3aac35c4c829c693f4e9607fedf9124e05465f66f615b3d6ff040b6b1d9348a_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Fibonacci Ensembles, a new ensemble learning method inspired by the Fibonacci sequence, which uses mathematically optimized Fibonacci weights and a recursive dynamic to reduce variance and improve model depth. Experimental results on one-dimensional regression show it can match or outperform uniform averaging and integrates effectively with orthogonal Rao-Blackwellization. The work suggests Fibonacci ensembles offer a natural and interpretable design within ensemble theory.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[On Fibonacci Ensembles] --> B[核心问题/Problem: How to design a principled ensemble learning method inspired by natural harmony?]
        A --> C[主要方法/Method: Use Fibonacci weights with orthogonalization/Rao-Blackwell optimization and recursive dynamics]
        A --> D[关键结果/Results: Fibonacci weighting matches/improves uniform averaging and integrates with Rao-Blackwellization]
    ```

- **[arXiv251230] A review of NMF, PLSA, LBA, EMA, and LCA with a focus on the identifiability issue**
  - **tags:** [ai], [matrix factorization], [nonnegative matrix factorization, identifiability, latent class analysis, probabilistic latent semantic analysis, end-member analysis]
  - **authors:** Qianqian Qi, Peter G. M. van der Heijden
  - **institution:** Hangzhou Dianzi University, Utrecht University, University of Southampton
  - **link:** https://arxiv.org/pdf/2512.22282
  - **contributions:** 1. Highlights the similarities among five popular matrix factorization models (LBA, LCA, EMA, PLSA, NMF) that are often presented separately across different fields. 2. Proves a unified identifiability condition, showing that the solution uniqueness for LBA, EMA, LCA, and PLSA is equivalent to the uniqueness of the NMF solution. 3. Provides a brief review of algorithms for these models and illustrates their application with a social science time budget dataset.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/369a6018ccc708c5d8368b9a1290021cb1b1e9d92785fa247417c9aeb167a164_w640_q70.webp
  - **Simple LLM Summary:** This paper reviews and unifies five nonnegative matrix factorization models (NMF, PLSA, LBA, EMA, LCA) from different disciplines, focusing on the identifiability issue. It proves that the uniqueness of solutions for LBA, EMA, LCA, and PLSA is equivalent to the uniqueness of the NMF solution. The work clarifies model similarities, reviews algorithms, and demonstrates application with a real-world dataset.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题: A review of NMF, PLSA, LBA, EMA, and LCA with a focus on the identifiability issue] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 跨领域非负矩阵分解模型的相似性与可识别性/Similarity and identifiability of cross-domain nonnegative matrix factorization models]
        C[主要方法/Method: 理论分析与统一证明/Theoretical analysis and unified proof]
        D[关键结果/Results: 证明LBA, EMA, LCA, PLSA解的唯一性与NMF解的唯一性等价/Proved solution uniqueness of LBA, EMA, LCA, PLSA is equivalent to uniqueness of NMF solution]
    ```

- **[arXiv251230] A General Weighting Theory for Ensemble Learning: Beyond Variance Reduction via Spectral and Geometric Structure**
  - **tags:** [ai], [ensemble learning], [weighting theory, spectral complexity, approximation geometry, bias-variance decomposition, constrained quadratic program]
  - **authors:** Ernest Fokoué
  - **institution:** Rochester Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.22286
  - **contributions:** 1. Develops a general weighting theory for ensembles that moves beyond variance reduction, formalizing ensembles as linear operators with geometric and spectral constraints. 2. Derives a refined bias-variance-approximation decomposition showing how structured weights can outperform uniform averaging by reshaping approximation geometry and redistributing spectral complexity. 3. Provides a unified theoretical framework that subsumes classical averaging, stacking, and recent Fibonacci-based ensembles, showing optimal weights arise from constrained quadratic programs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a91a59418696aa33fbf07981fc6c57647153631a58f387a01a431ae28237ebb8_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new theoretical framework for ensemble learning that explains its effectiveness beyond the traditional variance-reduction argument, particularly for stable base learners. The method formalizes ensembles as linear operators and shows how structured, non-uniform weighting can optimize performance by managing spectral complexity and approximation geometry. The main conclusion is that the principal role of aggregation for low-variance learners is the redistribution of spectral complexity, establishing a foundation for structure-driven ensemble design.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A General Weighting Theory for Ensemble Learning<br>集成学习的一般加权理论] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1["传统方差缩减理论无法解释稳定基学习器的集成效果<br>Traditional variance reduction fails to explain ensembles of stable learners"]
        C --> C1["将集成形式化为具有几何与谱约束的线性算子<br>Formalize ensembles as linear operators with geometric/spectral constraints"]
        C --> C2["推导偏差-方差-近似分解<br>Derive bias-variance-approximation decomposition"]
        D --> D1["结构化加权方案在理论上优于均匀平均<br>Structured weighting provably dominates uniform averaging"]
        D --> D2["最优权重是约束二次规划的解<br>Optimal weights are solutions to constrained QPs"]
        D --> D3["统一理论涵盖经典平均、堆叠等<br>Unified theory subsumes averaging, stacking, etc."]
    ```

- **[arXiv251230] Gradient Dynamics of Attention: How Cross-Entropy Sculpts Bayesian Manifolds**
  - **tags:** [ai], [transformer interpretability], [cross-entropy, gradient dynamics, attention mechanism, expectation-maximization, Bayesian inference]
  - **authors:** Naman Aggarwal, Siddhartha R. Dalal, Vishal Misra
  - **institution:** Dream Sports, Columbia University
  - **link:** https://arxiv.org/pdf/2512.22473
  - **contributions:** 1. Derived an advantage-based routing law and a responsibility-weighted update rule for attention scores and values under cross-entropy training. 2. Showed that the coupled gradient dynamics induce a positive feedback loop that behaves like a two-timescale Expectation-Maximization (EM) procedure. 3. Demonstrated that these gradient dynamics sculpt the low-dimensional manifolds necessary for Bayesian inference, linking optimization to geometry and function.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed145ec9892ca4b4f8b91e5c78948ac6b81399c20bcafdccd4cb429e92da2aed_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes how cross-entropy training shapes the internal geometry of transformer attention heads. By deriving first-order gradient dynamics, it shows that attention score and value updates form a positive feedback loop analogous to an EM algorithm. The core conclusion is that this gradient flow sculpts the Bayesian manifolds that enable in-context probabilistic reasoning.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Gradient Dynamics of Attention: How Cross-Entropy Sculpts Bayesian Manifolds] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[Transformer内部几何结构如何形成?/How is transformer internal geometry formed?]
    C --> C1[推导注意力梯度动态/Derive attention gradient dynamics]
    C --> C2[建立EM算法类比/Establish EM algorithm analogy]
    D --> D1[发现优势路由与责任更新/Discover advantage-based routing & responsibility-weighted update]
    D --> D2[梯度流塑造贝叶斯流形/Gradient flow sculpts Bayesian manifolds]
    ```

- **[arXiv251230] Integrating Wide and Deep Neural Networks with Squeeze-and-Excitation Blocks for Multi-Target Property Prediction in Additively Manufactured Fiber Reinforced Composites**
  - **tags:** [ai], [multi-target regression], [squeeze-and-excitation blocks, wide-and-deep neural networks, Latin Hypercube Sampling, SHAP analysis, multi-input multi-target learning]
  - **authors:** Behzad Parvaresh, Rahmat K. Adesunkanmi, Adel Alaeddini
  - **institution:** Southern Methodist University
  - **link:** https://arxiv.org/pdf/2512.22397
  - **contributions:** 1. Introduced a data-efficient multi-input, multi-target learning approach integrating Latin Hypercube Sampling (LHS) with a squeeze-and-excitation wide and deep neural network (SE-WDNN) for predicting mechanical and manufacturing properties of additively manufactured fiber-reinforced composites. 2. Demonstrated superior performance of SE-WDNN over baseline models (e.g., feedforward neural networks, XGBoost) with the lowest overall test error (MAPE=12.33%) and statistically significant improvements for several target variables. 3. Provided interpretability through SHAP analysis, identifying reinforcement strategy as the major influence on mechanical performance, enabling guided parameter selection balancing mechanical behavior and manufacturing metrics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/46886a511640f1fda32bb5caad6d94ff9e4208332562a065cf26f5a070434085_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of predicting multiple properties in additively manufactured fiber-reinforced composites, where performance is sensitive to process and material parameters. The authors propose a sample-efficient method combining Latin Hypercube Sampling with a novel squeeze-and-excitation wide and deep neural network (SE-WDNN) to jointly predict mechanical and manufacturing properties. The model outperforms several baseline machine learning models, achieving the lowest test error, and SHAP analysis reveals that reinforcement strategy is the most influential factor, demonstrating the approach's effectiveness for interpretable, multi-target prediction in this domain.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Integrating Wide and Deep Neural Networks with Squeeze-and-Excitation Blocks for Multi-Target Property Prediction in Additively Manufactured Fiber Reinforced Composites") --> Problem("核心问题/Problem: Exhaustive testing of CFRC-AM properties is impractical due to complex parameter interactions.")
        Root --> Method("主要方法/Method: Integrate LHS-guided experimentation with a novel SE-WDNN model for multi-target prediction.")
        Root --> Results("关键结果/Results: SE-WDNN achieves lowest test error (MAPE=12.33%); SHAP shows reinforcement strategy is key.")
    ```

- **[arXiv251230] Uncertainty-Aware Flow Field Reconstruction Using SVGP Kolmogorov-Arnold Networks**
  - **tags:** [ai], [uncertainty quantification], [sparse variational Gaussian processes, Kolmogorov-Arnold networks, flow reconstruction]
  - **authors:** Y. Sungtaek Ju
  - **institution:** University of California, Los Angeles
  - **link:** https://arxiv.org/pdf/2512.22426
  - **contributions:** 1. Proposes a novel machine learning framework (SVGP-KAN) for uncertainty-aware flow field reconstruction, combining sparse variational Gaussian processes with Kolmogorov-Arnold network topology. 2. Enables principled epistemic uncertainty quantification, extending classical methods like Linear Stochastic Estimation (LSE) and Spectral Analysis Modal Methods (SAMM). 3. Provides a systematic evaluation demonstrating that the method achieves accuracy comparable to established techniques while offering well-calibrated uncertainty estimates that reliably indicate prediction quality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78057a4908248b84f2c93949508c1a8ed187c23a15c17c9cb4d97da3da80d1a6_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a machine learning framework called SVGP-KAN for reconstructing time-resolved flow fields from sparse measurements. The method combines sparse variational Gaussian processes with Kolmogorov-Arnold networks to provide accurate reconstructions along with principled uncertainty estimates. The results show the framework achieves comparable accuracy to classical methods while offering reliable uncertainty quantification, which is valuable for experimental design in periodic flows.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Uncertainty-Aware Flow Field Reconstruction Using SVGP Kolmogorov-Arnold Networks] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[从稀疏测量中重建瞬态流场/Reconstruct time-resolved flow fields from sparse measurements]
        C --> C1[SVGP-KAN框架/SVGP-KAN framework]
        C1 --> C2[稀疏变分高斯过程/Sparse Variational Gaussian Processes]
        C1 --> C3[Kolmogorov-Arnold网络拓扑/Kolmogorov-Arnold Network Topology]
        D --> D1[精度与经典方法相当/Accuracy comparable to established methods]
        D --> D2[提供良好校准的不确定性估计/Provides well-calibrated uncertainty estimates]
    ```

- **[arXiv251230] Likelihood-Preserving Embeddings for Statistical Inference**
  - **tags:** [ai], [statistical inference], [likelihood-preserving embeddings, likelihood-ratio distortion, Hinge Theorem, approximate sufficient statistics, surrogate MLE]
  - **authors:** Deniz Akdemir
  - **institution:** Not explicitly provided; inferred from email domain as independent researcher or unspecified institution.
  - **link:** https://arxiv.org/pdf/2512.22638
  - **contributions:** 1. Introduces the Likelihood-Ratio Distortion metric and the Hinge Theorem, establishing it as the necessary and sufficient condition for preserving likelihood-based inference. 2. Proves an impossibility result for universal likelihood preservation, motivating model-class-specific guarantees. 3. Provides a constructive framework using neural networks as approximate sufficient statistics with explicit bounds linking training loss to inferential guarantees.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aff5ca31934e9408fcf0755ba3d0be2604e2c3a6692b27396516614ac67f2b0a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem that modern machine learning embeddings often destroy the geometric structure needed for classical likelihood-based statistical inference. It proposes a theory of likelihood-preserving embeddings, centered on controlling the Likelihood-Ratio Distortion, and proves that this control is necessary and sufficient to preserve tests, Bayes factors, and MLEs. The main conclusion is that with this framework, neural network embeddings can be made compatible with classical inference workflows under specific, provable conditions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Likelihood-Preserving Embeddings for Statistical Inference] --> B[核心问题/Problem: ML embeddings destroy geometric structure for likelihood-based inference]
        A --> C[主要方法/Method: Theory of likelihood-preserving embeddings using Likelihood-Ratio Distortion metric and Hinge Theorem]
        A --> D[关键结果/Results: Controlling distortion preserves tests & MLEs; framework for neural networks as approximate sufficient statistics]
    ```

- **[arXiv251230] Machine learning models for predicting catastrophe bond coupons using climate data**
  - **tags:** [ai], [financial machine learning], [catastrophe bonds, climate indicators, extremely randomized trees, gradient boosting, risk pricing]
  - **authors:** Julia Kończal, Michał Balcerek, Krzysztof Burnecki
  - **institution:** Wrocław University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.22660
  - **contributions:** 1. Proposes a novel integration of large-scale climate indicators (e.g., ONI, NAO, SSTs) into the prediction of catastrophe bond coupon rates. 2. Systematically compares the performance of linear regression against advanced tree-based ensemble methods (RF, GBM, ERT, XGBoost) for this financial prediction task. 3. Demonstrates that including climate variables improves predictive accuracy across all models, with Extremely Randomized Trees achieving the best performance, quantifying the influence of climate variability on CAT bond pricing.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad97e42c90e08944209aa776783ca45b8fd5114532eaa6a8db48fee77ac0f8e2_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the use of machine learning models to predict catastrophe bond coupons by incorporating climate data. The authors combine traditional financial features with climate indicators and compare models like linear regression, random forest, and gradient boosting. The results show that climate variables improve prediction accuracy, with extremely randomized trees performing best, indicating that climate variability significantly impacts bond pricing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Machine learning models for predicting catastrophe bond coupons using climate data] --> B(核心问题/Problem: 如何预测巨灾债券息票？/How to predict CAT bond coupons?)
        A --> C(主要方法/Method: 结合气候指标与机器学习模型/Combine climate indicators with ML models)
        A --> D(关键结果/Results: 气候变量提升预测精度，极端随机树表现最佳/Climate variables improve accuracy, Extremely Randomized Trees perform best)
    ```

- **[arXiv251230] Geometry-Aware Optimization for Respiratory Sound Classification: Enhancing Sensitivity with SAM-Optimized Audio Spectrogram Transformers**
  - **tags:** [ai], [medical audio classification], [Audio Spectrogram Transformer, Sharpness-Aware Minimization, ICBHI 2017, class imbalance, loss landscape]
  - **authors:** Atakan Işık, Selin Vulga Işık, Ahmet Feridun Işık, Mahşuk Taylan
  - **institution:** Başkent University, Gaziantep University
  - **link:** https://arxiv.org/pdf/2512.22564
  - **contributions:** 1. Proposes a novel framework integrating the Audio Spectrogram Transformer (AST) with Sharpness-Aware Minimization (SAM) for robust respiratory sound classification. 2. Implements a weighted sampling strategy to effectively handle the severe class imbalance present in medical datasets like ICBHI 2017. 3. Achieves state-of-the-art performance on the ICBHI 2017 dataset, with a particular focus on improving sensitivity for reliable clinical screening.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0861fcb0d50b762d97367d04dce9ca920f2ffca74cd5112df95b11652972a9b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenges of respiratory sound classification, such as data scarcity and class imbalance, by enhancing the Audio Spectrogram Transformer with Sharpness-Aware Minimization (SAM) to find flatter minima for better generalization. The method also employs weighted sampling and achieves a new state-of-the-art score of 68.10% and a sensitivity of 68.31% on the ICBHI 2017 dataset, demonstrating improved robustness for clinical applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Geometry-Aware Optimization for Respiratory Sound Classification<br/>呼吸声音分类的几何感知优化] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
    
        B --> B1[数据限制与过拟合<br/>Data Constraints & Overfitting]
        B1 --> B2[数据集小、噪声大、类别不平衡<br/>Small, Noisy, Imbalanced Dataset]
    
        C --> C1[使用SAM优化AST<br/>Enhance AST with SAM]
        C1 --> C2[优化损失曲面几何<br/>Optimize Loss Surface Geometry]
        C --> C3[加权采样策略<br/>Weighted Sampling Strategy]
    
        D --> D1[SOTA分数: 68.10%<br/>SOTA Score: 68.10%]
        D --> D2[高敏感度: 68.31%<br/>High Sensitivity: 68.31%]
    ```

- **[arXiv251230] Nonlinear Dynamical Modeling of Human Intracranial Brain Activity with Flexible Inference**
  - **tags:** [ai], [computational neuroscience], [DFINE, state-space models, intracranial EEG, neural forecasting, brain-computer interfaces]
  - **authors:** Kiarash Vaziri, Lucine L. Oganesian, HyeongChan Jo, Roberto M.C. Vera, Charles Y. Liu, Brian Lee, Maryam M. Shanechi
  - **institution:** University of Southern California
  - **link:** https://arxiv.org/pdf/2512.22785
  - **contributions:** 1. Extended the DFINE framework, originally for intracortical recordings, to model multisite human intracranial EEG (iEEG) signals. 2. Demonstrated that DFINE significantly outperforms linear state-space models (LSSMs) and matches or exceeds the accuracy of GRU models in forecasting future neural activity. 3. Showed that DFINE handles missing observations more robustly than baseline models, highlighting its flexible inference capability for practical BCI applications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b25c55145e75d86ed37939fcb3e028529910a649ed86c8bd2fdb2e8fb91c496_w640_q70.webp
  - **Simple LLM Summary:** This paper extends the DFINE framework to model nonlinear dynamics in human intracranial EEG (iEEG) data. DFINE combines neural networks with a linear state-space model backbone to enable accurate neural forecasting and robust handling of missing data. The results show DFINE outperforms linear models, matches or beats GRU performance, and is particularly effective in high gamma bands, making it a promising tool for next-generation brain-computer interfaces.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Nonlinear Dynamical Modeling of Human Intracranial Brain Activity with Flexible Inference") --> Problem
        Root --> Method
        Root --> Results
        Problem("核心问题/Problem") --> P1("线性模型无法捕捉神经活动中的非线性结构/Linear models fail to capture nonlinear neural structure")
        Problem --> P2("RNN模型不直接处理缺失观测值/RNN models do not directly handle missing observations")
        Method("主要方法/Method") --> M1("扩展DFINE框架至iEEG建模/Extend DFINE framework to iEEG modeling")
        Method --> M2("结合神经网络与线性状态空间模型/Integrate neural networks with linear state-space models")
        Results("关键结果/Results") --> R1("DFINE显著优于线性状态空间模型/DFINE significantly outperforms LSSM")
        Results --> R2("DFINE匹配或超过GRU的预测精度/DFINE matches or exceeds GRU accuracy")
        Results --> R3("DFINE更鲁棒地处理缺失数据/DFINE handles missing observations more robustly")
    ```

- **[arXiv251230] Causal-Policy Forest for End-to-End Policy Learning**
  - **tags:** [ai], [causal inference], [policy learning, causal forest, conditional average treatment effect (CATE), end-to-end learning, random forests]
  - **authors:** Masahiro Kato
  - **institution:** The University of Tokyo
  - **link:** https://arxiv.org/pdf/2512.22846
  - **contributions:** 1. Establishes an equivalence between maximizing policy value and minimizing MSE for CATE under a specific regression model, providing a theoretical foundation. 2. Proposes the causal-policy forest, a novel end-to-end algorithm that modifies the widely-used causal forest for direct policy learning. 3. Integrates policy training steps more tightly than prior methods, avoiding separate nuisance parameter estimation and improving computational efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a2b4476f0b9f739e0d89d20df3fd68607b0631baf53a2956bd05175daf10d348_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes an end-to-end algorithm for policy learning in causal inference, called the causal-policy forest. It modifies the causal forest method by leveraging a theoretical equivalence between policy value maximization and CATE estimation. The method unifies policy training steps, is computationally efficient, and bridges the gap between policy learning and CATE estimation in practice.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Causal-Policy Forest for End-to-End Policy Learning] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Policy learning from observational data to recommend optimal treatments] --> Problem_Sub[目标/Goal: Maximize policy value]
        Method[主要方法/Method: Causal-Policy Forest] --> Method_Sub1[基础/Foundation: Equivalence of policy value max and CATE MSE min]
        Method --> Method_Sub2[算法/Algorithm: Modify causal forest for end-to-end policy learning]
        Results[关键结果/Results: Three advantages] --> Results_Sub1[优势1/Advantage 1: Bridges policy learning and CATE estimation]
        Results --> Results_Sub2[优势2/Advantage 2: More end-to-end training]
        Results --> Results_Sub3[优势3/Advantage 3: Computationally efficient]
    ```

- **[arXiv251230] A first-order method for nonconvex-strongly-concave constrained minimax optimization**
  - **tags:** [ai], [optimization theory], [minimax optimization, augmented Lagrangian method, first-order method, operation complexity, nonconvex-strongly-concave]
  - **authors:** Zhaosong Lu, Sanyou Mei
  - **institution:** University of Minnesota, The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.22909
  - **contributions:** 1. Proposes a first-order augmented Lagrangian method for solving nonconvex-strongly-concave constrained minimax problems. 2. Develops a new first-order method to solve the resulting unconstrained minimax subproblems by leveraging the strong concavity structure. 3. Establishes an improved operation complexity of O(ε^\{-3.5\} log ε^\{-1\}) for finding an ε-KKT solution, which is a factor of ε^\{-0.5\} better than the previous best-known result.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8900c67d50fc273f41601bb4bbe900a26bc3aacdb1b31495591bc5c452297c76_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of nonconvex-strongly-concave constrained minimax optimization. The authors propose a novel first-order augmented Lagrangian method, where the subproblems are solved by a specially designed first-order algorithm. The main result is that their method achieves an improved operation complexity of O(ε^\{-3.5\} log ε^\{-1\}) for finding an approximate KKT solution.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题 / Paper Title: A first-order method for nonconvex-strongly-concave constrained minimax optimization] --> B(核心问题 / Problem: 非凸-强凹约束极小极大优化 / Nonconvex-strongly-concave constrained minimax optimization)
        A --> C(主要方法 / Method: 一阶增广拉格朗日法 / First-order augmented Lagrangian method)
        A --> D(关键结果 / Results: 操作复杂度 O(ε^{-3.5} log ε^{-1}) / Operation complexity O(ε^{-3.5} log ε^{-1}))
    ```

- **[arXiv251230] Deep Learning for the Multiple Optimal Stopping Problem**
  - **tags:** [ai], [reinforcement learning / optimal stopping], [multiple optimal stopping, dynamic programming principle, neural network approximation, high-dimensional problems, American basket options]
  - **authors:** Mathieu Laurière, Mehdi Talbi
  - **institution:** Shanghai Center for Data Science; NYU-ECNU Institute of Mathematical Sciences at NYU Shanghai; NYU Shanghai; Laboratoire de Probabilités, Statistiques et Modélisation, Université Paris-Cité
  - **link:** https://arxiv.org/pdf/2512.22961
  - **contributions:** 1. Proposes a novel deep learning framework combining the Dynamic Programming Principle with neural networks to solve high-dimensional multiple optimal stopping problems. 2. Provides theoretical error analysis for both the discrete-time problem (neural network training error) and continuous problems (discretization error). 3. Demonstrates the method's efficiency and scalability through numerical experiments on high-dimensional American basket options and nonlinear utility maximization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ef52bc9da77a7dcb529e7b4b3c239b993aeb4f5fc7464ce8d4f6e1c468ee677_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a deep learning framework to solve the challenging multiple optimal stopping problem in high dimensions. The method combines the Dynamic Programming Principle with neural network approximation of the value function. Numerical experiments show it is an efficient and scalable solution for problems like pricing American basket options.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Deep Learning for the Multiple Optimal Stopping Problem] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[高维多停止问题/High-dim Multiple Stopping]
        Problem --> P2[复杂递归依赖/Complex Recursive Dependencies]
        Method --> M1[动态规划原理/DPP]
        Method --> M2[神经网络值函数近似/Neural Network Value Approximation]
        Results --> R1[理论误差分析/Theoretical Error Analysis]
        Results --> R2[高效可扩展方法/Efficient & Scalable Method]
    ```

- **[arXiv251230] Risk-Averse Learning with Varying Risk Levels**
  - **tags:** [ai], [online convex optimization], [Conditional Value-at-Risk (CVaR), dynamic regret, zeroth-order optimization, risk-level variation, first-order optimization]
  - **authors:** Siyi Wang, Zifan Wang, Karl H. Johansson
  - **institution:** KTH Royal Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.22986
  - **contributions:** 1. Introduces a novel risk-level variation metric to capture the dynamics of changing risk preferences in online optimization. 2. Develops risk-averse learning algorithms for both first-order and zeroth-order information settings under a limited sampling budget. 3. Provides dynamic regret bounds for the proposed algorithms, analyzing their performance in terms of function variation, risk-level variation, and sample count.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/19b18e34aeb85bbf659ba6da5ac559cf4534627ec075752ac91c1f532838981e_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles risk-averse online optimization in non-stationary environments where both the cost functions and the desired risk level can change over time. The authors propose new algorithms for first-order and zeroth-order settings that use Conditional Value-at-Risk (CVaR) and analyze their dynamic regret, showing adaptability to changing conditions. Numerical experiments validate the effectiveness of the proposed methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Risk-Averse Learning with Varying Risk Levels<br>风险规避学习与变化的风险水平] --> B(Problem: Safety-critical decision-making in dynamic, risk-sensitive environments<br>核心问题: 动态风险敏感环境中的安全关键决策)
        A --> C(Method: CVaR-based online algorithms for first-order & zeroth-order settings<br>主要方法: 基于CVaR的一阶和零阶在线算法)
        A --> D(Results: Dynamic regret bounds and numerical validation<br>关键结果: 动态遗憾界与数值验证)
    ```

- **[arXiv251230] JADAI: Jointly Amortizing Adaptive Design and Bayesian Inference**
  - **tags:** [ai], [simulation-based inference], [Bayesian adaptive design, amortized inference, diffusion models, sequential experimental design, policy learning]
  - **authors:** Niels Bracher, Lars Kühmichel, Desi R. Ivanova, Xavier Intes, Paul-Christian Bürkner, Stefan T. Radev
  - **institution:** Rensselaer Polytechnic Institute, TU Dortmund University, University of Oxford
  - **link:** https://arxiv.org/pdf/2512.22999
  - **contributions:** 1. Introduces JADAI, a framework that jointly amortizes Bayesian adaptive design and inference by training a policy, history, and inference network end-to-end., 2. Proposes a generic loss function that aggregates incremental reductions in posterior error across sequential experiments., 3. Instantiates the inference network with diffusion-based posterior estimators to handle high-dimensional and multimodal posteriors at each experimental step.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a357d49f23f5fdffd9539d05904d86150c3c7775033f4847b56afac3375ad8e6_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces JADAI, a framework that jointly learns to optimize experimental designs and perform Bayesian inference in a sequential setting. It trains a policy network, a history network, and a diffusion-based inference network end-to-end to minimize posterior error. The method achieves superior or competitive performance on standard adaptive design benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[JADAI: Jointly Amortizing Adaptive Design and Bayesian Inference] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Actively optimizing design variables for parameter estimation] --> Problem_Sub[子问题/Sub-problem: Sequential design and inference are typically treated separately]
        Method[主要方法/Method: Jointly amortize design and inference via end-to-end training] --> Method_Sub1[网络/Networks: Policy, History, and Inference (Diffusion-based) networks]
        Method --> Method_Sub2[损失函数/Loss: Aggregates incremental posterior error reduction]
        Results[关键结果/Results: Superior/competitive performance on standard benchmarks]
    ```

- **[arXiv251230] Deep Learning for Art Market Valuation**
  - **tags:** [ai], [multi-modal learning], [multi-modal deep learning, visual embeddings, Grad-CAM, hedonic regression, repeated-sales dataset]
  - **authors:** Jianping Mei, Michael Moses, Jan Waelty, Yucheng Yang
  - **institution:** Cheung Kong Graduate School of Business (CKGSB), University of Zurich, Swiss Finance Institute, Art Market Consultancy
  - **link:** https://arxiv.org/pdf/2512.23078
  - **contributions:** 1. Introduces and benchmarks multi-modal deep learning models that fuse tabular data (artist, history) with visual embeddings from artwork images for art market valuation. 2. Demonstrates that visual content provides a distinct and economically significant predictive contribution, especially for fresh-to-market works lacking prior transaction history. 3. Provides interpretability analyses using Grad-CAM and embedding visualizations to show models attend to compositional and stylistic visual cues.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21784cb5e49e3a537b10ebbf9acd8a8be80b39a1879d7fe524e11c8045e1e665_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes using multi-modal deep learning to improve art market valuation by incorporating visual content from artwork images alongside traditional tabular data. It finds that while artist identity and history are most predictive overall, visual features provide crucial value for first-time sales where historical data is absent. The results show deep learning offers new insights for valuation, particularly in the most challenging scenarios.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deep Learning for Art Market Valuation<br/>艺术市场估值的深度学习] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br/>How to improve art market valuation?<br/>如何改进艺术市场估值？]
        C[主要方法/Method<br/>Multi-modal deep learning fusing tabular & image data<br/>融合表格与图像数据的多模态深度学习]
        D[关键结果/Results<br/>Visual features help most for fresh-to-market works<br/>视觉特征对首次上市作品最有帮助]
    ```

- **[arXiv251230] Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity**
  - **tags:** [mlsys], [federated learning], [L0 regularization, probabilistic gates, communication efficiency, model sparsity, federated stochastic gradient descent]
  - **authors:** Krishna Harsha Kovelakuntla Huthasana, Alireza Olama, Andreas Lundell
  - **institution:** Åbo Akademi University
  - **link:** https://arxiv.org/pdf/2512.23071
  - **contributions:** 1. Proposes a novel federated learning method that enforces an L0 constraint on model parameters using probabilistic gates and their continuous relaxation to achieve target sparsity. 2. Derives the L0 constrained stochastic minimization objective from an entropy maximization problem of the stochastic gates. 3. Demonstrates that the method can achieve high target sparsity (down to ρ=0.005) under data and client heterogeneity with minimal loss in statistical performance, outperforming magnitude pruning-based methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259d06fa8e807f154e153891f40b44308796040886ed51e218b65ee4e67a8c9c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of poor generalizability and communication inefficiency in Federated Learning due to overly dense models. It proposes a method to enforce L0 sparsity constraints via probabilistic gates, deriving the objective from entropy maximization and implementing it with federated stochastic gradient descent. The method is shown to be communication-efficient and achieves high target sparsity with better statistical performance than pruning-based baselines on synthetic and real datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: 数据与模型固有的稀疏性未被解决，导致模型过密、泛化性差，且存在数据和客户端参与异质性。]
        Method[主要方法/Method: 通过概率门及其连续松弛对非零参数密度施加L0约束，目标源自随机门的熵最大化问题，并基于联邦随机梯度下降。]
        Results[关键结果/Results: 在数据和客户端异质性下，能达到目标密度(ρ)，统计性能损失最小，且比基于幅度的剪枝方法更优、通信高效。]
    ```

- **[arXiv251230] QSAR-Guided Generative Framework for the Discovery of Synthetically Viable Odorants**
  - **tags:** [ai], [generative models], [variational autoencoder, QSAR, molecular generation, Fréchet ChemNet Distance, retrosynthesis]
  - **authors:** Tim C. Pearce, Ahmed Ibrahim
  - **institution:** University of Leicester, University of Cambridge
  - **link:** https://arxiv.org/pdf/2512.23080
  - **contributions:** 1. A novel generative AI framework combining a VAE with a QSAR model to design novel odorant molecules from limited training data., 2. Demonstration of effective latent space structuring for odor likelihood, enabling exploration of novel chemical scaffolds beyond simple derivatization., 3. Comprehensive validation showing generated molecules are syntactically valid, unique, thermodynamically stable, and synthetically viable.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2f78de871dd5cdb6d0663be15fa9ec9b8b77d5cae24344545c68979b5c02eaf_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a generative AI framework that combines a variational autoencoder (VAE) with a quantitative structure-activity relationship (QSAR) model to design novel odorant molecules. The method structures the VAE's latent space based on odor probability, enabling the generation of valid, unique, and synthetically viable candidate molecules from a limited training set. The results show the model successfully explores novel chemical space, producing stable candidates with practical synthesis routes.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["QSAR-Guided Generative Framework for Odorant Discovery<br>基于QSAR引导的生成式气味分子发现框架"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["核心问题/Problem<br>Challenging to discover novel odorants from vast chemical space with limited data<br>从巨大化学空间中利用有限数据发现新气味分子具有挑战性"]
        Method["主要方法/Method<br>VAE + QSAR model for de novo molecular design<br>使用VAE与QSAR模型进行从头分子设计"]
        Results["关键结果/Results<br>Generates valid, unique, novel, stable, and synthetically viable odorant candidates<br>生成有效、独特、新颖、稳定且可合成的气味分子候选物"]
    ```

- **[arXiv251230] Why Machine Learning Models Systematically Underestimate Extreme Values II: How to Fix It with LatentNN**
  - **tags:** [ai], [statistical machine learning], [attenuation bias, latent variable, neural networks, measurement error, joint likelihood]
  - **authors:** Yuan-Sen Ting
  - **institution:** The Ohio State University, Max-Planck-Institut für Astronomie
  - **link:** https://arxiv.org/pdf/2512.23138
  - **code:** https://github.com/tingyuansen/LatentNN
  - **contributions:** 1. Demonstrates that neural networks suffer from attenuation bias, a systematic underestimation of extreme values due to input measurement errors. 2. Proposes LatentNN, a method that generalizes the latent variable solution from linear regression to neural networks by jointly optimizing network parameters and latent input values. 3. Validates the method's effectiveness in reducing bias across various scenarios, including low signal-to-noise astronomical data, and defines its effective operational regime.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e1e58f31518d154aacb0668496d22b5dba87a170b019457f35d0fd0bfb1e03b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of attenuation bias, where neural networks systematically underestimate extreme values due to noisy input measurements. It introduces LatentNN, a method that treats true inputs as latent variables and jointly optimizes them with the network parameters by maximizing the joint data likelihood. The results show that LatentNN effectively reduces this bias, especially in the low signal-to-noise regimes common in astronomy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Why Machine Learning Models Systematically Underestimate Extreme Values II: How to Fix It with LatentNN] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[神经网络存在衰减偏差 / Neural networks suffer from attenuation bias]
        B1 --> B2[输入测量误差导致极端值被低估 / Input measurement errors cause underestimation of extreme values]
        C --> C1[提出LatentNN方法 / Propose LatentNN method]
        C1 --> C2[将真实输入作为潜变量 / Treat true inputs as latent variables]
        C2 --> C3[联合优化网络参数和潜变量 / Jointly optimize network parameters and latent values]
        D --> D1[有效减少衰减偏差 / Effectively reduces attenuation bias]
        D1 --> D2[在低信噪比天文数据中表现良好 / Performs well in low-SNR astronomical data]
    ```

- **[arXiv251230] An Inference-Based Architecture for Intent and Affordance Saturation in Decision-Making**
  - **tags:** [ai], [reinforcement learning], [Kullback-Leibler divergence, decision paralysis, intent selection, affordance selection, hierarchical decision process]
  - **authors:** Wendyam Eric Lionel Ilboudo, Saori C Tanaka
  - **institution:** Nara Institute of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.23144
  - **contributions:** 1. Proposes a computational account of decision paralysis as convergence failure in a hierarchical decision process, separating intent and affordance selection. 2. Formalizes decision commitment as inference under a mixture of reverse-KL (mode-seeking) and forward-KL (mode-covering) objectives. 3. Demonstrates through simulations that forward-KL-biased inference reproduces key features of decision inertia and shutdown, framing autism as an extreme regime of this general decision-making continuum.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae0c1bd96570e940c6fa7d72cbfcec334b1a94d288ce774a384e5c60b2bfe206_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses decision paralysis by proposing a hierarchical inference-based model that separates intent and affordance selection. Commitment is formalized using a mixture of reverse-KL and forward-KL divergence objectives, where a bias towards forward-KL leads to slow, heavy-tailed response times and distinct failure modes. The model reproduces features of decision inertia and suggests autism represents an extreme case on this decision-making continuum.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[An Inference-Based Architecture for Intent and Affordance Saturation in Decision-Making] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br>Decision Paralysis] --> P1[挑战/Challenge<br>Choice models assume ready-to-compare options]
        Problem --> P2[现象/Phenomenon<br>Hesitation, freezing, failure to act]
        Method[主要方法/Method<br>Computational Account] --> M1[架构/Architecture<br>Hierarchical decision process]
        Method --> M2[形式化/Formalization<br>Intent vs. Affordance selection]
        Method --> M3[目标/Objective<br>Mixture of reverse-KL & forward-KL]
        Results[关键结果/Results<br>Simulation Outcomes] --> R1[行为/Behavior<br>Slow, heavy-tailed response times]
        Results --> R2[失败模式/Failure Modes<br>Intent & Affordance saturation]
        Results --> R3[解释/Interpretation<br>Autism as an extreme regime]
    ```

- **[arXiv251230] Clipped Gradient Methods for Nonsmooth Convex Optimization under Heavy-Tailed Noise: A Refined Analysis**
  - **tags:** [ai], [stochastic optimization], [gradient clipping, heavy-tailed noise, nonsmooth convex optimization, convergence analysis, Freedman's inequality]
  - **authors:** Zijian Liu
  - **institution:** New York University
  - **link:** https://arxiv.org/pdf/2512.23178
  - **contributions:** 1. Provided a refined analysis for Clipped SGD under heavy-tailed noise, achieving faster high-probability convergence rates that depend on a novel "generalized effective dimension" term. 2. Extended the refined analysis to convergence in expectation, obtaining new rates that break previously known lower bounds and proving their optimality by matching newly established lower bounds. 3. Established new lower bounds for both high-probability and in-expectation convergence, completing the theoretical landscape and confirming the optimality of the new in-expectation rates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f14888c84379a942fea9e71d6d6a8df252ea20840f1e922a872a2fa3ee4897b2_w640_q70.webp
  - **Simple LLM Summary:** This paper refines the theoretical analysis of Clipped Stochastic Gradient Descent (Clipped SGD) for nonsmooth convex optimization under heavy-tailed gradient noise. By improving the use of Freedman's inequality and providing finer bounds for clipping error, the authors derive faster high-probability convergence rates and new optimal in-expectation rates that surpass previous lower bounds. The work also establishes matching lower bounds, demonstrating the optimality of the proposed analysis for convergence in expectation.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Clipped Gradient Methods for Nonsmooth Convex Optimization under Heavy-Tailed Noise: A Refined Analysis] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[Heavy-tailed gradient noise with bounded p-th moment (p∈(1,2]) / 具有有界p阶矩的重尾梯度噪声]
    C --> C1[Refined analysis of Clipped SGD / 对Clipped SGD的精细分析]
    C1 --> C2[Better use of Freedman's inequality / 更好地利用Freedman不等式]
    C1 --> C3[Finer bounds for clipping error / 对裁剪误差的更精细边界]
    D --> D1[Faster high-probability rates with generalized effective dimension / 具有广义有效维度的更快高概率收敛率]
    D --> D2[New optimal in-expectation rates breaking known lower bounds / 打破已知下界的新最优期望收敛率]
    D --> D3[New matching lower bounds established / 建立了新的匹配下界]
    ```

- **[arXiv251230] Persistent Homology via Finite Topological Spaces**
  - **tags:** [other], [topological data analysis], [persistent homology, finite topological spaces, posets, crosscut complexes, stability]
  - **authors:** Selçuk Kayacan
  - **institution:** Bahçeşehir University
  - **link:** https://arxiv.org/pdf/2512.23348
  - **contributions:** 1. Proposes a functorial framework for persistent homology using filtrations of finite topological spaces and posets, bypassing the need for inclusion relations between simplicial complexes. 2. Demonstrates that standard simplifications at the poset level preserve persistent invariants. 3. Proves the stability of the resulting persistence diagrams under metric perturbations in a density-based instantiation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66f9ee5417a1e46f255a691f585eeb3b163bd4b47edaafbe115e358a54f4c884_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes a new functorial framework for persistent homology that starts from a finite metric space and constructs a filtration of finite topological spaces, then functorially maps these to posets and simplicial complexes via crosscut constructions. This approach decouples the metric from the homological analysis and does not require inclusion maps between complexes. The authors show that poset-level simplifications preserve persistent invariants and prove the stability of the resulting persistence diagrams.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Persistent Homology via Finite Topological Spaces] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Standard persistent homology relies on inclusion-based filtrations of simplicial complexes.]
        C[主要方法/Method: A functorial framework using filtrations of finite topological spaces and posets, mapped to complexes via crosscut constructions.]
        D[关键结果/Results: Poset-level simplifications preserve invariants; persistence diagrams are stable under metric perturbations.]
    ```

- **[arXiv251230] Probabilistic Modelling is Sufficient for Causal Inference**
  - **tags:** [ai], [causal inference], [probabilistic modelling, causal inference, do-operator, structural causal models, Bayesian networks]
  - **authors:** Bruno Mlodozeniec, David Krueger, Richard E. Turner
  - **institution:** University of Cambridge, Max Planck Institute for Intelligent Systems, MILA
  - **link:** https://arxiv.org/pdf/2512.23408
  - **contributions:** 1. Demonstrates that standard probabilistic modelling is sufficient for answering causal inference questions without requiring special causal frameworks. 2. Provides concrete examples showing how causal problems (interventional and counterfactual) can be solved by "writing down the probability of everything". 3. Reinterprets established causal tools (e.g., do-operator, do-calculus) as "syntactic sugar" emerging from standard probabilistic modelling, clarifying their utility.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42538108be020614ac69c6d340cfeef4400c649311210c2f7081e50dc3d98ef5_w640_q70.webp
  - **Simple LLM Summary:** This paper argues that causal inference questions can be fully addressed using standard probabilistic modelling and inference, without needing specialized causal tools or notation. The core method is to "write down the probability of everything" to model and solve both interventional and counterfactual problems. The authors conclude that causal-specific frameworks are not fundamentally necessary but can be seen as convenient abstractions built upon probabilistic foundations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Probabilistic Modelling is Sufficient for Causal Inference] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Confusion over tools for causal inference in ML] --> B1[声称需要专门因果框架/Claims need for bespoke causal frameworks]
        C[主要方法/Method<br>Write down the probability of everything] --> C1[使用概率建模解决因果问题/Solve causal questions with probabilistic modelling]
        D[关键结果/Results<br>Causal tools are syntactic sugar] --> D1[因果工具源于概率建模/Causal tools emerge from probabilistic modelling]
    ```

- **[arXiv251230] Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [alpha screening, large language models, reinforcement learning, factor investing, economic reasoning]
  - **authors:** Zuoyou Jiang, Li Zhao, Rui Sun, Ruohan Sun, Zhongjian Li, Jing Li, Daxin Jiang, Zuo Bai, Cheng Hua
  - **institution:** Shanghai Jiao Tong University, StepFun, FinStep
  - **link:** https://arxiv.org/pdf/2512.23515
  - **code:** https://github.com/FinStep-AI/Alpha-R1
  - **contributions:** 1. Proposes Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. 2. Introduces a method for LLMs to reason over factor logic and real-time news to evaluate alpha relevance under changing market conditions. 3. Demonstrates that the model consistently outperforms benchmarks and shows improved robustness to alpha decay across multiple asset pools.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d921912985e0858276fe1088914641df9c33c30f5de309733b2244c86c21e75e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of alpha decay in non-stationary financial markets by proposing Alpha-R1, a reasoning model trained with reinforcement learning. It uses a large language model to process factor logic and news, selectively activating factors based on contextual economic relevance. Empirical results show it outperforms benchmark strategies and is more robust to signal decay.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning] --> B[核心问题/Problem: Signal decay and regime shifts in non-stationary markets; existing methods overlook semantic rationale for factor relevance.]
        A --> C[主要方法/Method: Alpha-R1, an 8B-parameter LLM trained via RL, reasons over factor logic and real-time news for context-aware alpha screening.]
        A --> D[关键结果/Results: Outperforms benchmark strategies; exhibits improved robustness to alpha decay across multiple asset pools.]
    ```

- **[arXiv251230] Adaptive Fusion Graph Network for 3D Strain Field Prediction in Solid Rocket Motor Grains**
  - **tags:** [ai], [graph neural networks], [graph U-Net, adaptive pooling, feature fusion, strain field prediction, solid rocket motor]
  - **authors:** Jiada Huang, Hao Ma, Zhibin Shen, Yizhou Qiao, Haiyang Li
  - **institution:** National University of Defense Technology, Zhengzhou University of Aeronautics
  - **link:** https://arxiv.org/pdf/2512.23443
  - **contributions:** 1. Proposes GrainGNet, an adaptive graph network with an adaptive pooling dynamic node selection mechanism to preserve key mechanical features in critical structural regions. 2. Utilizes feature fusion to transmit deep features and enhance the model's representational capacity for 3D strain field prediction. 3. Demonstrates significant performance improvements, including a 62.8% reduction in mean squared error and a sevenfold training efficiency gain over a baseline graph U-Net, with particular accuracy in high-strain regions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a35459d2c7214afb29d74bb1f279ddd56dc621982ef3910ac226653dcfc465f1_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes GrainGNet, an adaptive fusion graph network, to predict the 3D strain field in solid rocket motor grains, addressing the computational expense of traditional simulations. The model uses adaptive pooling and feature fusion to accurately capture high-strain regions. It achieves a 62.8% reduction in mean squared error and improved training efficiency compared to baseline methods, offering a high-fidelity approach for structural safety evaluation.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Adaptive Fusion Graph Network for 3D Strain Field Prediction in Solid Rocket Motor Grains] --> B[核心问题/Problem: Local high strain causes structural failure; traditional simulations are expensive; surrogate models lack geometric accuracy.]
    A --> C[主要方法/Method: Proposes GrainGNet with adaptive pooling and feature fusion to preserve key features and enhance representation.]
    A --> D[关键结果/Results: 62.8% MSE reduction vs. baseline; 7x training efficiency; 33% error reduction in high-strain regions.]
    ```

- **[arXiv251230] A general framework for deep learning**
  - **tags:** [ai], [statistical learning theory], [deep neural networks, Bernstein-type inequality, excess risk bound, minimax optimality, mixing processes]
  - **authors:** William Kengne, Modou Wade
  - **institution:** Université Jean Monnet, CY Cergy Paris Université
  - **link:** https://arxiv.org/pdf/2512.23425
  - **contributions:** 1. Proposes a general theoretical framework for deep learning that unifies analysis for data satisfying a generalized Bernstein-type inequality, encompassing independent and various dependent (mixing) observations. 2. Introduces two novel estimators: a Non-Penalized Deep Neural Network (NPDNN) and a Sparse-Penalized Deep Neural Network (SPDNN) estimator. 3. Establishes minimax optimal (up to logarithmic factors) convergence rates for the expected excess risk of both estimators on Hölder smooth and composition function classes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4efb1121ddfae593e4dedab080501366fad55274c1b149910f149a1920a0b6e2_w640_q70.webp
  - **Simple LLM Summary:** This paper develops a general theoretical framework for analyzing deep neural network estimators in settings including nonparametric regression and classification. It proposes two estimators (NPDNN and SPDNN) and derives upper bounds for their expected excess risk for data satisfying a generalized Bernstein-type inequality, covering independent and various dependent data processes. The main conclusion is that both proposed estimators achieve minimax optimal convergence rates in many classical settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A general framework for deep learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[统一理论分析框架/Unified theoretical analysis framework]
        B1 --> B2[数据满足广义Bernstein不等式/Data satisfies generalized Bernstein inequality]
        B2 --> B3[包含独立与混合观测/Includes independent and mixing observations]
        C --> C1[提出两种估计器/Propose two estimators]
        C1 --> C2[非惩罚深度神经网络/NPDNN]
        C1 --> C3[稀疏惩罚深度神经网络/SPDNN]
        D --> D1[推导期望超额风险上界/Establish upper bounds for expected excess risk]
        D1 --> D2[Hölder函数类/Hölder function classes]
        D --> D3[证明极小极大最优性/Prove minimax optimality]
        D3 --> D4[多种经典设置/Many classical settings]
    ```

- **[arXiv251230] From geometry to dynamics: Learning overdamped Langevin dynamics from sparse observations with geometric constraints**
  - **tags:** [ai], [stochastic system identification], [overdamped Langevin dynamics, sparse observations, geometric constraints, stochastic control, path augmentation]
  - **authors:** Dimitra Maoutsa
  - **institution:** Technical University of Berlin
  - **link:** https://arxiv.org/pdf/2512.23566
  - **contributions:** 1. A new framework that reconciles geometric and temporal perspectives by reformulating inference as a stochastic control problem. 2. A method using geometry-driven path augmentation, guided by the system's invariant density, to reconstruct trajectories without assuming specific parametric models. 3. Demonstrating accurate recovery of stochastic dynamics from extremely undersampled data, outperforming existing methods in synthetic benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7a01c554437b016c9e156f0cb5f7047dd8973704b2623e3d218e1b9c76975c0_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of learning stochastic dynamics from sparse temporal observations. It proposes a new framework that uses geometry-driven path augmentation within a stochastic control formulation to infer the underlying laws without parametric assumptions. The method successfully recovers overdamped Langevin dynamics from highly undersampled data, outperforming existing approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[From geometry to dynamics: Learning overdamped Langevin dynamics from sparse observations with geometric constraints] --> B(核心问题/Problem: How to learn stochastic dynamics from sparse observations?);
        A --> C(主要方法/Method: Reformulate inference as a stochastic control problem with geometry-driven path augmentation);
        A --> D(关键结果/Results: Accurately recovers dynamics from undersampled data, outperforms existing methods);
    ```

- **[arXiv251230] The Nonstationarity-Complexity Tradeoff in Return Prediction**
  - **tags:** [ai], [financial machine learning], [non-stationarity, model selection, adaptive window selection, return prediction, tournament procedure]
  - **authors:** Agostino Capponi, Chengpiao Huang, J. Antonio Sidaoui, Kaizheng Wang, Jiacheng Zou
  - **institution:** Columbia University, Stanford University
  - **link:** https://arxiv.org/pdf/2512.23596
  - **contributions:** 1. Identifies and formalizes the nonstationarity-complexity tradeoff in return prediction, where complex models reduce misspecification but require longer, more non-stationary training windows. 2. Proposes a novel model selection method that jointly optimizes model class and training window size using an adaptive tournament procedure evaluated on non-stationary validation data. 3. Provides theoretical analysis showing the method balances misspecification error, estimation variance, and non-stationarity, and demonstrates its empirical superiority with significant performance gains in out-of-sample prediction and trading strategy returns, especially during recessions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07919419a5b2bc9758efcadd74b91c11fcdca1529edf541c429c2694c06ddde0_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of predicting stock returns in non-stationary environments by identifying a tradeoff between model complexity and non-stationarity. It proposes a new model selection method that jointly chooses the model and its training window via an adaptive tournament. The method outperforms standard benchmarks, particularly during economic recessions, and generates higher cumulative returns for a trading strategy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Nonstationarity-Complexity Tradeoff in Return Prediction] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[预测中的非平稳性-复杂性权衡/Nonstationarity-Complexity Tradeoff in Prediction]
        C --> C1[联合优化模型与窗口的锦标赛方法/Tournament Method for Joint Model & Window Selection]
        D --> D1[OOS R²提升 & 衰退期表现优异/Improved OOS R² & Superior Recession Performance]
    ```

- **[arXiv251230] Calibrated Multi-Level Quantile Forecasting**
  - **tags:** [ai], [online learning, forecasting], [quantile forecasting, calibration, online learning, adversarial robustness, no-regret guarantee]
  - **authors:** Tiffany Ding, Isaac Gibbs, Ryan J. Tibshirani
  - **institution:** University of California, Berkeley
  - **link:** https://arxiv.org/pdf/2512.23671
  - **contributions:** 1. Introduces Multi-Level Quantile Tracker (MultiQT), a lightweight online method that wraps any existing forecaster to guarantee multi-level quantile calibration against adversarial distribution shifts. 2. Provides theoretical guarantees including calibration and a no-regret property ensuring asymptotic performance is not worse than the base forecaster. 3. Ensures the corrected forecasts are properly ordered across different quantile levels.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/133e23e4bb898bd730a1ed52ef1e6f20bce16c1d2910d09105ad3e344368fe6f_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of producing reliable multi-level quantile forecasts that are calibrated. It proposes MultiQT, an online wrapper method that guarantees calibration and proper ordering of forecasts even under adversarial conditions, without asymptotically worsening the base forecaster's performance. Experiments show it significantly improves calibration in epidemic and energy forecasting tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Calibrated Multi-Level Quantile Forecasting] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Need for reliable, calibrated multi-level quantile forecasts] --> P1[校准保证/Calibration Guarantee]
        Problem --> P2[顺序性/Ordering Constraint]
        Method[主要方法/Method: Multi-Level Quantile Tracker (MultiQT)] --> M1[在线包装器/Online Wrapper]
        Method --> M2[对抗性鲁棒/Adversarially Robust]
        Method --> M3[无遗憾保证/No-Regret Guarantee]
        Results[关键结果/Results] --> R1[显著改进校准/Significantly Improves Calibration]
        Results --> R2[实证验证/Empirical Validation in Real Problems]
    ```

- **[arXiv251230] Bellman Calibration for V-Learning in Offline Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [Bellman calibration, off-policy evaluation, value iteration, doubly robust estimator, Markov decision process]
  - **authors:** Lars van der Laan, Nathan Kallus
  - **institution:** University of Washington, Netflix, Cornell University
  - **link:** https://arxiv.org/pdf/2512.23694
  - **contributions:** 1. Introduces Iterated Bellman Calibration, a model-agnostic, post-hoc procedure for calibrating value predictions in infinite-horizon MDPs. 2. Adapts classical calibration methods (histogram, isotonic) to the dynamic, counterfactual setting using a doubly robust pseudo-outcome for off-policy data. 3. Provides finite-sample guarantees for calibration and prediction without requiring Bellman completeness or realizability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9300a417035535b3fec586f3ad8f9e10dae8a084d794d1d413f42e5ba2b05d37_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Iterated Bellman Calibration, a post-hoc method to improve the accuracy of long-term value predictions in offline reinforcement learning. The method repeatedly regresses fitted Bellman targets onto a model's predictions, adapting classical calibration techniques to handle off-policy data. The analysis shows the approach provides finite-sample guarantees for calibrated predictions under weak assumptions, without needing Bellman completeness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Bellman Calibration for V-Learning<br/>Bellman校准用于V学习] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[预测长期回报的校准<br/>Calibrating long-term value predictions]
        B --> B2[离线、反事实数据<br/>Offline, counterfactual data]
        C --> C1[迭代贝尔曼校准<br/>Iterated Bellman Calibration]
        C --> C2[使用双稳健伪结果<br/>Using doubly robust pseudo-outcome]
        C --> C3[直方图/保序回归适配<br/>Adapting histogram/isotonic regression]
        D --> D1[有限样本保证<br/>Finite-sample guarantees]
        D --> D2[无需贝尔曼完备性<br/>No Bellman completeness required]
    ```

- **[arXiv251230] INSIGHT: Spatially resolved survival modelling from routine histology crosslinked with molecular profiling reveals prognostic epithelial-immune axes in stage II/III colorectal cancer**
  - **tags:** [cv], [computational pathology], [graph neural network, survival prediction, spatial transcriptomics, colorectal cancer, histology]
  - **authors:** Piotr Keller, Mark Eastwood, Zedong Hu, Aimée Selten, Ruqayya Awan, Gertjan Rasschaert, Sara Verbandt, Vlad Popovici, Hubert Piessevaux, Hayley T Morris, Petros Tsantoulis, Thomas Alexander McKee, André D'Hoore, Cédric Schraepen, Xavier Sagaert, Gert De Hertogh, Sabine Tejpar, Fayyaz Minhas
  - **institution:** KU Leuven, University of Oxford, University of Cambridge, University of Manchester, University of Bristol, University of Edinburgh, University of Glasgow, University of Sheffield, University of Southampton, University of Warwick, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strathclyde, University of Aberdeen, University of Dundee, University of St Andrews, University of Glasgow, University of Edinburgh, University of Manchester, University of Bristol, University of Cambridge, University of Oxford, University of London, University of Warwick, University of Sheffield, University of Southampton, University of York, University of Birmingham, University of Nottingham, University of Leeds, University of Liverpool, University of Newcastle, University of Exeter, University of Leicester, University of Sussex, University of Surrey, University of Strath
  - **link:** https://arxiv.org/pdf/2512.22262
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e16c74c6d57e6b8f3cec00c4cc6267b2b66595c314bba0f371e27e2f86f25458_w640_q70.webp

## 2026-01-01

- **[arXiv260101] Network Traffic Analysis with Process Mining: The UPSIDE Case Study**
  - **tags:** [sys], [network traffic analysis], [process mining, Petri nets, unsupervised characterization, network traffic classification, interpretability]
  - **authors:** Francesco Vitale, Paolo Palmiero, Massimiliano Rak, Nicola Mazzocca
  - **institution:** University of Naples Federico II, University of Campania Luigi Vanvitelli
  - **link:** https://arxiv.org/pdf/2512.23718
  - **contributions:** 1. Proposes a novel process mining-based method for the unsupervised characterization of states from gaming network traffic data. 2. Encodes the identified network states into interpretable process models (Petri nets) for explainable analysis. 3. Demonstrates the method's capability to classify network traffic to identify different video games being played, achieving good accuracy and model coherence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aef2d73934ec0b931bbb0dbae5c9be217f30aa949e9142a6391ac35afe9d92a9_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a process mining method to analyze gaming network traffic for explainable modeling and classification. The method performs unsupervised state characterization, encodes states into interpretable Petri nets, and classifies traffic to identify specific games. Results on the UPSIDE case study show the approach can effectively model network behavior with high coherence and specificity while maintaining good classification accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Network Traffic Analysis with Process Mining: The UPSIDE Case Study] --> B(核心问题/Problem: Need for explainable analysis of complex gaming network traffic)
        A --> C(主要方法/Method: Process mining for unsupervised state characterization, encoding into Petri nets, and traffic classification)
        A --> D(关键结果/Results: High model coherence (94.02%), specificity (174.99%), and good game classification accuracy (73.84% AUC))
    ```

- **[arXiv260101] A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation**
  - **tags:** [hpc], [computational geometry], [mesh generation, geometry preparation, CAD-to-mesh, machine learning, large language models]
  - **authors:** Steven Owen, Nathan Brown, Nikos Chrisochoides, Rao Garimella, Xianfeng Gu, Franck Ledoux, Na Lei, Roshan Quadros, Navamita Ray, Nicolas Winovich, Yongjie Jessica Zhang
  - **institution:** Sandia National Laboratories, Old Dominion University, Los Alamos National Laboratory, New York University / Stony Brook University, CEA, Dalian University of Technology, Carnegie Mellon University
  - **link:** https://arxiv.org/pdf/2512.23719
  - **contributions:** 1. Surveys the application of AI/ML methods to automate and improve key steps in the CAD-to-mesh pipeline, such as part classification, mesh quality prediction, and defeaturing. 2. Reviews AI techniques for enhancing unstructured/block-structured meshing, volumetric parameterization, and parallel mesh generation. 3. Examines emerging tools like reinforcement learning and large language models for scripting automation in meshing workflows.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c3d8c73084ddd952c2e0c9fd20e1b7fe1d87bb02c884cf6327ca47e6ec442eb_w640_q70.webp
  - **Simple LLM Summary:** This survey paper reviews how artificial intelligence and machine learning are being applied to address bottlenecks in geometry preparation and mesh generation for engineering simulation. It explores a range of methods, from quality prediction to automation with large language models, concluding that AI serves as an assistive technology to extend traditional tools and highlights key challenges for future data-driven workflows.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[CAD-to-mesh流程瓶颈 / CAD-to-mesh Pipeline Bottlenecks]
        C --> C1[AI辅助几何与网格生成 / AI-aided Geometry & Meshing]
        C --> C2[机器学习方法 / Machine Learning Methods]
        C --> C3[新兴自动化工具 / Emerging Automation Tools]
        C1 --> C1a[部件分类 / Part Classification]
        C1 --> C1b[网格质量预测 / Mesh Quality Prediction]
        C1 --> C1c[去特征化 / Defeaturing]
        C2 --> C2a[非结构化/块结构化网格 / Unstructured/Block-structured Meshing]
        C2 --> C2b[体积参数化 / Volumetric Parameterizations]
        C2 --> C2c[并行网格生成 / Parallel Mesh Generation]
        C3 --> C3a[强化学习 / Reinforcement Learning]
        C3 --> C3b[大语言模型 / Large Language Models]
        D --> D1[AI作为辅助技术 / AI as Assistive Technology]
        D --> D2[代表性方法与部署 / Representative Methods & Deployments]
        D --> D3[关键研究挑战 / Key Research Challenges]
    ```

- **[arXiv260101] Governing Cloud Data Pipelines with Agentic AI**
  - **tags:** [mlsys], [agent system], [policy-aware control, bounded AI agents, adaptive resource reconfiguration, schema reconciliation, automated failure recovery]
  - **authors:** Aswathnarayan Muthukrishnan Kirubakaran, Adithya Parthasarathy, Nitin Saksena, Ram Sekhar Bodala, Akshay Deshpande, Suhas Malempati, Shiva Carimireddy, Abhirup Mazumder
  - **institution:** IEEE, Independent Researcher, Albertsons, Amtrak, Cato
  - **link:** https://arxiv.org/pdf/2512.23737
  - **contributions:** 1. A production-oriented control plane architecture for policy-aware agentic management of cloud data pipelines. 2. Detailed agent workflows for monitoring, optimization, and schema management. 3. An evaluation demonstrating significant improvements in recovery time, operational cost, and reduction of manual intervention.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5297c02d67a11ab83e576eb218227051a192108c8ce2adf60d62e9fbdb7e355_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Agentic Cloud Data Engineering, a control architecture that integrates bounded AI agents to autonomously govern cloud data pipelines by analyzing telemetry and enforcing declarative policies. The method enables adaptive actions like resource reconfiguration and automated recovery. Experimental results show it reduces recovery time by up to 45%, lowers costs by ~25%, and cuts manual intervention by over 70% compared to static orchestration.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Governing Cloud Data Pipelines with Agentic AI"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["静态配置与被动运维/Static Config & Reactive Ops"]
        Problem --> P2["恢复慢、成本高、手动多/Slow Recovery, High Cost, Manual Overhead"]
        Method --> M1["策略感知控制架构/Policy-aware Control Architecture"]
        Method --> M2["集成有界AI代理/Integrate Bounded AI Agents"]
        Method --> M3["自适应操作/Adaptive Actions"]
        Results --> R1["恢复时间降低45%/Recovery Time ↓45%"]
        Results --> R2["运营成本降低25%/Operational Cost ↓25%"]
        Results --> R3["手动干预减少70%/Manual Intervention ↓70%"]
    ```

- **[arXiv260101] A Comprehensive Study of Deep Learning Model Fixing Approaches**
  - **tags:** [se], [software testing and debugging], [deep learning model fixing, empirical study, robustness, fairness, backward compatibility]
  - **authors:** Hanmo You, Zan Wang, Zishuo Dong, Luanqi Mo, Jianjun Zhao, Junjie Chen
  - **institution:** Tianjin University, Kyushu University
  - **link:** https://arxiv.org/pdf/2512.23745
  - **contributions:** 1. Conducted a large-scale empirical study evaluating 16 state-of-the-art DL model fixing approaches across model-level, layer-level, and neuron-level categories. 2. Comprehensively assessed the approaches not only on fixing effectiveness but also on their impact on critical properties like robustness, fairness, and backward compatibility. 3. Provided key findings and insights for industry and academia, such as model-level approaches having superior fixing effectiveness and the trade-off between fixing performance and maintaining other model properties.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2da70efdc2c67bda59610794db06383b27cdc3ff0d3c9ab3e06c8ec8a0fac3a1_w640_q70.webp
  - **Simple LLM Summary:** This paper conducts a comprehensive empirical study on 16 deep learning model fixing approaches. It evaluates their effectiveness and impact on properties like robustness and fairness, finding that model-level approaches are most effective but no single approach excels in all aspects. The study concludes that future research should focus on mitigating the side effects of model fixing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Comprehensive Study of Deep Learning Model Fixing Approaches] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[DL模型存在故障，可能导致严重后果/DL models have faults causing severe consequences]
        C --> C1[对16种最新模型修复方法进行大规模实证研究/Large-scale empirical study on 16 SOTA model fixing approaches]
        C --> C2[评估修复效果及对鲁棒性、公平性等属性的影响/Evaluate fixing effectiveness and impact on robustness, fairness, etc.]
        D --> D1[模型级方法修复效果最佳/Model-level approaches have superior fixing effectiveness]
        D --> D2[没有方法能在所有属性上表现最佳/No single approach performs best on all properties]
    ```

- **[arXiv260101] A Review of Diffusion-based Simulation-Based Inference: Foundations and Applications in Non-Ideal Data Scenarios**
  - **tags:** [ai], [simulation-based inference], [diffusion models, score matching, posterior sampling, misspecification, Schrodinger bridge]
  - **authors:** Haley Rosso, Talea Mayo
  - **institution:** Emory University
  - **link:** https://arxiv.org/pdf/2512.23748
  - **contributions:** 1. Provides a comprehensive review of diffusion models as a framework for simulation-based inference (SBI), connecting mathematical foundations to practical applications. 2. Analyzes the comparative advantages of diffusion-based SBI over methods like normalizing flows, particularly in addressing robustness under non-ideal data conditions. 3. Synthesizes specialized methods for handling challenges like model misspecification, unstructured observations, and missing data, highlighting inference-time prior adaptation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c7b2b583a1f5706dab9104c469ca95816c45b56fef4f982f0a27368fe696141d_w640_q70.webp
  - **Simple LLM Summary:** This review paper explores the use of diffusion models for simulation-based inference, a method for learning posterior distributions when likelihood functions are intractable. It examines how diffusion models, through conditional score matching, offer a flexible and robust framework, especially for scientific data with issues like model misspecification and missingness. The main conclusion is that diffusion-based SBI provides significant advantages in non-ideal data scenarios, though it introduces trade-offs such as iterative sampling costs.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Review of Diffusion-based Simulation-Based Inference: Foundations and Applications in Non-Ideal Data Scenarios"] --> Problem["核心问题/Problem: Intractable likelihoods in complex simulations hinder parameter inference."]
        Root --> Method["主要方法/Method: Use diffusion models (score matching) for likelihood-free posterior sampling."]
        Root --> Results["关键结果/Results: Diffusion-based SBI is robust to non-ideal data (misspecification, missingness)."]
    ```

- **[arXiv260101] Coordinate Matrix Machine: A Human-level Concept Learning to Classify Very Similar Documents**
  - **tags:** [ai], [one-shot learning], [Coordinate Matrix Machine, structural intelligence, Green AI, lazy learning, glass-box model]
  - **authors:** Amin Sadri, M Maruf Hossain
  - **institution:** Not explicitly stated (email domains are personal: gmail.com)
  - **link:** https://arxiv.org/pdf/2512.23749
  - **code:** GitHub Repository (URL not fully specified in provided text)
  - **contributions:** Proposes the Coordinate Matrix Machine (CM^2) for one-shot document classification, Introduces a structural coordinate-based approach as an alternative to semantic vectorization, Designs a "Green AI" model optimized for CPU use with inherent explainability
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3acd9104b41dbc3c7f9d1597d31b940424a078e93beb2b2b21007c741209b006_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of human-level concept learning, where machines require many examples to learn a concept. It proposes the Coordinate Matrix Machine (CM^2), a purpose-built model that learns document structures to classify very similar documents using only one sample per class. The method is presented as a "Green AI" solution that outperforms traditional models while being computationally efficient and explainable.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Coordinate Matrix Machine: A Human-level Concept Learning to Classify Very Similar Documents] --> B[核心问题/Problem: Human-level Concept Learning Gap]
        A --> C[主要方法/Method: Coordinate Matrix Machine (CM^2)]
        A --> D[关键结果/Results: High Accuracy, One-shot Learning, Green AI]
        B --> B1[人类单样本学习/Human one-shot learning]
        B --> B2[机器需大量样本/Machine needs many samples]
        C --> C1[学习文档结构/Learns document structure]
        C --> C2[识别重要特征/Identifies important features]
        D --> D1[高精度与低数据/High accuracy with minimal data]
        D --> D2[CPU优化与可解释性/CPU-optimized & explainable]
    ```

- **[arXiv260101] Generalized Regularized Evidential Deep Learning Models: Theory and Comprehensive Evaluation**
  - **tags:** [ai], [uncertainty quantification], [Evidential Deep Learning, Subjective Logic, Activation Functions, Regularization, Learning Dynamics]
  - **authors:** Deep Shankar Pandey, Hyomin Choi, Qi Yu
  - **institution:** Rochester Institute of Technology, InterDigital
  - **link:** https://arxiv.org/pdf/2512.23753
  - **contributions:** 1. Theoretically characterizes the activation-dependent "learning-freeze" behavior in evidential deep learning models, where gradients vanish in low-evidence regions. 2. Designs a general family of activation functions and corresponding evidential regularizers to enable consistent evidence updates across different activation regimes. 3. Empirically validates the proposed theory and method through extensive experiments on multiple benchmark classification, few-shot classification, and blind face restoration tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fae8a70028f83294a153c8fd9b9083e99f87bf5f04f2fb8d64ce2fbab74beb82_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies and theoretically analyzes a "learning-freeze" problem in Evidential Deep Learning (EDL) models caused by specific activation functions. To solve this, the authors propose a generalized family of activation functions and regularizers. Extensive experiments show the proposed method improves learning dynamics and effectiveness across various tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Generalized Regularized Evidential Deep Learning Models") --> Problem("核心问题/Problem: Activation functions in EDL cause learning-freeze in low-evidence regions")
        Root --> Method("主要方法/Method: Design a general family of activation functions and evidential regularizers")
        Root --> Results("关键结果/Results: Theory validated; method effective across multiple benchmarks")
    ```

- **[arXiv260101] Geometric Scaling of Bayesian Inference in LLMs**
  - **tags:** [nlp], [interpretability], [Bayesian inference, geometric scaling, attention mechanism, value manifolds, predictive entropy]
  - **authors:** Naman Aggarwal, Siddhartha R. Dalal, Vishal Misra
  - **institution:** Dream Sports, Columbia University
  - **link:** https://arxiv.org/pdf/2512.23752
  - **contributions:** 1. Demonstrates that production-grade LLMs (Pythia, Phi-2, Llama-3, Mistral) preserve a geometric substrate (low-dimensional value manifolds) similar to that enabling exact Bayesian inference in small, controlled "wind-tunnel" models. 2. Shows that the dominant axis of last-layer value representations strongly correlates with predictive entropy, and domain-restricted prompts collapse the structure into the same low-dimensional manifolds. 3. Through targeted interventions on the entropy-aligned axis, reveals that this geometry is a privileged readout of uncertainty rather than a singular computational bottleneck for Bayesian-like behavior.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e11ae0519509ba1ae43d1087dfc56ed0f799df57a2ee4fe7c4a6a7f20eb11c3f_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether the geometric structures that enable exact Bayesian inference in small, controlled transformer models persist in large-scale production language models. The authors find that models like Llama-3 and Mistral organize their value representations along an entropy-correlated axis, forming similar low-dimensional manifolds. They conclude that modern LLMs preserve this geometric substrate for approximate Bayesian updates, though it acts more as a readout mechanism than a sole computational bottleneck.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Geometric Scaling of Bayesian Inference in LLMs] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Do geometric structures for Bayesian inference persist in production LLMs?]
        C[主要方法/Method<br>Analyze value representations & perform targeted axis interventions]
        D[关键结果/Results<br>Geometry persists as a privileged uncertainty readout]
    ```

- **[arXiv260101] HINTS: Extraction of Human Insights from Time-Series Without External Sources**
  - **tags:** [ai], [time series forecasting], [self-supervised learning, opinion dynamics, attention mechanism, latent factor extraction, residual analysis]
  - **authors:** Sheo Yon Jhin, Noseong Park
  - **institution:** KAIST
  - **link:** https://arxiv.org/pdf/2512.23755
  - **contributions:** 1. Proposes HINTS, a novel self-supervised framework that extracts latent human factors (e.g., sentiment, influence) endogenously from time series residuals without requiring external data sources like news or social media. 2. Introduces the use of the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to model evolving social influence, memory, and bias patterns within the time series data. 3. Demonstrates that integrating the extracted human factors as an attention map into a state-of-the-art backbone model consistently improves forecasting accuracy across multiple datasets and provides interpretable insights aligned with real-world events.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7a97eb229421de0a13cd23a1f8c66b8e7b1ac081ecf63d3e2a393fa375ac5f65_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high cost of using external data to model human factors in time series forecasting. It proposes HINTS, a self-supervised learning framework that extracts latent human insights directly from time series residuals using an opinion dynamics model as inductive bias. The method improves forecasting accuracy and provides interpretable factors aligned with real events, validated on nine real-world and benchmark datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HINTS: Extraction of Human Insights from Time-Series] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[外部数据依赖成本高/High cost of external data dependency]
        C --> C1[从残差中自监督提取人类因素/Self-supervised extraction from residuals]
        C --> C2[使用意见动力学作为归纳偏置/Using opinion dynamics as inductive bias]
        C --> C3[集成到注意力机制中/Integrated as attention map]
        D --> D1[预测精度提升/Forecasting accuracy improved]
        D --> D2[可解释性与现实事件对齐/Interpretability aligned with real events]
    ```

- **[arXiv260101] Drift-Based Dataset Stability Benchmark**
  - **tags:** [mlsys], [communication & networking], [concept drift, dataset stability, traffic classification, benchmark, feature weights]
  - **authors:** Dominik Soukup, Richard Plný, Daniel Vašata, Tomáš Čejka
  - **institution:** Czech Technical University in Prague, CESNET a.l.e.
  - **link:** https://arxiv.org/pdf/2512.23762
  - **contributions:** 1. A novel methodology for evaluating dataset stability based on concept drift detection and ML feature weights. 2. A benchmark workflow for comparing datasets and identifying their weak points. 3. A demonstration and initial benchmark of the framework on the CESNET-TLS-Year22 dataset, showing its use for dataset optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc4badd4590db607d7056063e44a30285afee3c4bd25f3f6b231fbc0932dd8de_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of model degradation in network traffic classification due to data/concept drift. It proposes a new framework that uses a concept drift detection method enhanced with ML feature weights to benchmark dataset stability. The method is demonstrated on a real-world TLS dataset, providing insights for dataset optimization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Drift-Based Dataset Stability Benchmark] --> B[核心问题/Problem: Model degradation from data drift in network traffic classification]
        A --> C[主要方法/Method: Concept drift detection boosted by ML feature weights for dataset benchmarking]
        A --> D[关键结果/Results: Initial stability benchmark for CESNET-TLS-Year22 dataset, showing optimization impact]
    ```

- **[arXiv260101] Exploring Cumulative Effects in Survival Data Using Deep Learning Networks**
  - **tags:** [ai], [survival analysis], [cumulative exposure, time-dependent data, deep learning, interpretability, Cox proportional hazards]
  - **authors:** Kang-Chung Yang, Shinsheng Yuan
  - **institution:** Institute of Statistical Science, Academia Sinica
  - **link:** https://arxiv.org/pdf/2512.23764
  - **contributions:** 1. Introduces CENNSurv, a novel deep learning approach for modeling the cumulative effects of time-dependent exposures on survival outcomes., 2. Addresses the scalability limitations of conventional spline-based methods by offering a more efficient approach suitable for large datasets., 3. Provides interpretable insights into cumulative exposure patterns, a feature often overlooked by existing neural network-based survival analysis methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1c5684128b891f6cf0f0d31c2656cc3c3eda012e286475475646b128c847e73_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces CENNSurv, a deep learning method designed to model the complex cumulative effects of time-varying exposures in survival data. It overcomes scalability issues of traditional methods and provides interpretable patterns. Evaluations on real-world datasets demonstrate its ability to uncover both long-term lagged associations and short-term critical shifts prior to an event.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Exploring Cumulative Effects in Survival Data Using Deep Learning Networks] --> B[核心问题/Problem: Modeling cumulative effects of time-dependent exposures is challenging]
        A --> C[主要方法/Method: Proposes CENNSurv, a novel deep learning approach]
        A --> D[关键结果/Results: Reveals lagged associations & behavioral shifts; shows improved scalability & interpretability]
    ```

- **[arXiv260101] Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data**
  - **tags:** [ai], [physics-informed machine learning], [coupled systems, sparsity regularization, multitask learning, partial differential equations, mesh-free sampling]
  - **authors:** Esha Saha, Hao Wang
  - **institution:** University of Alberta
  - **link:** https://arxiv.org/pdf/2512.23761
  - **contributions:** 1. Proposes MUSIC, a novel sparsity-induced multitask neural network framework for learning coupled system dynamics when physics constraints and data are incomplete and mutually exclusive. 2. Introduces a method that integrates partial physical constraints with data-driven learning using mesh-free sampling and sparsity regularization for model compression and efficiency. 3. Demonstrates the framework's effectiveness on complex solutions (e.g., shock waves) under data-scarce and noisy conditions, outperforming non-sparse baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0e3d79b9b98f61c6847aeaba2b3e63b7fa984963e6f3f20b8ab17794c98a542_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of modeling coupled dynamical systems where the governing equation is known for only one variable and data is available for another. It proposes MUSIC, a sparsity-regularized multitask neural network that integrates these partial constraints with data to recover full system solutions. The method shows improved accuracy and efficiency in learning complex solutions under scarce and noisy data conditions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Mismatch between known physics (for one variable) and observed data (for another) in coupled systems."]
        Method["主要方法/Method<br>MUSIC: Sparsity-induced multitask neural network with partial physics constraints and data-driven learning."]
        Results["关键结果/Results<br>Accurately learns complex solutions (shock waves, patterns) under data-scarce, noisy conditions; outperforms non-sparse methods."]
    ```

- **[arXiv260101] Neural Optimal Design of Experiment for Inverse Problems**
  - **tags:** [ai], [inverse problems], [optimal experimental design, neural reconstruction, sparsity by design, single-level optimization, sensor placement]
  - **authors:** John E. Darges, Babak Maboudi Afkham, Matthias Chung
  - **institution:** Emory University, University of Oulu
  - **link:** https://arxiv.org/pdf/2512.23763
  - **contributions:** 1. Proposes a novel single-level optimization framework (NODE) for optimal experimental design, avoiding the computational complexity of classical bilevel formulations. 2. Introduces direct optimization of continuous design variables (e.g., sensor locations) to enforce sparsity inherently, eliminating the need for l1 regularization and tuning. 3. Demonstrates the framework's effectiveness on analytical, image-based (MNIST), and real-world (sparse-view CT) inverse problems, showing improved reconstruction accuracy over baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6af595776f7b085ae6680908c7f2c444ddf88c3d25cdb5c27eba1e5fe6a41cbe_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces Neural Optimal Design of Experiments (NODE), a learning-based framework that jointly trains a neural reconstruction model and optimizes continuous experimental design variables (like sensor locations) in a single loop. This approach enforces sparsity directly, avoids complex bilevel optimization, and reduces computational cost. NODE is validated on multiple inverse problem benchmarks, consistently outperforming baseline methods in reconstruction accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Neural Optimal Design of Experiment for Inverse Problems<br>逆问题中的神经最优实验设计") --> Problem("核心问题/Problem: Optimal experimental design for inverse problems is traditionally complex (bilevel, requires sparsity tuning)<br>逆问题中的最优实验设计传统上很复杂（双层优化，需要稀疏性调参）")
        Root --> Method("主要方法/Method: NODE - Jointly trains neural reconstruction model & continuous design variables in a single loop<br>NODE - 在单层循环中联合训练神经重建模型和连续设计变量")
        Root --> Results("关键结果/Results: Enforces sparsity by design, reduces complexity, outperforms baselines on benchmarks (analytical, MNIST, CT)<br>通过设计实现稀疏性，降低复杂度，在多个基准测试上优于基线")
    ```

- **[arXiv260101] A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit**
  - **tags:** [ai], [subspace clustering], [Schubert Variety, Grassmann Manifold, Linde-Buzo-Grey (LBG), Subspace Clustering, Geometric Learning]
  - **authors:** Karim Salta, Michael Kirby, Chris Peterson
  - **institution:** Colorado State University
  - **link:** https://arxiv.org/pdf/2512.23766
  - **contributions:** 1. Introduces the concept of a trainable prototype called a Schubert Variety of Best Fit (SVBF) for representing clusters of subspaces. 2. Integrates the SVBF prototype into the Linde-Buzo-Grey (LBG) clustering pipeline to create the SVBF-LBG algorithm. 3. Demonstrates improved cluster purity on synthetic, image, spectral, and video action data compared to methods using subspace means.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a73e8fbe969f250567092a96ad55fca5bd7133b8ca34f30feedb918976b1faf5_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new subspace clustering method that uses a geometric prototype called a Schubert Variety of Best Fit (SVBF) instead of a simple subspace mean. The SVBF is integrated into the Linde-Buzo-Grey algorithm, resulting in an SVBF-LBG framework that shows improved clustering performance on various data types while preserving mathematical structure for analysis.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Need for geometric representatives in subspace clustering"] --> Problem_Sub["子问题/Sub-Problem<br>Subspace means on Grassmann manifold may not be optimal"]
        Method["主要方法/Method<br>Propose SVBF-LBG algorithm"] --> Method_Sub1["方法组件/Component 1<br>Schubert Variety of Best Fit (SVBF) prototype"]
        Method --> Method_Sub2["方法组件/Component 2<br>Integration into Linde-Buzo-Grey (LBG) pipeline"]
        Results["关键结果/Results<br>Improved cluster purity"] --> Results_Sub1["结果细节/Detail 1<br>Tested on synthetic, image, spectral, video data"]
        Results --> Results_Sub2["结果细节/Detail 2<br>Retains mathematical structure for downstream analysis"]
    ```

- **[arXiv260101] Enabling Physical AI at the Edge: Hardware-Accelerated Recovery of System Dynamics**
  - **tags:** [mlsys], [on-device ai], [FPGA acceleration, model recovery, hardware-software co-design, GRU, Neural ODE]
  - **authors:** Bin Xu, Ayan Banerjee, Sandeep Gupta
  - **institution:** Arizona State University
  - **link:** https://arxiv.org/pdf/2512.23767
  - **contributions:** 1. Proposed MERINDA, a hardware-friendly FPGA-accelerated framework for model recovery that replaces Neural ODEs with a formulation combining GRU-based discretized dynamics, dense inverse-ODE layers, sparsity-driven dropout, and lightweight solvers. 2. Designed the framework for streaming parallelism, enabling critical computational kernels to be fully parallelized on FPGA hardware. 3. Demonstrated transformative efficiency gains over GPU implementations, including 114x lower energy, 28x smaller memory footprint, and 1.68x faster training while maintaining state-of-the-art accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e286e0d5a9672c23140099a1b5fd5c7ad7e56f56cb1c276735170b95ad29fd47_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of deploying physical AI for model recovery on resource-constrained edge devices, where state-of-the-art methods using Neural ODEs are inefficient. The authors propose MERINDA, an FPGA-accelerated framework that uses a hardware-friendly architecture to replace expensive Neural ODE components. The results show that MERINDA achieves substantial improvements in energy, memory, and speed over GPU implementations while matching model recovery accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Enabling Physical AI at the Edge<br>在边缘实现物理人工智能] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Model recovery methods (Neural ODEs) are inefficient for edge hardware<br>模型恢复方法在边缘硬件上效率低下]
        C[主要方法/Method<br>MERINDA: FPGA-accelerated, hardware-friendly framework<br>MERINDA: FPGA加速的硬件友好框架]
        D[关键结果/Results<br>114x lower energy, 28x smaller memory, 1.68x faster training<br>能耗降低114倍, 内存占用减少28倍, 训练速度提升1.68倍]
    ```

- **[arXiv260101] Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations**
  - **tags:** [ai], [algorithmic fairness], [discrimination clustering, individual fairness, hybrid verification, SMT solver, MILP solver]
  - **authors:** Ranit Debnath Akash, Ashish Kumar, Verya Monjezi, Ashutosh Trivedi, Gang, Saeid Tizpaz-Niari
  - **institution:** University of Illinois Chicago, University of Colorado Boulder, Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2512.23769
  - **contributions:** 1. Introduced the concept of "discrimination clustering" as a generalization of individual fairness to uncover systematic bias patterns. 2. Proposed HyFair, a hybrid technique combining formal symbolic analysis (SMT/MILP) and randomized search for both certification and violation discovery. 3. Developed a novel explanation method to generate interpretable, decision-tree-style artifacts for inputs exhibiting high discrimination.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05da1223f6a1c9a93634f021d221ac5175d00dee272ded0b8782834941db9c55_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a limitation in individual fairness, which only detects isolated unfairness, and proposes the concept of "discrimination clustering" to uncover systematic bias patterns. It introduces HyFair, a hybrid method combining formal verification and randomized search to detect these clusters and generate explanations. Experiments show HyFair outperforms existing fairness verification and explanation methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Uncovering Discrimination Clusters") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("个体公平性检查的局限性/Limitations of individual fairness checks")
        P1 --> P2("无法捕捉系统性歧视模式/Fails to capture systematic bias patterns")
        Method --> M1("提出歧视聚类概念/Propose discrimination clustering concept")
        Method --> M2("开发HyFair混合技术/Develop HyFair hybrid technique")
        M2 --> M3("结合形式分析与随机搜索/Combine formal analysis & randomized search")
        Results --> R1("优于现有方法/Outperforms state-of-the-art methods")
        Results --> R2("揭示系统性偏差/Reveals substantial discrimination clustering")
        Results --> R3("提供可解释的说明/Provides intuitive explanations")
    ```

- **[arXiv260101] Safety-Biased Policy Optimisation: Towards Hard-Constrained Reinforcement Learning via Trust Regions**
  - **tags:** [ai], [safe reinforcement learning], [constrained MDP, trust region policy optimization, natural policy gradient, safety gymnasium, hard constraints]
  - **authors:** Ankit Kanwar, Dominik Wagner, Luke Ong
  - **institution:** Sony Corporation, Nanyang Technological University (NTU Singapore)
  - **link:** https://arxiv.org/pdf/2512.23770
  - **contributions:** 1. Proposes Safety-Biased Trust Region Policy Optimisation (SB-TRPO), a new algorithm for hard-constrained RL that adaptively biases policy updates towards safety while seeking reward improvement. 2. Introduces a trust-region update using a convex combination of the natural policy gradients of cost and reward to ensure a fixed fraction of optimal cost reduction per step. 3. Provides a theoretical guarantee of local progress towards safety and demonstrates superior balance of safety and task performance on Safety Gymnasium benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ea6c2a84f6cc7b4f3144847fc78a84736f7247b99f773ed23dd1861f2ff0760_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of reinforcement learning under hard safety constraints, where existing methods struggle to avoid violations without sacrificing reward. It proposes SB-TRPO, an algorithm that performs trust-region updates by combining reward and cost gradients to bias updates towards safety. Experiments show that SB-TRPO achieves a better balance of safety and task completion than state-of-the-art methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Safety-Biased Policy Optimisation] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: RL in safety-critical domains requires strict constraint adherence without sacrificing reward performance.]
        Method[主要方法/Method: SB-TRPO uses convex combination of natural policy gradients for cost and reward in trust-region updates.]
        Results[关键结果/Results: Achieves best balance of safety and task completion on Safety Gymnasium benchmarks.]
    ```

- **[arXiv260101] A Survey on Graph Neural Networks for Fraud Detection in Ride Hailing Platforms**
  - **tags:** [ai], [anomaly detection], [Graph Neural Networks (GNNs), Fraud Detection, Class Imbalance, Fraudulent Camouflage, Ride-Hailing Platforms]
  - **authors:** Kanishka Hewageegana, Janani Harischandra, Nipuna Senanayake, Gihan Danansuriya, Kavindu Hapuarachchi, Pooja Illangarathne
  - **institution:** Informatics Institute of Technology, Rajarata University, University of Sri Jayewardenepura
  - **link:** https://arxiv.org/pdf/2512.23777
  - **contributions:** 1. Provides a structured overview and comparison of existing Graph Neural Network (GNN) architectures and methodologies for fraud detection in ride-hailing platforms. 2. Highlights and analyzes key challenges in the domain, specifically class imbalance and fraudulent camouflage, within the ride-hailing ecosystem. 3. Identifies significant methodological progress and research gaps, calling for further exploration into real-world applicability and technical improvements.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65fc7f6ff0330c22a6dc35373a15256baac5eef984a9100cce967991d93a1e67_w640_q70.webp
  - **Simple LLM Summary:** This survey investigates the use of Graph Neural Networks (GNNs) for detecting fraud in ride-hailing platforms. It analyzes and compares various GNN models, focusing on their effectiveness in handling complex relational data and challenges like class imbalance. The paper concludes by identifying progress and gaps in the field, advocating for more research on real-world applications and technical enhancements.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Survey on Graph Neural Networks for Fraud Detection in Ride Hailing Platforms"] --> Problem["核心问题/Problem: Fraud detection in ride-hailing platforms"]
        Root --> Method["主要方法/Method: Survey and analysis of Graph Neural Networks (GNNs)"]
        Root --> Results["关键结果/Results: Identifies progress, gaps, and calls for future work"]
    ```

- **[arXiv260101] Prompt-Induced Over-Generation as Denial-of-Service: A Black-Box Attack-Side Benchmark**
  - **tags:** [sec], [adversarial attacks on llms], [denial-of-service, over-generation, black-box attack, evolutionary search, reinforcement learning]
  - **authors:** Manu, Yi Guo, Jo Plested, Tim Lynar, Kanchana Thilakarathna, Nirhoshan Sivaroopan, Jack Yang, Wangli Yang
  - **institution:** Western Sydney University, University of New South Wales Canberra, The University of Sydney, University of Wollongong
  - **link:** https://arxiv.org/pdf/2512.23779
  - **contributions:** 1. Introduces a black-box, query-only benchmark for evaluating prompt-induced denial-of-service attacks on LLMs. 2. Proposes two novel prompt-only attackers: an evolutionary search method (EOGen) and a goal-conditioned reinforcement learning method (RL-GOAL). 3. Defines the Over-Generation Factor (OGF) as a key metric to quantify attack success and characterize model vulnerability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3002b15ce3957d88befc241c59f1be73a9e49f4e8ad4c345e9d472f11883059e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of denial-of-service attacks on large language models via prompt-induced over-generation. It proposes a standardized black-box benchmark and two automated attack methods, EOGen and RL-GOAL, to find adversarial prefixes that delay model termination. The results show that the RL-GOAL attacker is particularly effective at forcing models to generate excessively long outputs, highlighting a significant vulnerability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Prompt-Induced Over-Generation as Denial-of-Service<br/>提示诱导过度生成作为拒绝服务攻击] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br/>LLM过度生成导致服务拒绝、延迟和成本增加]
        C[主要方法/Method<br/>黑盒基准与两种攻击者: EOGen(进化搜索)和RL-GOAL(强化学习)]
        D[关键结果/Results<br/>RL-GOAL攻击者实现更高的平均过度生成因子(OGF)]
    ```

- **[arXiv260101] FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading**
  - **tags:** [ai], [reinforcement learning], [ensemble reinforcement learning, selective update, variational autoencoder, high-frequency trading, risk management]
  - **authors:** Molei Qin, Xinyu Cai, Yewen Li, Haochong Xia, Chuqiao Zong, Shuo Sun, Xinrun Wang, Bo An
  - **institution:** Nanyang Technological University, Singapore Management University, Hong Kong University of Science and Technology (Guangzhou)
  - **link:** https://arxiv.org/pdf/2512.23773
  - **contributions:** 1. A selective update mechanism for ensemble Q-learners using ensemble TD errors to stabilize training and improve convergence in high-leverage environments. 2. A risk-aware filtering and routing mechanism that uses VAEs to model market state dynamics and identify agent capability boundaries, enabling dynamic policy selection to mitigate risk. 3. A novel three-stage ensemble RL framework (FineFT) that integrates stable training and risk management, demonstrating superior profitability and over 40% risk reduction in crypto futures trading.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c036ba975592c2c3be9068e742ccd28ed5b9722ff62085fbcc37e9f3627fe370_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes FineFT, a three-stage ensemble reinforcement learning framework designed to address the challenges of high leverage and unseen market states in futures trading. The method uses selective updates for stable training and VAEs for risk-aware policy routing, achieving higher profitability and significantly lower risk compared to state-of-the-art baselines in high-frequency crypto futures experiments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FineFT: Efficient and Risk-Aware Ensemble RL for Futures Trading] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[高杠杆放大波动/High leverage amplifies reward fluctuations]
        B --> B2[缺乏能力边界意识/Lack of self-awareness of capability boundaries]
        C --> C1[阶段I: 选择性更新/Stage I: Selective Update]
        C --> C2[阶段II: 过滤与VAE训练/Stage II: Filtering & VAE Training]
        C --> C3[阶段III: 动态路由/Stage III: Dynamic Routing]
        D --> D1[超越12个SOTA基线/Outperforms 12 SOTA baselines]
        D --> D2[风险降低超40%/Risk reduced by >40%]
        D --> D3[实现更高盈利/Achieves superior profitability]
    ```

- **[arXiv260101] TabMixNN: A Unified Deep Learning Framework for Structural Mixed Effects Modeling on Tabular Data**
  - **tags:** [ai], [statistical machine learning], [mixed-effects models, deep learning, tabular data, interpretability, structural equation models]
  - **authors:** Deniz Akdemir
  - **institution:** Not specified in provided content (email domain is gmail)
  - **link:** https://arxiv.org/pdf/2512.23787
  - **contributions:** 1. A modular three-stage deep learning framework (mixed-effects encoder, backbone architectures, outcome heads) that synthesizes classical mixed-effects modeling with neural networks for tabular data. 2. Key innovations including an R-style formula interface, support for DAG constraints for causal learning, SPDE kernels for spatial modeling, and comprehensive interpretability tools. 3. A unified interface that maintains the interpretability and theoretical grounding of classical models while leveraging the representational power of deep learning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1e0b6c8d4704d8d650a7573d4312c5032944f0b87d311b6d8a7f5554e250498_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces TabMixNN, a PyTorch-based deep learning framework designed to handle hierarchical tabular data by combining classical mixed-effects models with neural network architectures. It supports diverse tasks like regression and classification through a modular design and emphasizes interpretability. The framework provides a unified tool for complex data analysis while preserving the strengths of traditional statistical models.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[TabMixNN: 统一深度学习框架 / Unified Deep Learning Framework] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[层次表格数据 / Hierarchical Tabular Data]
        Problem --> P2[传统方法限制 / Limitations of Classical Methods]
        Method --> M1[混合效应编码器 / Mixed-Effects Encoder]
        Method --> M2[骨干架构 / Backbone Architectures]
        Method --> M3[预测头 / Prediction Heads]
        Results --> R1[灵活性应用 / Flexible Applications]
        Results --> R2[可解释性工具 / Interpretability Tools]
    ```

- **[arXiv260101] Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems**
  - **tags:** [mlsys], [federated learning], [Zero-Trust Architecture, SHAP-weighted aggregation, TPM-based attestation]
  - **authors:** Samaresh Kumar Singh, Joyjit Roy, Martin So
  - **institution:** Independent Researchers (based on provided affiliations: IEEE Senior Member in Texas, IEEE Member in Texas, Independent Researcher in Canada)
  - **link:** https://arxiv.org/pdf/2512.23809
  - **contributions:** 1) Proposed a hierarchical edge-fog-cloud zero-trust federated learning architecture for trusted agent participation. 2) Introduced a novel SHAP-weighted aggregation algorithm for explainable Byzantine detection in non-IID environments. 3) Integrated TPM-based cryptographic attestation and on-device adversarial training into a defense-in-depth framework.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/baa785fc442fcbc6a80214c4fdc6361e67a8e34e5a9bb6f5dd8fb34baf21bb68_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses security vulnerabilities in Federated Learning for Industrial IoT by proposing ZTA-FL, a framework combining zero-trust agent authentication, explainable Byzantine-resilient aggregation, and on-device adversarial training. It demonstrates high detection accuracy and robustness against attacks on intrusion detection benchmarks while reducing communication overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: IIoT安全漏洞与联邦学习攻击 / IIoT Security Gaps & FL Attacks]
        Method[主要方法/Method: 零信任认证与可解释聚合 / Zero-Trust Attestation & Explainable Aggregation]
        Results[关键结果/Results: 高检测精度与抗攻击鲁棒性 / High Detection Accuracy & Attack Robustness]
    ```

- **[arXiv260101] Improved Bounds for Private and Robust Alignment**
  - **tags:** [ai], [preference learning], [private alignment, robust alignment, uniform convergence, log loss, adversarial corruption]
  - **authors:** Wenqian Weng, Yi He, Xingyu Zhou
  - **institution:** Wayne State University
  - **link:** https://arxiv.org/pdf/2512.23816
  - **contributions:** 1. Showed that standard private MLE-type log loss can achieve near-optimal rates for private alignment, contrary to prior belief. 2. Demonstrated that existing offline algorithms for joint privacy-and-corruption provide stronger guarantees than previously known, leading to improved bounds for corruption-only settings. 3. Presented the first set of theoretical results for private and robust online alignment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07d766123762454b64f45852c98c882b263a3fe86efdee6b0c39b70b0d888215_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the theoretical alignment of language models under privacy constraints and adversarial corruption. It shows that a standard MLE-style log loss can achieve near-optimal rates for private alignment and provides improved bounds for joint private-and-robust settings, including the first online results, enabled by new uniform convergence guarantees.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Improved Bounds for Private and Robust Alignment] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[语言模型对齐/Language Model Alignment]
        B --> B2[隐私与噪声标签/Private & Noisy Labels]
        C --> C1[理论分析/Theoretical Analysis]
        C --> C2[统一收敛/Uniform Convergence]
        D --> D1[私有MLE达到最优/Private MLE Near-Optimal]
        D --> D2[离线和在线改进界限/Improved Offline & Online Bounds]
    ```

- **[arXiv260101] MS-SSM: A Multi-Scale State Space Model for Efficient Sequence Modeling**
  - **tags:** [ai], [sequence modeling], [state-space models, multi-scale dependencies, linear recurrences, long-range modeling, hierarchical tasks]
  - **authors:** Mahdi Karami, Ali Behrouz, Peilin Zhong, Razvan Pascanu, Vahab Mirrokni
  - **institution:** Google Research, Google DeepMind
  - **link:** https://arxiv.org/pdf/2512.23824
  - **contributions:** 1. Introduced a multi-scale SSM framework that processes sequence dynamics across multiple resolutions with specialized state-space dynamics. 2. Proposed an input-dependent scale-mixer for dynamic information fusion across different resolutions. 3. Demonstrated consistent performance improvements over prior SSM-based models on benchmarks including Long Range Arena, hierarchical reasoning, time series classification, and image recognition.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b8a72c3eef1e96a4a3f749cd5d5056117d6d9f67369231cfaf5ce87b8f9bd943_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes MS-SSM, a multi-scale state-space model that captures both fine-grained and coarse patterns in sequences to address the limited memory and multi-scale dependency issues of traditional SSMs. It introduces specialized dynamics per resolution and a dynamic scale-mixer, leading to enhanced memory efficiency and long-range modeling. Experiments show it outperforms prior SSM models across various tasks while maintaining computational efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MS-SSM: A Multi-Scale State Space Model for Efficient Sequence Modeling] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统SSMs有效记忆有限/Traditional SSMs have limited effective memory]
        B --> B2[现有SSMs难以捕捉多尺度依赖/Existing SSMs struggle to capture multi-scale dependencies]
        C --> C1[多分辨率状态空间框架/Multi-resolution state-space framework]
        C --> C2[输入依赖的尺度混合器/Input-dependent scale-mixer]
        D --> D1[提升记忆效率和长程建模/Enhances memory efficiency and long-range modeling]
        D --> D2[在多个基准测试中优于先前模型/Outperforms prior SSM-based models on benchmarks]
    ```

- **[arXiv260101] Deep learning methods for inverse problems using connections between proximal operators and Hamilton-Jacobi equations**
  - **tags:** [ai], [inverse problems], [proximal operators, Hamilton-Jacobi equations, deep learning architectures, prior learning, nonconvex priors]
  - **authors:** Oluwatosin Akande, Gabriel P. Langlois, Akwum Onwunta
  - **institution:** Lehigh University, University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2512.23829
  - **contributions:** 1. Proposes leveraging connections between proximal operators and Hamilton-Jacobi PDEs to develop novel deep learning architectures for learning priors in inverse problems. 2. Introduces a method to learn the prior directly without needing to invert it after training. 3. Demonstrates the efficiency of the proposed method through numerical results in high-dimensional settings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0a12124651668ce14c5fbfa24bee53d6d2566efb05706aeb5d6359b3d85bff6_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of solving ill-posed inverse problems by developing a novel deep learning approach that leverages the connection between proximal operators and Hamilton-Jacobi PDEs to directly learn the prior. The method avoids the need to invert the prior after training and is shown to be efficient in high-dimensional scenarios through numerical experiments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deep learning methods for inverse problems using connections between proximal operators and Hamilton-Jacobi equations] --> B(核心问题/Problem: 从噪声数据中恢复模型参数，逆问题通常不适定，需要正则化或先验信息)
        A --> C(主要方法/Method: 利用近端算子与Hamilton-Jacobi PDE之间的联系，开发新颖的深度学习架构来直接学习先验)
        A --> D(关键结果/Results: 所提方法在无需训练后反演先验的情况下，在高维问题中展现出高效性)
    ```

- **[arXiv260101] Exploiting the Prior of Generative Time Series Imputation**
  - **tags:** [ai], [time series imputation], [Schrodinger Bridge, generative model, diffusion model, expert prior, compositional priors]
  - **authors:** YuYang Miao, Chang Li, Zehua Chen
  - **institution:** Imperial College London, University of Science and Technology of China, Tsinghua University, Shengshu AI
  - **link:** https://arxiv.org/pdf/2512.23832
  - **contributions:** 1. Proposes Bridge-TS, a novel generative time series imputation method that builds a data-to-data generation process. 2. Introduces the concept of an "expert prior", using a pretrained transformer to provide a deterministic, informative starting point for the generation process. 3. Explores "compositional priors", combining estimations from multiple pretrained models to further enhance the imputation process.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e54cafc350b1a81442b6b33a9d58319eeae7b34b2cbcfba860bed3f8138ed8af_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of limited accuracy in generative time series imputation methods, which stems from using uninformative priors like Gaussian noise. It proposes Bridge-TS, a method that uses informative priors from pretrained models to guide a data-to-data generation process. Experiments show Bridge-TS achieves state-of-the-art imputation accuracy on benchmark datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Bridge-TS: Exploiting the Prior of Generative Time Series Imputation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[生成式时间序列插值中先验信息不充分/Uninformative prior in generative time series imputation]
        C --> C1[提出Bridge-TS方法/Propose Bridge-TS method]
        C1 --> C2[专家先验/Expert Prior]
        C1 --> C3[组合先验/Compositional Priors]
        D --> D1[在ETT等数据集上取得SOTA精度/Achieves SOTA accuracy on ETT, etc.]
    ```

- **[arXiv260101] Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation**
  - **tags:** [nlp], [adversarial robustness], [mechanistic interpretability, attention layers, adversarial examples, LLM evaluation, token substitution]
  - **authors:** Kaustubh Dhole
  - **institution:** Emory University
  - **link:** https://arxiv.org/pdf/2512.23837
  - **contributions:** 1. Proposes a novel adversarial example generation method that exploits intermediate attention layer token distributions, contrasting with prompt-based or gradient-based attacks. 2. Introduces two specific attention-based generation techniques: attention-based token substitution and attention-based conditional generation. 3. Empirically demonstrates that such adversarial examples can degrade performance on an evaluation task (argument quality assessment) while maintaining semantic similarity, highlighting both the promise and limitations (e.g., grammatical degradation) of the approach.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85f39e8eb9d1e9534ca2c7e95f4e08380c10c2d3b58ec0a3a896f0767b75fdd8_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new method to generate adversarial examples by extracting token predictions from the intermediate attention layers of LLMs, leveraging their iterative refinement property. The approach is used to stress-test LLM-based evaluation pipelines, showing it can cause performance drops on an argument quality task while preserving semantics, though grammatical issues can arise. The findings illustrate the potential and current constraints of using internal model representations for adversarial testing.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Can intermediate attention layers be used to generate adversarial examples for LLM evaluation?]
        Method[主要方法/Method: Leverage attention-layer token distributions for token substitution/conditional generation]
        Results[关键结果/Results: Adversarial examples cause performance drop but may introduce grammatical issues]
    ```

- **[arXiv260101] Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [adaptive prompting, context window, open-domain QA, retrieval-augmented generation, LLM ignorance]
  - **authors:** Dingmin Wang, Ji Ma, Shankar Kumar
  - **institution:** Google Research, University of Oxford
  - **link:** https://arxiv.org/pdf/2512.23836
  - **contributions:** 1. Proposes an adaptive prompting strategy for RAG that splits retrieved information into smaller chunks for sequential processing, mitigating the noise from irrelevant information in long contexts. 2. Demonstrates experimentally that this strategy matches or outperforms standard prompting on open-domain QA datasets while using fewer tokens. 3. Identifies and analyzes a key failure mode where LLMs generate incorrect answers instead of declining when information is insufficient, highlighting a critical area for future research.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58d02669f63e2ba5d0171fc84f89e87cc22d595344fc20e61769b4288b009ef5_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem that longer context windows in Retrieval-Augmented Generation (RAG) introduce irrelevant information, degrading LLM performance. It proposes an adaptive prompting strategy that processes retrieved text in smaller, sequential chunks, achieving comparable accuracy with lower token usage. The study concludes that a major source of error is the LLM's tendency to generate wrong answers rather than admit ignorance, pointing to the need for improved refusal capabilities.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[长上下文引入无关信息，降低LLM性能/Long contexts introduce irrelevant info, degrading LLM performance]
        C --> C1[自适应提示策略：分块顺序处理/Adaptive prompting: sequential chunk processing]
        D --> D1[性能相当，使用更少token/Matches performance, uses fewer tokens]
        D --> D2[LLM常生成错误答案而非拒绝/LLM often generates wrong answers instead of declining]
    ```

- **[arXiv260101] Integrating Domain Knowledge for Financial QA: A Multi-Retriever RAG Approach with LLMs**
  - **tags:** [nlp], [question answering], [Retrieval-Augmented Generation (RAG), SecBERT, financial numerical reasoning, multi-retriever, few-shot learning]
  - **authors:** Yukun Zhang, Stefan Elbl Droguett, Samyak Jain
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2512.23848
  - **contributions:** 1. Proposed a multi-retriever RAG system that retrieves both external domain knowledge (e.g., financial definitions) and internal question contexts to improve financial QA. 2. Demonstrated that domain-specific training with the SecBERT encoder significantly boosts performance, allowing a neural symbolic model to surpass a strong baseline. 3. Showed that a prompt-based LLM generator achieves state-of-the-art performance with a &gt;7% improvement, highlighting the enhanced few-shot numerical reasoning of latest LLMs and the trade-off between hallucination and external knowledge gains.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de021f75daa09442db831a9d2d84064bf5381a47f4cb0fc792e2cfd3bfbd128b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses errors in financial numerical QA by proposing a multi-retriever RAG system that retrieves external financial knowledge and internal context. The best model, using domain-specific training and a prompt-based LLM, achieves state-of-the-art results, though still below human expert performance, and reveals a trade-off between hallucination and knowledge gains.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Integrating Domain Knowledge for Financial QA<br>金融QA领域知识集成] --> B[Problem: Errors in financial numerical QA due to lack of domain knowledge<br>核心问题: 金融数值QA因缺乏领域知识出错]
        A --> C[Method: Multi-retriever RAG system with external/internal retrieval<br>主要方法: 多检索器RAG系统]
        A --> D[Results: SOTA performance, domain-specific training effective, trade-off analyzed<br>关键结果: SOTA性能, 领域训练有效, 权衡分析]
    ```

- **[arXiv260101] Flow Matching Neural Processes**
  - **tags:** [ai], [generative models], [neural processes, flow matching, ODE solver, conditional sampling, stochastic processes]
  - **authors:** Hussen Abu Hamad, Dan Rosenbaum
  - **institution:** University of Haifa
  - **link:** https://arxiv.org/pdf/2512.23853
  - **contributions:** 1. Proposes a new Neural Process model based on the flow matching generative modeling paradigm. 2. Enables sampling from conditional distributions using an ODE solver without auxiliary conditioning methods. 3. Provides a controllable trade-off between accuracy and computational cost via the ODE solver steps.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c876d5d150fc117d2b987aac4cc9a3bf9b34f3e670cf528e12b73266c4f2dab4_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Flow Matching Neural Processes, a new model that integrates flow matching into the neural process framework for learning stochastic processes. The method allows for efficient and simple conditional sampling using an ODE solver. The authors demonstrate that their model outperforms previous state-of-the-art neural process methods on several benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Flow Matching Neural Processes] --> B(核心问题/Problem: Learning stochastic processes for conditional predictions)
        A --> C(主要方法/Method: Integrate flow matching with neural processes, use ODE solver for sampling)
        A --> D(关键结果/Results: Outperforms SOTA on 1D GP, 2D images, weather data)
    ```

- **[arXiv260101] The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models**
  - **tags:** [nlp], [language model evaluation], [epistemic robustness, semantic compression, adversarial fabrication, two-system cognitive model, comprehension integrity]
  - **authors:** Rahul Baxi
  - **institution:** Independent Researcher (affiliation inferred from email domain: alumni.cmu.edu, Carnegie Mellon University)
  - **link:** https://arxiv.org/pdf/2512.23850
  - **contributions:** 1. Introduces the Drill-Down and Fabricate Test (DDFT), a novel protocol for measuring epistemic robustness in language models under stress from semantic compression and adversarial fabrication. 2. Proposes a two-system cognitive model (Semantic System and Epistemic Verifier) to explain and analyze LLM behavior. 3. Provides empirical evidence that epistemic robustness is orthogonal to model scale and architecture, identifying error detection as the critical bottleneck.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c853b521a9f8bb0173c42ffdb79e01c42db6066203b6aa0c5e838c2f6a78f18f_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a gap in current language model evaluations, which fail to measure how robustly models maintain factual knowledge under stress. It introduces the Drill-Down and Fabricate Test (DDFT) to measure epistemic robustness by applying semantic compression and adversarial fabrication. The key finding is that epistemic robustness is not predicted by model size or architecture but by a model's internal verification mechanisms, challenging assumptions about scaling and reliability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Drill-Down and Fabricate Test (DDFT)] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有评估无法衡量知识鲁棒性/Current evaluations fail to measure knowledge robustness]
        C --> C1[DDFT协议: 语义压缩与对抗伪造/DDFT Protocol: Semantic Compression & Adversarial Fabrication]
        C --> C2[双系统认知模型/Two-System Cognitive Model]
        D --> D1[鲁棒性与模型规模/架构无关/Robustness orthogonal to model size/architecture]
        D --> D2[错误检测能力是关键瓶颈/Error detection is the critical bottleneck]
    ```

- **[arXiv260101] Trellis: Learning to Compress Key-Value Memory in Attention Models**
  - **tags:** [mlsys], [llm inference], [KV cache compression, bounded memory, online gradient descent, recurrent compression, long-context]
  - **authors:** Mahdi Karami, Ali Behrouz, Praneeth Kacham, Vahab Mirrokni
  - **institution:** Google Research
  - **link:** https://arxiv.org/pdf/2512.23852
  - **contributions:** 1. Introduces Trellis, a novel Transformer architecture that replaces the standard unbounded KV cache with a fixed-size memory, enabling bounded memory usage. 2. Proposes a trainable two-pass recurrent compression mechanism that dynamically compresses new key-value pairs into the fixed memory at test time. 3. Leverages an online gradient descent procedure with a forget gate to recursively update the compressed memory, learning to retain important contextual information from long sequences.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/889c9150f49160406df5713209e4165753466bc69bac6ffa78b28c214caa5c7d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the quadratic complexity and unbounded memory growth of the KV cache in Transformers by proposing Trellis, an architecture with a fixed-size memory and a learned recurrent compression mechanism. The method uses online gradient descent with a forget gate to dynamically update the compressed memory during inference. Experiments show Trellis outperforms baselines, with increasing gains on longer sequences, demonstrating its potential for efficient long-context modeling.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Trellis: Learning to Compress Key-Value Memory"] --> Problem["核心问题/Problem: Transformer KV cache leads to quadratic complexity and unbounded memory"]
        Root --> Method["主要方法/Method: Fixed-size memory + Two-pass recurrent compression with online gradient descent & forget gate"]
        Root --> Results["关键结果/Results: Outperforms baselines; Gains increase with sequence length for long-context"]
    ```

- **[arXiv260101] Yggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding**
  - **tags:** [mlsys], [llm inference], [speculative decoding, tree-based decoding, latency optimization, compiler-friendly execution, static runtime]
  - **authors:** Yue Guan, Changming Yu, Shihan Fang, Weiming Hu, Zaifeng Pan, Zheng Wang, Zihan Liu, Yangjie Zhou, Yufei Ding, Minyi Guo, Jingwen Leng
  - **institution:** Shanghai Jiao Tong University, Shanghai Qizhi Institute, University of California, San Diego
  - **link:** https://arxiv.org/pdf/2512.23858
  - **contributions:** 1. Introduces an equal-growth tree structure for speculative decoding that is compatible with static graph compilers. 2. Proposes a latency-aware optimization objective for draft selection, moving beyond simple average accepted length. 3. Designs a stage-based scheduling mechanism to reduce runtime overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13cf851f76b89c86dd0ecc981628839d1ca0ba1772a6b9b893ec9677720b6be0_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a performance mismatch between dynamic speculative decoding algorithms and static runtime systems. It proposes Yggdrasil, a co-designed system that uses a context-aware tree drafting structure and compiler-friendly execution to achieve latency-optimal speculative decoding. The system supports unmodified LLMs and achieves up to 3.98x speedup over state-of-the-art baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Yggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding] --> B[核心问题/Problem: Mismatch between dynamic speculation and static runtime assumptions leads to suboptimal performance]
        A --> C[主要方法/Method: Co-designed system with context-aware tree drafting and compiler-friendly execution]
        A --> D[关键结果/Results: Up to 3.98x speedup over SOTA baselines, supports unmodified LLMs]
    ```

- **[arXiv260101] Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense**
  - **tags:** [sec], [IoT Security], [Economic Denial Security, Stackelberg Game, Cost Asymmetry, Computational Puzzles]
  - **authors:** Samaresh Kumar Singh, Joyjit Roy
  - **institution:** IEEE (Inferred from author affiliations as IEEE members; specific institutional affiliation not provided in the excerpt)
  - **link:** https://arxiv.org/pdf/2512.23849
  - **contributions:** 1. Proposed the Economic Denial Security (EDS) framework, a detection-independent defense that exploits the defender's environmental control to impose economic infeasibility on attackers., 2. Formally modeled EDS as a Stackelberg game, deriving optimal parameters and proving that the composition of its four mechanisms yields superlinear (2.1x) cost amplification., 3. Demonstrated practical efficacy with a lightweight (&lt;12KB) implementation, validated on a 20-device IoT testbed and against IoT-23 malware, showing significant attack slowdown, cost asymmetry, and improved mitigation rates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53020dd5fb969c1980dd7f764afe5f97440c1ef68620bdcd3383e97bf39600fc_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the failure of detection-based security in resource-constrained IoT/edge environments. It proposes Economic Denial Security (EDS), a framework that uses mechanisms like computational puzzles and bandwidth taxation to make attacks economically infeasible by amplifying attacker costs. The method is proven to be lightweight, effective in significantly slowing attacks and reducing success rates, and provides a detection-independent layer of defense.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[检测安全在资源受限的IoT/边缘环境中失效/Detection-based security fails in resource-constrained IoT/edge]
        C --> C1[经济拒绝安全框架 / Economic Denial Security (EDS) Framework]
        C1 --> C2[四种机制组合 / Four Mechanism Composition]
        C2 --> C3[计算谜题 / Computational Puzzles]
        C2 --> C4[交互熵 / Interaction Entropy]
        C2 --> C5[时间拉伸 / Temporal Stretching]
        C2 --> C6[带宽征税 / Bandwidth Taxation]
        C --> C7[斯塔克尔伯格博弈建模 / Stackelberg Game Modeling]
        D --> D1[32-560倍攻击减速 / 32-560x Attack Slowdown]
        D --> D2[85-520:1 成本不对称 / 85-520:1 Cost Asymmetry]
        D --> D3[内存占用<12KB / <12KB Memory Footprint]
        D --> D4[94% 恶意软件缓解 / 94% Malware Mitigation]
    ```

- **[arXiv260101] Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining**
  - **tags:** [mlsys], [llm training], [Infini-attention, compressive memory, small language models (SLMs), long-context extrapolation, pretraining]
  - **authors:** Ruizhe Huang, Kexuan Zhang, Yihao Fang, Baifeng Yu
  - **institution:** Huawei Technologies Canada Co., Ltd.
  - **link:** https://arxiv.org/pdf/2512.23862
  - **code:** https://github.com/RRaAy-H/nanotron-infini
  - **contributions:** 1. Replaced standard attention in a 300M-parameter LLaMA model with Infini-attention to study compressive memory behavior under short-sequence pretraining. 2. Analyzed the training dynamics of SLMs with Infini-attention, revealing characteristics like loss fluctuations, gradient volatility, and early-layer memory concentration. 3. Demonstrated that Infini-attention improves long-context extrapolation over a baseline model, with supervised fine-tuning further boosting performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af598a1dcd8b2b6a3dec75fe7434942b519517dea235cfb006c3cf73881444fd_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether the Infini-attention mechanism, which combines local attention with compressive memory, can enhance long-context capabilities in Small Language Models (SLMs) during small-scale pretraining. The authors empirically study a 300M-parameter LLaMA model equipped with Infini-attention and find it improves long-context retrieval accuracy over a baseline, despite some degradation over very long sequences. The conclusion is that architectural memory like Infini-attention is beneficial for achieving robust long-context performance in SLMs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Enhancing long-context extrapolation for Small Language Models (SLMs)]
        C[主要方法/Method: Using Infini-attention (compressive memory + local attention) in small-scale pretraining]
        D[关键结果/Results: Improves long-context retrieval; Identifies balance factor importance; Shows performance degradation over very long sequences but still outperforms baseline]
    ```

- **[arXiv260101] Lifelong Domain Adaptive 3D Human Pose Estimation**
  - **tags:** [cv], [human pose estimation], [lifelong domain adaptation, catastrophic forgetting, generative adversarial network, pose-aware knowledge, temporal-aware knowledge]
  - **authors:** Qucheng Peng, Hongfei Xue, Pu Wang, Chen Chen
  - **institution:** University of Central Florida, University of North Carolina at Charlotte
  - **link:** https://arxiv.org/pdf/2512.23860
  - **contributions:** 1. Proposes a novel lifelong domain adaptation task for 3D Human Pose Estimation, addressing the challenge of non-stationary target pose datasets. 2. Introduces an innovative GAN framework with 3D pose generators, a 2D pose discriminator, and a 3D pose estimator to mitigate domain shifts and align poses. 3. Constructs a novel 3D pose generator paradigm that integrates pose-aware, temporal-aware, and domain-aware knowledge to enhance adaptation and alleviate catastrophic forgetting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbe905e18ac9835b4aae0dbb155169c447150fbd0e28ac454c7cc8a56bb7251e_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a lifelong domain adaptation framework for 3D human pose estimation to handle non-stationary target data distributions. The method uses a novel GAN-based framework with a knowledge-integrated 3D pose generator to adapt to new domains while preventing catastrophic forgetting of previous ones. Experiments show the approach achieves superior performance on diverse domain adaptive 3D HPE datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Lifelong Domain Adaptive 3D Human Pose Estimation] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[3D HPE泛化挑战/3D HPE Generalization Challenge]
    B --> B2[非平稳目标域/Non-stationary Target Domains]
    B --> B3[灾难性遗忘/Catastrophic Forgetting]
    C --> C1[终身域适应任务/Lifelong DA Task]
    C --> C2[GAN框架/GAN Framework]
    C --> C3[3D姿态生成器/3D Pose Generator]
    C2 --> C2a[3D姿态生成器/3D Pose Generators]
    C2 --> C2b[2D姿态判别器/2D Pose Discriminator]
    C2 --> C2c[3D姿态估计器/3D Pose Estimator]
    C3 --> C3a[姿态感知/Pose-aware]
    C3 --> C3b[时序感知/Temporal-aware]
    C3 --> C3c[域感知/Domain-aware]
    D --> D1[缓解域偏移/Mitigates Domain Shifts]
    D --> D2[对齐姿态/Aligns Poses]
    D --> D3[卓越性能/Superior Performance]
    ```

- **[arXiv260101] Max-Entropy Reinforcement Learning with Flow Matching and A Case Study on LQR**
  - **tags:** [ai], [reinforcement learning], [max-entropy reinforcement learning, flow-based policy, flow matching, soft actor-critic, linear quadratic regulator]
  - **authors:** Yuyang Zhang, Yang Hu, Bo Dai, Na Li
  - **institution:** Harvard University, Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.23870
  - **contributions:** 1. Proposes a variant of the Soft Actor-Critic (SAC) algorithm that uses flow-based models to parameterize the policy, enhancing expressiveness. 2. Introduces an online variant of flow matching called Importance Sampling Flow Matching (ISFM) for policy updates using samples from a user-specified distribution instead of the unknown target. 3. Provides a theoretical analysis of ISFM, characterizing how the choice of sampling distribution impacts learning efficiency, and validates the method with a case study on max-entropy Linear Quadratic Regulator (LQR) problems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d43d8f718c30e1679c2274346eea229b95864ab6207cedce0e09dc784832028_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of simple policy approximations in max-entropy reinforcement learning by proposing a new SAC variant that uses expressive flow-based policies. The method employs a novel online flow matching technique (ISFM) for efficient policy updates and demonstrates its effectiveness by learning the optimal action distribution in max-entropy LQR problems.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Max-Entropy RL with Flow Matching and LQR Case Study] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[SAC使用简单策略类牺牲了表达性和鲁棒性/SAC's simple policy classes sacrifice expressiveness & robustness]
        Method[主要方法/Method] --> M1[提出使用流模型参数化策略的SAC变体/Propose SAC variant with flow-based policy]
        Method --> M2[开发在线流匹配变体ISFM进行策略更新/Develop online flow matching variant ISFM for policy update]
        Results[关键结果/Results] --> R1[理论分析ISFM采样分布的影响/Theoretical analysis of ISFM sampling distribution impact]
        Results --> R2[在最大熵LQR问题上验证算法有效性/Validate algorithm on max-entropy LQR problems]
    ```

- **[arXiv260101] Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City**
  - **tags:** [ai], [time series forecasting], [Transformer, Mamba, Knowledge Distillation]
  - **authors:** Tin Hoang
  - **institution:** University of Surrey
  - **link:** https://arxiv.org/pdf/2512.23898
  - **code:** github.com/Tin-Hoang/solar-timeseries-forecasting
  - **contributions:** 1. Conducted a comprehensive benchmark of ten deep learning architectures for short-term solar irradiance forecasting, identifying the Transformer as the best-performing model. 2. Used SHAP analysis to reveal and contrast the distinct temporal reasoning patterns of different architectures (e.g., Transformer's recency bias vs. Mamba's periodic dependency). 3. Demonstrated that Knowledge Distillation can effectively compress the high-performance Transformer model, reducing its size by 23.5% while improving accuracy for edge deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8685dbd2386bb45fd799c168962048f6a243c0b8c836a5be5978ff64d0c2e184_w640_q70.webp
  - **Simple LLM Summary:** This paper benchmarks ten deep learning models for 1-hour ahead solar irradiance forecasting in Ho Chi Minh City. The Transformer model achieved the highest accuracy, and the study used explainable AI to analyze model behavior and successfully compressed the model via Knowledge Distillation for efficient edge deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题 / Paper Title: Efficient Deep Learning for Short-Term Solar Irradiance Forecasting] --> B
        A --> C
        A --> D
        B[核心问题 / Problem: 预测全球水平辐照度(GHI)以缓解太阳能波动 / Forecasting GHI to mitigate solar energy variability]
        C[主要方法 / Method: 对十种深度学习架构进行基准测试与可解释性分析 / Benchmarking 10 DL architectures with explainability analysis]
        D[关键结果 / Results: Transformer性能最优；知识蒸馏实现高效压缩 / Transformer best; Knowledge Distillation enables efficient compression]
    ```

- **[arXiv260101] Rethinking Dense Linear Transformations: Stagewise Pairwise Mixing (SPM) for Near-Linear Training in Neural Networks**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [Stagewise Pairwise Mixers, dense linear layers, near-linear complexity, compositional inductive bias, drop-in replacement]
  - **authors:** Peter Farag
  - **institution:** SP Cloud & Technologies Inc.
  - **link:** https://arxiv.org/pdf/2512.23905
  - **contributions:** 1. Proposes Stagewise Pairwise Mixers (SPM), a structured linear operator that replaces dense matrices with a composition of sparse pairwise-mixing stages, achieving near-linear time and parameter complexity. 2. Derives complete forward and backward expressions for two parameterizations: an orthogonal norm-preserving rotation-based variant and a fully general 2×2 mixing variant. 3. Demonstrates that SPM reduces wall-clock cost and improves accuracy on structured learning problems while maintaining competitive performance on real-world benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6296322c9e11128e2315b979afc9e75bc26d003cffef0deb0d439140a648751a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high computational and parametric cost of dense linear layers in neural networks by introducing Stagewise Pairwise Mixers (SPM), a structured operator that composes sparse pairwise-mixing stages to achieve near-linear complexity. SPM serves as a drop-in replacement for dense layers, offering exact closed-form computations and an explicit compositional inductive bias. Proof-of-concept experiments show substantial reductions in training cost and improved generalization on structured tasks while retaining competitive performance on benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Rethinking Dense Linear Transformations: Stagewise Pairwise Mixing (SPM) for Near-Linear Training in Neural Networks] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[密集线性层计算和参数成本高/Dense linear layers are computationally and parametrically expensive]
        B --> B2[与表示结构不匹配/Misaligned with compositional structure of representations]
        C --> C1[引入SPM算子/Introduce Stagewise Pairwise Mixers (SPM)]
        C --> C2[稀疏成对混合阶段组成/Composition of sparse pairwise-mixing stages]
        C --> C3[近线性复杂度/Near-linear time and parameter complexity]
        D --> D1[降低训练成本/Reduces wall-clock cost]
        D --> D2[提升结构化任务准确率/Improves accuracy on structured problems]
        D --> D3[保持基准性能/Retains competitive benchmark performance]
    ```

- **[arXiv260101] Constraint Breeds Generalization: Temporal Dynamics as an Inductive Bias**
  - **tags:** [ai], [neuromorphic computing], [temporal inductive bias, dissipative dynamics, spiking neural networks, generalization, phase-space analysis]
  - **authors:** Xia Chen
  - **institution:** Technische Universität München (Georg Nemetschek Institute, Munich Data Science Institute)
  - **link:** https://arxiv.org/pdf/2512.23916
  - **contributions:** 1. Proposes that physical constraints (like metabolic budgets) act not as limitations but as a temporal inductive bias that promotes generalization in neural systems. 2. Reveals through phase-space analysis that proper dissipative dynamics compress the solution space and align with spectral bias to abstract invariant features, unlike expansive dynamics. 3. Empirically demonstrates across multiple tasks (classification, reconstruction, RL) that a critical "transition" regime of dynamical constraints maximizes generalization capability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b28592acb015fa66de83fc46eda200fa0018a58a31fbfacdf9dd0fced988bac9_w640_q70.webp
  - **Simple LLM Summary:** The paper argues that physical constraints, often seen as limitations, can serve as a beneficial temporal inductive bias for generalization in neural networks. It analyzes signal propagation to show that dissipative dynamics compress phase space and abstract features, a principle implemented using Spiking Neural Networks. Experiments across various tasks confirm that properly constrained temporal dynamics maximize generalization, suggesting a new direction for robust AI development.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["Constraint Breeds Generalization: Temporal Dynamics as an Inductive Bias"] --> B["核心问题/Problem: Conventional deep learning uses unconstrained optimization, unlike biologically constrained systems."]
        A --> C["主要方法/Method: Propose temporal constraints as inductive bias; analyze phase-space dynamics; use Spiking Neural Networks (SNNs) for temporal integration."]
        A --> D["关键结果/Results: Dissipative dynamics maximize generalization; a critical 'transition' regime is identified across tasks."]
    ```

- **[arXiv260101] Interactive Machine Learning: From Theory to Scale**
  - **tags:** [ai], [interactive machine learning], [active learning, contextual bandits, model selection, sequential decision making, partial feedback]
  - **authors:** Yinglun Zhu
  - **institution:** University of Wisconsin–Madison
  - **link:** https://arxiv.org/pdf/2512.23924
  - **contributions:** 1. Developed computationally efficient active learning algorithms that achieve exponential label savings without requiring low-noise assumptions., 2. Introduced the first efficient, general-purpose contextual bandit algorithms whose performance guarantees are independent of the action space size., 3. Provided the first tight characterizations of the fundamental cost of model selection in sequential decision-making settings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d3c8fc2dd2145126e7321fa8de265f0c2652dbd2dc7df8c387585634498e335_w640_q70.webp
  - **Simple LLM Summary:** This dissertation addresses the high cost of data labeling and trial-and-error in machine learning by developing new algorithms for interactive learning. It proposes statistically optimal and computationally efficient methods for active learning, contextual bandits with large action spaces, and model selection under partial feedback. The work advances the theoretical foundations of interactive learning and provides guidance for its deployment in large-scale, real-world applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Interactive Machine Learning: From Theory to Scale<br>交互式机器学习：从理论到规模")
        Root --> Problem("Problem: High cost of labeled data & trial-and-error in ML<br>核心问题：机器学习中标注数据和试错的高成本")
        Root --> Method("Method: Develop algorithms for interactive learning<br>主要方法：开发交互式学习算法")
        Root --> Results("Results: Statistically optimal & computationally efficient algorithms<br>关键结果：统计最优且计算高效的算法")
        Problem --> P1("Active learning with noisy data<br>含噪声数据的主动学习")
        Problem --> P2("Sequential decision making with large action spaces<br>大动作空间的序列决策")
        Problem --> P3("Model selection under partial feedback<br>部分反馈下的模型选择")
        Method --> M1("New algorithmic principles<br>新算法原理")
        Method --> M2("Establish fundamental limits<br>建立基本极限")
        Results --> R1("Exponential label savings in active learning<br>主动学习中的指数级标签节省")
        Results --> R2("Contextual bandit guarantees independent of action space size<br>与动作空间大小无关的上下文赌博机保证")
        Results --> R3("Tight characterization of model selection cost<br>模型选择成本的紧致刻画")
    ```

- **[arXiv260101] Statistical Guarantees in the Search for Less Discriminatory Algorithms**
  - **tags:** [ai], [algorithmic fairness], [model multiplicity, optimal stopping, disparate impact, statistical guarantees, less discriminatory algorithms]
  - **authors:** Chris Hays, Ben Laufer, Solon Barocas, Manish Raghavan
  - **institution:** MIT, Cornell University, Microsoft Research
  - **link:** https://arxiv.org/pdf/2512.23943
  - **contributions:** 1. Formalizes the search for less discriminatory algorithms (LDAs) as an optimal stopping problem, providing a statistical framework to define a "good-faith effort" in model development. 2. Proposes an adaptive stopping algorithm that yields a high-probability upper bound on the potential gains from continued search, allowing developers to certify the sufficiency of their exploration. 3. Provides a flexible framework where developers can incorporate stronger assumptions about the model distribution to obtain correspondingly stronger statistical bounds, validated on real-world datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/323b958070f176d29545b148d49cdc3b6141db385ed752500b67c6d9556a8c78_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of how firms can demonstrate a good-faith effort to find less discriminatory algorithms. It proposes an adaptive stopping algorithm based on optimal stopping theory, which provides statistical guarantees on the potential benefits of further search. The method allows developers to certify that their search for fairer models was sufficient, as validated on credit, employment, and housing datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Statistical Guarantees in the Search for Less Discriminatory Algorithms<br>寻找更少歧视性算法的统计保证"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>What constitutes a good-faith search for less discriminatory models?<br>什么是对更少歧视性模型的真诚搜索？"]
        Method["主要方法/Method<br>Formalize search as an optimal stopping problem; propose adaptive stopping algorithm.<br>将搜索形式化为最优停止问题；提出自适应停止算法。"]
        Results["关键结果/Results<br>High-probability bound on search gains; framework for certification.<br>搜索收益的高概率上界；用于认证的框架。"]
    ```

- **[arXiv260101] DivQAT: Enhancing Robustness of Quantized Convolutional Neural Networks against Model Extraction Attacks**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [Quantization Aware Training, Model Extraction Attack, Quantized Convolutional Neural Networks, Edge Device, Robustness]
  - **authors:** Kacem Khaled, Felipe Gohring de Magalhães, Gabriela Nicolescu
  - **institution:** Polytechnique Montreal
  - **link:** https://arxiv.org/pdf/2512.23948
  - **contributions:** 1. Proposes DivQAT, a novel algorithm to train quantized CNNs that integrates a defense mechanism directly into the Quantization Aware Training process to enhance robustness against model extraction attacks. 2. Demonstrates that the proposed technique effectively defends against model extraction attacks without compromising the model's accuracy, as validated on benchmark vision datasets. 3. Shows that combining the proposed quantization technique with other defense mechanisms improves their effectiveness compared to using traditional QAT.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c08371f06267ec2fffb37ff15727bbbcfaf1e05de4f88d1541883445740a65d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the vulnerability of quantized Convolutional Neural Networks to model extraction attacks. It proposes DivQAT, a novel training algorithm that modifies the quantization process to integrate a defense mechanism directly, enhancing model robustness. The method is shown to be effective against attacks without harming accuracy and can improve other defenses when combined.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["DivQAT: Enhancing Robustness of Quantized CNNs against Model Extraction Attacks"] --> Problem["核心问题/Problem: Quantized CNNs are vulnerable to model extraction attacks, posing IP theft risks."]
        Root --> Method["主要方法/Method: Proposes DivQAT, a novel QAT-based algorithm integrating defense into the quantization training process."]
        Root --> Results["关键结果/Results: Enhances robustness against attacks without compromising accuracy; improves other defenses."]
    ```

- **[arXiv260101] Improved Balanced Classification with Theoretically Grounded Loss Functions**
  - **tags:** [ai], [imbalanced classification], [balanced loss, surrogate loss, H-consistency, logit-adjusted, class-weighted]
  - **authors:** Corinna Cortes, Mehryar Mohri, Yutao Zhong
  - **institution:** Google Research
  - **link:** https://arxiv.org/pdf/2512.23947
  - **contributions:**  1. Introduces two new surrogate loss families for balanced classification: Generalized Logit-Adjusted (GLA) and Generalized Class-Aware weighted (GCA) losses. 2. Provides a comprehensive theoretical analysis showing GCA losses have stronger H-consistency guarantees (scaling as 1/√p_min) than GLA losses (scaling as 1/p_min) in imbalanced settings. 3. Empirically demonstrates that both GCA and GLA losses outperform standard class-weighted and Logit-Adjusted losses, with GLA slightly better on common benchmarks and GCA better in highly imbalanced scenarios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/03edb44855299a7da70383f03cc9676cdeb3330caf1fa4f5212538cf5a33b248_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses class imbalance in multi-class classification by proposing two theoretically grounded surrogate loss families: Generalized Logit-Adjusted (GLA) and Generalized Class-Aware weighted (GCA) losses. The theoretical analysis shows GCA offers stronger consistency guarantees, especially for imbalanced data. Experiments confirm both losses outperform existing methods, with each excelling in different imbalance settings.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Improved Balanced Classification with Theoretically Grounded Loss Functions] --> B(核心问题/Problem: Class imbalance leads to poor minority class performance)
    A --> C(主要方法/Method: Proposes GLA and GCA surrogate loss families)
    A --> D(关键结果/Results: GCA has stronger theoretical guarantees; both outperform baselines empirically)
    ```

- **[arXiv260101] Physics-informed Graph Neural Networks for Operational Flood Modeling**
  - **tags:** [ai], [graph neural networks], [physics-informed neural networks, graph neural networks, flood modeling, curriculum learning, message-passing]
  - **authors:** Carlo Malapad Acosta, Herath Mudiyanselage Viraj Vidura Herath, Jia Yu Lim, Abhishek Saha, Sanka Rasnayaka, Lucy Marshall
  - **institution:** National University of Singapore, The University of Sydney, Delft University of Technology
  - **link:** https://arxiv.org/pdf/2512.23964
  - **code:** https://github.com/acostacos/dual_flood_gnn
  - **contributions:** 1. Proposes DUALFloodGNN, a novel GNN architecture that embeds physical constraints at both global and local scales through explicit loss terms. 2. Introduces a model that jointly predicts water volume at nodes and flow along edges using a shared message-passing framework. 3. Enhances autoregressive inference performance via multi-step loss training with dynamic curriculum learning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c6bbddb2010c8550ce3ea4a09f24c04abc0993a7ee2a722f960fc0852c4f049_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high computational cost of physics-based flood models by proposing DUALFloodGNN, a physics-informed graph neural network architecture. The model incorporates physical constraints into its loss function and uses a multi-step training strategy with curriculum learning. It achieves improved prediction accuracy for hydrologic variables while maintaining high computational efficiency compared to existing GNN models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Physics-informed Graph Neural Networks for Operational Flood Modeling] --> B
        A --> C
        A --> D
        B[核心问题/Problem: High computational cost of physics-based flood models limits operational use]
        C[主要方法/Method: DUALFloodGNN embeds physical constraints via loss terms and uses multi-step training with curriculum learning]
        D[关键结果/Results: Achieves improved accuracy and maintains high computational efficiency]
    ```

- **[arXiv260101] Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [hypergraph memory, multi-step reasoning, global sense-making, long-context modeling, retrieval-augmented generation]
  - **authors:** Chulun Zhou, Chunkang Zhang, Guoxin Yu, Fandong Meng, Jie Zhou, Wai Lam, Mo Yu
  - **institution:** The Chinese University of Hong Kong, WeChat AI
  - **link:** https://arxiv.org/pdf/2512.23959
  - **code:** https://github.com/Encyclomen/HGMem
  - **contributions:** 1. Proposes HGMem, a novel hypergraph-based memory mechanism that models memory as a dynamic structure with higher-order interactions, moving beyond passive storage. 2. Addresses the limitation of existing multi-step RAG memory in capturing complex relational structures and providing strong guidance for subsequent reasoning steps. 3. Demonstrates through extensive experiments that the method consistently improves multi-step RAG performance and substantially outperforms strong baselines on global sense-making tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259f66b1c3afc451216d5a69cb56a5a72ee4244c5fa02941603de2fbd4afc261_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of static, passive memory in multi-step RAG systems, which leads to fragmented reasoning in long-context tasks. It proposes HGMem, a dynamic hypergraph-based memory mechanism that captures high-order correlations among facts to form an integrated knowledge structure for stronger reasoning guidance. The method is shown to consistently and substantially outperform baseline systems across diverse global sense-making tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Improving Multi-step RAG with Hypergraph-based Memory<br>改进多步RAG的超图记忆] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有记忆模块是被动的静态存储<br>Existing memory is passive static storage]
        B1 --> B2[忽略了高阶关联，导致碎片化推理<br>Ignores high-order correlations, causing fragmented reasoning]
        C --> C1[提出超图记忆机制 HGMem<br>Propose hypergraph memory mechanism HGMem]
        C1 --> C2[将记忆表示为动态超图<br>Represent memory as a dynamic hypergraph]
        C2 --> C3[超边形成高阶交互，构建集成知识结构<br>Hyperedges form high-order interactions, building integrated knowledge]
        D --> D1[在多步RAG上取得一致改进<br>Achieves consistent improvement on multi-step RAG]
        D1 --> D2[在全局理解任务上显著超越基线<br>Substantially outperforms baselines on global sense-making tasks]
    ```

- **[arXiv260101] Exploring the Potential of Spiking Neural Networks in UWB Channel Estimation**
  - **tags:** [mlsys], [on-device ai], [Spiking Neural Networks (SNNs), Ultra-Wide Band (UWB), Channel Estimation, Liquid State Machine (LSM), Neuromorphic Computing]
  - **authors:** Youdong Zhang, Xu He, Xiaolin Meng
  - **institution:** Southeast University (SEU)
  - **link:** https://arxiv.org/pdf/2512.23975
  - **contributions:** 1. Proposes a fully unsupervised Spiking Neural Network (SNN) solution for UWB channel estimation, addressing the resource constraints of edge devices. 2. Employs a Liquid State Machine (LSM) with fixed synaptic weights to extract spiking representations from UWB features, sidestepping typical SNN training difficulties. 3. Demonstrates that the proposed SNN approach achieves competitive accuracy (80%) compared to supervised deep learning methods while offering drastically reduced model complexity and suitability for neuromorphic deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6223f5cf13e59469e26c765b0854ea31ff37f76d9f1c9137587f99a5a743dcc0_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high computational cost of deep learning-based UWB channel estimation on resource-constrained edge devices by proposing a fully unsupervised Spiking Neural Network (SNN) solution. The method uses a Liquid State Machine to process encoded UWB features and achieves 80% test accuracy, comparable to supervised methods, while being inherently more efficient and suitable for neuromorphic hardware.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Exploring the Potential of Spiking Neural Networks in UWB Channel Estimation"] --> Problem["核心问题/Problem: High computational cost of DL-based UWB channel estimation clashes with edge device constraints"]
        Root --> Method["主要方法/Method: Propose a fully unsupervised SNN solution using Liquid State Machine (LSM)"]
        Root --> Results["关键结果/Results: Achieves 80% accuracy (on par with supervised DL), drastic model complexity reduction, suited for neuromorphic deployment"]
    ```

- **[arXiv260101] Causify DataFlow: A Framework For High-performance Machine Learning Stream Computing**
  - **tags:** [mlsys], [others], [streaming machine learning, directed acyclic graph (DAG), point-in-time idempotency, temporal tiling, causality enforcement]
  - **authors:** Giacinto Paolo Saggese, Paul Smith
  - **institution:** Not explicitly stated. Could be inferred from author names and arXiv submission, but no clear affiliation is provided in the given content.
  - **link:** https://arxiv.org/pdf/2512.23977
  - **contributions:** 1. A unified DAG-based execution model with point-in-time idempotency, ensuring identical model behavior in batch and streaming modes without code changes. 2. Automatic causality enforcement by tracking knowledge time across transformations, eliminating future-peeking bugs. 3. Flexible temporal and feature dimension tiling, allowing models to operate at different frequencies and memory profiles via configuration alone.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4105add65c1e7a9960d7e21b6bda977778c41365cfff18c04d16a1af3773b5c4_w640_q70.webp
  - **Simple LLM Summary:** The paper presents DataFlow, a framework for building high-performance ML systems on streaming time-series data. It uses a DAG-based model with point-in-time idempotency to bridge the gap between batch prototyping and streaming production, ensuring causality and reproducibility. The framework demonstrates effectiveness in domains like financial trading and IoT analytics.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Causify DataFlow: A Framework For High-performance Machine Learning Stream Computing"] --> Problem["核心问题/Problem: Gap between batch ML prototypes and streaming production systems causes causality violations and poor reproducibility."]
        Root --> Method["主要方法/Method: Unified DAG execution model with point-in-time idempotency and automatic causality tracking."]
        Root --> Results["关键结果/Results: Enables identical batch/stream execution, flexible tiling, and effective deployment in financial, IoT, and fraud detection domains."]
    ```

- **[arXiv260101] Information-Theoretic Quality Metric of Low-Dimensional Embeddings**
  - **tags:** [ai], [dimensionality reduction], [low-dimensional embeddings, information-theoretic metric, singular-value spectrum, stable rank, neighborhood preservation]
  - **authors:** Sebastián Gutiérrez-Bernal, Hector Medel Cobaxin, Abiel Galindo González
  - **institution:** Tecnologico de Monterrey
  - **link:** https://arxiv.org/pdf/2512.23981
  - **contributions:** 1. Introduces the Entropy Rank Preservation Measure (ERPM), a novel local quality metric for embeddings based on Shannon entropy and stable rank of neighborhood matrices. 2. Provides an information-theoretic perspective on embedding quality, directly assessing information preservation rather than just geometric or distance distortions. 3. Demonstrates that ERPM complements existing metrics by identifying neighborhoods with severe information loss, offering a more comprehensive assessment for information-sensitive applications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30121111f7039384030734c0f1c119a147b1f9d2605df8260026b1ba34b6b2dd_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes a new information-theoretic metric called ERPM to evaluate the quality of low-dimensional embeddings by measuring changes in uncertainty via the singular-value spectrum of neighborhood matrices. It shows that ERPM correlates strongly with geometric measures but identifies local discrepancies, complementing existing distance-based and geometric metrics. The conclusion is that ERPM enables a more thorough assessment of embeddings, especially for applications sensitive to information loss like early-warning indicators.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Information-Theoretic Quality Metric of Low-Dimensional Embeddings] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[经典指标如stress, MRRE, Local Procrustes不能直接评估信息保留/Classical metrics (stress, MRRE, Local Procrustes) do not directly assess information preservation]
        C --> C1[提出基于香农熵和稳定秩的ERPM度量/Propose ERPM based on Shannon entropy and stable rank of neighborhood matrices]
        D --> D1[距离指标与几何/谱指标相关性低/Distance-based criteria show low correlation with geometric/spectral measures]
        D --> D2[ERPM与Local Procrustes强相关但局部有差异/ERPM and Local Procrustes show strong correlation but local discrepancies]
        D --> D3[ERPM补充现有指标，识别信息严重丢失的邻域/ERPM complements existing metrics by identifying neighborhoods with severe information loss]
    ```

- **[arXiv260101] Assured Autonomy: How Operations Research Powers and Orchestrates Generative AI Systems**
  - **tags:** [mlsys], [agent system], [flow-based generative models, adversarial robustness, optimal transport]
  - **authors:** Tinglong Dai, David Simchi-Levi, Michelle Xiao Wu, Yao Xie
  - **institution:** Johns Hopkins University, Massachusetts Institute of Technology, Purdue University, Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.23978
  - **contributions:** 1. Proposes a conceptual framework for "assured autonomy" to address the fragility of stochastic generative models in operational domains. 2. Identifies flow-based generative models as a key approach for enabling auditability and constraint-aware generation. 3. Formulates operational safety through an adversarial robustness lens to account for worst-case perturbations and unmodeled risks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc5a435448048829b572c2ce3ff1418aa28bf4adcf98e17ff1ed80a690a1b51a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the "autonomy paradox" where more autonomous GenAI systems require stronger formal constraints. It proposes a framework grounded in Operations Research, combining flow-based generative models for deterministic control and adversarial robustness for safety. This shifts OR's role from solver to system architect, defining a research agenda for assured autonomy in critical domains.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Assured Autonomy: How Operations Research Powers and Orchestrates Generative AI Systems] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[自主性悖论: 更高的自主性需要更强的结构、约束和风险控制/Autonomy Paradox: Greater autonomy requires more structure, constraints, and risk discipline]
        B --> B2[生成模型在操作领域可能很脆弱/Generative models can be fragile in operational domains]
        C --> C1[基于流的生成模型: 确定性传输，可审计，约束感知/Flow-based generative models: Deterministic transport, auditability, constraint-aware]
        C --> C2[操作安全: 对抗性鲁棒性视角，考虑最坏情况扰动/Operational safety: Adversarial robustness lens, worst-case perturbations]
        D --> D1[框架将OR的角色从求解器转变为护栏和系统架构师/Framework shifts OR's role from solver to guardrail to system architect]
        D --> D2[定义了安全关键领域确保自主性的研究议程/Defines a research agenda for assured autonomy in safety-critical domains]
    ```

- **[arXiv260101] MeLeMaD: Adaptive Malware Detection via Chunk-wise Feature Selection and Meta-Learning**
  - **tags:** [sec], [malware detection], [Model-Agnostic Meta-Learning (MAML), Chunk-wise Feature Selection (CFSGB), Gradient Boosting]
  - **authors:** Ajvad Haneef K, Karan Kuwar Singh, Madhu Kumar S D
  - **institution:** National Institute of Technology Calicut
  - **link:** https://arxiv.org/pdf/2512.23987
  - **contributions:** 1. Proposed MeLeMaD, a novel malware detection framework leveraging Model-Agnostic Meta-Learning (MAML) for adaptability and generalization. 2. Introduced a novel Chunk-wise Feature Selection based on Gradient Boosting (CFSGB) technique to handle large-scale, high-dimensional datasets efficiently. 3. Demonstrated state-of-the-art performance on benchmark datasets (CIC-AndMal2020, BODMAS) and a custom dataset (EMBOD), achieving high accuracy and robustness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1509044c1c0bdfbb4a075c799e3c0cafd035f0b7c579548b445cf04caee2975d_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes MeLeMaD, a novel malware detection framework that combines a new chunk-wise feature selection method (CFSGB) with meta-learning (MAML) to improve adaptability and efficiency on large-scale datasets. It achieves high accuracy on benchmark and custom datasets, outperforming existing state-of-the-art approaches and demonstrating robustness against evolving threats.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MeLeMaD: Adaptive Malware Detection] --> B[核心问题/Problem: Malware detection needs robustness & adaptability]
        A --> C[主要方法/Method: Meta-Learning (MAML) + Chunk-wise Feature Selection (CFSGB)]
        A --> D[关键结果/Results: High accuracy on benchmarks (98.04%, 99.97%) & custom dataset]
    ```

- **[arXiv260101] Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process**
  - **tags:** [nlp], [mechanistic interpretability], [sparse auto-encoder, reasoning vectors, chain-of-thought]
  - **authors:** Zhenyu Zhang, Shujian Zhang, John Lambert, Wenxuan Zhou, Zhangyang Wang, Mingqing Chen, Andrew Hard, Rajiv Mathews, Lun Wang
  - **institution:** Google DeepMind, The University of Texas at Austin
  - **link:** https://arxiv.org/pdf/2512.23988
  - **contributions:** 1. Proposes RISE, an unsupervised framework using sparse auto-encoders (SAEs) to discover "reasoning vectors" that encode distinct reasoning behaviors from step-level LLM activations. 2. Demonstrates that these discovered vectors correspond to interpretable behaviors (e.g., reflection, backtracking) and can be used for targeted intervention to controllably steer the reasoning process without retraining. 3. Shows SAEs can uncover novel, human-undefined reasoning behaviors and structural properties, such as controlling response confidence, highlighting the potential of unsupervised latent discovery.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6bf740af692f8a7498e3cb43c54db55a7bd4f6005d4c48bc0e225978738bf9a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of interpreting the internal reasoning process of large language models (LLMs). It proposes RISE, an unsupervised framework that uses sparse auto-encoders to discover disentangled "reasoning vectors" from chain-of-thought activations. The method enables the identification, visualization, and controllable intervention of specific reasoning behaviors, revealing novel insights beyond supervised analysis.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process"]
        Root --> Problem["核心问题/Problem<br>LLM推理内部机制不明确<br>Supervised methods are limited"]
        Root --> Method["主要方法/Method<br>RISE框架: 无监督稀疏自编码器<br>Unsupervised SAEs on step-level activations"]
        Root --> Results["关键结果/Results<br>发现可解释推理行为向量<br>可控干预推理轨迹<br>Discover novel behaviors"]
    ```

- **[arXiv260101] RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress**
  - **tags:** [mlsys], [llm inference], [Mixture-of-Experts, Router Imbalance, Denial-of-Service, Expert Parallelism, Adversarial Prompt]
  - **authors:** Ruixuan Huang, Qingyue Wang, Hantao Huang, Yudong Gao, Dong Chen, Shuai Wang, Wei Wang
  - **institution:** HKUST, NTU
  - **link:** https://arxiv.org/pdf/2512.23995
  - **contributions:** 1. Identifies a novel DoS vulnerability in MoE LLMs where adversarial inputs can cause severe routing concentration and load imbalance during inference. 2. Proposes RepetitionCurse, a low-cost, black-box, and model-agnostic attack method that uses simple repetitive token patterns to exploit the router's universal flaw. 3. Empirically demonstrates significant performance degradation (e.g., 3.063x latency increase on Mixtral-8x7B), highlighting a critical risk to service-level agreements for real-world MoE deployments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d78c253b115346789599383601182c2e6e0cd34050dd3dfd9f1541a370776561_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies a denial-of-service vulnerability in Mixture-of-Experts LLMs, where adversarial prompts can manipulate the router to concentrate all tokens on a few experts, creating severe load imbalance. The authors propose RepetitionCurse, a simple black-box attack using repetitive token patterns to exploit this flaw. Their method significantly increases inference latency, demonstrating a critical risk to the availability of MoE-based services.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[MoE推理负载不均/MoE Inference Load Imbalance]
        B --> B2[路由集中导致DoS/Routing Concentration Leads to DoS]
        C --> C1[重复令牌攻击/Repetitive Token Attack]
        C --> C2[黑盒方法/Black-box Method]
        D --> D1[延迟显著增加/Latency Significantly Increased]
        D --> D2[服务可用性下降/Service Availability Degraded]
    ```

- **[arXiv260101] Tracing the Heart's Pathways: ECG Representation Learning from a Cardiac Conduction Perspective**
  - **tags:** [ai], [self-supervised learning], [electrocardiogram (ECG), self-supervised learning (SSL), cardiac conduction, sparse attention, hierarchical diagnosis]
  - **authors:** Tan Pan, Yixuan Sun, Chen Jiang, Qiong Gao, Rui Sun, Xingmeng Zhang, Zhenqi Yang, Limei Han, Yixiu Liang, Yuan Cheng, Kaiyu Guo
  - **institution:** Fudan University, Shanghai Academy of Artificial Intelligence for Science
  - **link:** https://arxiv.org/pdf/2512.24002
  - **code:** https://github.com/Ashespt/CLEAR-HUG
  - **contributions:** 1. Identifies a key limitation in prior ECG self-supervised learning (eSSL) methods: they overlook inherent heartbeat differences rooted in cardiac conduction and neglect the sequential logic of clinical ECG diagnosis. 2. Proposes a novel two-stage framework (CLEAR-HUG), where the first stage (CLEAR) is an eSSL model that uses a sparse attention mechanism to reconstruct signals by treating each heartbeat as a distinct entity, capturing subtle conduction variations. 3. Introduces a Hierarchical lead-Unified Group head (HUG) for the downstream diagnosis stage, which mirrors the clinical workflow from heartbeats to leads to lead combinations, aligning model patterns with expert guidelines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4316ae9f56d525621d461087803f69e54c99676d3863c02d5df1d1ad32dab6a_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes CLEAR-HUG, a two-stage framework for ECG representation learning. The method first uses a self-supervised model (CLEAR) with sparse attention to learn from cardiac conduction variations, then applies a hierarchical diagnosis head (HUG) aligned with clinical guidelines. Experiments across six tasks show a 6.84% performance improvement, validating its effectiveness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[追踪心路：从心脏传导视角的ECG表征学习<br>Tracing the Heart's Pathways: ECG Representation Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有eSSL方法忽视心脏传导导致的细微差异<br>Prior eSSL overlooks conduction-based heartbeat differences]
        B --> B2[模型未遵循从心跳到导联的临床诊断逻辑<br>Models neglect clinical diagnostic sequence]
        C --> C1[两阶段框架CLEAR-HUG<br>Two-stage framework CLEAR-HUG]
        C1 --> C2[阶段一: CLEAR (自监督学习)<br>Stage 1: CLEAR (eSSL)]
        C2 --> C3[稀疏注意力重构信号<br>Sparse attention for reconstruction]
        C1 --> C4[阶段二: HUG (分层诊断头)<br>Stage 2: HUG (hierarchical head)]
        C4 --> C5[模仿临床工作流<br>Mirrors clinical workflow]
        D --> D1[六项任务性能提升6.84%<br>6.84% improvement across six tasks]
        D --> D2[验证了方法的有效性<br>Validates effectiveness]
    ```

- **[arXiv260101] Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source Large Language Models**
  - **tags:** [nlp], [llm evaluation], [reliability, calibration, robustness, uncertainty quantification, composite score]
  - **authors:** Rohit Kumar Salla, Manoj Saravanan, Shrikar Reddy Kota
  - **institution:** Virginia Tech
  - **link:** https://arxiv.org/pdf/2512.24058
  - **code:** https://github.com/rohitsalla/CRS.git
  - **contributions:** 1. A unified reliability metric (CRS) integrating calibration, robustness, and uncertainty. 2. A large-scale evaluation of ten open-source LLMs on five QA datasets. 3. The demonstration that CRS provides stable model rankings and uncovers hidden failure modes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98ff5e45b3d4957a7de510123e5e0280e7ee39117d9ff73439f058e6965ebfab_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the fragmented evaluation of Large Language Model (LLM) reliability by proposing the Composite Reliability Score (CRS), a unified metric that integrates calibration, robustness, and uncertainty quantification. Through experiments on ten open-source LLMs, the authors show that CRS provides consistent model rankings and reveals trade-offs between reliability dimensions. The main conclusion is that the most dependable LLM systems balance accuracy, robustness, and calibrated uncertainty.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Beyond Hallucinations: A Composite Score for Measuring Reliability] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[LLM可靠性评估碎片化/Fragmented LLM Reliability Evaluation]
        C --> C1[提出CRS复合分数/Propose Composite Reliability Score (CRS)]
        D --> D1[CRS提供稳定模型排名/CRS Delivers Stable Model Rankings]
        D --> D2[揭示隐藏的失败模式/Uncovers Hidden Failure Modes]
    ```

- **[arXiv260101] Hyperspherical Graph Representation Learning via Adaptive Neighbor-Mean Alignment and Uniformity**
  - **tags:** [ai], [graph representation learning], [hyperspherical embedding, neighbor-mean alignment, sampling-free uniformity, entropy-guided balancing, graph neural networks]
  - **authors:** Rui Chen, Junjun Guo, Hongbin Wang, Yan Xiang, Yantuan Xian, Zhengtao Yu
  - **institution:** Kunming University of Science and Technology, Yunnan Key Laboratory of Artificial Intelligence
  - **link:** https://arxiv.org/pdf/2512.24062
  - **contributions:** 1. Proposes HyperGRL, a unified framework for hyperspherical graph representation learning using two adversarially coupled objectives: neighbor-mean alignment and sampling-free uniformity. 2. Introduces an entropy-guided adaptive balancing mechanism to dynamically regulate the interplay between alignment and uniformity without manual hyperparameter tuning. 3. Demonstrates superior performance on node classification, clustering, and link prediction tasks, achieving improvements over existing methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e0d10e35c66ca8482e3324110ac5fded6eefbaab8a774c81cba99d854efe694_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes HyperGRL, a novel framework for graph representation learning that embeds nodes on a hypersphere using neighbor-mean alignment and a sampling-free uniformity objective, stabilized by an adaptive balancing mechanism. The method avoids complex negative sampling and hyperparameter tuning, addressing issues like over-smoothing and training instability. Experiments show HyperGRL outperforms existing methods on standard graph learning tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HyperGRL: 超球面图表示学习 / Hyperspherical Graph Representation Learning] --> B
        A --> C
        A --> D
        B[核心问题 / Problem: 现有方法依赖复杂对比目标 / Existing methods rely on complex contrastive objectives]
        C[主要方法 / Method: 邻域均值对齐与采样无关均匀性 / Neighbor-Mean Alignment & Sampling-Free Uniformity]
        D[关键结果 / Results: 在节点分类等任务上性能提升 / Performance gains on node classification, etc.]
    ```

- **[arXiv260101] How and Why LLMs Generalize: A Fine-Grained Analysis of LLM Reasoning from Cognitive Behaviors to Low-Level Patterns**
  - **tags:** [ai], [large language models], [supervised fine-tuning, reinforcement learning, reasoning decomposition, meta-probing, generalization]
  - **authors:** Haoyue Bai, Yiyou Sun, Wenjie Hu, Shi Qiu, Maggie Ziyu Huan, Peiyang Song, Robert Nowak, Dawn Song
  - **institution:** University of Wisconsin, Madison; University of California, Berkeley; University of Pennsylvania; California Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.24063
  - **contributions:** 1. Introduced a novel benchmark that decomposes reasoning into atomic core skills (e.g., calculation, simulation) for fine-grained analysis. 2. Proposed a meta-probing framework to track model behavioral profiles across different training stages. 3. Provided a combined analysis linking high-level cognitive skill changes to low-level statistical patterns, revealing that RL tuning preserves reasoning skills better than SFT.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e9fab646e78db9be62f127bfa42a9acf6be78552ea9847e5873b10c18802eaa_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates why LLMs generalize differently after SFT versus RL tuning. It proposes a new benchmark to decompose reasoning into core skills and a meta-probing framework to analyze model behavior, finding that RL-tuned models maintain more stable reasoning abilities while SFT models tend to overfit to surface patterns.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["How and Why LLMs Generalize<br>LLM泛化能力研究"] --> Problem["核心问题/Problem<br>Why SFT narrows generalization while RL preserves it?"]
        Root --> Method["主要方法/Method<br>Novel benchmark + Meta-probing framework"]
        Root --> Results["关键结果/Results<br>RL-tuned models resist skill collapse; SFT models overfit."]
    ```

- **[arXiv260101] Time-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning**
  - **tags:** [mlsys], [federated learning], [decentralized federated learning, mixing matrix, energy consumption, time-varying topology, wireless networks]
  - **authors:** Xusheng Zhang, Tuan Nguyen, Ting He
  - **institution:** University of Oxford, Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2512.24069
  - **contributions:** 1. A novel convergence theorem for DFL that allows for arbitrarily time-varying mixing matrices, providing theoretical justification for dynamic communication topologies. 2. A multi-phase design framework for mixing matrices that activates time-varying communication topologies to trade off per-iteration energy consumption and convergence rate. 3. An optimization approach that minimizes the maximum per-node energy consumption until convergence, explicitly considering the broadcast nature of wireless communications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/090a96d0adae430f081f3c2325be19fc983de3cc1e88b07fcc83e4ab4e983d30_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of high energy consumption in Decentralized Federated Learning (DFL) for wireless networks by designing time-varying mixing matrices. The proposed method introduces a multi-phase framework that dynamically adjusts communication topologies to balance energy use across nodes and trade off per-iteration cost with convergence speed. The evaluation shows the solution effectively combines the low energy of sparse topologies with the fast convergence of dense ones.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Time-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning<br>时变混合矩阵设计用于能效去中心化联邦学习"]
        Root --> Problem["Minimize max per-node energy consumption in DFL<br>最小化DFL中最大单节点能耗"]
        Root --> Method["Multi-phase framework with time-varying topologies<br>基于时变拓扑的多阶段框架"]
        Root --> Results["Validated efficacy: low energy + fast convergence<br>验证有效性：低能耗+快速收敛"]
    ```

- **[arXiv260101] Multi-Scenario Highway Lane-Change Intention Prediction: A Temporal Physics-Informed Multi-Modal Framework**
  - **tags:** [ai], [autonomous driving], [lane-change intention prediction, physics-informed AI, temporal embeddings, class imbalance, LightGBM]
  - **authors:** Jiazhao Shi, Ziyu Wang, Yichen Lin, Shoufeng Lu
  - **institution:** New York University, Wake Forest University, Nanjing Tech University
  - **link:** https://arxiv.org/pdf/2512.24075
  - **contributions:** 1. Proposed a hybrid Temporal Physics-Informed AI (TPI-AI) framework that fuses deep temporal embeddings from a Bi-LSTM encoder with physics-inspired interaction features for lane-change intention prediction. 2. Introduced imbalance-aware optimization techniques, including resampling/weighting and fold-wise threshold calibration, to improve minority-class reliability. 3. Demonstrated robust multi-scenario generalization by evaluating on two large-scale, heterogeneous highway datasets (highD and exiD) with location-based splits and outperforming standalone baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/689b7843d7cd1396bf4f4df0cdc13d3a94ef4d76e2d2ca0c9948486895c4e482_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes TPI-AI, a hybrid framework combining Bi-LSTM temporal embeddings with physics-informed interaction features for highway lane-change intention prediction. It addresses challenges like class imbalance and noisy data, achieving high macro-F1 scores on two drone-based datasets. The results show that integrating physics cues with learned representations yields robust performance across diverse highway scenarios.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multi-Scenario Highway Lane-Change Intention Prediction: A Temporal Physics-Informed Multi-Modal Framework] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[车道变换意图预测困难/Lane-change intention prediction is difficult]
        B1 --> B2[噪声运动学, 类别不平衡, 泛化性差/Noisy kinematics, class imbalance, poor generalization]
        C --> C1[提出TPI-AI框架/Propose TPI-AI framework]
        C1 --> C2[融合时序嵌入与物理特征/Fuse temporal embeddings with physics features]
        C2 --> C3[Bi-LSTM编码器 + LightGBM分类器/Bi-LSTM encoder + LightGBM classifier]
        C3 --> C4[不平衡优化/Imbalance-aware optimization]
        D --> D1[在两个数据集上评估/Evaluate on two datasets]
        D1 --> D2[highD: 直道高速路/highD: straight highways]
        D1 --> D3[exiD: 匝道丰富环境/exiD: ramp-rich environments]
        D2 --> D4[宏F1: 0.9562, 0.9124, 0.8345/Macro-F1: 0.9562, 0.9124, 0.8345]
        D3 --> D5[宏F1: 0.9247, 0.8197, 0.7605/Macro-F1: 0.9247, 0.8197, 0.7605]
    ```

- **[arXiv260101] Random Multiplexing**
  - **tags:** [sys], [wireless communication], [random multiplexing, AMP detection, power allocation, replica optimality, constrained capacity]
  - **authors:** Lei Liu, Yuhao Chi, Shunqi Huang, Zhaoyang Zhang
  - **institution:** Zhejiang University, Xidian University, Japan Advanced Institute of Science and Technology (JAIST)
  - **link:** https://arxiv.org/pdf/2512.24087
  - **contributions:** 1. Proposes a random multiplexing technique decoupled from physical channel structures, enabling application to arbitrary norm-bounded and spectrally convergent channel matrices. 2. Introduces a low-complexity cross-domain memory AMP (CD-MAMP) detector and derives optimal power allocations to minimize BER and maximize constrained capacity. 3. Investigates the optimal coding principle and proves the replica constrained-capacity optimality of the CD-MAMP detector for random multiplexing systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad2f6d7e30422bda561811ec881c0aa17f79a2f4e7bf13203955c43c9c8fab17_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a random multiplexing technique to overcome the limitations of traditional and emerging multiplexing schemes (like OFDM and OTFS) which rely on specific channel structures. The method decouples from the physical channel, uses a random transform to create an input-isotropic equivalent channel, and employs a low-complexity AMP-type detector to achieve near-optimal performance for arbitrary norm-bounded channels. The authors validate the approach with theoretical analysis and numerical results, demonstrating its robustness and versatility in dynamic wireless environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Random Multiplexing] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统复用技术依赖特定信道结构/Traditional multiplexing relies on specific channel structures]
        B --> B2[在动态真实环境中鲁棒性有限/Limited robustness in dynamic real-world environments]
        C --> C1[随机复用技术/Random Multiplexing Technique]
        C --> C2[构建输入各向同性等效信道/Construct input-isotropic equivalent channel]
        C --> C3[CD-MAMP检测器/CD-MAMP Detector]
        D --> D1[保证渐近最优BER/Guarantees asymptotic optimal BER]
        D --> D2[推导最优功率分配/Derives optimal power allocation]
        D --> D3[验证理论结果/Validates theoretical findings]
    ```

- **[arXiv260101] Training a Huggingface Model on AWS Sagemaker (Without Tears)**
  - **tags:** [mlsys], [llm training], [AWS SageMaker, Hugging Face, MLOps, cloud computing, Jupyter as a Service]
  - **authors:** Liling Tan
  - **institution:** (Institution not explicitly stated in provided content. Based on author name and context, likely independent researcher or affiliation not listed on first page.)
  - **link:** https://arxiv.org/pdf/2512.24098
  - **contributions:** 1. Provides a centralized, comprehensive guide to train a Hugging Face model on AWS SageMaker, addressing fragmented documentation. 2. Bridges the knowledge gap between local Jupyter Notebook development and cloud-based training on SageMaker. 3. Aims to democratize cloud adoption for researchers lacking on-premise computing resources by lowering the platform's learning curve.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e9d3b4e38e89877a6b18e1df5bad45a785b69e26e421db2b8a658f22bdff539_w640_q70.webp
  - **Simple LLM Summary:** This demo paper addresses the steep learning curve and fragmented documentation that hinder researchers from using AWS SageMaker to train Hugging Face models. It proposes a centralized guide to bridge the gap between local and cloud-based development workflows. The main conclusion is that this approach can democratize cloud adoption, enabling more researchers to train models without extensive on-premise resources.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Training a Huggingface Model on AWS Sagemaker (Without Tears)] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Barriers to Cloud Adoption<br>资源壁垒与学习曲线]
        C[主要方法/Method<br>Centralized Guide<br>提供集中化指南]
        D[关键结果/Results<br>Democratized Cloud Training<br>实现云训练的民主化]
    ```

- **[arXiv260101] Enhancing LLM Planning Capabilities through Intrinsic Self-Critique**
  - **tags:** [ai], [planning], [self-critique, few-shot learning, many-shot learning, iterative refinement, planning benchmarks]
  - **authors:** Bernd Bohnet, Pierre-Alexandre Kamienny, Hanie Sedghi, Dilan Gorur, Pranjal Awasthi, Aaron Parisi, Kevin Swersky, Rosanne Liu, Azade Nova, Noah Fiedel
  - **institution:** Google DeepMind
  - **link:** https://arxiv.org/pdf/2512.24103
  - **contributions:**  1. Proposes an intrinsic self-critique method for LLMs to improve their own planning outputs without external verifiers. 2. Demonstrates significant performance gains on established planning benchmarks (Blocksworld, Logistics, Mini-grid) over strong baselines. 3. Shows the method's applicability across different models and datasets, achieving new state-of-the-art results for the considered model class.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1646fd60ae3c2dbada7b54640bd9b507a010326fc6e75dd48733e4e2612eeefd_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces an intrinsic self-critique approach where LLMs iteratively critique and refine their own plans. The method, building upon few-shot and many-shot learning, significantly improves planning performance on benchmarks like Blocksworld without needing external verification. The results set a new state-of-the-art, demonstrating that self-critique can effectively enhance LLM planning capabilities.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Enhancing LLM Planning Capabilities through Intrinsic Self-Critique] --> B[核心问题/Problem: LLM规划能力不足，传统自批判方法效果受质疑/LLM planning capability is limited, effectiveness of self-critique is questioned]
        A --> C[主要方法/Method: 内在自批判与迭代精炼/Intrinsic Self-Critique and Iterative Refinement]
        A --> D[关键结果/Results: 在规划基准测试中取得显著性能提升，达到新SOTA/Significant performance gains on planning benchmarks, achieving new SOTA]
    ```

- **[arXiv260101] Autoregressivity in the Latent Space of a GP-VAE Language Model: An Empirical Ablation Study**
  - **tags:** [nlp], [language modeling], [GP-VAE, latent autoregression, ablation study, Gaussian process, variational autoencoder]
  - **authors:** Yves Ruffenach
  - **institution:** Conservatoire National des Arts et Métiers
  - **link:** https://arxiv.org/pdf/2512.24102
  - **contributions:** 1. Conducts a systematic ablation study to isolate and analyze the role of latent autoregression in a GP-VAE language model., 2. Demonstrates that latent autoregression leads to latent trajectories more aligned with the Gaussian-process prior and with greater long-horizon stability., 3. Provides empirical evidence that sequential structure can be effectively carried by latent dynamics even when using a non-autoregressive decoder.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bed10d31b6309110f5cec704462d295e7459d74c493da4d130689dc4d04af954_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the role of latent autoregression in a GP-VAE language model through an ablation study. It compares models with and without latent autoregression, finding that latent autoregression organizes long-range structure, leading to more stable and prior-aligned latent trajectories. The study shows latent dynamics can carry sequential structure even with a non-autoregressive decoder.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Autoregressivity in the Latent Space of a GP-VAE Language Model: An Empirical Ablation Study<br/>GP-VAE语言模型潜在空间中的自回归性：一项实证消融研究"]
        Root --> Problem["核心问题/Problem<br/>What is the role of latent autoregression in organizing sequential structure?<br/>潜在自回归在组织序列结构中的作用是什么？"]
        Root --> Method["主要方法/Method<br/>Ablation study comparing GP-VAE with latent autoregression, without it, and a standard autoregressive Transformer.<br/>消融研究：比较带潜在自回归的GP-VAE、不带潜在自回归的版本和标准自回归Transformer。"]
        Root --> Results["关键结果/Results<br/>Latent autoregression yields more prior-aligned, stable latent trajectories, effectively organizing long-range structure.<br/>潜在自回归产生更符合先验、更稳定的潜在轨迹，有效组织长程结构。"]
    ```

- **[arXiv260101] OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [post-training quantization, weight outliers, rotation, GPTQ, data-free]
  - **authors:** Advait Gadhikar, Riccardo Grazzi, James Hensman
  - **institution:** CISPA Helmholtz Center for Information Security, Microsoft Research
  - **link:** https://arxiv.org/pdf/2512.24124
  - **contributions:** 1. Proposes OptRot, a data-free method that learns fusible rotations by minimizing a principled, cheap proxy objective (element-wise fourth power of weights) to reduce weight outliers for quantization. 2. Demonstrates that OptRot outperforms existing rotation methods (Hadamard, SpinQuant, OSTQuant) for weight quantization and improves W4A8 activation quantization. 3. Introduces OptRot+, a data-dependent variant that incorporates activation covariance information for further performance gains, while highlighting a trade-off between weight and activation quantization in the W4A4 setting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/137fb0c1b0206d10c607db973da90e5733c1ed86f7a8360cfe91f146000affae_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of quantizing Large Language Models (LLMs) by mitigating weight outliers. It proposes OptRot, a data-free method that learns efficient rotations to minimize a proxy for weight quantization error, and shows it outperforms existing techniques for weight and W4A8 activation quantization. The work also introduces an enhanced data-dependent variant and reveals a performance trade-off in more aggressive quantization settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization] --> B[核心问题/Problem: LLM权重和激活中的异常值使量化困难/Outliers in LLM weights & activations make quantization difficult]
        A --> C[主要方法/Method: 通过最小化旋转后权重的四阶矩学习可融合的旋转/Learn fusible rotations by minimizing element-wise fourth power of rotated weights (OptRot)]
        A --> D[关键结果/Results: OptRot在权重量化上优于现有方法，改进W4A8激活量化，W4A4下存在权衡/OptRot outperforms existing methods for weight quant., improves W4A8 activation quant., trade-off in W4A4 setting]
    ```

- **[arXiv260101] Colorful Pinball: Density-Weighted Quantile Regression for Conditional Guarantee of Conformal Prediction**
  - **tags:** [ai], [uncertainty quantification], [conformal prediction, conditional coverage, quantile regression, density-weighted pinball loss, three-headed network]
  - **authors:** Qianyi Chen, Bo Li
  - **institution:** Tsinghua University
  - **link:** https://arxiv.org/pdf/2512.24139
  - **contributions:** 1. Derivation of a novel density-weighted pinball loss as a sharp surrogate objective for quantile regression to improve conditional coverage in conformal prediction. 2. Proposal of a three-headed quantile network architecture that estimates the necessary density weights via finite differences using auxiliary quantiles. 3. Provision of a theoretical analysis with exact non-asymptotic guarantees for the excess risk and demonstration of significant conditional coverage improvements on real-world datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0a2f8de6a5fa6ef2df8d7f5895f2503ae4000f24fff02f3e88840fcb1d0f27f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of achieving reliable conditional coverage in conformal prediction. The authors propose a new method that refines quantile regression using a density-weighted pinball loss and a three-headed network to estimate the weights, leading to improved conditional coverage guarantees. Experiments show the method significantly enhances conditional coverage performance on diverse datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Colorful Pinball: Density-Weighted Quantile Regression for Conditional Guarantee of Conformal Prediction") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("标准CP仅提供边际覆盖/Standard CP only provides marginal coverage")
        Problem --> P2("难以实现可靠的输入条件覆盖/Hard to achieve reliable input-conditional coverage")
        Method --> M1("推导密度加权分位数损失/Derive density-weighted quantile loss")
        Method --> M2("提出三头分位数网络/Propose three-headed quantile network")
        Method --> M3("通过有限差分估计权重/Estimate weights via finite differences")
        Results --> R1("理论非渐近保证/Theoretical non-asymptotic guarantees")
        Results --> R2("实验显示条件覆盖显著提升/Experiments show significant conditional coverage improvement")
    ```

- **[arXiv260101] GARDO: Reinforcing Diffusion Models without Reward Hacking**
  - **tags:** [ai], [reinforcement learning], [reward hacking, diffusion models, regularization, mode collapse, online RL]
  - **authors:** Haoran He, Yuxiao Ye, Jie Liu, Jiajun Liang, Zhiyong Wang, Ziyang Yuan, Xintao Wang, Hangyu Mao, Pengfei Wan, Ling Pan
  - **institution:** Hong Kong University of Science and Technology, Kuaishou Technology, CUHK MMLab, The University of Edinburgh
  - **link:** https://arxiv.org/pdf/2512.24138
  - **code:** https://tinnerhrhe.github.io/gardo_project
  - **contributions:** 1. Proposed GARDO, a framework with gated regularization that selectively penalizes high-uncertainty samples to mitigate reward hacking efficiently., 2. Introduced an adaptive regularization mechanism that periodically updates the reference model to align with the online policy, enabling effective exploration., 3. Designed a diversity-aware reward amplification strategy to encourage mode coverage and prevent diversity collapse during RL fine-tuning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df8973aa0f222e89b818973c0c7ef576738632b0095b29ac1f837f1a83f47f9b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of reward hacking in RL-fine-tuned diffusion models, where optimizing imperfect proxy rewards degrades real image quality and diversity. The authors propose GARDO, a framework featuring gated, adaptive regularization and diversity-aware optimization to prevent overfitting, maintain exploration, and enhance diversity. Experiments show GARDO effectively mitigates reward hacking and improves generation diversity without sacrificing sample efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GARDO: Reinforcing Diffusion Models without Reward Hacking] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Reward Hacking in RL for Diffusion Models/扩散模型RL中的奖励破解]
        B --> B2[Proxy Reward Mismatch & Mode Collapse/代理奖励不匹配与模式崩溃]
        C --> C1[Gated & Adaptive Regularization/门控自适应正则化]
        C --> C2[Diversity-aware Reward Optimization/多样性感知奖励优化]
        D --> D1[Mitigates Reward Hacking/缓解奖励破解]
        D --> D2[Enhances Diversity & Maintains Efficiency/提升多样性并保持效率]
    ```

- **[arXiv260101] Paired Seed Evaluation: Statistical Reliability for Learning-Based Simulators**
  - **tags:** [ai], [experimental methodology], [paired evaluation, variance reduction, statistical power, random seeds, learning-based simulators]
  - **authors:** Udit Sharma
  - **institution:** IIT Kharagpur
  - **link:** https://arxiv.org/pdf/2512.24145
  - **contributions:** 1. Formalizes a paired seed evaluation design for learning-based simulators, where competing systems are evaluated under identical random seeds to induce matched realizations of stochastic components. 2. Analyzes the statistical structure of comparative evaluation, showing that this design provides strict variance reduction and tighter confidence intervals when outcomes are positively correlated at the seed level. 3. Empirically demonstrates that seed-level correlations are typically large and positive, leading to order-of-magnitude efficiency gains in statistical power and effective sample size compared to independent evaluation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22d4813c6d5407b2660a9657493b8a66ce92b409d971e7a9ac715b6c94922b60_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high variance in evaluating learning-based simulators by proposing a paired seed evaluation design. This method evaluates competing systems under identical random seeds, reducing variance when outcomes are correlated. The main conclusion is that this approach is weakly dominant, improving statistical reliability with efficiency gains when correlation exists and reverting to standard evaluation without loss when it does not.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Paired Seed Evaluation: Statistical Reliability for Learning-Based Simulators] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[评估结果高方差<br>High Variance in Evaluation]
    B --> B2[独立评估设计低效<br>Inefficient Independent Evaluation]
    C --> C1[配对种子评估<br>Paired Seed Evaluation]
    C --> C2[共享随机源<br>Exploit Shared Randomness]
    D --> D1[方差严格降低<br>Strict Variance Reduction]
    D --> D2[统计效能提升<br>Higher Statistical Power]
    D --> D3[效率显著增益<br>Order-of-Magnitude Gains]
    ```

- **[arXiv260101] Deep Global Clustering for Hyperspectral Image Segmentation: Concepts, Applications, and Open Challenges**
  - **tags:** [cv], [hyperspectral image segmentation], [deep global clustering, memory-efficient segmentation, unsupervised disease detection, multi-objective loss balancing]
  - **authors:** Yu-Tang Chang, Pin-Wei Chen, Shih-Fang Chen
  - **institution:** National Taiwan University
  - **link:** https://arxiv.org/pdf/2512.24172
  - **code:** https://github.com/b05611038/HSI_global_clustering
  - **contributions:** 1. Proposed Deep Global Clustering (DGC), a conceptual framework for memory-efficient hyperspectral image segmentation that learns global clustering from local patches without pre-training., 2. Demonstrated the framework's ability to achieve background-tissue separation and unsupervised disease detection on a leaf disease dataset with high efficiency (training &lt;30 min on consumer hardware)., 3. Identified and analyzed the key challenge of optimization instability due to multi-objective loss balancing, positioning the work as intellectual scaffolding for future principled solutions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c5ca8fa4968e4f11184d8faa275b2f2edacdd6e6374072e519e722e16016a06_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the computational bottleneck in hyperspectral image (HSI) analysis by proposing Deep Global Clustering (DGC), a memory-efficient framework that learns global segmentation from local patches without pre-training. It successfully demonstrates background-tissue separation and unsupervised disease detection on agricultural data. However, the main conclusion is that while the design philosophy is promising, the framework suffers from optimization instability due to loss balancing, requiring more principled solutions for stable implementation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deep Global Clustering for Hyperspectral Image Segmentation<br>高光谱图像分割的深度全局聚类] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Computational bottlenecks in HSI analysis<br>Foundation models fail in domain-specific transfer]
        C[主要方法/Method<br>Deep Global Clustering (DGC)<br>Memory-efficient, learns from local patches]
        D[关键结果/Results<br>Achieves background-tissue separation<br>Shows unsupervised disease detection<br>Suffers from optimization instability]
    ```

- **[arXiv260101] Guiding a Diffusion Transformer with the Internal Dynamics of Itself**
  - **tags:** [mlsys], [diffusion models], [Internal Guidance, Diffusion Transformer, Classifier-Free Guidance, Sampling Guidance, Denoising Diffusion]
  - **authors:** Xingyu Zhou, Qifan Li, Xiaobin Hu, Hai Chen, Shuhang Gu
  - **institution:** University of Electronic Science and Technology of China, National University of Singapore, Sun Yat-sen University, North China Institute of Computer Systems Engineering
  - **link:** https://arxiv.org/pdf/2512.24176
  - **contributions:** 1. Proposes Internal Guidance (IG), a novel sampling guidance strategy that uses intermediate-layer outputs within a Diffusion Transformer to improve generation quality. 2. Introduces an auxiliary supervisory signal at an intermediate layer during training and extrapolates outputs during sampling, requiring no extra training, degradation strategies, or additional sampling steps. 3. Demonstrates state-of-the-art performance on ImageNet 256x256, achieving an FID of 1.19 when combined with CFG, and shows significant improvements in training efficiency and generation quality across various baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/605c83917fcbd68353ebfb53e0da152ab446f909b59cdfd81ee3bd6c6023a44f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the issue of standard classifier-free guidance (CFG) causing over-simplified or distorted samples in diffusion models. It proposes Internal Guidance (IG), a simple method that adds auxiliary supervision to an intermediate layer during training and extrapolates outputs during sampling. The method significantly improves generation quality and efficiency, achieving state-of-the-art FID scores on ImageNet.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Guiding a Diffusion Transformer with the Internal Dynamics of Itself] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[标准CFG导致样本过简或失真/Standard CFG leads to over-simplified or distorted samples]
    B --> B2[现有替代方法需要额外训练或步骤/Existing alternatives require extra training or steps]
    C --> C1[提出内部引导/Propose Internal Guidance (IG)]
    C --> C2[训练时中间层辅助监督/Auxiliary supervision on intermediate layer during training]
    C --> C3[采样时输出外推/Extrapolate outputs during sampling]
    D --> D1[显著提升训练效率和生成质量/Significant improvements in training efficiency and generation quality]
    D --> D2[在ImageNet上达到SOTA FID=1.19/Achieves SOTA FID=1.19 on ImageNet]
    ```

- **[arXiv260101] Micro-Macro Tensor Neural Surrogates for Uncertainty Quantification in Collisional Plasma**
  - **tags:** [hpc], [uncertainty quantification], [tensor neural networks, micro-macro decomposition, asymptotic-preserving methods, variance-reduced Monte Carlo, physics-informed neural networks]
  - **authors:** Wei Chen, Giacomo Dimarco, Lorenzo Pareschi
  - **institution:** Xiamen University, University of Ferrara
  - **link:** https://arxiv.org/pdf/2512.24205
  - **contributions:** 1. A variance-reduced Monte Carlo framework for UQ in the Vlasov-Poisson-Landau system that uses neural network surrogates to replace costly collision term evaluations. 2. A generalization of separable physics-informed neural networks (SPINN) into a class of tensor neural networks based on an anisotropic micro-macro decomposition to reduce model complexity and the curse of dimensionality. 3. The calibration of a VPFP surrogate model and the design of an asymptotic-preserving SPINN to increase correlation with the high-fidelity VPL model, ensuring correct recovery of limiting systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b3b7038e3ab35211c6d097f5ecf8a93c74f1b92887ec66726a8e7618764cb3d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of efficient uncertainty quantification in collisional plasma simulations, which is hindered by high computational cost and dimensionality. The authors propose a method that couples a high-fidelity solver with inexpensive neural network surrogates based on tensor networks and a micro-macro decomposition. The results show their framework achieves substantial variance reduction, accurate statistics with fewer samples, and lower computational time compared to standard Monte Carlo.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Micro-Macro Tensor Neural Surrogates for UQ in Collisional Plasma] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[高维相空间与多尺度刚度/High-dimensional phase space & multiscale stiffness]
        B --> B2[碰撞项计算成本高/High cost of collision term evaluation]
        C --> C1[方差缩减蒙特卡洛框架/Variance-reduced Monte Carlo framework]
        C --> C2[基于张量神经网络的代理模型/Tensor neural network surrogates]
        C --> C3[各向异性微宏观分解/Anisotropic micro-macro decomposition]
        D --> D1[方差大幅降低/Substantial variance reduction]
        D --> D2[用更少样本获得准确统计/Accurate statistics with fewer samples]
        D --> D3[更低的计算时间/Lower wall-clock time]
    ```

- **[arXiv260101] Medical Image Classification on Imbalanced Data Using ProGAN and SMA-Optimized ResNet: Application to COVID-19**
  - **tags:** [cv], [medical image classification], [imbalanced data, progressive generative adversarial network (ProGAN), slime mould algorithm (SMA), ResNet, synthetic data generation]
  - **authors:** Sina Jahromi, Farshid Hajati, Alireza Rezaee, Javaher Nourian
  - **institution:** University of Tehran, University of New England
  - **link:** https://arxiv.org/pdf/2512.24214
  - **contributions:** 1. Proposes a Progressive GAN (ProGAN) to generate synthetic medical images to address data imbalance. 2. Introduces a weighted approach for combining synthetic and real data before classification. 3. Employs the Slime Mould Algorithm (SMA), a multi-objective meta-heuristic, to optimize the hyper-parameters of the ResNet classifier.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95bbc93b1f6719a8c5ffdfe98638f4844e331a5a71715b6698a65f669e17f927_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the problem of imbalanced medical image data, particularly for COVID-19 detection from chest X-rays. The proposed method uses a Progressive GAN to generate synthetic data and a weighted combination of real and synthetic data, with a ResNet classifier optimized by the Slime Mould Algorithm. The model achieved high accuracy (95.5% for 4-class, 98.5% for 2-class) on an imbalanced dataset, demonstrating its effectiveness for pandemic-related medical image classification.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Medical Image Classification on Imbalanced Data Using ProGAN and SMA-Optimized ResNet: Application to COVID-19] --> B(核心问题/Problem: 医学图像数据不平衡/Imbalanced Medical Image Data)
    A --> C(主要方法/Method: 使用ProGAN生成数据并用SMA优化ResNet/Use ProGAN for Data Generation and SMA to Optimize ResNet)
    A --> D(关键结果/Results: 在COVID-19胸部X光数据集上取得高准确率/High Accuracy on COVID-19 Chest X-ray Dataset)
    B --> B1(挑战: 疫情中数据集更不平衡/Challenge: Increased Imbalance During Pandemics)
    C --> C1(步骤1: 用ProGAN生成合成数据/Step 1: Generate Synthetic Data with ProGAN)
    C --> C2(步骤2: 加权结合真实与合成数据/Step 2: Weighted Combination of Real and Synthetic Data)
    C --> C3(步骤3: 用SMA优化ResNet超参数/Step 3: Optimize ResNet Hyper-parameters with SMA)
    D --> D1(4分类准确率: 95.5%/4-Class Accuracy: 95.5%)
    D --> D2(2分类准确率: 98.5%/2-Class Accuracy: 98.5%)
    ```

- **[arXiv260101] MotivNet: Evolving Meta-Sapiens into an Emotionally Intelligent Foundation Model**
  - **tags:** [cv], [facial expression recognition], [facial emotion recognition, generalization, foundation model, masked autoencoder, downstream task]
  - **authors:** Rahul Medicharla, Alper Yilmaz
  - **institution:** The Ohio State University
  - **link:** https://arxiv.org/pdf/2512.24231
  - **code:** https://github.com/OSUPCVLab/EmotionFromFaceImages
  - **contributions:** 1. Proposes MotivNet, a novel FER model built on the Meta-Sapiens foundation model to achieve strong generalization without cross-domain training. 2. Defines and applies three criteria (benchmark performance, model similarity, data similarity) to validate a new downstream task for the Sapiens foundation model. 3. Demonstrates that the proposed approach achieves competitive performance across diverse datasets, making FER more viable for real-world, in-the-wild applications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81d3ca85dac4626b7644912941beba01e188b0d41eefb51c00fdb16cd74177b8_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces MotivNet, a facial emotion recognition model that uses the Meta-Sapiens foundation model as a backbone to achieve strong generalization across datasets without requiring cross-domain training. The authors validate MotivNet as a suitable downstream task for Sapiens using specific criteria and show it achieves competitive performance. The work aims to make FER more robust and applicable in real-world scenarios.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[MotivNet: Evolving Meta-Sapiens into an Emotionally Intelligent Foundation Model] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[FER模型泛化能力弱 / Poor generalization of FER models]
        P1 --> P2[跨域训练不切实际 / Cross-domain training is impractical]
        Method[主要方法/Method] --> M1[使用Sapiens作为主干 / Use Sapiens as backbone]
        M1 --> M2[定义下游任务评估标准 / Define downstream task evaluation criteria]
        Results[关键结果/Results] --> R1[跨数据集具有竞争力 / Competitive across datasets]
        R1 --> R2[验证为有效的下游任务 / Validated as a viable downstream task]
    ```

- **[arXiv260101] Early Prediction of Sepsis using Heart Rate Signals and Genetic Optimized LSTM Algorithm**
  - **tags:** [mlsys], [on-device ai], [Genetic Algorithm, LSTM, Wearable Device, Transfer Learning, Heart Rate Signals]
  - **authors:** Alireza Rafiei, Farshid Hajati, Alireza Rezaee, Amirhossien Panahi, Shahadat Uddin
  - **institution:** University of Tehran, University of New England, The University of Sydney
  - **link:** https://arxiv.org/pdf/2512.24253
  - **contributions:** 1. Developed and optimized four machine learning models (LGB, MLP, LSTM, LSTM-FCN) for early sepsis prediction specifically for deployment on wearable devices. 2. Used a genetic algorithm to refine the model architectures, optimizing for performance, computational complexity, and memory requirements suitable for wearables. 3. Extended the prediction window from one hour to four hours using transfer learning, demonstrating adaptability for longer-term forecasting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1495386bf6867b81b1a66ce95759268f2ed495c711dc3b4668583fc8a9c26b95_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes using genetic algorithm-optimized machine learning models to predict sepsis early by analyzing heart rate data from wearable devices. The models are designed for computational efficiency on wearables and were extended to a four-hour prediction window via transfer learning. The results show promise for enabling early sepsis detection outside of intensive care settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Early Prediction of Sepsis using Heart Rate Signals and Genetic Optimized LSTM Algorithm") --> Problem
        Root --> Method
        Root --> Results
        Problem("核心问题/Problem: Early sepsis detection outside ICU settings")
        Method("主要方法/Method: Genetic algorithm-optimized ML models for wearables")
        Results("关键结果/Results: Promising potential for wearable-based early detection")
    ```

- **[arXiv260101] Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem**
  - **tags:** [ai], [reinforcement learning], [Fleet Size and Mix Vehicle Routing Problem (FSMVRP), deep reinforcement learning (DRL), Markov Decision Process (MDP), fleet-and-route integrated policy network (FRIPN), remaining graph embedding]
  - **authors:** Pengfu Wan, Jiawei Chen, Gangyan Xu
  - **institution:** The Hong Kong Polytechnic University
  - **link:** https://arxiv.org/pdf/2512.24251
  - **contributions:** 1. Formulates the Fleet Size and Mix Vehicle Routing Problem (FSMVRP) as a Markov Decision Process (MDP) for a deep reinforcement learning approach. 2. Proposes a novel policy network (FRIPN) that integrates fleet composition and routing decisions into a single model. 3. Introduces specialized input embeddings, including a remaining graph embedding, to enhance decision-making for vehicle employment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3969891b48accce35280355d106951820196973739958b782a307a2a3df23aa3_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a deep reinforcement learning method to solve the complex Fleet Size and Mix Vehicle Routing Problem (FSMVRP). The core innovation is a policy network called FRIPN that jointly decides on fleet composition and routing. Experiments show the method is computationally efficient and scalable, producing near-optimal solutions quickly, especially for large-scale problems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem] --> B(核心问题/Problem: FSMVRP - simultaneous fleet composition & routing)
        A --> C(主要方法/Method: DRL-based MDP formulation with FRIPN policy network & remaining graph embedding)
        A --> D(关键结果/Results: Near-optimal solutions in seconds, high computational efficiency & scalability)
    ```

- **[arXiv260101] Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning**
  - **tags:** [mlsys], [llm training], [data selection, policy gradient, mask learning, quality-diversity trade-off, FineWeb]
  - **authors:** Ziqing Fan, Yuqiao Xian, Yan Sun, Li Shen
  - **institution:** ByteDance Seed, Shanghai Jiao Tong University, University of Sydney, Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.24265
  - **code:** https://github.com/ByteDance-Seed/DATAMASK
  - **contributions:** 1. Introduces DATAMASK, a novel joint learning framework for large-scale pre-training data selection that simultaneously optimizes quality and diversity metrics. 2. Formulates data selection as a mask learning problem and solves it efficiently using policy gradient-based optimization with acceleration enhancements, reducing selection time by 98.9% compared to greedy algorithms. 3. Creates and releases FineWeb-Mask, a high-quality and diverse 10% subset of the 15-trillion-token FineWeb dataset, which significantly improves model performance (e.g., +3.2% on a 1.5B model) across diverse tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02fd504349b8c0bb1934304d821a648ed4ca490b2f41e136f9b7a6220f39d5d2_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of efficiently selecting high-quality and diverse data for large-scale LLM pre-training, where traditional methods are costly and suboptimal. It proposes DATAMASK, a policy gradient-based framework that learns optimal data masks to jointly optimize quality and diversity, drastically speeding up selection. The resulting curated dataset, FineWeb-Mask, leads to significant performance gains in pre-trained models, demonstrating the framework's effectiveness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 大规模预训练数据中，联合考虑质量与多样性指标进行样本选择计算成本过高]
        C[主要方法/Method: 提出DATAMASK框架，将选择过程视为掩码学习问题，使用策略梯度进行优化]
        D[关键结果/Results: 选择时间减少98.9%，从FineWeb中选出的子集显著提升多种模型性能]
    ```

- **[arXiv260101] Empower Low-Altitude Economy: A Reliability-Aware Dynamic Weighting Allocation for Multi-modal UAV Beam Prediction**
  - **tags:** [mlsys], [multi-modal inference], [reliability-aware dynamic weighting, cross-modal contrastive learning, semantic-aware beam prediction, low-altitude UAV, multi-modal learning]
  - **authors:** Haojin Li, Anbang Zhang, Chen Sun, Chenyuan Feng, Kaiqian Qu, Tony Q. S. Quek, Haijun Zhang
  - **institution:** University of Science and Technology Beijing, Sony China Research Laboratory, Shandong University, Southeast University, University of Exeter, Singapore University of Technology and Design
  - **link:** https://arxiv.org/pdf/2512.24324
  - **contributions:** 1. Proposes a reliability-aware dynamic weighting scheme that adaptively allocates contributions across different modalities (e.g., visual, posture, geospatial) based on their instantaneous reliability, moving beyond fixed-weight approaches. 2. Introduces a semantic-aware multi-modal beam prediction framework (SaM²B) that uses cross-modal contrastive learning to align multi-source representations into a shared semantic space, enhancing robustness to noise and distribution shifts. 3. Validates the proposed SaM²B framework on real-world low-altitude UAV datasets, demonstrating superior performance over baseline methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1fa219c5db4bfd0eeac8ee93679e8eba9ceb6e2e5ce7336d45afc6686f1d8162_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of unreliable beam prediction in multi-modal UAV communications caused by static weighting and modal misalignment. It proposes SaM²B, a framework that uses reliability-aware dynamic weighting and cross-modal contrastive learning to adaptively fuse modalities and align their semantics. Experiments on real-world datasets show SaM²B outperforms existing baseline methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Empower Low-Altitude Economy: A Reliability-Aware Dynamic Weighting Allocation for Multi-modal UAV Beam Prediction] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[静态权重与模态失配/Static Weighting & Modal Mismatch]
        B --> B2[跨场景泛化弱/Weak Cross-Scenario Generalization]
        C --> C1[可靠性感知动态加权/Reliability-Aware Dynamic Weighting]
        C --> C2[跨模态对比学习/Cross-Modal Contrastive Learning]
        C --> C3[语义感知多模态框架/Semantic-Aware Multi-Modal Framework (SaM²B)]
        D --> D1[真实数据集验证/Validated on Real-World UAV Datasets]
        D --> D2[优于基线方法/Superior to Baseline Methods]
    ```

- **[arXiv260101] MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems**
  - **tags:** [mlsys], [agent system], [Multi-Agent Reinforcement Learning, Centralized Training with Decentralized Execution (CTDE), Model Predictive Control (MPC), Dynamic Computation Allocation, Recommender Systems]
  - **authors:** Wan Jiang, Xinyi Zang, Yudong Zhao, Yusi Zou, Yunfei Lu, Junbo Tong, Yang Liu, Ming Li, Jiani Shi, Xin Yang
  - **institution:** JD.com, Tsinghua University
  - **link:** https://arxiv.org/pdf/2512.24325
  - **contributions:** 1. Proposes MaRCA, a multi-agent reinforcement learning framework that models recommender system stages as cooperative agents for end-to-end computation resource allocation. 2. Introduces an AutoBucket TestBench for accurate computation cost estimation in large-scale systems. 3. Designs a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5648d9986b292c2db26fc1ddb4325c3fc0f14c6516ddecf792ceaf524e365c4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of dynamic computation allocation in large-scale, multi-stage recommender systems under resource constraints. It proposes MaRCA, a multi-agent reinforcement learning framework that uses Centralized Training with Decentralized Execution (CTDE) and integrates a Model Predictive Control-based balancer to optimize revenue. The system was deployed on a major e-commerce platform, handling hundreds of billions of daily requests and achieving a 16.67% revenue uplift using existing resources.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MaRCA: Multi-Agent RL for Dynamic Computation Allocation] --> B[核心问题/Problem: 大规模推荐系统中，模型复杂度和流量规模增长带来的计算挑战，现有方法忽略阶段间依赖，限制全局最优性。]
        A --> C[主要方法/Method: 提出MaRCA框架，将推荐系统阶段建模为合作智能体，使用CTDE进行训练，并引入AutoBucket TestBench和基于MPC的收益-成本平衡器。]
        A --> D[关键结果/Results: 在领先的全球电商平台广告管线中端到端部署，每日处理数千亿广告请求，使用现有计算资源实现16.67%的收益提升。]
    ```

- **[arXiv260101] Tubular Riemannian Laplace Approximations for Bayesian Neural Networks**
  - **tags:** [ai], [bayesian deep learning], [Laplace approximation, Riemannian geometry, uncertainty quantification, Bayesian neural networks, model calibration]
  - **authors:** Rodrigo Pereira David
  - **institution:** National Institute of Metrology, Technology and Quality (Inmetro)
  - **link:** https://arxiv.org/pdf/2512.24381
  - **contributions:** 1. Introduces the Tubular Riemannian Laplace (TRL) approximation, a novel method that models the posterior as a probabilistic tube following low-loss valleys induced by functional symmetries. 2. Proposes using a Fisher/Gauss-Newton metric to separate prior-dominated tangential uncertainty from data-dominated transverse uncertainty, adapting to the anisotropic, curved loss surfaces of deep models. 3. Demonstrates empirically that TRL achieves calibration comparable to Deep Ensembles on ResNet-18 (CIFAR-10/100) at a fraction (1/5) of the training cost, bridging single-model efficiency with ensemble-grade reliability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbef449cd138ae804891e277de76405797dfc3e78511bcb03bf13e56823c9746_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the poor calibration of traditional Euclidean Laplace approximations in Bayesian Neural Networks. It proposes the Tubular Riemannian Laplace (TRL) approximation, which models the posterior as a tube using a Riemannian metric to better capture parameter space geometry. The method achieves excellent uncertainty calibration on image classification tasks, matching Deep Ensembles' reliability with significantly lower computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Tubular Riemannian Laplace Approximations<br>管状黎曼拉普拉斯近似] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统拉普拉斯近似在深度模型中校准不佳<br>Traditional Laplace approximations struggle with calibration in deep models]
        C --> C1[提出管状黎曼拉普拉斯(TRL)近似<br>Propose Tubular Riemannian Laplace (TRL) approximation]
        C1 --> C2[使用Fisher/Gauss-Newton度量建模概率管<br>Model probabilistic tube using Fisher/Gauss-Newton metric]
        D --> D1[在ResNet-18上实现优秀校准<br>Achieves excellent calibration on ResNet-18]
        D1 --> D2[匹配集成方法可靠性，成本仅1/5<br>Matches ensemble reliability at 1/5 training cost]
    ```

- **[arXiv260101] Lifting Vision: Ground to Aerial Localization with Reasoning Guided Planning**
  - **tags:** [cv], [cross-view geo-localization], [visual reasoning, reinforcement learning, contrastive learning, cross-view alignment, visual planning]
  - **authors:** Soham Pahari, M. Srinivas
  - **institution:** UPES (School of Computer Science), NIT Warangal (Department of CS&E)
  - **link:** https://arxiv.org/pdf/2512.24404
  - **contributions:** 1. Proposes a novel visual reasoning paradigm called Geo-Consistent Visual Planning and a framework named ViReLoc for planning and localization using only visual representations. 2. Introduces a method that learns spatial and geometric dependencies through step-by-step visual inference optimized with reinforcement learning objectives. 3. Integrates contrastive learning and adaptive feature interaction to align ground and aerial perspectives and reduce viewpoint differences.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d4164fa0c19f567cf79df4a59a8129e5b520a00f0d6456c7d4f5649d4a580da_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of text-based reasoning in spatial tasks by proposing ViReLoc, a visual reasoning framework for ground-to-aerial localization and route planning. The method uses reinforcement learning and contrastive learning to perform inference directly in the visual domain without relying on GPS. Experiments show improved spatial reasoning and cross-view retrieval, establishing visual reasoning as a secure complementary approach for navigation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Lifting Vision: Ground to Aerial Localization with Reasoning Guided Planning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[文本推理在空间任务中的局限性<br/>Limitations of Text-Based Reasoning in Spatial Tasks]
        C --> C1[视觉推理框架ViReLoc<br/>Visual Reasoning Framework ViReLoc]
        C1 --> C2[Geo-Consistent Visual Planning<br/>Geo-Consistent Visual Planning]
        C1 --> C3[强化学习与对比学习<br/>Reinforcement & Contrastive Learning]
        D --> D1[空间推理与跨视图检索性能提升<br/>Improved Spatial Reasoning & Cross-View Retrieval]
        D --> D2[无需GPS的安全导航方案<br/>Secure Navigation Without GPS]
    ```

- **[arXiv260101] Efficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models**
  - **tags:** [ai], [reinforcement learning], [inverse reinforcement learning, dynamic discrete choice, semiparametric inference, debiased machine learning, efficient influence function]
  - **authors:** Lars van der Laan, Aurelien Bibaut, Nathan Kallus
  - **institution:** University of Washington, Netflix Research, Cornell University
  - **link:** https://arxiv.org/pdf/2512.24407
  - **contributions:** 1. Introduced a semiparametric framework for debiased inverse reinforcement learning that enables statistically efficient inference for reward-dependent functionals. 2. Showed that the log-behavior policy acts as a pseudo-reward that identifies policy value differences and, with normalization, the reward itself, formalizing these as smooth functionals. 3. Constructed automatic debiased machine-learning estimators that allow flexible nonparametric nuisance estimation while achieving √n-consistency, asymptotic normality, and semiparametric efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f071bfe838a84ec68caefb3e8f32ddce9a94446707278cc78a1f8f23d2b1cdcf_w640_q70.webp
  - **Simple LLM Summary:** This paper develops a unified semiparametric framework for inference in inverse reinforcement learning and dynamic discrete choice models. The method leverages the log-behavior policy as a pseudo-reward and constructs debiased machine learning estimators, enabling flexible nonparametric estimation while providing statistical guarantees like asymptotic normality and efficiency. The framework bridges classical econometric inference with modern machine learning tools for sequential decision-making problems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Efficient Inference for IRL and DDC Models] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Flexible IRL lacks inference guarantees;<br>Classical DDC is restrictive & computationally heavy]
        C[主要方法/Method<br>Semiparametric debiased IRL framework;<br>Log-behavior policy as pseudo-reward;<br>Automatic debiased ML estimators]
        D[关键结果/Results<br>√n-consistent, asymptotically normal,<br>semiparametrically efficient inference;<br>Unified, tractable approach]
    ```

- **[arXiv260101] Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics**
  - **tags:** [ai], [adaptive learning], [bias-noise-alignment, diagnostic-driven adaptation, temporal-difference error, stabilized optimizer, actor-critic]
  - **authors:** Akash Samanta, Sheldon Williamson
  - **institution:** Ontario Tech University
  - **link:** https://arxiv.org/pdf/2512.24445
  - **contributions:** 1. Proposes a novel diagnostic-driven adaptive learning framework that decomposes error evolution into bias, noise, and alignment components. 2. Derives and instantiates the framework across multiple learning paradigms, including supervised optimization, actor-critic RL, and learned optimizers. 3. Establishes theoretical stability guarantees and bounded updates for the proposed diagnostic-driven methods under standard assumptions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fffef5a11b6873e7029659f1544c8ea507323fdf48462b3c7caeee1ffd63e30_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of unstable and slow learning in nonstationary environments by proposing a new framework that models error evolution through bias, noise, and alignment diagnostics. The method uses these online-computed diagnostics to guide and stabilize learning in optimization, reinforcement learning, and meta-learning. The work provides a unifying, interpretable foundation for reliable adaptation in dynamic settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics] --> B(核心问题/Problem: Learning instability in nonstationary environments)
        A --> C(主要方法/Method: Diagnostic-driven framework decomposing error into bias, noise, alignment)
        A --> D(关键结果/Results: Unifying control backbone for optimization/RL/learned optimizers with stability guarantees)
    ```

- **[arXiv260101] Sparse classification with positive-confidence data in high dimensions**
  - **tags:** [ai], [weakly-supervised learning], [Pconf classification, sparse regularization, Lasso, SCAD, MCP]
  - **authors:** Tien Mai, Mai Anh Nguyen, Trung Nghia Nguyen
  - **institution:** Norwegian Institute of Public Health, Seoul National University, Rutgers University
  - **link:** https://arxiv.org/pdf/2512.24443
  - **contributions:** 1. Proposes a novel sparse-penalization framework for high-dimensional Positive-Confidence (Pconf) classification, bridging weak supervision and high-dimensional statistics. 2. Introduces estimators using both convex (Lasso) and non-convex (SCAD, MCP) penalties to address shrinkage bias and improve feature recovery. 3. Establishes theoretical error bounds for the L1-regularized estimator and develops an efficient proximal gradient algorithm to solve the composite objective.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d4d37b85ea25099bdc6c46c973123d1cadddc0454b10411668cb1a47bc23596_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of performing sparse classification in high-dimensional settings using only positive samples with confidence scores (Pconf data). It proposes a new framework using Lasso, SCAD, and MCP penalties for variable selection and develops an efficient algorithm. The method achieves performance comparable to fully supervised approaches, effectively bridging weak supervision and high-dimensional learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Sparse classification with positive-confidence data in high dimensions] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[High-dim weak-supervised learning<br>高维弱监督学习]
        B --> B2[Existing Pconf methods ill-suited<br>现有Pconf方法不适用]
        C --> C1[Sparse-penalization framework<br>稀疏惩罚框架]
        C --> C2[Convex & non-convex penalties<br>凸与非凸惩罚项]
        C --> C3[Proximal gradient algorithm<br>近端梯度算法]
        D --> D1[Near minimax-optimal recovery<br>接近极小极大最优恢复]
        D --> D2[Comparable to supervised methods<br>性能媲美全监督方法]
    ```

- **[arXiv260101] Generative forecasting with joint probability models**
  - **tags:** [ai], [probabilistic forecasting], [joint probability distribution, generative model, uncertainty quantification, chaotic dynamical systems, Wasserstein drift]
  - **authors:** Patrick Wyrod, Ashesh Chattopadhyay, Daniele Venturi
  - **institution:** University of California Santa Cruz
  - **link:** https://arxiv.org/pdf/2512.24446
  - **contributions:** 1. Reframes forecasting as a fully generative problem by learning the joint probability distribution of system states over temporal windows and obtaining forecasts via marginalization. 2. Introduces a general, model-agnostic training and inference framework for joint generative forecasting. 3. Proposes three complementary uncertainty quantification metrics (ensemble variance, short-horizon autocorrelation, cumulative Wasserstein drift) to assess forecast robustness without ground truth.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95523ae23ff02d01f3cc01323f495f300ee24988a99409698e6d43daf9c09a82_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new generative forecasting method that learns the joint probability distribution of system states over time windows, rather than just next-step predictions. This approach better captures temporal dependencies and dynamics, leading to improved short-term predictions and more accurate long-term statistical behavior for chaotic systems like Lorenz-63 and Kuramoto-Sivashinsky, as demonstrated by several uncertainty metrics.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Generative forecasting with joint probability models] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[确定性预测有限/Deterministic forecasting limited for chaotic systems]
        B --> B2[现有方法关注下一步预测/Existing methods focus on next-step prediction]
        C --> C1[学习联合概率分布/Learn joint probability distribution of lagged states]
        C --> C2[通过边缘化进行预测/Forecast via marginalization]
        C --> C3[模型无关框架/Model-agnostic framework]
        D --> D1[改进短期预测技能/Improved short-term predictive skill]
        D --> D2[保持吸引子几何/Preserve attractor geometry]
        D --> D3[更准确的长程统计行为/More accurate long-range statistical behavior]
    ```

- **[arXiv260101] Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations**
  - **tags:** [sec], [semantic communications], [min-max optimization, adversarial perturbations, multi-task learning]
  - **authors:** Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus
  - **institution:** Nexcepta, The Ohio State University, University of Maryland
  - **link:** https://arxiv.org/pdf/2512.24452
  - **contributions:** 1. A deep learning-based semantic communication framework that jointly supports multiple receiver tasks (e.g., inference and reconstruction) while explicitly limiting semantic information leakage to an eavesdropper. 2. Formulation of the privacy problem as an iterative min-max optimization, where the legitimate transmitter-receiver pair is trained to degrade an adaptive eavesdropper's semantic inference performance. 3. Introduction of an auxiliary adversarial perturbation layer that superimposes a crafted signal on the transmitted waveform to degrade eavesdropper performance, even when the legitimate link is not co-trained against it.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25e9c394c6a473f54b07d7337b43fb693f3ebef1de80e7b275ea3c91df03de11_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses privacy leakage in semantic communications, where task-optimized representations can be exploited by eavesdroppers. The proposed method uses a min-max adversarial training framework and an auxiliary perturbation layer to protect semantic information. Evaluations on image datasets show the approach significantly reduces eavesdropper inference accuracy without harming legitimate receiver performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Semantic representations leak sensitive information to eavesdroppers] --> Problem_Detail[语义泄露/Semantic Leakage]
        Method[主要方法/Method: Deep learning framework with min-max optimization and adversarial perturbations] --> Method_Detail1[对抗训练/Min-Max Optimization]
        Method --> Method_Detail2[扰动层/Perturbation Layer]
        Results[关键结果/Results: Reduces eavesdropper accuracy, maintains legitimate performance] --> Results_Detail[有效隐私保护/Effective Privacy Preservation]
    ```

- **[arXiv260101] Spectral and Spatial Graph Learning for Multispectral Solar Image Compression**
  - **tags:** [cv], [image compression], [graph neural network, multispectral image compression, spectral graph embedding, spatial graph attention, learned image compression]
  - **authors:** Prasiddha Siwakoti, Atefeh Khoshkhahtinat, Piyush M. Mehta, Barbara J. Thompson, Michael S. F. Kirk, Daniel da Silva
  - **institution:** West Virginia University, NASA Goddard Space Flight Center
  - **link:** https://arxiv.org/pdf/2512.24463
  - **code:** https://github.com/agyat4/sgraph
  - **contributions:** 1. Proposed an Inter-Spectral Windowed Graph Embedding (iSWGE) module to model inter-band relationships by representing spectral channels as graph nodes with learned edges. 2. Introduced a Windowed Spatial Graph Attention and Convolutional Block Attention (WSGA-C) module to reduce spatial redundancy and emphasize fine-scale structures. 3. Developed a learned image compression framework tailored for multispectral solar imagery, achieving improved spectral fidelity and reconstruction quality on the SDOML dataset.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22141561baf730c3986a8299115f064f9a3f82996264d04ebeefffad89a18be1_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of compressing high-volume multispectral solar imagery for space missions. It proposes a learned compression framework that uses two novel graph-based modules to model spectral and spatial dependencies. The method demonstrates improved performance in preserving spectral information and reconstruction quality compared to strong baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题: Spectral and Spatial Graph Learning for Multispectral Solar Image Compression] --> B(核心问题/Problem: High-fidelity compression of multispectral solar imagery with limited bandwidth)
        A --> C(主要方法/Method: Two complementary graph learning modules: iSWGE for spectral, WSGA-C for spatial dependencies)
        A --> D(关键结果/Results: 20.15% MSID reduction, up to 1.09% PSNR gain, 1.62% MS-SSIM gain)
    ```

- **[arXiv260101] HOLOGRAPH: Active Causal Discovery via Sheaf-Theoretic Alignment of Large Language Model Priors**
  - **tags:** [ai], [causal discovery], [sheaf theory, large language models, natural gradient descent, algebraic latent projection, presheaf]
  - **authors:** Hyunjun Kim
  - **institution:** Korea Advanced Institute of Science and Technology (KAIST), École Polytechnique Fédérale de Lausanne (EPFL)
  - **link:** https://arxiv.org/pdf/2512.24478
  - **code:** https://github.com/hyunjun1121/holograph
  - **contributions:** 1. A sheaf-theoretic framework formalizing LLM-guided causal discovery as a presheaf satisfaction problem. 2. A natural gradient descent algorithm on the belief manifold for principled optimization. 3. The introduction of Algebraic Latent Projection to handle hidden confounders.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68eaf3f0002711b7e42d725e2a453cb23c5db4c9ca0b3a10f0290cfce9779f2e_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces HOLOGRAPH, a framework that uses sheaf theory to formally integrate Large Language Model priors for causal discovery, addressing issues of coherence and hidden confounders. It proposes novel methods like Algebraic Latent Projection and natural gradient optimization. The approach provides a rigorous mathematical foundation and shows competitive performance, while analysis reveals a failure of the Locality axiom in larger graphs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HOLOGRAPH] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[因果发现受可识别性限制/Causal discovery limited by identifiability]
        B --> B2[现有LLM方法缺乏理论基础/Existing LLM methods lack theory]
        C --> C1[层理论框架/Sheaf-theoretic framework]
        C --> C2[代数潜在投影/Algebraic Latent Projection]
        C --> C3[自然梯度下降/Natural Gradient Descent]
        D --> D1[提供数学基础/Provides mathematical foundation]
        D --> D2[性能有竞争力/Achieves competitive performance]
        D --> D3[局部性公理失效/Locality axiom fails for large graphs]
    ```

- **[arXiv260101] What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?**
  - **tags:** [ai], [world models], [joint-embedding predictive architecture, representation space planning, model-based reinforcement learning]
  - **authors:** Basile Terver, Tsung-Yen Yang, Jean Ponce, Adrien Bardes, Yann LeCun
  - **institution:** Meta FAIR, INRIA Paris, Ecole normale supérieure/PSL, New York University
  - **link:** https://arxiv.org/pdf/2512.24497
  - **code:** https://github.com/facebookresearch/jepa-wms
  - **contributions:** 1. Proposes a comprehensive characterization and study of Joint-Embedding Predictive Architecture World Models (JEPA-WMs) for physical planning. 2. Systematically investigates the impact of model architecture, training objective, and planning algorithm on planning success in simulated and real-world robotic tasks. 3. Combines the findings to propose a new model that outperforms established baselines (DINO-WM and V-JEPA-2-AC) in navigation and manipulation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3be3154d136e165197c022f619cd1d45cd62098d7f202059d7110d6335e67c44_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the key factors for successful physical planning using Joint-Embedding Predictive World Models (JEPA-WMs). It conducts a systematic study of architectural and algorithmic choices within this family of methods and proposes a new model that achieves superior performance on navigation and manipulation tasks compared to existing baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[What Drives Success in Physical Planning with JEPA-WMs?] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br>How to build agents that generalize to new physical tasks?]
        Method[主要方法/Method<br>Study JEPA-WMs: architecture, objective, planning algorithm]
        Results[关键结果/Results<br>Proposed model outperforms baselines (DINO-WM, V-JEPA-2-AC)]
    ```

- **[arXiv260101] Can Small Training Runs Reliably Guide Data Curation? Rethinking Proxy-Model Practice**
  - **tags:** [mlsys], [llm training], [proxy models, data curation, hyperparameter tuning, learning rate, pretraining]
  - **authors:** Jiachen T. Wang, Tong Wu, Kaifeng Lyu, James Zou, Dawn Song, Ruoxi Jia, Prateek Mittal
  - **institution:** Princeton University, Tsinghua University, Stanford University, UC Berkeley, Virginia Tech
  - **link:** https://arxiv.org/pdf/2512.24503
  - **contributions:** 1. Identifies a critical flaw in the standard proxy-model evaluation protocol, showing that using a fixed training configuration for all data recipes leads to unreliable conclusions that can flip with minor hyperparameter changes. 2. Proposes a simple and effective patch to the protocol: training proxy models with reduced learning rates, which preserves the relative performance ranking of data recipes and correlates strongly with fully-tuned large-scale training. 3. Provides theoretical justification for the proposed method by proving it preserves dataset ordering for random-feature models, and validates it empirically across 23 data recipes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0253b877f5ec90fd3f09b9d1a8f7d0967a88407fbbd25eb1e8a8bfcdf23081c4_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that the standard practice of using small proxy models with identical hyperparameters to evaluate data recipes is unreliable because optimal training configurations are data-dependent. To fix this, the authors propose training proxy models with reduced learning rates, a simple change that makes small-scale experiment rankings strongly correlate with those from fully-tuned large-scale LLM pretraining. This method is theoretically justified and empirically validated, dramatically improving the reliability of data curation guidance from small training runs.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Can Small Training Runs Reliably Guide Data Curation? Rethinking Proxy-Model Practice] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[固定配置评估不可靠/Fixed-config evaluation unreliable]
        Problem --> P2[结论随超参翻转/Conclusions flip with hyperparams]
        Method[主要方法/Method] --> M1[降低学习率训练代理模型/Train proxy models with reduced LR]
        Method --> M2[数据特定调优目标/Data-specific tuning objective]
        Results[关键结果/Results] --> R1[与大规模训练强相关/Strong correlation with large-scale training]
        Results --> R2[理论证明与实证验证/Theoretical proof & empirical validation]
    ```

- **[arXiv260101] Generalising E-prop to Deep Networks**
  - **tags:** [ai], [biologically plausible learning algorithms], [E-prop, eligibility traces, credit assignment, recurrent neural networks, backpropagation through time]
  - **authors:** Beren Millidge
  - **institution:** Zyphra
  - **link:** https://arxiv.org/pdf/2512.24506
  - **contributions:** 1. Extends the E-prop framework to handle arbitrarily deep networks, enabling credit assignment across both time and depth. 2. Derives a novel recursion relationship across depth that generalizes eligibility traces to deeper layers. 3. Demonstrates an online learning algorithm capable of training deep recurrent networks without backpropagation through time.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6eda8a1b73fb9e52a5baf437a42dfe8578438c0dde5dfa6d166ba856f037f47_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the biological implausibility of Backpropagation Through Time (BPTT) for training recurrent neural networks. It proposes an extension of the E-prop algorithm to deep networks, enabling online credit assignment across both time and depth. The main conclusion is that this method allows for the training of deep recurrent networks without BPTT.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Generalising E-prop to Deep Networks") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("BPTT生物不可信/BPTT biologically implausible")
        Problem --> P2("RTRL计算复杂/RTRL computationally expensive")
        Problem --> P3("现有方法局限于单层/Existing methods limited to single layer")
        Method --> M1("扩展E-prop框架/Extend E-prop framework")
        Method --> M2("推导跨深度的递归关系/Derive depth-wise recursion")
        Method --> M3("推广资格迹到深层/Generalize eligibility traces to deep layers")
        Results --> R1("实现跨时空的在线信用分配/Online credit assignment across time and depth")
        Results --> R2("无需BPTT训练深度循环网络/Train deep recurrent networks without BPTT")
    ```

- **[arXiv260101] A Graph Neural Network with Auxiliary Task Learning for Missing PMU Data Reconstruction**
  - **tags:** [ai], [graph neural networks], [graph neural network, auxiliary task learning, missing data reconstruction, spatial-temporal dependencies, low-rank property]
  - **authors:** Bo Li, Zijun Chen, Haiwang Zhong, Di Cao, Guangchun Ruan
  - **institution:** Tsinghua University (inferred from IEEE affiliations and common institutional patterns for authors Bo Li, Haiwang Zhong, Di Cao, Guangchun Ruan)
  - **link:** https://arxiv.org/pdf/2512.24542
  - **contributions:** 1. Proposes a K-hop GNN that operates directly on the subgraph of observable PMU nodes, enabling learning under incomplete system observability. 2. Designs an auxiliary learning framework with two complementary GNNs: a spatial-temporal GNN for reconstruction and an auxiliary GNN for unsupervised online learning using the low-rank property of data. 3. Demonstrates that the method dynamically leverages low-rank properties across the architecture to achieve robustness and self-adaptation, showing superior performance under high missing rates and incomplete observability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0bb99f00deaaada2673c4fa2deba197e3de14c9c3164c0d055378a9290049033_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of reconstructing missing data from Phasor Measurement Units (PMUs) in power systems, which is critical for grid monitoring. The proposed method uses a Graph Neural Network with Auxiliary Task Learning, combining a spatial-temporal GNN for reconstruction with an auxiliary GNN for online adaptation using data's low-rank properties. The results show the method is robust under high missing rates and incomplete system observability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Graph Neural Network with Auxiliary Task Learning for Missing PMU Data Reconstruction<br>基于辅助任务学习的图神经网络用于PMU缺失数据重构"]
        Root --> Problem["核心问题/Problem<br>PMU数据因故障、攻击等缺失，现有方法对概念漂移适应性差、高缺失率下鲁棒性弱、依赖全系统可观性假设"]
        Root --> Method["主要方法/Method<br>提出K跳GNN在PMU子图上学习；设计辅助学习框架，包含时空GNN和利用数据低秩特性的辅助GNN"]
        Root --> Results["关键结果/Results<br>在高缺失率和不完全可观性下，方法展现出优越的离线和在线性能"]
    ```

- **[arXiv260101] More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [extreme quantization, double binary factorization, low-bit LLM, post-training quantization, binary matrix multiplication]
  - **authors:** Yuma Ichikawa, Yoshihiko Fujisawa, Yudai Fujimoto, Akira Sakai, Katsuki Fujisawa
  - **institution:** Fujitsu Limited, RIKEN Center for AIP, Institute of Science Tokyo, Tokai University
  - **link:** https://arxiv.org/pdf/2512.24545
  - **contributions:** 1. Proposed Multi-Envelope Double Binary Factorization (MDBF), which replaces the single magnitude envelope in DBF with a rank-l envelope to enhance magnitude expressiveness while maintaining a shared binary sign carrier. 2. Introduced a closed-form initialization and an alternating refinement method to effectively optimize the MDBF parameters. 3. Demonstrated that MDBF improves perplexity and zero-shot accuracy over prior binary formats on LLaMA and Qwen models at matched bit budgets while preserving the same efficient inference primitive.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e17ec329eb54b789cd97cf9a3fc6db67786908aca3eb86af65de80d0797eb12_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the performance saturation of Double Binary Factorization (DBF) in extreme low-bit quantization of LLMs, where a single magnitude envelope limits expressiveness. It proposes Multi-Envelope DBF (MDBF), which uses multiple envelope components to allocate more expressivity to magnitudes while keeping binary sign matrices shared. Experiments on LLaMA and Qwen families show MDBF outperforms previous binary formats in accuracy and perplexity at the same bit rate without changing the inference primitive.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>DBF scaling too restrictive,<br>single envelope causes<br>performance saturation"]
        Method["主要方法/Method<br>Propose MDBF: shared 1-bit sign bases,<br>replace single envelope with<br>rank-l envelope"]
        Results["关键结果/Results<br>Better perplexity & accuracy<br>over previous binary formats,<br>same inference primitive"]
    ```

- **[arXiv260101] From Perception to Punchline: Empowering VLM with the Art of In-the-wild Meme**
  - **tags:** [ai], [multimodal generation], [vision-language models, chain-of-thought, reinforcement learning from human feedback]
  - **authors:** Xueyan Li, Yingyi Xue, Mengjie Jiang, Qingzi Zhu, Yazhe Niu
  - **institution:** Shanghai Artificial Intelligence Laboratory, Xi'an Jiaotong University, Columbia University, The Chinese University of Hong Kong MMLab
  - **link:** https://arxiv.org/pdf/2512.24555
  - **contributions:** 1. Proposes a hierarchical, multi-path Chain-of-Thought (CoT) method to enhance reasoning diversity for meme generation. 2. Introduces a group-wise pairwise reward model trained on memes sharing the same template to robustly capture subjective human humor preferences. 3. Develops a group-wise reinforcement learning optimization framework with a theoretical guarantee for monotonic improvement, enabling better alignment with human preferences.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51d7b92e3cbe88fcb46458e3ce7a303a30ccee8230eb6865946f2c654b707c34_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces HUMOR, a framework for generating humorous memes. It uses a hierarchical multi-path Chain-of-Thought to guide reasoning and a group-wise reward model with RL for preference alignment. Experiments show it improves reasoning diversity, alignment, and overall meme quality in VLMs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[From Perception to Punchline: Empowering VLM with the Art of In-the-wild Meme] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 超越监督的幽默梗图生成/Humorous meme generation beyond direct supervision]
        C[主要方法/Method: HUMOR框架/HUMOR Framework]
        D[关键结果/Results: 提升多样性、对齐性和质量/Improved diversity, alignment, and quality]
        C --> C1[分层多路径思维链/Hierarchical Multi-path CoT]
        C --> C2[基于分组的奖励模型与强化学习/Group-wise Reward Model & RL]
    ```

- **[arXiv260101] CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts**
  - **tags:** [ai], [robust machine learning], [causal representation learning, adversarial robustness, electrocardiogram (ECG), structural causal model (SCM), smooth adversarial perturbations (SAP)]
  - **authors:** Shunbo Jia, Caizhi Liao
  - **institution:** Macau University of Science and Technology, Shenzhen University of Advanced Technology
  - **link:** https://arxiv.org/pdf/2512.24564
  - **contributions:** 1. Proposes Causal Physiological Representation Learning (CPR), a novel framework that integrates a Physiological Structural Prior into a causal disentanglement model for ECG analysis. 2. Models ECG generation via a Structural Causal Model (SCM) to enforce a structural intervention that strictly separates invariant pathological features from non-causal artifacts. 3. Demonstrates that CPR achieves certified robustness comparable to Randomized Smoothing while maintaining single-pass inference efficiency, offering a superior trade-off for real-time clinical applications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ba48c31785d4bc725e8bd6077843ed01150da361f64874d3d85d9a541b0d692_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the vulnerability of deep learning ECG diagnostic models to smooth adversarial perturbations. The authors propose Causal Physiological Representation Learning (CPR), a method that uses a causal disentanglement framework with a physiological prior to separate robust pathological features from artifacts. The results show that CPR provides strong adversarial robustness with efficient inference, outperforming existing defense methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CPR: Causal Physiological Representation Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[ECG模型对对抗性扰动脆弱/Fragile to adversarial perturbations (SAP)]
        B --> B2[现有防御方法存在效率与鲁棒性权衡/Existing defenses (AT, RS) have efficiency-robustness trade-off]
        C --> C1[提出因果生理表征学习/Propose Causal Physiological Representation Learning (CPR)]
        C --> C2[结合生理结构先验与因果解耦/Integrate Physiological Structural Prior & causal disentanglement]
        C --> C3[使用结构因果模型分离病理特征/Use SCM to separate pathological features from artifacts]
        D --> D1[在SAP攻击下F1分数0.632/F1 score 0.632 under SAP attacks]
        D --> D2[超越中值平滑9.1%/Surpass Median Smoothing by 9.1%]
        D --> D3[匹配随机平滑的鲁棒性且保持单次推理效率/Matches RS robustness with single-pass inference]
    ```

- **[arXiv260101] Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time**
  - **tags:** [mlsys], [llm inference], [chain-of-thought reasoning, attention heads, test-time intervention, computational efficiency, reasoning steering]
  - **authors:** Zhenyu Zhang, Xiaoxia Wu, Zhongzhu Zhou, Qingyang Wu, Yineng Zhang, Pragaash Ponnusamy, Harikaran Subbaraj, Jue Wang, Shuaiwen Leon Song, Ben Athiwaratkun
  - **institution:** University of Texas at Austin, Together AI, University of Sydney
  - **link:** https://arxiv.org/pdf/2512.24574
  - **code:** https://github.com/togethercomputer/CREST
  - **contributions:** 1. Identified specialized attention heads in LLMs that correlate with distinct cognitive reasoning behaviors (e.g., verification, backtracking). 2. Proposed CREST, a training-free method for Cognitive REasoning Steering at Test-time, which involves offline calibration to find steering vectors and inference-time rotation to suppress unproductive reasoning. 3. Demonstrated that CREST improves reasoning accuracy and reduces token usage across diverse benchmarks, offering a pathway to faster and more reliable LLM inference.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7de1babf1bde06083c19ff84ab24d16f7280ee2cd3e28ae548f08be7f95a5882_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the inefficiency and instability of long chain-of-thought reasoning in LLMs, which leads to high latency and alternating underthinking/overthinking. The authors propose CREST, a training-free method that identifies and steers specific attention heads at test-time to suppress unproductive cognitive behaviors. The method improves accuracy by up to 17.5% and reduces token usage by 37.6%, enabling faster and more reliable reasoning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[LLM推理轨迹低效且不稳定/Inefficient & Unstable LLM Reasoning Trajectories]
        B1 --> B2[过度思考与思考不足/Overthinking & Underthinking]
        B1 --> B3[高延迟与高令牌消耗/High Latency & Token Usage]
        C --> C1[识别与认知行为相关的注意力头/Identify Cognitive Attention Heads]
        C --> C2[提出CREST方法: 测试时认知推理引导/Propose CREST: Test-time Cognitive REasoning Steering]
        C2 --> C3[离线校准获取引导向量/Offline Calibration for Steering Vectors]
        C2 --> C4[推理时旋转隐藏表示/Inference-time Representation Rotation]
        D --> D1[准确率显著提升/Accuracy Improved Up to 17.5%]
        D --> D2[令牌使用大幅减少/Token Usage Reduced by 37.6%]
        D --> D3[实现更快更可靠的推理/Enables Faster, More Reliable Reasoning]
    ```

- **[arXiv260101] 3D Semantic Segmentation for Post-Disaster Assessment**
  - **tags:** [cv], [3D semantic segmentation], [3D point clouds, Structure-from-Motion (SfM), Multi-View Stereo (MVS), Fast Point Transformer (FPT), Point Transformer v3 (PTv3)]
  - **authors:** Nhut Le, Maryam Rahnemoonfar
  - **institution:** Lehigh University
  - **link:** https://arxiv.org/pdf/2512.24593
  - **contributions:** 1. Constructed a specialized 3D dataset for post-disaster assessment using UAV footage and 3D reconstruction techniques (SfM/MVS). 2. Evaluated state-of-the-art 3D semantic segmentation models (FPT, PTv3, OA-CNNs) on this new dataset. 3. Identified significant limitations of existing models in disaster-stricken environments, highlighting the need for new techniques and benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7f40d3c2e21cef6917feeb765394fae515f763b5c2f2f5b374f921e3a8ac1ba_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of specialized datasets for 3D semantic segmentation in post-disaster scenarios by constructing a new 3D point cloud dataset from UAV footage of Hurricane Ian. The authors evaluated several state-of-the-art models on this dataset and found their performance to be significantly limited, demonstrating an urgent need for improved methods and benchmarks tailored to disaster environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[3D Semantic Segmentation for Post-Disaster Assessment] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[缺乏灾后3D数据集 / Lack of post-disaster 3D datasets]
        C --> C1[使用无人机与SfM/MVS构建3D数据集 / Construct 3D dataset using UAV & SfM/MVS]
        C --> C2[评估SOTA 3D分割模型 / Evaluate SOTA 3D segmentation models]
        D --> D1[现有模型存在显著局限 / Existing models have significant limitations]
        D --> D2[需要新技术与基准 / Need for new techniques & benchmarks]
    ```

- **[arXiv260101] Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space**
  - **tags:** [mlsys], [llm inference], [hierarchical compression, compression-aware scaling law, decoupled µP parametrization, concept space, adaptive semantic boundaries]
  - **authors:** Xingwei Qu, Shaowen Wang, Zihao Huang, Kai Hua, Fan Yin, Rui-Jie Zhu, Jundong Zhou, Qiyang Min, Zihao Wang, Yizhi Li, Tianyu Zhang, He Xing, Zheng Zhang, Yuxuan Song, Tianyu Zheng, Zhiyuan Zeng, Chenghua Lin, Ge Zhang, Wenhao Huang
  - **institution:** ByteDance Seed, University of Manchester, Mila - Quebec AI Institute, Tsinghua University, M-A-P
  - **link:** https://arxiv.org/pdf/2512.24617
  - **contributions:** 1. Proposed Dynamic Large Concept Models (DLCM), a hierarchical language modeling framework that learns variable-length semantic concepts end-to-end and shifts computation from tokens to a compressed concept space for more efficient reasoning. 2. Introduced the first compression-aware scaling law that disentangles token-level capacity, concept-level reasoning capacity, and compression ratio, enabling principled compute allocation under fixed FLOPs. 3. Developed a decoupled µP parametrization for stable training of the heterogeneous architecture, supporting zero-shot hyperparameter transfer across model widths and compression regimes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dff9c61b225b5a86d535cfc752b13f390ae301473e649284a6815c3eaf80b24_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the inefficiency of uniform token-level computation in LLMs by proposing Dynamic Large Concept Models (DLCM), which learns adaptive semantic concepts and reallocates compute to a higher-capacity reasoning backbone in a compressed concept space. This approach achieves a +2.69% average improvement across 12 zero-shot benchmarks under matched inference FLOPs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space] --> B[核心问题/Problem: LLMs apply uniform computation to tokens, wasting capacity on predictable spans and under-allocating to critical transitions]
        A --> C[主要方法/Method: Hierarchical framework learns semantic boundaries, shifts computation to compressed concept space, introduces compression-aware scaling law and decoupled µP parametrization]
        A --> D[关键结果/Results: +2.69% average improvement on 12 zero-shot benchmarks under matched inference FLOPs with R=4 compression]
    ```

- **[arXiv260101] AutoFed: Manual-Free Federated Traffic Prediction via Personalized Prompt**
  - **tags:** [mlsys], [federated learning], [personalized federated learning, prompt learning, traffic prediction, non-IID data, hyper-parameter tuning]
  - **authors:** Zijian Zhao, Yitong Shang, Sen Li
  - **institution:** The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.24625
  - **code:** https://github.com/RS2002/AutoFed
  - **contributions:** 1. Proposes AutoFed, a novel Personalized Federated Learning (PFL) framework for traffic prediction that eliminates the need for manual hyper-parameter tuning. 2. Introduces a federated representor with a client-aligned adapter to distill local data into a compact, globally shared prompt matrix, inspired by prompt learning. 3. Demonstrates through extensive experiments that AutoFed consistently achieves superior performance across diverse real-world traffic prediction scenarios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e572784e0dff554ff14fce989febaa7869bdfb488d60b6fd86ebd7e98cdf0bf7_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes AutoFed, a manual-free Personalized Federated Learning framework for traffic prediction that uses a client-aligned adapter to generate a shared prompt matrix, enabling knowledge sharing while preserving local specificity. Experiments on real-world datasets show that AutoFed achieves superior performance without requiring manual hyper-parameter tuning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AutoFed: Manual-Free Federated Traffic Prediction via Personalized Prompt] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[数据孤岛与隐私问题 / Data Silos & Privacy]
        B --> B2[非独立同分布数据 / Non-IID Data]
        B --> B3[手动超参数调优 / Manual Hyper-parameter Tuning]
        C --> C1[个性化联邦学习 / Personalized Federated Learning (PFL)]
        C --> C2[提示学习 / Prompt Learning]
        C --> C3[联邦表征器与客户端对齐适配器 / Federated Representor & Client-Aligned Adapter]
        D --> D1[性能优越 / Superior Performance]
        D --> D2[无需手动调参 / No Manual Tuning]
        D --> D3[真实数据集验证 / Validated on Real-world Datasets]
    ```

- **[arXiv260101] AI-Driven Acoustic Voice Biomarker-Based Hierarchical Classification of Benign Laryngeal Voice Disorders from Sustained Vowels**
  - **tags:** [ai], [medical audio classification], [hierarchical classification, acoustic biomarkers, mel-spectrograms, voice disorders, sustained vowels]
  - **authors:** Mohsen Annabestani, Samira Aghadoost, Anais Rameau, Olivier Elemento, Gloria Chia-Yi Chiang
  - **institution:** Weill Cornell Medicine
  - **link:** https://arxiv.org/pdf/2512.24628
  - **contributions:** 1. A novel three-stage hierarchical machine learning framework for voice disorder classification that mirrors clinical triage workflows, integrating deep spectral features with interpretable acoustic biomarkers. 2. The proposed system outperforms flat multi-class classifiers and state-of-the-art pre-trained self-supervised audio models (HuBERT, HeAR) on the task of classifying benign laryngeal disorders from sustained vowels. 3. Demonstrates the potential of combining deep learning representations with clinically interpretable features to enhance transparency and alignment for scalable, non-invasive vocal health screening and monitoring.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a53018a32ff94f55161f7c3e6f57843d9d248636c6146e968b0832ca7fdb34b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a hierarchical AI framework to classify benign laryngeal voice disorders from short, sustained vowel recordings. The method uses a three-stage pipeline combining CNN-derived mel-spectrogram features with interpretable acoustic biomarkers, outperforming standard multi-class and pre-trained audio models. The results highlight the framework's potential as a scalable tool for early voice disorder screening and diagnostic triage.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AI-Driven Acoustic Voice Biomarker-Based Hierarchical Classification of Benign Laryngeal Voice Disorders from Sustained Vowels] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[良性喉部嗓音疾病分类/Benign Laryngeal Voice Disorder Classification]
        C --> C1[三级分层机器学习框架/Three-Stage Hierarchical ML Framework]
        C1 --> C1_1[阶段1: 病理筛查/Stage 1: Pathological Screening]
        C1 --> C1_2[阶段2: 粗粒度分层/Stage 2: Coarse Stratification]
        C1 --> C1_3[阶段3: 细粒度分类/Stage 3: Fine-Grained Classification]
        C1_1 --> C1_1a[融合CNN梅尔谱特征与21种声学生物标志物/Integrates CNN Mel-Spectrogram & 21 Acoustic Biomarkers]
        D --> D1[性能优于平面多类分类器与预训练模型/Outperforms Flat Classifiers & Pre-trained Models (HuBERT, HeAR)]
        D --> D2[结合深度表征与可解释特征，增强临床可操作性/Enhances Transparency & Clinical Alignment via Deep & Interpretable Features]
    ```

- **[arXiv260101] A Scalable Framework for logP Prediction: From Terabyte-Scale Data Integration to Interpretable Ensemble Modeling**
  - **tags:** [mlsys], [cluster infrastructure], [byte-offset indexing, ensemble modeling, SHAP analysis, heteroskedasticity, stratified modeling]
  - **authors:** Malikussaid, Septian Caesar Floresko, Ade Romadhony, Isman Kurniawan, Warih Maharani, Hilal Hudan Nuha
  - **institution:** Telkom University
  - **link:** https://arxiv.org/pdf/2512.24643
  - **contributions:** 1. Developed a novel computational infrastructure for terabyte-scale data integration, achieving a 740-fold speedup in processing time using a byte-offset indexing architecture. 2. Conducted a comprehensive analysis revealing the multivariate nature of lipophilicity, identifying molecular weight as the most important global predictor via SHAP analysis, despite its weak bivariate correlation. 3. Proposed and validated a stratified modeling strategy (specialized models for drug-like vs. extreme molecules) that achieved optimal predictive performance, demonstrating the competitiveness of well-curated descriptor-based ensemble models with graph neural networks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad416775f59ba17a28f8c4aa4f177b114e9e8b7b5d9ab0210d586ba595ee51e6_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a scalable framework for predicting molecular lipophilicity (logP). It introduces a high-performance data integration infrastructure and employs tree-based ensemble models with a stratified strategy, achieving robust prediction accuracy and providing insights into key molecular descriptors. The work shows that carefully engineered traditional machine learning models can remain competitive with advanced neural architectures for this task.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Scalable Framework for logP Prediction<br>可扩展的logP预测框架"] --> Problem["核心问题/Problem<br>Accurate, scalable logP prediction for drug discovery<br>药物发现中准确、可扩展的logP预测"]
        Root --> Method["主要方法/Method<br>Byte-offset indexing & stratified ensemble modeling<br>字节偏移索引与分层集成建模"]
        Root --> Results["关键结果/Results<br>740x speedup, robust models competitive with GNNs<br>740倍加速，模型性能与图神经网络相当"]
    ```

- **[arXiv260101] Hybrid Motion Planning with Deep Reinforcement Learning for Mobile Robot Navigation**
  - **tags:** [ai], [robot navigation], [hybrid motion planning, deep reinforcement learning, entity-aware reward, graph-based global planner, collision avoidance]
  - **authors:** Yury Kolomeytsev, Dmitry Golembiovsky
  - **institution:** Lomonosov Moscow State University
  - **link:** https://arxiv.org/pdf/2512.24651
  - **contributions:** 1. Proposes HMP-DRL, a hybrid framework integrating a graph-based global planner with a local DRL policy via checkpoints. 2. Introduces an entity-aware reward structure for the local planner to ensure social compliance by adjusting safety based on agent type. 3. Validates the method in a realistic simulation, showing superior performance in success rate, collision rate, and time to goal.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6963a6e6a0df2bf9e5857d6154c70386d9271eb85763359a237ce12c4881bec_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes HMP-DRL, a hybrid motion planning framework that combines a graph-based global planner for long-range pathfinding with a local Deep Reinforcement Learning policy for reactive, socially-compliant navigation. The method uses checkpoints to integrate the global path and an entity-aware reward function to dynamically adjust to different moving agents. Experiments in realistic simulation show it outperforms other methods in key navigation metrics, enhancing safety and reliability in complex environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Hybrid Motion Planning with Deep Reinforcement Learning for Mobile Robot Navigation] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统图规划器缺乏反应性/Traditional graph planners lack reactivity]
        B --> B2[深度强化学习方法缺乏全局上下文/DRL methods lack global context]
        C --> C1[混合框架HMP-DRL/Hybrid framework HMP-DRL]
        C1 --> C2[图规划器生成路径/Graph planner generates path]
        C1 --> C3[局部DRL策略使用检查点和实体感知奖励/Local DRL policy uses checkpoints & entity-aware reward]
        D --> D1[更高的成功率/Higher success rate]
        D --> D2[更低的碰撞率/Lower collision rate]
        D --> D3[更短的到达时间/Shorter time to goal]
    ```

- **[arXiv260101] HeteroHBA: A Generative Structure-Manipulating Backdoor Attack on Heterogeneous Graphs**
  - **tags:** [sec], [adversarial machine learning], [heterogeneous graph neural networks, backdoor attack, adaptive instance normalization, maximum mean discrepancy, node classification]
  - **authors:** Honglin Gao, Lan Zhao, Junhao Ren, Xiang Li, Gaoxi Xiao
  - **institution:** Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.24665
  - **contributions:** 1. A generative backdoor attack framework (HeteroHBA) for heterogeneous graphs that selects influential trigger attachment points and synthesizes diverse trigger features/connections. 2. A stealthiness enhancement method combining Adaptive Instance Normalization (AdaIN) and Maximum Mean Discrepancy (MMD) loss to align trigger features with benign statistics. 3. A bilevel optimization objective that jointly maximizes attack success rate and preserves clean model accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4ba54f6485be7540924a3b9c9f4089fbeb975b730fbabfbde211ba1bfb4ba09c_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes HeteroHBA, a generative backdoor attack method for heterogeneous graph neural networks (HGNNs) that manipulates graph structure and node features to stealthily poison the model. The method uses saliency-based screening and distribution alignment techniques to improve attack effectiveness and stealth. Experiments show HeteroHBA achieves higher attack success than baselines while maintaining clean accuracy, demonstrating significant security risks in heterogeneous graph learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HeteroHBA: A Generative Structure-Manipulating Backdoor Attack on Heterogeneous Graphs] --> B[核心问题/Problem: Backdoor attacks on heterogeneous graphs are understudied.]
        A --> C[主要方法/Method: Generative trigger synthesis with saliency screening, AdaIN+MMD for stealth, bilevel optimization.]
        A --> D[关键结果/Results: Higher attack success than baselines, maintains clean accuracy, evades a structural defense.]
    ```

- **[arXiv260101] Mobility-Assisted Decentralized Federated Learning: Convergence Analysis and A Data-Driven Approach**
  - **tags:** [mlsys], [federated learning], [decentralized federated learning, user mobility, convergence analysis, data heterogeneity, wireless networks]
  - **authors:** Reza Jahani, Md Farhamdur Reza, Richeng Jin, Huaiyu Dai
  - **institution:** North Carolina State University, Zhejiang University
  - **link:** https://arxiv.org/pdf/2512.24694
  - **contributions:** 1. Established the convergence of Decentralized Federated Learning (DFL) in sparse networks under user mobility, theoretically showing that even random movement can boost performance. 2. Proposed a novel DFL framework that utilizes mobile users with data-distribution-aware induced mobility patterns to enhance information propagation. 3. Provided extensive empirical validation and a comprehensive analysis of how network parameters influence DFL performance in mobile settings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcaaf30fa2b4fe4f882f45ad096166cc0d22979181161bedc0b1504a8bf7549b_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the role of user mobility in improving Decentralized Federated Learning (DFL) performance in sparse, heterogeneous networks. It proposes a data-driven DFL framework where mobile users follow induced trajectories to enhance information flow. Theoretical and experimental results show that mobility, even when random, significantly boosts DFL convergence and performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Mobility-Assisted Decentralized Federated Learning"] --> Problem["核心问题/Problem: DFL性能受限于稀疏连接和数据异构性"]
        Root --> Method["主要方法/Method: 利用数据分布知识引导用户移动性以增强信息传播"]
        Root --> Results["关键结果/Results: 理论证明移动性提升收敛性; 实验验证方法优越性"]
    ```

- **[arXiv260101] Causal Discovery with Mixed Latent Confounding via Precision Decomposition**
  - **tags:** [ai], [causal discovery], [latent confounding, precision matrix decomposition, DAG learning, identifiability, deconfounding]
  - **authors:** Amir Asiaee, Samhita Pal, James O'quinn, James P. Long
  - **institution:** Vanderbilt University Medical Center, Johns Hopkins University, MD Anderson Cancer Center
  - **link:** https://arxiv.org/pdf/2512.24696
  - **contributions:** 1. Proposed DCL-DECOR, a modular pipeline using precision matrix decomposition to separate pervasive from local latent confounding. 2. Provided identifiability results characterizing recoverable causal structure under mixed confounding. 3. Demonstrated improved directed edge recovery in synthetic experiments over baseline methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0fdc733393b17ba1fd45e5626a557d39d8072f5494f4f2325aa8b588ae2f0ee_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses causal discovery in linear Gaussian systems with mixed latent confounding, where some confounders affect many variables and others only a few. It introduces DCL-DECOR, a method that decomposes the precision matrix to isolate pervasive confounders and then applies a correlated-noise DAG learner to recover the causal graph. Experiments show it consistently improves edge recovery compared to applying DAG learning directly to confounded data.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Causal Discovery with Mixed Latent Confounding via Precision Decomposition] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Mixed latent confounding in causal discovery] --> P1[挑战/Challenge: Global confounders mimic causal edges]
        Problem --> P2[现状/Current Methods: DAG learners or undirected models fail]
        Method[主要方法/Method: DCL-DECOR pipeline] --> M1[步骤1/Step 1: Precision matrix decomposition]
        Method --> M2[步骤2/Step 2: Correlated-noise DAG learning]
        Method --> M3[步骤3/Step 3: Bow-freeness reconciliation]
        Results[关键结果/Results] --> R1[理论/Theoretical: Identifiability guarantees]
        Results --> R2[实验/Experimental: Improved edge recovery]
    ```

- **[arXiv260101] Nested Learning: The Illusion of Deep Learning Architectures**
  - **tags:** [ai], [learning theory], [nested learning, in-context learning, continual learning, associative memory, self-modifying model]
  - **authors:** Ali Behrouz, Meisam Razaviyayn, Peilin Zhong, Vahab Mirrokni
  - **institution:** Google Research (inferred from authors Ali Behrouz, Meisam Razaviyayn, Peilin Zhong, and Vahab Mirrokni, who are affiliated with Google)
  - **link:** https://arxiv.org/pdf/2512.24695
  - **contributions:** 1. Expressive Optimizers: Shows gradient-based optimizers are associative memory modules and proposes more expressive variants with deeper memory and learning rules. 2. Self-Modifying Learning Module: Presents a sequence model that learns to modify itself by learning its own update algorithm. 3. Continuum Memory System: Introduces a new memory formulation generalizing long/short-term memory, which is combined with the self-modifying model to create "Hope", a continual learning module.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aac4e338b76a10773a96b12a072d809a81c99a79e63d8b40927cb078da7b7fdb_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes a new learning paradigm called Nested Learning (NL), which frames machine learning models as nested optimization problems. This view explains the emergence of in-context learning and is used to design more expressive optimizers, a self-modifying model, and a new memory system, culminating in a continual learning module named "Hope" that shows promising results on various tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Nested Learning: The Illusion of Deep Learning Architecture] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[如何实现持续学习与自我改进/How to achieve continual learning and self-improvement]
        C --> C1[嵌套学习范式/Nested Learning Paradigm]
        C --> C2[设计表达性优化器/Design Expressive Optimizers]
        C --> C3[自修改学习模块/Self-Modifying Learning Module]
        C --> C4[连续体记忆系统/Continuum Memory System]
        D --> D1[提出持续学习模块Hope/Propose continual learning module Hope]
        D --> D2[在多个任务上展示潜力/Show potential on multiple tasks]
    ```

- **[arXiv260101] BandiK: Efficient Multi-Task Decomposition Using a Multi-Bandit Framework**
  - **tags:** [ai], [multi-task learning], [multi-armed bandit, negative transfer, auxiliary task selection, multi-bandit framework, drug-target interaction]
  - **authors:** András Millinghoffer, András Formanek, András Antos, Péter Antal
  - **institution:** Budapest University of Technology and Economics, E-Group ICT Software Zrt., KU Leuven
  - **link:** https://arxiv.org/pdf/2512.24708
  - **contributions:** 1. A three-stage method (BandiK) for efficient auxiliary task subset selection in multi-task learning, 2. Reduction of candidate auxiliary sets from exponential to linear complexity using pairwise transfer estimations, 3. A novel multi-bandit framework that exploits semi-overlapping arms across tasks to improve computational efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e49fedc6c9b07cd38435ef8daff0ba16207d6088f86e049c77cd192822bd2cf_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces BandiK, a three-stage method using multi-armed bandits to efficiently select beneficial auxiliary task subsets in multi-task learning, reducing computational cost by estimating pairwise transfers and leveraging a multi-bandit structure. It is validated on a drug-target interaction benchmark, showing scalable performance for complex multi-task scenarios.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[BandiK: Efficient Multi-Task Decomposition Using a Multi-Bandit Framework] --> B[核心问题/Problem: 多任务学习中负迁移和辅助任务选择的高计算成本与复杂性]
        A --> C[主要方法/Method: 三阶段多臂老虎机框架，估计任务间转移、构建线性候选集、利用半重叠臂的多老虎机结构]
        A --> D[关键结果/Results: 在药物-靶点相互作用基准上验证，实现高效可扩展的任务分解]
    ```

- **[arXiv260101] FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [N:M structured pruning, 4-bit quantization, systolic array, FPGA accelerator, hardware-software co-design]
  - **authors:** Fen-Yu Hsieh, Yun-Chang Teng, Ding-Yong Hong, Jan-Jan Wu
  - **institution:** Institute of Information Science, Academia Sinica
  - **link:** https://arxiv.org/pdf/2512.24713
  - **contributions:** 1. Proposes an automation framework and unified pipeline for applying N:M structured pruning and 4-bit integer quantization to compress LLMs. 2. Presents a hardware-software co-design method that generates a custom systolic-array-based FPGA accelerator for efficient inference. 3. Demonstrates the synergy of fine-grained sparsity and quantization, achieving significant reductions in storage and latency while offering flexibility beyond fixed hardware sparsity patterns.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a594f5eb4f19e15f5f182ee786cc270613c6a3d07553a78731a54b9a3ae90ea_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high computational and memory demands of LLMs by proposing a hardware-software co-design framework. The method combines N:M structured pruning and 4-bit quantization to compress models, and implements a custom FPGA accelerator for efficient inference. The results show significant reductions in storage and latency, demonstrating the effectiveness of the approach for deployable LLM inference.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("LLM部署困难/LLM Deployment Challenge")
        P1 --> P2("高计算与内存需求/High Computation & Memory Requirements")
        Method --> M1("模型压缩/Model Compression")
        M1 --> M2("N:M结构化剪枝与4-bit量化/N:M Structured Pruning & 4-bit Quantization")
        Method --> M3("软硬件协同设计/Hardware-Software Co-Design")
        M3 --> M4("生成基于脉动阵列的FPGA加速器/Generating Systolic-Array-based FPGA Accelerator")
        Results --> R1("存储减少4倍/4x Weight Storage Reduction")
        Results --> R2("矩阵乘法加速1.71倍/1.71x Matrix Multiplication Speedup")
        Results --> R3("端到端延迟降低1.29倍/1.29x End-to-End Latency Reduction")
    ```

- **[arXiv260101] From Trial to Deployment: A SEM Analysis of Traveler Adoptions to Fully Operational Autonomous Taxis**
  - **tags:** [other], [human-computer interaction, transportation systems], [Structural Equation Modeling, autonomous taxis, user adoption, survey, latent constructs]
  - **authors:** Yutong Cai, Hua Wang
  - **institution:** Singapore University of Technology and Design, Hefei University of Technology
  - **link:** https://arxiv.org/pdf/2512.24767
  - **contributions:** 1. Conducts a study on actual user behavior of a fully operational autonomous taxi service (Baidu Apollo Robotaxi in Wuhan), moving beyond hypothetical scenarios. 2. Identifies and validates six key latent psychological constructs (Trust & Policy Support, Cost Sensitivity, Performance, Behavioral Intention, Lifestyle, Education) influencing adoption using Structural Equation Modeling. 3. Provides empirical evidence that Cost Sensitivity and Behavioral Intention are the strongest positive predictors of adoption frequency, offering insights for real-world policy and service deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8981785dc74c2d0e8bd1e9be7c18041b4ff904b4eac18913982db535cbd97bd4_w640_q70.webp
  - **Simple LLM Summary:** This study investigates the factors influencing traveler adoption of fully operational autonomous taxis by analyzing survey data from actual users of Baidu's Apollo Robotaxi service in Wuhan, China. Using Structural Equation Modeling on 336 valid responses, the research identifies key psychological constructs and finds that Cost Sensitivity and Behavioral Intention are the strongest predictors of adoption frequency. The findings offer empirical support for policymaking and service design to scale autonomous taxi deployments in urban settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FROM TRIAL TO DEPLOYMENT: A SEM ANALYSIS OF TRAVELER ADOPTIONS TO FULLY OPERATIONAL AUTONOMOUS TAXIS] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Gap in studying actual user behavior of operational AV services]
        C[主要方法/Method: Survey & Structural Equation Modeling on real Apollo Robotaxi users]
        D[关键结果/Results: Cost Sensitivity & Behavioral Intention are strongest adoption predictors]
    ```

- **[arXiv260101] Projection-based Adversarial Attack using Physics-in-the-Loop Optimization for Monocular Depth Estimation**
  - **tags:** [cv], [monocular depth estimation], [adversarial attack, physics-in-the-loop optimization, sep-CMA-ES]
  - **authors:** Takeru Kusakabe, Yudai Hirose, Mashiho Mukaida, Satoshi Ono
  - **institution:** Kagoshima University
  - **link:** https://arxiv.org/pdf/2512.24792
  - **contributions:** 1. Proposes a projection-based adversarial attack method for monocular depth estimation models, using projected light as the perturbation. 2. Employs physics-in-the-loop (PITL) optimization to design perturbations in real-world environments, accounting for device specifications and disturbances. 3. Utilizes a distributed covariance matrix adaptation evolution strategy (sep-CMA-ES) for effective black-box optimization to generate adversarial examples.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5085ff109d1d570d16fe1fa964d0eb5cc890f0ebaed8dcfe0c3cdaa01d4f00bd_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a physical adversarial attack method for monocular depth estimation models. The method projects perturbation light onto a target object and uses physics-in-the-loop optimization with a distributed evolution strategy to create adversarial examples. Experiments confirmed the attack's success, causing depth misestimations that made parts of objects disappear from the scene.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Projection-based Adversarial Attack using Physics-in-the-Loop Optimization for Monocular Depth Estimation] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: DNN-based monocular depth estimation models are vulnerable to adversarial attacks, threatening reliability in applications like autonomous systems.]
        Method[主要方法/Method: Proposes a projection-based attack using physics-in-the-loop optimization and sep-CMA-ES to generate adversarial light perturbations.]
        Results[关键结果/Results: Successfully created adversarial examples causing depth misestimation, making parts of objects disappear from the scene.]
    ```

- **[arXiv260101] Self-Supervised Neural Architecture Search for Multimodal Deep Neural Networks**
  - **tags:** [mlsys], [multi-modal training], [neural architecture search, self-supervised learning, multimodal fusion, contrastive learning, gradient-based search]
  - **authors:** Shota Suzuki, Satoshi Ono
  - **institution:** Kagoshima University
  - **link:** https://arxiv.org/pdf/2512.24793
  - **contributions:** 1. Proposes a self-supervised learning (SSL) method for neural architecture search (NAS) specifically for multimodal deep neural networks. 2. Applies SSL comprehensively to both the architecture search and model pretraining processes, eliminating the need for labeled data during search. 3. Demonstrates that the method can successfully design network architectures from unlabeled training data, achieving performance comparable to supervised NAS methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a6c1a495cc476572529c11ecd2d19b6e7849693fc7a5c6941d8e99e91599cc5_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem that neural architecture search (NAS) for multimodal deep neural networks typically requires large amounts of labeled data. The authors propose a self-supervised learning method that uses contrastive learning to perform NAS without labeled data. Experimental results show the method can successfully design effective multimodal network architectures using only unlabeled data.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Self-supervised Neural Architecture Search for Multimodal Deep Neural Networks] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Multimodal NAS requires substantial labeled data] --> P1[问题细化/Sub-problem: High labeling cost for multimodal data]
        Method[主要方法/Method: Self-supervised NAS] --> M1[方法基础/Foundation: Gradient-based NAS (BM-NAS)] --> M1_1[技术/Technique: Differential Architecture Search]
        Method --> M2[自监督机制/SSL Mechanism: Contrastive Learning (SimCLR)] --> M2_1[目标/Objective: Learn from unlabeled data]
        Results[关键结果/Results: Successfully designed architectures from unlabeled data] --> R1[评估/Evaluation: Comparable to supervised methods]
    ```

- **[arXiv260101] Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training**
  - **tags:** [cv], [image denoising], [Noise2Noise, Monte Carlo denoising, high dynamic range, tone mapping, Jensen gap]
  - **authors:** Andrew Tinits, Stephen Mann
  - **institution:** University of Waterloo
  - **link:** https://arxiv.org/pdf/2512.24794
  - **contributions:** 1. Identified that certain nonlinear functions can be applied to noisy targets in Noise2Noise training without introducing significant bias. 2. Developed a theoretical framework to analyze the effects of nonlinearities and described a class of functions with minimal bias. 3. Demonstrated the method's effectiveness for training Monte Carlo denoisers on HDR images using only noisy data, achieving results comparable to models trained with clean references.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a7ef23248abb9edf960ef0ea8dac0c52ee12d9db03ab8dd602dfd8c83c62645_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of Noise2Noise training where applying nonlinear functions to noisy targets introduces bias. The authors propose a theoretical framework to identify low-bias nonlinearities and apply this to denoise high dynamic range Monte Carlo renderings using tone mapping. Their method, trained only on noisy data, achieves performance close to models trained with clean reference images.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("Noise2Noise训练中非线性函数导致偏差/Bias from nonlinearities in Noise2Noise")
        Problem --> P2("HDR图像训练被异常值干扰/HDR training overwhelmed by outliers")
        Method --> M1("理论分析非线性影响/Theoretical analysis of nonlinear effects")
        Method --> M2("识别低偏差非线性函数类/Identify low-bias nonlinear function class")
        Method --> M3("特定损失与色调映射组合/Specific loss & tone mapping combination")
        Results --> R1("仅用噪声数据训练/Train with only noisy data")
        Results --> R2("性能接近干净数据训练模型/Performance approaches clean-data-trained model")
    ```

- **[arXiv260101] Gradient Descent as Implicit EM in Distance-Based Neural Models**
  - **tags:** [ai], [machine learning theory], [gradient descent, expectation-maximization, log-sum-exp, distance-based models, probabilistic inference]
  - **authors:** Alan Oursland
  - **institution:** Unknown (Inferred from arXiv identifier only; no explicit affiliation provided)
  - **link:** https://arxiv.org/pdf/2512.24780
  - **contributions:** 1. Provides a direct derivation showing that for objectives with a log-sum-exp structure, the gradient with respect to a distance is exactly the negative posterior responsibility, an algebraic identity. 2. Demonstrates that gradient descent on such objectives implicitly performs expectation-maximization, embedding inference within the optimization process. 3. Unifies learning in unsupervised mixture modeling, attention mechanisms, and supervised classification under a single mechanism, explaining observed Bayesian behaviors as a necessary consequence of objective geometry.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dedc1f2ebe4cae6339387562e130f21772d7b403da5771f698e488286b8cffce_w640_q70.webp
  - **Simple LLM Summary:** The paper shows that gradient descent on objectives with a log-sum-exp structure (common in neural networks) is algebraically equivalent to performing expectation-maximization, where the gradient directly corresponds to posterior responsibilities. This finding unifies learning across unsupervised, attention-based, and supervised regimes, explaining probabilistic behaviors like soft clustering as a fundamental property of the objective, not an emergent phenomenon.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Gradient Descent as Implicit EM in Distance-Based Neural Models] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[神经网络表现出概率推断行为/Neural nets show probabilistic inference behaviors]
        B --> B2[现有解释不充分/Existing explanations are unsatisfactory]
        C --> C1[推导梯度与后验责任的恒等式/Derive gradient-posterior identity]
        C --> C2[分析目标函数的几何结构/Analyze objective function geometry]
        D --> D1[梯度下降即隐式EM/Gradient descent is implicit EM]
        D --> D2[统一三种学习机制/Unifies three learning regimes]
        D --> D3[贝叶斯结构是必然结果/Bayesian structure is necessary]
    ```

- **[arXiv260101] LeanCat: A Benchmark Suite for Formal Category Theory in Lean (Part I: 1-Categories)**
  - **tags:** [ai], [theorem proving], [formal verification, category theory, benchmark, Lean, large language models]
  - **authors:** Rongge Xu, Hui Dai, Yiming Fu, Jiedong Jiang, Tianjiao Nie, Hongwei Wang, Junkai Wang, Holiverse Yang, Jiatong Yang, Zhi-Hao Zhang
  - **institution:** Tsinghua University, Southern University of Science and Technology, Westlake University, Xi'an Jiaotong-Liverpool University, The Chinese University of Hong Kong, Yanqi Lake Beijing Institute of Mathematical Sciences and Applications (BIMSA)
  - **link:** https://arxiv.org/pdf/2512.24796
  - **code:** https://github.com/sciencraft/LeanCat
  - **contributions:** 1. Introduces LeanCat, a benchmark for formal category theory in Lean, designed to stress-test abstraction and library-mediated reasoning. 2. Presents a curated dataset of 100 tasks with topic families and difficulty tiers, created via an LLM-assisted human grading process. 3. Demonstrates the benchmark's utility by evaluating models and the LeanBridge method, showing current AI capabilities and providing a checkpoint for tracking progress.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4bb17bb33fa46697baca7f3b3a6262916453dd0a4bf5f92ff26cebdd7d681ffe_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces LeanCat, a benchmark for formalizing category theory in Lean to better evaluate AI's ability for abstract, library-based reasoning in mathematics. It presents a curated set of 100 tasks and evaluates models, finding low success rates, especially on harder problems, while showing that retrieval-augmented methods like LeanBridge can improve performance. The benchmark serves as a compact checkpoint for tracking progress in research-level formal theorem proving.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LeanCat: A Benchmark Suite for Formal Category Theory in Lean] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>现有基准未能充分衡量抽象和基于库的推理/Current benchmarks under-measure abstraction and library-mediated reasoning]
        C[主要方法/Method<br>为Lean创建形式化范畴论基准，包含100个分级任务/Create a Lean benchmark for formal category theory with 100 graded tasks]
        D[关键结果/Results<br>最佳模型pass@1为8.25%，检索增强方法有提升/Best model pass@1 is 8.25%, retrieval-augmented methods show gains]
    ```

- **[arXiv260101] DTI-GP: Bayesian operations for drug-target interactions using deep kernel Gaussian processes**
  - **tags:** [ai], [drug-target interaction prediction], [Gaussian processes, deep kernel learning, Bayesian inference, drug-target interaction, Bayesian precedence matrix]
  - **authors:** Bence Bolgár, András Millinghoffer, Péter Antal
  - **institution:** None
  - **link:** https://arxiv.org/pdf/2512.24810
  - **contributions:** 1. Proposed DTI-GP, a deep kernel Gaussian process architecture for drug-target interaction prediction that combines neural embeddings with Bayesian inference. 2. Introduced novel Bayesian operations, including classification with rejection, top-K selection, and ranking, enabled by sampling from the predictive distribution. 3. Demonstrated superior performance over state-of-the-art methods and enabled new evaluation metrics like a Bayesian accuracy-confidence enrichment score.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5db80a2ae688e29179cef03704df858a81feee85a09984daebbb301bc3ea93a0_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the need for precise probabilistic predictions in drug-target interaction (DTI) tasks. It proposes DTI-GP, a method that integrates deep neural embeddings for drugs and proteins with a Gaussian process module to enable scalable Bayesian inference. The approach outperforms existing methods and facilitates novel operations like confidence-aware rejection and ranking.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[DTI-GP: Bayesian operations for drug-target interactions using deep kernel Gaussian processes] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Need for precise probabilistic DTI predictions] --> P1[理解限制与提升性能/Understanding limitations & boosting performance]
        Method[主要方法/Method: Deep Kernel Gaussian Process] --> M1[神经嵌入模块/Neural embedding module for compounds & proteins]
        Method --> M2[高斯过程模块/GP module for Bayesian inference]
        Method --> M3[采样预测分布/Sampling predictive distribution for Bayesian precedence matrix]
        Results[关键结果/Results] --> R1[性能超越SOTA/Outperforms state-of-the-art]
        Results --> R2[支持新操作/Enables novel operations: rejection, top-K, ranking]
        Results --> R3[构建贝叶斯富集分数/Constructs Bayesian accuracy-confidence enrichment score]
    ```

- **[arXiv260101] Unregularized Linear Convergence in Zero-Sum Game from Preference Feedback**
  - **tags:** [ai], [reinforcement learning], [Nash equilibrium, Optimistic Multiplicative Weights Update, duality gap, last-iterate convergence, non-transitive preferences]
  - **authors:** Shulun Chen, Runlong Zhou, Zihan Zhang, Maryam Fazel, Simon S. Du
  - **institution:** Tsinghua University, University of Washington, HKUST
  - **link:** https://arxiv.org/pdf/2512.24818
  - **contributions:** 1. Provides the first convergence guarantee for Optimistic Multiplicative Weights Update (OMWU) in the Nash Learning from Human Feedback (NLHF) setting, showing it achieves last-iterate linear convergence to the original Nash equilibrium after a burn-in phase when a full-support NE exists. 2. Removes the prior assumption of Nash equilibrium uniqueness required by related work. 3. Identifies a novel marginal convergence behavior where the probability of rarely played actions grows exponentially from small values, leading to an exponentially better dependence on instance-dependent constants.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad0c58b07c97ac061247ceb0efd9cdb7a7663982811f67d347d7d126d158bebc_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of aligning LLMs with non-transitive human preferences by framing it as a zero-sum game in the NLHF framework. It proposes using the unregularized Optimistic Multiplicative Weights Update (OMWU) algorithm and proves it achieves last-iterate linear convergence to the original Nash equilibrium without requiring uniqueness assumptions. The theoretical findings are supported by experiments on tabular and neural policy classes, demonstrating the method's potential for LLM alignment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Unregularized Linear Convergence in Zero-Sum Game from Preference Feedback] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Standard preference models assume transitivity, overlooking non-transitive human preferences in LLM alignment.]
        C[主要方法/Method: Use unregularized Optimistic Multiplicative Weights Update (OMWU) to find Nash equilibrium in the NLHF zero-sum game.]
        D[关键结果/Results: OMWU achieves last-iterate linear convergence to the original NE without uniqueness assumption, with a novel marginal convergence behavior.]
    ```

- **[arXiv260101] Discovering Coordinated Joint Options via Inter-Agent Relative Dynamics**
  - **tags:** [ai], [multi-agent reinforcement learning], [option discovery, graph Laplacian, state abstraction, coordination, Fermat state]
  - **authors:** Raul D. Steleac, Mohan Sridharan, David Abel
  - **institution:** University of Edinburgh, Google DeepMind
  - **link:** https://arxiv.org/pdf/2512.24827
  - **contributions:** 1. Proposes a novel joint-state abstraction method that compresses the state space while preserving information needed for discovering strongly coordinated behaviors. 2. Introduces the concept of a "Fermat state" (a fictitious state of maximal team alignment) and a "spreadness" measure to quantify team-level misalignment. 3. Employs a neural graph Laplacian estimator on this representation to derive options that capture state synchronization patterns between agents.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80fbcbdbf3ff73a3709f40a0baeb20e2f256323634f984656081dbac35380c30_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of discovering coordinated, temporally extended actions (options) in multi-agent systems, where the joint state space grows exponentially. The proposed method introduces a joint-state abstraction based on agent state synchronization, using a "Fermat state" and "spreadness" measure, and then applies a neural graph Laplacian estimator to discover options. The resulting options demonstrate stronger downstream coordination capabilities compared to existing methods in multi-agent domains.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Discovering Coordinated Joint Options via Inter-Agent Relative Dynamics<br/>通过智能体间相对动力学发现协调的联合选项] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[多智能体选项发现挑战<br/>Multi-agent Option Discovery Challenge]
        B1 --> B2[状态空间指数增长<br/>Exponential State Space Growth]
        B1 --> B3[现有方法缺乏协调<br/>Existing Methods Lack Coordination]
        C --> C1[联合状态抽象<br/>Joint-State Abstraction]
        C1 --> C2[费马状态与扩散度<br/>Fermat State & Spreadness]
        C2 --> C3[神经图拉普拉斯估计器<br/>Neural Graph Laplacian Estimator]
        D --> D1[更强的协调能力<br/>Stronger Coordination Capabilities]
        D1 --> D2[优于现有方法<br/>Outperforms Alternative Methods]
    ```

- **[arXiv260101] AODDiff: Probabilistic Reconstruction of Aerosol Optical Depth via Diffusion-based Bayesian Inference**
  - **tags:** [ai], [diffusion models], [diffusion-based Bayesian inference, corruption-aware training, decoupled annealing posterior sampling, uncertainty quantification, spatiotemporal prior]
  - **authors:** Linhao Fan, Hongqiang Fang, Jingyang Dai, Yong Jiang, Qixing Zhang
  - **institution:** University of Science and Technology of China, National Institute of Standards and Technology
  - **link:** https://arxiv.org/pdf/2512.24847
  - **contributions:** 1. Proposes AODDiff, a probabilistic reconstruction framework using diffusion-based Bayesian inference to learn a spatiotemporal prior for AOD fields. 2. Introduces a corruption-aware training strategy to learn the prior from naturally incomplete data, eliminating the need for complete training data. 3. Employs a decoupled annealing posterior sampling strategy to effectively integrate heterogeneous observations as constraints for flexible task adaptation without retraining.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c1c9e0ed0baf5b503de97c6a15b2d7601232aba8c5c2f231a32ee44d046afcf_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes AODDiff, a diffusion-based Bayesian inference framework for probabilistically reconstructing Aerosol Optical Depth fields. It learns a spatiotemporal prior from incomplete data and uses a novel sampling strategy to integrate observations for tasks like downscaling and inpainting. Experiments show it maintains high fidelity and enables uncertainty quantification.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AODDiff: Probabilistic Reconstruction of AOD] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[数据稀缺与不确定性/Data Scarcity & Uncertainty]
        C --> C1[扩散贝叶斯推断/Diffusion-based Bayesian Inference]
        C1 --> C2[损坏感知训练/Corruption-aware Training]
        C1 --> C3[解耦退火采样/Decoupled Annealing Sampling]
        D --> D1[高保真度/High Fidelity]
        D --> D2[不确定性量化/Uncertainty Quantification]
    ```

- **[arXiv260101] Characterization of Transfer Using Multi-task Learning Curves**
  - **tags:** [ai], [multi-task learning], [multi-task learning curves, task affinity grouping, transfer effects, inductive inference, foundation models]
  - **authors:** András Millinghoffer, Bence Bolgár, Péter Antal
  - **institution:** Budapest University of Technology and Economics
  - **link:** https://arxiv.org/pdf/2512.24866
  - **contributions:** 1. Proposes using multi-task learning curves (approximating performance over varying sample sizes) as a fundamental method to characterize transfer effects, complementing gradient-based training analysis. 2. Describes an efficient method to approximate these multi-task learning curves, analogous to the Task Affinity Grouping method. 3. Compares statistical (learning curve) and computational (training-based) approaches to transfer, finding the former has lower compute cost while the latter has better power and broader applicability, and demonstrates its utility on a drug-target interaction dataset and for analyzing foundation models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7a18c81d007e0d8e8e143a6ef66be8aaaafd4edddc20571b598040702aaa801_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes characterizing transfer effects in machine learning by analyzing multi-task learning curves, which model inductive performance as sample size varies, rather than solely through gradient updates during training. It introduces an efficient method to approximate these curves and compares this statistical approach to traditional computational methods. The results show that learning curves effectively capture multi-task learning effects and can delineate transfer in foundation models, offering a complementary and more computationally efficient perspective.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Characterization of Transfer Using Multi-task Learning Curves] --> B(核心问题/Problem: How to fundamentally characterize transfer effects beyond gradient-based training analysis?)
        A --> C(主要方法/Method: Use multi-task learning curves over varying sample sizes; efficient approximation method analogous to Task Affinity Grouping)
        A --> D(关键结果/Results: Learning curves better capture MTL effects; method delineates transfer in foundation models; statistical approach has lower compute cost)
    ```

- **[arXiv260101] mHC: Manifold-Constrained Hyper-Connections**
  - **tags:** [mlsys], [llm training], [Hyper-Connections, residual connection, identity mapping, manifold constraint, training stability]
  - **authors:** Zhenda Xie, Yixuan Wei, Huanqi Cao, Chenggang Zhao, Chengqi Deng, Jiashi Li, Damai Dai, Huazuo Gao, Jiang Chang, Liang Zhao, Shangyan Zhou, Zhean Xu, Zhengyan Zhang, Wangding Zeng, Shengding Hu, Yuqing Wang, Jingyang Yuan, Lean Wang, Wenfeng Liang
  - **institution:** DeepSeek-AI
  - **link:** https://arxiv.org/pdf/2512.24880
  - **contributions:** 1. Proposes Manifold-Constrained Hyper-Connections (mHC), a framework that projects the residual connection space onto a specific manifold to restore the identity mapping property compromised by Hyper-Connections (HC). 2. Incorporates rigorous infrastructure optimization to address the memory access overhead and ensure training efficiency. 3. Demonstrates that mHC enables effective large-scale training with tangible performance improvements and superior scalability, offering a flexible and practical extension of HC.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7219c6945df5dfb5231231a93ccf8e3cf155e38527f2c4071501eaae05a8b7ac_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that Hyper-Connections (HC), while improving performance, lose the identity mapping property of standard residual connections, leading to training instability and memory overhead. To solve this, the authors propose Manifold-Constrained Hyper-Connections (mHC), which projects HC's connection space onto a manifold to restore identity mapping and includes infrastructure optimizations. Empirical results show mHC is effective for scalable training, offering better performance and stability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[mHC: Manifold-Constrained Hyper-Connections] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1["HC 破坏了恒等映射，导致训练不稳定/HC compromises identity mapping, causing instability"]
        B --> B2["HC 带来内存开销/HC incurs memory overhead"]
        C --> C1["将残差连接空间投影到特定流形/Project residual space onto a manifold"]
        C --> C2["恢复恒等映射属性/Restore identity mapping property"]
        C --> C3["结合基础设施优化/Incorporate infrastructure optimization"]
        D --> D1["实现可扩展的有效训练/Enables effective training at scale"]
        D --> D2["提供性能改进和可扩展性/Offers performance improvements & scalability"]
    ```

- **[arXiv260101] PRISM: A hierarchical multiscale approach for time series forecasting**
  - **tags:** [ai], [time series forecasting], [hierarchical modeling, multiscale decomposition, wavelet transform, tree-based partitioning, multivariate forecasting]
  - **authors:** Zihao Chen, Alexandre Andre, Wenrui Ma, Ian Knight, Sergey Shuvaev, Eva Dyer
  - **institution:** University of Pennsylvania
  - **link:** https://arxiv.org/pdf/2512.24898
  - **code:** https://github.com/nerdslab/prism
  - **contributions:** 1. Proposes PRISM, a novel hierarchical forecasting method using a learnable tree-based partitioning of time series signals. 2. Introduces a joint time-frequency decomposition (e.g., wavelets) at each tree level to extract and aggregate scale-specific features. 3. Demonstrates a lightweight and flexible framework that outperforms state-of-the-art methods on benchmark datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a39698d43f8debac5a07c7c8b7b2c886add93fdb385fed95a191b3257708859_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of forecasting time series with multiscale features by proposing PRISM, a method that uses a learnable tree structure to hierarchically partition the signal and apply time-frequency transforms at each level. This approach jointly captures global trends and local dynamics, leading to improved forecasting accuracy. Experiments show that PRISM outperforms existing state-of-the-art methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[PRISM: 时间序列预测 / Time Series Forecasting]
        Root --> Problem[核心问题: 多尺度特征预测 / Problem: Forecasting Multiscale Features]
        Root --> Method[主要方法: 可学习树状分层 / Method: Learnable Tree-based Hierarchy]
        Root --> Results[关键结果: 性能超越SOTA / Results: Outperforms SOTA]
        Problem --> P1[全局趋势与局部结构 / Global Trends & Local Structure]
        Method --> M1[时间-频率分解 / Time-Frequency Decomposition]
        Method --> M2[特征跨层次聚合 / Feature Aggregation Across Hierarchy]
        Results --> R1[轻量灵活框架 / Lightweight & Flexible Framework]
    ```

- **[arXiv260101] Spectral Graph Neural Networks for Cognitive Task Classification in fMRI Connectomes**
  - **tags:** [ai], [neuroimaging analysis], [Graph Neural Network, Spectral Convolution, Graph Fourier Transform, fMRI Connectome, Cognitive Classification]
  - **authors:** Debasis Maji, Arghya Banerjee, Debaditya Barman
  - **institution:** Visva-Bharati, Institute of Engineering & Management
  - **link:** https://arxiv.org/pdf/2512.24901
  - **code:** https://github.com/gnnplayground/SpectralBrainGNN
  - **contributions:** 1. Proposed SpectralBrainGNN, a novel spectral convolution framework for brain network analysis. 2. Applied Graph Fourier Transform (GFT) computed via normalized Laplacian eigendecomposition to model functional connectivity. 3. Demonstrated state-of-the-art cognitive task classification performance (96.25% accuracy) on the HCP-Task dataset.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef6720522974da991b45f55d20e9895bdadedeae152a749a83e04947607b62bd_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses cognitive task classification from fMRI brain networks. It proposes SpectralBrainGNN, a spectral graph neural network model based on Graph Fourier Transforms, to capture complex connectivity patterns. The method achieves high classification accuracy on a standard dataset, showing its effectiveness for decoding brain states.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["Spectral Graph Neural Networks for Cognitive Task Classification in fMRI Connectomes"] --> B["核心问题/Problem: Decoding brain states from neuroimaging data"]
        A --> C["主要方法/Method: SpectralBrainGNN using Graph Fourier Transform (GFT)"]
        A --> D["关键结果/Results: 96.25% classification accuracy on HCP-Task dataset"]
    ```

- **[arXiv260101] Frequent subgraph-based persistent homology for graph classification**
  - **tags:** [ai], [graph representation learning], [persistent homology, frequent subgraph mining, graph neural networks, graph filtration, topological data analysis]
  - **authors:** Xinyang Chen, Amaël Broustet, Guoting Chen
  - **institution:** Harbin Institute of Technology, Shenzhen; Université de Lille, Laboratoire Painlevé (CNRS UMR 8524); Great Bay University
  - **link:** https://arxiv.org/pdf/2512.24917
  - **contributions:** 1. Proposed a novel Frequent Subgraph Filtration (FSF) method to generate frequency-based persistent homology features for graphs. 2. Developed two graph classification frameworks: an FPH-based machine learning model (FPH-ML) and a hybrid framework integrating FPH with GNNs (FPH-GNNs). 3. Provided theoretical analysis and experimental validation showing performance improvements over baseline methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/027326f2cb71708e2df7a0cf125f5d22c8db2742b7d53533a738ac9ae412b01d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of existing persistent homology methods on graphs, which rely on simple filtrations and miss recurring structural patterns. The authors propose a Frequent Subgraph Filtration (FSF) to extract richer topological features and integrate them into both traditional ML and GNN models for graph classification. Experiments show that the proposed methods achieve competitive or superior accuracy, with the hybrid FPH-GNN framework yielding significant performance gains over standard GNN backbones.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Frequent subgraph-based persistent homology for graph classification] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有持久同源方法过滤有限，忽略数据集中重复出现的子图特征/Existing PH methods use limited filtrations, overlooking recurring subgraph features.]
        C --> C1[提出基于频繁子图的过滤方法(FSF)，生成频率持久同源(FPH)特征/Propose Frequent Subgraph Filtration (FSF) to generate Frequency-based Persistent Homology (FPH) features.]
        C --> C2[构建FPH-ML和FPH-GNN混合框架进行图分类/Build FPH-ML and hybrid FPH-GNN frameworks for graph classification.]
        D --> D1[FPH-ML达到竞争性或更优的准确率/FPH-ML achieves competitive or superior accuracy.]
        D --> D2[FPH-GNN相比GCN/GIN基线获得显著性能提升/FPH-GNN yields significant performance gains over GCN/GIN backbones.]
    ```

- **[arXiv260101] Adaptive Dependency-aware Prompt Optimization Framework for Multi-Step LLM Pipeline**
  - **tags:** [mlsys], [agent system], [prompt optimization, multi-step LLM pipeline, Shapley value, text-gradient estimation, dependency modeling]
  - **authors:** Minjun Zhao, Xinyu Zhang, Shuai Zhang, Deyang Li, Ruifeng Shi
  - **institution:** Huawei Poisson Lab
  - **link:** https://arxiv.org/pdf/2512.24933
  - **contributions:** 1. Proposes ADOPT, a framework that explicitly models the dependency between each LLM step and the final task outcome for precise text-gradient estimation. 2. Decouples textual gradient estimation from gradient updates, reducing complex multi-prompt optimization to flexible single-prompt optimization steps. 3. Employs a Shapley-based mechanism to adaptively allocate optimization resources across different pipeline steps.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0120693b7eaf05e640c60779fef913238cda72212cee4971942ac26a248c12d_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of jointly optimizing prompts in multi-step LLM pipelines, where missing step-level supervision and inter-step dependencies make optimization difficult. It proposes ADOPT, an Adaptive Dependency-aware Prompt Optimization framework that models step dependencies for precise gradient estimation and uses a Shapley-based resource allocation mechanism. Experiments show ADOPT is effective and robust, consistently outperforming existing prompt optimization methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[ADOPT: Adaptive Dependency-aware Prompt Optimization Framework] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Multi-step LLM pipeline prompt optimization is difficult due to missing supervision and dependencies] --> P1[子问题/Sub-problem: Missing step-level supervision]
        Problem --> P2[子问题/Sub-problem: Inter-step dependencies]
        Method[主要方法/Method: ADOPT Framework] --> M1[关键技术/Key Technique: Explicit dependency modeling for text-gradient estimation]
        Method --> M2[关键技术/Key Technique: Decouples gradient estimation from updates]
        Method --> M3[关键技术/Key Technique: Shapley-based adaptive resource allocation]
        Results[关键结果/Results: Effective and robust, outperforms SOTA baselines] --> R1[实验/Experiments: Real-world datasets]
        Results --> R2[实验/Experiments: Diverse pipeline structures]
    ```

- **[arXiv260101] Iterative Deployment Improves Planning Skills in LLMs**
  - **tags:** [ai], [reinforcement learning], [iterative deployment, implicit reward, data curation, planning, fine-tuning]
  - **authors:** Augusto B. Corrêa, Yoav Gelberg, Luckeciano C. Melo, Ilia Shumailov, André G. Pereira, Yarin Gal
  - **institution:** University of Oxford, AI Sequrity Company, UFRGS
  - **link:** https://arxiv.org/pdf/2512.24940
  - **contributions:** 1. Demonstrates that iterative deployment and fine-tuning on curated user data significantly improves LLM planning skills, including emergent generalization to longer plans. 2. Provides a theoretical analysis showing iterative deployment effectively implements an outer-loop reinforcement learning process with an implicit reward function. 3. Highlights the AI safety implications of this implicit training regime and positions it as an alternative to explicit RL training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8da35d1ea681d386cec51c012c9f81bb54c6876b6c1e632e59874f77690cd1a_w640_q70.webp
  - **Simple LLM Summary:** The paper shows that repeatedly deploying LLMs and fine-tuning them on curated data from previous deployments significantly improves their planning capabilities. This process is analyzed as an implicit form of reinforcement learning, which raises safety concerns due to the undefined reward function and offers an alternative training paradigm based on data curation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Iterative Deployment Improves Planning Skills in LLMs] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM规划能力/LLM Planning Skills]
        C --> C1[迭代部署与微调/Iterative Deployment & Fine-tuning]
        C1 --> C2[用户数据筛选/User Data Curation]
        D --> D1[规划能力提升/Improved Planning Skills]
        D --> D2[发现隐式RL/Discovering Implicit RL]
        D2 --> D3[AI安全影响/AI Safety Implications]
    ```

- **[arXiv260101] RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment**
  - **tags:** [ai], [information retrieval], [relevance assessment, benchmark, long-tail, visual salience, e-commerce]
  - **authors:** Chenji Lu, Zhuo Chen, Hui Zhao, Zhenyi Wang, Pengjie Wang, Jian Xu, Bo Zheng
  - **institution:** Taobao & Tmall Group of Alibaba
  - **link:** https://arxiv.org/pdf/2512.24943
  - **contributions:** 1. Proposes RAIR, a comprehensive Chinese benchmark for e-commerce relevance assessment derived from real-world scenarios. 2. Establishes a standardized evaluation framework with universal rules to address the lack of standardized metrics. 3. Introduces a dataset with three specialized subsets (general, long-tail hard, visual salience) to evaluate fundamental, challenging, and multimodal capabilities.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01d0a7f153d6f84b77a35da0a0f62dec9a8af10bfb23f1a8a481697233cbe992_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes RAIR, a rule-aware benchmark for e-commerce search relevance assessment, to address the lack of complex and standardized evaluation datasets. It introduces a comprehensive dataset with three subsets to test different model capabilities. Experiments on 14 models show RAIR is challenging, with GPT-5 performing best, and it serves as a new industry benchmark.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RAIR: 一个用于电子商务相关性评估的规则感知基准 / RAIR: A Rule-Aware Benchmark for E-commerce Relevance Assessment]
        A --> B[核心问题/Problem: 现有基准缺乏复杂性，缺少标准化评估 / Existing benchmarks lack complexity and standardized evaluation]
        A --> C[主要方法/Method: 提出包含通用、长尾、视觉显著性子集的基准和规则框架 / Propose benchmark with general, long-tail, visual-salience subsets and rule framework]
        A --> D[关键结果/Results: 对14个模型构成挑战，GPT-5表现最佳，可作为行业基准 / Presents challenge to 14 models, GPT-5 performs best, serves as industry benchmark]
    ```

- **[arXiv260101] MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates for Exponentially Stabilizing Control**
  - **tags:** [ai], [reinforcement learning], [Lyapunov certificates, exponential stability, multi-step learning, actor-critic, maximum entropy RL]
  - **authors:** Yongwei Zhang, Yuanzhe Xing, Quan Quan, Zhikun She
  - **institution:** Beihang University
  - **link:** https://arxiv.org/pdf/2512.24955
  - **contributions:** 1. Proposes a novel framework (MSACL) that integrates exponential stability theory with maximum entropy RL via multi-step Lyapunov certificate learning, using off-policy data to learn certificates that satisfy theoretical stability conditions. 2. Introduces Exponential Stability Labels (ESL) and a λ-weighted aggregation mechanism to effectively balance the bias-variance trade-off in multi-step learning. 3. Guides policy optimization with a stability-aware advantage function to ensure the learned policy promotes rapid Lyapunov descent, achieving provable stability and robustness under simple rewards.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea102a46402567fc13871b6bc5f72e6c07e79e6ee87e8349aee1c18c8fc9627e_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes MSACL, a model-free reinforcement learning framework that ensures provable exponential stability by learning Lyapunov certificates from multi-step data and guiding policy optimization with a stability-aware advantage. It demonstrates superior performance over baseline and state-of-the-art Lyapunov-based RL methods across six benchmarks, achieving rapid convergence and robustness with simple rewards. The work establishes a link between Lyapunov theory and actor-critic frameworks for verifiably safe control.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Provable Stability in Model-Free RL / 模型无关RL的可证明稳定性]
        C --> C1[Multi-Step Lyapunov Certificate Learning / 多步李雅普诺夫证书学习]
        C --> C2[Stability-Aware Advantage Function / 稳定性感知优势函数]
        D --> D1[Superiority over SOTA / 优于现有最优方法]
        D --> D2[Exponential Stability & Robustness / 指数稳定性与鲁棒性]
    ```

- **[arXiv260101] ProDM: Synthetic Reality-driven Property-aware Progressive Diffusion Model for Coronary Calcium Motion Correction in Non-gated Chest CT**
  - **tags:** [cv], [medical image analysis], [diffusion models, motion correction, synthetic data, coronary artery calcium, non-gated CT]
  - **authors:** Xinran Gong, Gorkem Durak, Halil Ertugrul Aktas, Vedat Cicek, Jinkui Hao, Ulas Bagci, Nilay S. Shah, Bo Zhou
  - **institution:** Northwestern University, Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.24948
  - **contributions:** 1. A CAC motion simulation data engine that synthesizes realistic non-gated CT acquisitions from gated CTs for supervised training without paired data. 2. A property-aware learning strategy that incorporates calcium-specific priors via a differentiable consistency loss to preserve lesion integrity. 3. A progressive correction scheme that gradually reduces motion artifacts across diffusion steps to enhance stability and calcium fidelity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd53987de700ad7024fad5ea5d53da57ecb375707cda1bff594c7264ec4ca118_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes ProDM, a diffusion model framework to correct motion artifacts in coronary calcium lesions from non-gated chest CT scans. The method uses a synthetic data engine for training, incorporates calcium-specific priors, and applies progressive correction. Experiments show it improves scoring accuracy, lesion fidelity, and risk stratification compared to baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ProDM: Synthetic Reality-driven Property-aware Progressive Diffusion Model for Coronary Calcium Motion Correction in Non-gated Chest CT] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[非门控CT中冠脉钙化运动伪影影响评分/Non-gated CT CAC scoring affected by motion artifacts]
        C --> C1[合成数据引擎/Synthetic Data Engine]
        C --> C2[属性感知学习/Property-aware Learning]
        C --> C3[渐进式校正/Progressive Correction]
        D --> D1[提高评分准确性和病灶保真度/Improved scoring accuracy & lesion fidelity]
        D --> D2[提升风险分层性能/Enhanced risk stratification]
        D --> D3[抑制伪影，提升临床可用性/Suppresses artifacts & improves clinical usability]
    ```

- **[arXiv260101] Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning**
  - **tags:** [ai], [multi-armed bandits], [semi-overlapping multi-bandit, best arm identification, sequential support network learning, GapE algorithm, sample complexity]
  - **authors:** András Antos, András Millinghoffer, Péter Antal
  - **institution:** Budapest University of Technology and Economics, E-Group ICT Software Zrt.
  - **link:** https://arxiv.org/pdf/2512.24959
  - **contributions:** 1. Proposes a new pure-exploration model called the semi-overlapping multi-bandit (SOMMAB) for Sequential Support Network Learning (SSNL)., 2. Develops a generalized GapE algorithm for the SOMMAB setting., 3. Derives new exponential error bounds that improve the best-known constant in the exponent and scale linearly with the degree of overlap, showing sample complexity gains from shared evaluations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1ccf2e1312507d052da8a3c6c2b6fb042432d3f13e5efa2572b5d2cd1dff292_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a new framework called Sequential Support Network Learning (SSNL) and models it as a semi-overlapping multi-bandit (SOMMAB) problem, where a single evaluation provides feedback to multiple bandits. The authors develop a generalized GapE algorithm for SOMMABs and prove new, improved error bounds that demonstrate significant sample-complexity reductions due to structural overlap.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem: Selecting beneficial partners via shared, asymmetric evaluations"] --> P1["问题领域/Application Domains: MTL, ATL, FL, MAS"]
        Method["主要方法/Method: SOMMAB model & generalized GapE algorithm"] --> M1["模型/Model: Semi-overlapping multi-bandit"]
        Results["关键结果/Results: Improved error bounds & sample complexity gains"] --> R1["理论保证/Theoretical: Exponential bounds scale with overlap"]
    ```

- **[arXiv260101] Efficiently Estimating Data Efficiency for Language Model Fine-tuning**
  - **tags:** [nlp], [fine-tuning], [data efficiency, gradient cosine similarity, low-confidence examples, fine-tuning scaling, annotation cost]
  - **authors:** Gyung Hyun Je, Colin Raffel
  - **institution:** University of Toronto
  - **link:** https://arxiv.org/pdf/2512.24991
  - **code:** https://github.com/r-three/dataefficiency
  - **contributions:** 1. Introduced a concrete metric to quantify a task's data efficiency for LLM fine-tuning. 2. Proposed a method using gradient cosine similarity of low-confidence examples to predict data efficiency from a small number of samples. 3. Validated the approach on diverse tasks, achieving 8.6% prediction error and significantly reducing unnecessary annotations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd5fa15acf63fdcf1cd6c628775da72e936b364cb45a18adddcde2e329ce8c48_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of unknown data efficiency for fine-tuning LLMs, which leads to costly annotation cycles. It proposes predicting data efficiency using gradient cosine similarity from low-confidence examples, based on a small labeled set. The method achieves low prediction error and can eliminate hundreds of unnecessary annotations per task.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Efficiently Estimating Data Efficiency for Language Model Fine-tuning] --> B[核心问题/Problem: Unknown data efficiency for fine-tuning leads to costly annotation cycles]
        A --> C[主要方法/Method: Predict using gradient cosine similarity of low-confidence examples]
        A --> D[关键结果/Results: 8.6% prediction error, eliminates hundreds of annotations]
    ```

- **[arXiv260101] Attribution-Guided Distillation of Matryoshka Sparse Autoencoders**
  - **tags:** [mlsys], [llm training], [sparse autoencoders, mechanistic interpretability, gradient attribution, feature distillation, matryoshka]
  - **authors:** Cristina P. Martin-Linares, Jonathan P. Ling
  - **institution:** Johns Hopkins University
  - **link:** https://arxiv.org/pdf/2512.24975
  - **contributions:** 1. Introduces Distilled Matryoshka Sparse Autoencoders (DMSAEs), a novel training pipeline for distilling a compact, reusable core of consistent features from sparse autoencoders. 2. Proposes an iterative, attribution-guided distillation cycle that uses gradient × activation to select the most useful features based on their contribution to next-token loss. 3. Demonstrates empirically that the distilled core improves SAEBench metrics and enables the transfer of consistent latent features across different sparsity levels.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a691c55852370e5366257008c9914761d773cede53c49ece8c170d5653fcbac4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of feature redundancy and inconsistency in sparse autoencoders (SAEs) used for mechanistic interpretability. It proposes Distilled Matryoshka Sparse Autoencoders (DMSAEs), a method that iteratively distills a core set of useful features using gradient-based attribution. The results show that this approach yields a stable, compact feature set that improves performance and can be transferred across training runs and sparsity levels.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Attribution-Guided Distillation of Matryoshka Sparse Autoencoders] --> B
        A --> C
        A --> D
        B[核心问题/Problem: SAE特征冗余且不一致/SAE features are redundant and inconsistent]
        C[主要方法/Method: 基于归因的迭代蒸馏循环/Attribution-guided iterative distillation cycle]
        D[关键结果/Results: 获得紧凑、可迁移的特征核心/Obtains a compact, transferable feature core]
    ```

- **[arXiv260101] DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments**
  - **tags:** [cv], [embodied vision-language reasoning], [low-light vision, embodied question answering, vision-language models, image enhancement, benchmark]
  - **authors:** Yohan Park, Hyunwoo Ha, Wonjun Jo, Tae-Hyun Oh
  - **institution:** Korea Advanced Institute of Science and Technology (KAIST), Pohang University of Science and Technology (POSTECH)
  - **link:** https://arxiv.org/pdf/2512.24985
  - **contributions:** 1. Introduces DarkEQA, the first benchmark for evaluating Embodied Question Answering (EQA) under multi-level, physics-based low-light conditions. 2. Features a physically faithful degradation pipeline that models illumination drop and sensor noise in linear RAW space, followed by an ISP-inspired renderer. 3. Systematically evaluates and reveals the limitations of state-of-the-art VLMs and the effectiveness of Low-Light Image Enhancement (LLIE) models as pre-processors in this challenging scenario.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f144c0ff2baabb069f605975462919cef76b3f54919a8c9db67dab0432973003_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies a gap in evaluating Vision-Language Models (VLMs) for embodied agents under low-light conditions and proposes DarkEQA, a new benchmark that simulates realistic dark environments. The benchmark uses a physics-based image degradation model to test VLM robustness and the utility of image enhancement techniques. The evaluation reveals significant performance drops in VLMs under low-light, highlighting a critical area for improvement in robust embodied AI.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DarkEQA: Benchmarking VLMs for EQA in Low-Light] --> B[核心问题/Problem: Existing EQA benchmarks overlook low-light conditions, a necessity for 24/7 robot operation.]
        A --> C[主要方法/Method: Proposes DarkEQA benchmark with physics-based low-light simulation in RAW space and ISP pipeline.]
        A --> D[关键结果/Results: Evaluates VLMs & LLIE models, systematically revealing VLM limitations under low-light.]
    ```

- **[arXiv260101] Diffusion Language Models are Provably Optimal Parallel Samplers**
  - **tags:** [mlsys], [diffusion models], [diffusion language models, parallel sampling, chain-of-thought, remasking, revision]
  - **authors:** Haozhe Jiang, Nika Haghtalab, Lijie Chen
  - **institution:** University of California, Berkeley
  - **link:** https://arxiv.org/pdf/2512.25014
  - **contributions:** 1. Formalized a model of parallel sampling and proved that DLMs with CoT can simulate any parallel sampling algorithm with an optimal number of sequential steps. 2. Showed that enabling remasking or revision with CoT allows DLMs to simulate any parallel sampling algorithm with optimal space complexity. 3. Established a strict expressivity gap, proving DLMs with revision or remasking are strictly more expressive than those without.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43c65e3d030ce4b9471215a4735f2217f9be018da8e7b5ecc092a62d1394440b_w640_q70.webp
  - **Simple LLM Summary:** This paper provides a theoretical foundation for the efficiency of Diffusion Language Models (DLMs) as parallel samplers. It proves that DLMs augmented with chain-of-thought reasoning can simulate any parallel sampling algorithm with optimal sequential steps and, when further equipped with token remasking or revision, also achieve optimal space complexity. The results theoretically justify DLMs as highly efficient parallel samplers and advocate for enabling revision capabilities in such models.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Diffusion Language Models are Provably Optimal Parallel Samplers<br>扩散语言模型是可证明最优的并行采样器"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>DLMs的理论优势与效率极限未明<br>Theoretical advantages and efficiency limits of DLMs are unclear"] --> P1["并行采样效率/Parallel Sampling Efficiency"]
        Problem --> P2["空间复杂度/Space Complexity"]
        Method["主要方法/Method<br>形式化并行采样模型与电路复杂度<br>Formalize parallel sampling model & circuit complexity"] --> M1["增强CoT/Augment with CoT"]
        Method --> M2["引入重掩码或修订/Introduce Remasking or Revision"]
        Results["关键结果/Results"] --> R1["最优顺序步骤/Optimal Sequential Steps"]
        Results --> R2["最优空间复杂度/Optimal Space Complexity"]
        Results --> R3["严格表达能力差距/Strict Expressivity Gap"]
    ```

- **[arXiv260101] Convergence of the generalization error for deep gradient flow methods for PDEs**
  - **tags:** [ai], [scientific machine learning], [deep gradient flow methods, generalization error, partial differential equations, neural networks, approximation error]
  - **authors:** Chenguang Liu, Antonis Papapantoleon, Jasper Rou
  - **institution:** (Inferred from author names and typical affiliations in the field; specific institutions not listed on the first page. Could be academic institutions like universities.)
  - **link:** https://arxiv.org/pdf/2512.25017
  - **contributions:** 1. Provides a rigorous mathematical framework for analyzing the generalization error of Deep Gradient Flow Methods (DGFMs) for solving PDEs. 2. Proves that the approximation error for PDE solutions using neural networks converges to zero as the network width increases. 3. Derives and analyzes the gradient flow dynamics in the wide network limit, showing the training error converges as training time increases.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ade90edaf9660be616e42f9a752fe8dcdd594d87db2454f913bca0a983f2d8bc_w640_q70.webp
  - **Simple LLM Summary:** This paper establishes a mathematical foundation for Deep Gradient Flow Methods (DGFMs) used to solve high-dimensional PDEs. It decomposes the generalization error into approximation and training components, proving both converge to zero as the number of neurons and training time go to infinity. The main conclusion is that DGFMs are theoretically sound, with provable convergence of the total error.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Convergence of the generalization error for deep gradient flow methods for PDEs] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[为DGFM提供数学基础/Provide mathematical foundation for DGFMs]
        C --> C1[分解泛化误差/Decompose generalization error]
        C1 --> C2[近似误差分析/Analyze approximation error]
        C1 --> C3[训练误差分析/Analyze training error]
        D --> D1[近似误差趋于零/Approximation error tends to zero]
        D --> D2[训练误差在极限下收敛/Training error converges in limit]
        D --> D3[泛化误差趋于零/Generalization error tends to zero]
    ```

- **[arXiv260101] ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning**
  - **tags:** [ai], [reinforcement learning from human feedback (RLHF)], [preference strength, reward modeling, sample efficiency, utility difference, Pearson Distance Correlation (PDC)]
  - **authors:** Timo Kaufmann, Yannick Metz, Daniel Keim, Eyke Hüllermeier
  - **institution:** LMU Munich, University of Konstanz
  - **link:** https://arxiv.org/pdf/2512.25023
  - **contributions:** 1. ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals. 2. Empirical evidence of improved sample efficiency and robustness across diverse tasks. 3. The Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/89532a897b8fa7db270c20a989bfbc8848f6809665ba966305a08daa55266fce_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limitation of standard RLHF, which only captures the direction of a preference but not its strength. It proposes ResponseRank, a method that learns preference strength by ranking responses using relative differences in noisy proxy signals (like response times) within local strata. The method demonstrates improved sample efficiency and robustness across synthetic, language modeling, and RL control tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[标准RLHF仅提供偏好方向/Standard RLHF only provides preference direction]
        B --> B2[偏好强度难以可靠测量/Preference strength is hard to measure reliably]
        C --> C1[利用代理信号(如响应时间)/Leverage proxy signals (e.g., response time)]
        C --> C2[局部层内相对比较/Local within-strata relative comparison]
        C --> C3[排序推断强度/Rank to infer strength]
        D --> D1[提升样本效率与鲁棒性/Improved sample efficiency & robustness]
        D --> D2[提出新评估指标PDC/Proposed new metric PDC]
    ```

- **[arXiv260101] Generative Classifiers Avoid Shortcut Solutions**
  - **tags:** [ai], [generative models], [generative classifiers, spurious correlations, distribution shift, diffusion models, autoregressive models]
  - **authors:** Alexander C. Li, Ananya Kumar, Deepak Pathak
  - **institution:** Carnegie Mellon University, Stanford University
  - **link:** https://arxiv.org/pdf/2512.25034
  - **code:** https://github.com/alexlioralexli/generative-classifiers
  - **contributions:** 1. Demonstrates that generative classifiers (using class-conditional generative models) inherently avoid shortcut learning by modeling all features, not just spurious ones. 2. Shows that generative classifiers achieve state-of-the-art performance on multiple image and text distribution shift benchmarks without specialized techniques. 3. Provides a theoretical analysis in a Gaussian toy setting to explain the inductive biases and data conditions favoring generative classifiers.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f744eff83ad768a9dc5e431ef5b2d98baefe24c12d01fc980aa2fa92c3c21c65_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of discriminative classifiers learning spurious shortcuts that fail under distribution shift. It proposes using generative classifiers, which model p(x|y), and finds they avoid shortcuts and achieve state-of-the-art robustness on standard benchmarks without needing specialized training tricks. The main conclusion is that generative classifiers offer a simple and effective alternative for building more robust models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Generative Classifiers Avoid Shortcut Solutions] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Discriminative models learn spurious shortcuts<br>判别模型学习虚假捷径]
        C --> C1[Use class-conditional generative models<br>使用类条件生成模型]
        C --> C2[Model p(x|y) instead of p(y|x)<br>建模 p(x|y) 而非 p(y|x)]
        D --> D1[Avoid shortcuts & SOTA on distribution shift<br>避免捷径并在分布偏移上达到SOTA]
        D --> D2[Simple training, no specialized techniques<br>训练简单，无需专门技术]
    ```

- **[arXiv260101] Reliable and Resilient Collective Communication Library for LLM Training and Serving**
  - **tags:** [mlsys], [communication & networking], [fault-tolerant collective communication, multi-NIC failover, connection migration, bandwidth-aware load redistribution, resilient collective algorithms]
  - **authors:** Wei Wang, Nengneng Yu, Sixian Xiong, Zaoxing Liu
  - **institution:** University of Maryland, College Park
  - **link:** https://arxiv.org/pdf/2512.25059
  - **code:** https://github.com/r2cc-project/R-2CCL
  - **contributions:** 1. A fault-tolerant communication library (R²CCL) that provides lossless, low-overhead failover by exploiting multi-NIC hardware. 2. Techniques including rapid connection migration, bandwidth-aware load redistribution, and resilient collective algorithms to maintain progress under network failures. 3. Demonstrated high robustness to NIC failures with minimal overhead (&lt;1% for training, &lt;3% for inference) and significant performance improvements over baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd037366831b8135233f491feff11095f79c30662f36cb517794f6588542c452_w640_q70.webp
  - **Simple LLM Summary:** The paper presents R²CCL, a fault-tolerant collective communication library designed to handle network faults in large-scale LLM training and serving. It achieves low-overhead recovery through techniques like rapid connection migration and bandwidth-aware load redistribution. Evaluation shows it incurs minimal performance overhead and significantly outperforms existing solutions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Reliable and Resilient Collective Communication Library for LLM Training and Serving] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Network faults waste GPU hours and cause job failures in large-scale ML clusters]
        Method[主要方法/Method: R²CCL library with rapid connection migration, bandwidth-aware load redistribution, and resilient collective algorithms]
        Results[关键结果/Results: <1% training overhead, <3% inference overhead, 12.18x-47x faster than baselines]
    ```

- **[arXiv260101] On the geometry and topology of representations: the manifolds of modular addition**
  - **tags:** [ai], [mechanistic interpretability], [modular addition, manifold hypothesis, topological analysis, circuit universality, attention mechanisms]
  - **authors:** Gabriela Moisescu-Pareja, Gavin McCracken, Harley Wiltzer, Vincent Létourneau, Colin Daniels, Doina Precup, Jonathan Love
  - **institution:** McGill University, Mila, Université de Montréal, Leiden University, Google DeepMind
  - **link:** https://arxiv.org/pdf/2512.25060
  - **contributions:** 1. Demonstrates that different neural network architectures (uniform vs. learnable attention) learn topologically and geometrically equivalent representations for modular addition, refuting prior claims of disparate circuits. 2. Introduces a methodology that studies learned representations as collective manifolds rather than interpreting individual neurons, applying tools from topology. 3. Provides statistical analysis across hundreds of circuits to show the similarity of learned modular addition algorithms under common deep learning paradigms, supporting the universality hypothesis.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17fc5efae344878642fe3a2ab7985eeb71b49efef00cf839b1bb65714a390090_w640_q70.webp
  - **Simple LLM Summary:** This paper challenges the claim that different neural network architectures learn fundamentally different circuits for modular addition. By analyzing learned representations as manifolds using topological methods, the authors show that both uniform and trainable attention architectures implement the same underlying algorithm with equivalent representations. The work provides statistical evidence supporting the universality hypothesis in mechanistic interpretability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[On the geometry and topology of representations: the manifolds of modular addition] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Do different architectures learn distinct circuits for modular addition?]
        C --> C1[Analyze representations as manifolds using topology/将表示作为流形进行拓扑分析]
        D --> D1[Uniform and learnable attention learn the same algorithm/均匀和可学习注意力学习相同算法]
        D --> D2[Representations are topologically & geometrically equivalent/表示在拓扑和几何上等价]
    ```

- **[arXiv260101] Many Minds from One Model: Bayesian Transformers for Population Intelligence**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [Bayesian Transformers, Variational Inference, Population Diversity, Normalization Layers, Wisdom of Crowds]
  - **authors:** Diji Yang, Yi Zhang
  - **institution:** University of California Santa Cruz
  - **link:** https://arxiv.org/pdf/2512.25063
  - **contributions:** 1. Proposes Population Bayesian Transformers (B-Trans), a method to convert a standard LLM into a Bayesian model by treating normalization layer biases as stochastic variables with a Gaussian variational approximation, enabling diverse model sampling from a single weight set. 2. Introduces sequence-level noise freezing to maintain temporal coherence within each sampled model instance's generation, ensuring consistent behavior across tokens. 3. Demonstrates that aggregating predictions from a population of sampled B-Trans instances enhances exploration and decision-making, leading to superior semantic diversity and task performance in zero-shot generation, RLVR, and RL without labels.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae0113a2c263c7e9a33e3b5ce49ac7afb88b3a3baeb7fd88c121fac5ef4b745b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of diversity and exploration in deterministic LLMs by proposing B-Trans, which transforms a standard LLM into a Bayesian model by making normalization biases stochastic. This allows sampling diverse "minds" from one model, and aggregating their predictions improves performance and semantic variety in reasoning tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Many Minds from One Model: Bayesian Transformers for Population Intelligence] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现代Transformer是单一思维的/Modern Transformers are single-minded]
        B --> B2[缺乏多样性阻碍探索/Lack of diversity hinders exploration]
        C --> C1[提出B-Trans: 贝叶斯Transformer/Propose B-Trans: Bayesian Transformer]
        C --> C2[归一化层偏置作为随机变量/Normalization biases as stochastic variables]
        C --> C3[序列级噪声冻结/Sequence-level noise freezing]
        D --> D1[增强语义多样性/Improved semantic diversity]
        D --> D2[提升任务性能/Better task performance]
        D --> D3[实现群体智慧/Achieves wisdom of crowds]
    ```

- **[arXiv260101] Scaling Open-Ended Reasoning to Predict the Future**
  - **tags:** [ai], [language model forecasting], [open-ended forecasting, reinforcement learning, retrieval-augmented generation, calibration, Qwen3]
  - **authors:** Nikhil Chandak, Shashwat Goel, Ameya Prabhu, Moritz Hardt, Jonas Geiping
  - **institution:** Max Planck Institute for Intelligent Systems, ELLIS Institute Tübingen, Tübingen AI Center, University of Tübingen
  - **link:** https://arxiv.org/pdf/2512.25070
  - **code:** /github (URL implied from first page content)
  - **contributions:** 1. A fully automated pipeline to synthesize a large-scale dataset (OpenForesight) for training language models on open-ended forecasting questions from news events. 2. A specialized forecasting system integrating retrieval and an improved RL reward function, trained on Qwen3, which prevents future information leakage. 3. The OpenForecaster 8B model, which demonstrates that specialized training improves accuracy, calibration, and consistency, matching larger proprietary models, with calibration benefits generalizing to other benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7433331ffccb9fb0f52db33a75b12ae808ae87c5410037274fcfdc5f22b3505_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of training language models for open-ended future prediction. The authors propose an automated method to generate a large forecasting dataset from news and train a specialized model (OpenForecaster 8B) using retrieval and an improved RL reward. Their final model matches the performance of much larger proprietary models, showing improved prediction accuracy, calibration, and consistency.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Scaling Open-Ended Reasoning to Predict the Future<br>预测未来的开放式推理扩展] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[训练语言模型进行开放式未来预测<br>Train LLMs for open-ended future forecasting]
        C --> C1[自动从新闻生成数据集<br>Automated dataset generation from news]
        C --> C2[使用检索和改进的RL进行训练<br>Training with retrieval & improved RL]
        C --> C3[防止未来信息泄露<br>Prevent future info leakage]
        D --> D1[OpenForecaster 8B 匹配更大模型<br>Matches larger proprietary models]
        D --> D2[提升准确性、校准和一致性<br>Improves accuracy, calibration, consistency]
    ```

- **[arXiv260101] Coordinated Humanoid Manipulation with Choice Policies**
  - **tags:** [ai], [imitation learning], [humanoid robot, teleoperation, choice policy, multimodal behavior, whole-body coordination]
  - **authors:** Haozhi Qi, Yen-Jen Wang, Toru Lin, Brent Yi, Yi Ma, Koushil Sreenath, Jitendra Malik
  - **institution:** UC Berkeley
  - **link:** https://arxiv.org/pdf/2512.25072
  - **code:** https://choice-policy.github.io
  - **contributions:** 1. A modular teleoperation interface that decomposes humanoid control into intuitive submodules (e.g., hand-eye coordination, locomotion) for efficient, high-quality data collection. 2. The Choice Policy, a novel imitation learning architecture that generates multiple candidate actions and learns to score them, enabling fast inference and effective modeling of multimodal behaviors. 3. Empirical validation on real-world tasks (dishwasher loading, whiteboard wiping) showing superior performance over diffusion policies and behavior cloning, and highlighting the critical role of hand-eye coordination.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8fc3a4a5fc6ec972fc1d7ab23cbd63d6c1c8efc8d326140cc34f70ea5a5cb65_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the challenge of achieving robust whole-body coordination for humanoid robots in unstructured environments. It proposes a system combining a modular teleoperation interface for data collection with a novel "Choice Policy" for imitation learning, which scores multiple candidate actions. Experiments on real-world tasks demonstrate that this approach outperforms baseline methods and that hand-eye coordination is crucial for success in long-horizon manipulation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Coordinated Humanoid Manipulation with Choice Policies] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1["实现人形机器人头、手、腿的鲁棒全身协调/Robust whole-body coordination for humanoids"]
        C --> C1["模块化遥操作接口/Modular teleoperation interface"]
        C --> C2["选择策略：生成并评估候选动作/Choice Policy: generate & score candidate actions"]
        D --> D1["在洗碗机装载、白板擦拭任务上超越基线/Outperforms baselines on dishwasher loading & whiteboard wiping"]
        D --> D2["手眼协调对长时域任务至关重要/Hand-eye coordination is critical for long-horizon tasks"]
    ```

- **[arXiv260101] Spike-Timing-Dependent Plasticity for Bernoulli Message Passing**
  - **tags:** [ai], [computational neuroscience], [spike-timing-dependent plasticity, Bayesian inference, message passing, factor graphs, spiking neural networks]
  - **authors:** Sepideh Adamiat, Wouter M. Kouw, Bert de Vries
  - **institution:** TU Eindhoven, Lazy Dynamics B.V.
  - **link:** https://arxiv.org/pdf/2512.23728
  - **contributions:** 1. Bridging Bayesian inference and spike-based neural computation by designing spiking neural networks for Bernoulli message passing. 2. Employing spike-timing-dependent plasticity (STDP), a biologically plausible Hebbian learning rule, to train these networks. 3. Demonstrating the approach's versatility by applying it to a factor graph example from coding theory for signal transmission over an unreliable channel.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a449542e05c85b78a1c2c36d2343549e26e8c17a9edfccf34c692fd2512f710c_w640_q70.webp
  - **Simple LLM Summary:** This paper bridges Bayesian inference and spike-based neural activity by designing spiking neural networks that perform message passing for Bernoulli variables. The networks are trained using the biologically plausible spike-timing-dependent plasticity rule. The results show the network's performance matches the true numerical solution, and the method is demonstrated on a coding theory problem.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Spike-Timing-Dependent Plasticity for Bernoulli Message Passing] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[连接贝叶斯推理与脉冲神经活动/Bridging Bayesian inference and spike-based neural activity]
        C --> C1[设计用于伯努利消息传递的脉冲神经网络/Designing SNNs for Bernoulli message passing]
        C --> C2[使用脉冲时序依赖可塑性进行训练/Using STDP for training]
        D --> D1[网络性能匹配真实数值解/Network performance matches true numerical solution]
        D --> D2[方法应用于编码理论因子图/Method applied to coding theory factor graph]
    ```

- **[arXiv260101] Fitted Q Evaluation Without Bellman Completeness via Stationary Weighting**
  - **tags:** [ai], [reinforcement learning], [off-policy evaluation, fitted Q-evaluation, Bellman completeness, stationary distribution, density ratio]
  - **authors:** Lars van der Laan, Nathan Kallus
  - **institution:** University of Washington, Netflix, Cornell University
  - **link:** https://arxiv.org/pdf/2512.23805
  - **contributions:** 1. Identified the fundamental norm mismatch causing FQE's reliance on Bellman completeness, 2. Proposed a simple fix by reweighting regression steps with an estimated stationary density ratio, 3. Provided strong evaluation guarantees without requiring realizability or Bellman completeness, avoiding geometric error blow-up.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0334a3bea1166b5e2cbda1d446e2561bf91e6e45af4da23da7bb2759aa9a5043_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the fragility of Fitted Q-evaluation (FQE) in off-policy reinforcement learning, which traditionally requires the strong assumption of Bellman completeness. The authors propose a simple modification to FQE by reweighting each regression step using an estimate of the stationary density ratio, aligning the optimization with the contractive norm of the Bellman operator. This enables robust policy evaluation guarantees even when the function class is not Bellman complete, maintaining the practicality of regression-based methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Fitted Q Evaluation Without Bellman Completeness via Stationary Weighting] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[标准FQE需要贝尔曼完备性假设 / Standard FQE requires Bellman completeness]
        B --> B2[假设过强且难以满足 / Assumption is strong and hard to satisfy]
        C --> C1[识别根本的范数不匹配 / Identify fundamental norm mismatch]
        C --> C2[使用平稳密度比重新加权回归步骤 / Reweight regression steps using stationary density ratio]
        D --> D1[无需贝尔曼完备性的强保证 / Strong guarantees without Bellman completeness]
        D --> D2[避免几何误差爆炸 / Avoid geometric error blow-up]
    ```

- **[arXiv260101] Quantum Error Mitigation with Attention Graph Transformers for Burgers Equation Solvers on NISQ Hardware**
  - **tags:** [mlsys], [others], [quantum error mitigation, attention graph neural network, NISQ hardware, Burgers equation, zero-noise extrapolation]
  - **authors:** Seyed Mohamad Ali Tousi, Adib Bazgir, Yuwen Zhang, G. N. DeSouza
  - **institution:** University of Missouri
  - **link:** https://arxiv.org/pdf/2512.23817
  - **contributions:** 1. A hybrid quantum-classical framework for solving the viscous Burgers equation on NISQ hardware, using the Cole-Hopf transformation and Trotterized quantum circuits. 2. The creation of a large parametric dataset of noisy, ZNE-corrected, hardware, and classical solutions with circuit metadata for data-driven error mitigation. 3. A novel attention-based graph neural network model that ingests circuit features and noisy outputs to predict error-mitigated solutions, outperforming ZNE alone.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57bb32110f5a354755f846f1b5a7ab41ac3fc4a701e97b9b25486f2bab0c72eb_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a hybrid quantum-classical framework enhanced with a learned error mitigation model to solve the Burgers equation on noisy quantum hardware. The method uses an attention graph neural network trained on a dataset of noisy quantum simulations to predict corrected solutions. The results show the learned model consistently reduces errors beyond standard zero-noise extrapolation techniques.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Quantum Error Mitigation with Attention Graph Transformers for Burgers Equation Solvers on NISQ Hardware] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[在含噪声量子硬件上求解Burgers方程/Solving Burgers Equation on Noisy Quantum Hardware]
        C --> C1[混合量子-经典框架与注意力图神经网络/Hybrid Quantum-Classical Framework with Attention GNN]
        D --> D1[学习模型超越ZNE，减少量子-经典解差异/Learned Model Outperforms ZNE, Reduces Quantum-Classical Discrepancy]
    ```

- **[arXiv260101] A Test of Lookahead Bias in LLM Forecasts**
  - **tags:** [ai], [machine learning for finance], [lookahead bias, pre-training data detection, forecast accuracy, Lookahead Propensity (LAP), statistical test]
  - **authors:** Zhenyu Gao, Wenxi Jiang, Yutong Yan
  - **institution:** The Chinese University of Hong Kong (CUHK Business School, Department of Finance)
  - **link:** https://arxiv.org/pdf/2512.23847
  - **contributions:** 1. Proposes a novel statistical test to detect lookahead bias in LLM-generated economic forecasts. 2. Introduces the concept of Lookahead Propensity (LAP), a metric estimating the likelihood a prompt was in the model's training data. 3. Demonstrates the test's application on real-world forecasting tasks (stock returns and capital expenditures) to assess forecast validity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3862b50bacdf9663a9e884b32c3a91e6601a609ccd21f8f622e4d85c8d4b3dee_w640_q70.webp
  - **Simple LLM Summary:** This paper develops a statistical test to detect lookahead bias in LLM forecasts by correlating forecast accuracy with a new metric called Lookahead Propensity (LAP), which estimates if a prompt was in the training data. The method is applied to financial forecasting tasks, providing a cost-efficient tool to assess the reliability of LLM-generated predictions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Test of Lookahead Bias in LLM Forecasts] --> B[核心问题/Problem: Detecting lookahead bias in LLM economic forecasts]
        A --> C[主要方法/Method: Use pre-training data detection to compute Lookahead Propensity (LAP)]
        A --> D[关键结果/Results: Positive correlation between LAP and accuracy indicates lookahead bias; Test applied to financial tasks]
    ```

- **[arXiv260101] Energy-Tweedie: Score meets Score, Energy meets Energy**
  - **tags:** [ai], [diffusion models], [Tweedie's formula, energy score, elliptical distributions, score estimation, denoising]
  - **authors:** Andrej Leban
  - **institution:** University of Michigan
  - **link:** https://arxiv.org/pdf/2512.23818
  - **contributions:** 1. Extends Tweedie's identity beyond the exponential family to a broad class of noising distributions (energy models/elliptical distributions). 2. Derives a fundamental identity connecting the Stein score of the noisy marginal to the (path-) derivative of the energy score. 3. Proposes a practical score estimation method based on this identity, using samples from the denoising posterior.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ff6ceee3e2856f05799a33cb8c1de1d291f58a0c5ebc90275070d02dddc961d_w640_q70.webp
  - **Simple LLM Summary:** This paper connects the concepts of denoising and score estimation by extending Tweedie's formula to elliptical distributions and deriving a new identity linking the energy score's derivative to the Stein score. This allows for new applications in score estimation, noise parameter estimation, and enables the use of energy score models with a wider variety of noising distributions in diffusion model samplers.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Energy-Tweedie: Score meets Score, Energy meets Energy] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[连接去噪与评分规则/Linking Denoising and Scoring Rules]
        C --> C1[扩展Tweedie公式至椭圆分布/Extend Tweedie's Formula to Elliptical Distributions]
        C --> C2[推导能量评分与Stein评分的关系/Derive Identity Between Energy Score and Stein Score]
        D --> D1[提出基于新恒等式的评分估计方法/Propose Score Estimation Method]
        D --> D2[支持更广泛的噪声分布/Enable Wider Array of Noising Distributions]
    ```

- **[arXiv260101] Tensor Computing Interface: An Application-Oriented, Lightweight Interface for Portable High-Performance Tensor Network Applications**
  - **tags:** [mlsys], [compiler & ir], [tensor networks, high-performance computing, portable interface, tensor linear-algebra, Cytnx]
  - **authors:** Rong-Yang Sun, Tomonori Shirakawa, Hidehiko Kohshiro, D. N. Sheng, Seiji Yunoki
  - **institution:** California State University Northridge, RIKEN
  - **link:** https://arxiv.org/pdf/2512.23917
  - **contributions:** 1. Introduces the Tensor Computing Interface (TCI), a lightweight, application-oriented API for framework-independent tensor network applications. 2. Provides a well-defined type system and a minimal, expressive set of core functions abstracting tensor objects and operations. 3. Demonstrates through numerical experiments that TCI enables seamless code migration across heterogeneous platforms while maintaining performance comparable to native implementations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa77bed89109740ba89e21e2beb0128aa40959ecc783f216c3104fb3a4a59038_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of portability in tensor network applications due to framework-specific dependencies. It proposes the Tensor Computing Interface (TCI), a lightweight API that abstracts tensor operations, enabling developers to write portable, high-performance code. The authors demonstrate that TCI-based applications can be migrated across different hardware and software backends without sacrificing performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Tensor Computing Interface (TCI)") --> Problem("核心问题/Problem: Lack of unified interface limits tensor network application portability")
        Root --> Method("主要方法/Method: Lightweight, application-oriented API with abstracted tensor type system and core functions")
        Root --> Results("关键结果/Results: Enables seamless cross-platform migration with native-level performance")
    ```

- **[arXiv260101] A multimodal Transformer for InSAR-based ground deformation forecasting with cross-site generalization across Europe**
  - **tags:** [cv], [remote sensing image analysis], [InSAR, Transformer, ground deformation forecasting, cross-site generalization, multimodal learning]
  - **authors:** Wendong Yao, Binhua Huang, Soumyabrata Dev
  - **institution:** ADAPT SFI Research Centre, University College Dublin
  - **link:** https://arxiv.org/pdf/2512.23906
  - **contributions:** 1. Proposed a novel multimodal patch-based Transformer architecture for InSAR-based ground deformation nowcasting, integrating displacement snapshots with static kinematic indicators and temporal encodings. 2. Demonstrated superior performance of the proposed model over baseline models (CNN-LSTM, STGCN) on a test tile in eastern Ireland, achieving high accuracy (RMSE=0.90mm, R²=0.97). 3. Showcased strong cross-site generalization by training on one tile and applying the model without fine-tuning to five unseen European tiles, maintaining high performance (R²≥0.93) across diverse deformation patterns.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/36024dc5598b92b146557714c9e66eeb494b793bdcfaacb98b73cf6725cc8bfa_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of forecasting ground deformation from InSAR time series data. It proposes a multimodal Transformer model that combines recent displacement maps with kinematic indicators and temporal features to predict the next displacement epoch. The model achieves high accuracy and demonstrates strong generalization across different geographic sites in Europe without requiring retraining.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[论文标题: A multimodal Transformer for InSAR-based ground deformation forecasting] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: 如何利用历史InSAR数据预测未来的地表形变?] --> P1[挑战/Challenges: 长期趋势、季节周期、突变事件的叠加]
        Method[主要方法/Method: 多模态Transformer] --> M1[输入/Inputs: 近期形变图、静态运动学指标、时间编码]
        Method --> M2[任务/Task: 单步、固定间隔的下一时期临近预报]
        Results[关键结果/Results] --> R1[性能/Performance: RMSE=0.90mm, R²=0.97 (爱尔兰测试集)]
        Results --> R2[泛化/Generalization: 跨欧洲5个未见区域，R²≥0.93]
    ```

- **[arXiv260101] Assessing generative modeling approaches for free energy estimates in condensed matter**
  - **tags:** [ai], [generative models], [free energy estimation, normalizing flows, generative modeling, Jarzynski equality, molecular simulation]
  - **authors:** Maximilian Schebek, Jiajun He, Emil Hoffmann, Yuanqi Du, Frank Noé, Jutta Rogal
  - **institution:** Freie Universität Berlin, University of Cambridge, Cornell University, Microsoft Research AI for Science, Rice University, Flatiron Institute
  - **link:** https://arxiv.org/pdf/2512.23930
  - **contributions:** 1. Systematic review and benchmarking of generative-model-based methods for free energy estimation in condensed matter systems., 2. Evaluation of discrete and continuous normalizing flows, FEAT, and the escorted Jarzynski equality on coarse-grained ice and Lennard-Jones solids., 3. Provides a quantitative framework comparing accuracy, data efficiency, cost, and scalability to guide method selection.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e09c407083c9249376083548ea23d622f173cbe2b1df29b4bfcf42731dca47e3_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the computationally expensive challenge of estimating free energy differences in molecular simulations by systematically benchmarking generative modeling approaches like normalizing flows. It evaluates these methods on condensed-matter systems to assess their trade-offs in efficiency, accuracy, and scalability. The main conclusion provides a quantitative framework for selecting effective free energy estimation strategies in condensed-phase systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Assessing generative modeling approaches for free energy estimates in condensed matter] --> B[核心问题/Problem: Accurate free energy estimation is computationally expensive]
        A --> C[主要方法/Method: Benchmark generative models (normalizing flows, FEAT, escorted Jarzynski)]
        A --> D[关键结果/Results: Provides a quantitative framework for method selection]
    ```

- **[arXiv260101] Stationary Reweighting Yields Local Convergence of Soft Fitted Q-Iteration**
  - **tags:** [ai], [reinforcement learning], [fitted Q-iteration, entropy regularization, stationary distribution, Bellman operator, offline RL]
  - **authors:** Lars van der Laan, Nathan Kallus
  - **institution:** University of Washington, Netflix, Cornell University
  - **link:** https://arxiv.org/pdf/2512.23927
  - **contributions:** 1. Identified a geometric mismatch causing instability in soft FQI, showing the soft Bellman operator is contractive in the stationary norm of the soft-optimal policy, not the behavior norm. 2. Proposed stationary-reweighted soft FQI, a method that reweights regression updates using the current policy's stationary distribution to restore contraction. 3. Provided a theoretical analysis proving local linear convergence under function approximation with damped weight-estimation errors and suggested a continuation approach for global convergence via temperature annealing.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a133d7f0a68e796e5601b9dd17517ab3deea2ceb5f9dce008c265e4c615a1b43_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the instability of entropy-regularized fitted Q-iteration (soft FQI) under function approximation and distribution shift in offline reinforcement learning. The authors propose a new method, stationary-reweighted soft FQI, which reweights updates using the policy's stationary distribution to restore local contraction. They prove local linear convergence and suggest that global convergence can be achieved by gradually reducing the softmax temperature.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Stationary Reweighting Yields Local Convergence of Soft Fitted Q-Iteration] --> B[核心问题/Problem: Soft FQI instability under function approximation & distribution shift]
        A --> C[主要方法/Method: Stationary-reweighted soft FQI (reweights updates using policy's stationary distribution)]
        A --> D[关键结果/Results: Local linear convergence proven; global convergence via temperature annealing suggested]
    ```

- **[arXiv260101] Fundamental limits for weighted empirical approximations of tilted distributions**
  - **tags:** [other], [Monte Carlo simulation, rare event estimation], [exponential tilting, self-normalized importance sampling, rare event simulation, scaling limits, weighted empirical approximations]
  - **authors:** Sarvesh Ravichandran Iyer, Himadri Mandal, Dhruman Gupta, Rushil Gupta, Agniv Bandhyopadhyay, Achal Bassamboo, Varun Gupta, Sandeep Juneja
  - **institution:** Ashoka University, Indian Statistical Institute, Kolkata, Tata Institute of Fundamental Research, Northwestern University, The University of Utah
  - **link:** https://arxiv.org/pdf/2512.23979
  - **contributions:** 1. Provides a sharp asymptotic characterization of the accuracy of a self-normalized importance sampler for tilted distributions. 2. Establishes a fundamental dichotomy in sample complexity: polynomial scaling for bounded random vectors vs. super-polynomial scaling for unbounded ones. 3. Analyzes the efficiency of data-driven tilting when the underlying distribution is unknown but samples are available.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2b2078a5f12e67b3138f44c52f21fc16fdfbf4166041f6980ae84c0a56a3c52_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the efficiency of generating samples from a tilted distribution when only samples from the original, unknown distribution are available, using a self-normalized importance sampling method. It provides a precise characterization of the estimator's accuracy based on sample size and tilt degree. The key finding is a dichotomy in sample complexity: it grows polynomially for bounded random vectors but super-polynomially for unbounded ones.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Fundamental limits for weighted empirical approximations of tilted distributions<br>倾斜分布加权经验近似的根本极限") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("从倾斜分布生成样本<br>Generating samples from tilted distribution")
        Problem --> P2("基础分布未知<br>Underlying distribution unknown")
        Method --> M1("自归一化重要性采样<br>Self-normalized importance sampler")
        Results --> R1("有界变量: 样本量多项式增长<br>Bounded: Polynomial sample growth")
        Results --> R2("无界变量: 样本量超多项式增长<br>Unbounded: Super-polynomial sample growth")
    ```

- **[arXiv260101] Implicit geometric regularization in flow matching via density weighted Stein operators**
  - **tags:** [ai], [generative models], [flow matching, density weighting, Stein metric, Sobolev regularization, continuous normalizing flows]
  - **authors:** Shinto Eguchi
  - **institution:** The Institute of Statistical Mathematics
  - **link:** https://arxiv.org/pdf/2512.23956
  - **contributions:** 1. Proposes γ-Flow Matching (γ-FM), a density-weighted variant of Flow Matching that aligns regression geometry with the underlying probability flow to address inefficiencies in high-dimensional void regions., 2. Introduces a Dynamic Density-Weighting strategy that estimates the target density from training particles, enabling dynamic downweighting of the loss in void regions without requiring explicit density evaluation., 3. Theoretically establishes that γ-FM minimizes transport cost on a statistical manifold with the γ-Stein metric and shows it induces implicit Sobolev regularization, leading to smoother vector fields and improved sampling efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51edeed5e04fe354ae4150f7b6f2ac284b3b71da9bc820ece3883dd4198be9ce_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies that standard Flow Matching is inefficient in high dimensions due to unweighted regression over low-density "void" regions. To solve this, it proposes γ-Flow Matching, a method that dynamically weights the regression loss based on estimated target density, aligning the geometry with the probability flow. The approach theoretically connects to the γ-Stein metric, induces implicit regularization, and empirically improves vector field smoothness and sampling efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Implicit geometric regularization in flow matching via density weighted Stein operators] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[标准FM在低密度区域效率低下/Standard FM inefficient in low-density 'void' regions]
        Method[主要方法/Method] --> M1[提出γ-Flow Matching (γ-FM)/Propose γ-Flow Matching (γ-FM)]
        Method --> M2[动态密度加权策略/Dynamic Density-Weighting strategy]
        Results[关键结果/Results] --> R1[理论: 最小化γ-Stein度量下的传输成本/Theory: Minimizes transport cost under γ-Stein metric]
        Results --> R2[谱分析: 诱导隐式Sobolev正则化/Spectral analysis: Induces implicit Sobolev regularization]
        Results --> R3[实证: 改善向量场平滑度与采样效率/Empirical: Improves vector field smoothness & sampling efficiency]
    ```

- **[arXiv260101] Constructive Approximation of Random Process via Stochastic Interpolation Neural Network Operators**
  - **tags:** [ai], [function approximation], [stochastic interpolation, neural network operators, sigmoidal functions, mean square approximation, modulus of continuity]
  - **authors:** Sachin Saini, Uaday Singh
  - **institution:** Indian Institute of Technology Roorkee
  - **link:** https://arxiv.org/pdf/2512.24106
  - **contributions:** 1. Constructed a novel class of Stochastic Interpolation Neural Network Operators (SINNOs) with random coefficients., 2. Established theoretical properties of SINNOs, including boundedness, interpolation accuracy, and approximation capabilities in mean square, probability, and path-wise senses., 3. Provided quantitative error estimates for the approximation using the modulus of continuity of the stochastic processes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f705010d1796a2048a2e675bb4dc8e1bca921170079aa88325df4b4644ffd64a_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Stochastic Interpolation Neural Network Operators (SINNOs) to approximate random processes. The method constructs operators with random coefficients and sigmoidal activations, proving their theoretical approximation properties and providing error bounds. The results demonstrate SINNOs' effectiveness for approximating stochastic processes, with potential applications like COVID-19 case prediction.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Constructive Approximation of Random Process via Stochastic Interpolation Neural Network Operators] --> B(核心问题/Problem: Approximating stochastic processes)
        A --> C(主要方法/Method: Stochastic Interpolation Neural Network Operators (SINNOs) with random coefficients)
        A --> D(关键结果/Results: Proven boundedness, interpolation, and approximation capabilities with error estimates)
    ```

- **[arXiv260101] Policy Mirror Descent with Temporal Difference Learning: Sample Complexity under Online Markov Data**
  - **tags:** [ai], [reinforcement learning], [policy mirror descent, temporal difference learning, sample complexity, Markov decision process, policy optimization]
  - **authors:** Wenye Li, Hongxu Chen, Jiacai Liu, Ke Wei
  - **institution:** Fudan University
  - **link:** https://arxiv.org/pdf/2512.24056
  - **contributions:** 1. Proposes two novel algorithms (Expected TD-PMD and Approximate TD-PMD) that combine policy mirror descent with TD learning under online Markovian sampling. 2. Establishes an $\tilde\{O\}(\varepsilon^\{-2\})$ sample complexity for achieving average-time $\varepsilon$-optimality with a constant step size. 3. Improves sample complexity to $O(\varepsilon^\{-2\})$ for last-iterate $\varepsilon$-optimality using adaptive policy update step sizes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e127c9df69a866d0fceeb04827980cde5bc823d8ff492633bf924e6720d9ce1_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the sample complexity of policy mirror descent combined with temporal difference learning under online Markovian data. It introduces two algorithms, Expected TD-PMD and Approximate TD-PMD, and proves they achieve $\tilde\{O\}(\varepsilon^\{-2\})$ sample complexity for average-time optimality, which is further refined to $O(\varepsilon^\{-2\})$ for last-iterate optimality with adaptive step sizes.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Policy Mirror Descent with Temporal Difference Learning: Sample Complexity under Online Markov Data] --> B[核心问题/Problem: Existing PMD analysis limited to generative or Markovian sampling with pre-approximated action values]
    A --> C[主要方法/Method: Propose Expected TD-PMD (off-policy) and Approximate TD-PMD (mixed policy) algorithms]
    A --> D[关键结果/Results: Achieve ˜O(ε⁻²) sample complexity for average-time ε-optimality; improved to O(ε⁻²) for last-iterate ε-optimality with adaptive steps]
    ```

- **[arXiv260101] Quantitative Understanding of PDF Fits and their Uncertainties**
  - **tags:** [ai], [neural tangent kernel], [Parton Distribution Functions, Neural Tangent Kernel, training dynamics, uncertainty quantification, stochastic gradient descent]
  - **authors:** Amedeo Chiefa, Luigi Del Debbio, Richard Kenway
  - **institution:** The University of Edinburgh, Higgs Centre for Theoretical Physics
  - **link:** https://arxiv.org/pdf/2512.24116
  - **contributions:** 1. Developed a theoretical framework based on the Neural Tangent Kernel (NTK) to analyze the training dynamics of neural networks in PDF fits. 2. Derived an analytical description of neural network evolution during training, clarifying the role of NN architecture and the impact of experimental data. 3. Provided a quantitative description of how uncertainties propagate from data to the fitted function by describing the evolution of the covariance of the NN output.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/283b144a92809766c93247cb89d39262cf21156f386f26a3c176b21ddd101f6d_w640_q70.webp
  - **Simple LLM Summary:** This paper develops a theoretical framework using the Neural Tangent Kernel to analytically model the training dynamics of neural networks used for fitting Parton Distribution Functions. The method provides a quantitative understanding of how the network learns and how uncertainties propagate from data, serving as a diagnostic tool to assess the robustness of PDF fitting methodologies. The findings also offer a testbed for applying machine learning theory, showing deviations from the simple "lazy training" regime.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Quantitative Understanding of PDF Fits and their Uncertainties") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("高精度LHC测量需要稳健的PDF和不确定性量化/Robust PDF & uncertainty quantification needed for high-precision LHC")
        Problem --> P2("需要理解NN训练动态和不确定性传播/Need to understand NN training dynamics & uncertainty propagation")
        Method --> M1("基于神经正切核的理论框架/Theoretical framework based on Neural Tangent Kernel")
        Method --> M2("分析神经网络训练动态/Analyze neural network training dynamics")
        Results --> R1("对训练过程和架构作用的定量理解/Quantitative understanding of training process & architecture role")
        Results --> R2("不确定性从数据到函数的传播描述/Description of uncertainty propagation from data to function")
        Results --> R3("评估当前拟合方法的诊断工具/Diagnostic tool to assess current fitting methodologies")
    ```

- **[arXiv260101] Variational Quantum Brushes**
  - **tags:** [other], [quantum computing for art], [variational quantum algorithms, quantum geometric control, variational eigensolver, computational art, quantum brushes]
  - **authors:** Jui-Ting Lu, Henrique Ennes, Chih-Kang Huang, Ali Abbassi
  - **institution:** Université de Lorraine, CNRS, Inria, Université de Technologie de Troyes, Orange Research
  - **link:** https://arxiv.org/pdf/2512.24173
  - **code:** https://github.com/moth-quantum/QuantumBrush
  - **contributions:** 1. Introduces a mathematical framework for quantum brushes based on variational quantum algorithms. 2. Implements the "Steerable" brush, which uses quantum geometric control theory to merge two images. 3. Implements the "Chemical" brush, which mimics variational eigensolvers to evolve colors on a canvas.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d8a1ae2b1cfdee3a098d127a86fa773993bb3eab697781cc52c1e25f3f449b7_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces two new quantum brushes for computational art, built on variational quantum algorithms. The "Steerable" brush merges artworks using quantum geometric control, while the "Chemical" brush evolves colors by mimicking molecular energy estimation. The implementations are open-source and compatible with existing quantum brush software.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Variational Quantum Brushes] --> B[核心问题/Problem: Leveraging quantum behavior for novel artistic effects]
        A --> C[主要方法/Method: Two variational quantum algorithm-based brushes: Steerable and Chemical]
        A --> D[关键结果/Results: Open-source implementation, compatible with original quantum brushes]
    ```

- **[arXiv260101] Score-based sampling without diffusions: Guidance from a simple and modular scheme**
  - **tags:** [mlsys], [diffusion models], [score-based sampling, strongly log concave, modular scheme]
  - **authors:** M. J. Wainwright
  - **institution:** Massachusetts Institute of Technology (MIT)
  - **link:** https://arxiv.org/pdf/2512.24152
  - **contributions:** 1. Proposes a modular scheme that reduces score-based sampling to a sequence of "nice" sampling problems, specifically those defined by strongly log concave (SLC) distributions. 2. Shows how to design forward trajectories such that both the terminal and backward conditional distributions are SLC, enabling the use of any high-accuracy SLC sampler. 3. Establishes novel theoretical guarantees for both uni-modal and multi-modal densities, achieving ε-accuracy with polynomial dependence on log(1/ε) and √d dimension dependence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18db1a89bccabdb56e6dc374b810b4ddafad4b8325763f60f894ada6c6f8926c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of score-based sampling, which typically relies on approximate score functions. It introduces a modular method that transforms the sampling problem into a short sequence of simpler, strongly log-concave sampling sub-problems. This approach allows leveraging existing high-accuracy samplers and provides theoretical guarantees for efficient and accurate sampling from complex densities.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Score-based sampling without diffusions: Guidance from a simple and modular scheme] --> B[核心问题/Problem: Sampling from complex densities using score-based methods]
        A --> C[主要方法/Method: Modular reduction to a sequence of strongly log concave (SLC) sampling problems]
        A --> D[关键结果/Results: Novel guarantees for uni/multi-modal densities, ε-accuracy with poly-log and √d dependence]
    ```

- **[arXiv260101] Topological Spatial Graph Coarsening**
  - **tags:** [ai], [topological data analysis], [spatial graph coarsening, persistent diagrams, triangle-aware graph filtration]
  - **authors:** Anna Calissano, Etienne Lasalle
  - **institution:** University College London, Nantes Université, École Centrale Nantes, CNRS
  - **link:** https://arxiv.org/pdf/2512.24327
  - **contributions:** 1. Proposes a topological spatial graph coarsening method that balances graph reduction with topological feature preservation. 2. Introduces a triangle-aware graph filtration to adapt persistent diagrams (a topological descriptor) for spatial graphs. 3. Demonstrates that the method is parameter-free and equivariant under rotations, translations, and scaling.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06067063c056f1d3d0e7b1438bde8daf5524598eca6b311651201d86b9e87d88_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of reducing spatial graphs while preserving their topological structure. It proposes a method that collapses short edges and uses a novel triangle-aware graph filtration to guide the coarsening process. The approach is shown to significantly reduce graph size while maintaining key topological information.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Topological Spatial Graph Coarsening] --> B(核心问题/Problem: Spatial graph reduction while preserving topology)
        A --> C(主要方法/Method: Collapse short edges using triangle-aware graph filtration & persistent diagrams)
        A --> D(关键结果/Results: Parameter-free, equivariant method that reduces size and preserves topology)
    ```

- **[arXiv260101] Fast reconstruction-based ROI triggering via anomaly detection in the CYGNO optical TPC**
  - **tags:** [mlsys], [others], [anomaly detection, autoencoder, online data reduction, optical TPC, ROI triggering]
  - **authors:** F. D. Amaro, R. Antonietti, E. Baracchini, L. Benussi, C. Capoccia, M. Caponero, L. G. M. de Carvalho, G. Cavoto, I. A. Costa, A. Croce, M. D'Astolfo, G. D'Imperio, G. Dho, E. Di Marco, J. M. F. dos Santos, D. Fiorina, F. Iacoangeli, Z. Islam, E. Kemp, H. P. Lima Jr., G. Maccarrone, R. D. P. Mano, D. J. G. Marques, G. Mazzitelli, P. Meloni, A. Messina, V. Monno, C. M. B. Monteiro, R. A. Nobrega, G. M. Oppedisano, I. F. Pains, E. Paoletti, F. Petrucci, S. Piacentini, D. Pierluigi, D. Pinci, F. Renga, A. Russo, G. Saviano, P. A. O. C. Silva, N. J. Spooner, R. Tesauro, S. Tomassini, D. Tozzi
  - **institution:** University of Coimbra, Gran Sasso Science Institute, INFN (Istituto Nazionale di Fisica Nucleare), Sapienza University of Rome
  - **link:** https://arxiv.org/pdf/2512.24290
  - **contributions:** 1. Proposed an unsupervised, reconstruction-based anomaly detection method using a convolutional autoencoder trained exclusively on pedestal (noise) images for fast ROI extraction in optical TPCs. 2. Demonstrated the critical impact of the training objective design through a controlled comparison of two autoencoder configurations on real data. 3. Achieved high performance, retaining 93.0% of signal intensity while discarding 97.8% of image area with an inference time of ~25 ms per frame, establishing a transparent, detector-agnostic baseline for online data reduction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07a2394c8601a3636fcb96b0e78aa474c0a406733284a194c5cbd05434e20b37_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of real-time data selection from large images in optical Time Projection Chambers (TPCs). It proposes an unsupervised anomaly detection method using a pedestal-trained convolutional autoencoder to quickly identify and extract Regions of Interest (ROIs) from particle tracks. The results show the method is highly effective for online data reduction, with performance heavily dependent on the careful design of the training objective.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Fast reconstruction-based ROI triggering via anomaly detection in the CYGNO optical TPC] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Optical TPCs produce large images challenging real-time data selection for rare-event searches.]
        C[主要方法/Method: Unsupervised anomaly detection using a pedestal-trained convolutional autoencoder for fast ROI extraction.]
        D[关键结果/Results: Retains 93% signal, discards 98% area, ~25 ms inference, training objective is critical.]
    ```

- **[arXiv260101] Deep Learning in Geotechnical Engineering: A Critical Assessment of PINNs and Operator Learning**
  - **tags:** [ai], [scientific machine learning], [physics-informed neural networks, deep operator networks, graph network simulators, automatic differentiation, geotechnical engineering]
  - **authors:** Krishna Kumar
  - **institution:** None (Institution not provided in the given content. Author is Krishna Kumar, but no affiliation or email domain is shown.)
  - **link:** https://arxiv.org/pdf/2512.24365
  - **contributions:** 1. A critical empirical comparison of PINNs, DeepONet, and GNS against traditional solvers for canonical geotechnical problems, revealing severe performance and accuracy limitations. 2. Demonstrates the efficacy of automatic differentiation through traditional solvers for rapid and accurate inverse parameter estimation in geotechnical engineering. 3. Provides practical recommendations for the application of deep learning in geotechnical contexts, emphasizing the importance of site-based validation and the limited envelope where neural networks are viable.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4f4b161baea59d1dc122276a25b7891aac2248e8367a3b0e01bacce08a12baa_w640_q70.webp
  - **Simple LLM Summary:** This paper critically evaluates deep learning methods like PINNs, DeepONet, and GNS for geotechnical engineering simulations. It finds these methods are often orders of magnitude slower and less accurate than traditional solvers, and fail when extrapolating. The authors recommend using automatic differentiation for inverse problems and reserving neural networks only for specific, well-bounded cases where traditional solvers are prohibitively expensive.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deep Learning in Geotechnical Engineering: A Critical Assessment<br/>岩土工程中的深度学习：关键评估] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br/>评估深度学习在岩土工程中的实用性<br/>Assessing the practicality of deep learning in geotechnical engineering]
        C[主要方法/Method<br/>对比PINNs, DeepONet, GNS与传统求解器<br/>Compare PINNs, DeepONet, GNS vs. traditional solvers]
        D[关键结果/Results<br/>PINNs慢90,000倍；DeepONet需大量训练；神经网络外推失败；推荐自动微分<br/>PINNs 90,000x slower; DeepONet needs massive training; NNs fail at extrapolation; Recommends automatic differentiation]
    ```

- **[arXiv260101] OptiVote: Non-Coherent FSO Over-the-Air Majority Vote for Communication-Efficient Distributed Federated Learning in Space Data Centers**
  - **tags:** [mlsys], [federated learning], [over-the-air computation, free-space optical communication, signSGD, majority vote, pulse-position modulation]
  - **authors:** Anbang Zhang, Chenyuan Feng, Wai Ho Mow, Jia Ye, Shuaishuai Guo, Geyong Min, Tony Q. S. Quek
  - **institution:** Shandong University, University of Exeter, The Hong Kong University of Science and Technology, Chongqing University, Singapore University of Technology and Design
  - **link:** https://arxiv.org/pdf/2512.24334
  - **contributions:** 1. Proposes OptiVote, a non-coherent FSO AirComp framework that integrates signSGD with majority-vote aggregation and PPM to eliminate the need for precise phase synchronization in space environments. 2. Develops an importance-aware, CSI-free dynamic power control scheme to mitigate aggregation bias caused by heterogeneous FSO channels without extra signaling. 3. Provides theoretical analysis of aggregate error probability and convergence guarantees, and demonstrates superior communication efficiency and learning accuracy through experiments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72d34a686b6aa623eca2a7d8853b5d062ec21148534d26149a8be732a2526af4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of communication-efficient federated learning in space data centers by proposing OptiVote, a robust non-coherent free-space optical over-the-air computation framework. It combines signSGD with majority-vote aggregation and pulse-position modulation to perform aggregation without precise phase synchronization, and includes a power control scheme to handle channel heterogeneity. The method is shown to outperform baselines in both communication efficiency and learning accuracy for distributed intelligence in space.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[OptiVote: Non-Coherent FSO Over-the-Air Majority Vote] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[卫星数据中心联邦学习通信效率低/Federated Learning in SDCs is communication-inefficient]
        B --> B2[相干AirComp需要严格相位同步/Coherent AirComp requires precise phase sync]
        C --> C1[非相干FSO AirComp框架/Non-coherent FSO AirComp framework]
        C --> C2[集成signSGD与多数投票/PPM/Integrates signSGD with MV & PPM]
        C --> C3[CSI-free动态功率控制/CSI-free dynamic power control]
        D --> D1[消除相位同步需求/Eliminates need for phase sync]
        D --> D2[提升通信效率与学习精度/Improves comm. efficiency & learning accuracy]
        D --> D3[理论分析与实验验证/Theoretical analysis & experimental validation]
    ```

- **[arXiv260101] Implicit score matching meets denoising score matching: improved rates of convergence and log-density Hessian estimation**
  - **tags:** [ai], [diffusion models], [score matching, implicit score matching, denoising score matching, Fisher divergence, Gagliardo-Nirenberg inequality]
  - **authors:** Konstantin Yakovlev, Anna Markovich, Nikita Puchkin
  - **institution:** HSE University
  - **link:** https://arxiv.org/pdf/2512.24378
  - **contributions:** 1. Proved that implicit score matching can adapt to the intrinsic dimension of low-dimensional data distributions and achieve the same convergence rates as denoising score matching. 2. Demonstrated that both implicit and denoising score matching enable estimation of log-density Hessians without the curse of dimensionality via simple differentiation. 3. Provided theoretical justification for the convergence of ODE-based samplers used in generative diffusion models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09412dadfda9474a45ce50ae36a846be163fb7cca6813c986c3a6c13f5ba9670_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the estimation of the score function using implicit and denoising score matching. It proves that implicit score matching matches the convergence rates of denoising score matching for low-dimensional data and that both methods can efficiently estimate log-density Hessians, thereby justifying the convergence of ODE-based samplers in diffusion models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Implicit score matching meets denoising score matching] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[估计得分函数 / Estimate Score Function]
        C --> C1[隐式得分匹配与去噪得分匹配 / Implicit & Denoising Score Matching]
        C --> C2[基于Gagliardo-Nirenberg不等式 / Gagliardo-Nirenberg Inequalities]
        D --> D1[收敛率相同 / Same Convergence Rates]
        D --> D2[无维度灾难估计Hessian / Hessian Estimation without Curse of Dimensionality]
        D --> D3[证明ODE采样器收敛 / Justifies ODE Sampler Convergence]
    ```

- **[arXiv260101] Virasoro Symmetry in Neural Network Field Theories**
  - **tags:** [ai], [theoretical machine learning], [Neural Network Field Theories, Virasoro symmetry, conformal field theory, stress-energy tensor, super-Virasoro]
  - **authors:** Brandon Robinson
  - **institution:** University of Amsterdam
  - **link:** https://arxiv.org/pdf/2512.24420
  - **contributions:** 1. First construction of a Neural Network Field Theory (NN-FT) that encodes the full Virasoro symmetry of a 2d CFT, achieved via a specific "Log-Kernel Network" architecture and prior distribution. 2. Extension of the framework to include super-Virasoro symmetry by constructing neural realizations of a Majorana Fermion and an N=(1,1) scalar multiplet. 3. Development of boundary NN-FTs that preserve (super-)conformal symmetry using the method of images, demonstrating the robustness of the framework.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0e2e1fe141fac45bc31d96a59d9378b6ce343fa02fab3e24378bc7554b1789c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of local, infinite-dimensional conformal symmetry (Virasoro symmetry) in typical Neural Network Field Theories (NN-FTs). It proposes a specific neural architecture, the Log-Kernel Network, to construct a 2d free boson theory with a local stress-energy tensor, enabling the emergence of Virasoro algebra. The work is validated numerically, extended to super-Virasoro symmetry, and further generalized to boundary theories preserving conformal invariance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Virasoro Symmetry in Neural Network Field Theories] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[NN-FTs lack local stress tensor & Virasoro symmetry]
        C --> C1[Design Log-Kernel Network architecture]
        C --> C2[Proper prior for parameters]
        D --> D1[Verified central charge & scaling dimensions]
        D --> D2[Extended to super-Virasoro & boundary NN-FTs]
    ```

- **[arXiv260101] Towards mechanistic understanding in a data-driven weather model: internal activations reveal interpretable physical features**
  - **tags:** [ai], [mechanistic interpretability], [sparse autoencoders, feature discovery, model intervention, GraphCast, interpretability]
  - **authors:** Theodore MacMillan, Nicholas T. Ouellette
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2512.24440
  - **contributions:** 1. Adapted interpretability tools from Large Language Models (specifically sparse autoencoders) to analyze a large-scale data-driven weather model (GraphCast). 2. Discovered that the model's internal activations correspond to interpretable physical features like tropical cyclones and atmospheric rivers. 3. Demonstrated causal probing via feature interventions, showing physically consistent modifications to model predictions (e.g., altering hurricane evolution).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0540d3e6e8dd4531270c37251313fe5f6b7b7ef8f4792bfb500db7d9f5d7ba6_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the interpretability of data-driven physics models like GraphCast by applying mechanistic interpretability techniques from LLMs. Using sparse autoencoders, the authors discover that the model's internal features correspond to meaningful physical phenomena. They further show that targeted interventions on these features lead to interpretable and physically consistent changes in the model's forecasts, advancing the trustworthiness of such models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Towards mechanistic understanding in a data-driven weather model: internal activations reveal interpretable physical features] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>How do data-driven physics models work internally? Are they interpretable and physically consistent?]
        C[主要方法/Method<br>Adapt LLM interpretability tools (sparse autoencoders) to analyze GraphCast's activations.]
        D[关键结果/Results<br>Discovered interpretable physical features (cyclones, rivers). Interventions yield physically consistent predictions.]
    ```

- **[arXiv260101] Improving the stability of the covariance-controlled adaptive Langevin thermostat for large-scale Bayesian sampling**
  - **tags:** [ai], [Bayesian sampling], [stochastic gradient Langevin dynamics, covariance-controlled adaptive Langevin, numerical stability]
  - **authors:** Jiani Wei, Xiaocheng Shang
  - **institution:** University of Birmingham
  - **link:** https://arxiv.org/pdf/2512.24515
  - **contributions:** 1. Proposed a modified CCAdL (mCCAdL) thermostat using the scaling part of the scaling and squaring method and a truncated Taylor series to approximate the exact solution to a key subsystem. 2. Introduced a symmetric splitting method for discretizing the mCCAdL thermostat, replacing the Euler-type discretization used in the original CCAdL. 3. Demonstrated that the mCCAdL thermostat achieves substantial improvement in numerical stability over the original CCAdL and outperforms alternative stochastic gradient methods in accuracy for large-scale applications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f9577aa049234db392488eb89c746ecf45ccd1d5a0555bdc8f9a7fefd2c23a7_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the numerical stability issue in the covariance-controlled adaptive Langevin (CCAdL) thermostat, a method for large-scale Bayesian sampling. The authors propose a modified version (mCCAdL) that uses a more stable numerical approximation scheme and a symmetric splitting integrator. Their experiments show that mCCAdL significantly improves stability and accuracy compared to the original CCAdL and other stochastic gradient methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Improving the stability of the covariance-controlled adaptive Langevin thermostat] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[CCAdL数值稳定性差，限制步长/CCAdL poor numerical stability limits stepsize]
        C --> C1[提出mCCAdL，使用缩放和平方及泰勒近似/Propose mCCAdL using scaling & squaring and Taylor approximation]
        C --> C2[提出对称分裂方法/Propose symmetric splitting method]
        D --> D1[稳定性显著提升/Stability substantially improved]
        D --> D2[精度优于其他方法/Accuracy outperforms alternatives]
    ```

- **[arXiv260101] Probabilistic Computers for Neural Quantum States**
  - **tags:** [mlsys], [cluster infrastructure], [probabilistic computing, FPGA, Boltzmann machine, neural quantum states, Monte Carlo sampling]
  - **authors:** Shuvro Chowdhury, Jasper Pieterse, Navid Anjum Aadit, Johan H. Mentink, Kerem Y. Camsari
  - **institution:** University of California, Santa Barbara, Radboud University
  - **link:** https://arxiv.org/pdf/2512.24558
  - **contributions:** 1. Implementation of a probabilistic computer on a custom multi-FPGA cluster to serve as a fast sampler for neural quantum states. 2. Introduction of a dual-sampling algorithm to train deep Boltzmann machines by replacing intractable marginalization with conditional sampling. 3. Demonstration of scaling variational quantum simulations to large system sizes (up to 6400 spins) and deeper architectures, overcoming the MCMC sampling bottleneck.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ef4c4bc51129bbcf4c7afb6bc33c07bd787081538aa3dbb925d18f3bf724567_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the Monte Carlo sampling bottleneck in scaling neural quantum states for quantum many-body simulations. It proposes combining sparse Boltzmann machine architectures with probabilistic computing hardware implemented on FPGAs and introduces a dual-sampling training algorithm. The results show that this approach enables accurate simulations of large spin systems and deeper models, overcoming a key scaling limitation.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Probabilistic Computers for Neural Quantum States"] --> Problem["核心问题/Problem: Monte Carlo sampling limits scaling of neural quantum states"]
        Root --> Method["主要方法/Method: Combine sparse Boltzmann machines with FPGA-based probabilistic computer & dual-sampling algorithm"]
        Root --> Results["关键结果/Results: Accurate ground-state energies for 6400 spins; trained deep models for 1225 spins"]
    ```

- **[arXiv260101] MultiRisk: Multiple Risk Control via Iterative Score Thresholding**
  - **tags:** [ai], [risk control], [test-time filtering, dynamic programming, risk constraints, score thresholding, exchangeability]
  - **authors:** Sunay Joshi, Yan Sun, Hamed Hassani, Edgar Dobriban
  - **institution:** University of Pennsylvania, New Jersey Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.24587
  - **contributions:** 1. Formalizes the problem of enforcing multiple risk constraints with user-defined priorities for generative AI systems. 2. Introduces two efficient dynamic programming algorithms (MULTIRISK-BASE and MULTIRISK) for selecting thresholds to control risks. 3. Provides a theoretical analysis showing that MULTIRISK achieves nearly tight simultaneous control of all constraint risks under mild assumptions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51cedb2b9055aea411d20349fafef70fbd282669fb33f5fc821167eb1304019e_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes MultiRisk, a framework for controlling multiple risks in generative AI outputs via test-time filtering. It introduces dynamic programming algorithms to set score thresholds, guaranteeing simultaneous risk control by leveraging data exchangeability. The method is validated on an LLM alignment task, showing it can control individual risks close to their target levels.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[MultiRisk: Multiple Risk Control via Iterative Score Thresholding] --> B[核心问题/Problem: Regulating multiple dimensions of generative AI model behavior at test-time]
    A --> C[主要方法/Method: Dynamic programming algorithms (MULTIRISK-BASE, MULTIRISK) for iterative score thresholding]
    A --> D[关键结果/Results: Achieves nearly tight simultaneous control of multiple constraint risks on LLM alignment task]
    ```

- **[arXiv260101] Robust Bayesian Dynamic Programming for On-policy Risk-sensitive Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [risk-sensitive reinforcement learning, Bayesian dynamic programming, coherent risk measures, robust Markov decision process, convex optimization]
  - **authors:** Shanyu Han, Yangbo He, Yang Liu
  - **institution:** Peking University, The Chinese University of Hong Kong, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.24580
  - **contributions:** 1. Proposes a novel unified framework for risk-sensitive reinforcement learning (RSRL) that incorporates robustness against transition uncertainty by defining inner and outer coherent risk measures. 2. Develops a Bayesian Dynamic Programming algorithm that alternates posterior updates with value iteration, using a Monte Carlo and convex optimization estimator with strong consistency guarantees. 3. Provides theoretical analysis including convergence, sample complexity, and computational complexity under Dirichlet posterior and CVaR, validated through numerical experiments and an option hedging application.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b966fa69f9b8aafe26700ce5afe83099b3257d5b90314e5d3f668e4079ecdda_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces a robust Bayesian framework for on-policy risk-sensitive reinforcement learning that addresses transition uncertainty through coupled inner and outer risk measures. It develops a Bayesian Dynamic Programming algorithm with theoretical guarantees and demonstrates its effectiveness in convergence and robustness via numerical experiments and an option hedging application.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Robust Bayesian Dynamic Programming for On-policy Risk-sensitive Reinforcement Learning"] --> Problem["核心问题/Problem: Need for risk-sensitive RL robust to transition uncertainty"]
        Root --> Method["主要方法/Method: Unified framework with inner/outer risk measures, Bayesian DP algorithm with posterior updates and value iteration"]
        Root --> Results["关键结果/Results: Theoretical guarantees, convergence, validated via experiments and option hedging application"]
    ```

- **[arXiv260101] Soliton profiles: Classical Numerical Schemes vs. Neural Network - Based Solvers**
  - **tags:** [ai], [scientific computing], [Physics-Informed Neural Networks, Deep Operator Network, Petviashvili method, solitary waves, numerical solvers]
  - **authors:** Chandler Haight, Svetlana Roudenko, Zhongming Wang
  - **institution:** Wayne State University
  - **link:** https://arxiv.org/pdf/2512.24634
  - **contributions:** 1. A comprehensive comparative study of classical numerical schemes (e.g., Petviashvili's method) and neural network-based solvers (PINNs, operator-learning) for computing soliton profiles in 1D dispersive PDEs. 2. An empirical confirmation that classical methods retain superior accuracy and computational efficiency for single-instance problems in one-dimensional settings. 3. An analysis highlighting the trade-offs of neural network methods, where operator-learning approaches, despite costly training, offer rapid inference and reusability for multi-parameter or real-time applications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4b9a088c1ebb97139a0da346b37d398fe825a096d76a313979e6fe0f8544c65_w640_q70.webp
  - **Simple LLM Summary:** This paper compares classical numerical solvers and neural network-based methods for finding solitary-wave solutions to nonlinear PDEs like the NLS and KdV equations. It finds that classical methods are more accurate and efficient for single problems, while neural operators are better suited for repeated simulations due to fast inference after training. The core conclusion is that the choice of solver depends on the application context: precision for single instances vs. speed for parameterized families.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题 / Paper Title: Soliton profiles: Classical Numerical Schemes vs. Neural Network - Based Solvers] --> B(核心问题 / Problem: 如何计算一维色散PDE的孤立波解？ / How to compute solitary-wave solutions for 1D dispersive PDEs?)
        A --> C(主要方法 / Method: 比较经典数值方法与神经网络求解器 / Compare classical numerical methods and neural network-based solvers)
        A --> D(关键结果 / Results: 经典方法在单实例上更优，算子学习方法适合重复模拟 / Classical methods better for single instances, operator-learning suitable for repeated simulations)
    ```

- **[arXiv260101] Sparse Offline Reinforcement Learning with Corruption Robustness**
  - **tags:** [ai], [reinforcement learning], [offline reinforcement learning, sparsity, corruption robustness, single-policy concentrability, actor-critic]
  - **authors:** Nam Phuong Tran, Andi Nika, Goran Radanovic, Long Tran-Thanh, Debmalya Mandal
  - **institution:** University of Warwick, Max Planck Institute for Software Systems (MPI-SWS)
  - **link:** https://arxiv.org/pdf/2512.24768
  - **contributions:** 1. Identifies limitations of integrating sparsity into standard robust offline RL methods like LSVI, showing they can fail due to overly pessimistic bonuses. 2. Proposes novel actor-critic methods with sparse robust estimator oracles that avoid pointwise pessimistic bonuses. 3. Provides the first non-vacuous theoretical guarantees for learning in high-dimensional sparse MDPs under weak (single-policy concentrability) coverage and strong data corruption.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ce133c71cdf619bf6a1597c047c8adc5b10b7d0584bd6af1944718635e12340_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of robust offline reinforcement learning in high-dimensional, sparse Markov Decision Processes where data may be corrupted. The authors propose new actor-critic methods that use sparse robust estimator oracles, avoiding the pitfalls of traditional approaches. Their work provides the first theoretical guarantees showing that learning a near-optimal policy is possible under weak data coverage and strong corruption, where previous methods fail.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Sparse Offline RL with Corruption Robustness<br>稀疏离线强化学习与抗污染鲁棒性"] --> Problem["Problem: High-dim sparse MDPs with corrupted data & weak coverage<br>问题: 具有污染数据和弱覆盖的高维稀疏MDP"]
        Root --> Method["Method: Actor-critic with sparse robust estimator oracles<br>方法: 使用稀疏鲁棒估计器oracle的Actor-critic"]
        Root --> Results["Results: First non-vacuous guarantees under single-policy concentrability & corruption<br>结果: 在单策略集中性和污染下的首个非平凡保证"]
    ```

- **[arXiv260101] A New Decomposition Paradigm for Graph-structured Nonlinear Programs via Message Passing**
  - **tags:** [mlsys], [communication & networking], [Message Passing, Jacobi Block Updates, Graph Decomposition, Hypergraph Optimization, Decentralized Optimization]
  - **authors:** Kuangyu Ding, Marie Maros, Gesualdo Scutari
  - **institution:** Purdue University, Texas A&M University
  - **link:** https://arxiv.org/pdf/2512.24676
  - **contributions:** 1. Introduces MP-Jacobi, a novel decentralized framework that combines min-sum message passing with Jacobi block updates for graph-structured nonlinear programs, enabling single-hop communication and convergence on loopy graphs. 2. Establishes global linear convergence rates for strongly convex objectives, providing theoretical guidance on how curvature, coupling strength, and graph partitioning affect scalability. 3. Develops graph-compliant surrogate updates and a hyperedge-splitting scheme to reduce per-iteration computation/communication costs and extend the method to hypergraphs while preserving convergence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b545e505c1cccda1a2f472afecb206a4b95c552dd11319ac3f007bab097156a8_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes MP-Jacobi, a decentralized algorithm for solving graph-structured nonlinear programs by partitioning the graph into tree clusters and combining min-sum message passing within clusters with Jacobi-style updates for inter-cluster couplings. This design uses only single-hop communication and is proven to converge linearly for strongly convex problems. Experiments show it outperforms decentralized gradient baselines, offering a scalable primitive for graph optimization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A New Decomposition Paradigm for Graph-structured Nonlinear Programs via Message Passing] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[图结构非线性规划/Graph-structured Nonlinear Programs]
        B --> B2[局部交互与循环图/Local Interactions & Loopy Graphs]
        C --> C1[MP-Jacobi 框架/MP-Jacobi Framework]
        C1 --> C1_1[树簇分区/Tree Clusters Partition]
        C1 --> C1_2[簇内消息传递/Intra-cluster Message Passing]
        C1 --> C1_3[簇间雅可比更新/Inter-cluster Jacobi Updates]
        C --> C2[图合规代理/Graph-compliant Surrogates]
        C --> C3[超图扩展/Hypergraph Extension]
        D --> D1[线性收敛/Linear Convergence]
        D --> D2[单跳通信/Single-hop Communication]
        D --> D3[优于基线/Outperforms Baselines]
    ```

- **[arXiv260101] Fairness-Aware Insurance Pricing: A Multi-Objective Optimization Approach**
  - **tags:** [ai], [fairness in machine learning], [multi-objective optimization, NSGA-II, fairness criteria, insurance pricing, Pareto front]
  - **authors:** Tim J. Boonen, Xinyue Fan, Zixiao Quan
  - **institution:** University of Hong Kong
  - **link:** https://arxiv.org/pdf/2512.24747
  - **contributions:** 1. Proposes a novel multi-objective optimization framework for insurance pricing that jointly optimizes accuracy, group fairness, individual fairness, and counterfactual fairness. 2. Employs the Non-dominated Sorting Genetic Algorithm II (NSGA-II) to generate a diverse Pareto front of trade-off solutions, moving beyond single-objective optimization. 3. Introduces a specific selection mechanism to extract a balanced premium from the Pareto front, demonstrating a consistent and superior compromise compared to single-model approaches.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ea23717323b55541619e16c4dd6ff704d96b756316680eeebec5f447f78a5d2_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the trade-offs between accuracy and multiple fairness criteria in machine learning for insurance pricing. It proposes a multi-objective optimization framework using NSGA-II to generate a Pareto front of solutions and a method to select a balanced premium. The results show the proposed method achieves a better compromise than existing single-objective models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Fairness-Aware Insurance Pricing: A Multi-Objective Optimization Approach] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[ML improves accuracy but worsens fairness trade-offs<br>ML提高准确性但加剧公平性权衡]
        C --> C1[Multi-objective framework via NSGA-II<br>通过NSGA-II的多目标框架]
        C --> C2[Jointly optimizes four criteria<br>联合优化四个标准]
        C --> C3[Generates Pareto front & selects premium<br>生成帕累托前沿并选择保费]
        D --> D1[XGBoost: high accuracy, high disparity<br>XGBoost: 高精度, 高差异]
        D --> D2[Orthogonal: best group fairness<br>Orthogonal: 最佳群体公平性]
        D --> D3[Synthetic Control: best individual/counterfactual fairness<br>Synthetic Control: 最佳个体/反事实公平性]
        D --> D4[Proposed method: balanced compromise<br>所提方法: 平衡的折衷]
    ```

- **[arXiv260101] Limits of quantum generative models with classical sampling hardness**
  - **tags:** [ai], [quantum machine learning], [quantum generative models, anticoncentration, barren plateaus, classical simulability, surrogate sampling]
  - **authors:** Sabrina Herbst, Ivona Brandić, Adrián Pérez-Salinas
  - **institution:** TU Wien, ETH Zurich
  - **link:** https://arxiv.org/pdf/2512.24801
  - **contributions:** 1. Shows that quantum generative models which anticoncentrate (a property linked to classical hardness) are not trainable on average, creating a trade-off between advantage and learnability. 2. Demonstrates that models outputting sparse distributions can be trained, and explores special cases to enhance trainability. 3. Links this trainability trade-off to quantum process verification and identifies that quantum advantage in generative models must stem from sources other than anticoncentration.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db3f019ba893a7df48b4f7eb38a379b3b7ed4612455ba75a7c9068c960c84acc_w640_q70.webp
  - **Simple LLM Summary:** This paper studies the trainability of quantum generative models, finding a fundamental trade-off: models that output anticoncentrated distributions (which are classically hard to sample from) suffer from untrainable loss landscapes, while models with sparse outputs are trainable. The authors link this to verification and conclude that quantum advantage in generative modeling is still possible but must originate from mechanisms distinct from anticoncentration.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Limits of quantum generative models with classical sampling hardness<br>量子生成模型与经典采样难度的局限") --> Problem("核心问题/Problem<br>Quantum advantage vs. trainability in generative models<br>生成模型中量子优势与可训练性的矛盾")
        Root --> Method("主要方法/Method<br>Analyze models via output distribution properties (anticoncentration, sparsity)<br>通过输出分布特性（反集中性、稀疏性）分析模型")
        Root --> Results("关键结果/Results<br>Anticoncentrating models are not trainable; sparse ones are. Advantage source distinct from anticoncentration.<br>反集中模型不可训练；稀疏模型可训练。优势来源不同于反集中性。")
    ```

- **[arXiv260101] Learning Temporally Consistent Turbulence Between Sparse Snapshots via Diffusion Models**
  - **tags:** [ai], [diffusion models], [Denoising Diffusion Probabilistic Models (DDPMs), turbulence interpolation, generative surrogate, Kolmogorov Flow, Kelvin-Helmholtz Instability]
  - **authors:** Mohammed Sardar, Małgorzata J. Zimoń, Samuel Draycott, Alistair Revell, Alex Skillen
  - **institution:** The University of Manchester, IBM Research Europe
  - **link:** https://arxiv.org/pdf/2512.24813
  - **contributions:** 1. Proposes a conditional DDPM-based method for temporally interpolating coherent turbulent dynamics between sparse, decorrelated flow snapshots. 2. Demonstrates the method as a proof-of-concept generative surrogate on both a 2D Kolmogorov Flow and a 3D Kelvin-Helmholtz Instability case. 3. Evaluates the generated sequences through statistical turbulence analysis, including turbulent kinetic energy spectra and the temporal decay of structures, showing the ability to capture evolving flow statistics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0eee4dacebc613c047d4355fd35c417d91dbabc771afd4a894ccdc60312874e4_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes using conditional Denoising Diffusion Probabilistic Models (DDPMs) as a generative surrogate to reconstruct statistically accurate turbulent flow sequences between sparse snapshots. The method is demonstrated on 2D and 3D turbulent flow cases. The analysis shows the generated sequences capture key turbulent statistics and the evolution of flow structures.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Learning Temporally Consistent Turbulence Between Sparse Snapshots via Diffusion Models] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[从稀疏、不相关的湍流快照重建中间动态/Reconstruct intermediate dynamics from sparse, decorrelated turbulent snapshots]
        C --> C1[使用条件去噪扩散概率模型/Conditional Denoising Diffusion Probabilistic Models (DDPMs)]
        C --> C2[作为生成式代理模型/As a generative surrogate model]
        D --> D1[分析生成序列的统计特性/Analyze statistical properties of generated sequences]
        D --> D2[评估湍流能量谱和结构衰减/Evaluate turbulent kinetic energy spectra & structure decay]
        D --> D3[在2D Kolmogorov流和3D KHI上验证/Validated on 2D Kolmogorov Flow & 3D KHI]
    ```

- **[arXiv260101] Are First-Order Diffusion Samplers Really Slower? A Fast Forward-Value Approach**
  - **tags:** [mlsys], [diffusion models], [diffusion model, training-free acceleration, first-order sampler, forward-value discretization]
  - **authors:** Yuchen Jiao, Na Li, Changxiao Cai, Gen Li
  - **institution:** The Chinese University of Hong Kong, Zhejiang University, University of Michigan
  - **link:** https://arxiv.org/pdf/2512.24927
  - **contributions:** 1. Challenges the prevailing belief that higher-order ODE solvers are inherently faster for DPM sampling, proposing that the placement of DPM evaluations is a crucial, independent design factor. 2. Introduces a novel, training-free first-order sampler that approximates the forward-value evaluation using a cheap one-step lookahead predictor, resulting in a leading discretization error with the opposite sign to DDIM. 3. Provides theoretical guarantees for the sampler's approximation of the ideal forward-value trajectory while maintaining first-order convergence, and demonstrates empirical competitiveness with higher-order samplers on standard benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef8de5dcbba9edb9daa0ab1ba8e254668331d9851247da681521a06ad8b83b22_w640_q70.webp
  - **Simple LLM Summary:** This paper challenges the view that first-order diffusion samplers are inherently slower than higher-order ones. It proposes a new first-order sampler that uses a forward-value approach with a lookahead predictor to better place model evaluations. The method is theoretically sound and empirically matches or outperforms state-of-the-art higher-order samplers on image generation tasks under the same computational budget.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["Are First-Order Diffusion Samplers Really Slower? A Fast Forward-Value Approach<br>论文标题"] --> B["核心问题/Problem<br>Higher-order solvers are standard; first-order methods are seen as slower.<br>高阶求解器是标准；一阶方法被认为更慢。"]
        A --> C["主要方法/Method<br>Proposes a training-free first-order sampler using forward-value evaluation via a one-step lookahead predictor.<br>提出一种免训练的一阶采样器，通过一步前瞻预测器进行前向值评估。"]
        A --> D["关键结果/Results<br>Sampler improves quality under same NFE budget, competitive with higher-order methods.<br>采样器在相同NFE预算下提升质量，与高阶方法竞争。"]
    ```

- **[arXiv260101] Basic Inequalities for First-Order Optimization with Applications to Statistical Risk Analysis**
  - **tags:** [ai], [optimization theory], [basic inequalities, implicit regularization, gradient descent, mirror descent, statistical risk analysis]
  - **authors:** Seunghoon Paik, Kangjie Zhou, Matus Telgarsky, Ryan J. Tibshirani
  - **institution:** University of California, Berkeley, Columbia University, New York University
  - **link:** https://arxiv.org/pdf/2512.24999
  - **contributions:** 1. Introduces a formal framework of "basic inequalities" that connects implicit and explicit regularization in first-order optimization. 2. Applies the framework to derive new results for mirror descent with Bregman divergence, generalized linear models trained by gradient/exponentiated gradient descent, and randomized predictors. 3. Revisits and refines known results on gradient descent, demonstrating the framework's versatility for analyzing training dynamics and prediction risk.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/056dd77c9a8e63bc02d7a61166503bba0d0961e3c1f64d12e92c35803aa0bd9a_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a framework of "basic inequalities" to analyze first-order optimization algorithms, linking the number of iterations to an effective regularization parameter. The method provides a unified tool to derive statistical risk bounds for algorithms like gradient descent and mirror descent. The main conclusion is that this framework simplifies and generalizes the analysis of implicit regularization across various optimization settings.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Basic Inequalities for First-Order Optimization] --> B[核心问题/Problem: Connecting implicit and explicit regularization in iterative optimization]
    A --> C[主要方法/Method: Introduce "basic inequalities" framework to bound f(θ_T)-f(z) using distances and step sizes]
    A --> D[关键结果/Results: New risk bounds for mirror descent, GLMs, randomized predictors; refines gradient descent analysis]
    ```

- **[arXiv260101] SymSeqBench: a unified framework for the generation and analysis of rule-based symbolic sequences and datasets**
  - **tags:** [ai], [sequence learning], [formal language theory, symbolic sequences, benchmark suite, cognitive modeling, sequence processing]
  - **authors:** Barna Zajzon, Younes Bouhadjar, Maxime Fabre, Felix Schmidt, Noah Ostendorf, Emre Neftci, Abigail Morrison, Renato Duarte
  - **institution:** Jülich Research Centre, RWTH Aachen University, University of Groningen, University of Coimbra
  - **link:** https://arxiv.org/pdf/2512.24977
  - **contributions:** 1. Introduces SymSeq, a tool for the rigorous generation and analysis of structured symbolic sequences. 2. Introduces SeqBench, a comprehensive benchmark suite of rule-based sequence processing tasks for evaluating AI systems. 3. Provides a unified, domain-agnostic framework (SymSeqBench) based on Formal Language Theory to standardize experiments across cognitive science and AI.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/71331410faecaa464fb09419a580962b2cddad2a5e128910f8482dc81e965858_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces SymSeqBench, a unified software framework combining a symbolic sequence generator/analyzer (SymSeq) and a benchmark suite (SeqBench) for evaluating sequence learning. It is based on Formal Language Theory to provide a domain-agnostic, formal link between computation and cognition. The main conclusion is that this modular, open-source tool offers a versatile and standardized way to investigate sequential structure across diverse fields like psycholinguistics, cognitive psychology, and AI.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[SymSeqBench: 统一框架] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[评估序列学习/Evaluating Sequence Learning]
        Problem --> P2[领域无关的评估/Domain-Agnostic Evaluation]
        Problem --> P3[连接形式理论与认知/Linking Formal Theory & Cognition]
        Method --> M1[SymSeq: 生成与分析/SymSeq: Generation & Analysis]
        Method --> M2[SeqBench: 基准测试套件/SeqBench: Benchmark Suite]
        Method --> M3[基于形式语言理论/Based on Formal Language Theory]
        Results --> R1[跨领域多功能/Versatile Across Domains]
        Results --> R2[标准化实验/Standardizes Experiments]
        Results --> R3[模块化开源工具/Modular Open-Source Tool]
    ```
