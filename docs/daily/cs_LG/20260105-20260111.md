---
slug: /daily/cslg/20260105-20260111
---
# 20260105-20260111 (cs.LG)

## 2026-01-05

- **[arXiv260105] Evaluating Anomaly Detectors for Simulated Highly Imbalanced Industrial Classification Problems**
  - **tags:** [ai], [anomaly detection], [class imbalance, synthetic dataset, generalization error, unsupervised methods, semi-supervised methods]
  - **authors:** Lesley Wheat, Martin v. Mohrenschildt, Saeid Habibi
  - **institution:** McMaster University
  - **link:** https://arxiv.org/pdf/2601.00005
  - **contributions:** 1. Conducted a comprehensive, problem-agnostic evaluation of 14 anomaly detectors under simulated industrial constraints of extreme class imbalance. 2. Identified that the best-performing detector depends critically on the absolute number of faulty examples available, not just the imbalance ratio, and provided thresholds for method selection. 3. Demonstrated the nuanced impact of feature dimensionality on method performance, showing semi-supervised methods gain advantage in higher dimensions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d98d7533bc130ddf43f0469391265ce51a72fe31fdeb441a3c4b553d4e3dd35_w640_q70.webp
  - **Simple LLM Summary:** This paper evaluates anomaly detection algorithms for industrial problems with extreme class imbalance using a synthetic dataset. It benchmarks 14 detectors across varying anomaly rates and training sizes, finding that the optimal detector depends on the absolute number of faulty examples, with unsupervised methods best for very few faults and supervised/semi-supervised methods improving with 30-50 faults. The study highlights performance drops on smaller datasets and provides practical deployment insights.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Evaluating Anomaly Detectors for Simulated Highly Imbalanced Industrial Classification Problems] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Extreme class imbalance in industrial applications due to limited faulty data]
        C[主要方法/Method: Benchmark 14 detectors on synthetic hyperspherical dataset with varying anomaly rates and training sizes]
        D[关键结果/Results: Best detector depends on number of faulty examples; Unsupervised dominates with <20 faults; Supervised/semi-supervised improve with 30-50 faults]
    ```

- **[arXiv260105] A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system**
  - **tags:** [other], [logistics optimization], [workload balancing, evolutionary algorithms, k-means, last-mile delivery, hybrid algorithm]
  - **authors:** Luis M. Moreno-Saavedra, Silvia Jimenez-Fernandez, Antonio Portilla-Figueras, David Casillas-Perez, Sancho Salcedo-Sanz
  - **institution:** Universidad de Alcalá, Universidad Rey Juan Carlos
  - **link:** https://arxiv.org/pdf/2601.00023
  - **contributions:** 1. Proposes a multi-algorithm methodology for operational human resources workload balancing in last-mile delivery, moving beyond simple geographical assignment. 2. Introduces and combines several algorithmic approaches, including different versions of k-means, evolutionary algorithms, recursive assignments, and a hybrid evolutionary ensemble. 3. Validates the proposed approach by applying it to a real-world case study of a delivery workforce in Azuqueca de Henares, Spain.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43bf05ee106d97a42fa05d1af33419810885c8fff72d16b95af434c71d43f4ff_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of unbalanced workload distribution among delivery workers in last-mile urban logistics. It proposes a multi-algorithm approach that uses a combination of distance and workload considerations, including k-means variants and evolutionary algorithms, to assign packages and balance daily effort. The method was successfully tested on a real-world delivery system in Spain.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A multi-algorithm approach for operational human resources workload balancing<br>多算法方法用于最后一公里配送的人力资源负载均衡"] --> Problem["核心问题/Problem: Unbalanced workload among delivery workers in last-mile systems<br>最后一公里配送中快递员工作量不均衡"]
        Root --> Method["主要方法/Method: Multi-algorithm approach combining k-means, evolutionary algorithms, and hybrid ensembles<br>结合k-means、进化算法和混合集成的多算法方法"]
        Root --> Results["关键结果/Results: Successfully applied to a real-world delivery workforce, balancing workload<br>成功应用于现实配送团队，实现了工作量均衡"]
    ```

- **[arXiv260105] Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study**
  - **tags:** [nlp], [mental health language modeling], [large language models, fine-tuning, PHQ-9, Nigerian Pidgin, depression screening]
  - **authors:** Isaac Iyinoluwa Olufadewa, Miracle Ayomikun Adesina, Ezekiel Ayodeji Oladejo, Uthman Babatunde Usman, Owen Kolade Adeniyi, Matthew Tolulope Olawoyin
  - **institution:** Artificial Intelligence for Low-Resource Public Health Application (ALPHA) Centre, Slum and Rural Health Initiative; University of Ibadan; University of Ilorin
  - **link:** https://arxiv.org/pdf/2601.00004
  - **contributions:** 1. Created a novel, annotated dataset of 432 Nigerian Pidgin audio responses for depression screening aligned with PHQ-9 items. 2. Fine-tuned and evaluated three LLMs (Phi-3-mini, Gemma-3-4B-it, GPT-4.1) for automated depression screening in a low-resource language. 3. Demonstrated that fine-tuned GPT-4.1 achieved high accuracy (94.5%) and cultural appropriateness for PHQ-9 severity scoring in Nigerian Pidgin.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/849aa2e2bc1566aab5f5b5e5d072677a6a66426e677648e836adf89c32b964e6_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of depression screening in Nigeria by fine-tuning large language models for Nigerian Pidgin English. The authors collected and annotated a dataset of audio responses, then fine-tuned three LLMs to predict PHQ-9 severity scores. The fine-tuned GPT-4.1 model achieved the best performance, providing a foundation for AI-mediated mental health tools in linguistically diverse, resource-constrained settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Finetuning LLMs for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Limited depression screening in Nigeria due to language barriers and lack of clinicians]
        C[主要方法/Method<br>Fine-tune LLMs on annotated Nigerian Pidgin dataset for PHQ-9 scoring]
        D[关键结果/Results<br>GPT-4.1 achieved 94.5% accuracy and best cultural appropriateness]
    ```

- **[arXiv260105] Yahtzee: Reinforcement Learning Techniques for Stochastic Combinatorial Games**
  - **tags:** [ai], [reinforcement learning], [policy gradient, self-play, Markov Decision Process, Advantage Actor-Critic, ablation study]
  - **authors:** Nicholas A. Pape
  - **institution:** The University of Texas at Austin
  - **link:** https://arxiv.org/pdf/2601.00007
  - **contributions:** 1. Formulates the classic stochastic combinatorial game Yahtzee as a Markov Decision Process and establishes it as a mid-scale RL benchmark. 2. Conducts a comprehensive empirical study comparing REINFORCE, A2C, and PPO under a fixed training budget, identifying A2C as the most robust method. 3. Achieves a median score within 5% of the optimal dynamic programming solution, while analyzing persistent challenges like long-horizon credit assignment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bfca1ffc9ad8523e303bf57755dcad543948f47e5e9f3c5a9d726a359bd3fe5b_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates using deep reinforcement learning to play the full solitaire version of Yahtzee. It trains self-play agents with policy gradient methods (REINFORCE, A2C, PPO) and performs ablation studies on various design choices. The main finding is that A2C robustly achieves near-optimal performance, while all methods struggle with long-term strategic elements like securing the upper section bonus.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Yahtzee: Reinforcement Learning Techniques for Stochastic Combinatorial Games] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Yahtzee as a mid-scale RL benchmark with delayed rewards & combinatorial complexity] --> B1[目标/Objectives<br>Can RL achieve near-optimal performance via self-play?]
        C[主要方法/Method<br>Formulate as MDP, train self-play agents with policy gradient methods (REINFORCE, A2C, PPO)] --> C1[技术/Techniques<br>Ablation on encodings, architecture, estimators, entropy]
        D[关键结果/Results<br>A2C is robust & achieves median score within 5% of optimal DP score] --> D1[挑战/Challenges<br>Agents struggle with long-horizon strategy (upper bonus)]
    ```

- **[arXiv260105] Personalized Spiking Neural Networks with Ferroelectric Synapses for EEG Signal Processing**
  - **tags:** [mlsys], [on-device ai], [ferroelectric synapses, spiking neural networks, EEG signal processing, adaptive learning, neuromorphic computing]
  - **authors:** Nikhil Garg, Anxiong Song, Niklas Plessnig, Nathan Savoia, Laura Bégon-Lours
  - **institution:** ETH Zurich (Integrated Systems Laboratory, Department of Information Technology and Electrical Engineering)
  - **link:** https://arxiv.org/pdf/2601.00020
  - **contributions:** 1. Demonstrated the deployment and adaptation of Spiking Neural Networks (SNNs) on fabricated ferroelectric memristive synaptic devices for EEG-based motor imagery decoding under realistic device constraints. 2. Introduced a device-aware weight-update strategy that accumulates gradient updates digitally and triggers discrete programming events only when a threshold is exceeded, reducing programming frequency and emulating device dynamics. 3. Evaluated two complementary deployment strategies (device-aware training and transfer learning with on-device re-tuning) that achieve performance comparable to software-based SNNs and show improved accuracy through subject-specific adaptation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce95488f8704205e4a01e64825c78c800662f36da33df71b138881b21ab7b9bb_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of adapting EEG-based brain-computer interfaces to non-stationary neural signals on resource-constrained hardware. It proposes deploying Spiking Neural Networks on ferroelectric memristive synapses with a novel device-aware update strategy and demonstrates two effective deployment methods for personalized, low-overhead adaptation. The results show that programmable ferroelectric hardware can support robust, efficient adaptation for personalized neuromorphic processing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Personalized Spiking Neural Networks with Ferroelectric Synapses for EEG Signal Processing] --> B
        A --> C
        A --> D
        B[核心问题/Problem: EEG信号非平稳性限制模型泛化，需在资源受限平台上进行个性化适应/Non-stationary EEG signals limit model generalization, requiring personalized adaptation on resource-constrained platforms]
        C[主要方法/Method: 在铁电忆阻突触上部署SNN，采用设备感知的权重更新策略/Deploy SNNs on ferroelectric memristive synapses with a device-aware weight-update strategy]
        D[关键结果/Results: 两种部署策略性能媲美软件SNN，特定对象迁移学习提升准确率/Two deployment strategies achieve performance comparable to software SNNs, subject-specific transfer learning improves accuracy]
    ```

- **[arXiv260105] The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition**
  - **tags:** [mlsys], [llm inference], [tokenizer transplant, model composition, supply-chain vulnerability, sparse solver, spectral mimicry]
  - **authors:** Xiaoze Liu, Weichen Yu, Matt Fredrikson, Xiaoqian Wang, Jing Gao
  - **institution:** Purdue University, Carnegie Mellon University
  - **link:** https://arxiv.org/pdf/2601.00065
  - **code:** https://github.com/xz-liu/tokenforge
  - **contributions:** 1. Identifies tokenizer transplant as a novel attack surface in the LLM composition supply chain, 2. Introduces the concept of a "breaker token"—a single, engineered token that is inert in a donor model but maliciously activates after transplant, 3. Formalizes and instantiates the attack as a dual-objective optimization problem solved with a sparse solver, demonstrating its training-free nature, stealth, and persistence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bac901d101e76e81a328892233109e7f05c25f328de683add53ccd17ae81590e_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies a security vulnerability in the tokenizer transplant step required for composing different LLMs. The authors propose a method to engineer a single "breaker token" that, when added to a donor model, remains harmless but sabotages a base model after transplant by exploiting coefficient reuse. The attack is stealthy, training-free, and persistent, revealing a hidden risk in modular AI pipelines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Tokenizer transplant introduces a supply-chain vulnerability for LLM composition]
        C[主要方法/Method<br>Engineer a single "breaker token" exploiting coefficient reuse via sparse solver]
        D[关键结果/Results<br>Stealthy, training-free attack that persists against fine-tuning and merging]
    ```

- **[arXiv260105] It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models**
  - **tags:** [cv], [diffusion models], [mode collapse, noise optimization, frequency characteristics, text-to-image generation, inference-time scaling]
  - **authors:** Anne Harrington, A. Sophia Koepke, Shyamgopal Karthik, Trevor Darrell, Alexei A. Efros
  - **institution:** UC Berkeley, University of Tübingen (Tübingen AI Center), Technical University of Munich (MCML)
  - **link:** https://arxiv.org/pdf/2601.00090
  - **contributions:** 1. Proposes a simple noise optimization objective to mitigate mode collapse in trained diffusion models while preserving model fidelity. 2. Analyzes the frequency characteristics of noise and demonstrates that alternative noise initializations with different frequency profiles can improve optimization and search. 3. Empirically shows that the proposed noise optimization method yields superior results in generation quality and variety compared to existing approaches.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90471f45dfeeb47a677f1a1f9518845473c93d7756e36367a947d6ebb4031c24_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of mode collapse in text-to-image diffusion models, where repeated sampling with the same prompt yields nearly identical images. The proposed solution is to optimize the initial noise input to the model to encourage diverse outputs, while also analyzing and leveraging the frequency characteristics of the noise for better performance. The experiments demonstrate that this noise optimization approach effectively recovers diversity without compromising the quality of the generated images.
  - **Mindmap:**

    ```mermaid
    graph TB
    Root("It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models") --> Problem("核心问题/Problem: Mode collapse in text-to-image models")
    Root --> Method("主要方法/Method: Noise optimization with frequency analysis")
    Root --> Results("关键结果/Results: Improved generation diversity and quality")
    ```

- **[arXiv260105] IMBWatch -- a Spatio-Temporal Graph Neural Network approach to detect Illicit Massage Business**
  - **tags:** [ai], [spatio-temporal graph neural networks], [spatio-temporal graph neural network, dynamic graphs, temporal attention, graph convolutional network, network forensics]
  - **authors:** Swetha Varadarajan, Abhishek Ray, Lumina Albert
  - **institution:** University of Cape Town, George Mason University, Colorado State University
  - **link:** https://arxiv.org/pdf/2601.00075
  - **code:** https://anonymous.4open.science/r/IMB-GNN-F022
  - **contributions:** 1. Proposes IMBWatch, a novel ST-GNN framework for detecting Illicit Massage Businesses by modeling them as dynamic, heterogeneous graphs from open-source data. 2. Introduces a method combining graph convolutions with temporal attention to capture evolving spatio-temporal patterns like intercity movement and coordinated advertising. 3. Demonstrates superior performance over baseline models on real-world data and provides an interpretable, scalable tool for proactive anti-trafficking interventions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef349259f296853dd5ad0527274fd725d811fdf18b16b020222413bfeb7f6f93_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces IMBWatch, a spatio-temporal graph neural network framework designed to detect Illicit Massage Businesses by modeling their operations as dynamic graphs from online ads and records. The method uses graph convolutions and temporal attention to learn evolving patterns, and it outperforms baseline models in accuracy and F1-score on real-world data, offering a scalable tool for law enforcement.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[IMBWatch: A Spatio-Temporal Graph Neural Network Framework for Detecting Illicit Massage Businesses] --> B(核心问题/Problem: Detecting covert Illicit Massage Businesses is difficult due to encoded ads and dynamic operations.)
    A --> C(主要方法/Method: Constructs dynamic graphs from open-source data and uses ST-GNN with temporal attention to model spatio-temporal evolution.)
    A --> D(关键结果/Results: Outperforms baseline models (GCN, GAT, etc.) on real data, offering higher accuracy, interpretability, and scalability.)
    ```

- **[arXiv260105] Large Empirical Case Study: Go-Explore adapted for AI Red Team Testing**
  - **tags:** [sec], [LLM Security], [Go-Explore, Prompt Injection, Adversarial Testing, Agent Safety, Multi-Hop Attacks]
  - **authors:** Manish Bhatt, Adrian Wood, Idan Habler, Ammar Al-Kahfah
  - **institution:** OWASP, Amazon, Dropbox, CISCO, AWS
  - **link:** https://arxiv.org/pdf/2601.00042
  - **code:** https://github.com/mbhatt1/competitionscratch
  - **contributions:** 1. Adapted the Go-Explore reinforcement learning algorithm for systematic security testing of LLM agents. 2. Conducted a large-scale empirical study revealing that random seed variance dominates algorithmic parameter choices in this domain. 3. Provided actionable insights for practitioners, such as the ineffectiveness of reward shaping and the benefits of using ensembles and simple state signatures.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5fd9dc0076e96f0b8282984cab768d0355248ad4e2af52c17ac7798bb446d49_w640_q70.webp
  - **Simple LLM Summary:** This paper adapts the Go-Explore algorithm to test the security of safety-trained LLM agents against prompt injection attacks. Through 28 experimental runs on GPT-4o-mini, the study finds that random seed variance is a major factor, reward shaping is harmful, and simple state signatures work best. The results suggest that managing seed variance and applying domain knowledge are more critical than algorithmic sophistication for effective security testing.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Large Empirical Case Study: Go-Explore adapted for AI Red Team Testing<br/>大型实证案例研究：用于AI红队测试的Go-Explore"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br/>Testing security of safety-trained LLM agents<br/>测试经过安全训练的LLM代理的安全性"] --> P1["Prompt Injection<br/>提示注入"]
        Method["主要方法/Method<br/>Adapt Go-Explore algorithm<br/>改编Go-Explore算法"] --> M1["Systematic exploration from archive<br/>从存档进行系统探索"]
        Results["关键结果/Results<br/>Key Findings<br/>关键发现"] --> R1["Seed variance dominates<br/>种子方差占主导"]
        Results --> R2["Reward shaping harms performance<br/>奖励塑形损害性能"]
        Results --> R3["Simple signatures outperform<br/>简单签名效果更好"]
        Results --> R4["Ensembles provide diversity<br/>集成提供多样性"]
    ```

- **[arXiv260105] Exploration in the Limit**
  - **tags:** [ai], [bandit algorithms], [best arm identification, asymptotic error control, confidence sequences, nonparametric, sample complexity]
  - **authors:** Brian M. Cho, Nathan Kallus
  - **institution:** Cornell University, Netflix
  - **link:** https://arxiv.org/pdf/2601.00084
  - **contributions:** 1. Introduces a relaxed, asymptotic formulation for fixed-confidence best arm identification (BAI) that requires valid error control only after a minimum sample size, aligning with long-horizon practical settings. 2. Develops a novel asymptotic anytime-valid confidence sequence for arm indices and uses it to design a new BAI algorithm that flexibly incorporates covariates for variance reduction in fully nonparametric settings. 3. Provides asymptotic sample complexity bounds, showing the worst-case complexity matches the best-case complexity of Gaussian BAI under exact guarantees, and demonstrates reduced average sample complexity in experiments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a27e11a98452705127752d5c92465faa383d4d4bc6f162ce25d8230c0bd85bbd_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses limitations in existing best arm identification (BAI) methods by proposing an asymptotic framework that relaxes the requirement for exact error control to an asymptotic one, enabling the use of tighter bounds and handling nonparametric distributions with covariates. It introduces a new algorithm based on asymptotic anytime-valid confidence sequences. Experiments show this approach reduces average sample complexity while maintaining error control.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Exploration in the Limit] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有BAI方法不实用/Existing BAI methods impractical]
        B1 --> B2[严格误差控制导致限制/Stringent exact error control causes restrictions]
        C --> C1[渐近误差控制框架/Asymptotic error control framework]
        C1 --> C2[新颖置信序列/Novel confidence sequences]
        C2 --> C3[新BAI算法/New BAI algorithm]
        D --> D1[样本复杂度匹配最佳情况/Sample complexity matches best-case]
        D1 --> D2[实验减少平均样本量/Experiments reduce average sample size]
    ```

- **[arXiv260105] Dynamic Bayesian Optimization Framework for Instruction Tuning in Partial Differential Equation Discovery**
  - **tags:** [ai], [symbolic regression], [Bayesian Optimization, Instruction Tuning, Partial Differential Equation Discovery, LLM Prompting]
  - **authors:** Junqi Qu, Yan Zhang, Shangqian Gao, Shibo Li
  - **institution:** Florida State University
  - **link:** https://arxiv.org/pdf/2601.00088
  - **contributions:** 1. Identifies and formalizes the problem of "instruction brittleness" in LLMs for equation discovery, where model outputs are highly sensitive to prompt phrasing. 2. Proposes NeuroSymBO, a novel framework that reframes prompt engineering as a sequential decision problem, using Bayesian Optimization to dynamically select optimal instructions from a library at each step. 3. Demonstrates through experiments on PDE discovery benchmarks that adaptive instruction selection significantly outperforms static prompts, achieving higher recovery rates and more parsimonious solutions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/987d0309ae3b94e9b3ab379ec45397a3f052c2722939b39c6750528988b21974_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of "instruction brittleness" in LLMs used for discovering partial differential equations, where fixed prompts lead to suboptimal results. It proposes NeuroSymBO, a framework that uses Bayesian Optimization to dynamically select the best instruction at each step of the generation process. Experiments show this adaptive approach outperforms static prompting, yielding more accurate and simpler equations.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Dynamic Bayesian Optimization Framework for Instruction Tuning in Partial Differential Equation Discovery] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: LLM指令脆弱性<br/>Instruction Brittleness in LLMs] --> P1[静态提示导致次优解<br/>Static prompts cause suboptimal solutions]
        Method[主要方法/Method: NeuroSymBO框架<br/>NeuroSymBO Framework] --> M1[将提示工程视为序列决策问题<br/>Reframes prompt engineering as sequential decision] --> M2[使用贝叶斯优化动态选择指令<br/>Uses Bayesian Optimization for adaptive instruction selection]
        Results[关键结果/Results: 实验评估<br/>Experimental Evaluation] --> R1[自适应选择显著优于固定提示<br/>Adaptive selection significantly outperforms fixed prompts] --> R2[更高的恢复率与更简约的解<br/>Higher recovery rates & more parsimonious solutions]
    ```

- **[arXiv260105] Reinforcement learning with timed constraints for robotics motion planning**
  - **tags:** [ai], [reinforcement learning], [Metric Interval Temporal Logic (MITL), Timed Limit-Deterministic Generalized Büchi Automata (Timed-LDGBA), Q-learning, POMDP]
  - **authors:** Zhaoan Wang, Junchao Li, Mahdi Mohammad, Shaoping Xiao
  - **institution:** University of Iowa, Talus Renewables, Inc., Roma Tre University
  - **link:** https://arxiv.org/pdf/2601.00087
  - **contributions:** 1. Proposes a unified automata-based RL framework for synthesizing policies under MITL specifications in both MDPs and POMDPs. 2. Introduces a translation of MITL formulas into Timed-LDGBA and their synchronization with decision processes to create product timed models for Q-learning. 3. Validates the framework with simulation studies showing it satisfies time-bounded requirements, scales to larger state spaces, and works in partially observable environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/556427a99f7edc810f0aa638c014e36ca104d451bbd5edf5c81df58176b568d9_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the challenge of integrating formal temporal logic (MITL) with reinforcement learning for robotic motion planning under stochastic and partially observable dynamics. It proposes a method that translates MITL specifications into timed automata and synchronizes them with the decision process to enable policy learning via Q-learning. The results demonstrate that the learned policies successfully satisfy strict time constraints in various simulated environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Reinforcement learning with timed constraints for robotics motion planning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[复杂任务序列与严格时间约束/Complex task sequences & strict temporal constraints]
        B --> B2[随机动态与部分可观测性/Stochastic dynamics & partial observability]
        C --> C1[MITL公式转换为Timed-LDGBA/MITL to Timed-LDGBA translation]
        C --> C2[构建产品定时模型与Q学习/Construct product timed models for Q-learning]
        C --> C3[简单而富有表现力的奖励结构/Simple yet expressive reward structure]
        D --> D1[满足时间约束的策略/Policies satisfy time-bounded requirements]
        D --> D2[扩展到更大状态空间/Scales to larger state spaces]
        D --> D3[在部分可观测环境中有效/Effective in partially observable environments]
    ```

- **[arXiv260105] GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments**
  - **tags:** [ai], [reinforcement learning], [geometric reinforcement learning, Hamiltonian optimization, simultaneous navigation and mapping, local sensory observations, path differential]
  - **authors:** Aditya Sai Ellendula, Yi Wang, Minh Nguyen, Chandrajit Bajaj
  - **institution:** University of Texas at Austin
  - **link:** https://arxiv.org/pdf/2601.00116
  - **code:** https://github.com/ (as per the abstract "The code is publicly available on Github." The specific URL is not provided in the given text, only a placeholder link.)
  - **contributions:** 1. Proposes a novel geometric reinforcement learning framework (GRL-SNAM) for Simultaneous Navigation and Mapping that relies exclusively on local sensory observations without constructing a global map. 2. Formulates navigation and mapping as a dynamic shortest path search using controlled Hamiltonian optimization, translating sensory inputs into local energy landscapes and evolving policies via updating Hamiltonians. 3. Demonstrates that the method enables high-quality navigation with minimal exploration through local energy refinement, preserving clearance and generalizing to unseen environments in 2D navigation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/776eec0810502d9188877dd04875e090e89eaeb9b6aaa3dec59b37da20fe81b7_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping (SNAM) in unknown environments. It formulates the problem as a dynamic shortest path search using Hamiltonian optimization, where local sensory data is used to update energy landscapes and refine trajectories without building a global map. The method is shown to achieve efficient, high-quality navigation with minimal exploration and good generalization in 2D tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GRL-SNAM: Geometric RL for SNAM] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Simultaneous Navigation and Mapping in mapless environments]
        C[主要方法/Method: Geometric RL with Path Differential Hamiltonians, local energy landscapes]
        D[关键结果/Results: High-quality navigation with minimal exploration, generalizes to unseen layouts]
    ```

- **[arXiv260105] Reinforcement Learning with Function Approximation for Non-Markov Processes**
  - **tags:** [ai], [reinforcement learning], [non-Markov processes, linear function approximation, policy evaluation, Q-learning, partially observed MDPs]
  - **authors:** Ali Devran Kara
  - **institution:** Florida State University
  - **link:** https://arxiv.org/pdf/2601.00151
  - **contributions:** 1. Proved convergence of policy evaluation with linear function approximation under ergodic non-Markov processes, linking the limit to a fixed point of a joint projection-Bellman operator. 2. Established convergence for a special case of Q-learning with linear approximation where basis functions are based on quantization maps under similar ergodicity conditions. 3. Applied the theoretical results to Partially Observed MDPs (POMDPs) using finite-memory state representations and derived explicit error bounds for the learning algorithm limits.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e117bcd100ad5f0daa634538585e364383717d05bbbd527d7dcc2b26e2b92b1_w640_q70.webp
  - **Simple LLM Summary:** This paper studies reinforcement learning with linear function approximation for non-Markov processes. It proves convergence for policy evaluation and a special case of Q-learning under ergodicity conditions, and applies the theory to POMDPs to derive error bounds.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Reinforcement Learning with Function Approximation for Non-Markov Processes] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br>RL with linear function approximation for non-Markov processes] --> P1[非马尔可夫过程/Non-Markov Processes]
        Method[主要方法/Method<br>Theoretical analysis under ergodicity conditions] --> M1[策略评估/Policy Evaluation]
        Method --> M2[Q学习/Q-learning]
        M2 --> M2_1[特殊情况:基于量化的基函数/Special Case: Quantization-based basis]
        Results[关键结果/Results] --> R1[收敛性证明/Convergence Proofs]
        Results --> R2[应用于POMDPs/Application to POMDPs]
        R2 --> R2_1[显式误差界/Explicit Error Bounds]
    ```

- **[arXiv260105] The Weather Paradox: Why Precipitation Fails to Predict Traffic Accident Severity in Large-Scale US Data**
  - **tags:** [ai], [predictive modeling], [XGBoost, feature importance, class imbalance]
  - **authors:** Yann Bellec, Rohan Kaman, Siwen Cui, Aarav Agrawal, Calvin Chen
  - **institution:** University of California San Diego
  - **link:** https://arxiv.org/pdf/2601.00152
  - **contributions:** 1. A large-scale empirical analysis using an XGBoost model to predict traffic accident severity from environmental, temporal, and spatial factors. 2. A feature importance analysis revealing that time of day, location, temperature, and wind speed are strong predictors, while precipitation and visibility show limited predictive power, suggesting driver behavioral adaptation. 3. Identification of dataset limitations (class imbalance, predominance of mid-level severity) and proposed future directions including alternative sampling and enhanced feature engineering.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27e52d086cf3d330117b8cda24994123a6a67bf935b7650263f6ca2e120a3ed2_w640_q70.webp
  - **Simple LLM Summary:** This study uses an XGBoost classifier on a dataset of 500,000 US traffic accidents to predict accident severity. The model achieves 78% accuracy, and feature analysis shows that while time, location, and some weather factors are predictive, precipitation and visibility are not, potentially due to driver adaptation. The findings highlight the limitations of current data for predicting extreme cases and suggest future research directions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[The Weather Paradox: Why Precipitation Fails to Predict Traffic Accident Severity in Large-Scale US Data] --> Problem(核心问题/Problem)
        Root --> Method(主要方法/Method)
        Root --> Results(关键结果/Results)
        Problem --> P1[Predict traffic accident severity/预测交通事故严重程度]
        Method --> M1[XGBoost Classifier/XGBoost分类器]
        Method --> M2[Randomized Search CV/随机搜索交叉验证]
        Method --> M3[Class Weighting/类别加权]
        Results --> R1[78% Accuracy/78%准确率]
        Results --> R2[Precipitation low importance/降水预测力低]
        Results --> R3[Dataset limitations identified/识别数据集局限]
    ```

- **[arXiv260105] Online Finetuning Decision Transformers with Pure RL Gradients**
  - **tags:** [ai], [reinforcement learning], [Decision Transformer, online finetuning, GRPO, hindsight return relabeling, sub-trajectory optimization]
  - **authors:** Junkai Luo, Yinglun Zhu
  - **institution:** University of California, Riverside
  - **link:** https://arxiv.org/pdf/2601.00167
  - **contributions:** 1. Identifies hindsight return relabeling as a fundamental obstacle to using pure RL gradients for online finetuning of Decision Transformers. 2. Proposes new algorithms that adapt GRPO to DTs with key modifications like sub-trajectory optimization, sequence-level likelihood objectives, and active sampling. 3. Demonstrates state-of-the-art performance across multiple benchmarks, showing the effectiveness of pure-RL-based online finetuning for DTs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7142aabdfb71311da4fa293bcc82f4d6d24b9dddc11ccaf74c0aaea92b54d5e3_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of online finetuning for Decision Transformers using pure reinforcement learning gradients, which has been largely unexplored. The authors identify and overcome the incompatibility of standard hindsight return relabeling with RL algorithms, proposing modified methods based on GRPO. Their approach outperforms existing online DT baselines, achieving new state-of-the-art results on several benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Online Finetuning Decision Transformers with Pure RL Gradients] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[在线微调DT时，纯RL梯度方法未被探索/Pure RL gradients for online DT finetuning unexplored]
    B --> B2[后见之益回报重标注与RL算法不兼容/Hindsight return relabeling incompatible with RL]
    C --> C1[适配GRPO至DT/Adapt GRPO to DTs]
    C --> C2[引入关键修改: 子轨迹优化等/Introduce key modifications]
    D --> D1[超越现有在线DT基线/Outperform online DT baselines]
    D --> D2[实现SOTA性能/Achieve SOTA performance]
    ```

- **[arXiv260105] Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting**
  - **tags:** [mlsys], [others], [Reservoir Computing, Sequential Architecture, Spatiotemporal Forecasting, High-dimensional Data, Training Efficiency]
  - **authors:** Ata Akbari Asanjan, Filip Wudarski, Daniel O'Connor, Shaun Geaney, Elena Strbac, P. Aaron Lott, Davide Venturelli
  - **institution:** USRA Research Institute for Advanced Computer Science (RIACS), Standard Chartered Bank
  - **link:** https://arxiv.org/pdf/2601.00172
  - **contributions:** 1. Introduces a Sequential Reservoir Computing architecture that decomposes a large reservoir into smaller, interconnected ones to reduce computational and memory costs. 2. Demonstrates superior performance with longer forecast horizons and lower error metrics on chaotic and high-dimensional physical systems compared to RNN/LSTM baselines. 3. Achieves up to three orders of magnitude lower training cost, maintaining RC's efficiency while improving scalability for high-dimensional forecasting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80a4bf491108d4e92c2c08807229cd230f08dd3e916c820595ac48efa8952783_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Sequential Reservoir Computing, a novel architecture that breaks a large reservoir into a sequence of smaller ones to efficiently forecast high-dimensional spatiotemporal systems. It outperforms traditional RNNs and LSTMs in forecast horizon and accuracy while drastically reducing training costs, offering a path to real-time, energy-efficient forecasting.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>RNN/LSTM训练成本高，传统RC扩展性差"]
        Method["主要方法/Method<br>顺序储层计算架构"]
        Results["关键结果/Results<br>预测更长，误差更低，训练成本大幅降低"]
    ```

- **[arXiv260105] Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings**
  - **tags:** [ai], [semantic communication], [reinforcement learning, unequal error protection, adaptive repetition coding, semantic distortion metric, per-dimension protection]
  - **authors:** Moirangthem Tiken Singh, Adnan Arif
  - **institution:** Department of Computer Science and Engineering, Dibrugarh University Institute of Engineering and Technology, Dibrugarh University
  - **link:** https://arxiv.org/pdf/2601.00186
  - **contributions:** 1. A novel reinforcement learning framework for per-dimension unequal error protection of quantized semantic embeddings, 2. A composite semantic distortion metric that balances global embedding similarity with entity-level preservation to guide the RL agent, 3. The demonstration that simple, intelligently allocated repetition coding can outperform conventional codes like LDPC for fine-grained semantic protection
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb4eade98aeb895832aed0b8cd026ed4c334838f42e2fd62ce3cdef3c7aea4d0_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a reinforcement learning framework to protect quantized semantic embeddings transmitted over noisy channels. The method uses adaptive repetition coding to provide unequal error protection per embedding dimension, guided by a novel semantic distortion metric. The results show that this approach significantly outperforms uniform protection, challenging traditional channel coding paradigms by aligning code structure with semantic granularity.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[带宽受限下保持语义/Bandwidth-constrained Semantic Preservation]
        C --> C1[基于RL的自适应重复编码/RL-based Adaptive Repetition Coding]
        C --> C2[复合语义失真度量/Composite Semantic Distortion Metric]
        D --> D1[性能显著超越均匀保护/Significant Gains Over Uniform Protection]
        D --> D2[挑战传统信道编码范式/Challenges Traditional Channel Coding]
    ```

- **[arXiv260105] Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score**
  - **tags:** [ai], [clinical prediction], [XGBoost, electronic health records (EHR), FIB-4 score, liver cirrhosis, early prediction]
  - **authors:** Zhuqi Miao, Sujan Ravi, Abdulaziz Ahmed
  - **institution:** Oklahoma State University, University of Alabama at Birmingham
  - **link:** https://arxiv.org/pdf/2601.00175
  - **contributions:** 1. Developed and validated machine learning models for predicting liver cirrhosis 1, 2, and 3 years before diagnosis using routine EHR data. 2. Established a rigorous benchmark by comparing the ML models' performance directly against the traditional clinical FIB-4 score across multiple time horizons. 3. Demonstrated that ML models consistently outperform FIB-4, with performance gains increasing for longer-term (3-year) predictions, enabling earlier clinical risk stratification.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/10f123bbaaf0097372e87215cac6fce63e113f7c0a6ea463635fbc4532641048_w640_q70.webp
  - **Simple LLM Summary:** This paper develops XGBoost models using electronic health record data to predict liver cirrhosis 1-3 years before diagnosis. The models consistently outperformed the standard FIB-4 score, with performance gains increasing for longer prediction horizons. The study concludes that these ML models can be integrated into clinical workflows as automated decision-support tools for earlier and more accurate risk stratification.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Early Prediction of Liver Cirrhosis Up to Three Years in Advance] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[早期预测肝硬化 / Early Prediction of Liver Cirrhosis]
    B --> B2[超越FIB-4评分 / Benchmarking Against FIB-4]
    C --> C1[使用EHR数据 / Use EHR Data]
    C --> C2[构建预测场景 / Construct Prediction Scenarios]
    C --> C3[训练XGBoost模型 / Train XGBoost Models]
    D --> D1[ML模型性能更优 / ML Models Outperform FIB-4]
    D --> D2[AUC: 0.81, 0.73, 0.69 / AUC: 0.81, 0.73, 0.69]
    D --> D3[支持早期风险分层 / Supports Early Risk Stratification]
    ```

- **[arXiv260105] SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification**
  - **tags:** [ai], [semi-supervised learning], [Generative Adversarial Network, Swin Transformer, spike classification, semi-supervised learning, Bayesian optimization]
  - **authors:** Danial Sharifrazi, Nouman Javed, Mojtaba Mohammadi, Seyede Sana Salehi, Roohallah Alizadehsani, Prasad N. Paradkar, U. Rajendra Acharya, Asim Bhatti
  - **institution:** Deakin University, CSIRO Health and Biosecurity, Islamic Azad University, University of Southern Queensland
  - **link:** https://arxiv.org/pdf/2601.00189
  - **contributions:** 1. Proposed a novel semi-supervised GAN architecture (SSI-GAN) with a Swin-inspired, shifted-window discriminator for neuronal spike classification. 2. Introduced a transformer-based generator and a flat, window-based transformer discriminator with multi-head self-attention to capture sparse, high-frequency spike features. 3. Demonstrated state-of-the-art performance with 99.93% accuracy using only 1-3% labeled data, reducing manual labeling effort by 97-99% compared to supervised methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49a3916713727a5d92dd8fe976e78d600a974d9217a0ccc868f8608ec8453524_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the labor-intensive problem of classifying mosquito neuronal spikes for arboviral disease detection by proposing SSI-GAN, a semi-supervised GAN that combines a Swin-inspired discriminator with a transformer-based generator. Using only 1-3% labeled data from over 15 million spike samples, it achieved up to 99.93% accuracy in classifying Zika-infected, dengue-infected, or uninfected categories, significantly reducing labeling effort while outperforming baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SSI-GAN: 半监督Swin启发的生成对抗网络用于神经元尖峰分类] --> B[核心问题/Problem: 蚊虫神经元尖峰模式手动分类劳动密集且昂贵，现有深度学习方法需要全标记数据和高度预处理]
        A --> C[主要方法/Method: 提出SSI-GAN，使用Swin启发的移位窗口判别器和基于Transformer的生成器，仅需1-3%标记数据]
        A --> D[关键结果/Results: 达到99.93%分类准确率，标记工作量减少97-99%，在所有感染阶段保持高精度]
    ```

- **[arXiv260105] Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework**
  - **tags:** [mlsys], [on-device ai], [hybrid feature engineering, wavelet decomposition, graph-theoretic descriptors, linear separability, model compression]
  - **authors:** Moirangthem Tiken Singh, Manibhushan Yaikhom
  - **institution:** Dibrugarh University Institute of Engineering and Technology (DUIET), Dibrugarh University; Regional Institute of Medical Sciences
  - **link:** https://arxiv.org/pdf/2601.00192
  - **contributions:** 1. A resource-efficient, data-centric framework that makes high-dimensional ECG data linearly separable through hybrid feature engineering. 2. A novel feature space integrating time-frequency wavelet decompositions with graph-theoretic structural descriptors like PageRank centrality. 3. An ultra-lightweight model achieving state-of-the-art efficiency (8.54 KB, 0.46 µs latency) for real-time arrhythmia detection on edge devices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7a662793cb6f13133cb7159786a9b30cdc33ffe10a9ca51a20ba5d501aa94a04_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a resource-efficient framework for arrhythmia detection on edge devices by using hybrid feature engineering (wavelet and graph descriptors) to make ECG data linearly separable, enabling the use of ultra-lightweight linear classifiers. The resulting model achieves high accuracy (98.44%) with a very small footprint (8.54 KB) and low latency, offering significant efficiency gains over compressed deep learning models for IoMT applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection<br>优化的混合特征工程用于资源高效的心律失常检测"] --> B
        A --> C
        A --> D
        B["Problem: Deep learning models are too heavy for edge devices.<br>核心问题: 深度学习模型在边缘设备上计算开销过大"]
        C["Method: Hybrid feature engineering (wavelet + graph) for linear separability.<br>主要方法: 混合特征工程（小波+图论）实现线性可分性"]
        D["Results: 98.44% accuracy, 8.54 KB model, 0.46 µs latency.<br>关键结果: 98.44% 准确率, 8.54 KB 模型, 0.46 µs 延迟"]
    ```

- **[arXiv260105] StockBot 2.0: Vanilla LSTMs Outperform Transformer-based Forecasting for Stock Prices**
  - **tags:** [ai], [time series forecasting], [LSTM, Transformer, Stock Prediction, Time Series Forecasting, Attention]
  - **authors:** Shaswat Mohanty
  - **institution:** Stanford University
  - **link:** https://arxiv.org/pdf/2601.00197
  - **contributions:** 1. Presents an enhanced StockBot architecture for systematic evaluation of modern time-series forecasting models (attention-based, convolutional, recurrent) in a unified setting. 2. Demonstrates empirically that a carefully constructed vanilla LSTM model consistently outperforms transformer-based models in stock price forecasting accuracy and decision-making stability under default hyperparameters. 3. Highlights the robustness, data efficiency, and importance of architectural inductive bias of recurrent models for financial forecasting, especially in data-limited scenarios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/131078c30708f9e13fee0c529bee858ed184717ff3b0bf5f762eda2a9370616c_w640_q70.webp
  - **Simple LLM Summary:** This paper presents StockBot 2.0, a framework for evaluating time-series models for stock prediction. It finds that a vanilla LSTM model, despite its simplicity, outperforms more complex transformer-based models in forecasting accuracy and trading decision stability when trained with default settings, emphasizing the value of recurrent inductive biases for financial data.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["StockBot 2.0: Vanilla LSTMs Outperform Transformer-based Forecasting for Stock Prices"] --> Problem["核心问题/Problem: Forecasting financial markets is challenging due to complexity and volatility."]
        Root --> Method["主要方法/Method: Enhanced StockBot architecture for systematic evaluation of attention, CNN, and RNN models."]
        Root --> Results["关键结果/Results: Vanilla LSTM achieves superior accuracy and stable decisions compared to transformers."]
    ```

- **[arXiv260105] Unknown Aware AI-Generated Content Attribution**
  - **tags:** [cv], [image attribution], [generative model attribution, constrained optimization, open world setting, CLIP features, unknown generators]
  - **authors:** Ellie Thieu, Jifan Zhang, Haoyue Bai
  - **institution:** University of Wisconsin–Madison (UW–Madison)
  - **link:** https://arxiv.org/pdf/2601.00218
  - **contributions:** 1. Establishes a strong baseline for target generator attribution using CLIP features and a linear classifier with limited labeled data. 2. Proposes a novel constrained optimization method that leverages unlabeled "wild" data from the internet to improve robustness to unseen generators. 3. Demonstrates that incorporating unlabeled wild data substantially improves attribution performance on challenging, unseen, and newly released generative models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53bb1bd3ca2eb8682e06279d4402b6c4441fc76d44f3b86a930479ba697b4e06_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of attributing AI-generated images to their specific source model in an open-world setting where new, unseen generators constantly emerge. The authors propose a constrained optimization approach that uses unlabeled data collected from the internet to encourage the classifier to treat unknown samples as non-target, while maintaining performance on known labeled data. The method significantly improves attribution accuracy on challenging, unseen generative models compared to a baseline trained only on limited labeled data.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Unknown Aware AI-Generated Content Attribution") --> Problem("核心问题/Problem: Attribution in open world with unseen generators")
        Root --> Method("主要方法/Method: Constrained optimization with unlabeled wild data")
        Root --> Results("关键结果/Results: Improved performance on unseen generators")
    ```

- **[arXiv260105] Robust Graph Fine-Tuning with Adversarial Graph Prompting**
  - **tags:** [ai], [graph neural networks], [Adversarial Graph Prompting, Parameter-Efficient Fine-Tuning, Graph Prompt Learning, Adversarial Learning, Robust Fine-Tuning]
  - **authors:** Ziyan Zhang, Bo Jiang, Jin Tang
  - **institution:** Anhui University
  - **link:** https://arxiv.org/pdf/2601.00229
  - **contributions:** 1. Proposes a novel Adversarial Graph Prompting (AGP) framework that integrates adversarial learning into graph prompting for robust parameter-efficient fine-tuning of pre-trained GNNs. 2. Formulates AGP as a min-max optimization problem and develops an alternating optimization scheme, featuring a Joint Projected Gradient Descent (JointPGD) algorithm for generating adversarial noise and a module for learning optimal node prompts. 3. Provides theoretical analysis demonstrating that AGP can handle both graph topology and node feature noise, confirming its versatility and robustness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/337af6d04faa59592d198afa70192352bc013ab310b674dbdaed1185325d78c7_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the vulnerability of Parameter-Efficient Fine-Tuning (PEFT) methods for Graph Neural Networks (GNNs) to noise and attacks. It proposes a novel Adversarial Graph Prompting (AGP) framework that formulates robust fine-tuning as a min-max optimization problem, using adversarial noise generation and prompt learning to counteract it. The method is theoretically sound and experimentally validated to be more robust than state-of-the-art approaches across various graph noises.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Robust Graph Fine-Tuning with Adversarial Graph Prompting] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有PEFT方法对图噪声和攻击脆弱/Existing PEFT methods are vulnerable to graph noise & attacks]
        C --> C1[对抗图提示(AGP)框架/Adversarial Graph Prompting (AGP) Framework]
        C1 --> C2[最小-最大优化/Min-Max Optimization]
        C2 --> C3[内层: JointPGD生成对抗噪声/Inner: JointPGD for adversarial noise]
        C2 --> C4[外层: 学习最优节点提示/Outer: Learn optimal node prompts]
        D --> D1[理论证明处理拓扑和节点噪声/Theoretically handles topology & node noise]
        D --> D2[实验验证鲁棒性和有效性/Experiments validate robustness & effectiveness]
    ```

- **[arXiv260105] GRIT -- Geometry-Aware PEFT with K-FACPreconditioning, Fisher-Guided Reprojection, andDynamic Rank Adaptation**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [LoRA, K-FAC, Parameter-Efficient Fine-Tuning, Fisher Information, Dynamic Rank Adaptation]
  - **authors:** Pritish Saha, Chandrav Rajbangshi, Rudra Goyal, Mohit Goyal, Anurag Deo, Biswajit Roy, Ningthoujam Dhanachandra Singh, Raxit Goswami, Amitava Das
  - **institution:** RAAPID Lab, Pragya Lab (BITS Pilani, Goa)
  - **link:** https://arxiv.org/pdf/2601.00231
  - **contributions:** 1. Introduces K-FAC-based gradient preconditioning in the low-rank subspace for more geometry-aware updates. 2. Proposes periodic Fisher-guided reprojection of the LoRA basis to suppress parameter drift. 3. Implements dynamic rank adaptation to concentrate capacity on high-signal directions, reducing the number of trainable parameters.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e9515d46161014bf32c8c1a74f165b3980c9984817a7e1ca0778ce4d66219f5_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that standard LoRA/QLoRA methods are geometry-agnostic, leading to inefficient updates and parameter drift. It proposes GRIT, a new LoRA procedure that uses K-FAC preconditioning, Fisher-guided reprojection, and dynamic rank adaptation to make updates more curvature-aware. This approach matches or surpasses baseline performance while reducing trainable parameters by an average of 46% and achieving lower drift.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GRIT: Geometry-Aware PEFT] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[标准LoRA/QLoRA忽略曲率/Standard LoRA/QLoRA ignores curvature]
        B --> B2[导致低效更新与参数漂移/Causes inefficient updates & parameter drift]
        C --> C1[K-FAC预条件梯度/K-FAC preconditioned gradients]
        C --> C2[Fisher引导重投影/Fisher-guided reprojection]
        C --> C3[动态秩适应/Dynamic rank adaptation]
        D --> D1[性能相当或更好/Matches or surpasses baselines]
        D --> D2[参数减少~46%/Reduces parameters by ~46%]
        D --> D3[漂移更低/Lower drift]
    ```

- **[arXiv260105] Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection**
  - **tags:** [cv], [object detection], [CycleGAN, YOLOv8, infrared image generation, data augmentation, PCB defect detection]
  - **authors:** Chao Yang, Haoyuan Zheng, Yue Ma
  - **institution:** Xi’an Jiaotong Liverpool University
  - **link:** https://arxiv.org/pdf/2601.00237
  - **contributions:** 1. Proposes a cross-modal data augmentation framework using CycleGAN for unpaired translation from visible-light to infrared images to address IR data scarcity. 2. Introduces a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a YOLOv8 detector. 3. Demonstrates that the method significantly improves detection performance under low-data conditions, approaching fully supervised benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6328838143840b03119bcacf495d6f90fd2cfbf75f09c866a7d8dbf7d351c32_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the problem of scarce infrared data for PCB defect detection by using CycleGAN to generate synthetic infrared images from abundant visible-light images and training a YOLOv8 detector on this augmented dataset. The proposed method enhances feature learning with limited real data, significantly outperforming models trained only on real data and nearly matching the performance of fully supervised training.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection"] --> Problem["核心问题/Problem: 红外数据稀缺 / IR Data Scarcity"]
        Root --> Method["主要方法/Method: CycleGAN跨模态生成 + YOLOv8检测 / CycleGAN Cross-modal Generation + YOLOv8 Detection"]
        Root --> Results["关键结果/Results: 性能显著提升，接近全监督基准 / Performance Significantly Improved, Approaches Fully Supervised Benchmark"]
    ```

- **[arXiv260105] Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [neuromorphic computing, state-space models, sparse attention, surrogate gradients, local learning rules]
  - **authors:** Osvaldo Simeone
  - **institution:** Northeastern University London (Intelligent Networked Systems Institute - INSI)
  - **link:** https://arxiv.org/pdf/2601.00245
  - **contributions:** 1. Proposes a novel conceptual framework for analyzing modern neuromorphic AI through the lens of intra-token (feature-level) and inter-token (contextual) processing. 2. Systematically reviews the convergence of neuromorphic principles (e.g., sparse, discrete activations) with state-of-the-art AI architectures like state-space models and transformers. 3. Reviews and categorizes training methodologies for neuromorphic models, from surrogate gradients to local learning rules based on reinforcement learning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9154dccb8e64d45d3b60bd0f6bb1e84fa9423cf041633e14a8cb6272baa46_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high energy costs of modern AI by exploring the convergence of neuromorphic computing principles with contemporary architectures. It proposes a framework distinguishing between intra-token and inter-token processing to analyze how neuromorphic ideas like sparse activations and state dynamics are embodied in models such as transformers and state-space models. The main conclusion is that modern AI is increasingly adopting brain-inspired, energy-efficient neuromorphic principles for both processing types, offering a path toward more sustainable intelligent systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[AI能耗增长 / Escalating AI Energy Requirements]
        C --> C1[神经形态计算原则 / Neuromorphic Computing Principles]
        C1 --> C2[离散稀疏激活 / Discrete & Sparse Activations]
        C1 --> C3[循环动态 / Recurrent Dynamics]
        C --> C4[处理框架: 令牌内与令牌间 / Processing Framework: Intra-Token vs. Inter-Token]
        D --> D1[现代AI体现神经形态原则 / Modern AI Embodies Neuromorphic Principles]
        D --> D2[连接SNN、状态空间模型、Transformer / Connects SNNs, State-Space Models, Transformers]
    ```

- **[arXiv260105] Rectifying Adversarial Examples Using Their Vulnerabilities**
  - **tags:** [sec], [adversarial defense], [adversarial examples, label rectification, re-attack, white-box attack, black-box attack]
  - **authors:** Fumiya Morimoto, Ryuto Morita, Satoshi Ono
  - **institution:** Kagoshima University
  - **link:** https://arxiv.org/pdf/2601.00270
  - **contributions:** 1. Proposes a novel adversarial example rectification method based on "re-attacking" AEs to move them beyond the decision boundary for correct label estimation. 2. The method is designed to be straightforward, requiring only AEs as input without parameter adjustments or preliminary training, enabling it to address diverse attack types. 3. Demonstrates consistent performance and superior stability against various attacks, including targeted and black-box attacks, compared to conventional rectification and input transformation methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c32aaba927fb42e32f98d767a04b8c60ecebe5d8f0f13c4c25f72d7d23e5138c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of rectifying adversarial examples (AEs) to recover the correct labels of the original inputs, which is crucial for applications like autonomous driving. The proposed method works by "re-attacking" the AEs to push them across the model's decision boundary. The results show that this method performs consistently across different attack types and is more stable than existing approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Rectifying Adversarial Examples Using Their Vulnerabilities] --> B(核心问题/Problem: DNNs misclassify adversarial examples, needing correct label recovery)
        A --> C(主要方法/Method: Re-attack AEs to move them beyond decision boundary)
        A --> D(关键结果/Results: Consistent performance across attacks, outperforms conventional methods in stability)
    ```

- **[arXiv260105] Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [quantization, self-explanations, faithfulness, natural language explanations, counterfactual examples]
  - **authors:** Qianli Wang, Nils Feldhus, Pepa Atanasova, Fedor Splitt, Simon Ostermann, Sebastian Möller, Vera Schmitt
  - **institution:** Technische Universität Berlin, German Research Center for Artificial Intelligence (DFKI), University of Copenhagen
  - **link:** https://arxiv.org/pdf/2601.00282
  - **contributions:** 1. First comprehensive study on the impact of quantization on the quality and faithfulness of LLM self-explanations. 2. Empirical evaluation across multiple quantization techniques, bit widths, and model sizes, revealing moderate but consistent degradation in explanation metrics. 3. Provides practical recommendations for validating self-explanations in quantized models, highlighting the greater sensitivity of natural language explanations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8576a4dae59be54ef8b0a451a49893f5b9d59eceafecb4a697aed2b3fd4a470b_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how quantization affects the quality and faithfulness of self-explanations generated by large language models. The authors evaluate multiple quantization methods and find they cause moderate declines in explanation metrics, with larger models showing better faithfulness preservation. They conclude that while quantization degrades self-explanations, the impact is relatively minor and does not negate its benefits for model compression.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Can Large Language Models Still Explain Themselves?<br/>大语言模型还能解释自己吗？"] --> Problem["Quantization's effect on Self-Explanations is unknown.<br/>量化对自我解释的影响未知"]
        Root --> Method["Evaluate NLEs & Counterfactuals from quantized LLMs.<br/>评估量化后LLM的自然语言解释和反事实示例"]
        Root --> Results["Moderate decline in quality/faithfulness; context-dependent impact.<br/>质量/忠实度适度下降；影响因上下文而异"]
    ```

- **[arXiv260105] Task-Driven Kernel Flows: Label Rank Compression and Laplacian Spectral Filtering**
  - **tags:** [ai], [theoretical machine learning], [kernel evolution, spectral truncation, label rank compression, Laplacian spectral filtering, Neural Tangent Kernel]
  - **authors:** Hongxi Li, Chunlin Huang
  - **institution:** Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2601.00276
  - **contributions:** 1. Derives a kernel ODE revealing a "water-filling" spectral law for supervised learning, showing the kernel is compressed into a low-rank subspace bounded by the number of classes. 2. Proves that any stable steady state under L2-regularization and linear readout inherently exhibits label-driven rank compression, independent of the fast-readout approximation. 3. Demonstrates that SGD noise is confined to a low-rank subspace (O(C)), unifying deterministic and stochastic views of alignment, and contrasts this with expansive self-supervised representations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/03dc1352545d41fe155dce9a675ce3e4dfa7f83f33a1829acc745f5fa2954776_w640_q70.webp
  - **Simple LLM Summary:** This paper develops a kernel-centric theory for feature learning in wide neural networks. It shows that supervised learning inherently compresses the kernel into a low-rank subspace bounded by the number of classes, and that SGD noise is similarly confined, contrasting this compressive behavior with the expansive representations of self-supervised learning.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Task-Driven Kernel Flows<br>任务驱动的核流] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[Understanding kernel evolution in feature learning<br>理解特征学习中的核演化]
    C --> C1[Kernel ODE & algebraic analysis<br>核ODE与代数分析]
    D --> D1[Supervised learning is compressive (rank ≤ C)<br>监督学习是压缩性的 (秩 ≤ C)]
    D --> D2[SGD noise is low-rank (O(C))<br>SGD噪声是低秩的 (O(C))]
    D --> D3[Contrast with expansive self-supervision<br>与扩张的自监督学习对比]
    ```

- **[arXiv260105] Can Optimal Transport Improve Federated Inverse Reinforcement Learning?**
  - **tags:** [mlsys], [federated learning], [Inverse Reinforcement Learning, Federated Learning, Optimal Transport, Wasserstein Barycenter, Maximum Entropy IRL]
  - **authors:** David Millard, Ali Baheri
  - **institution:** Rochester Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.00309
  - **contributions:** 1. Introduces an optimal transport-based approach for federating learned reward functions in Inverse Reinforcement Learning (IRL). 2. Proposes using a Wasserstein barycenter for reward fusion, which accounts for the geometric structure of the reward landscape, as opposed to simple parameter averaging. 3. Provides a theoretical proof that the barycentric fusion yields a more faithful global reward estimate than conventional federated averaging methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18b7dd99db471c1c90bc7b908611843e09230b1dcad68713f2c1d393a1fa86bb_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of learning a shared reward function across heterogeneous agents in privacy-sensitive, communication-limited settings. It proposes a federated IRL framework where agents perform local Maximum Entropy IRL and then fuse their reward functions via a Wasserstein barycenter. The authors prove this method provides a more accurate global reward estimate than standard parameter averaging, offering a principled and efficient solution for multi-agent systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Can Optimal Transport Improve Federated Inverse Reinforcement Learning?"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Heterogeneous agents need a shared reward, but data pooling is impractical due to privacy, dynamics differences, and limited bandwidth."]
        Method["主要方法/Method<br>Local lightweight MaxEnt IRL followed by reward fusion via Wasserstein barycenter."]
        Results["关键结果/Results<br>Barycentric fusion yields a more faithful global reward estimate than parameter averaging."]
    ```

- **[arXiv260105] Quantum King-Ring Domination in Chess: A QAOA Approach**
  - **tags:** [ai], [quantum optimization], [QAOA, benchmark, constraint-preserving mixers, warm-start, CVaR]
  - **authors:** Gerhard Stenzel, Michael Kölle, Tobias Rohe, Julian Hager, Leo Sünkel, Maximilian Zorn, Claudia Linnhoff-Popien
  - **institution:** LMU Munich
  - **link:** https://arxiv.org/pdf/2601.00318
  - **contributions:** 1. Introduction of the Quantum King-Ring Domination (QKRD) benchmark, a structured, NISQ-scale testbed derived from chess with 5,000 instances. 2. Systematic evaluation of QAOA design choices, showing the advantages of constraint-preserving mixers and warm-start strategies. 3. Demonstration that structured benchmarks reveal performance insights for problem-informed QAOA techniques that are obscured in random synthetic instances.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0b58913db95e3acf390bd659716f38782d77c5b0f4c58736c855c0b4940575b_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces a new structured benchmark called Quantum King-Ring Domination (QKRD) based on chess to evaluate the Quantum Approximate Optimization Algorithm (QAOA). Using this benchmark, the authors systematically test various QAOA design choices and find that constraint-preserving mixers and warm-start strategies significantly improve performance. The results show that structured benchmarks are crucial for revealing the advantages of problem-informed quantum optimization techniques.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Quantum King-Ring Domination in Chess: A QAOA Approach] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有基准缺乏语义结构/Existing benchmarks lack semantic structure]
        C --> C1[提出基于国际象棋的QKRD基准/Propose chess-based QKRD benchmark]
        C --> C2[系统评估QAOA设计选择/Systematically evaluate QAOA design choices]
        D --> D1[约束保持混频器收敛更快/Constraint-preserving mixers converge faster]
        D --> D2[热启动策略显著改进/Warm-start strategies yield significant improvement]
        D --> D3[结构化基准揭示隐藏优势/Structured benchmarks reveal obscured advantages]
    ```

- **[arXiv260105] Smart Fault Detection in Nanosatellite Electrical Power System**
  - **tags:** [ai], [fault diagnosis], [neural network, PCA classification, decision tree, KNN]
  - **authors:** Alireza Rezaee, Niloofar Nobahari, Amin Asgarifar, Farshid Hajati
  - **institution:** University of Tehran, University of New England
  - **link:** https://arxiv.org/pdf/2601.00335
  - **contributions:** 1. Proposes a new fault detection method for nanosatellite electrical power systems operating without an Attitude Determination Control Subsystem (ADCS) in LEO orbit. 2. Uses a neural network to simulate the fault-free system behavior using solar radiation and panel temperature as inputs to predict current and load. 3. Applies multiple machine learning classifiers (neural network, PCA, decision tree, KNN) to diagnose specific fault patterns and types in the power subsystem.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab383b2f3d676c3a09faf3b55b3c7d4dd74c574ecc0a93d40c28f82897ffe1bf_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a machine learning-based method for detecting faults in nanosatellite electrical power systems. It first simulates normal system behavior using a neural network and then employs various classifiers to identify specific fault types. The approach aims to diagnose common faults like line-to-line shorts and open circuits without relying on an ADCS.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Smart Fault Detection in Nanosatellite Electrical Power System] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LEO轨道无ADCS的纳卫星电源系统故障检测/Fault detection for nanosatellite EPS without ADCS in LEO]
        C --> C1[使用神经网络模拟无故障系统/Simulate fault-free system with neural network]
        C --> C2[应用多种机器学习分类器进行故障诊断/Apply multiple ML classifiers for fault diagnosis]
        D --> D1[诊断光伏、转换器、电池等特定故障/Diagnose specific faults in PV, converter, battery]
    ```

- **[arXiv260105] BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics**
  - **tags:** [nlp], [multilingual representation learning], [Joint Embedding Predictive Architecture (JEPA), BERT, CLS token, language-agnostic embedding, multilingual benchmarks]
  - **authors:** Taj Gillin, Adam Lalani, Kenneth Zhang, Marcel Mateos Salles
  - **institution:** Brown University
  - **link:** https://arxiv.org/pdf/2601.00366
  - **contributions:** 1. Introduces BERT-JEPA (BEPA), a novel training paradigm that adds a JEPA objective to BERT-style models to reorganize the [CLS] embedding space. 2. Demonstrates that BEPA finetuning transforms the [CLS] embedding space into a semantic-first, language-agnostic space, shifting its PCA representation from low-rank to fuller-rank. 3. Shows that this reorganization improves performance on multilingual tasks with little to no loss in English performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cd5b4a28e22d003dd88f59a4d1a1a55a97fa54c9c398a578c710764342d3180_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem that BERT's [CLS] embeddings fail to capture language-invariant semantics. It proposes BERT-JEPA (BEPA), a method that adds a Joint Embedding Predictive Architecture (JEPA) objective during training to reorganize the [CLS] embedding space into a language-agnostic "thought space". The main conclusion is that this approach significantly improves performance on multilingual benchmarks while maintaining English task performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics"] --> Problem["核心问题/Problem: CLS embeddings are not language-invariant and fail to capture true sentence semantics."]
        Root --> Method["主要方法/Method: Add JEPA training objective to BERT to create a language-agnostic embedding space."]
        Root --> Results["关键结果/Results: Improved multilingual benchmark performance; reorganized, semantic-first CLS space."]
    ```

- **[arXiv260105] Deterministic Coreset for Lp Subspace**
  - **tags:** [other], [randomized algorithms, numerical linear algebra, data summarization], [coreset, subspace embedding, ℓp regression, deterministic algorithm, iterative algorithm]
  - **authors:** Rachit Chhaya, Anirban Dasgupta, Dan Feldman, Supratim Shit
  - **institution:** Dhirubhai Ambani University, IIT Gandhinagar, University of Haifa, IIIT-Delhi
  - **link:** https://arxiv.org/pdf/2601.00361
  - **contributions:** 1. Introduces the first iterative algorithm for constructing a deterministic ε-coreset for ℓp subspace embedding for any p in [1,∞). 2. Achieves an optimal coreset size of O(d^\{max(1,p/2)\}/ε²), removing long-standing logarithmic factors. 3. Provides a deterministic guarantee for the coreset, enabling its use for approximately solving ℓp regression deterministically.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b23fc2c49cea022bba3ab19cb79b7de330860628aab1b669177840bc826ecda1_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a new iterative algorithm for constructing a deterministic coreset that provides an ℓp subspace embedding for any p≥1. The method ensures bounded loss in each iteration, leading to a coreset whose size is optimal and free of logarithmic factors. The result solves a long-standing open problem and enables deterministic approximate solutions to ℓp regression.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Deterministic Coreset for Lp Subspace") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("需要为 ℓp 子空间嵌入构建确定性核心集 / Need deterministic coreset for ℓp subspace embedding")
        Problem --> P2("现有核心集存在对数因子 / Existing coresets have log factors")
        Method --> M1("迭代算法 / Iterative algorithm")
        Method --> M2("确保有界损失 / Ensures bounded loss")
        Results --> R1("核心集大小: O(d^{max(1,p/2)}/ε²) / Coreset size: O(d^{max(1,p/2)}/ε²)")
        Results --> R2("移除对数因子 / Removes log factors")
        Results --> R3("确定性保证 / Deterministic guarantee")
    ```

- **[arXiv260105] Engineering Attack Vectors and Detecting Anomalies in Additive Manufacturing**
  - **tags:** [sec], [cyber-physical systems security], [intrusion detection system, anomaly detection, G-code manipulation, transformer encoder, self-attention autoencoder]
  - **authors:** Md Mahbub Hasan, Marcus Sternhagen, Krishna Chandra Roy
  - **institution:** New Mexico Institute of Mining and Technology
  - **link:** https://arxiv.org/pdf/2601.00384
  - **contributions:** 1. Investigation of stealthy Man-in-the-Middle (MitM) attack vectors targeting the CAD-to-machine interface in Fused Deposition Modeling (FDM) 3D printers. 2. Proposal of an unsupervised Intrusion Detection System (IDS) that uses a frozen Transformer-based encoder and contrastive learning to create anomaly-sensitive embeddings from machine logs. 3. Demonstration of effective anomaly classification using a combination of clustering and a self-attention autoencoder on real 3D printing systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b296e2b64944be1e0ab79e116131c11acbb4a662a6a9c3e8adaf377db0c3190e_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates stealthy cyberattacks that manipulate G-code in additive manufacturing systems, leading to structurally defective parts. To detect these attacks, the authors propose an unsupervised intrusion detection system that uses a Transformer-based encoder and contrastive learning to analyze machine logs. Their method successfully distinguishes between normal and compromised printing executions.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Engineering Attack Vectors and Detecting Anomalies in Additive Manufacturing] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[AM系统的新攻击面 / New Attack Surfaces in AM]
    B --> B2[隐秘的中间人攻击 / Stealthy MitM Attacks]
    C --> C1[基于日志的无监督IDS / Unsupervised IDS from Logs]
    C --> C2[Transformer编码器 / Transformer Encoder]
    C --> C3[对比学习与自注意力 / Contrastive Learning & Self-Attention]
    D --> D1[有效区分正常与攻击 / Effectively Distinguishes Benign & Compromised]
    ```

- **[arXiv260105] Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models**
  - **tags:** [cv], [object detection], [aerial video, optical flow, convolutional neural network, hierarchical extreme learning machine, UCF-ARG dataset]
  - **authors:** Nouar AlDahoul, Aznul Qalid Md Sabri, Ali Mohammed Mansoor
  - **institution:** University of Malaya
  - **link:** https://arxiv.org/pdf/2601.00391
  - **contributions:** 1. Proposes a framework combining optical flow with three different deep learning models (S-CNN, pretrained CNN, H-ELM) for human detection in challenging aerial videos. 2. Conducts a comparative performance analysis of the models on the UCF-ARG dataset, evaluating accuracy and training speed across five human actions. 3. Demonstrates the effectiveness of automatic feature learning over handcrafted features for handling dynamic events like camera jitter and scale variation in aerial footage.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/104ed4332f4aebfb8e2617a89656868c3e4e5fae6201be63d4509d5b080a2f50_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of human detection in aerial videos with a non-static camera. It proposes using optical flow combined with three deep learning models (S-CNN, a pretrained CNN, and H-ELM) for automatic feature learning. The experiments on the UCF-ARG dataset show that the pretrained CNN achieves the highest accuracy (98.09%), successfully demonstrating the method's robustness to dynamic conditions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[动态事件挑战<br/>Dynamic Event Challenges]
        B1 --> B2[光照变化, 相机抖动, 目标尺寸变化<br/>Illumination Changes, Camera Jitter, Object Size Variation]
        C --> C1[特征学习方法<br/>Feature Learning Methods]
        C1 --> C2[结合光流与三种深度模型<br/>Combine Optical Flow with Three Deep Models]
        C2 --> C3[监督CNN, 预训练CNN, 分层极限学习机<br/>S-CNN, Pretrained CNN, H-ELM]
        D --> D1[预训练CNN准确率最高<br/>Pretrained CNN Highest Accuracy]
        D1 --> D2[平均准确率98.09%<br/>Average Accuracy 98.09%]
    ```

- **[arXiv260105] NOS-Gate: Queue-Aware Streaming IDS for Consumer Gateways under Timing-Controlled Evasion**
  - **tags:** [sec], [network intrusion detection], [timing-controlled evasion, weighted fair queueing (WFQ), network-optimised spiking (NOS), metadata-only detection, streaming IDS]
  - **authors:** Muhammad Bilal, Omer Tariq, Hasan Ahmed
  - **institution:** Lancaster University, Korea Advanced Institute of Science and Technology (KAIST)
  - **link:** https://arxiv.org/pdf/2601.00389
  - **contributions:** 1. Proposed NOS-Gate, a lightweight, streaming IDS for consumer gateways that uses a two-state unit derived from Network-Optimised Spiking dynamics per flow. 2. Introduced a queue-aware, reversible mitigation action that temporarily reduces a flagged flow's weight under Weighted Fair Queueing (WFQ). 3. Developed an executable 'worlds' benchmark for evaluating IDS under timing-controlled evasion, specifying benign processes, attacker budgets, and enabling packet-level WFQ replay.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16e859896027b80a597ad555df2beab42dc7cf683d8aef57af2a60ff1820126c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of detecting intrusions in encrypted traffic on resource-constrained consumer gateways, where attackers can evade detection by manipulating timing patterns. It proposes NOS-Gate, a lightweight streaming IDS that uses metadata features and a novel mitigation strategy integrated with queue management. The evaluation shows NOS-Gate achieves higher detection recall and reduces queueing delays compared to baselines, with low computational overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[NOS-Gate: Queue-Aware Streaming IDS] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[加密流量中时序模式泄露/Timing patterns leak through encryption]
        Problem --> P2[攻击者进行时序控制规避/Attacker uses timing-controlled evasion]
        Problem --> P3[网关资源严格受限/Gateway has tight CPU & latency budget]
        Method[主要方法/Method] --> M1[轻量级双态单元/Lightweight two-state NOS unit per flow]
        Method --> M2[基于元数据窗口的评分/Score fixed-length metadata windows]
        Method --> M3[可逆的WFQ权重缓解/Reversible WFQ weight mitigation]
        Results[关键结果/Results] --> R1[高事件召回率/High incident recall (0.952)]
        Results --> R2[降低排队延迟/Reduced p99.9 queueing delay]
        Results --> R3[低计算开销/Low scoring cost (~2.09 µs)]
    ```

- **[arXiv260105] Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving**
  - **tags:** [mlsys], [llm inference], [time-warp emulation, CUDA interception, virtual time coordination, performance modeling, discrete-event simulation]
  - **authors:** Amey Agrawal, Mayank Yadav, Sukrit Kumar, Anirudha Agrawal, Garv Ghai, Souradeep Bera, Elton Pinto, Sirish Gambhira, Mohammad Adain, Kasra Sohrab, Chus Antonanzas, Alexey Tumanov
  - **institution:** Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.00397
  - **contributions:** 1. A time-warp emulator that enables performance modeling by directly executing real serving system code without physical GPUs, eliminating the need to re-implement complex control logic. 2. A system that intercepts CUDA API calls to virtualize device management and performs time jumps by fast-forwarding virtual time based on predicted kernel durations. 3. A coordination protocol that synchronizes time jumps across distributed processes while preserving causality, ensuring accurate emulation of parallel execution.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87798fc4e00db06b5558e8552991b262a89ec7eea8a194407a93b93519f3357e_w640_q70.webp
  - **Simple LLM Summary:** The paper presents Revati, a time-warp emulator for efficient LLM serving configuration testing. It directly executes real serving system code by intercepting CUDA calls and performing virtual time jumps instead of running GPU kernels, achieving less than 5% prediction error while running 5-17x faster than real GPU execution on frameworks like vLLM and SGLang.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[GPU集群评估成本高且慢/Evaluating serving configs on GPU clusters is slow and expensive]
        B --> B2[模拟器需要重写控制逻辑/Simulators require re-implementing complex control logic]
        C --> C1[拦截CUDA API调用/Intercept CUDA API calls]
        C --> C2[虚拟时间跳跃/Virtual time jumps based on kernel predictions]
        C --> C3[分布式协调协议/Distributed coordination protocol]
        D --> D1[<5%预测误差/<5% prediction error]
        D --> D2[5-17倍加速/5-17x faster than real execution]
    ```

- **[arXiv260105] Secure, Verifiable, and Scalable Multi-Client Data Sharing via Consensus-Based Privacy-Preserving Data Distribution**
  - **tags:** [sec], [Privacy-preserving data aggregation], [unanimous-release confidentiality, consensus locking, malicious deviation detection]
  - **authors:** Prajwal Panth, Sahaj Raj Malla
  - **institution:** KIIT University, Kathmandu University
  - **link:** https://arxiv.org/pdf/2601.00418
  - **contributions:** 1. Proposes the CPPDD framework, a lightweight protocol for secure multi-client data aggregation using per-client affine masking and priority-driven sequential consensus locking to enforce unanimous-release confidentiality. 2. Introduces decentralized integrity verification via step and data checksums (σ_S, σ_D) enabling autonomous malicious deviation detection and atomic abort without persistent coordination. 3. Formally proves the framework's properties (correctness, CDIF, IND-CPA security) and empirically demonstrates linear scalability up to 500 clients with significantly lower computational overhead compared to MPC and HE baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1a94aa63b5803d44299e228782541c1d2830c11c784cb2a9d0a55df2b0c6765_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes the CPPDD framework to address the problem of secure and verifiable multi-client data sharing. The method combines affine masking and consensus locking for privacy, and uses checksums for integrity verification, enabling efficient, scalable aggregation with malicious security. The framework is proven secure and shown to be orders of magnitude more efficient than traditional cryptographic approaches like MPC and HE.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Secure, Verifiable, and Scalable Multi-Client Data Sharing<br>安全、可验证、可扩展的多客户端数据共享] --> B(核心问题/Problem: Secure multi-client data aggregation with privacy and verifiability<br>安全、可验证的多客户端隐私数据聚合)
        A --> C(主要方法/Method: Consensus-Based Privacy-Preserving Data Distribution (CPPDD)<br>基于共识的隐私保护数据分发)
        C --> C1(Affine Masking & Consensus Locking<br>仿射掩码与共识锁定)
        C --> C2(Step/Data Checksums (σ_S, σ_D)<br>步骤/数据校验和)
        A --> D(关键结果/Results: Linear scalability, 100% deviation detection, lower FLOPs vs MPC/HE<br>线性可扩展性，100%异常检测，相比MPC/HE更低的计算量)
    ```

- **[arXiv260105] RMAAT: Astrocyte-Inspired Memory Compression and Replay for Efficient Long-Context Transformers**
  - **tags:** [ai], [efficient transformers], [astrocyte-inspired computing, long-term plasticity (LTP), short-term plasticity (STP), memory compression, Long Range Arena (LRA)]
  - **authors:** Md Zesun Ahmed Mia, Malyaban Bal, Abhronil Sengupta
  - **institution:** Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2601.00426
  - **contributions:** 1. Introduces RMAAT, a novel Transformer architecture that integrates abstracted astrocyte functionalities for efficient long-context processing. 2. Proposes an adaptive memory compression mechanism governed by a novel retention factor derived from simulated astrocyte long-term plasticity (LTP). 3. Develops Astrocytic Memory Replay Backpropagation (AMRB), a novel training algorithm designed for memory efficiency in recurrent networks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48db0bbab3b8ca0fcbec4bfde72ebb384d63651cf925a575ef2f9e06a070abc5_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the quadratic complexity problem of Transformer self-attention for long sequences by proposing RMAAT, an architecture inspired by astrocyte functions in biological memory. The method uses recurrent segment-based processing with adaptive memory compression and a linear-complexity attention mechanism. Evaluations on the Long Range Arena benchmark show that RMAAT achieves competitive accuracy with substantial improvements in computational and memory efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[RMAAT: Astrocyte-Inspired Memory Compression and Replay] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Transformer自注意力二次复杂度/Quadratic Complexity of Self-Attention]
        Method[主要方法/Method: 星形胶质细胞启发的循环记忆架构/Astrocyte-Inspired Recurrent Memory Architecture]
        Results[关键结果/Results: 在LRA基准上具有竞争力的准确性和效率/Competitive Accuracy & Efficiency on LRA]
    ```

- **[arXiv260105] Deep Delta Learning**
  - **tags:** [ai], [neural network architecture], [residual networks, geometric transformation, spectral analysis, rank-1 perturbation, dynamic gating]
  - **authors:** Yifan Zhang, Yifeng Liu, Mengdi Wang, Quanquan Gu
  - **institution:** Princeton University, University of California, Los Angeles
  - **link:** https://arxiv.org/pdf/2601.00417
  - **code:** https://github.com/yifanzhang-pro/deep-delta-learning
  - **contributions:** 1. Introduces Deep Delta Learning (DDL), a novel architecture that generalizes residual connections with a learnable, data-dependent geometric transformation called the Delta Operator. 2. Provides a spectral analysis of the Delta Operator, showing it can dynamically interpolate between identity mapping, orthogonal projection, and geometric reflection via a gating scalar. 3. Restructures the residual update as a synchronous rank-1 injection, unifying feature erasure and writing under a dynamic step size to enable complex, non-monotonic dynamics while preserving stable training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e9151cd8b5ec94dcb21276489c4319c73f4c1a7295a6715a6c2a36d36f9a9b_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies that the strictly additive inductive bias of standard residual networks limits their capacity to model complex state transitions. To address this, it proposes Deep Delta Learning (DDL), which modulates the identity shortcut with a learnable, data-dependent geometric transformation (the Delta Operator). This allows the network to explicitly control its layer-wise transition spectrum, enabling the modeling of complex dynamics like oscillations while maintaining stable training.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deep Delta Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[残差网络限制/ResNet Limitation]
        B1 --> B2["刚性相加偏置/Rigid Additive Bias"]
        B2 --> B3["限制复杂状态转换/Limits Complex State Transitions"]
        C --> C1[Delta 算子/Delta Operator]
        C1 --> C2["秩-1扰动/ Rank-1 Perturbation"]
        C2 --> C3["可学习几何变换/Learnable Geometric Transform"]
        C3 --> C4["动态门控/Dynamic Gating (β)"]
        D --> D1["谱分析/Spectral Analysis"]
        D1 --> D2["插值身份/投影/反射/Interpolates Identity/Projection/Reflection"]
        D --> D3["同步秩-1注入/Synchronous Rank-1 Injection"]
        D3 --> D4["控制转换谱/Controls Transition Spectrum"]
        D4 --> D5["保持稳定训练/Preserves Stable Training"]
    ```

- **[arXiv260105] E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models**
  - **tags:** [ai], [reinforcement learning for human feedback], [reinforcement learning from human feedback (RLHF), flow matching, stochastic differential equations (SDE), group relative policy optimization (GRPO), entropy-aware sampling]
  - **authors:** Shengjun Zhang, Zhang Zhang, Chensheng Dai, Yueqi Duan
  - **institution:** Tsinghua University
  - **link:** https://arxiv.org/pdf/2601.00423
  - **code:** https://github.com/shengjun-zhang/VisualGRPO
  - **contributions:** 1. Identified that high-entropy denoising steps are crucial for effective exploration in RL for flow models, while low-entropy steps lead to ambiguous rewards. 2. Proposed E-GRPO, an entropy-aware method that consolidates consecutive low-entropy steps into a single high-entropy step for SDE sampling and uses ODE sampling elsewhere. 3. Introduced a multi-step group normalized advantage calculation that computes advantages relative to samples sharing the same consolidated SDE step.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/517610c9d7d0b5f72ab6ea2e2c36dda14fb3879dc1ff5c4a8ae66c97dd3a6457_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of sparse and ambiguous reward signals when applying reinforcement learning to flow models over multiple denoising steps. It proposes E-GRPO, an entropy-aware method that strategically uses SDE sampling on high-entropy steps and ODE sampling on others, along with a group-relative advantage calculation. Experiments show this approach is more effective for aligning flow models with human preferences.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[E-GRPO: High Entropy Steps Drive Effective RL for Flow Models] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[现有方法在多个去噪步上优化，奖励信号稀疏模糊/Existing methods suffer from sparse & ambiguous rewards over multiple steps]
        C --> C1[提出E-GRPO: 熵感知分组相对策略优化/Propose E-GRPO: Entropy-aware Group Relative Policy Optimization]
        C1 --> C2[合并低熵步为高熵SDE采样步，其他步用ODE采样/Merge low-entropy steps for SDE, use ODE elsewhere]
        C1 --> C3[引入多步分组归一化优势计算/Introduce multi-step group normalized advantage]
        D --> D1[在不同奖励设置下验证了方法的有效性/Method effectiveness demonstrated across different reward settings]
    ```

- **[arXiv260105] A Comparative Analysis of Interpretable Machine Learning Methods**
  - **tags:** [ai], [interpretable machine learning], [Explainable Boosting Machines (EBMs), Symbolic Regression (SR), Generalized Optimal Sparse Decision Trees (GOSDT), Interpretable Generalized Additive Neural Networks (IGANNs), tabular data]
  - **authors:** Mattia Billa, Giovanni Orlandi, Veronica Guidetti, Federica Mandreoli
  - **institution:** University of Modena and Reggio Emilia
  - **link:** https://arxiv.org/pdf/2601.00428
  - **contributions:** 1. Conducted a large-scale comparative evaluation of 16 inherently interpretable methods across 216 real-world tabular datasets. 2. Stratified performance analysis based on structural dataset characteristics (dimensionality, sample size, linearity, class imbalance) and assessed training time and robustness under distributional shifts. 3. Provided empirical findings on performance hierarchies and context-dependent model suitability, offering practical guidance for balancing interpretability and predictive performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b45f5348139a7a9be289787000b2099d616e153113ae1190dc4749f573df65bb_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the scarcity of systematic evaluations for inherently interpretable machine learning models on tabular data by conducting a large-scale benchmark of 16 methods. The study analyzes performance across 216 datasets, considering structural characteristics and robustness. The results show that EBMs are strong for regression, while SR and IGANNs excel in non-linear settings, and GOSDT is sensitive to class imbalance, providing context-dependent guidance for practitioners.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Comparative Analysis of Interpretable Machine Learning Methods<br/>可解释机器学习方法比较分析] --> B[Problem: Need for systematic evaluation of inherently interpretable models for tabular data<br/>问题: 缺乏对表格数据固有可解释模型的系统评估]
        A --> C[Method: Large-scale benchmark of 16 interpretable methods across 216 datasets, stratified by data characteristics<br/>方法: 在216个数据集上对16种方法进行大规模基准测试，按数据特征分层]
        A --> D[Results: EBMs strong for regression; SR/IGANNs good for non-linear data; GOSDT sensitive to imbalance<br/>结果: EBMs在回归中表现好；SR/IGANNs在非线性数据中表现好；GOSDT对不平衡敏感]
    ```

- **[arXiv260105] A Comparative Study of Adaptation Strategies for Time Series Foundation Models in Anomaly Detection**
  - **tags:** [ai], [time series anomaly detection], [time series foundation models, parameter-efficient fine-tuning, anomaly detection, LoRA, AUC-PR]
  - **authors:** Miseon Park, Kijung Yoon
  - **institution:** Hanyang University
  - **link:** https://arxiv.org/pdf/2601.00446
  - **contributions:** 1. Systematically evaluated the use of Time Series Foundation Models (TSFMs) as universal backbones for anomaly detection, showing they outperform task-specific models. 2. Compared multiple adaptation strategies (zero-shot, full fine-tuning, PEFT) for TSFMs across benchmarks, highlighting their versatility. 3. Demonstrated that Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA can match or exceed full fine-tuning performance while being computationally cheaper.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94e39b065d01be71b9920224b4a74b3db8c40a04646e3c3b4b83dce81d7aa0c3_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether pretrained Time Series Foundation Models (TSFMs) can be effectively adapted for anomaly detection. It compares different adaptation strategies, including zero-shot inference and parameter-efficient fine-tuning (PEFT). The results show that TSFMs, especially when adapted with PEFT methods like LoRA, outperform traditional task-specific models, offering a scalable and efficient solution for time series anomaly detection.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Comparative Study of Adaptation Strategies for Time Series Foundation Models in Anomaly Detection<br>时间序列基础模型在异常检测中适应策略的比较研究"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Most anomaly detection methods need extensive task-specific training.<br>大多数异常检测方法需要大量特定任务的训练。"]
        Method["主要方法/Method<br>Adapt TSFMs using zero-shot, full fine-tuning, and PEFT (e.g., LoRA).<br>使用零样本、全微调和PEFT（如LoRA）来适应TSFMs。"]
        Results["关键结果/Results<br>TSFMs outperform baselines; PEFT is efficient and effective.<br>TSFMs超越基线；PEFT高效且有效。"]
    ```

- **[arXiv260105] Controllable Concept Bottleneck Models**
  - **tags:** [ai], [explainable ai], [Concept Bottleneck Models, Model Editing, Influence Functions, Machine Unlearning, Incremental Learning]
  - **authors:** Hongbin Lin, Chenyang Ren, Juangui Xu, Zhengyu Hu, Cheng-Long Wang, Yao Shu, Hui Xiong, Jingfeng Zhang, Di Wang, Lijie Hu
  - **institution:** Based on the author list and affiliations (Hui Xiong, Fellow, IEEE), the primary institution is likely Rutgers University. Other affiliations may be present but are not explicitly listed in the provided content.
  - **link:** https://arxiv.org/pdf/2601.00451
  - **contributions:** 1. Proposes Controllable Concept Bottleneck Models (CCBMs) that support three granularities of model editing (concept-label, concept, and data-level) for dynamic maintenance. 2. Derives mathematically rigorous closed-form approximations for editing operations using influence functions, eliminating the need for retraining from scratch. 3. Demonstrates the efficiency and adaptability of CCBMs through experiments, validating their practical value for creating dynamic and trustworthy models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8610f217ce88f4c2d5513fec62b4fe3c5b8a65762f2a3fae9fcf60d3e539a686_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of efficiently editing Concept Bottleneck Models (CBMs) in dynamic real-world scenarios without retraining. It proposes Controllable Concept Bottleneck Models (CCBMs), which use influence functions to provide closed-form approximations for edits at concept-label, concept, and data levels. Experimental results show that CCBMs are efficient and adaptable, making them practical for maintaining trustworthy AI systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Controllable Concept Bottleneck Models] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[静态CBM难以动态编辑/Static CBMs are hard to edit dynamically]
        C --> C1[CCBM与影响函数/CCBMs with Influence Functions]
        D --> D1[高效且适应性强/Efficient and Adaptable]
    ```

- **[arXiv260105] Imitation from Observations with Trajectory-Level Generative Embeddings**
  - **tags:** [ai], [imitation learning], [imitation learning from observations, offline learning, diffusion models, trajectory embedding, surrogate reward]
  - **authors:** Yongtao Qu, Shangzhe Li, Weitong Zhang
  - **institution:** University of North Carolina at Chapel Hill
  - **link:** https://arxiv.org/pdf/2601.00452
  - **contributions:** 1. Proposes TGE, a trajectory-level generative embedding method for offline imitation learning from observations. 2. Introduces a dense, smooth surrogate reward by estimating expert state density in the latent space of a temporal diffusion model. 3. Demonstrates that the method effectively bridges distributional gaps and outperforms prior methods on D4RL benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8023941a359742c0280304bc5c6d6f3a9e7332f5f298e3867930992f450af6fb_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses offline imitation learning from observations where expert data is scarce and offline data is suboptimal. It proposes TGE, a method that uses a temporal diffusion model to create a smooth trajectory embedding for robust reward estimation. The approach outperforms existing methods on standard locomotion and manipulation benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Imitation from Observations with Trajectory-Level Generative Embeddings] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[离线模仿学习，专家数据稀缺，离线数据不理想/Offline LfO, scarce expert data, imperfect offline data]
        C --> C1[提出TGE，利用扩散模型嵌入构建平滑的轨迹级奖励/Propose TGE, constructs smooth trajectory-level reward via diffusion embedding]
        D --> D1[在D4RL基准上匹配或超越现有方法/Matches or outperforms prior methods on D4RL benchmarks]
    ```

- **[arXiv260105] Deep Networks Learn Deep Hierarchical Models**
  - **tags:** [ai], [theoretical machine learning], [hierarchical models, residual networks, layerwise SGD, efficient learnability, teacher-student framework]
  - **authors:** Amit Daniely
  - **institution:** Hebrew University of Jerusalem, Google Research Tel Aviv
  - **link:** https://arxiv.org/pdf/2601.00455
  - **contributions:** 1. Proves that layerwise SGD on residual networks can efficiently learn a class of hierarchical models with polynomial depth, surpassing previous learnable models limited to log-depth. 2. Introduces a formal model where the existence of human teachers, providing granular labels, naturally reveals a hierarchical structure that facilitates learning. 3. Suggests that the learnability of deep hierarchical models could form a theoretical basis for understanding why deep learning works.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1faa5ee1ce6f2d929632472a3fef6f2a37f968b78b881ef42a244f56de38679_w640_q70.webp
  - **Simple LLM Summary:** The paper shows that layerwise stochastic gradient descent (SGD) on residual networks can efficiently learn a class of hierarchical models where labels are structured in increasingly complex levels. This class is more expressive, requiring polynomial depth, than previously known learnable models. The authors argue that this learnability, supported by a formal model of teaching, provides a potential theoretical foundation for understanding deep learning's success.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Deep Networks Learn Deep Hierarchical Models] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[理解深度网络为何有效/Understanding why deep networks work]
    C --> C1[层级SGD与残差网络/Layerwise SGD on ResNets]
    C --> C2[形式化教师-学生模型/Formal teacher-student model]
    D --> D1[可高效学习多项式深度模型/Efficiently learn polynomial-depth models]
    D --> D2[超越对数深度电路/Surpasses log-depth circuits]
    D --> D3[为理解深度学习提供基础/Provides basis for understanding deep learning]
    ```

- **[arXiv260105] Laplacian Kernelized Bandit**
  - **tags:** [ai], [multi-armed bandits], [graph Laplacian, reproducing kernel Hilbert space (RKHS), Gaussian process, regret bound, multi-user contextual bandits]
  - **authors:** Shuang Wu, Arash A. Amini
  - **institution:** University of California, Los Angeles (UCLA)
  - **link:** https://arxiv.org/pdf/2601.00461
  - **contributions:** 1. Introduced a principled joint penalty combining graph smoothness and individual roughness, proving it is equivalent to the squared norm in a unified multi-user RKHS. 2. Explicitly derived the reproducing kernel for this RKHS, which fuses the graph Laplacian with a base arm kernel. 3. Designed two algorithms (LK-GP-UCB and LK-GP-TS) based on this kernel and provided theoretical regret bounds scaling with the kernel's effective dimension.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4eb4360cdf936fab9711bd6722ad2b67b34b282bf409e4e900beb17c23a0b2_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses multi-user contextual bandits where users are connected by a graph and have non-linear reward functions. It proposes a new kernel that combines graph structure with arm features, enabling the design of efficient Gaussian Process-based algorithms for exploration. The method provides strong theoretical regret guarantees and outperforms baselines in non-linear settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Laplacian Kernelized Bandit] --> B[核心问题/Problem: Multi-user contextual bandits with graph homophily and non-linear rewards]
        A --> C[主要方法/Method: Unified multi-user RKHS with Laplacian-fused kernel; Algorithms LK-GP-UCB & LK-GP-TS]
        A --> D[关键结果/Results: Regret bounds scale with effective kernel dimension; Outperforms baselines empirically]
    ```

- **[arXiv260105] Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations**
  - **tags:** [mlsys], [llm training], [Mixture-of-Experts, Orthogonality Regularization, Weight-Activation Gap, Sparse Activation, Expert Diversity]
  - **authors:** Hyunjun Kim
  - **institution:** Korea Advanced Institute of Science and Technology (KAIST)
  - **link:** https://arxiv.org/pdf/2601.00457
  - **contributions:** 1. Showed that orthogonality regularization fails to reduce weight-space overlap and yields inconsistent effects on model performance across different datasets. 2. Identified a significant disconnect between weight-space and activation-space orthogonality, with no significant correlation between the two. 3. Demonstrated that weight-space regularization is an unreliable optimization target for improving expert diversity in MoE models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/297630182c2a41472ac5ae250b1200161c3b50705c9ba5130f166dda38b1a979_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the effectiveness of applying orthogonality loss to enforce expert diversity in Mixture-of-Experts (MoE) models. The analysis reveals that this geometric regularization fails to reduce weight-space overlap, does not translate to activation-space orthogonality, and leads to inconsistent performance changes. The findings demonstrate that weight-space regularization is unsuitable for achieving MoE diversity.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Geometric Regularization in MoEs: The Disconnect Between Weights and Activations] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1(专家多样性的几何正则化作用不明确/The role of geometric regularization in expert specialization is unclear)
        C --> C1(应用正交性损失以强制专家多样性/Apply orthogonality loss to enforce expert diversity)
        D --> D1(权重空间重叠未减少/Weight-space overlap not reduced)
        D --> D2(激活空间重叠保持高位/Activation-space overlap remains high)
        D --> D3(性能影响不一致/Inconsistent effects on performance)
        D --> D4(权重与激活正交性无显著相关/No significant correlation between weight and activation orthogonality)
    ```

- **[arXiv260105] Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet**
  - **tags:** [ai], [biomedical signal processing], [EEG, UNet, data augmentation, spike wave discharges, seizure detection]
  - **authors:** Saurav Sengupta, Scott Kilianski, Suchetha Sharma, Sakina Lashkeri, Ashley McHugh, Mark Beenhakker, Donald E. Brown
  - **institution:** University of Virginia
  - **link:** https://arxiv.org/pdf/2601.00459
  - **contributions:** 1. Comprehensive comparison of 14 machine learning classifiers on a large, manually annotated EEG dataset for SWD detection, identifying a 1D UNet as the best performer. 2. Enhancement of the 1D UNet model through data augmentation, with scaling identified as the most beneficial augmentation technique, resulting in the AugUNet1D model. 3. Public release of the AugUNet1D model (both pretrained and untrained) and demonstration of its superior performance against a state-of-the-art algorithmic method ("Twin Peaks").
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/284cd89a49b52c6de51bc92974e7ebd74725aa53109914c27ce628c85db7b46c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the time-consuming manual labeling of spike wave discharges (SWDs) in EEG recordings by proposing an automated detection method. The authors developed and evaluated a 1D UNet model enhanced with data augmentation (AugUNet1D) on a large mouse EEG dataset, finding it outperformed other classifiers and a recent algorithmic approach. The main conclusion is that AugUNet1D provides a superior, publicly available tool for accurate SWD detection.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Detecting SWD using 1D Residual UNet<br/>使用一维残差UNet检测SWD] --> B
        A --> C
        A --> D
        B[Problem: Manual EEG labeling is time-consuming<br/>问题: 手动标记EEG耗时] --> B1[Target: Automate SWD detection<br/>目标: 自动化SWD检测]
        C[Method: 1D UNet with data augmentation (AugUNet1D)<br/>方法: 使用数据增强的一维UNet] --> C1[Compared 14 classifiers<br/>比较了14种分类器]
        D[Results: AugUNet1D outperforms other methods<br/>结果: AugUNet1D性能最优] --> D1[Model made public<br/>模型已公开]
    ```

- **[arXiv260105] Neural Chains and Discrete Dynamical Systems**
  - **tags:** [ai], [scientific machine learning], [neural chains, physics-informed neural networks (PINNs), finite-difference methods, Burgers equation, Eikonal equation]
  - **authors:** Sauro Succi, Abhisek Ganguly, Santosh Ansumali
  - **institution:** Italian Institute of Technology, Jawaharlal Nehru Centre for Advanced Scientific Research (JNCASR), University of Roma Tre, Harvard University, Cornell University
  - **link:** https://arxiv.org/pdf/2601.00473
  - **contributions:** 1. Proposes and analyzes the analogy between transformer-based neural chains (without self-attention) and discrete dynamical systems from discretized neural integral/PDEs. 2. Conducts a comparative analysis between standard numerical discretization (finite-difference) and PINN learning for solving Burgers and Eikonal equations, showing they converge to similar dynamical knowledge. 3. Identifies that PINNs explore a vast space of random matrices, unlike the structured matrices of finite-difference methods, leading to more parameters, higher training costs, and reduced explainability for 1D problems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/484d1f1718d109a31c34806ec956587c6c88440887cfe665bb5795e2c2cad940_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the connection between neural chains (transformers without self-attention) and discrete dynamical systems. It compares solving PDEs like Burgers and Eikonal equations using standard finite-difference methods versus Physics-Informed Neural Networks (PINNs), finding both methods yield similar solutions but PINNs use many more random, less interpretable parameters. The authors conclude that for these 1D problems, PINNs offer no efficiency advantage over traditional methods, though their potential for high-dimensional problems remains open.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Neural Chains and Discrete Dynamical Systems] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[分析神经链与离散动力系统的类比/Analyze analogy between neural chains and discrete dynamical systems]
        B --> B2[比较PINN与传统数值方法/Compare PINNs vs. traditional numerical methods]
        C --> C1[将数值离散化表述为神经链/Cast numerical discretization as neural chains]
        C --> C2[使用PINN求解方程/Use PINNs to solve equations]
        C --> C3[比较矩阵结构与参数空间/Compare matrix structure and parameter space]
        D --> D1[两种方法获得相同动力学知识/Both methods acquire same dynamical knowledge]
        D --> D2[PINN使用更多随机参数/PINNs use more random parameters]
        D --> D3[1D问题中PINN无效率优势/No PINN efficiency advantage for 1D problems]
    ```

- **[arXiv260105] Noise-Aware Named Entity Recognition for Historical VET Documents**
  - **tags:** [nlp], [named entity recognition], [Noise-Aware Training (NAT), OCR Noise, Data Augmentation, Transfer Learning, Multi-stage Fine-tuning]
  - **authors:** Alexander M. Esser, Jens Dörpinghaus
  - **institution:** Federal Institute for Vocational Education and Training (BIBB), University of Koblenz
  - **link:** https://arxiv.org/pdf/2601.00488
  - **contributions:** 1. Proposes a robust NER approach for historical VET documents using Noise-Aware Training with synthetic OCR errors. 2. Systematically compares three complementary training strategies (noisy, clean, and artificial data). 3. Demonstrates that domain-specific and noise-aware fine-tuning significantly improves robustness and accuracy under noisy conditions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb3e9604f5f72e56feeecdc196004299094bc184a404fe77959f2a61d9e4da2_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles Named Entity Recognition in noisy, historical Vocational Education and Training documents by proposing a method using Noise-Aware Training with synthetic OCR errors, transfer learning, and multi-stage fine-tuning. The approach, one of the first to recognize multiple entity types in this domain, shows that domain-specific and noise-aware fine-tuning substantially increases model robustness and accuracy. The method is applied to German but is designed to be transferable to other languages.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Noise-Aware NER for Historical VET Documents] --> Problem(核心问题/Problem: NER in noisy historical VET documents)
        Root --> Method(主要方法/Method: Noise-Aware Training with synthetic OCR errors, transfer learning, multi-stage fine-tuning)
        Root --> Results(关键结果/Results: Increased robustness and accuracy under noisy conditions)
    ```

- **[arXiv260105] Improving LLM-Assisted Secure Code Generation through Retrieval-Augmented-Generation and Multi-Tool Feedback**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [Retrieval-Augmented Generation, CodeQL, KLEE, Self-Repair, Symbolic Execution]
  - **authors:** Vidyut Sriram, Sawan Pandita, Achintya Lakshmanan, Aneesh Shamraj, Suman Saha
  - **institution:** Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2601.00509
  - **contributions:** 1. Proposes a retrieval-augmented, multi-tool repair workflow integrating compiler diagnostics, CodeQL security scanning, and KLEE symbolic execution for iterative LLM self-repair. 2. Utilizes a lightweight embedding model for semantic retrieval of security-focused repair examples to guide code generation. 3. Demonstrates significant robustness improvements, reducing security vulnerabilities by up to 96% for DeepSeek-Coder and from 58.55% to 22.19% for CodeLlama.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cdcdc91c311cf046454507445fa7f6baef39a437738ec8e32b2eb087f6fbfa91_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of LLM-generated code containing security vulnerabilities and errors. It proposes a method where a code-generating LLM iteratively refines its output using feedback from multiple tools (compiler, CodeQL, KLEE) and retrieval of past successful repairs. The results show this approach significantly reduces security defects, even for larger, more stubborn models.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Improving LLM-Assisted Secure Code Generation<br>提升LLM辅助安全代码生成"] --> Problem["LLM生成代码存在安全漏洞<br>LLM-generated code has security vulnerabilities"]
        Root --> Method["检索增强的多工具自修复工作流<br>Retrieval-Augmented Multi-Tool Self-Repair Workflow"]
        Root --> Results["安全漏洞显著减少<br>Security vulnerabilities significantly reduced"]
        Problem --> P1["逻辑不一致<br>Logical inconsistencies"]
        Problem --> P2["编译错误<br>Compilation errors"]
        Method --> M1["检索修复示例<br>Retrieve repair examples"]
        Method --> M2["工具反馈(编译器/CodeQL/KLEE)<br>Tool feedback (Compiler/CodeQL/KLEE)"]
        Method --> M3["迭代自修复<br>Iterative self-repair"]
        Results --> R1["DeepSeek漏洞减少96%<br>DeepSeek vulnerabilities reduced 96%"]
        Results --> R2["CodeLlama关键缺陷率22.19%<br>CodeLlama critical defect rate 22.19%"]
    ```

- **[arXiv260105] When Small Models Are Right for Wrong Reasons: Process Verification for Trustworthy Agents**
  - **tags:** [mlsys], [agent system], [reasoning integrity, retrieval-augmented generation, process verification, small language models, neural classifier]
  - **authors:** Laksh Advani
  - **institution:** Independent Researcher (affiliation inferred from email domain: University of Colorado Boulder)
  - **link:** https://arxiv.org/pdf/2601.00513
  - **contributions:**  1. Introduces the "Right-for-Wrong-Reasons" (RWR) phenomenon and the Reasoning Integrity Score (RIS), a novel process-based metric for evaluating the trustworthiness of small language model agents, validated with high inter-rater agreement. 2. Empirically demonstrates that while retrieval-augmented generation (RAG) significantly improves reasoning integrity, meta-cognitive interventions like self-critique often degrade it in small models, providing mechanistic explanations for these effects. 3. Distills the verification capability into a lightweight neural classifier that achieves high performance (0.86 F1-score) and efficiency (100x speedup), enabling practical process-based verification for deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05b874fd2b8e4599623bc1f3efd5491de7179346cb166566b9907ab13137ae7a_w640_q70.webp
  - **Simple LLM Summary:** This paper identifies a critical reliability problem where small language models (7-9B parameters) often produce correct answers based on flawed reasoning, a phenomenon invisible to standard accuracy metrics. To address this, the authors introduce a process-based evaluation metric (RIS) and analyze the impact of interventions like RAG and self-critique, finding RAG improves reasoning while self-critique harms it in small models. They conclude that process verification is essential for trustworthy agents and demonstrate a fast neural classifier for this purpose.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[When Small Models Are Right for Wrong Reasons<br>当小模型因错误原因而正确时] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Small models give correct answers with flawed reasoning<br>小模型基于错误推理给出正确答案]
        C[主要方法/Method<br>Introduce Reasoning Integrity Score (RIS)<br>引入推理完整性评分]
        D[关键结果/Results<br>RAG helps, self-critique hurts; Neural verifier is fast<br>RAG有效，自我批判有害；神经验证器速度快]
    ```

- **[arXiv260105] Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI**
  - **tags:** [mlsys], [agent system], [Siamese Recurrent Autoencoder, hybrid loss, real-time anomaly detection]
  - **authors:** Laksh Advani
  - **institution:** Independent Researcher (affiliation inferred from email domain: University of Colorado Boulder)
  - **link:** https://arxiv.org/pdf/2601.00516
  - **contributions:** 1. Demonstrated the ineffectiveness of standard anomaly detection methods for agent trajectory validation, establishing the need for specialized models. 2. Proposed a novel, sequence-aware Siamese Recurrent Autoencoder with a hybrid loss function for real-time trajectory anomaly detection. 3. Demonstrated that the approach is over 17x faster than LLM Judge baselines, making it suitable for real-time deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de97af87ef40e2bb7fa3067f0d8a7f8e2dc7d8fd40b77747e64af793669009c2_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of detecting anomalous action plans in autonomous LLM agents, where existing methods fail to capture sequential structure and context. It proposes Trajectory Guard, a Siamese Recurrent Autoencoder with a hybrid loss combining contrastive learning and reconstruction for unified anomaly detection. The method achieves high F1-scores (0.88-0.94) and significantly faster inference (32 ms) than LLM-based baselines, enabling real-time safety verification.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Trajectory Guard] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[现有方法不适用/Existing methods ill-suited]
        Problem --> P2[需要序列感知/Need for sequence-awareness]
        Method --> M1[孪生循环自编码器/Siamese Recurrent Autoencoder]
        Method --> M2[混合损失函数/Hybrid Loss Function]
        M2 --> M2a[对比学习/Contrastive Learning]
        M2 --> M2b[重建/Reconstruction]
        Results --> R1[高F1分数/High F1-scores (0.88-0.94)]
        Results --> R2[低延迟/32 ms latency]
        Results --> R3[实时部署/Real-time deployment]
    ```

- **[arXiv260105] Optimizing LSTM Neural Networks for Resource-Constrained Retail Sales Forecasting: A Model Compression Study**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [LSTM compression, model efficiency, retail forecasting, edge computing, hidden units]
  - **authors:** Ravi Teja Pagidoju
  - **institution:** Campbellsville University
  - **link:** https://arxiv.org/pdf/2601.00525
  - **code:** https://github.com/RaviTeja444/sales-forecast-LSTM
  - **contributions:** 1. Systematic evaluation of LSTM network sizes from 16 to 128 hidden units on real retail data. 2. Discovery that moderate compression (to 64 units) actually improves forecast accuracy. 3. Practical guidelines for model selection based on the accuracy-efficiency trade-off.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bda8da07103a6f89178a84bdce230c27d6cea8328b8c1fcb749e7912c516181_w640_q70.webp
  - **Simple LLM Summary:** This paper studies LSTM model compression for resource-constrained retail sales forecasting by reducing the number of hidden units. The method involves systematically pruning the LSTM from 128 to 16 hidden units. The main conclusion is that reducing the model to 64 units not only makes it 73% smaller but also improves accuracy by 47%, showing larger models are not always better.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Optimizing LSTM for Resource-Constrained Retail Forecasting] --> B(核心问题/Problem: LSTM模型计算需求大，中小型零售商难以部署/LSTM models are computationally expensive for mid-to-small retailers)
        A --> C(主要方法/Method: 通过逐步减少隐藏单元进行模型压缩/Model compression by reducing hidden units from 128 to 16)
        A --> D(关键结果/Results: 64单元模型更小(76KB vs 280KB)且更准确(MAPE 12.4% vs 23.6%)/64-unit model is smaller and more accurate)
    ```

- **[arXiv260105] A Sparse-Attention Deep Learning Model Integrating Heterogeneous Multimodal Features for Parkinson's Disease Severity Profiling**
  - **tags:** [ai], [multimodal learning], [sparse-attention, cross-attention, class-balanced focal loss, multimodal fusion, explainable AI]
  - **authors:** Dristi Datta, Tanmoy Debnath, Minh Chau, Manoranjan Paul, Gourab Adhikary, Md Geaur Rahman
  - **institution:** Charles Sturt University
  - **link:** https://arxiv.org/pdf/2601.00519
  - **contributions:** 1. Proposed the Class-Weighted Sparse-Attention Fusion Network (SAFN), an interpretable deep learning framework for multimodal Parkinson's disease profiling. 2. Introduced a sparsity-constrained attention-gating fusion layer to dynamically prioritize informative modalities from heterogeneous data (MRI, clinical, demographic). 3. Employed a Class-Balanced Focal Loss to effectively handle dataset imbalance without synthetic oversampling, achieving high performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2a0104d1bebca16cde5f74be8dbe6bfbcfb976784343fbe1f1f8025e57eed10_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes SAFN, an interpretable deep learning model that integrates MRI and clinical data using sparse-attention and cross-attention mechanisms for Parkinson's disease severity profiling. It addresses challenges in multimodal fusion and class imbalance. The model achieves high accuracy and interpretability, aligning clinical assessment importance with diagnostic principles.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[SAFN: Parkinson's Disease Severity Profiling<br/>SAFN: 帕金森病严重程度分析] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br/>Multimodal fusion, interpretability, class imbalance<br/>多模态融合、可解释性、类别不平衡] --> P1[挑战/Challenges<br/>Integrate imaging & clinical data<br/>整合影像与临床数据]
        Problem --> P2[目标/Goal<br/>Robust & interpretable PD profiling<br/>鲁棒且可解释的PD分析]
        Method[主要方法/Method<br/>Class-Weighted Sparse-Attention Fusion Network<br/>类别加权稀疏注意力融合网络] --> M1[技术/Techniques<br/>Modality-specific encoders, symmetric cross-attention<br/>模态特定编码器、对称交叉注意力]
        Method --> M2[创新/Innovations<br/>Sparsity-constrained attention gating, Class-Balanced Focal Loss<br/>稀疏约束注意力门控、类别平衡焦点损失]
        Results[关键结果/Results<br/>Evaluation on PPMI dataset<br/>在PPMI数据集上的评估] --> R1[性能/Performance<br/>Accuracy: 0.98±0.02, PR-AUC: 1.00±0.00<br/>准确率: 0.98±0.02, PR-AUC: 1.00±0.00]
        Results --> R2[可解释性/Interpretability<br/>~60% weight to clinical assessments<br/>~60%权重分配给临床评估]
    ```

- **[arXiv260105] Federated Customization of Large Models: Approaches, Experiments, and Insights**
  - **tags:** [mlsys], [federated learning], [federated learning, prefix-tuning, large model customization, efficient fine-tuning, retrieval-augmented generation]
  - **authors:** Yuchuan Ye, Ming Ding, Youjia Chen, Peng Cheng, Dusit Niyato
  - **institution:** Fuzhou University, Data61 CSIRO, La Trobe University, Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2601.00526
  - **contributions:** 1. Provides a comprehensive review of large model customization techniques and discusses their implementation within a federated learning framework. 2. Proposes and experimentally validates federated prefix-tuning, which is the first application of prefix-tuning in a federated learning setting. 3. Demonstrates through comparative experiments that federated prefix-tuning achieves competitive performance, satisfactory efficiency, and consistent robustness compared to other federated customization methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02fea5cfedb112a13fd696a58bea7fb932671198f51d78a63540d7922a373af9_w640_q70.webp
  - **Simple LLM Summary:** This paper explores the federated customization of large models, which aims to adapt pre-trained models for specialized tasks using decentralized, private data. It proposes and validates federated prefix-tuning as a novel method, showing its performance is close to centralized approaches and competitive with other federated techniques. The work provides insights into implementing various customization methods within a federated learning framework to address privacy and data decentralization challenges.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Federated Customization of Large Models: Approaches, Experiments, and Insights] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[在联邦学习框架下定制大模型的挑战/Challenges of customizing large models within FL]
        C --> C1[回顾大模型定制技术/Review LM customization techniques]
        C --> C2[讨论联邦学习实现/Discuss FL implementations]
        C --> C3[实验联邦前缀调优/Experiment with federated prefix-tuning]
        D --> D1[验证联邦前缀调优可行性/Validate feasibility of federated prefix-tuning]
        D --> D2[性能接近集中式方法/Performance close to centralized]
        D --> D3[展示竞争力与鲁棒性/Show competitive performance & robustness]
    ```

- **[arXiv260105] Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization**
  - **tags:** [mlsys], [diffusion models], [diffusion models, cloud-native architecture, edge deployment, constraint satisfaction, planogram generation]
  - **authors:** Ravi Teja Pagidoju, Shriya Agarwal
  - **institution:** Campbellsville University, University of the Cumberlands
  - **link:** https://arxiv.org/pdf/2601.00527
  - **contributions:** 1. A novel cloud-native architecture for automated planogram synthesis using diffusion models, combining AWS for training and edge deployment for real-time inference. 2. A diffusion model that integrates retail-specific constraints through a modified loss function to generate store-specific layouts. 3. A comprehensive simulation-based and economic analysis demonstrating significant reductions in design time (98.3%) and cost (97.5%) with high constraint satisfaction (94.4%) and linear scalability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b868081df5651946090e341fbb8526b8b99531ee775ea4b316dc9682b146e22e_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a cloud-native system using diffusion models to automate the generation of retail planograms. The method learns from successful shelf arrangements across multiple stores and incorporates business constraints into the model. The results show it drastically reduces design time and cost while maintaining high constraint satisfaction, proving the viability of generative AI for retail space optimization.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Cloud-Native Generative AI for Planogram Synthesis] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Manual planogram creation is slow and expensive] --> P1[挑战/Challenge: 30 hours per layout]
        Method[主要方法/Method: Cloud-native diffusion model] --> M1[训练/Training: Cloud-based (AWS)]
        Method --> M2[推理/Inference: Edge deployment]
        Method --> M3[模型/Model: Constraint-integrated diffusion]
        Results[关键结果/Results] --> R1[效率/Efficiency: 98.3% time reduction]
        Results --> R2[效果/Effectiveness: 94.4% constraint satisfaction]
        Results --> R3[经济/Economic: 97.5% cost reduction]
        Results --> R4[可扩展性/Scalability: Linear scaling to 10k stores]
    ```

- **[arXiv260105] Entropy Production in Machine Learning Under Fokker-Planck Probability Flow**
  - **tags:** [mlsys], [others], [Fokker-Planck equation, Kullback-Leibler divergence, entropy production, data drift, retraining trigger]
  - **authors:** Lennon Shikhman
  - **institution:** Florida Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.00554
  - **contributions:** 1. Proposes a novel entropy-based retraining framework for machine learning models grounded in nonequilibrium statistical physics, modeling data drift as probability flow governed by a Fokker-Planck equation. 2. Derives a dynamical interpretation of model-data mismatch by showing its time derivative decomposes into an entropy-balance equation featuring a nonnegative entropy production term. 3. Introduces and validates an entropy-triggered retraining strategy that maintains high predictive performance while significantly reducing retraining frequency compared to daily or label-based policies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a53bb0b8d5d5942ee17365e19e7b865b31c2701e9fcbcde1a5d6b9dc2ccc5b0e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses performance degradation in ML models due to data drift in nonstationary environments. It proposes a principled retraining framework based on nonequilibrium dynamics, using a Fokker-Planck model of drift and an entropy-production trigger. The method achieves performance comparable to frequent retraining while drastically reducing the number of retraining events.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Entropy Production in Machine Learning Under Fokker-Planck Probability Flow") --> Problem("核心问题/Problem: Model performance degrades due to data drift in nonstationary environments.")
        Root --> Method("主要方法/Method: Entropy-based retraining framework using Fokker-Planck dynamics and KL divergence.")
        Root --> Results("关键结果/Results: Achieves high performance with order-of-magnitude fewer retraining events.")
    ```

- **[arXiv260105] Adversarial Samples Are Not Created Equal**
  - **tags:** [ai], [adversarial robustness], [adversarial samples, non-robust features, adversarial bugs, ensemble-based metric, sharpness-aware minimization]
  - **authors:** Jennifer Crawford, Amol Khanna, Fred Lu, Amy R. Wagoner, Stella Biderman, Andre T. Nguyen, Edward Raff
  - **institution:** Scale AI, CrowdStrike, Booz Allen Hamilton, EleutherAI
  - **link:** https://arxiv.org/pdf/2601.00577
  - **contributions:** 1. Proposes an ensemble-based metric to measure the manipulation of non-robust features by adversarial perturbations. 2. Introduces the concept of "adversarial bugs" to differentiate adversarial samples that do not rely on non-robust features. 3. Uses this new perspective to re-examine phenomena like the impact of sharpness-aware minimization and the robustness gap in adversarially trained models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e880259ebf04545c0ce64ed1e802b2caa6a3b401669986a52d0c3ccb0f063371_w640_q70.webp
  - **Simple LLM Summary:** The paper argues that not all adversarial samples are created equal, differentiating between those that exploit brittle "non-robust" features and those that do not ("adversarial bugs"). It proposes an ensemble-based metric to identify this distinction and uses it to analyze adversarial attacks, offering a new lens to re-examine existing robustness phenomena.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Adversarial Samples Are Not Created Equal<br>对抗性样本并非生而平等") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("现有理论无法解释所有对抗样本<br>Existing theory doesn't explain all adversarial samples")
        Method --> M1("提出基于集成的度量<br>Propose ensemble-based metric")
        Method --> M2("区分'对抗性漏洞'<br>Differentiate 'adversarial bugs'")
        Results --> R1("重新审视鲁棒性现象<br>Re-examine robustness phenomena")
    ```

- **[arXiv260105] Learning to be Reproducible: Custom Loss Design for Robust Neural Networks**
  - **tags:** [ai], [training stability & reproducibility], [custom loss function, training robustness, reproducibility, stochastic factors, weight initialization]
  - **authors:** Waqas Ahmed, Sheeba Samuel, Kevin Coakley, Birgitta Koenig-Ries, Odd Erik Gundersen
  - **institution:** Friedrich Schiller University Jena, University of Technology Chemnitz, Norwegian University of Science and Technology
  - **link:** https://arxiv.org/pdf/2601.00578
  - **contributions:** 1. Identifies and empirically analyzes the critical gap in ensuring consistent performance across training runs due to stochastic factors like weight initialization and data shuffling. 2. Proposes a novel Custom Loss Function (CLF) designed to explicitly balance predictive accuracy with training stability, reducing sensitivity to these stochastic factors. 3. Demonstrates through extensive experiments on diverse architectures and tasks (image classification, time series forecasting) that CLF significantly improves training robustness without sacrificing predictive performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0accb01febbfd00a3b2c4650b921cc29a716544cb9a8fbc39d5a8ebe82c21bf6_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of inconsistent model performance across training runs due to stochastic factors. It proposes a Custom Loss Function (CLF) to explicitly balance accuracy and stability, which is shown to improve training robustness without harming predictive performance in experiments on image classification and time series forecasting.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Learning to be Reproducible: Custom Loss Design for Robust Neural Networks") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("模型性能不一致/Inconsistent Model Performance")
        Problem --> P2("对随机因素敏感/Sensitive to Stochastic Factors")
        Method --> M1("提出自定义损失函数/Propose Custom Loss Function (CLF)")
        Results --> R1("提高训练鲁棒性/Improves Training Robustness")
        Results --> R2("保持预测性能/Maintains Predictive Performance")
    ```

- **[arXiv260105] HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts**
  - **tags:** [mlsys], [federated learning], [Mixture-of-Experts, federated fine-tuning, resource-aware, expert selection, sparsity-aware aggregation]
  - **authors:** Zihan Fang, Zheng Lin, Senkang Hu, Yanan Ma, Yihang Tao, Yiqin Deng, Xianhao Chen, Yuguang Fang
  - **institution:** City University of Hong Kong, The University of Hong Kong
  - **link:** https://arxiv.org/pdf/2601.00583
  - **contributions:** 1. Introduces a method to identify expert importance based on contributions to fine-tuning performance, enabling informed expert selection. 2. Proposes an adaptive expert subset selection mechanism from an information bottleneck perspective to align with heterogeneous client computing budgets. 3. Designs a sparsity-aware model aggregation strategy that weights updates from actively fine-tuned experts and gating parameters to mitigate destructive interference during global aggregation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a4349d6a95221a61360e261ad370cd60546e55c0ae19bef19bfe4f05de72ff4_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes HFedMoE, a heterogeneous federated learning framework for fine-tuning large language models using Mixture-of-Experts. It addresses challenges in expert selection, resource heterogeneity, and aggregation interference by customizing expert subsets per client and using importance-weighted aggregation. Experiments show HFedMoE outperforms state-of-the-art methods in accuracy and convergence speed.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM联邦微调中MoE面临的挑战/Challenges in MoE for FL fine-tuning]
        B1 --> B2[专家选择困难/Difficulty in expert selection]
        B1 --> B3[客户端资源异构性/Client resource heterogeneity]
        B1 --> B4[聚合干扰/Aggregation interference]
        C --> C1[定制化专家子集/Customized expert subset per client]
        C1 --> C2[基于重要性的专家选择/Importance-based expert selection]
        C1 --> C3[信息瓶颈视角的适配/Adaptation via information bottleneck]
        C --> C4[稀疏感知的模型聚合/Sparsity-aware model aggregation]
        D --> D1[更高的训练精度/Higher training accuracy]
        D --> D2[更快的收敛速度/Faster convergence speed]
    ```

- **[arXiv260105] Cycling Race Time Prediction: A Personalized Machine Learning Approach Using Route Topology and Training Load**
  - **tags:** [ai], [sports analytics], [Lasso regression, training load (CTL/ATL), N-of-1 study, feature engineering, route topology]
  - **authors:** Francisco Aguilera Moreno
  - **institution:** None specified (Inferred from author's email domain: gmail.com)
  - **link:** https://arxiv.org/pdf/2601.00604
  - **contributions:** 1. Proposes a personalized machine learning model for cycling time prediction that uses route topology and athlete fitness state, avoiding complex physics-based parameters. 2. Implements and validates the approach using an N-of-1 study design with rigorous feature engineering to prevent data leakage. 3. Demonstrates that integrating fitness metrics (CTL, ATL) reduces prediction error by 14% compared to using route features alone, highlighting the importance of physiological state.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9697eaafe078b4416e1e63fcfa2f99ad60e0031eff1e90380ad4c7d7042e046_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a personalized machine learning approach to predict cycling race times by combining route topology features with the athlete's training load-derived fitness state. The method, evaluated on a single-athlete dataset, uses Lasso regression and achieves high accuracy (MAE=6.60 min, R²=0.922), showing that fitness metrics significantly improve predictions over topology alone.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Cycling Race Time Prediction] --> Problem[核心问题/Problem<br>Physics-based models are impractical<br>物理模型不实用]
        Root --> Method[主要方法/Method<br>Personalized ML with Route & Fitness<br>个性化ML结合路线与体能]
        Root --> Results[关键结果/Results<br>Fitness reduces error by 14%<br>体能指标降低14%误差]
    ```

- **[arXiv260105] Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [Graph Neural Network, Q-learning, traffic-aware optimization]
  - **authors:** Sonia Khetarpaul, P Y Sharan
  - **institution:** Shiv Nadar Institution of Eminence
  - **link:** https://arxiv.org/pdf/2601.00607
  - **contributions:** 1. Proposes a novel traffic-aware, graph-based reinforcement learning framework for optimal taxi placement that integrates real-time traffic data (e.g., congestion scores) with historical demand patterns. 2. Employs Graph Neural Network (GNN) embeddings to encode spatial-temporal dependencies within the urban road network, enhancing the agent's understanding of network topology and dynamics. 3. Designs a multi-objective reward mechanism that jointly optimizes passenger waiting time, driver travel distance, and congestion avoidance, leading to significant performance improvements over a baseline.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d1b24d654126d64fa77f6ff66cd948e1830612a785483db227d8986e431770d_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of inefficient taxi supply-demand matching in smart cities by proposing a framework that models the urban road network as a graph and uses Graph Neural Networks combined with Q-learning to recommend optimal taxi placement hotspots. The method integrates real-time traffic conditions and historical data to optimize for passenger waiting time and driver travel distance. Experiments on a simulated Delhi dataset show the model reduces passenger waiting time by 56% and travel distance by 38% compared to a stochastic baseline.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Traffic-Aware Optimal Taxi Placement<br>Using Graph Neural Network-Based Reinforcement Learning] --> B(核心问题/Problem: Conventional taxi hotspot models overlook dynamic traffic influences.)
        A --> C(主要方法/Method: Graph-based RL with GNN embeddings for spatial-temporal dependencies.)
        A --> D(关键结果/Results: Reduced passenger waiting time by 56% and travel distance by 38%.)
    ```

- **[arXiv260105] Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization**
  - **tags:** [ai], [submodular optimization], [weakly DR-submodular, continuous-greedy, Frank-Wolfe, approximation algorithm, down-closed convex body]
  - **authors:** Hareshkumar Jadav, Ranveer Singh, Vaneet Aggarwal
  - **institution:** IIT Indore, Purdue University
  - **link:** https://arxiv.org/pdf/2601.00611
  - **contributions:** 1. A novel approximation algorithm for maximizing non-monotone γ-weakly DR-submodular functions over down-closed convex bodies. 2. A smooth approximation guarantee that recovers the 0.401 factor for DR-submodular (γ=1) and degrades gracefully for γ&lt;1, improving upon prior bounds. 3. A hybrid algorithmic framework combining Frank-Wolfe-guided continuous-greedy with a γ-aware double-greedy step to handle non-monotonicity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3fb1d9788f036c8398d4ed9b82b8201cf4616c9a51d4916ebe91884a9996b77_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of maximizing non-monotone, nonnegative γ-weakly DR-submodular functions over down-closed convex bodies. The authors propose a new algorithm that integrates a Frank-Wolfe-guided continuous-greedy approach with a γ-aware double-greedy step. This method achieves state-of-the-art approximation guarantees that depend smoothly on the parameter γ, improving upon previous results for this class of functions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization<br>非单调γ-弱DR-子模最大化的更强近似保证] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Maximize non-monotone γ-weakly DR-submodular function<br>最大化非单调γ-弱DR-子模函数]
        B --> B2[Over down-closed convex body<br>在下封闭凸体上]
        C --> C1[Frank-Wolfe-guided continuous-greedy<br>Frank-Wolfe引导的连续贪心]
        C --> C2[γ-aware double-greedy step<br>γ感知的双贪心步骤]
        D --> D1[Smooth approximation guarantee based on γ<br>基于γ的平滑近似保证]
        D --> D2[Recovers 0.401 for γ=1 (DR-submodular)<br>γ=1时恢复0.401因子]
        D --> D3[Improves prior bounds for γ<1<br>改进了γ<1时的现有界限]
    ```

- **[arXiv260105] Do Chatbot LLMs Talk Too Much? The YapBench Benchmark**
  - **tags:** [nlp], [llm evaluation], [verbosity, benchmark, brevity, over-generation, evaluation metric]
  - **authors:** Vadim Borisov, Michael Gröger, Mina Mikhael, Richard H. Schreiber
  - **institution:** tabularis.ai
  - **link:** https://arxiv.org/pdf/2601.00624
  - **code:** https://huggingface.co/datasets/tabularisai/yapbench
  - **contributions:** 1. Introduces YapBench, a benchmark with over 300 prompts to quantify LLM over-generation in brevity-ideal scenarios. 2. Proposes YapScore, a tokenizer-agnostic metric based on character count to measure excess response length. 3. Establishes a live leaderboard and provides analysis revealing an order-of-magnitude spread in verbosity across 76 evaluated LLMs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87b7bd8c8557d407f813af012f276e8f3d15707b3fbc649fe498992f3cbf4d01_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of LLMs generating unnecessarily long and verbose responses to simple prompts. It introduces the YapBench benchmark and YapScore metric to measure this over-generation. The evaluation of 76 models shows significant variation in verbosity, highlighting a common failure mode in current assistant LLMs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Do Chatbot LLMs Talk Too Much? The YapBench Benchmark] --> B
        A --> C
        A --> D
        B[核心问题/Problem: LLMs often give unnecessarily long responses, increasing cognitive load and cost.]
        C[主要方法/Method: Introduce YapBench benchmark and YapScore metric to measure excess verbosity.]
        D[关键结果/Results: Large variation in verbosity found across 76 models; benchmark and leaderboard released.]
    ```

- **[arXiv260105] HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis**
  - **tags:** [cv], [medical image analysis], [Hypergraph Neural Network, Learning Using Privileged Information, Knowledge Distillation, Severed Graph Strategy, dual-stream distillation]
  - **authors:** Shuren Gabriel Yu, Sikang Ren, Yongji Tian
  - **institution:** Tsinghua University, Beijing Tiantan Hospital
  - **link:** https://arxiv.org/pdf/2601.00626
  - **contributions:** 1. Proposes HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information framework for preoperative ependymoma prognosis. 2. Introduces a Severed Graph Strategy with a shared encoder to process both a Teacher graph (with post-surgery text) and a Student graph (with pre-op MRI only). 3. Employs dual-stream distillation to enable the Student model to hallucinate semantic community structures from visual features alone, transferring expert knowledge without requiring text at inference.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b9ab4eaefd7ae386c2d1758797c14d52ec57c898fa468bb73264675d58297cb_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of preoperative ependymoma prognosis where post-operative text reports are unavailable at inference. It proposes HyperPriv-EPN, a hypergraph learning framework that uses a severed graph strategy and dual-stream distillation to transfer knowledge from privileged text data to a model that only uses MRI. The method achieves state-of-the-art diagnostic accuracy and survival stratification on a multi-center cohort, enabling the use of historical post-operative data for new patient diagnosis.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HyperPriv-EPN] --> B[核心问题/Problem: Pre-op prognosis lacks semantic insights from post-op reports]
        A --> C[主要方法/Method: Hypergraph LUPI with Severed Graph Strategy & dual-stream distillation]
        A --> D[关键结果/Results: SOTA accuracy & survival stratification on 311 patients]
    ```

- **[arXiv260105] Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability**
  - **tags:** [ai], [interpretable machine learning], [Bi-objective Optimization, Temporal Integrated Gradients, Optimal Path Oracle, Directed Acyclic Graph, Structured Regularization]
  - **authors:** Kasra Fouladi, Hamta Rahmani
  - **institution:** Not explicitly stated; inferred from email domains as independent researchers.
  - **link:** https://arxiv.org/pdf/2601.00655
  - **contributions:** 1. Proposes the IGBO framework that trains interpretable models by formalizing the task as a bi-objective optimization problem, jointly optimizing for accuracy and adherence to domain knowledge constraints. 2. Introduces an Optimal Path Oracle to generate data-manifold-aware integration paths, addressing the Out-of-Distribution problem in Temporal Integrated Gradients computation. 3. Provides theoretical analysis proving convergence properties and robustness to mini-batch noise, and demonstrates empirical effectiveness on time-series data with minimal accuracy loss.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/797ceec0d9225c3c9714a73c2ff308494df8996ce6022916738679549e999bd1_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains models to be both accurate and interpretable by jointly optimizing a task loss and an interpretability loss derived from domain knowledge encoded as a DAG. It addresses a key challenge in gradient-based attribution (the OOD problem) by learning an Optimal Path Oracle. Empirical results show IGBO effectively enforces interpretability constraints with minimal impact on accuracy, outperforming standard regularization methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Interpretability-Guided Bi-objective Optimization] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[黑盒模型缺乏可解释性/Black-box models lack interpretability]
        B --> B2[事后解释方法无法保证约束/Post-hoc methods don't guarantee constraints]
        B --> B3[梯度归因存在OOD问题/Gradient attribution has OOD problem]
        C --> C1[双目标优化框架/Bi-objective Optimization Framework]
        C --> C2[使用DAG编码领域知识/Encode knowledge via DAG]
        C --> C3[最优路径预言机/Optimal Path Oracle]
        D --> D1[理论收敛性证明/Theoretical convergence proof]
        D --> D2[实证效果优于基线/Empirically outperforms baselines]
        D --> D3[最小精度损失/Minimal accuracy loss]
    ```

- **[arXiv260105] Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation**
  - **tags:** [cv], [talking head generation], [diffusion forcing, direct preference optimization, real-time interaction, low latency, multimodal inputs]
  - **authors:** Taekyung Ki, Sangwon Jang, Jaehyeong Jo, Jaehong Yoon, Sung Ju Hwang
  - **institution:** KAIST, NTU Singapore, DeepAuto.ai
  - **link:** https://arxiv.org/pdf/2601.00664
  - **code:** https://taekyungki.github.io/AvatarForcing
  - **contributions:** 1. Proposes Avatar Forcing, a framework using diffusion forcing for real-time interactive head avatar generation that processes multimodal user inputs with low latency. 2. Introduces a label-free direct preference optimization method using synthetic losing samples to learn expressive interactions. 3. Demonstrates real-time performance (~500ms latency, 6.8x speedup) and generates avatars preferred over 80% against the baseline for expressiveness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17340b71396da059acb45bce5718d0e4a786ccf313c43918ba84c25b9384bb11_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of truly interactive and emotionally engaging talking head avatars by proposing Avatar Forcing, a framework that uses diffusion forcing for real-time, low-latency generation and a direct preference optimization method for label-free learning of expressive reactions. The method achieves a significant speedup and produces avatar motions that are strongly preferred by users in evaluations.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Avatar Forcing: Real-Time Interactive Head Avatar Generation] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[缺乏真正互动/Lacks truly interactive communication]
        Problem --> P2[单向反应缺乏情感/One-way responses lack emotional engagement]
        Method[主要方法/Method] --> M1[扩散驱动框架/Diffusion forcing framework]
        Method --> M2[无标签直接偏好优化/Label-free direct preference optimization]
        Results[关键结果/Results] --> R1[低延迟实时交互/Low-latency real-time interaction (~500ms)]
        Results --> R2[6.8倍加速/6.8x speedup]
        Results --> R3[80%用户偏好/Over 80% user preference]
    ```

- **[arXiv260105] Three factor delay learning rules for spiking neural networks**
  - **tags:** [mlsys], [on-device ai], [spiking neural networks, delay learning, three-factor learning, online learning, neuromorphic processors]
  - **authors:** Luke Vassallo, Nima Taherinejad
  - **institution:** Heidelberg University
  - **link:** https://arxiv.org/pdf/2601.00668
  - **contributions:** 1. Introduced learnable synaptic and axonal delays into LIF-based SNNs and proposed novel three-factor learning rules for online, simultaneous learning of both weights and delays. 2. Employed a smooth Gaussian surrogate gradient exclusively for eligibility trace calculation to enable gradient-equivalent delay parameter updates. 3. Demonstrated significant improvements in model efficiency, achieving up to 6.6x model size reduction and 67% lower inference latency with minimal accuracy loss, enabling on-device learning for resource-constrained environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58cabcbc7350cb70af9599a2c224309ae64c370ecf64ef754054d42693a8f504_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limited temporal learning capability of Spiking Neural Networks (SNNs) by introducing learnable synaptic and axonal delays and proposing online three-factor learning rules to train them. The method uses a Gaussian surrogate gradient for eligibility traces and achieves competitive accuracy on temporal tasks like speech recognition while drastically reducing model size and latency. The findings facilitate efficient, on-device learning for power and area-constrained neuromorphic hardware.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Three factor delay learning rules for spiking neural networks] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[SNNs lack temporal parameters/SNNs缺乏时间参数]
        B --> B2[Existing delay learning is offline & large/现有延迟学习是离线的且模型大]
        C --> C1[Learnable synaptic & axonal delays/可学习的突触和轴突延迟]
        C --> C2[Three-factor online learning rules/三因素在线学习规则]
        C --> C3[Gaussian surrogate for eligibility trace/用于资格迹的高斯代理梯度]
        D --> D1[Accuracy improved up to 20%/准确率提升高达20%]
        D --> D2[Model size reduced 6.6x/模型大小减少6.6倍]
        D --> D3[Latency reduced 67%/延迟降低67%]
    ```

- **[arXiv260105] Sparse FEONet: A Low-Cost, Memory-Efficient Operator Network via Finite-Element Local Sparsity for Parametric PDEs**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [operator learning, finite element methods, sparse networks, computational efficiency, stability]
  - **authors:** Seungchan Ko, Jiyeon Kim, Dongwook Shin
  - **institution:** Inha University, Ajou University
  - **link:** https://arxiv.org/pdf/2601.00672
  - **contributions:** 1. Proposes a novel sparse network architecture for FEONet, leveraging finite-element local sparsity to reduce computational cost and memory usage. 2. Provides theoretical analysis demonstrating the sparse architecture's approximation capability and stability for reliable training. 3. Validates the method through extensive numerical experiments, showing substantial efficiency gains while maintaining accuracy comparable to the original FEONet.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ca7dbad16ad9ca12a77087fa33228fbe27facf787daefb7dcf7928c77caf2bd_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Sparse FEONet, a memory-efficient variant of the Finite Element Operator Network, to address the scalability issues of the original model. By incorporating a sparse architecture inspired by finite element structures, it significantly reduces computational cost and memory footprint while preserving accuracy. Theoretical and experimental results confirm its effectiveness and stability for solving parametric PDEs.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Sparse FEONet<br>稀疏FEONet"] --> Problem["核心问题/Problem<br>FEONet计算成本高，大规模问题有挑战<br>High computational cost of FEONet for large-scale problems"]
        Root --> Method["主要方法/Method<br>提出基于有限元局部稀疏性的新网络架构<br>Propose new sparse network architecture via finite-element local sparsity"]
        Root --> Results["关键结果/Results<br>计算成本效率显著提升，保持精度，理论保证<br>Substantial improvements in cost/efficiency, maintained accuracy, theoretical guarantees"]
    ```

- **[arXiv260105] IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning**
  - **tags:** [mlsys], [post-training (sft/rlhf)], [Generative Reward Models, Bradley-Terry Model, Group Relative Policy Optimization, Reinforcement Learning from Human Feedback, Pointwise Scoring]
  - **authors:** Haonan Song, Qingchen Xie, Huan Zhu, Feng Xiao, Luxi Xing, Fuzhen Li, Liu Kang, Feng Jiang, Zhiyong Zheng, Fan Yang
  - **institution:** HUJING Digital Media & Entertainment Group (XingYun Lab), Tsinghua University
  - **link:** https://arxiv.org/pdf/2601.00677
  - **contributions:** 1. Proposes IRPO, a novel RL framework that integrates the Bradley-Terry model into GRPO to scale pairwise reward models for RL training. 2. Introduces a pointwise scoring mechanism that enables efficient evaluation of many candidate responses during RL, overcoming the O(n^2) computational bottleneck. 3. Demonstrates state-of-the-art performance among pointwise GRMs and shows significant advantages over pairwise GRMs in post-training evaluations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5cc90e0083ca0244ea3fbdd445ab9a0b8ff4478f444643d38c88fecae22744f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the computational bottleneck of pairwise Generative Reward Models (GRMs) in reinforcement learning by proposing Intergroup Relative Preference Optimization (IRPO). IRPO incorporates the Bradley-Terry model into Group Relative Policy Optimization to generate pointwise scores, enabling efficient evaluation of many candidates. The method achieves state-of-the-art performance among pointwise GRMs and outperforms pairwise GRMs in post-training evaluations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[IRPO: Scaling the Bradley-Terry Model via RL] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Pairwise GRMs create O(n²) bottleneck in RL/成对GRM在RL中造成O(n²)瓶颈]
        C --> C1[IRPO: Integrate Bradley-Terry into GRPO for pointwise scoring/IRPO: 将Bradley-Terry融入GRPO实现逐点评分]
        D --> D1[SOTA among pointwise GRMs/在逐点GRM中达到SOTA]
        D --> D2[Outperforms pairwise GRMs in post-training/在训练后评估中优于成对GRM]
    ```

- **[arXiv260105] QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [quantization, spike-driven language models (SLMs), memory footprint, tiered search, embedded systems]
  - **authors:** Rachmad Vidya Wicaksana Putra, Pasindu Wickramasinghe, Muhammad Shafique
  - **institution:** New York University (NYU) Abu Dhabi
  - **link:** https://arxiv.org/pdf/2601.00679
  - **contributions:** 1. Proposes QSLM, an automated quantization framework for compressing pre-trained Spike-driven Language Models (SLMs) to meet performance and memory constraints. 2. Introduces a tiered quantization strategy (global-, block-, and module-level) guided by network hierarchy and layer sensitivity analysis. 3. Leverages a multi-objective performance-and-memory trade-off function to select the final quantization setting, achieving significant memory and power reduction while maintaining high task performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/911838f93e33219fcf586121369dd081b9908c86a1169c367cfdd1bb7e50139b_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes QSLM, an automated framework for quantizing Spike-driven Language Models (SLMs) to reduce their memory footprint for embedded deployment. It uses a tiered search strategy based on network hierarchy and layer sensitivity, along with a multi-objective trade-off function, to find optimal quantization settings. Experimental results show QSLM can reduce memory by up to 86.5% and power by up to 20% while maintaining performance close to the original model.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models] --> B
        A --> C
        A --> D
        B[核心问题/Problem: SLMs内存占用大，难以部署在资源受限的嵌入式设备/SLMs have large memory footprints, challenging for resource-constrained embedded deployment]
        C[主要方法/Method: 自动化分层量化策略，结合网络层次、层敏感性和多目标权衡函数/Automated tiered quantization strategy using network hierarchy, layer sensitivity, and multi-objective trade-off]
        D[关键结果/Results: 内存占用减少高达86.5%，功耗降低高达20%，性能接近原始模型/Memory footprint reduced by up to 86.5%, power by up to 20%, performance close to original model]
    ```

- **[arXiv260105] Cost Optimization in Production Line Using Genetic Algorithm**
  - **tags:** [ai], [combinatorial optimization], [genetic algorithm, task scheduling, production line, chromosome encoding, JGAP]
  - **authors:** Alireza Rezaee
  - **institution:** University of Tehran
  - **link:** https://arxiv.org/pdf/2601.00689
  - **contributions:** 1. Proposes and compares two chromosome encoding strategies (station-based and task-based) for a GA applied to a production line scheduling problem. 2. Adapts standard GA operators (crossover, mutation, etc.) to preserve solution feasibility under precedence and capacity constraints. 3. Empirically demonstrates that the task-based encoding yields smoother convergence and more reliable cost minimization, especially for problems with a large number of valid schedules.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d46632061e4499187a195e89a09ba37b6eff28c44f9881da5b237c2b781953b_w640_q70.webp
  - **Simple LLM Summary:** This paper applies a genetic algorithm to optimize task scheduling in a production line to minimize cost. It investigates two different ways to represent the schedule (encoding) within the algorithm and finds that a task-based encoding performs better, converging more smoothly to lower-cost solutions. The study shows GAs are advantageous for this type of complex, constrained scheduling problem.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cost Optimization in Production Line Using Genetic Algorithm] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[最小化生产线成本/Minimize Production Line Cost]
        B --> B2[任务调度与约束/Task Scheduling with Constraints]
        C --> C1[遗传算法/Genetic Algorithm]
        C --> C2[两种编码策略/Two Encoding Strategies]
        C2 --> C21[基于工位的编码/Station-based Encoding]
        C2 --> C22[基于任务的编码/Task-based Encoding]
        D --> D1[基于任务的编码性能更优/Task-based Encoding Performs Better]
        D --> D2[更平滑的收敛/Smoother Convergence]
        D --> D3[更可靠的优化/More Reliable Optimization]
    ```

- **[arXiv260105] TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [ticket troubleshooting, retrieval-augmented generation, instruction-tuning, domain-specific ranking, large language models]
  - **authors:** Mohamed Trabelsi, Huseyin Uzunalioglu
  - **institution:** Nokia Bell Labs
  - **link:** https://arxiv.org/pdf/2601.00691
  - **contributions:** 1. Proposes TeleDoCTR, an end-to-end system for telecom ticket troubleshooting integrating classification, retrieval, and generation tasks. 2. Introduces a domain-specific and contextual approach combining ranking and generative models tailored for the telecom domain. 3. Demonstrates superior performance over state-of-the-art methods on a real-world telecom dataset, enhancing troubleshooting accuracy and efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/151b34be88d61fea64f35727dce1917583308996e63a1822af1e6ad8863fe6a8_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes TeleDoCTR, a system that automates telecom ticket troubleshooting by integrating domain-specific models for ticket classification, retrieval of similar historical tickets, and generation of fault analysis reports. It is evaluated on a real-world telecom dataset and shows improved performance over existing methods, making the troubleshooting process more accurate and efficient.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications] --> B[核心问题/Problem: Telecom ticket troubleshooting is complex, time-consuming, and human-intensive.]
        A --> C[主要方法/Method: Integrates domain-specific ranking and generative models for classification, retrieval, and generation tasks.]
        A --> D[关键结果/Results: Superior performance over SOTA methods on real-world data, enhancing accuracy and efficiency.]
    ```

- **[arXiv260105] ARISE: Adaptive Reinforcement Integrated with Swarm Exploration**
  - **tags:** [ai], [reinforcement learning], [swarm intelligence, policy gradient, adaptive exploration, non-stationary rewards, particle swarm]
  - **authors:** Rajiv Chaitanya M, D R Ramesh Babu
  - **institution:** Dayananda Sagar College of Engineering
  - **link:** https://arxiv.org/pdf/2601.00693
  - **contributions:** 1. Introduces ARISE, a lightweight framework that augments standard policy-gradient RL methods with a swarm-based exploration layer., 2. Proposes an adaptive mechanism that modulates exploration intensity based on reward-variance cues., 3. Demonstrates significant performance improvements and robustness, particularly in challenging and non-stationary environments, without altering core algorithmic structures.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da08cf28812cd5b0330c83f593897cfcd5e8e953ff273742e122d3262910e186_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces ARISE, a framework that enhances reinforcement learning by integrating a swarm-based exploration layer with standard policy-gradient methods to improve exploration. It adaptively blends policy actions with particle-driven proposals and modulates exploration using reward variance. The method shows substantial performance gains on complex tasks and improved robustness in non-stationary environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[ARISE: Adaptive Reinforcement Integrated with Swarm Exploration] --> Problem(核心问题/Problem)
        Root --> Method(主要方法/Method)
        Root --> Results(关键结果/Results)
        Problem --> P1[RL探索挑战/RL Exploration Challenge]
        Problem --> P2[非平稳奖励/Non-stationary Rewards]
        Method --> M1[群体智能探索层/Swarm-based Exploration Layer]
        Method --> M2[自适应调节/Adaptive Modulation]
        Method --> M3[策略-粒子混合/Policy-Particle Blending]
        Results --> R1[性能显著提升/Substantial Performance Gains]
        Results --> R2[鲁棒性增强/Enhanced Robustness]
        Results --> R3[架构无关/Architecture-agnostic]
    ```

- **[arXiv260105] BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting**
  - **tags:** [ai], [time series forecasting], [B-spline tokenization, adaptive segmentation, Rotary Positional Embedding (RoPE), long-term forecasting, transformer efficiency]
  - **authors:** Maximilian Reinwardt, Michael Eichelbeck, Matthias Althoff
  - **institution:** Technical University of Munich
  - **link:** https://arxiv.org/pdf/2601.00698
  - **contributions:** 1. Introduces the B-Spline Adaptive Tokenizer (BSAT), a parameter-free method for adaptively segmenting time series by fitting B-splines and placing tokens in high-curvature regions. 2. Proposes a hybrid positional encoding strategy combining additive learnable encoding with a novel L-RoPE (layer-wise learnable base Rotary Positional Embedding). 3. Demonstrates that the model achieves competitive performance at high compression rates, making it suitable for memory-constrained use cases.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6206fb30f6a9eddbc2ada96d43c221bc41515951535d8d579b2df705186641a9_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the inefficiency of transformers for long-term time series forecasting by introducing BSAT, an adaptive tokenizer that uses B-splines to create variable-length tokens aligned with data semantics, and a novel hybrid positional encoding. The method achieves strong performance with high compression, making it effective under memory constraints.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting"] --> Problem["核心问题/Problem<br>Quadratic self-attention complexity & rigid uniform patching in transformers for time series"]
        Root --> Method["主要方法/Method<br>B-Spline Adaptive Tokenizer (BSAT) & Hybrid Positional Encoding (L-RoPE)"]
        Root --> Results["关键结果/Results<br>Competitive performance at high compression rates, suitable for memory-constrained use"]
    ```

- **[arXiv260105] Bayesian Inverse Games with High-Dimensional Multi-Modal Observations**
  - **tags:** [ai], [inverse reinforcement learning], [Bayesian inference, variational autoencoder, Nash equilibrium, inverse games, multimodal observations]
  - **authors:** Yash Jain, Xinjie Liu, Lasse Peters, David Fridovich-Keil, Ufuk Topcu
  - **institution:** The University of Texas at Austin, Delft University of Technology
  - **link:** https://arxiv.org/pdf/2601.00696
  - **contributions:** 1. Proposes a Bayesian inference framework for inverse games to quantify uncertainty in estimating agent objectives, addressing the overconfidence of point-estimate methods. 2. Introduces a structured variational autoencoder with an embedded differentiable Nash game solver, enabling posterior sampling without requiring labeled objective data. 3. Demonstrates that multimodal inference reduces uncertainty when trajectory data is insufficient, leading to safer downstream planning decisions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9263c0ad6078bf92eb8f7a7ca21579f0a55a6e710fa80a06f40a66a735ce24a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of inferring agents' hidden objectives in multi-agent interactions, where existing maximum likelihood methods produce overconfident point estimates. The authors propose a Bayesian inverse game framework using a structured variational autoencoder with a differentiable Nash solver to generate posterior samples from multimodal observations. Experiments show the method improves inference quality, quantifies uncertainty, and enables safer autonomous decision-making compared to prior approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Bayesian Inverse Games with High-Dimensional Multi-Modal Observations") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("MLE方法只提供点估计，导致不确定性被忽略/MLE methods provide only point estimates, ignoring uncertainty")
        Problem --> P2("下游规划可能过度自信，导致不安全动作/Downstream planning can be overconfident, leading to unsafe actions")
        Method --> M1("近似贝叶斯推理框架/Approximate Bayesian inference framework")
        Method --> M2("结构化变分自编码器嵌入可微纳什求解器/Structured VAE with embedded differentiable Nash solver")
        Method --> M3("利用多模态观测数据/Utilizes multi-modal observation data")
        Results --> R1("成功学习先验和后验分布/Successfully learns prior and posterior distributions")
        Results --> R2("推理质量优于MLE方法/Improves inference quality over MLE")
        Results --> R3("多模态推理进一步减少不确定性/Multimodal inference further reduces uncertainty")
    ```

- **[arXiv260105] Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [reinforcement learning, precision autotuning, contextual bandit, mixed-precision, linear solvers]
  - **authors:** Erin Carson, Xinye Chen
  - **institution:** Charles University, Sorbonne Université, CNRS, LIP6
  - **link:** https://arxiv.org/pdf/2601.00728
  - **contributions:** 1. Proposes a novel reinforcement learning framework formulated as a contextual bandit problem for adaptive precision tuning of numerical algorithms. 2. Applies the framework to iterative refinement for linear solvers, using a Q-table and epsilon-greedy strategy to dynamically select precision configurations based on system features. 3. Demonstrates the framework's effectiveness and generalization, reducing computational cost while maintaining accuracy comparable to double-precision baselines on unseen data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7720c36c9ae5fbf03bb75ea2bb7142862906819bb41cf70b683252fc884718e2_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a reinforcement learning framework for adaptive precision tuning, formulated as a contextual bandit problem, to optimize the trade-off between computational cost and accuracy in linear solvers. The method dynamically selects precision configurations based on system features using a Q-learning approach. Empirical results show it reduces cost while maintaining accuracy, and it generalizes well to unseen data.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root(Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL) --> Problem(核心问题/Problem)
        Root --> Method(主要方法/Method)
        Root --> Results(关键结果/Results)
        Problem --> P1(高精度计算能耗高/High-precision computing is energy-intensive)
        Problem --> P2(低精度计算可能不稳定/Reduced-precision can be unstable)
        Method --> M1(将问题建模为上下文赌博机/Formulate as Contextual Bandit)
        Method --> M2(使用Q表和epsilon-greedy策略/Use Q-table & epsilon-greedy)
        Method --> M3(应用于线性求解器的迭代精化/Apply to iterative refinement for linear solvers)
        Results --> R1(有效降低计算成本/Effectively reduces computational cost)
        Results --> R2(保持与双精度相当的精度/Maintains accuracy comparable to double-precision)
        Results --> R3(泛化到未见数据/Generalizes to unseen data)
    ```

- **[arXiv260105] Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty**
  - **tags:** [ai], [reinforcement learning], [actor-critic, overestimation, aleatoric uncertainty, distributional critic, dropout]
  - **authors:** Uğurcan Özalp
  - **institution:** Turkish Aerospace
  - **link:** https://arxiv.org/pdf/2601.00737
  - **contributions:** 1. Proposes Stochastic Actor-Critic (STAC), a novel algorithm that uses temporal aleatoric uncertainty (from stochastic transitions, rewards, and policy) to scale pessimistic bias in TD updates, instead of relying on epistemic uncertainty. 2. Demonstrates that a single distributional critic network modeling return uncertainty is sufficient to mitigate overestimation and induce risk-averse behavior. 3. Shows that applying dropout for regularization in both actor and critic networks further improves training stability and performance, enhancing computational efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/602bf8125f08dc0296e56b4a9e156cd6089d329c07cd83909cc1b3c96effc1bf_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of overestimation bias in off-policy actor-critic reinforcement learning methods. It proposes the Stochastic Actor-Critic (STAC) algorithm, which mitigates overestimation by using a single distributional critic to model temporal aleatoric uncertainty for scaling pessimistic updates, and employs dropout for regularization. The results show that this approach effectively reduces overestimation, leads to risk-averse behavior, and improves computational efficiency and training stability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[STAC: Mitigating Overestimation via Temporal Aleatoric Uncertainty] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Critic网络系统性高估价值/Critic Networks Systematically Overestimate Value Estimates]
        C --> C1[使用单分布评论家建模时序偶然不确定性/Use Single Distributional Critic to Model Temporal Aleatoric Uncertainty]
        C --> C2[在TD更新中应用基于不确定性的悲观偏差/Apply Uncertainty-Based Pessimistic Bias in TD Updates]
        C --> C3[对评论家和行动者网络使用Dropout正则化/Use Dropout Regularization on Critic and Actor Networks]
        D --> D1[缓解高估偏差/Mitigates Overestimation Bias]
        D --> D2[在随机环境中产生风险规避行为/Leads to Risk-Averse Behavior in Stochastic Environments]
        D --> D3[提高计算效率和训练稳定性/Improves Computational Efficiency and Training Stability]
    ```

- **[arXiv260105] The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving**
  - **tags:** [ai], [reinforcement learning], [distributional creative reasoning, diversity collapse, gradient flow, variational objective, reasoning paths]
  - **authors:** Max Ruiz Luyten, Mihaela van der Schaar
  - **institution:** University of Cambridge
  - **link:** https://arxiv.org/pdf/2601.00747
  - **contributions:** 1. Introduces Distributional Creative Reasoning (DCR), a unified variational framework that models training as gradient flow through probability measures on solution traces, encompassing methods like STaR, GRPO, and DPO as special cases. 2. Proves the diversity decay theorem, which explains how correctness-focused objectives lead to distinct modes of diversity collapse in different algorithms. 3. Provides principled designs and actionable recipes to ensure convergence to a stable and diverse policy, preventing creative collapse while maintaining correctness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9fbb639faaebe1f394144b6e1a9a7bbb2ea6b005c8194a324964adf46349c164_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that bootstrapped reasoning loops in LLMs, which optimize for correctness, lead to a collapse in the diversity of reasoning paths, harming creative problem-solving. To address this, it proposes Distributional Creative Reasoning (DCR), a unified theoretical framework that explains this collapse and offers designs to prevent it. The main conclusion is that DCR provides the first principled recipe for training LLMs that are both correct and creative.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving<br>推理-创造力权衡：迈向创造力驱动的问题解决"]
        Root --> Problem["核心问题/Problem<br>Correctness-focused training causes diversity collapse in reasoning paths.<br>以正确性为核心的训练导致推理路径的多样性崩溃。"]
        Root --> Method["主要方法/Method<br>Introduce Distributional Creative Reasoning (DCR), a unified variational framework.<br>提出分布创造性推理（DCR），一个统一的变分框架。"]
        Root --> Results["关键结果/Results<br>Diversity decay theorem, designs to prevent collapse, actionable recipes.<br>多样性衰减定理，防止崩溃的设计，可操作的方案。"]
    ```

- **[arXiv260105] A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football**
  - **tags:** [ai], [sports analytics], [covariate-dependent Hidden Markov Model, defensive credit attribution, role-conditioned ghosting]
  - **authors:** Sean Groom, Shuo Wang, Francisco Belo, Axl Rice, Liam Anderson
  - **institution:** The University of Birmingham, Nottingham Forest Football Club
  - **link:** https://arxiv.org/pdf/2601.00748
  - **contributions:** 1. Introduces a covariate-dependent Hidden Markov Model (CDHMM) to infer time-resolved defensive role assignments (man-marking and zonal) from player tracking data during corner kicks. 2. Proposes a novel framework for defensive credit attribution based on the inferred role assignments. 3. Develops a role-conditioned ghosting method for context-aware counterfactual analysis of off-ball defensive performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/829cb6bc9dbc2a288f24bae908e436437a33ee4cddc07525ba2d5196a191500c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of evaluating off-ball defensive performance in football, which is not captured by traditional metrics. The authors propose a covariate-dependent Hidden Markov Model to automatically infer defensive roles from tracking data and use this to create a new framework for credit attribution and counterfactual analysis. The method provides an interpretable, context-aware evaluation of defensive contributions.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football<br>足球中无球防守角色与性能评估的机器学习框架"]
        Root --> Problem["核心问题/Problem<br>传统指标无法评估无球防守表现<br>现有反事实方法缺乏战术背景"]
        Root --> Method["主要方法/Method<br>引入协变量依赖隐马尔可夫模型(CDHMM)<br>提出基于角色的防守贡献归因与幻影方法"]
        Root --> Results["关键结果/Results<br>提供可解释的、情境感知的防守贡献评估"]
    ```

- **[arXiv260105] Memory Bank Compression for Continual Adaptation of Large Language Models**
  - **tags:** [mlsys], [memory & caching], [memory bank compression, codebook optimization, online resetting mechanism, Key-Value Low-Rank Adaptation (KV-LoRA)]
  - **authors:** Thomas Katraouras, Dimitrios Rafailidis
  - **institution:** University of Thessaly
  - **link:** https://arxiv.org/pdf/2601.00756
  - **code:** https://github.com/Thomkat/MBC
  - **contributions:** 1. Proposed MBC, a model that compresses the memory bank for continual learning via a codebook optimization strategy. 2. Introduced an online resetting mechanism to prevent codebook collapse and ensure stable learning. 3. Employed Key-Value Low-Rank Adaptation (KV-LoRA) in the LLM's attention layers to efficiently utilize the compressed memory representations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4b16d7a0bdd1f6fa0e71da5c21a92629d07342bdc56905e10612ee07549b8dd_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of memory bank growth in continual learning for LLMs by proposing MBC, which compresses the memory bank using codebook optimization and an online resetting mechanism. The method integrates KV-LoRA for efficient adaptation and achieves a 99.7% reduction in memory bank size while maintaining high accuracy on question-answering tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Memory Bank Compression for Continual Adaptation of Large Language Models] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLMs知识过时 / LLMs' knowledge becomes outdated]
        B --> B2[持续学习中的灾难性遗忘 / Catastrophic forgetting in continual learning]
        B --> B3[内存库无限增长 / Memory bank grows unbounded]
        C --> C1[内存库压缩 / Memory bank compression]
        C --> C2[码本优化策略 / Codebook optimization strategy]
        C --> C3[在线重置机制 / Online resetting mechanism]
        C --> C4[KV-LoRA / Key-Value Low-Rank Adaptation]
        D --> D1[内存库大小减少至0.3% / Memory bank size reduced to 0.3%]
        D --> D2[保持高精度 / Maintains high retention accuracy]
    ```

- **[arXiv260105] Categorical Reparameterization with Denoising Diffusion models**
  - **tags:** [ai], [diffusion models], [categorical reparameterization, gradient estimation, denoising diffusion, continuous relaxation, Gumbel-Softmax]
  - **authors:** Samson Gourevitch, Alain Durmus, Eric Moulines, Jimmy Olsson, Yazid Janati
  - **institution:** CMAP, Ecole polytechnique; Mohamed Bin Zayed University of AI; KTH Royal Institute of Technology; Institute of Foundation Models, MBZUAI
  - **link:** https://arxiv.org/pdf/2601.00781
  - **contributions:** 1. Introduces a novel diffusion-based soft reparameterization for categorical distributions, extending the family of continuous relaxations. 2. Shows that the denoiser for categorical distributions under a Gaussian noising process has a closed-form, efficient solution, enabling a training-free diffusion sampler. 3. Demonstrates that the proposed method yields competitive or improved optimization performance on various benchmarks compared to existing gradient estimators.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07551087da54975e4db6aaddfb0b58a659ed27c7a4b438249f27613f2153d75f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of gradient-based optimization with categorical variables by proposing a new diffusion-based reparameterization method. It leverages the closed-form denoiser for categorical distributions to create a differentiable, training-free sampler. Experimental results show this approach provides effective gradient estimates, outperforming or matching existing methods on several benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Categorical Reparameterization with Denoising Diffusion models] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[梯度优化与分类变量/Gradient optimization with categorical variables]
        P1 --> P2[现有估计器存在偏差-方差权衡/Existing estimators have bias-variance trade-off]
        Method[主要方法/Method] --> M1[扩散基软重参数化/Diffusion-based soft reparameterization]
        M1 --> M2[闭式去噪器/Closed-form denoiser for categorical distributions]
        M2 --> M3[免训练可微分采样器/Training-free differentiable sampler]
        Results[关键结果/Results] --> R1[竞争性或改进的优化性能/Competitive or improved optimization performance]
    ```

- **[arXiv260105] Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning**
  - **tags:** [nlp], [reasoning verification], [spectral graph analysis, attention patterns, Fiedler value, high-frequency energy ratio, sliding window attention]
  - **authors:** Valentin Noël
  - **institution:** Devoteam
  - **link:** https://arxiv.org/pdf/2601.00791
  - **contributions:** 1. Introduced a training-free method for detecting valid mathematical reasoning in LLMs by performing spectral analysis on attention matrices treated as dynamic graphs. 2. Identified four interpretable spectral diagnostics (Fiedler value, HFER, smoothness, entropy) that show significant statistical differences between valid and invalid proofs across multiple model families. 3. Discovered that the method captures logical coherence rather than formal verifier acceptance and revealed an architectural dependency where different attention mechanisms (e.g., Sliding Window Attention) shift the primary discriminative spectral feature.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2b1f2999ddcf2e05565198a4f51efee7b71422414b78038f132537978df2e4e9_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes a training-free method to detect valid mathematical reasoning in large language models by analyzing the spectral properties of attention patterns. The method identifies key spectral signatures that effectively distinguish between valid and invalid proofs with high accuracy. The findings show the method captures logical coherence and its effectiveness depends on the model's attention architecture.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning") --> Problem("核心问题/Problem: Detecting valid mathematical reasoning in LLMs")
        Root --> Method("主要方法/Method: Spectral analysis of attention patterns as dynamic graphs")
        Root --> Results("关键结果/Results: High classification accuracy, detects logical coherence, architectural dependency identified")
    ```

- **[arXiv260105] FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing**
  - **tags:** [mlsys], [federated learning], [hypernetwork, conditional VAE, differential privacy, MMD alignment, client heterogeneity]
  - **authors:** Sunny Gupta, Amit Sethi
  - **institution:** Indian Institute of Technology Bombay
  - **link:** https://arxiv.org/pdf/2601.00785
  - **code:** github.com/sunnyinAI/FedHypeVAE
  - **contributions:** 1. A bi-level framework using a shared hypernetwork to generate personalized, client-aware decoders and class-conditional priors for a conditional VAE, decoupling local data from shared parameters. 2. Incorporation of differential privacy during hypernetwork optimization with noise-perturbed, clipped gradients to provide formal privacy guarantees against gradient leakage. 3. Introduction of a local MMD alignment loss and Lipschitz regularization to enhance stability and distributional coherence under non-IID data conditions, along with a neutral meta-code for domain-agnostic synthesis.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5726225d41733e7b16755efae5f3b9ec28771c58479913c7f5581e9843368fd0_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes FedHypeVAE, a federated learning framework that uses a differentially private hypernetwork to generate personalized conditional VAEs for synthesizing embedding-level data across decentralized clients. It addresses challenges of non-IID data and privacy by decoupling local data from shared parameters and ensuring formal privacy guarantees. The method establishes a foundation for privacy-preserving data synthesis in federated settings by unifying personalization, privacy, and distribution alignment at the generator level.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FedHypeVAE] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[非IID数据与隐私挑战/non-IID & Privacy]
        C --> C1[超网络生成条件VAE/Hypernetwork-Generated Conditional VAE]
        C --> C2[差分隐私训练/Differentially Private Training]
        C --> C3[MMD对齐与正则化/MMD Alignment & Regularization]
        D --> D1[个性化与隐私统一/Unified Personalization & Privacy]
        D --> D2[可控多域合成/Controllable Multi-Domain Synthesis]
    ```

- **[arXiv260105] Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI**
  - **tags:** [cv], [medical image segmentation], [U-Net, layer normalization, instance-batch normalization, left ventricle segmentation, cardiac MRI]
  - **authors:** Wenhui Chu, Nikolaos V. Tsekos
  - **institution:** University of Houston
  - **link:** https://arxiv.org/pdf/2601.00794
  - **contributions:** 1. Proposed LNU-Net, a novel segmentation architecture derived from U-Net that applies layer normalization in each convolutional block. 2. Proposed IBU-Net, another novel architecture that incorporates instance and batch normalization together in the first convolutional block. 3. Demonstrated that the proposed methods outperform state-of-the-art approaches on a dataset of 805 MRI images using metrics like dice coefficient and average perpendicular distance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45a19599df20601908ea938c8bea28356e54685c5ce08dbe58a85a26dda95834_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes two new deep learning models, LNU-Net and IBU-Net, for automated segmentation of the left ventricle in cardiac MRI images. The models are based on the U-Net architecture but incorporate different normalization strategies—layer normalization and a combined instance-batch normalization—to improve segmentation performance. Experimental results show that both proposed approaches outperform existing state-of-the-art methods on key evaluation metrics.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[左心室分割对临床诊断至关重要/Left ventricle segmentation is critical for clinical diagnosis]
        C --> C1[提出LNU-Net和IBU-Net/Propose LNU-Net and IBU-Net]
        C1 --> C2[基于U-Net，采用不同归一化策略/Based on U-Net with different normalization strategies]
        D --> D1[在805张MRI图像上评估/Evaluated on 805 MRI images]
        D1 --> D2[性能优于现有方法/Outperforms state-of-the-art approaches]
    ```

- **[arXiv260105] Active learning for data-driven reduced models of parametric differential systems with Bayesian operator inference**
  - **tags:** [other], [scientific machine learning], [Bayesian operator inference, active learning, reduced-order models, parametric systems, adaptive sampling]
  - **authors:** Shane A. McQuarrie, Mengwu Guo, Anirban Chaudhuri
  - **institution:** Brigham Young University, Lund University, The University of Texas at Austin
  - **link:** https://arxiv.org/pdf/2601.00038
  - **contributions:** 1. Developed a probabilistic version of parametric operator inference by casting the learning problem as Bayesian linear regression. 2. Designed a sequential adaptive sampling scheme that uses prediction uncertainties from the probabilistic ROM to select new training parameters. 3. Demonstrated through numerical experiments that the active learning framework yields more stable and accurate ROMs than random sampling under the same computational budget.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c29bb4bdd9fe6e4385983b4dab88a4de7d95bf126d6c1b64568426082175c1b6_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes an active learning framework to improve data-driven reduced-order models (ROMs) for parametric dynamical systems. The method uses Bayesian operator inference to create probabilistic ROMs and leverages their prediction uncertainties to adaptively select the most informative training parameters. The results show this approach consistently produces more stable and accurate ROMs compared to training with random parameter samples.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Active learning for data-driven reduced models<br>数据驱动的降阶模型主动学习") --> Problem("ROM quality depends on training data<br>ROM质量依赖于训练数据")
        Root --> Method("Bayesian OpInf + Adaptive Sampling<br>贝叶斯算子推断 + 自适应采样")
        Root --> Results("More stable & accurate ROMs vs. random sampling<br>相比随机采样，获得更稳定准确的ROM")
    ```

- **[arXiv260105] Automated electrostatic characterization of quantum dot devices in single- and bilayer heterostructures**
  - **tags:** [other], [quantum computing], [quantum dot, charge stability diagram, automated characterization, machine learning, image processing]
  - **authors:** Merritt P. R. Losert, Dario Denora, Barnaby van Straaten, Michael Chan, Stefan D. Oosterhout, Lucas Stehouwer, Giordano Scappucci, Menno Veldhorst, Justyna P. Zwolak
  - **institution:** National Institute of Standards and Technology (NIST), Delft University of Technology (QuTech)
  - **link:** https://arxiv.org/pdf/2601.00067
  - **contributions:** 1. Developed an automated protocol combining ML, image processing, and object detection to extract capacitive properties from charge stability diagrams without manual labeling. 2. Demonstrated the method's effectiveness on complex bilayer germanium heterostructures, which feature interlayer tunneling and distinct loading lines. 3. Enabled statistical estimation of physically relevant device parameters, such as lever arms and capacitive couplings, facilitating rapid device characterization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c536889ababa23206b42f144321036dbbfd329505ea45c505aa53c2a04bf7815_w640_q70.webp
  - **Simple LLM Summary:** This paper presents an automated method for characterizing quantum dot devices by analyzing charge stability diagrams. The protocol integrates machine learning and image processing to identify charge transitions and extract capacitive properties from experimental data. It enables rapid, scalable extraction of key device parameters, which is critical for advancing large-scale quantum dot arrays.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Automated electrostatic characterization of quantum dot devices<br>量子点器件自动静电表征] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Manual interpretation of CSDs is slow and error-prone<br>CSD手动解释慢且易错]
        C --> C1[Integrates ML, image processing, object detection<br>集成ML、图像处理、目标检测]
        D --> D1[Enables rapid extraction of device parameters (lever arms, couplings)<br>实现器件参数快速提取]
    ```

- **[arXiv260105] Group Cross-Correlations with Faintly Constrained Filters**
  - **tags:** [other], [group theory, harmonic analysis, topological dynamics], [group cross-correlations, G-equivariant filters, non-compact stabilizers, non-transitive actions, unimodularity]
  - **authors:** Benedikt Fluhr
  - **institution:** Cannot be inferred from the provided content.
  - **link:** https://arxiv.org/pdf/2601.00045
  - **contributions:** 1. Introduces a new notion of group cross-correlations with less constrained filters, 2. Resolves incompatibilities for group actions with non-compact stabilizers, 3. Generalizes results to non-transitive group actions and weakens the unimodularity assumption.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/140a9a6a7cb64898feb16f84d9ad4ac9bc745bc82682b538beb6dd66d1f871c8_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a generalized framework for group cross-correlations by relaxing the constraints on the filters used. This new approach resolves previous theoretical limitations for group actions with non-compact stabilizers and extends applicability to non-transitive actions without requiring unimodularity. The work provides a more flexible mathematical foundation for equivariant transformations on vector bundles.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Group Cross-Correlations with Faintly Constrained Filters] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[先前滤波器约束过紧 / Previous filter constraints too tight]
        B --> B2[与非紧稳定子群不兼容 / Incompatible with non-compact stabilizers]
        C --> C1[提出弱约束滤波器概念 / Propose faintly constrained filters]
        C --> C2[推广到非传递群作用 / Generalize to non-transitive actions]
        D --> D1[解决不兼容性问题 / Resolves incompatibility]
        D --> D2[放宽单模性假设 / Weakens unimodularity assumption]
    ```

- **[arXiv260105] Deep Learning Approach for the Diagnosis of Pediatric Pneumonia Using Chest X-ray Imaging**
  - **tags:** [cv], [medical image classification], [Convolutional Neural Network, Transfer Learning, Chest X-ray, Pediatric Pneumonia, RegNet]
  - **authors:** Fatemeh Hosseinabadi, Mohammad Mojtaba Rohani
  - **institution:** Zahedan University of Medical Sciences, Guilan University of Medical Sciences
  - **link:** https://arxiv.org/pdf/2601.00041
  - **contributions:** 1. Evaluated and compared the performance of state-of-the-art CNN architectures (ResNetRS, RegNet, EfficientNetV2) for automated pediatric pneumonia diagnosis. 2. Applied transfer learning with ImageNet-pretrained weights to a curated dataset of pediatric chest X-rays to address data and expertise limitations. 3. Demonstrated that the RegNet model achieved the highest accuracy and sensitivity for this specific binary classification task.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbf67414c0b3072bcb906df1f0ca6e5942968a2374f2ac09a701ed20efb78f09_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes using transfer learning with deep convolutional neural networks to automate the diagnosis of pediatric pneumonia from chest X-ray images. The authors fine-tuned and compared three CNN models (ResNetRS, RegNet, EfficientNetV2) on a curated dataset, finding that RegNet performed best with 92.4% accuracy. The study concludes that such deep learning approaches can provide reliable diagnostic support, especially in settings with limited radiological expertise.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Deep Learning Approach for Pediatric Pneumonia Diagnosis] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[儿童肺炎诊断困难 / Pediatric Pneumonia Diagnosis is Challenging]
        C --> C1[使用预训练CNN进行迁移学习 / Use Pretrained CNNs with Transfer Learning]
        C --> C2[评估ResNetRS, RegNet, EfficientNetV2 / Evaluate ResNetRS, RegNet, EfficientNetV2]
        D --> D1[RegNet性能最佳 / RegNet Achieved Best Performance]
        D --> D2[准确率92.4%, 敏感度90.1% / Accuracy 92.4%, Sensitivity 90.1%]
    ```

- **[arXiv260105] Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes**
  - **tags:** [ai], [neural fields, signal processing], [Neural Radiance Fields (NeRF), EEG, brain-computer interfaces, signal reconstruction, continuous representation]
  - **authors:** Shahar Ain Kedem, Itamar Zimerman, Eliya Nachmani
  - **institution:** Ben Gurion University of the Negev, Tel Aviv University
  - **link:** https://arxiv.org/pdf/2601.00012
  - **code:** https://github.com/Shaharak88/neural-brain-fields
  - **contributions:** 1. Proposes a novel NeRF-inspired method to learn a continuous representation of brain activity from discrete EEG electrode data. 2. Enables rendering of EEG signals at unseen time steps and spatial electrode positions, including simulating non-existent electrodes. 3. Demonstrates that the reconstructed signals can be used to improve the performance of standard EEG processing networks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79dda8675c25fe2c8906136ddc20e55e51c835cb08bed2a4e02388b7dadc16da_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Neural Brain Fields, a method inspired by Neural Radiance Fields (NeRF) to model EEG data. It trains a neural network on a single EEG sample to produce a fixed-size weight vector that encodes the continuous neural activity, allowing for signal reconstruction at any time or scalp location. The approach effectively generates data for non-existent electrodes, which can enhance downstream EEG analysis tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>EEG data challenges: low SNR, variability, limited datasets"] --> P1["具体挑战/Challenges<br>Varying length, low SNR, participant differences"]
        Method["主要方法/Method<br>NeRF-inspired neural network for EEG"] --> M1["核心类比/Core Analogy<br>Viewpoints (NeRF) ↔ Electrodes (EEG)"]
        Method --> M2["技术实现/Technique<br>Train on single sample to get fixed weight vector"]
        Results["关键结果/Results<br>Enables continuous visualization & reconstruction"] --> R1["功能一/Capability 1<br>Render signal at unseen times/positions"]
        Results --> R2["功能二/Capability 2<br>Simulate non-existent electrodes"]
        Results --> R3["实证结果/Empirical Result<br>Improves standard EEG network performance"]
    ```

- **[arXiv260105] Modeling Day-Long ECG Signals to Predict Heart Failure Risk with Explainable AI**
  - **tags:** [ai], [health informatics], [deep learning, Holter ECG, explainable AI, time series analysis, risk prediction]
  - **authors:** Eran Zvuloni, Ronit Almog, Michael Glikson, Shany Brimer Biton, Ilan Green, Izhar Laufer, Offer Amir, Joachim A. Behar
  - **institution:** Technion - Israel Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.00014
  - **contributions:** 1. Developed DeepHHF, a deep learning model that uses full 24-hour single-lead ECG recordings for heart failure risk prediction, outperforming models using short segments and clinical scores. 2. Created and utilized the large-scale Technion-Leumit Holter ECG (TLHE) dataset, comprising 69,663 recordings from 47,729 patients collected over 20 years. 3. Provided explainability analysis showing the model focuses on arrhythmias and heart abnormalities, with key attention patterns during daytime hours (8 AM to 3 PM), linking model decisions to clinically relevant features.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfa3d768712a10f4b2d45732f0f8e0d64f70a07add2581bf81c12c996da11b77_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes DeepHHF, a deep learning model that analyzes 24-hour single-lead ECG data to predict the 5-year risk of heart failure. The model achieved an AUC of 0.80, outperforming baseline methods, and identified high-risk individuals with a two-fold increased chance of hospitalization or death. The study demonstrates the feasibility of using long-term, continuous ECG data and explainable AI for non-invasive and accessible heart failure risk prediction.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Modeling Day-Long ECG Signals to Predict Heart Failure Risk with Explainable AI] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[预测心力衰竭风险/Predict Heart Failure Risk]
        B --> B2[使用长时程ECG数据/Using Long-term ECG Data]
        C --> C1[深度学习模型DeepHHF/Deep Learning Model DeepHHF]
        C --> C2[分析24小时单导联ECG/Analyze 24-hour Single-lead ECG]
        C --> C3[可解释性分析/Explainability Analysis]
        D --> D1[AUC达到0.80/AUC of 0.80]
        D --> D2[识别高风险个体/Identify High-risk Individuals]
        D --> D3[关注心律失常与日间模式/Focus on Arrhythmias & Daytime Patterns]
    ```

- **[arXiv260105] Cuffless, calibration-free hemodynamic monitoring with physics-informed machine learning models**
  - **tags:** [other], [biomedical sensing and instrumentation], [electrical bioimpedance, physics-informed neural network, cuffless blood pressure, hemodynamic monitoring, wearable device]
  - **authors:** Henry Crandall, Tyler Schuessler, Filip Bělík, Albert Fabregas, Barry M. Stults, Alexandra Boyadzhiev, Huanan Zhang, Jim S. Wu, Aylin R. Rodan, Stephen P. Juraschek, Ramakrishna Mukkamala, Alfred K. Cheung, Stavros G. Drakos, Christel Hohenegger, Braxton Osting, Benjamin Sanchez
  - **institution:** University of Utah, University of Illinois Chicago
  - **link:** https://arxiv.org/pdf/2601.00081
  - **contributions:** 1. Developed a smartwatch device with real-time electrical bioimpedance (BioZ) sensing for cuffless hemodynamic monitoring. 2. Established a multiscale biophysical modeling framework to elucidate the relationship between BioZ and blood pressure, identifying key influencing parameters. 3. Created a signal-tagged physics-informed neural network that incorporates fluid dynamics principles for calibration-free estimation of blood pressure and blood velocity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ba7d002ced9d6e8a70d39b806f9e6640ce2f6db3f9aa85c2884e1ce15b38a91_w640_q70.webp
  - **Simple LLM Summary:** This paper develops a smartwatch-based system using electrical bioimpedance sensing and a physics-informed machine learning model to enable cuffless, calibration-free monitoring of blood pressure and blood velocity. The method addresses the theoretical limitations of existing wearable technologies by grounding the model in biophysical principles. The approach was successfully validated across diverse populations and settings, demonstrating its clinical feasibility.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Cuffless, Calibration-Free Hemodynamic Monitoring<br>无袖带、免校准血流动力学监测"] --> Problem
        Root --> Method
        Root --> Results
        Problem["现有无袖带设备依赖缺乏理论依据的方法，易受生理和实验混杂因素影响<br>Existing cuffless devices lack theoretical foundation and are vulnerable to confounders"]
        Method["开发具有实时生物电阻抗传感的智能手表，并使用结合流体动力学原理的信号标记物理信息神经网络<br>Developed smartwatch with real-time BioZ sensing and a signal-tagged physics-informed neural network"]
        Results["在健康个体和患者中成功测试，证明了该技术用于无袖带血压和血流速度监测的可行性<br>Successfully tested in healthy individuals and patients, demonstrating feasibility for cuffless BP and velocity monitoring"]
    ```

- **[arXiv260105] Detecting Unobserved Confounders: A Kernelized Regression Approach**
  - **tags:** [ai], [causal inference], [unobserved confounders, kernel regression, reproducing kernel hilbert space, single-environment, causal effect estimation]
  - **authors:** Yikai Chen, Yunxin Mao, Chunyuan Zheng, Hao Zou, Shanzhi Gu, Shixuan Liu, Yang Shi, Wenjing Yang, Kun Kuang, Haotian Wang
  - **institution:** National University of Defense Technology
  - **link:** https://arxiv.org/pdf/2601.00200
  - **contributions:** 1. Proposed a novel method (KRCD) for detecting unobserved confounders in nonlinear observational data under single-environment conditions, bridging a key gap in existing methods. 2. Provided theoretical guarantees, proving that in infinite samples, regression coefficients coincide if and only if no unobserved confounders exist, and that finite-sample differences converge to a zero-mean Gaussian distribution. 3. Demonstrated superior performance and computational efficiency over existing baselines through extensive experiments on synthetic benchmarks and the Twins dataset.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d34f526abd65dea1ab2c42ba3db6b7f0a13399cb09990eded28483079693cf4f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Kernel Regression Confounder Detection (KRCD), a method to detect unobserved confounders in nonlinear, single-environment observational data by comparing standard and higher-order kernel regressions. Theoretically, it proves key properties about the test statistic's behavior. Experiments show KRCD outperforms existing baselines in both detection performance and computational efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Detecting Unobserved Confounders: A Kernelized Regression Approach") --> Problem("核心问题/Problem: Detecting unobserved confounders in nonlinear, single-environment data")
        Root --> Method("主要方法/Method: Kernel Regression Confounder Detection (KRCD)")
        Root --> Results("关键结果/Results: Outperforms baselines, proven theoretical guarantees, high computational efficiency")
    ```

- **[arXiv260105] Neural Minimum Weight Perfect Matching for Quantum Error Codes**
  - **tags:** [mlsys], [others], [Quantum Error Correction, Minimum Weight Perfect Matching, Graph Neural Networks, Transformer, Hybrid Decoder]
  - **authors:** Yotam Peled, David Zenati, Eliya Nachmani
  - **institution:** Ben-Gurion University of the Negev
  - **link:** https://arxiv.org/pdf/2601.00242
  - **contributions:** 1. Proposed a hybrid decoder (NMWPM) that integrates GNNs and Transformers to predict dynamic edge weights for the MWPM algorithm. 2. Formulated a novel proxy loss function to enable end-to-end training through the non-differentiable MWPM algorithm. 3. Demonstrated a significant reduction in Logical Error Rate (LER) compared to standard baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e507723ea614845b9a945c6d086d7f6413ab64a2e5cbfa21b28ceaa1777ffa60_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a neural-enhanced decoder for quantum error correction called Neural Minimum Weight Perfect Matching (NMWPM). It uses a hybrid architecture of Graph Neural Networks and Transformers to predict dynamic edge weights for the classical MWPM decoder, trained with a novel proxy loss. The method significantly reduces the Logical Error Rate, showing the advantage of combining neural networks with classical algorithms.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Neural Minimum Weight Perfect Matching for Quantum Error Codes"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Quantum error correction requires effective decoding."]
        Method["主要方法/Method<br>Hybrid GNN+Transformer predicts weights for MWPM."]
        Results["关键结果/Results<br>Significant reduction in Logical Error Rate."]
    ```

- **[arXiv260105] Combining datasets with different ground truths using Low-Rank Adaptation to generalize image-based CNN models for photometric redshift prediction**
  - **tags:** [cv], [astronomical image analysis], [Low-Rank Adaptation (LoRA), photometric redshift, spectroscopic redshift, CNN, transfer learning]
  - **authors:** Vikram Seenivasan, Srinath Saikrishnan, Andrew Lizarraga, Jonathan Soriano, Bernie Boscoe, Tuan Do
  - **institution:** University of California, Los Angeles (UCLA), Southern Oregon University
  - **link:** https://arxiv.org/pdf/2601.00146
  - **contributions:** 1. Applied Low-Rank Adaptation (LoRA), a technique from large language models, to fine-tune CNN-based regression models for photometric redshift prediction in astrophysics. 2. Demonstrated that LoRA effectively combines datasets with different ground truths (photometric and spectroscopic redshifts) to improve model performance, outperforming traditional transfer learning with significantly reduced bias and scatter. 3. Showed that LoRA provides a computationally efficient middle ground between full model retraining and no retraining, enabling the leveraging of pre-trained models for data-sparse tasks in astrophysics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7c8dfd9d9ff319ca34f37730c3de7d103e6a39edc2131c3e4ca2711ce7fd7e3_w640_q70.webp
  - **Simple LLM Summary:** This paper applies Low-Rank Adaptation (LoRA) to fine-tune a CNN model for predicting galaxy redshifts, combining a less accurate but broad photometric redshift dataset with a more accurate but limited spectroscopic redshift dataset. The LoRA-based method outperforms traditional transfer learning, achieving lower bias and scatter, and offers a computationally efficient compromise between full retraining and no adaptation. The work demonstrates LoRA's utility for improving regression models in astrophysics by efficiently integrating datasets with different quality ground truths.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Combining datasets with different ground truths using LoRA for photometric redshift prediction] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 如何结合不同精度的红移数据集以提升CNN模型泛化能力？<br>How to combine redshift datasets of different accuracy to improve CNN model generalization?]
        C[主要方法/Method: 使用低秩适应(LoRA)在光谱红移数据集上微调基于测光红移训练的基模型<br>Using Low-Rank Adaptation (LoRA) to fine-tune a base model (trained on photometric redshifts) on a spectroscopic redshift dataset.]
        D[关键结果/Results: LoRA模型比传统迁移学习偏差和散射更小；提供全重训练与不训练之间的高效折中方案<br>LoRA model has less bias/scatter than traditional transfer learning; offers an efficient middle ground between full retraining and no retraining.]
    ```

- **[arXiv260105] Solving nonlinear subsonic compressible flow in infinite domain via multi-stage neural networks**
  - **tags:** [other], [computational fluid dynamics], [physics-informed neural networks, multi-stage training, unbounded domain, coordinate transformation, compressible potential equation]
  - **authors:** Xuehui Qian, Hongkai Tao, Yongji Wang
  - **institution:** Washington University in St. Louis, University of Notre Dame, Central South University, Stanford University, New York University
  - **link:** https://arxiv.org/pdf/2601.00342
  - **contributions:** 1. Proposes a novel PINN framework to solve the full nonlinear compressible potential equation in an infinite domain, overcoming a key limitation of traditional methods. 2. Introduces a coordinate transformation and embeds physical asymptotic constraints to address the unbounded-domain and convergence challenges inherent in standard PINNs. 3. Employs a Multi-Stage PINN (MS-PINN) approach to iteratively minimize residuals, achieving solution accuracy approaching machine precision.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/70afc10edc6a8a0b3606afe357472e00dfb9e25867b67948c402e19271e24608_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a novel framework using Physics-Informed Neural Networks (PINNs) to solve the full nonlinear subsonic compressible flow equation in an infinite domain. The method addresses domain and convergence challenges via coordinate transformation and a multi-stage training process. The results demonstrate high-fidelity solutions and quantify errors from traditional domain truncation and linearization, especially at higher Mach numbers.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Solving Nonlinear Subsonic Flow in Infinite Domain via MS-PINNs<br>基于多阶段神经网络求解无限域非线性亚音速流动] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br>传统方法在无限域求解非线性亚音速流动存在误差] --> P1[线性化或截断域引入误差<br>Linearization/Truncation Causes Error]
        Problem --> P2[标准PINNs在无限域收敛困难<br>Standard PINNs Struggle in Unbounded Domain]
        Method[主要方法/Method<br>提出新的PINN框架] --> M1[坐标变换处理无限域<br>Coordinate Transformation for Unbounded Domain]
        Method --> M2[网络嵌入物理渐近约束<br>Embed Physical Asymptotic Constraints]
        Method --> M3[多阶段训练提高精度<br>Multi-Stage Training for High Accuracy]
        Results[关键结果/Results<br>验证框架并量化误差] --> R1[在圆和椭圆几何上验证<br>Validated on Circular/Elliptical Geometries]
        Results --> R2[精度接近机器精度<br>Accuracy Approaches Machine Precision]
        Results --> R3[量化截断和线性化误差<br>Quantifies Truncation/Linearization Errors]
    ```

- **[arXiv260105] Interpretable Machine Learning for Quantum-Informed Property Predictions in Artificial Sensing Materials**
  - **tags:** [ai], [interpretable machine learning], [quantum-mechanical properties, CatBoost, explainable AI, binding features, electronic descriptors]
  - **authors:** Li Chen, Leonardo Medrano Sandonas, Shirong Huang, Alexander Croy, Gianaurelio Cuniberti
  - **institution:** TUD Dresden University of Technology, Friedrich Schiller University Jena
  - **link:** https://arxiv.org/pdf/2601.00503
  - **contributions:** 1. Development of the MORE-ML computational framework integrating quantum-mechanical data with machine learning for predicting sensing properties. 2. Expansion of the dataset to MORE-QX, providing extensive electronic binding features for body odor volatilome adsorption. 3. Demonstration that CatBoost models with explainable AI methods offer superior performance and mechanistic insights for rational receptor design.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e19c57b3a84042598ddfad14eee8131675c83c4b83807b904281ff6859ca8850_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of designing sensing materials for complex body odor detection by developing MORE-ML, a framework that uses quantum-mechanical property data of molecular building blocks as inputs to train tree-based ML models (like CatBoost) to predict binding features. The approach, validated on an expanded dataset, shows that CatBoost models perform well, especially on unseen compounds, and explainable AI methods identify key quantum properties influencing predictions, providing a foundation for rational design of artificial sensing materials.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Interpretable Machine Learning for Quantum-Informed Property Predictions in Artificial Sensing Materials"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Challenges in extending e-noses to complex body odor volatilome (BOV)"] --> P1["缺乏机理理解/Lack of mechanistic insight"]
        Method["主要方法/Method<br>MORE-ML framework"] --> M1["数据集/Dataset<br>Expand MORE-Q to MORE-QX"]
        Method --> M2["模型/Model<br>Tree-based ML (CatBoost) with QM descriptors"]
        Method --> M3["分析/Analysis<br>Explainable AI methods"]
        Results["关键结果/Results<br>CatBoost outperforms, provides design principles"] --> R1["高可转移性/High transferability"]
        Results --> R2["可解释的见解/Interpretable insights"]
    ```

- **[arXiv260105] AceFF: A State-of-the-Art Machine Learning Potential for Small Molecules**
  - **tags:** [ai], [machine learning interatomic potential], [TensorNet2, force field, drug-like compounds, charged states, DFT-level accuracy]
  - **authors:** Stephen E. Farr, Stefan Doerr, Antonio Mirarchi, Francesc Sabanes Zariquiey, Gianni De Fabritiis
  - **institution:** Acellera Labs, Universitat Pompeu Fabra, ICREA
  - **link:** https://arxiv.org/pdf/2601.00581
  - **code:** https://github.com/acellera/aceff-paper
  - **contributions:** 1. Introduces AceFF, a pre-trained MLIP specifically optimized for small molecule drug discovery. 2. Employs a refined TensorNet2 architecture trained on a comprehensive dataset of drug-like compounds to improve generalizability. 3. Achieves a balance of high-throughput inference speed and DFT-level accuracy, explicitly supporting essential medicinal chemistry elements and charged states.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbf03a6da5bff3c9952736adc7ba7fd161d48187c1623ade05d2174437fd823b_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces AceFF, a machine learning interatomic potential designed for small molecule drug discovery. It uses a refined TensorNet2 architecture trained on drug-like compounds to achieve DFT-level accuracy with fast inference. The authors demonstrate its state-of-the-art performance on organic molecules through rigorous benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AceFF: A State-of-the-Art Machine Learning Potential for Small Molecules] --> B[核心问题/Problem: MLIPs lack generalizability across diverse chemical spaces for drug discovery.]
        A --> C[主要方法/Method: Refined TensorNet2 architecture trained on comprehensive dataset of drug-like compounds.]
        A --> D[关键结果/Results: Achieves DFT-level accuracy with high-throughput speed, establishing a new SOTA for organic molecules.]
    ```

- **[arXiv260105] Generative Conditional Missing Imputation Networks**
  - **tags:** [ai], [missing data imputation], [Generative Neural Network, Missing Imputation, Multiple Imputation by Chained Equations, MCAR, MAR]
  - **authors:** George Sun, Yi-Hui Zhou
  - **institution:** North Carolina State University
  - **link:** https://arxiv.org/pdf/2601.00517
  - **contributions:** 1. Introduces the Generative Conditional Missing Imputation Networks (GCMI) with a theoretical foundation for MCAR and MAR mechanisms., 2. Enhances GCMI's robustness and accuracy by integrating a multiple imputation framework using chained equations., 3. Empirically demonstrates the superior performance of the proposed method compared to other leading imputation techniques.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c2fe27f0abc6f988f3b6e7f4d03378bacf1dab0ce55f725ea0b5d5b1991f7df_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Generative Conditional Missing Imputation Networks (GCMI), a generative method for imputing missing data. The method is theoretically grounded for MCAR and MAR scenarios and is further improved by integrating a multiple imputation approach. Experiments show it outperforms other state-of-the-art imputation techniques.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Generative Conditional Missing Imputation Networks] --> Problem(核心问题/Problem: Missing Data Imputation)
        Root --> Method(主要方法/Method: GCMI with Multiple Imputation)
        Root --> Results(关键结果/Results: Superior Performance)
        Problem --> SubP1(缺失机制/Missing Mechanisms: MCAR, MAR)
        Method --> SubM1(理论基础/Theoretical Foundation: GCMI)
        Method --> SubM2(增强框架/Enhanced Framework: Multiple Imputation by Chained Equations)
        Results --> SubR1(评估方式/Evaluation: Simulations & Benchmark Datasets)
    ```
