# 20251215-20251221 (cs.MA)

## 2025-12-18

- **[arXiv251218] SGEMAS: A Self-Growing Ephemeral Multi-Agent System for Unsupervised Online Anomaly Detection via Entropic Homeostasis**
  - **tags:** [mlsys], [others], [multi-agent system, structural plasticity, variational free energy, metabolic lagrangian, stochastic thermodynamics, unsupervised anomaly detection]
  - **authors:** Mustapha Hamdi
  - **institution:** InnoDeep
  - **link:** https://arxiv.org/pdf/2512.14708
  - **Simple LLM Summary:** This paper introduces SGEMAS, a bio-inspired multi-agent system that uses agent birth/death and a variational free energy objective to achieve energy-efficient, unsupervised anomaly detection in physiological signals. It validates the approach on the MIT-BIH Arrhythmia Database, showing that this physics-based, energy-constrained model can detect anomalies in a zero-shot setting, outperforming a standard autoencoder baseline.

- **[arXiv251218] Epistemic diversity across language models mitigates knowledge collapse**
  - **tags:** [mlsys], [llm training], [model collapse, epistemic diversity, AI ecosystem, self-training, distributed training]
  - **authors:** Damian Hodel, Jevin D. West
  - **institution:** University of Washington
  - **link:** https://arxiv.org/pdf/2512.15011
  - **Simple LLM Summary:** The paper investigates whether diversity across language models (an "AI ecosystem") can mitigate performance decay from training on model-generated data. It segments training data across multiple models and evaluates performance over self-training iterations. The main conclusion is that increased epistemic diversity mitigates knowledge collapse, but only up to an optimal level, with too few or too many models leading to poor performance.

## 2025-12-19

- **[arXiv251219] GLOW: Graph-Language Co-Reasoning for Agentic Workflow Performance Prediction**
  - **tags:** [mlsys], [llm inference], [graph neural networks, large language models, contrastive alignment, instruction tuning, graph-language co-reasoning]
  - **authors:** Wei Guan, Jian Cao, Jinyu Cai, Qiqi Cai, Jianqi Gao, See-Kiong Ng
  - **institution:** Shanghai Jiao Tong University, National University of Singapore, Shanghai University
  - **link:** https://arxiv.org/pdf/2512.15751
  - **Simple LLM Summary:** The paper proposes GLOW, a framework that combines Graph Neural Networks (GNNs) and instruction-tuned Large Language Models (LLMs) to predict the performance of Agentic Workflows by jointly modeling their graph structure and semantic logic. It uses a contrastive alignment strategy to refine the feature space. Experiments show GLOW outperforms existing methods in prediction accuracy and ranking utility on the FLORA-Bench benchmark.

- **[arXiv251219] Emergence: Overcoming Privileged Information Bias in Asymmetric Embodied Agents via Active Querying**
  - **tags:** [ai], [embodied ai], [Asymmetric Assistive Reasoning, active querying, Pull-based protocol, Privileged Information Bias, AI2-THOR, Leader-Follower dyad]
  - **authors:** Shaun Baek, Sam Liu, Joseph Ukpong
  - **institution:** Emory University
  - **link:** https://arxiv.org/pdf/2512.15776
  - **Simple LLM Summary:** This paper proposes an Asymmetric Assistive Reasoning framework in AI2-THOR to study how a knowledgeable "Leader" agent can guide a sensor-limited "Follower," finding that standard "Push-based" instruction fails due to Privileged Information Bias. It demonstrates that a "Pull-based" active querying protocol, where the Follower requests clarifications, significantly improves collaborative success by reducing grounding errors.

- **[arXiv251219] Evaluation of Generative Models for Emotional 3D Animation Generation in VR**
  - **tags:** [mlsys], [multi-modal inference], [generative models, speech-driven 3D animation, virtual reality (VR), user study, emotional arousal, reconstruction-based method, UV mapping, OpenXR, Blender]
  - **authors:** Kiran Chhatre, Renan Guarese, Andrii Matviienko, Christopher Peters
  - **institution:** KTH Royal Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.16081
  - **Simple LLM Summary:** This paper evaluates generative models for creating emotional 3D animations synchronized with speech in a VR environment using a user study. The main conclusion is that models explicitly modeling emotions achieve higher recognition accuracy than those focusing only on speech synchrony, but current models struggle with subtle emotions and underperform compared to reconstruction-based methods in facial expression quality.

- **[arXiv251219] Ev-Trust: A Strategy Equilibrium Trust Mechanism for Evolutionary Games in LLM-Based Multi-Agent Services**
  - **tags:** [mlsys], [others], [evolutionary game theory, replicator dynamics, trust mechanism, multi-agent systems, strategy equilibrium]
  - **authors:** Shiduo Yang, Jiye Wang, Jiayu Qin, Jianbin Li, Yu Wang, Yuanhe Zhao, Kenan Guo
  - **institution:** State Grid Corporation of China, North China Electric Power University
  - **link:** https://arxiv.org/pdf/2512.16167
  - **Simple LLM Summary:** The paper proposes Ev-Trust, a trust mechanism based on evolutionary game theory that integrates direct trust, indirect trust, and expected revenue to guide agent behavior in LLM-based multi-agent systems. Theoretical analysis proves the stability of evolutionary equilibria, and experiments show the approach reduces malicious strategies and increases collective revenue in open service interactions.

- **[arXiv251219] AMUSE: Audio-Visual Benchmark and Alignment Framework for Agentic Multi-Speaker Understanding**
  - **tags:** [mlsys], [multi-modal inference], [agentic reasoning, reward optimization, self-evaluation, selective parameter adaptation, benchmark evaluation]
  - **authors:** Sanjoy Chowdhury, Karren D. Yang, Xudong Liu, Fartash Faghri, Pavan Kumar Anasosalu Vasu, Oncel Tuzel, Dinesh Manocha, Chun-Liang Li, Raviteja Vemulapalli
  - **institution:** University of Maryland, College Park, Apple
  - **link:** https://arxiv.org/pdf/2512.16250
  - **Simple LLM Summary:** The paper introduces AMUSE, a benchmark for evaluating agentic multi-speaker understanding in audio-visual models, and RAFT, an alignment framework that uses reward optimization with multimodal self-evaluation. The main conclusion is that current models struggle with multi-speaker reasoning, but the proposed RAFT framework achieves significant accuracy improvements on the benchmark.

- **[arXiv251219] NDRL: Cotton Irrigation and Nitrogen Application with Nested Dual-Agent Reinforcement Learning**
  - **tags:** [ai], [reinforcement learning], [nested dual-agent reinforcement learning, water stress factor, nitrogen stress factor, dssat simulation, hierarchical decision making]
  - **authors:** Ruifeng Xu, Liang He
  - **institution:** Xinjiang University, Tsinghua University
  - **link:** https://arxiv.org/pdf/2512.16408
  - **Simple LLM Summary:** This paper proposes a Nested Dual-Agent Reinforcement Learning (NDRL) method to optimize cotton irrigation and nitrogen fertilization, using a parent agent for macro-action selection and a child agent incorporating quantified stress factors for daily dynamic control. The method, validated with DSSAT simulations using 2023-2024 field data, achieved increased simulated yield, irrigation water productivity, and nitrogen partial factor productivity compared to baselines. It provides a new approach for improving precision and sustainability in agricultural resource management.

- **[arXiv251219] Don't Guess, Escalate: Towards Explainable Uncertainty-Calibrated AI Forensic Agents**
  - **tags:** [mlsys], [multi-modal inference], [AI forensic agents, uncertainty-aware assessments, detector orchestration, multimedia forensics, authenticity verification]
  - **authors:** Giulia Boato, Andrea Montibeller, Edward Delp, Luisa Verdoliva, Daniele Miorandi
  - **institution:** Truebees, University of Trento, Purdue University, University of Naples Federico II
  - **link:** https://arxiv.org/pdf/2512.16614
  - **Simple LLM Summary:** The paper proposes a framework for AI forensic agents that autonomously orchestrate multiple forensic detectors to verify the authenticity of multimedia content. It argues that a holistic, uncertainty-calibrated approach is necessary to address the challenges posed by generative AI, moving beyond isolated, single-purpose detectors. The main conclusion is that such explainable, uncertainty-aware agents can improve the trustworthiness and interpretability of the forensic verification process.

- **[arXiv251219] Stackelberg Learning from Human Feedback: Preference Optimization as a Sequential Game**
  - **tags:** [ai], [preference optimization], [Stackelberg game, sequential-move game, inference-time refinement, preference models, Nash equilibrium, Bradley-Terry model]
  - **authors:** Barna Pásztor, Thomas Kleine Buening, Andreas Krause
  - **institution:** ETH Zürich
  - **link:** https://arxiv.org/pdf/2512.16626
  - **Simple LLM Summary:** This paper introduces Stackelberg Learning from Human Feedback (SLHF), a new framework that frames preference optimization as a sequential-move game between a Leader and a Follower policy. It demonstrates that this approach offers advantages in consistency, data sensitivity, and robustness to intransitive preferences compared to RLHF and NLHF. Experiments on large language models show that SLHF achieves strong alignment and enables inference-time refinements that transfer across model families.
