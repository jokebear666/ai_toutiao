---
slug: /daily/csma/20251229-20260104
---
# 20251229-20260104 (cs.MA)

## 2025-12-29

- **[arXiv251229] EcoNet: Multiagent Planning and Control Of Household Energy Resources Using Active Inference**
  - **tags:** [mlsys], [agent system], [active inference, multi-agent systems, home energy management systems (HEMS), distributed energy resources (DER), Bayesian inference]
  - **authors:** John C. Boik, Kobus Esterhuysen, Jacqueline B. Hynes, Axel Constant, Ines Hipolito, Mahault Albarracin, Alex B. Kiefer, Karl Friston
  - **institution:** VERSES, University of Sussex, Macquarie University, UCL (University College London)
  - **link:** https://arxiv.org/pdf/2512.21343
  - **contributions:** 1. Proposes EcoNet, a novel Bayesian framework for household and neighborhood energy management based on active inference. 2. Addresses the challenge of planning under uncertainty (e.g., weather, solar forecasts) while handling complex, conditional, and conflicting household goals. 3. Demonstrates the approach through simulations for multiagent planning and control of distributed energy resources.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b885d3c6c9f392a494063522c79cde9a59fead8ab6b04010259b6485f007cec8_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces EcoNet, a multiagent planning and control system for household energy resources using active inference, a Bayesian approach, to manage uncertainty and conflicting goals. The method aims to optimize energy use, costs, and emissions while maintaining comfort. Simulation results demonstrate its potential for improved energy management and coordination.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[EcoNet: 多智能体家庭能源规划与控制 / EcoNet: Multiagent Household Energy Planning & Control] --> B[核心问题 / Problem]
        A --> C[主要方法 / Method]
        A --> D[关键结果 / Results]
        B --> B1[复杂且冲突的家庭目标 / Complex & Conflicting Household Goals]
        B --> B2[决策存在不确定性 / Decision-making Under Uncertainty]
        C --> C1[基于主动推理的贝叶斯方法 / Active Inference-based Bayesian Approach]
        C --> C2[多智能体规划与控制 / Multiagent Planning & Control]
        D --> D1[模拟结果展示 / Simulation Results Presented]
        D --> D2[改善能源管理与协调 / Improved Energy Management & Coordination]
    ```

- **[arXiv251229] Multi-Agent LLM Committees for Autonomous Software Beta Testing**
  - **tags:** [se], [automated software testing], [multi-agent system, large language model, vision-language model, consensus voting, beta testing]
  - **authors:** Sumanth Bharadwaj Hachalli Karanam, Dhiwahar Adhithya Kennady
  - **institution:** New York University
  - **link:** https://arxiv.org/pdf/2512.21352
  - **contributions:** 1. A novel multi-agent committee framework that uses a three-round voting protocol for consensus-based decision-making in software testing. 2. Integration of vision-enabled LLMs and diverse testing personas to systematically explore and understand web application user interfaces. 3. Demonstrated significant performance improvements over single-agent baselines in task success, bug detection (F1 score), and security vulnerability coverage on established benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40573d0b1209c41e9825c09111398107cc51ee9d86c5234b50bea2515d0ab37f_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high cost of manual software beta testing and the limitations of single-agent LLM approaches by proposing a multi-agent committee framework. The method employs diverse, vision-enabled LLMs that collaborate through a structured voting protocol and persona-driven behavior to autonomously test web applications. The results show that this multi-agent approach significantly outperforms single-agent baselines in task success rates, bug detection, and security testing coverage, making it suitable for real-time CI/CD integration.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multi-Agent LLM Committees for Autonomous Software Beta Testing] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[手动测试成本高，单智能体LLM存在幻觉/Manual testing costly, single-agent LLM hallucinates]
        C --> C1[多智能体委员会与三轮投票协议/Multi-agent committee & three-round voting]
        C --> C2[视觉LLM与角色多样性/Vision LLMs & persona diversity]
        D --> D1[任务成功率89.5%，超越基线/Task success 89.5%, beats baseline]
        D --> D2[动作延迟0.71秒，适合CI/CD/Action latency 0.71s, suitable for CI/CD]
        D --> D3[覆盖8/10 OWASP漏洞类别/Covers 8/10 OWASP Top 10]
    ```

- **[arXiv251229] Developing a Fundamental Diagram for Urban Air Mobility Based on Physical Experiments**
  - **tags:** [other], [Transportation Systems, Robotics], [Fundamental Diagram, Urban Air Mobility, Traffic Flow Theory, Drone Control, Physical Experiments]
  - **authors:** Hang Zhou, Yuhui Zhai, Shiyu Shen, Yanfeng Ouyang, Xiaowei Shi, Xiaopeng
  - **institution:** University of Wisconsin-Madison, University of Illinois Urbana-Champaign, University of Wisconsin-Milwaukee
  - **link:** https://arxiv.org/pdf/2512.21425
  - **code:** https://github.com/CATS-Lab/UAM-FD
  - **contributions:** 1. Proposes a novel framework integrating theory and physical experiments to construct a Fundamental Diagram for Urban Air Mobility traffic. 2. Develops and validates the first UAM Fundamental Diagram using real-world physical test data from a reduced-scale drone testbed. 3. Creates and releases the UAMTra2Flow dataset containing simulation and physical test trajectory data for UAM traffic analysis.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fcb69b60c91e88b8ff8fdb72d4cfe7a72f7f1c82ac3f0ed8afd4f7ca60297d6_w640_q70.webp
  - **Simple LLM Summary:** This study addresses the lack of understanding of Urban Air Mobility (UAM) traffic flow by proposing a framework to construct its Fundamental Diagram (FD) through theoretical modeling and physical experiments using drones. The results show that classical ground traffic FD structures are applicable to UAM, but physical experiments reveal deviations from simulation, underscoring the need for experimental validation. The findings and a public dataset provide practical insights for future UAM system design.
  - **Mindmap:**

    ```mermaid
    graph TB
    Root("Developing a Fundamental Diagram for Urban Air Mobility Traffic Flow / 构建城市空中交通基本图")
    Root --> Problem("UAM交通流特性未知 / UAM Traffic Flow Poorly Understood")
    Root --> Method("理论分析+物理实验框架 / Theory + Physical Experiment Framework")
    Root --> Results("经典FD结构适用，实验验证关键 / Classical FD Applicable, Validation Crucial")
    ```

- **[arXiv251229] The AI Committee: A Multi-Agent Framework for Automated Validation and Remediation of Web-Sourced Data**
  - **tags:** [mlsys], [agent system], [multi-agent system, data validation, web-sourced data, LLM-powered agents, self-correction loop]
  - **authors:** Sunith Vallabhaneni, Thomas Berkane, Maimuna Majumder
  - **institution:** UC Berkeley, Harvard Medical School, Boston Children's Hospital
  - **link:** https://arxiv.org/pdf/2512.21481
  - **contributions:** 1. Introduces the AI Committee, a novel model-agnostic multi-agent framework for automating the validation and remediation of web-sourced data. 2. Leverages in-context learning, chain-of-thought reasoning, and a self-correction loop for complex semantic validation and data remediation without task-specific training. 3. Demonstrates the system's effectiveness and generalization across LLMs on real-world datasets, significantly outperforming baselines in completeness and precision.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/816c1ca8125d7f9edf185b93dea380612ff92bb0f45d615c40cfe0f38f364fdb_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of ensuring data validity when using LLM-powered web agents for data collection, which are prone to errors like hallucination. It proposes the AI Committee, a multi-agent system where specialized agents automate validation and remediation using various LLM capabilities. The system is shown to generalize across LLMs and significantly outperform baseline approaches on real-world datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["The AI Committee: A Multi-Agent Framework for Automated Validation and Remediation of Web-Sourced Data"] --> Problem["核心问题/Problem: LLM-powered web agents struggle with data validity (hallucination, omissions, misinterpretation)"]
        Root --> Method["主要方法/Method: AI Committee - a model-agnostic multi-agent system with specialized agents for validation and remediation"]
        Root --> Results["关键结果/Results: Generalizes across LLMs, outperforms baselines, achieves high completeness (78.7%) and precision (100%)"]
    ```

- **[arXiv251229] Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design**
  - **tags:** [mlsys], [agent system], [multi-agent platform, knowledge graph, physiologically based pharmacokinetic (PBPK) simulations, autonomous execution, human-in-the-loop]
  - **authors:** Takahide Suzuki, Kazuki Nakanishi, Takashi Fujiwara, Hideyuki Shimizu
  - **institution:** Institute of Science Tokyo, Kyoto University
  - **link:** https://arxiv.org/pdf/2512.21623
  - **contributions:** 1. Introduces OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine for drug design. 2. Features an architecture with specialized agents (Biologist, Chemist, Pharmacologist) governed by an Orchestrator, which actively execute simulations and reason over results to create a dynamic feedback loop for iterative optimization. 3. Democratizes therapeutic design by transforming drug discovery from a stochastic search into a programmable, evidence-based engineering discipline through the integration of autonomous execution with human guidance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbd4a841925fb9129111928c81fe29ac7016c26df168e9b4ca87c8782a692d5e_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of fragmented and passive tools in therapeutic discovery by proposing OrchestRA, a multi-agent platform where specialized AI agents autonomously execute and reason over biological, chemical, and pharmacological tasks. This creates a dynamic feedback loop for iterative drug candidate optimization, guided by human input. The conclusion is that this approach transforms drug discovery into a more programmable and evidence-based engineering process.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Fragmented domains & execution gap<br>AI as passive assistants]
        C[主要方法/Method<br>OrchestRA Multi-Agent Platform<br>Agents execute & reason<br>Human-in-the-loop]
        D[关键结果/Results<br>Autonomous discovery engine<br>Dynamic feedback loop<br>Programmable evidence-based design]
    ```

- **[arXiv251229] PERELMAN: Pipeline for scientific literature meta-analysis. Technical report**
  - **tags:** [mlsys], [agent system], [literature meta-analysis, agentic framework, domain knowledge elicitation, VLM agent, data extraction pipeline]
  - **authors:** Daniil Sherki, Daniil Merkulov, Alexandra Savina, Ekaterina Muravleva
  - **institution:** AI4Science Center (Sber), Skoltech
  - **link:** https://arxiv.org/pdf/2512.21727
  - **contributions:** 1. An agentic framework (PERELMAN) designed to extract specific information from a large corpus of scientific articles for meta-analyses. 2. A method to elicit and reuse domain knowledge (target variables, criteria, units) through structured dialogue with an expert to guide coordinated extraction agents. 3. Validation of the system by reproducing a meta-analysis of Li-ion cathode properties, demonstrating potential to reduce preparation time from months to minutes.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2a664cd7177015584e06153b1c167ca9dfb0cf35e5e253d01e48cbe01e9d595_w640_q70.webp
  - **Simple LLM Summary:** The paper presents PERELMAN, an agentic pipeline that extracts structured information from scientific literature for meta-analysis by first eliciting domain knowledge from an expert and then using coordinated agents to process text, tables, and figures. It was validated by reproducing a meta-analysis on NMC811 cathode material. The approach aims to drastically reduce the time required for large-scale literature reviews.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[PERELMAN: 科学文献元分析管道 / Pipeline for Scientific Literature Meta-Analysis] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题：从大量异构科学文献中可靠提取信息以支持元分析 / Core Problem: Reliably extract information from heterogeneous scientific literature for meta-analysis]
        Method[主要方法：基于专家对话获取领域知识，协调智能体从文本、表格、图像中提取证据 / Method: Elicit domain knowledge via expert dialogue, coordinate agents to extract evidence from text, tables, figures]
        Results[关键结果：在NMC811材料元分析任务上验证，可将准备时间从数月缩短至分钟 / Results: Validated by reproducing NMC811 meta-analysis, reducing preparation time from months to minutes]
    ```

- **[arXiv251229] Multi-agent Adaptive Mechanism Design**
  - **tags:** [ai], [mechanism design], [distributionally robust optimization, online learning, incentive compatibility, adaptive mechanism, regret analysis]
  - **authors:** Qiushi Han, David Simchi-Levi, Renfei Tan, Zishuo Zhao
  - **institution:** Massachusetts Institute of Technology, University of Illinois Urbana-Champaign
  - **link:** https://arxiv.org/pdf/2512.21794
  - **contributions:** 1. Introduces DRAM, a novel framework combining mechanism design and online learning to handle unknown agent beliefs. 2. Provides theoretical guarantees of high-probability truthfulness and achieves optimal $\tilde\{O\}(\sqrt\{T\})$ cumulative regret with a matching lower bound. 3. Generalizes the framework (DRAM+) to support plug-in estimators, structured priors, and delayed feedback.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c99ece7d8b60855735e1eee48c51256eacf5f3997d56ced3396434f12a30ad44_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of designing a truthful mechanism when the principal has no prior knowledge of agents' beliefs. It proposes the Distributionally Robust Adaptive Mechanism (DRAM), which iteratively learns beliefs and updates a robust optimization problem to minimize cost while ensuring truthfulness. The mechanism is proven to achieve optimal regret, and the framework is the first to maintain truthfulness under these general learning conditions.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multi-agent Adaptive Mechanism Design] --> B[核心问题/Problem: Elicit truthful reports with no prior knowledge of agent beliefs]
        A --> C[主要方法/Method: Distributionally Robust Adaptive Mechanism (DRAM)]
        A --> D[关键结果/Results: Guaranteed truthfulness & optimal $\tilde{O}(\sqrt{T})$ regret]
    ```

- **[arXiv251229] Analyzing Code Injection Attacks on LLM-based Multi-Agent Systems in Software Development**
  - **tags:** [mlsys], [agent system], [multi-agent system, code injection, threat model, security analysis agent, LLM]
  - **authors:** Brian Bowers, Smita Khapre, Jugal Kalita
  - **institution:** Loyola Marymount University, University of Colorado Colorado Springs
  - **link:** https://arxiv.org/pdf/2512.21818
  - **contributions:** 1. Proposed and evaluated LLM-based multi-agent architectures (coder, coder-tester, coder-reviewer-tester) for software implementation, assessing their accuracy, attack resilience, and efficiency. 2. Introduced a security analysis agent to mitigate code injection attacks, showing it improves resilience while recovering lost efficiency. 3. Demonstrated a vulnerability in the security analysis agent where embedding poisonous few-shot examples in injected code drastically increases attack success rate.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43b214bf9d80e3aaa2e2412bbf3ea1727db748cf0f33f818d81076fa53654f97_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the vulnerability of LLM-based multi-agent systems in software development to code injection attacks. It proposes and evaluates several agent architectures, finding that adding a security analysis agent improves resilience and efficiency. However, the study concludes that even this security agent can be compromised by advanced attacks using poisoned few-shot examples, significantly increasing the attack success rate.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Analyzing Code Injection Attacks on LLM-based Multi-Agent Systems] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: LLM-based multi-agent systems for software development are vulnerable to code injection attacks] --> Problem_Detail[缺乏人在环/No Human-in-the-Loop]
        Method[主要方法/Method: Propose and evaluate multi-agent architectures, then add a security analysis agent] --> Method_Arch[架构评估/Architecture Evaluation: coder, coder-tester, coder-reviewer-tester]
        Method --> Method_Sec[安全代理/Security Agent: Add a security analysis agent for mitigation]
        Results[关键结果/Results: Security agent improves resilience but is itself vulnerable to advanced attacks] --> Results_Resilience[韧性提升/Improved Resilience: coder-reviewer-tester is more resilient]
        Results --> Results_Vulnerability[新漏洞/New Vulnerability: Poisonous few-shot examples increase attack success to 71.95%]
    ```

- **[arXiv251229] MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting**
  - **tags:** [mlsys], [agent system], [multi-agent framework, bias mitigation, financial forecasting, LLM integration, modular design]
  - **authors:** Marc S. Montalvo, Hamed Yaghoobian
  - **institution:** Rochester Institute of Technology, Muhlenberg College
  - **link:** https://arxiv.org/pdf/2512.21878
  - **contributions:** 1. Introduces MASFIN, a modular multi-agent framework that integrates LLMs with structured financial metrics and unstructured news for decomposed financial reasoning. 2. Embeds explicit bias-mitigation protocols (e.g., against survivorship and hindsight bias) to enhance transparency and robustness. 3. Demonstrates practical effectiveness through an eight-week evaluation showing outperformance of major market benchmarks, highlighting the promise of bias-aware generative AI in finance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/351cdc3ccfe2b2d987cf53c8380e153fe4b93de0def6253cbc7b2feb4af093fe_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces MASFIN, a multi-agent system that combines LLMs with financial data and news to perform decomposed reasoning and forecasting while mitigating biases. In an eight-week evaluation, it achieved a 7.33% cumulative return, outperforming benchmarks like the S&P 500 in most weeks, though with higher volatility. The results show the potential of modular, bias-aware AI frameworks for transparent and reproducible quantitative finance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统量化方法易受生存偏差影响/Traditional quantitative methods vulnerable to survivorship bias]
        B --> B2[AI方法在信号集成和可复现性上存在挑战/AI approaches struggle with signal integration and reproducibility]
        C --> C1[模块化多智能体框架/Modular multi-agent framework]
        C --> C2[集成LLM与结构化指标和非结构化新闻/Integrates LLMs with structured metrics and unstructured news]
        C --> C3[嵌入偏差缓解协议/Embeds bias-mitigation protocols]
        D --> D1[8周累计回报7.33%/7.33% cumulative return over eight weeks]
        D --> D2[在6/8周中超越基准/Outperformed benchmarks in six of eight weeks]
        D --> D3[波动性较高/Higher volatility]
    ```

## 2025-12-30

- **[arXiv251230] ReCollab: Retrieval-Augmented LLMs for Cooperative Ad-hoc Teammate Modeling**
  - **tags:** [ai], [multi-agent reinforcement learning], [ad-hoc teamwork, retrieval-augmented generation, teammate modeling, Overcooked]
  - **authors:** Conor Wallace, Umer Siddique, Yongcan Cao
  - **institution:** University of Texas at San Antonio
  - **link:** https://arxiv.org/pdf/2512.22129
  - **contributions:** 1. Introduces COLLAB, a novel language-based framework that uses LLMs as behavioral world models to classify unseen teammate types in ad-hoc teamwork. 2. Extends COLLAB to RECOLLAB by incorporating retrieval-augmented generation (RAG) with exemplar trajectories to stabilize inference and improve adaptation. 3. Demonstrates empirically in the Overcooked environment that RECOLLAB achieves Pareto-optimal trade-offs between classification accuracy and episodic return, highlighting the value of retrieval grounding.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/078fe396118022eaa0d391e86072d08c5b6617a143aba1478029ca3185af6472_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of ad-hoc teamwork, where an agent must collaborate with unseen teammates. It proposes RECOLLAB, a framework that uses retrieval-augmented LLMs to model and classify teammate behavior from short interaction traces. The method is shown to effectively improve adaptation and coordination in the cooperative Overcooked environment.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("RECOLLAB: Retrieval-Augmented LLMs for Cooperative Ad-hoc Teammate Modeling") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("Ad-hoc Teammate Modeling<br>Ad-hoc队友建模")
        Problem --> P2("Brittle Conventional Models<br>传统模型脆弱性")
        Method --> M1("COLLAB: LLM-based Framework<br>基于LLM的框架")
        Method --> M2("RECOLLAB: Adds RAG<br>增加RAG检索")
        Results --> R1("Improved Adaptation<br>提升适应性")
        Results --> R2("Pareto-Optimal Trade-offs<br>帕累托最优权衡")
    ```

- **[arXiv251230] SoDA: An Efficient Interaction Paradigm for the Agentic Web**
  - **tags:** [mlsys], [agent system], [Sovereign Digital Avatar, Intent-Permission Handshake, orthogonal decoupling, A2A protocols, dual-factor adaptive routing]
  - **authors:** Zicai Cui, Zhouyuan Jian, Weiwen Liu, Weinan Zhang
  - **institution:** Shanghai Jiao Tong University, Shanghai Innovation Institute
  - **link:** https://arxiv.org/pdf/2512.22135
  - **contributions:** 1. Proposes a user sovereignty interaction paradigm for the Agentic Web, decoupling memory from application logic to break data lock-in and shifting from explicit instruction to implicit intent alignment to reduce cognitive load. 2. Implements the paradigm via the Sovereign Digital Avatar (SoDA) with an orthogonal decoupling design of storage, computation, and interaction, establishing the principle of "data as a persistent asset, model as a transient tool". 3. Designs an Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor adaptive routing for active risk governance in zero-trust environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes the Sovereign Digital Avatar (SoDA), a new interaction paradigm for the Agentic Web that decouples user memory from applications and uses intent alignment to reduce cognitive load. It introduces an architecture with orthogonal decoupling and a secure handshake mechanism for zero-trust environments. Empirical results show it significantly reduces token consumption and user cognitive load compared to existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SoDA: An Efficient Interaction Paradigm for the Agentic Web] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[数据锁定/Data Lock-in]
        B --> B2[认知过载/Cognitive Overload]
        C --> C1[主权数字化身/Sovereign Digital Avatar (SoDA)]
        C --> C2[正交解耦设计/Orthogonal Decoupling Design]
        C --> C3[意图-权限握手机制/Intent-Permission Handshake Mechanism]
        D --> D1[降低令牌消耗/Reduces Token Consumption by 27-35%]
        D --> D2[降低认知负载/Reduces Cognitive Load by 72% vs RAG, 88% vs Manual]
    ```

- **[arXiv251230] Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments**
  - **tags:** [mlsys], [agent system], [serverless computing, GPU resource allocation, workload scheduling, multi-agent systems, collaborative reasoning]
  - **authors:** Guilin Zhang, Wulan Guo, Ziqi Tan
  - **institution:** George Washington University
  - **link:** https://arxiv.org/pdf/2512.22149
  - **contributions:** 1. An adaptive GPU resource allocation framework for multi-agent systems in serverless environments that dynamically adjusts resources based on workload characteristics, agent priorities, and minimum requirements. 2. An O(N) complexity algorithm for real-time adaptation, enabling millisecond-scale reallocation to handle dynamic workload fluctuations. 3. A comprehensive evaluation demonstrating the framework's superiority over static and round-robin strategies, achieving 85% latency reduction while maintaining throughput and improving GPU utilization and cost-efficiency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2fe7e30427c00e4689f161fb9912d4d11cc091ed6dd1dae3c4ea2c5805084e3b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes an adaptive GPU resource allocation framework to address the challenge of efficiently deploying heterogeneous multi-agent AI systems on serverless platforms. The method dynamically allocates resources using a real-time algorithm to handle varying computational demands and workload fluctuations. The results show it significantly reduces latency compared to baseline schedulers while maintaining throughput, offering a cost-effective solution for serverless multi-agent deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments<br/>面向无服务器环境的多智能体协同推理的自适应GPU资源分配"] --> Problem["核心问题/Problem<br/>Heterogeneous agent workloads & dynamic demands on serverless GPU platforms<br/>多智能体工作负载异构与无服务器GPU平台动态需求"]
        Root --> Method["主要方法/Method<br/>Adaptive GPU resource allocation framework with O(N) real-time algorithm<br/>基于O(N)实时算法的自适应GPU资源分配框架"]
        Root --> Results["关键结果/Results<br/>85% latency reduction vs. round-robin, maintains throughput<br/>相比轮询调度延迟降低85%，保持吞吐量"]
    ```

- **[arXiv251230] Practical challenges of control monitoring in frontier AI deployments**
  - **tags:** [sec], [ai security], [control monitoring, oversight latency, safety case, scheming agents, incremental attacks]
  - **authors:** David Lindner, Charlie Griffin, Tomek Korbak, Roland S. Zimmermann, Geoffrey Irving, Sebastian Farquhar, Alan Cooney
  - **institution:** Google DeepMind, UK AI Safety Institute, University of Oxford
  - **link:** https://arxiv.org/pdf/2512.22154
  - **contributions:** 1. Analysis of real-world deployment dynamics (parallelism, latency, incremental attacks, partial incrimination) for control monitoring, 2. Proposal and comparison of three monitoring protocols (synchronous, semi-synchronous, asynchronous) with different latency-safety trade-offs, 3. Introduction of a high-level safety case sketch as a tool for analyzing and comparing monitoring protocols, applied to four case studies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7cfc3d08c169a23a56cd0a16a1471c5bceacb1b76913f7079f51b7024f030d1_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the practical challenges of scaling automated control monitors for overseeing frontier AI agents in real-world deployments. It proposes and compares three monitoring protocols (synchronous, semi-synchronous, asynchronous) with different latency-safety trade-offs and introduces a safety case sketch as an analytical tool. The analysis identifies oversight, latency, and recovery as key challenges, explored through four case studies of potential AI attacks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Practical challenges of control monitoring in frontier AI deployments<br>前沿AI部署中控制监控的实际挑战") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("现实部署的动态<br>Real-world Deployment Dynamics")
        P1 --> P1_1("并行实例<br>Parallel Instances")
        P1 --> P1_2("监督延迟<br>Oversight Latency")
        P1 --> P1_3("增量攻击<br>Incremental Attacks")
        P1 --> P1_4("部分归责<br>Partial Incrimination")
        Method --> M1("监控协议<br>Monitoring Protocols")
        M1 --> M1_1("同步监控<br>Synchronous")
        M1 --> M1_2("半同步监控<br>Semi-synchronous")
        M1 --> M1_3("异步监控<br>Asynchronous")
        Method --> M2("安全案例草图<br>Safety Case Sketch")
        Results --> R1("识别核心挑战<br>Identified Core Challenges")
        R1 --> R1_1("监督<br>Oversight")
        R1 --> R1_2("延迟<br>Latency")
        R1 --> R1_3("恢复<br>Recovery")
        Results --> R2("案例研究应用<br>Case Studies Application")
    ```

- **[arXiv251230] Solving Multi-Agent Multi-Goal Path Finding Problems in Polynomial Time**
  - **tags:** [ai], [multi-agent path finding], [multi-agent path finding, vehicle routing, polynomial-time algorithm, conflict resolution, assignment problem]
  - **authors:** Stefan Edelkamp
  - **institution:** Charles University
  - **link:** https://arxiv.org/pdf/2512.22171
  - **contributions:**  1. Proposes a polynomial-time algorithm for solving discrete multi-agent multi-goal path finding (CMAPF) problems with node and edge conflicts, which is unexpected given the NP-hardness of traditional vehicle routing. 2. Introduces a planner that autonomously finds and updates the assignment of multiple goals to agents, contrasting with regular MAPF which uses fixed assignments. 3. Develops conflict resolution strategies including global assignment to reduce conflicts, and local methods like "ants-on-the-stick," local assignment, path interleaving, and destination clearing.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e9267701cf1d96333033d8663590f3b652040a494de98cd10ba5a86ede709d3b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the multi-agent multi-goal path finding (CMAPF) problem where agents in graphs must be assigned and routed to multiple goals. It presents a polynomial-time algorithm for discrete variants with conflicts, implemented in a planner that autonomously handles goal assignment and resolves conflicts. The main conclusion is that efficient, conflict-free solutions can be achieved in polynomial time, challenging the typical NP-hard complexity of vehicle routing.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Solving Multi-Agent Multi-Goal Path Finding Problems in Polynomial Time] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[为多智能体规划多目标无冲突路径/Plan multi-goal conflict-free paths for multi-agent]
    C --> C1[自主目标分配与冲突解决策略/Autonomous goal assignment & conflict resolution]
    D --> D1[离散问题可在多项式时间内解决/Discrete problems solvable in polynomial time]
    ```

- **[arXiv251230] SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents**
  - **tags:** [mlsys], [agent system], [self-verifying agent, proactive evidence seeking, LLM-as-a-Judge, 3C Principles, agentic reinforcement learning]
  - **authors:** Shaofei Cai, Yulei Qin, Haojia Lin, Zihan Xu, Gang Li, Yuchen Shi, Zongyi Li, Yong Mao, Siqi Cai, Xiaoyu Tan, Yitao Liang, Ke Li, Xing Sun
  - **institution:** Peking University, Tencent
  - **link:** https://arxiv.org/pdf/2512.22322
  - **code:** https://huggingface.co/collections/yolay/smartsnap
  - **contributions:** 1. Proposed SmartSnap, a paradigm shift from passive, post-hoc task verification to proactive, in-situ self-verification by the agent itself. 2. Introduced the Self-Verifying Agent, a new agent type with dual missions to complete tasks and prove accomplishment via curated snapshot evidences guided by 3C Principles (Completeness, Conciseness, Creativity). 3. Demonstrated that the SmartSnap paradigm enables scalable training of LLM-driven agents, achieving significant performance gains (up to 26.08% and 16.66%) on mobile tasks and competitive results against larger models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the scalability bottleneck in agentic RL caused by costly and unreliable post-hoc task verification. It proposes SmartSnap, a paradigm where agents proactively seek minimal, decisive snapshot evidence to prove task completion during execution, guided by 3C Principles. Experiments show this approach significantly improves agent performance and enables scalable training, achieving competitive results with much larger models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Passive, post-hoc verification is costly and unreliable for agentic RL]
        C[主要方法/Method: Proactive self-verification via Self-Verifying Agent and 3C Principles]
        D[关键结果/Results: Performance gains up to 26.08%; competitive with larger models]
    ```

- **[arXiv251230] AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents**
  - **tags:** [mlsys], [agent system], [reproducibility, dependency management, code generation, large language models, empirical study]
  - **authors:** Bhanu Prakash Vangala, Ali Adibifar, Tanu Malik, Ashish Gehani
  - **institution:** University of Missouri, SRI International
  - **link:** https://arxiv.org/pdf/2512.22387
  - **contributions:** 1. Introduces a three-layer dependency framework (claimed, working, runtime) to quantify the execution reproducibility of LLM-generated code. 2. Conducts an empirical study evaluating three state-of-the-art LLM coding agents across 300 projects in three programming languages, revealing low out-of-the-box execution success rates. 3. Discovers a significant hidden dependency problem, with an average 13.5x expansion from declared to actual runtime dependencies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the reproducibility of code generated by LLM-based coding agents. It proposes a three-layer dependency framework and conducts an empirical study on 300 projects, finding that only 68.3% execute successfully out-of-the-box and that actual runtime dependencies are significantly larger than declared ones. The study concludes that AI-generated code currently suffers from major reproducibility issues due to dependency gaps and code generation errors.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents"] --> Problem["核心问题/Problem: Is AI-generated code reproducible?"]
        Root --> Method["主要方法/Method: Empirical study using a three-layer dependency framework on 300 projects from 3 LLM agents."]
        Root --> Results["关键结果/Results: Low out-of-the-box execution rate (68.3%) and large hidden dependencies (13.5x expansion)."]
    ```

- **[arXiv251230] Bugs with Features: Vision-Based Fault-Tolerant Collective Motion Inspired by Nature**
  - **tags:** [ai], [swarm robotics], [collective motion, visual perception, fault-tolerance, intermittent locomotion, distance estimation]
  - **authors:** Peleg Shefi, Amir Ayali, Gal A. Kaminka
  - **institution:** Bar Ilan University, Tel Aviv University
  - **link:** https://arxiv.org/pdf/2512.22448
  - **contributions:** 1. A robust distance estimation method for vision-based swarms that combines perceived horizontal and vertical sizes of neighbors. 2. The introduction of intermittent locomotion as a mechanism for reliably detecting faulty peers that disrupt swarm motion. 3. A fault-avoidance strategy that is robust to errors in classifying robots as faulty, improving swarm resilience in both Avoid-Attract and Alignment-based models.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/456a9beab88e762dd3d3dfcafbb4d0007f77b2154cd9a7b657dcdf5df21407db_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the brittleness of artificial swarms using vision by proposing two bio-inspired mechanisms. It introduces a robust visual distance estimation method and an intermittent locomotion strategy for fault detection and avoidance. Extensive simulations show these techniques dramatically improve swarm resilience across different collective motion models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Bugs with Features: Vision-Based Fault-Tolerant Collective Motion Inspired by Nature] --> B[核心问题/Problem: Artificial swarms are brittle with vision sensing due to ambiguities and information loss.]
        A --> C[主要方法/Method: 1. Robust visual distance estimation. 2. Intermittent locomotion for fault detection.]
        A --> D[关键结果/Results: Dramatic improvement in swarm resilience across Avoid-Attract and Alignment models.]
    ```

- **[arXiv251230] Hierarchical Pedagogical Oversight: A Multi-Agent Adversarial Framework for Reliable AI Tutoring**
  - **tags:** [mlsys], [agent system], [adversarial reasoning, multi-agent system, pedagogical oversight, hierarchical framework, low-compute inference]
  - **authors:** Saisab Sadhu, Ashim Dhor
  - **institution:** Indian Institute of Science Education and Research Bhopal
  - **link:** https://arxiv.org/pdf/2512.22496
  - **contributions:** 1. Introduces Hierarchical Pedagogical Oversight (HPO), a novel multi-agent adversarial framework designed to improve the reliability of AI tutoring by separating pedagogical generation from evaluation. 2. Adapts structured adversarial synthesis to educational assessment, enforcing a dialectical debate between opposing pedagogical critics to mitigate sycophancy and superficial consensus. 3. Demonstrates that the adversarial protocol enables a small 8B-parameter model to outperform GPT-4o on pedagogical oversight while using significantly fewer computational resources.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67b6c2853ea8b40662f9788f9062b5488d7ec541a754a445a856888b9fb9300c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of unreliable AI tutors (LLMs) that often validate incorrect student answers. It proposes the Hierarchical Pedagogical Oversight (HPO) framework, which uses a structured multi-agent adversarial debate to assess tutoring quality. The main conclusion is that this adversarial approach enables a much smaller model to outperform a much larger one (GPT-4o) on a pedagogical reasoning benchmark, establishing it as a critical mechanism for reliable, low-compute oversight.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Hierarchical Pedagogical Oversight<br>分层教学监督框架] --> B[Problem: LLMs as tutors are unreliable<br>问题: LLM导师不可靠]
        A --> C[Method: Multi-Agent Adversarial Framework<br>方法: 多智能体对抗框架]
        A --> D[Results: 8B model beats GPT-4o, low-compute<br>结果: 8B模型超越GPT-4o, 低计算]
    ```

- **[arXiv251230] The Wisdom of Deliberating AI Crowds: Does Deliberation Improve LLM-Based Forecasting?**
  - **tags:** [ai], [forecasting], [large language models, deliberation, multi-agent, forecasting accuracy, log loss]
  - **authors:** Paul Schneider, Amalie Schramm
  - **institution:** PRIORB
  - **link:** https://arxiv.org/pdf/2512.22625
  - **contributions:** 1. Introduces and tests a structured deliberation intervention for LLMs, where models review each other's forecasts before updating, as a novel method for improving AI-based forecasting. 2. Systematically evaluates the intervention across four distinct scenarios (diverse/homogeneous models with distributed/shared information), identifying that accuracy improvement is specific to diverse models with shared information. 3. Provides empirical evidence that deliberation can be a viable strategy for improving LLM forecasting, while also revealing the unexpected finding that providing additional contextual information did not improve accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0685f113c8c22bd110f615c357b7de1633adf1104f67be97e690bae6bee70345_w640_q70.webp
  - **Simple LLM Summary:** This study investigates whether allowing large language models (LLMs) to deliberate by reviewing each other's forecasts improves their forecasting accuracy. The method was tested on 202 binary questions across different model group compositions and information-sharing scenarios. The main conclusion is that deliberation significantly improves accuracy for diverse LLM groups with shared information, but not for homogeneous groups, suggesting it as a viable strategy for enhancing LLM-based forecasting.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["The Wisdom of Deliberating AI Crowds: Does Deliberation Improve LLM-Based Forecasting?"]
        Root --> Problem["核心问题/Problem<br>Does structured deliberation improve LLM forecasting accuracy?"]
        Root --> Method["主要方法/Method<br>LLMs review each other's forecasts before updating across four scenarios."]
        Root --> Results["关键结果/Results<br>Accuracy improved for diverse models with shared info; no benefit for homogeneous groups."]
    ```

- **[arXiv251230] MARPO: A Reflective Policy Optimization for Multi Agent Reinforcement Learning**
  - **tags:** [ai], [multi-agent reinforcement learning], [reflective policy optimization, asymmetric clipping, sample efficiency]
  - **authors:** Cuiling Wu, Yaozhong Gan, Junliang Xing, Ying Fu
  - **institution:** Beijing Institute of Technology, QiYuan Lab
  - **link:** https://arxiv.org/pdf/2512.22832
  - **contributions:** 1. Proposes a reflection mechanism that leverages subsequent trajectories to enhance sample efficiency. 2. Introduces an asymmetric clipping mechanism derived from KL divergence to dynamically adjust the clipping range for improved training stability. 3. Validates the proposed MARPO framework on complex multi-agent benchmarks, demonstrating superior performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f4bb8bd99df87d3fa5d6dae0b3405e01825ac1c612b07fbdd5519ae2b33ce19_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes MARPO, a new multi-agent reinforcement learning method to address sample inefficiency. It introduces a reflection mechanism to use trajectory information and an asymmetric clipping mechanism for stable training. The method is shown to outperform existing approaches in standard multi-agent environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[MARPO: A Reflective Policy Optimization for Multi-Agent Reinforcement Learning] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Sample inefficiency in MARL] --> P1[挑战/Challenge: High interaction cost]
        Method[主要方法/Method: MARPO Framework] --> M1[反射机制/Reflection Mechanism: Leverages subsequent trajectories]
        Method --> M2[非对称裁剪/Asymmetric Clipping: KL-based dynamic adjustment]
        Results[关键结果/Results: Outperforms other methods] --> R1[评估/Evaluation: Classic multi-agent environments]
    ```

- **[arXiv251230] Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks**
  - **tags:** [sec], [blockchain security, IoT security, adversarial machine learning], [Fully Homomorphic Encryption, Attribute-Based Access Control, Multi-Agent Reinforcement Learning, Byzantine Fault Tolerance, Trust-Based Consensus]
  - **authors:** Soham Padia, Dhananjay Vaidya, Ramchandra Mangrulkar
  - **institution:** Northeastern University, Dwarkadas J. Sanghvi College of Engineering
  - **link:** https://arxiv.org/pdf/2512.22860
  - **contributions:** 1. Proposes a novel trust-based delegated consensus framework for blockchain IoT that integrates Fully Homomorphic Encryption (FHE) with Attribute-Based Access Control (ABAC) for privacy-preserving policy evaluation. 2. Systematically compares the performance of three reinforcement learning approaches (RL, DRL, MARL) against five distinct and sophisticated adversarial attack families. 3. Empirically demonstrates that Multi-Agent RL (MARL) provides superior defense against collusive attacks and identifies the catastrophic vulnerability of all learning agents to Time-Delayed Poisoning (sleeper) attacks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373f990d6c218afb4f9e660bb84fd86dc8e9d7006d2b7bdef3d956a991960bff_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses securing blockchain-enabled IoT networks by proposing a trust-based consensus framework that combines privacy-preserving techniques (FHE and ABAC) with learning-based defenses. It compares RL, DRL, and MARL against five attack types, finding MARL most effective against collusive attacks but revealing that all methods are highly vulnerable to time-delayed poisoning attacks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Adaptive Trust Consensus for Blockchain IoT<br/>区块链物联网自适应信任共识"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["Securing Blockchain IoT Against Attacks<br/>保护区块链物联网免受攻击"] --> A1["Naive Malicious Attack (NMA)<br/>简单恶意攻击"]
        Problem --> A2["Collusive Rumor Attack (CRA)<br/>合谋谣言攻击"]
        Problem --> A3["Adaptive Adversarial Attack (AAA)<br/>自适应对抗攻击"]
        Problem --> A4["Byzantine Fault Injection (BFI)<br/>拜占庭故障注入"]
        Problem --> A5["Time-Delayed Poisoning (TDP)<br/>时间延迟投毒"]
    
        Method["Trust Framework with FHE & ABAC + Learning Defenses<br/>基于FHE和ABAC的信任框架与学习防御"] --> M1["Reinforcement Learning (RL)<br/>强化学习"]
        Method --> M2["Deep RL (DRL)<br/>深度强化学习"]
        Method --> M3["Multi-Agent RL (MARL)<br/>多智能体强化学习"]
    
        Results["Key Experimental Findings<br/>关键实验结果"] --> R1["MARL best vs. Collusive Attacks<br/>MARL对合谋攻击最佳"]
        Results --> R2["DRL & MARL perfect vs. Adaptive Attacks<br/>DRL和MARL完美防御自适应攻击"]
        Results --> R3["All agents fail vs. Time-Delayed Poisoning<br/>所有智能体在延迟投毒攻击下失效"]
    ```

- **[arXiv251230] Reinforcement Networks: novel framework for collaborative Multi-Agent Reinforcement Learning tasks**
  - **tags:** [ai], [multi-agent reinforcement learning], [Reinforcement Networks, directed acyclic graph (DAG), credit assignment, LevelEnv, hierarchical RL]
  - **authors:** Maksim Kryzhanovskiy, Svetlana Glazyrina, Roman Ischenko, Konstantin Vorontsov
  - **institution:** Lomonosov Moscow State University, Institute for Artificial Intelligence, Lomonosov Moscow State University
  - **link:** https://arxiv.org/pdf/2512.22876
  - **contributions:** 1. Introduces the Reinforcement Networks framework, a general approach for collaborative MARL that organizes agents as vertices in a directed acyclic graph (DAG)., 2. Formalizes training and inference methods for the framework and connects it to the LevelEnv concept for reproducible construction and evaluation., 3. Demonstrates improved performance over standard MARL baselines and unifies hierarchical, modular, and graph-structured views of MARL.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b613175c92e9bdddfbd57ed84d044a5846b7b8148cca8ab0405e69847f66c33a_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of end-to-end training for AI systems with multiple learnable components. It proposes Reinforcement Networks, a framework that organizes agents in a directed acyclic graph for flexible credit assignment and coordination in multi-agent reinforcement learning. The method shows improved performance over baselines and provides a principled foundation for designing complex multi-agent systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Reinforcement Networks] --> B[核心问题/Problem: End-to-end training of multi-component AI systems]
        A --> C[主要方法/Method: MARL agents organized in a DAG (Reinforcement Networks)]
        A --> D[关键结果/Results: Improved performance, unified framework for structured MARL]
    ```

- **[arXiv251230] Heterogeneity in Multi-Agent Reinforcement Learning**
  - **tags:** [ai], [multi-agent reinforcement learning], [heterogeneity, multi-agent reinforcement learning, parameter sharing, heterogeneity distance, dynamic algorithm]
  - **authors:** Tianyi Hu, Zhiqiang Pu, Yuan Wang, Tenghai Qiu, Min Chen, Xin Yu
  - **institution:** Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences
  - **link:** https://arxiv.org/pdf/2512.22941
  - **code:** https://github.com/Harry67Hu/HetDPS
  - **contributions:** 1. Proposes a systematic categorization of heterogeneity in MARL into five types with mathematical definitions. 2. Defines a heterogeneity distance and introduces a practical method to quantify agent heterogeneity. 3. Designs a heterogeneity-based dynamic parameter sharing algorithm that demonstrates better interpretability and adaptability compared to baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de4448c413f180749bc7f2220bea2793dad9a358fb068164020bd7b0421e5b05_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of a rigorous definition and understanding of heterogeneity in multi-agent reinforcement learning (MARL). It proposes a methodology to define, quantify, and utilize heterogeneity, culminating in a dynamic parameter sharing algorithm. Experiments show this algorithm offers improved interpretability and adaptability over other parameter-sharing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Heterogeneity in Multi-Agent Reinforcement Learning<br/>多智能体强化学习中的异质性"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["缺乏对异质性的严格定义<br/>Lacks rigorous definition of heterogeneity"]
        Method --> M1["定义与分类<br/>Definition & Categorization"]
        Method --> M2["量化方法<br/>Quantification Method"]
        Method --> M3["应用算法<br/>Application Algorithm"]
        M1 --> M1_1["五类异质性<br/>Five types of heterogeneity"]
        M2 --> M2_1["异质性距离<br/>Heterogeneity distance"]
        M3 --> M3_1["动态参数共享<br/>Dynamic Parameter Sharing"]
        Results --> R1["有效识别与量化<br/>Effective identification & quantification"]
        Results --> R2["算法性能优越<br/>Algorithm outperforms baselines"]
    ```

- **[arXiv251230] It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents**
  - **tags:** [sec], [prompt injection], [prompt injection, web agents, social-engineering, benchmark, autonomous agents]
  - **authors:** Karolina Korgul, Yushi Yang, Arkadiusz Drohomirecki, Piotr Błaszczyk, Will Howard, Lukas Aichberger, Chris Russell, Philip H.S. Torr, Adam Mahdi, Adel Bibi
  - **institution:** University of Oxford, SoftServe, Johannes Kepler University Linz
  - **link:** https://arxiv.org/pdf/2512.23128
  - **contributions:** 1. Introduces the Task-Redirecting Agent Persuasion Benchmark (TRAP) for evaluating prompt injection vulnerabilities in web-based LLM agents. 2. Provides a modular social-engineering injection framework for controlled experiments on high-fidelity website clones. 3. Demonstrates systemic vulnerabilities, showing agents are susceptible to injection in 25% of tasks on average, with small interface changes often doubling success rates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c246d5b23e99374a1d754ec870b203d23f214abac92f8d20d849cc98d00e86ca_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the vulnerability of web-based LLM agents to prompt injection attacks, where hidden adversarial instructions can divert agents from their tasks. It introduces the TRAP benchmark, built on realistic website clones, to evaluate these vulnerabilities. The study finds significant susceptibility across models, revealing systemic, psychologically driven weaknesses in current agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Web agents vulnerable to prompt injection attacks] --> Problem_Detail[问题详情/Problem Detail: Adversarial instructions in web content can divert agents from original tasks]
        Method[主要方法/Method: Introduce TRAP benchmark & modular injection framework] --> Method_Detail[方法详情/Method Detail: Evaluation on high-fidelity website clones using social-engineering techniques]
        Results[关键结果/Results: Agents susceptible in 25% of tasks on average] --> Results_Detail[结果详情/Results Detail: Small interface changes can double success rates, revealing systemic vulnerabilities]
    ```

- **[arXiv251230] Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems**
  - **tags:** [sec], [machine learning security], [TTPs, threat graph, multi-agent RAG, model stealing, jailbreaking]
  - **authors:** Armstrong Foundjem, Lionel Nganyewou Tidjon, Leuson Da Silva, Foutse Khomh
  - **institution:** Polytechnique Montréal (based on author affiliations and sMIEEE notation)
  - **link:** https://arxiv.org/pdf/2512.23132
  - **contributions:** 1. Conducted a large-scale empirical analysis of ML security, extracting 93 distinct threats from multiple sources including real-world incidents and code repositories. 2. Developed a multi-agent RAG system to automatically build an ontology-driven threat graph linking TTPs, vulnerabilities, and lifecycle stages from over 300 articles. 3. Identified unreported threats and dominant attack patterns (e.g., commercial LLM API model stealing, preference-guided jailbreaks) and highlighted vulnerability clusters in ML libraries with poor patch propagation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3da226bc9e7639392b95f6f00808f162580d1a90050c1261b3a0703259e42cf_w640_q70.webp
  - **Simple LLM Summary:** This paper characterizes modern security risks in AI systems by analyzing threats from multiple sources and using a multi-agent RAG system to construct a threat graph. The analysis uncovers unreported attack vectors and dominant TTPs, concluding that adaptive, ML-specific security frameworks are urgently needed to mitigate supply-chain and inference-time risks.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[传统安全框架缺乏针对ML的威胁建模/Traditional cybersecurity lacks ML-specific threat modeling]
    C --> C1[多智能体RAG系统分析威胁/Multi-agent RAG system analyzes threats]
    C1 --> C2[构建本体驱动的威胁图谱/Builds ontology-driven threat graph]
    D --> D1[识别未报告的威胁/Identifies unreported threats]
    D --> D2[发现主要的攻击TTPs/Identifies dominant attack TTPs]
    D --> D3[强调自适应ML安全框架的必要性/Highlights need for adaptive ML security frameworks]
    ```

- **[arXiv251230] SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search**
  - **tags:** [mlsys], [agent system], [LLM planning, Monte Carlo Tree Search (MCTS), multi-agent architecture, symbolic reasoning, self-correction]
  - **authors:** Yifan Zhang, Giridhar Ganapavarapu, Srideepika Jayaraman, Bhavna Agrawal, Dhaval Patel, Achille Fokoue
  - **institution:** IBM T.J. Watson Research Center, Vanderbilt University
  - **link:** https://arxiv.org/pdf/2512.23167
  - **code:** https://github.com/IBM/SPIRAL
  - **contributions:** 1. Introduces SPIRAL, a novel framework that embeds a cognitive architecture of three specialized LLM agents (Planner, Simulator, Critic) into an MCTS loop for planning. 2. Transforms MCTS from a brute-force search into a guided, self-correcting reasoning process by leveraging dense, semantic-aware feedback from the agents. 3. Demonstrates superior performance and token efficiency on benchmark datasets (e.g., DailyLifeAPIs) compared to Chain-of-Thought and other state-of-the-art planning agents.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c24b184565ce8e4c4a35d80f46a857779e111625dc4ea57e56333bef27bea7e6_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of LLMs struggling with complex planning tasks due to linear reasoning and lack of self-correction. It proposes SPIRAL, a framework that integrates three specialized LLM agents into a Monte Carlo Tree Search loop to create a guided, reflective, and grounded planning process. The method significantly outperforms existing planning approaches in accuracy and efficiency on benchmark datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search] --> B[核心问题/Problem: LLMs falter at complex planning, linear reasoning lacks self-correction]
        A --> C[主要方法/Method: Integrates three LLM agents (Planner, Simulator, Critic) into MCTS loop]
        A --> D[关键结果/Results: Outperforms SOTA agents, achieves 83.6% accuracy on DailyLifeAPIs, superior token efficiency]
    ```

- **[arXiv251230] KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta**
  - **tags:** [mlsys], [gpu kernels], [agentic kernel coding, heterogeneous accelerators, retrieval-augmented prompt synthesis, graph-based search, Triton/CuTe DSL]
  - **authors:** Gang Liao, Hongsen Qin, Ying Wang, Alicia Golden, Michael Kuchnik, Yavuz Yetim, Jia Jiunn Ang, Chunli Fu, Yihan He, Samuel Hsia, Zewei Jiang, Dianshi Li, Uladzimir Pashkevich, Varna Puvvada, Feng Shi, Matt Steiner, Ruichao Xiao, Nathan Yan, Xiayu Yu, Zhou Fang, Abdul Zainul-Abedin, Ketan Singh, Hongtao Yu, Wenyuan Chi, Barney Huang, Sean Zhang, Noah Weller, Zach Marine, Wyatt Cook, Carole-Jean Wu, Gaoxiang Liu
  - **institution:** Meta Platforms
  - **link:** https://arxiv.org/pdf/2512.23236
  - **contributions:** 1. Proposes KernelEvolve, an agentic framework that automates kernel generation and optimization for DLRMs across heterogeneous hardware (NVIDIA/AMD GPUs, Meta accelerators) by operating at multiple programming abstractions. 2. Introduces a kernel optimization process modeled as a graph-based search with dynamic adaptation to runtime context via retrieval-augmented prompt synthesis and a persistent hardware knowledge base. 3. Demonstrates the system's effectiveness by achieving 100% correctness on benchmark suites and substantial performance speedups (up to 17x) in production, reducing development time from weeks to hours and lowering the programmability barrier for new AI hardware.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp
  - **Simple LLM Summary:** This paper presents KernelEvolve, an agentic framework that automates the generation and optimization of compute kernels for deep learning recommendation models to address challenges posed by model, kernel, and hardware heterogeneity. The method uses a graph-based search process enhanced with retrieval-augmented prompts and operates across multiple programming abstractions. The system was validated on production models and benchmarks, showing significant performance improvements and reduced development time, effectively mitigating the programmability barrier for new AI accelerators.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[KernelEvolve: Scaling Agentic Kernel Coding] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[DLRM训练/推理效率<br/>DLRM Training/Inference Efficiency]
        B --> B2[模型、内核、硬件异构性<br/>Model, Kernel, Hardware Heterogeneity]
        C --> C1[智能内核编码框架<br/>Agentic Kernel Coding Framework]
        C --> C2[多抽象层: Triton, CuTe DSL<br/>Multi-Abstraction: Triton, CuTe DSL]
        C --> C3[图搜索与检索增强提示<br/>Graph Search & Retrieval-Augmented Prompt]
        D --> D1[100%正确率, 17倍加速<br/>100% Correctness, 17x Speedup]
        D --> D2[开发时间: 数周->数小时<br/>Dev Time: Weeks->Hours]
        D --> D3[降低新硬件编程壁垒<br/>Reduces New Hardware Programmability Barrier]
    ```

- **[arXiv251230] The Law of Multi-Model Collaboration: Scaling Limits of Model Ensembling for Large Language Models**
  - **tags:** [ai], [scaling laws], [scaling laws, model ensembling, multi-model collaboration, cross-entropy loss, parameter budget]
  - **authors:** Dakuan Lu, Jiaqi Zhang, Cheng Yuan, Jiawei Shao, Chi Zhang, Xuelong Li
  - **institution:** Institute of Artificial Intelligence (TeleAI), China Telecom
  - **link:** https://arxiv.org/pdf/2512.23340
  - **contributions:** 1. Proposes the "Law of Multi-model Collaboration," a novel scaling law for predicting the performance limits of LLM ensembles based on aggregated parameters. 2. Establishes a method-agnostic theoretical framework using an idealized integration oracle to quantify the intrinsic upper bound of multi-model collaboration. 3. Empirically demonstrates that multi-model systems follow a power-law scaling with better trends and lower loss floors than single models, and that heterogeneous ensembles outperform homogeneous ones.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68212ad5f9cd50ef959cdd80f4b7274178d9a6b124904010fc5b0cf0834b21a1_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of a theoretical framework for scaling in multi-model LLM systems. It proposes the "Law of Multi-model Collaboration," a scaling law based on aggregated parameters, and finds that ensembles scale better and achieve lower loss than single models, with diversity being a key driver of gains.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["The Law of Multi-Model Collaboration<br>多模型协作定律"] --> Problem["核心问题/Problem<br>Lack of scaling theory for multi-model collaboration<br>缺乏多模型协作的扩展理论"]
        Root --> Method["主要方法/Method<br>Propose Law of Multi-model Collaboration<br>提出多模型协作定律"]
        Root --> Results["关键结果/Results<br>Ensembles scale better than single models<br>集成模型比单一模型扩展性更好"]
    ```

- **[arXiv251230] Optimal Scalability-Aware Allocation of Swarm Robots: From Linear to Retrograde Performance via Marginal Gains**
  - **tags:** [ai], [multi-agent systems], [task allocation, swarm robotics, scalability functions, marginal gains, collective decision-making]
  - **authors:** Simay Atasoy Bingöl, Tobias Töpfer, Sven Kosub, Heiko Hamann, Andreagiovanni Reina
  - **institution:** Universität Konstanz, Max Planck Institute of Animal Behavior
  - **link:** https://arxiv.org/pdf/2512.23431
  - **contributions:** 1. A computationally efficient algorithm for optimal agent allocation based on marginal performance gains. 2. The algorithm handles tasks with concave scalability functions, including linear, saturating, and retrograde scaling. 3. Validation of the algorithm in a simulated robot swarm performing collective decision-making tasks with varying difficulty.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65eaf636a462023cd662333c71ac9a0b2b73588d8278f1b001d8292a37ecc630_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of optimally allocating a finite number of agents across multiple tasks where performance scales differently. It proposes an efficient algorithm based on marginal gains to handle concave scalability functions, including retrograde scaling where too many agents degrade performance. The method is validated in robot swarm simulations for collective decision-making, showing its utility for future multi-robot systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Optimal Scalability-Aware Allocation of Swarm Robots<br>机器人集群的可扩展性感知最优分配] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[有限智能体分配到多个任务<br>Limited agents to multiple tasks]
        B --> B2[性能随智能体数量非线性变化<br>Nonlinear performance scaling]
        B --> B3[暴力搜索不可行<br>Brute-force infeasible]
        C --> C1[基于边际性能增益的算法<br>Algorithm based on marginal gains]
        C --> C2[处理凹可扩展性函数<br>Handles concave scalability functions]
        D --> D1[在机器人集群决策中验证<br>Validated in robot swarm decision-making]
        D --> D2[算法有效分配机器人<br>Algorithm useful for allocation]
    ```

- **[arXiv251230] Assessing behaviour coverage in a multi-agent system simulation for autonomous vehicle testing**
  - **tags:** [ai], [multi-agent systems], [Model Predictive Control, Coverage-Based Testing, Edge-Case Exploration, Multi-Agent Simulation, Behaviour Coverage]
  - **authors:** Manuel Franco-Vivo
  - **institution:** University of Bristol
  - **link:** https://arxiv.org/pdf/2512.23445
  - **contributions:** 1. A systematic approach to measure and assess behaviour coverage within a multi-agent simulation for autonomous vehicle testing. 2. The proposal of a Model Predictive Control (MPC) pedestrian agent designed to generate interesting tests and realistic behaviour. 3. Insights and analysis for improving and optimizing simulation frameworks through behaviour coverage metrics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/385ed91e6ca24b7cc0e8d369cc587a3dd677cf4643f89f27d85aaadf4cd4ea70_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the need for comprehensive testing of autonomous vehicles by analyzing behaviour coverage in multi-agent simulations. It proposes a systematic method to measure coverage and introduces an MPC-based pedestrian agent to generate more realistic and challenging test scenarios. The research concludes that assessing behaviour coverage is crucial for validating the robustness of autonomous systems and improving simulation frameworks.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Assessing Behaviour Coverage in a Multi-Agent System Simulation for Autonomous Vehicle Testing] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[如何全面评估自动驾驶系统在模拟环境中的行为覆盖度？/How to comprehensively evaluate behaviour coverage of AV systems in simulation?]
    C --> C1[定义场景与交互，提出MPC行人智能体/Define scenarios & interactions, propose MPC pedestrian agent]
    D --> D1[行为覆盖度对验证系统有效性至关重要/Behaviour coverage is crucial for validating system effectiveness]
    ```

- **[arXiv251230] Nested Browser-Use Learning for Agentic Information Seeking**
  - **tags:** [mlsys], [agent system], [information-seeking agents, browser interaction, ReAct-style agents, nested framework]
  - **authors:** Baixuan Li, Jialong Wu, Wenbiao Yin, Kuan Li, Zhongwang Zhang, Huifeng Yin, Zhengwei Tao, Liwen Zhang, Pengjun Xie, Jingren Zhou, Yong Jiang
  - **institution:** Tongyi Lab, Alibaba Group
  - **link:** https://arxiv.org/pdf/2512.23647
  - **code:** https://github.com/Alibaba-NLP/DeepResearch
  - **contributions:** 1. Proposes a minimal and complete browser-action framework for agents, 2. Introduces a nested structure to decouple interaction control from page exploration, 3. Demonstrates improved performance on deep information-seeking benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab4c5e1fc52fc83cedffe542098b6777a8df396f1f3d30f2a130aebdd36e0dc_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limitation of current information-seeking agents, which rely on simple API calls and cannot perform real browsing. It proposes NestBrowse, a framework that uses a nested structure to enable fine-grained browser control for agents, simplifying reasoning and improving performance on deep search tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Nested Browser-Use Learning for Agentic Information Seeking<br>面向智能信息搜索的嵌套浏览器使用学习"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Agents lack real browsing, limited to APIs."]
        Method["主要方法/Method<br>NestBrowse: nested browser-action framework."]
        Results["关键结果/Results<br>Better performance on deep IS benchmarks."]
    ```

## 2026-01-01

- **[arXiv260101] Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems**
  - **tags:** [mlsys], [federated learning], [Zero-Trust Architecture, SHAP-weighted aggregation, TPM-based attestation]
  - **authors:** Samaresh Kumar Singh, Joyjit Roy, Martin So
  - **institution:** Independent Researchers (based on provided affiliations: IEEE Senior Member in Texas, IEEE Member in Texas, Independent Researcher in Canada)
  - **link:** https://arxiv.org/pdf/2512.23809
  - **contributions:** 1) Proposed a hierarchical edge-fog-cloud zero-trust federated learning architecture for trusted agent participation. 2) Introduced a novel SHAP-weighted aggregation algorithm for explainable Byzantine detection in non-IID environments. 3) Integrated TPM-based cryptographic attestation and on-device adversarial training into a defense-in-depth framework.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/baa785fc442fcbc6a80214c4fdc6361e67a8e34e5a9bb6f5dd8fb34baf21bb68_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses security vulnerabilities in Federated Learning for Industrial IoT by proposing ZTA-FL, a framework combining zero-trust agent authentication, explainable Byzantine-resilient aggregation, and on-device adversarial training. It demonstrates high detection accuracy and robustness against attacks on intrusion detection benchmarks while reducing communication overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: IIoT安全漏洞与联邦学习攻击 / IIoT Security Gaps & FL Attacks]
        Method[主要方法/Method: 零信任认证与可解释聚合 / Zero-Trust Attestation & Explainable Aggregation]
        Results[关键结果/Results: 高检测精度与抗攻击鲁棒性 / High Detection Accuracy & Attack Robustness]
    ```

- **[arXiv260101] An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System**
  - **tags:** [mlsys], [agent system], [agentic AI, recommendation system, KYC (Know Your Customer), nDCG, multi-stage architecture]
  - **authors:** Junjie H. Xu
  - **institution:** Hechu Tech
  - **link:** https://arxiv.org/pdf/2512.23961
  - **contributions:** 1. Proposes a novel agentic AI-based recommendation system specifically designed for integrating KYC (Know Your Customer) processes. 2. Conducts a comparative performance evaluation across five distinct content verticals (Ad, News, Gossip, Sharing, Tech) using the nDCG metric. 3. Synthesizes experimental data with industry benchmarks to provide engineering insights for building large-scale agentic recommendation systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76e7c4d7572522a69f7c0db05b6553014273403aa44576ea9c0de823750c5368_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a new recommendation system that uses agentic AI to incorporate KYC (Know Your Customer) information. It evaluates the system's performance across five different content types and compares it against standard benchmarks. The study concludes by providing practical insights for engineering large-scale agentic recommendation systems based on the experimental results.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System] --> B[核心问题/Problem: Transition from passive ranking to agentic AI in RecSys]
        A --> C[主要方法/Method: Agentic AI for KYC, evaluated across 5 content verticals using nDCG@k]
        A --> D[关键结果/Results: Performance comparison of 4 KYC usage groups, insights for large-scale engineering]
    ```

- **[arXiv260101] SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents**
  - **tags:** [mlsys], [agent system], [Science Context Protocol, autonomous scientific agents, unified resource integration, experiment lifecycle management, federated servers]
  - **authors:** Yankai Jiang, Wenjie Lou, Lilong Wang, Zhenyu Tang, Shiyang Feng, Jiaxuan Lu, Haoran Sun, Yaning Pan, Shuang Gu, Haoyang Su, Feng Liu, Wangxu Wei, Pan Tan, Dongzhan Zhou, Fenghua Ling, Cheng Tan, Bo Zhang, Xiaosong Wang, Lei Bai, Bowen Zhou
  - **institution:** Shanghai Artificial Intelligence Laboratory
  - **link:** https://arxiv.org/pdf/2512.24189
  - **code:** https://github.com/InternScience/scp
  - **contributions:** 1. Proposes SCP, an open-source protocol-level standard for universally describing and invoking heterogeneous scientific resources (tools, models, datasets, instruments)., 2. Introduces a secure service architecture (centralized Hub & federated Servers) for managing the complete, traceable experiment lifecycle and enforcing fine-grained access control., 3. Demonstrates a functional platform built on SCP, integrating over 1,600 tool resources to facilitate secure, large-scale, multi-institution collaboration between AI agents and human researchers, reducing integration overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8885d3eeb276d5044f777dc33201481a07be8831aaff9d61726e4a6c13e821be_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces the Science Context Protocol (SCP), an open-source standard designed to address the fragmentation and bespoke nature of current autonomous scientific agent systems. SCP provides a universal specification for resource integration and a secure service architecture for experiment orchestration, enabling seamless, large-scale collaboration across platforms. The authors conclude that SCP establishes essential infrastructure for scalable, reproducible, and agent-driven science by standardizing context and tool orchestration at the protocol level.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Bespoke, isolated agent systems; Lack of shared protocol for heterogeneous resources"] --> Problem_Detail["具体挑战/Specific Challenges<br>Difficult to deploy beyond single lab; Hard to reuse components & reproduce workflows"]
        Method["主要方法/Method<br>Science Context Protocol (SCP)"] --> Method_Pillar1["支柱1: 统一资源集成/Unified Resource Integration<br>Universal spec for describing/invoking tools, models, data, instruments"]
        Method --> Method_Pillar2["支柱2: 实验生命周期管理/Experiment Lifecycle Management<br>Secure architecture (Hub & Servers) for registration, execution, monitoring"]
        Results["关键结果/Results<br>Enables global web of autonomous agents"] --> Results_Outcome1["成果1: 大规模生态系统/Large-scale Ecosystem<br>1,600+ integrated tool resources"]
        Results --> Results_Outcome2["成果2: 促进协作/Facilitates Collaboration<br>Reduces integration overhead; Enhances reproducibility"]
    ```

- **[arXiv260101] MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems**
  - **tags:** [mlsys], [agent system], [Multi-Agent Reinforcement Learning, Centralized Training with Decentralized Execution (CTDE), Model Predictive Control (MPC), Dynamic Computation Allocation, Recommender Systems]
  - **authors:** Wan Jiang, Xinyi Zang, Yudong Zhao, Yusi Zou, Yunfei Lu, Junbo Tong, Yang Liu, Ming Li, Jiani Shi, Xin Yang
  - **institution:** JD.com, Tsinghua University
  - **link:** https://arxiv.org/pdf/2512.24325
  - **contributions:** 1. Proposes MaRCA, a multi-agent reinforcement learning framework that models recommender system stages as cooperative agents for end-to-end computation resource allocation. 2. Introduces an AutoBucket TestBench for accurate computation cost estimation in large-scale systems. 3. Designs a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5648d9986b292c2db26fc1ddb4325c3fc0f14c6516ddecf792ceaf524e365c4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of dynamic computation allocation in large-scale, multi-stage recommender systems under resource constraints. It proposes MaRCA, a multi-agent reinforcement learning framework that uses Centralized Training with Decentralized Execution (CTDE) and integrates a Model Predictive Control-based balancer to optimize revenue. The system was deployed on a major e-commerce platform, handling hundreds of billions of daily requests and achieving a 16.67% revenue uplift using existing resources.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MaRCA: Multi-Agent RL for Dynamic Computation Allocation] --> B[核心问题/Problem: 大规模推荐系统中，模型复杂度和流量规模增长带来的计算挑战，现有方法忽略阶段间依赖，限制全局最优性。]
        A --> C[主要方法/Method: 提出MaRCA框架，将推荐系统阶段建模为合作智能体，使用CTDE进行训练，并引入AutoBucket TestBench和基于MPC的收益-成本平衡器。]
        A --> D[关键结果/Results: 在领先的全球电商平台广告管线中端到端部署，每日处理数千亿广告请求，使用现有计算资源实现16.67%的收益提升。]
    ```

- **[arXiv260101] Heterogeneous Multi-Agent Multi-Target Tracking using Cellular Sheaves**
  - **tags:** [other], [multi-agent systems], [cellular sheaves, sheaf Laplacian, harmonic extension, heterogeneous agents, decentralized control]
  - **authors:** Tyler Hanks, Cristian F. Nino, Joana Bou Barcelo, Austin Copeland, Warren Dixon, James Fairbanks
  - **institution:** University of Florida
  - **link:** https://arxiv.org/pdf/2512.24886
  - **contributions:** 1. Extends the cellular sheaf framework from cooperative consensus problems to the non-cooperative multi-target tracking problem. 2. Formulates multi-target tracking as a harmonic extension problem on a cellular sheaf to natively handle agent heterogeneity and nonlinear dynamics. 3. Develops a decentralized control law using the sheaf Laplacian and provides a Lyapunov-based stability analysis guaranteeing tracking error convergence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2f3adc6c3676e271ab58554c6c1cc06190ebf26ca42824712b494c63fb1b8d8_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of heterogeneous multi-agent multi-target tracking with nonlinear dynamics. It proposes a novel method using cellular sheaves to model the system and formulates tracking as a harmonic extension problem, leading to a decentralized control law. The approach is proven stable via Lyapunov analysis and validated through simulation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题 / Paper Title: Heterogeneous Multi-Agent Multi-Target Tracking using Cellular Sheaves] --> B
        A --> C
        A --> D
        B[核心问题 / Problem: 异构多智能体多目标跟踪 / Heterogeneous Multi-Agent Multi-Target Tracking]
        C[主要方法 / Method: 基于胞腔层与调和扩展 / Cellular Sheaves & Harmonic Extension]
        D[关键结果 / Results: 分散控制律与稳定性证明 / Decentralized Control Law & Stability Proof]
    ```

- **[arXiv260101] BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts**
  - **tags:** [nlp], [strategic dialogue], [belief estimation, probabilistic constraints, dialogue acts, adversarial, alignment]
  - **authors:** Hengli Li, Zhaoxin Yu, Qi Shen, Chenxi Li, Mengmeng Wang, Tinglang Wu, Yipeng Kang, Yuxuan Wang, Song-Chun Zhu, Zixia Jia, Zilong Zheng
  - **institution:** Peking University (PKU), Beijing Institute for General Artificial Intelligence (BIGAI), Chinese Academy of Sciences (CAS), Beijing University of Posts and Telecommunications (BUPT), Tsinghua University (THU)
  - **link:** https://arxiv.org/pdf/2512.24885
  - **contributions:** 1. Formalizes two core strategic dialogue acts (Adversarial and Alignment) within a game-theoretic framework of beliefs and common knowledge. 2. Proposes a principled mechanism that operationalizes these acts by casting belief estimation as probabilistic constraints on utterance generation. 3. Introduces the BEDA framework, which integrates a world set, a belief estimator, and a conditional generator to select acts and realize utterances consistent with inferred beliefs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f74e9bdf6a51c0f1ab61ad8d67cba11cf929a7b681e1d4c3a1c8682bf34bb3fe_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the gap between accurate belief estimation and its principled use in strategic dialogue generation. It proposes BEDA, a framework that formalizes adversarial and alignment dialogue acts and uses belief estimates as probabilistic constraints to guide utterance generation. The method consistently outperforms strong baselines across adversarial, cooperative, and negotiation settings, demonstrating its effectiveness.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("BEDA: Belief Estimation as Probabilistic Constraints") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("Prior work lacks principled use of beliefs for generation/先前工作缺乏使用信念的机制")
        Method --> M1("Formalizes Adversarial & Alignment acts/形式化对抗与对齐行为")
        Method --> M2("Beliefs as probabilistic constraints/信念作为概率约束")
        Method --> M3("BEDA framework: belief estimator + conditional generator/BEDA框架")
        Results --> R1("Outperforms baselines on CKBG, MF, CaSiNo/在多个设定超越基线")
        Results --> R2("Improves success rates significantly/显著提升成功率")
        Results --> R3("Provides simple, general mechanism/提供简单通用机制")
    ```
