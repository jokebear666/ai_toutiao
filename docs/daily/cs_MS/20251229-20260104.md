---
slug: /daily/csms/20251229-20260104
---
# 20251229-20260104 (cs.MS)

## 2025-12-29

- **[arXiv251229] Some Patterns of Duplications in the outputs of Mersenne Twister Pseudorandom Number Generator MT19937**
  - **tags:** [other], [pseudorandom number generation], [Mersenne Twister, statistical tests, run-length distribution, linear recurrence, matrix sparseness]
  - **authors:** Alain Schumacher, Takuji Nishimura, Makoto Matsumoto
  - **institution:** SICAP R&D, Yamagata University, AMAGAERU Institute of Free Mathematics
  - **link:** https://arxiv.org/pdf/2512.21678
  - **contributions:** 1. Identified a new statistical failure in the widely-used MT19937 PRNG using a natural run-length distribution test. 2. Provided a mathematical theorem explaining the observed anomalies, linking them to the sparseness of a specific matrix in the generator's recursion. 3. Demonstrated that while the defect is theoretically significant, detecting it in practice requires an astronomical number of samples, thus assessing its practical severity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5ed4ef3ce698fce7371b0c2d2270aad2355731f92eecd3697b292e4cb41bab5_w640_q70.webp
  - **Simple LLM Summary:** This paper reports a new statistical flaw in the Mersenne Twister MT19937 pseudorandom number generator, where the distribution of run-lengths for identical 32-bit integers shows a significant anomaly (e.g., run-length 623 appears ~40 times more than expected). The authors mathematically analyze and prove that this failure is caused by the sparseness of a specific matrix in the generator's recurrence. They conclude that while this is a theoretical defect, its practical impact is minimal due to the extreme difficulty of detection.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Some Patterns of Duplications in MT19937] --> B[核心问题/Problem: MT19937 fails a natural statistical test]
        A --> C[主要方法/Method: Run-length distribution analysis & mathematical theorem]
        A --> D[关键结果/Results: Run-length 623 anomaly explained; defect is not practically serious]
    ```

## 2025-12-30

- **[arXiv251230] SPUMA: a minimally invasive approach to the GPU porting of OPENFOAM**
  - **tags:** [hpc], [computational fluid dynamics], [GPU porting, unified memory, memory pool manager, OpenFOAM, scalability]
  - **authors:** Simone Bnà, Giuseppe Giaquinto, Ettore Fadiga, Tommaso Zanelli, Francesco Bottau
  - **institution:** Cineca Supercomputing Centre, Università degli Studi di Napoli Federico II
  - **link:** https://arxiv.org/pdf/2512.22215
  - **contributions:** 1. Presents SPUMA, a full GPU porting of OpenFOAM targeting both NVIDIA and AMD GPUs. 2. Implements a portable programming model with a memory pool manager leveraging unified memory for efficient GPU utilization. 3. Demonstrates significant performance and energy efficiency gains through extensive testing on pre-exascale clusters, showing up to 82% energy reduction compared to CPU simulations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ea486a67026343b5f3c7d85db1ef1ff1202af04d0bd147ef25d9dc29565e2b1_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of GPU programmability for open-source CFD by introducing SPUMA, a portable GPU port of OpenFOAM that uses a memory pool manager with unified memory. The method was tested on LUMI and Leonardo clusters, showing strong scalability up to 65% efficiency and weak scalability up to 85%, while reducing energy consumption by up to 82% compared to CPU-based simulations.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[SPUMA: a minimally invasive approach to the GPU porting of OPENFOAM] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: GPU programmability challenge in open-source CFD] --> P1[GPU可编程性挑战/GPU Programmability Challenge]
        Method[主要方法/Method: Portable GPU porting with memory pool] --> M1[便携式编程模型/Portable Programming Model]
        Method --> M2[内存池管理器/Memory Pool Manager]
        Method --> M3[利用统一内存/Leverages Unified Memory]
        Results[关键结果/Results: Performance and energy efficiency on pre-exascale clusters] --> R1[强可扩展性达65%/Strong Scalability 65%]
        Results --> R2[弱可扩展性达85%/Weak Scalability 85%]
        Results --> R3[能耗降低82%/Energy Reduction 82%]
    ```
