---
slug: /daily/csne/20260105-20260111
---
# 20260105-20260111 (cs.NE)

## 2026-01-05

- **[arXiv260105] Personalized Spiking Neural Networks with Ferroelectric Synapses for EEG Signal Processing**
  - **tags:** [mlsys], [on-device ai], [ferroelectric synapses, spiking neural networks, EEG signal processing, adaptive learning, neuromorphic computing]
  - **authors:** Nikhil Garg, Anxiong Song, Niklas Plessnig, Nathan Savoia, Laura Bégon-Lours
  - **institution:** ETH Zurich (Integrated Systems Laboratory, Department of Information Technology and Electrical Engineering)
  - **link:** https://arxiv.org/pdf/2601.00020
  - **contributions:** 1. Demonstrated the deployment and adaptation of Spiking Neural Networks (SNNs) on fabricated ferroelectric memristive synaptic devices for EEG-based motor imagery decoding under realistic device constraints. 2. Introduced a device-aware weight-update strategy that accumulates gradient updates digitally and triggers discrete programming events only when a threshold is exceeded, reducing programming frequency and emulating device dynamics. 3. Evaluated two complementary deployment strategies (device-aware training and transfer learning with on-device re-tuning) that achieve performance comparable to software-based SNNs and show improved accuracy through subject-specific adaptation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce95488f8704205e4a01e64825c78c800662f36da33df71b138881b21ab7b9bb_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of adapting EEG-based brain-computer interfaces to non-stationary neural signals on resource-constrained hardware. It proposes deploying Spiking Neural Networks on ferroelectric memristive synapses with a novel device-aware update strategy and demonstrates two effective deployment methods for personalized, low-overhead adaptation. The results show that programmable ferroelectric hardware can support robust, efficient adaptation for personalized neuromorphic processing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Personalized Spiking Neural Networks with Ferroelectric Synapses for EEG Signal Processing] --> B
        A --> C
        A --> D
        B[核心问题/Problem: EEG信号非平稳性限制模型泛化，需在资源受限平台上进行个性化适应/Non-stationary EEG signals limit model generalization, requiring personalized adaptation on resource-constrained platforms]
        C[主要方法/Method: 在铁电忆阻突触上部署SNN，采用设备感知的权重更新策略/Deploy SNNs on ferroelectric memristive synapses with a device-aware weight-update strategy]
        D[关键结果/Results: 两种部署策略性能媲美软件SNN，特定对象迁移学习提升准确率/Two deployment strategies achieve performance comparable to software SNNs, subject-specific transfer learning improves accuracy]
    ```

- **[arXiv260105] Covariance Matrix Adaptation Evolution Strategy without a matrix**
  - **tags:** [ai], [evolutionary computation], [CMA-ES, matrix-free, high-dimensional optimization, step-size adaptation, black-box optimization]
  - **authors:** Jarosław Arabas, Adam Stelmaszczyk, Eryk Warchulski, Dariusz Jagodziński, Rafał Biedrzycki
  - **institution:** Warsaw University of Technology
  - **link:** https://arxiv.org/pdf/2601.00102
  - **contributions:** 1. Proposes a novel, matrix-free variant of CMA-ES that eliminates the need for covariance matrix decomposition by using an archive of normalized difference vectors. 2. Provides a theoretical proof that the probability distribution of individuals generated by the matrix-free method is identical to that of the standard CMA-ES. 3. Demonstrates experimentally that the method maintains or improves optimization efficiency, especially when combined with step-size adaptation, and allows for a reduced archive size without performance loss.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57b7923e9e9cac21a68aeaefb1bed6421d350b6a739556df9a54b09abc025039_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the computational bottleneck of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) in high dimensions, which stems from the cubic cost of matrix decomposition. It introduces a matrix-free CMA-ES that generates new solutions by taking weighted combinations of past normalized difference vectors stored in an archive, eliminating the need for an explicit covariance matrix. The method is proven to be distributionally equivalent to standard CMA-ES and is shown to achieve comparable or superior performance, particularly when coupled with step-size adaptation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Covariance Matrix Adaptation Evolution Strategy without a matrix] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>CMA-ES在高维空间的计算瓶颈<br>Computational bottleneck of CMA-ES in high dimensions]
        C[主要方法/Method<br>提出无矩阵CMA-ES，使用存档向量加权组合<br>Propose matrix-free CMA-ES using weighted combination of archive vectors]
        D[关键结果/Results<br>分布等价，性能相当或更优，收敛更快<br>Distributionally equivalent, comparable/superior performance, faster convergence]
    ```

- **[arXiv260105] Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting**
  - **tags:** [mlsys], [others], [Reservoir Computing, Sequential Architecture, Spatiotemporal Forecasting, High-dimensional Data, Training Efficiency]
  - **authors:** Ata Akbari Asanjan, Filip Wudarski, Daniel O'Connor, Shaun Geaney, Elena Strbac, P. Aaron Lott, Davide Venturelli
  - **institution:** USRA Research Institute for Advanced Computer Science (RIACS), Standard Chartered Bank
  - **link:** https://arxiv.org/pdf/2601.00172
  - **contributions:** 1. Introduces a Sequential Reservoir Computing architecture that decomposes a large reservoir into smaller, interconnected ones to reduce computational and memory costs. 2. Demonstrates superior performance with longer forecast horizons and lower error metrics on chaotic and high-dimensional physical systems compared to RNN/LSTM baselines. 3. Achieves up to three orders of magnitude lower training cost, maintaining RC's efficiency while improving scalability for high-dimensional forecasting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80a4bf491108d4e92c2c08807229cd230f08dd3e916c820595ac48efa8952783_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Sequential Reservoir Computing, a novel architecture that breaks a large reservoir into a sequence of smaller ones to efficiently forecast high-dimensional spatiotemporal systems. It outperforms traditional RNNs and LSTMs in forecast horizon and accuracy while drastically reducing training costs, offering a path to real-time, energy-efficient forecasting.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>RNN/LSTM训练成本高，传统RC扩展性差"]
        Method["主要方法/Method<br>顺序储层计算架构"]
        Results["关键结果/Results<br>预测更长，误差更低，训练成本大幅降低"]
    ```

- **[arXiv260105] Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [neuromorphic computing, state-space models, sparse attention, surrogate gradients, local learning rules]
  - **authors:** Osvaldo Simeone
  - **institution:** Northeastern University London (Intelligent Networked Systems Institute - INSI)
  - **link:** https://arxiv.org/pdf/2601.00245
  - **contributions:** 1. Proposes a novel conceptual framework for analyzing modern neuromorphic AI through the lens of intra-token (feature-level) and inter-token (contextual) processing. 2. Systematically reviews the convergence of neuromorphic principles (e.g., sparse, discrete activations) with state-of-the-art AI architectures like state-space models and transformers. 3. Reviews and categorizes training methodologies for neuromorphic models, from surrogate gradients to local learning rules based on reinforcement learning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9154dccb8e64d45d3b60bd0f6bb1e84fa9423cf041633e14a8cb6272baa46_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high energy costs of modern AI by exploring the convergence of neuromorphic computing principles with contemporary architectures. It proposes a framework distinguishing between intra-token and inter-token processing to analyze how neuromorphic ideas like sparse activations and state dynamics are embodied in models such as transformers and state-space models. The main conclusion is that modern AI is increasingly adopting brain-inspired, energy-efficient neuromorphic principles for both processing types, offering a path toward more sustainable intelligent systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[AI能耗增长 / Escalating AI Energy Requirements]
        C --> C1[神经形态计算原则 / Neuromorphic Computing Principles]
        C1 --> C2[离散稀疏激活 / Discrete & Sparse Activations]
        C1 --> C3[循环动态 / Recurrent Dynamics]
        C --> C4[处理框架: 令牌内与令牌间 / Processing Framework: Intra-Token vs. Inter-Token]
        D --> D1[现代AI体现神经形态原则 / Modern AI Embodies Neuromorphic Principles]
        D --> D2[连接SNN、状态空间模型、Transformer / Connects SNNs, State-Space Models, Transformers]
    ```

- **[arXiv260105] Rectifying Adversarial Examples Using Their Vulnerabilities**
  - **tags:** [sec], [adversarial defense], [adversarial examples, label rectification, re-attack, white-box attack, black-box attack]
  - **authors:** Fumiya Morimoto, Ryuto Morita, Satoshi Ono
  - **institution:** Kagoshima University
  - **link:** https://arxiv.org/pdf/2601.00270
  - **contributions:** 1. Proposes a novel adversarial example rectification method based on "re-attacking" AEs to move them beyond the decision boundary for correct label estimation. 2. The method is designed to be straightforward, requiring only AEs as input without parameter adjustments or preliminary training, enabling it to address diverse attack types. 3. Demonstrates consistent performance and superior stability against various attacks, including targeted and black-box attacks, compared to conventional rectification and input transformation methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c32aaba927fb42e32f98d767a04b8c60ecebe5d8f0f13c4c25f72d7d23e5138c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of rectifying adversarial examples (AEs) to recover the correct labels of the original inputs, which is crucial for applications like autonomous driving. The proposed method works by "re-attacking" the AEs to push them across the model's decision boundary. The results show that this method performs consistently across different attack types and is more stable than existing approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Rectifying Adversarial Examples Using Their Vulnerabilities] --> B(核心问题/Problem: DNNs misclassify adversarial examples, needing correct label recovery)
        A --> C(主要方法/Method: Re-attack AEs to move them beyond decision boundary)
        A --> D(关键结果/Results: Consistent performance across attacks, outperforms conventional methods in stability)
    ```

- **[arXiv260105] Vehicle Painting Robot Path Planning Using Hierarchical Optimization**
  - **tags:** [other], [robotic path planning], [hierarchical optimization, vehicle routing problem (VRP), constraint handling, evolutionary computation]
  - **authors:** Yuya Nagai, Hiromitsu Nakamura, Narito Shinmachi, Yuta Higashizono, Satoshi Ono
  - **institution:** Kagoshima University, TOYOTA Body Research & Development Co., Ltd.
  - **link:** https://arxiv.org/pdf/2601.00271
  - **contributions:** 1. Formulates vehicle painting robot path planning as a hierarchical optimization problem, separating high-level task assignment (VRP-like) from low-level detailed path planning. 2. Proposes a flexible constraint handling framework for the painting process through custom variable representation, repair operators, and initialization. 3. Demonstrates the method's effectiveness by automatically generating paths for commercial vehicles that are comparable in quality to manual designs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd6fcb32eb9c80960a0ed996281f691e7732ffdfe85f78eaf940b5a4d0c7ce64_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the manual and time-consuming task of planning paint paths for multiple robotic arms in vehicle factories. It proposes a hierarchical optimization method that treats the problem as a high-level vehicle routing task and a low-level detailed path planning task, enabling automated design. Experiments on real vehicle models show the method can generate constraint-satisfying paths of comparable quality to those created by human engineers.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Vehicle Painting Robot Path Planning Using Hierarchical Optimization") --> Problem("核心问题/Problem: Manual paint path design for multiple robotic arms is time-consuming")
        Root --> Method("主要方法/Method: Hierarchical optimization (Upper: VRP-like assignment, Lower: detailed path planning)")
        Root --> Results("关键结果/Results: Automatically generates constraint-satisfying paths comparable to manual designs")
    ```

- **[arXiv260105] Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems**
  - **tags:** [mlsys], [agent system], [self-healing, distributed computing continuum, language model agents, multi-agent systems, fault tolerance]
  - **authors:** Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar Susanna Pirttikangas, Lauri Lovén
  - **institution:** University of Oulu, Stockholm University, EURECOM, University of Helsinki, RISE Research Institutes of Sweden, Luleå University of Technology, Peking University, TU Wien
  - **link:** https://arxiv.org/pdf/2601.00339
  - **contributions:** 1. Introduces ReCiSt, a novel bio-inspired framework that maps biological self-healing phases (Hemostasis, Inflammation, Proliferation, Remodeling) to computational layers (Containment, Diagnosis, Meta-Cognitive, Knowledge) for resilience in DCCS. 2. Proposes the use of Language Model (LM)-powered agents to autonomously interpret logs, diagnose faults, and reconfigure resources with minimal human intervention. 3. Demonstrates the framework's capability for self-healing within tens of seconds with low resource overhead (e.g., 10% CPU usage) through evaluation on public fault datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61eb83e4510dadeebc7e84fe1a44a89c218981f7cc3a6c7ef337ea51860d2146_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes ReCiSt, a bio-inspired, agent-based framework that uses Language Model-powered agents to autonomously detect, diagnose, and recover from faults in Distributed Computing Continuum Systems. The framework is evaluated on public datasets, showing it can achieve self-healing in tens of seconds with minimal resource overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Bio-inspired Agentic Self-healing Framework<br>生物启发的智能体自愈框架"] --> Problem["核心问题/Problem<br>DCCS中的复杂性与故障频发<br>Complexity & Frequent Faults in DCCS"]
        Root --> Method["主要方法/Method<br>ReCiSt框架: 仿生四层与LM智能体<br>ReCiSt Framework: Bio-inspired Layers & LM Agents"]
        Root --> Results["关键结果/Results<br>数十秒内自愈，低CPU开销<br>Self-healing in tens of seconds, low CPU overhead"]
    ```

- **[arXiv260105] RMAAT: Astrocyte-Inspired Memory Compression and Replay for Efficient Long-Context Transformers**
  - **tags:** [ai], [efficient transformers], [astrocyte-inspired computing, long-term plasticity (LTP), short-term plasticity (STP), memory compression, Long Range Arena (LRA)]
  - **authors:** Md Zesun Ahmed Mia, Malyaban Bal, Abhronil Sengupta
  - **institution:** Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2601.00426
  - **contributions:** 1. Introduces RMAAT, a novel Transformer architecture that integrates abstracted astrocyte functionalities for efficient long-context processing. 2. Proposes an adaptive memory compression mechanism governed by a novel retention factor derived from simulated astrocyte long-term plasticity (LTP). 3. Develops Astrocytic Memory Replay Backpropagation (AMRB), a novel training algorithm designed for memory efficiency in recurrent networks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48db0bbab3b8ca0fcbec4bfde72ebb384d63651cf925a575ef2f9e06a070abc5_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the quadratic complexity problem of Transformer self-attention for long sequences by proposing RMAAT, an architecture inspired by astrocyte functions in biological memory. The method uses recurrent segment-based processing with adaptive memory compression and a linear-complexity attention mechanism. Evaluations on the Long Range Arena benchmark show that RMAAT achieves competitive accuracy with substantial improvements in computational and memory efficiency.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[RMAAT: Astrocyte-Inspired Memory Compression and Replay] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Transformer自注意力二次复杂度/Quadratic Complexity of Self-Attention]
        Method[主要方法/Method: 星形胶质细胞启发的循环记忆架构/Astrocyte-Inspired Recurrent Memory Architecture]
        Results[关键结果/Results: 在LRA基准上具有竞争力的准确性和效率/Competitive Accuracy & Efficiency on LRA]
    ```

- **[arXiv260105] Benchmarking ERP Analysis: Manual Features, Deep Learning, and Foundation Models**
  - **tags:** [ai], [brain-computer interfaces], [event-related potential, EEG, deep learning, transformer, benchmark]
  - **authors:** Yihe Wang, Zhiqiao Kang, Bohan Chen, Yu Zhang, Xiang Zhang
  - **institution:** University of North Carolina-Charlotte, South China University of Technology, University of California-Davis, Stanford University
  - **link:** https://arxiv.org/pdf/2601.00573
  - **code:** https://github.com/DL4mHealth/ERP-Benchmark
  - **contributions:** 1. Conducted a comprehensive benchmark comparing manual features, deep learning models, and EEG foundation models for ERP analysis. 2. Established a unified data preprocessing and training pipeline and evaluated methods on two tasks across 12 public datasets. 3. Investigated various patch-embedding strategies within Transformer architectures to identify designs better suited for ERP data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58ac79c471f534c1c0facf539a3aecc0242ffa2b33fb14835383bc5dbe5a8d85_w640_q70.webp
  - **Simple LLM Summary:** This paper benchmarks methods for analyzing Event-Related Potentials (ERPs) in EEG data. It systematically compares traditional manual features, deep learning models, and pre-trained foundation models using a unified pipeline across 12 datasets. The study provides a framework for method selection and identifies effective Transformer embedding strategies for ERP data.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Benchmarking ERP Analysis] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[ERP分析中深度学习方法有效性未充分探索/Deep learning effectiveness on ERP data underexplored]
        C --> C1[建立统一预处理与训练流水线/Establish unified preprocessing & training pipeline]
        C --> C2[系统比较三类方法/Systematically compare three method categories]
        C --> C3[研究Transformer的Patch嵌入策略/Investigate Transformer patch-embedding strategies]
        D --> D1[提供方法选择与模型设计框架/Provide framework for method selection & model design]
    ```

- **[arXiv260105] Three factor delay learning rules for spiking neural networks**
  - **tags:** [mlsys], [on-device ai], [spiking neural networks, delay learning, three-factor learning, online learning, neuromorphic processors]
  - **authors:** Luke Vassallo, Nima Taherinejad
  - **institution:** Heidelberg University
  - **link:** https://arxiv.org/pdf/2601.00668
  - **contributions:** 1. Introduced learnable synaptic and axonal delays into LIF-based SNNs and proposed novel three-factor learning rules for online, simultaneous learning of both weights and delays. 2. Employed a smooth Gaussian surrogate gradient exclusively for eligibility trace calculation to enable gradient-equivalent delay parameter updates. 3. Demonstrated significant improvements in model efficiency, achieving up to 6.6x model size reduction and 67% lower inference latency with minimal accuracy loss, enabling on-device learning for resource-constrained environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58cabcbc7350cb70af9599a2c224309ae64c370ecf64ef754054d42693a8f504_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limited temporal learning capability of Spiking Neural Networks (SNNs) by introducing learnable synaptic and axonal delays and proposing online three-factor learning rules to train them. The method uses a Gaussian surrogate gradient for eligibility traces and achieves competitive accuracy on temporal tasks like speech recognition while drastically reducing model size and latency. The findings facilitate efficient, on-device learning for power and area-constrained neuromorphic hardware.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Three factor delay learning rules for spiking neural networks] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[SNNs lack temporal parameters/SNNs缺乏时间参数]
        B --> B2[Existing delay learning is offline & large/现有延迟学习是离线的且模型大]
        C --> C1[Learnable synaptic & axonal delays/可学习的突触和轴突延迟]
        C --> C2[Three-factor online learning rules/三因素在线学习规则]
        C --> C3[Gaussian surrogate for eligibility trace/用于资格迹的高斯代理梯度]
        D --> D1[Accuracy improved up to 20%/准确率提升高达20%]
        D --> D2[Model size reduced 6.6x/模型大小减少6.6倍]
        D --> D3[Latency reduced 67%/延迟降低67%]
    ```

- **[arXiv260105] QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [quantization, spike-driven language models (SLMs), memory footprint, tiered search, embedded systems]
  - **authors:** Rachmad Vidya Wicaksana Putra, Pasindu Wickramasinghe, Muhammad Shafique
  - **institution:** New York University (NYU) Abu Dhabi
  - **link:** https://arxiv.org/pdf/2601.00679
  - **contributions:** 1. Proposes QSLM, an automated quantization framework for compressing pre-trained Spike-driven Language Models (SLMs) to meet performance and memory constraints. 2. Introduces a tiered quantization strategy (global-, block-, and module-level) guided by network hierarchy and layer sensitivity analysis. 3. Leverages a multi-objective performance-and-memory trade-off function to select the final quantization setting, achieving significant memory and power reduction while maintaining high task performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/911838f93e33219fcf586121369dd081b9908c86a1169c367cfdd1bb7e50139b_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes QSLM, an automated framework for quantizing Spike-driven Language Models (SLMs) to reduce their memory footprint for embedded deployment. It uses a tiered search strategy based on network hierarchy and layer sensitivity, along with a multi-objective trade-off function, to find optimal quantization settings. Experimental results show QSLM can reduce memory by up to 86.5% and power by up to 20% while maintaining performance close to the original model.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models] --> B
        A --> C
        A --> D
        B[核心问题/Problem: SLMs内存占用大，难以部署在资源受限的嵌入式设备/SLMs have large memory footprints, challenging for resource-constrained embedded deployment]
        C[主要方法/Method: 自动化分层量化策略，结合网络层次、层敏感性和多目标权衡函数/Automated tiered quantization strategy using network hierarchy, layer sensitivity, and multi-objective trade-off]
        D[关键结果/Results: 内存占用减少高达86.5%，功耗降低高达20%，性能接近原始模型/Memory footprint reduced by up to 86.5%, power by up to 20%, performance close to original model]
    ```

- **[arXiv260105] Cost Optimization in Production Line Using Genetic Algorithm**
  - **tags:** [ai], [combinatorial optimization], [genetic algorithm, task scheduling, production line, chromosome encoding, JGAP]
  - **authors:** Alireza Rezaee
  - **institution:** University of Tehran
  - **link:** https://arxiv.org/pdf/2601.00689
  - **contributions:** 1. Proposes and compares two chromosome encoding strategies (station-based and task-based) for a GA applied to a production line scheduling problem. 2. Adapts standard GA operators (crossover, mutation, etc.) to preserve solution feasibility under precedence and capacity constraints. 3. Empirically demonstrates that the task-based encoding yields smoother convergence and more reliable cost minimization, especially for problems with a large number of valid schedules.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d46632061e4499187a195e89a09ba37b6eff28c44f9881da5b237c2b781953b_w640_q70.webp
  - **Simple LLM Summary:** This paper applies a genetic algorithm to optimize task scheduling in a production line to minimize cost. It investigates two different ways to represent the schedule (encoding) within the algorithm and finds that a task-based encoding performs better, converging more smoothly to lower-cost solutions. The study shows GAs are advantageous for this type of complex, constrained scheduling problem.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cost Optimization in Production Line Using Genetic Algorithm] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[最小化生产线成本/Minimize Production Line Cost]
        B --> B2[任务调度与约束/Task Scheduling with Constraints]
        C --> C1[遗传算法/Genetic Algorithm]
        C --> C2[两种编码策略/Two Encoding Strategies]
        C2 --> C21[基于工位的编码/Station-based Encoding]
        C2 --> C22[基于任务的编码/Task-based Encoding]
        D --> D1[基于任务的编码性能更优/Task-based Encoding Performs Better]
        D --> D2[更平滑的收敛/Smoother Convergence]
        D --> D3[更可靠的优化/More Reliable Optimization]
    ```

- **[arXiv260105] Quadratic Unconstrained Binary Optimisation for Training and Regularisation of Binary Neural Networks**
  - **tags:** [mlsys], [on-device ai], [binary neural networks, quadratic unconstrained binary optimization, ising machine, regularization, simulated annealing]
  - **authors:** Jonas Christoffer Villumsen, Yusuke Sugita
  - **institution:** Hitachi Europe Ltd., Hitachi Ltd.
  - **link:** https://arxiv.org/pdf/2601.00449
  - **contributions:** 1. Extends existing QUBO models for training Binary Neural Networks to accommodate arbitrary network topologies. 2. Proposes a novel regularization method that maximizes neuron margins to bias training toward configurations with larger pre-activation magnitudes. 3. Proposes a second novel, dropout-inspired iterative regularization scheme that trains reduced subnetworks to adjust linear penalties on network parameters.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28133ab4719e6b11d3441bf2c924e33139268781e601ff1ef434dd50fa7de88c_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of efficiently training discrete Binary Neural Networks (BNNs) by formulating the training as a Quadratic Unconstrained Binary Optimization (QUBO) problem. It extends existing QUBO models to arbitrary network topologies and introduces two new regularization methods to improve generalization. Experimental results on a GPU-based Ising machine show that the proposed methods modify training behavior and improve classification accuracy on unseen data.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Quadratic Unconstrained Binary Optimisation for Training and Regularisation of Binary Neural Networks] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[训练二元神经网络的挑战/Challenge of training BNNs]
        C --> C1[扩展QUBO模型/Extend QUBO models]
        C --> C2[提出两种正则化方法/Propose two regularization methods]
        C2 --> C2_1[最大化神经元间隔/Maximize neuron margins]
        C2 --> C2_2[Dropout启发式迭代方案/Dropout-inspired iterative scheme]
        D --> D1[正则化改变训练行为/Regularization modifies training behavior]
        D --> D2[提升未见数据分类精度/Improves classification accuracy on unseen data]
    ```
