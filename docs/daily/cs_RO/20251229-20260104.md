---
slug: /daily/csro/20251229-20260104
---
# 20251229-20260104 (cs.RO)

## 2025-12-29

- **[arXiv251229] Safe Path Planning and Observation Quality Enhancement Strategy for Unmanned Aerial Vehicles in Water Quality Monitoring Tasks**
  - **tags:** [cv], [robotic perception and planning], [Interfered Fluid Dynamical System (IFDS), Model Predictive Control (MPC), Dynamic Flight Altitude Adjustment (DFAA)]
  - **authors:** Yuanshuang Fu, Qianyao Wang, Qihao Wang, Bonan Zhang, Jiaxin Zhao, Yiming Cao, Zhijun Li
  - **institution:** University of Electronic Science and Technology of China, North China University of Technology
  - **link:** https://arxiv.org/pdf/2512.21375
  - **contributions:** 1. Proposes a dynamic prediction model that transforms time-varying light and shadow disturbances (e.g., sun glint) into 3D virtual obstacles for path planning. 2. Introduces an improved IFDS algorithm combined with an MPC framework to generate smooth, safe, and dynamically feasible real-time trajectories for UAVs. 3. Designs a Dynamic Flight Altitude Adjustment (DFAA) mechanism to actively lower flight altitude in narrow observable areas, enhancing spatial resolution and data quality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5582bc8dd27c45953b75b142df4da9d25f5164a9ed81f8842a846572fbb8a2f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of UAV water quality monitoring being hindered by dynamic illumination disturbances like shadows and sun glint, which degrade spectral data. The proposed method actively plans safe flight paths by modeling disturbances as obstacles, using an improved IFDS and MPC for real-time trajectory optimization, and dynamically adjusting altitude to improve data quality. Simulation results show the method achieves a 98% obstacle avoidance success rate and increases effective observation data volume by approximately 27%.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Safe Path Planning and Observation Quality Enhancement Strategy for UAVs in Water Quality Monitoring Tasks] --> B
    A --> C
    A --> D
    B[核心问题/Problem<br>Dynamic illumination disturbances (shadows, sun glint) cause spectral distortion, reducing data quality and safety.]
    C[主要方法/Method<br>1. Model disturbances as 3D virtual obstacles.<br>2. Improved IFDS + MPC for real-time path planning.<br>3. Dynamic Flight Altitude Adjustment (DFAA).]
    D[关键结果/Results<br>98% obstacle avoidance success rate, improved path smoothness, ~27% increase in effective observation data.]
    ```

- **[arXiv251229] Fast Navigation Through Occluded Spaces via Language-Conditioned Map Prediction**
  - **tags:** [ai], [robot navigation], [language-conditioned planning, map forecasting, Log-MPPI]
  - **authors:** Rahul Moorthy Mahesh, Oguzhan Goktug Poyrazoglu, Yukang Cao, Volkan Isler
  - **institution:** University of Minnesota (inferred from author "Volkan Isler")
  - **link:** https://arxiv.org/pdf/2512.21398
  - **contributions:** 1. Introduces PaceForecaster, a novel architecture that integrates co-pilot language instructions into local motion planning. 2. Predicts a forecasted map (Level-2) of occluded areas and an instruction-conditioned subgoal within it. 3. Demonstrates a 36% improvement in navigation performance by integrating PaceForecaster with a Log-MPPI controller.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e1b55661a25fc48b61cda55eadcd0e6f2f90bf3fac6514d8b38c5f3883d102b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the speed-safety trade-off in robot navigation in occluded environments by introducing PaceForecaster, a method that uses language instructions to forecast occluded map regions and generate conditioned subgoals. Integrating this with a Log-MPPI controller allows for more decisive and goal-directed planning. The approach improves navigation performance by 36% over a baseline that uses only the local sensor map.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Fast Navigation Through Occluded Spaces via Language-Conditioned Map Prediction] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[安全与速度的权衡<br/>Safety-Speed Trade-off]
        B1 --> B2[遮挡导致的不确定性<br/>Uncertainty from Occlusions]
        C --> C1[PaceForecaster 架构<br/>PaceForecaster Architecture]
        C1 --> C2[输入: 传感器足迹与指令<br/>Input: Sensor Footprint & Instruction]
        C2 --> C3[输出: 预测地图与子目标<br/>Output: Forecasted Map & Subgoal]
        C3 --> C4[集成 Log-MPPI 控制器<br/>Integrated with Log-MPPI Controller]
        D --> D1[性能提升 36%<br/>36% Performance Improvement]
        D1 --> D2[超越仅使用局部地图的基线<br/>Over Local-Map-Only Baseline]
    ```

- **[arXiv251229] Developing a Fundamental Diagram for Urban Air Mobility Based on Physical Experiments**
  - **tags:** [other], [Transportation Systems, Robotics], [Fundamental Diagram, Urban Air Mobility, Traffic Flow Theory, Drone Control, Physical Experiments]
  - **authors:** Hang Zhou, Yuhui Zhai, Shiyu Shen, Yanfeng Ouyang, Xiaowei Shi, Xiaopeng
  - **institution:** University of Wisconsin-Madison, University of Illinois Urbana-Champaign, University of Wisconsin-Milwaukee
  - **link:** https://arxiv.org/pdf/2512.21425
  - **code:** https://github.com/CATS-Lab/UAM-FD
  - **contributions:** 1. Proposes a novel framework integrating theory and physical experiments to construct a Fundamental Diagram for Urban Air Mobility traffic. 2. Develops and validates the first UAM Fundamental Diagram using real-world physical test data from a reduced-scale drone testbed. 3. Creates and releases the UAMTra2Flow dataset containing simulation and physical test trajectory data for UAM traffic analysis.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fcb69b60c91e88b8ff8fdb72d4cfe7a72f7f1c82ac3f0ed8afd4f7ca60297d6_w640_q70.webp
  - **Simple LLM Summary:** This study addresses the lack of understanding of Urban Air Mobility (UAM) traffic flow by proposing a framework to construct its Fundamental Diagram (FD) through theoretical modeling and physical experiments using drones. The results show that classical ground traffic FD structures are applicable to UAM, but physical experiments reveal deviations from simulation, underscoring the need for experimental validation. The findings and a public dataset provide practical insights for future UAM system design.
  - **Mindmap:**

    ```mermaid
    graph TB
    Root("Developing a Fundamental Diagram for Urban Air Mobility Traffic Flow / 构建城市空中交通基本图")
    Root --> Problem("UAM交通流特性未知 / UAM Traffic Flow Poorly Understood")
    Root --> Method("理论分析+物理实验框架 / Theory + Physical Experiment Framework")
    Root --> Results("经典FD结构适用，实验验证关键 / Classical FD Applicable, Validation Crucial")
    ```

- **[arXiv251229] EVE: A Generator-Verifier System for Generative Policies**
  - **tags:** [ai], [robot learning], [generative policies, test-time compute, vision-language models, verifier agents, embodied control]
  - **authors:** Yusuf Ali, Gryphon Patlin, Karthik Kothuri, Muhammad Zubair Irshad, Wuwei Liang, Zsolt Kira
  - **institution:** Georgia Institute of Technology, Toyota Research Institute, Symbotic Inc.
  - **link:** https://arxiv.org/pdf/2512.21430
  - **contributions:** 1. Proposes EVE, a modular generator-verifier framework that improves pretrained generative visuomotor policies at test time without additional training. 2. Introduces a system of multiple zero-shot VLM-based verifier agents that propose action refinements, coupled with an action incorporator to fuse these suggestions. 3. Provides a systematic analysis and practical guidelines for designing scalable generator-verifier systems for embodied control through extensive ablations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a88f407920b463e24f81294c5ecb39e2cf549c376fd258eaa250ec03d1cdbed1_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem that generative visuomotor policies degrade under distribution shifts and lack recovery capabilities. It proposes EVE, a framework that uses additional inference-time compute to refine a frozen base policy's actions via multiple zero-shot VLM verifiers. The method consistently improves task success rates across diverse manipulation tasks without any retraining.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[EVE: A Generator-Verifier System for Generative Policies] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Generative policies degrade under distribution shifts and lack recovery.] --> ProblemDetail[问题细节/Problem Detail: Costly to finetune; limited test-time robustness.]
        Method[主要方法/Method: EVE framework] --> MethodDetail1[方法细节/Method Detail 1: Wraps frozen base policy with zero-shot VLM verifiers.]
        Method --> MethodDetail2[方法细节/Method Detail 2: Verifiers propose action refinements.]
        Method --> MethodDetail3[方法细节/Method Detail 3: Action incorporator fuses verifier outputs.]
        Results[关键结果/Results: Boosts performance without training.] --> ResultsDetail[结果细节/Results Detail: Improves task success rates across diverse manipulation tasks.]
    ```

- **[arXiv251229] Planetary Terrain Datasets and Benchmarks for Rover Path Planning**
  - **tags:** [ai], [path planning], [global path planning, digital terrain models, autonomous navigation, rover exploration, benchmark datasets]
  - **authors:** Marvin Chancán, Avijit Banerjee, George Nikolakopoulos
  - **institution:** Luleå University of Technology
  - **link:** https://arxiv.org/pdf/2512.21438
  - **code:** https://github.com/mchancan/PlanetaryPathBench
  - **contributions:** 1. Proposes the first two large, space mission-derived planetary benchmark datasets for rover path planning (MarsPlanBench and MoonPlanBench). 2. Establishes a unified framework for evaluating both classical and learning-based path planning algorithms on these planetary terrains. 3. Provides new empirical insights into algorithm performance, showing classical methods achieve high success rates on challenging terrains while learning-based methods struggle to generalize.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbb45e523b7fc6a07c19646449f84300acdad583bbecaad64993aae93fddcf33_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of standardized planetary datasets and benchmarks for rover path planning by introducing MarsPlanBench and MoonPlanBench, two large datasets derived from high-resolution digital terrain models of Mars and the Moon. The authors evaluate classical and learning-based path planning algorithms in a unified framework on these new benchmarks. The key finding is that classical algorithms achieve very high success rates (up to 100%) on challenging planetary terrains, explaining their practical use by agencies like NASA, while learning-based models still face generalization difficulties in these domains.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Planetary Terrain Datasets and Benchmarks for Rover Path Planning] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[缺乏用于路径规划的行星数据集与基准/Lack of planetary datasets & benchmarks for path planning]
    C --> C1[提出火星与月球基准数据集/Propose MarsPlanBench & MoonPlanBench datasets]
    C --> C2[建立统一评估框架/Establish unified evaluation framework]
    D --> D1[经典算法成功率高达100%/Classical algorithms achieve up to 100% success rate]
    D --> D2[学习模型泛化困难/Learning-based models struggle to generalize]
    ```

- **[arXiv251229] Spatiotemporal Tubes for Probabilistic Temporal Reach-Avoid-Stay Task in Uncertain Dynamic Environment**
  - **tags:** [ai], [control theory], [spatiotemporal tube, probabilistic safety, real-time control, uncertain dynamic environment, reach-avoid-stay]
  - **authors:** Siddhartha Upadhyay, Ratnangshu Das, Pushpak Jagtap
  - **institution:** Robert Bosch Centre for Cyber-Physical Systems, Indian Institute of Science (IISc), Bengaluru
  - **link:** https://arxiv.org/pdf/2512.21497
  - **contributions:** 1. Extension of the Spatiotemporal Tube (STT) framework to handle Probabilistic Temporal Reach-Avoid-Stay (PrT-RAS) tasks in environments with time-varying uncertain obstacles. 2. Development of a real-time tube synthesis procedure that provides formal probabilistic safety guarantees. 3. Derivation of a closed-form, model-free, approximation-free, and optimization-free control law that confines the system within the tube for efficient real-time execution.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90c986ba71dbe6e082ded217bbbe89ccda980dde23fb1eaaed32b9bf8e4aa780_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes an extension of the Spatiotemporal Tube framework to solve Probabilistic Temporal Reach-Avoid-Stay tasks in uncertain dynamic environments. The method synthesizes a time-varying safe tube online and provides a closed-form control law to keep the system inside it, offering formal probabilistic safety and task completion guarantees. The approach is validated through simulations and hardware experiments on various robotic platforms.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Paper Title: Spatiotemporal Tubes for Probabilistic Temporal Reach-Avoid-Stay Task] --> B(核心问题/Problem: Probabilistic Temporal Reach-Avoid-Stay in uncertain dynamic environments)
        A --> C(主要方法/Method: Real-time Spatiotemporal Tube synthesis with closed-form control)
        A --> D(关键结果/Results: Formal probabilistic safety guarantees & efficient real-time execution)
    ```

- **[arXiv251229] A Novel Robotic Variable Stiffness Mechanism Based on Helically Wound Structured Electrostatic Layer Jamming**
  - **tags:** [other], [soft robotics, variable stiffness actuators], [electrostatic layer jamming, helical winding, variable stiffness robotic finger, voltage-driven control]
  - **authors:** Congrui Bai, Zhenting Du, Weibang Bai
  - **institution:** ShanghaiTech University, King's College London
  - **link:** https://arxiv.org/pdf/2512.21534
  - **contributions:** 1. Proposes a novel Helically Wound Structured Electrostatic Layer Jamming (HWS-ELJ) mechanism for variable stiffness., 2. Demonstrates that the helical configuration provides exponentially greater stiffness adjustment and a reduced footprint compared to conventional planar designs., 3. Develops and validates a functional robotic finger prototype that confirms the feasibility of voltage-driven stiffness modulation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/287c4eb37a5ab5af01f325e34fecea5969ff071b0b31c3e96ae601a3ad2f8fad_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a novel variable stiffness mechanism for robotics called Helically Wound Structured Electrostatic Layer Jamming (HWS-ELJ). It uses a helical configuration and electrostatic attraction to achieve tunable stiffness, offering superior performance and a smaller footprint than traditional planar designs. The work is validated through experiments and a functional robotic finger prototype, confirming its feasibility.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Novel Robotic Variable Stiffness Mechanism Based on Helically Wound Structured Electrostatic Layer Jamming] --> B(核心问题/Problem: Robotic joints need variable stiffness for adaptability and safety.)
        A --> C(主要方法/Method: Proposes HWS-ELJ, using helical winding and electrostatic attraction for tunable stiffness.)
        A --> D(关键结果/Results: HWS-ELJ shows superior stiffness enhancement and smaller footprint; a functional robotic finger prototype validates feasibility.)
    ```

- **[arXiv251229] World-Coordinate Human Motion Retargeting via SAM 3D Body**
  - **tags:** [cv], [human motion capture and retargeting], [SAM 3D Body, Momentum HumanRig, contact-aware optimization]
  - **authors:** Zhangzheng Tum, Kailun Su, Shaolong Zhu, Yukun Zheng
  - **institution:** Dalian University of Technology, Shenzhen University, Harbin Institute of Technology, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.21573
  - **contributions:** 1. Proposes a lightweight framework using a frozen SAM 3D Body backbone and Momentum HumanRig representation for world-coordinate human motion recovery from monocular video. 2. Introduces temporal consistency enforcement via identity/scale locking and efficient sliding-window smoothing in a low-dimensional latent space. 3. Recovers physically plausible global root trajectories using a differentiable soft foot-ground contact model and contact-aware optimization for reliable robot retargeting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ddf0876edffc654fb4ec059aced2eb58f78ddcb89551be7a907e2f5bdee145c_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a lightweight framework for recovering world-coordinate human motion from monocular video and retargeting it to a humanoid robot. The method leverages SAM 3D Body as a frozen backbone, enforces temporal consistency, smooths predictions, and uses a contact model for plausible global trajectories. Results show the method produces stable, robot-ready motion from monocular input.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[World-Coordinate Human Motion Retargeting via SAM 3D Body] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>从单目视频恢复世界坐标系人体运动并重定向到机器人]
        C[主要方法/Method<br>轻量级框架，使用冻结的SAM 3D Body，MHR表示，时序一致性约束，滑动窗口平滑，接触感知全局优化]
        D[关键结果/Results<br>稳定的世界轨迹，可靠的机器人重定向，从单目输入生成机器人就绪的运动]
    ```

- **[arXiv251229] SymDrive: Realistic and Controllable Driving Simulator via Symmetric Auto-regressive Online Restoration**
  - **tags:** [cv], [novel view synthesis], [diffusion models, 3D Gaussian Splatting, auto-regressive restoration, context-aware inpainting, view synthesis]
  - **authors:** Zhiyuan Liu, Daocheng Fu, Pinlong Cai, Lening Wang, Ying Liu, Yilong Ren, Botian Shi, Jianqiang Wang
  - **institution:** Tsinghua University, Shanghai Artificial Intelligence Laboratory, Beihang University
  - **link:** https://arxiv.org/pdf/2512.21618
  - **contributions:** 1. Proposes SymDrive, a unified diffusion-based framework for joint high-quality rendering and scene editing in autonomous driving simulation. 2. Introduces a Symmetric Auto-regressive Online Restoration paradigm for recovering fine-grained details and generating consistent lateral views. 3. Leverages the restoration capability for a training-free harmonization mechanism, treating vehicle insertion as context-aware inpainting to ensure lighting and shadow consistency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fc8335a8d121faeeab0173601f0f5c37fa7781ac9d3431d854039722cd203b51_w640_q70.webp
  - **Simple LLM Summary:** SymDrive addresses the challenge of creating high-fidelity and controllable 3D driving simulators by proposing a unified diffusion-based framework. It uses a symmetric auto-regressive online restoration method to enhance novel-view synthesis and a training-free harmonization mechanism for realistic vehicle insertion. The method achieves state-of-the-art performance in both rendering quality and scene editing realism.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SymDrive: Realistic and Controllable Driving Simulator via Symmetric Auto-regressive Online Restoration] --> B[核心问题/Problem: 现有方法难以同时实现高保真渲染和交互式交通编辑 / Existing methods struggle with joint photorealistic rendering and interactive traffic editing.]
        A --> C[主要方法/Method: 提出对称自回归在线修复范式与免训练协调机制 / Proposes Symmetric Auto-regressive Online Restoration paradigm and training-free harmonization mechanism.]
        A --> D[关键结果/Results: 在新视角增强和3D车辆插入中实现最先进性能 / Achieves SOTA performance in novel-view enhancement and realistic 3D vehicle insertion.]
    ```

- **[arXiv251229] AstraNav-Memory: Contexts Compression for Long Memory**
  - **tags:** [mlsys], [memory & caching], [visual context compression, image-centric memory, lifelong embodied navigation, DINOv3, Qwen2.5-VL]
  - **authors:** Botao Ren, Junjun Hu, Xinda Xue, Minghua Luo, Jintao Chen, Haochen Bai, Liangliang You, Mu Xu
  - **institution:** Alibaba Group (Amap), Tsinghua University, Peking University
  - **link:** https://arxiv.org/pdf/2512.21627
  - **code:** https://astra-amap.github.io/AstraNav-Memory.github.io/
  - **contributions:** 1. Proposed an image-centric memory framework for lifelong embodied navigation that uses an efficient visual context compression module to achieve long-term implicit memory. 2. Introduced a configurable visual tokenizer built on a ViT backbone with frozen DINOv3 features and lightweight PixelUnshuffle+Conv blocks, enabling high compression rates (e.g., 16x) to expand context capacity. 3. Demonstrated state-of-the-art navigation performance on benchmarks (GOAT-Bench, HM3D-OVON), showing improved exploration in unfamiliar environments and shorter paths in familiar ones, with ablation studies validating the efficiency-accuracy trade-off.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce3c5628c478fa221373bddffcb2cb72bd35c261cc9b555152b34063fccbb9f2_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of building long-term memory for lifelong embodied navigation. It proposes AstraNav-Memory, an image-centric framework that compresses visual contexts using a configurable tokenizer to efficiently store hundreds of images, coupled with a Qwen2.5-VL-based navigation policy. The method achieves state-of-the-art performance, balancing efficiency and accuracy for scalable lifelong agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AstraNav-Memory: Contexts Compression for Long Memory] --> B[核心问题/Problem: Lifelong embodied navigation requires efficient long-term spatial-semantic memory. Object-centric methods are limited by robustness and scalability.]
        A --> C[主要方法/Method: Propose an image-centric memory framework with a visual context compression module (ViT+DINOv3+PixelUnshuffle) coupled with a Qwen2.5-VL navigation policy.]
        A --> D[关键结果/Results: Achieves SOTA on GOAT-Bench and HM3D-OVON. Improves exploration in unfamiliar environments and shortens paths in familiar ones. Moderate compression offers best balance.]
    ```

- **[arXiv251229] Structural Induced Exploration for Balanced and Scalable Multi-Robot Path Planning**
  - **tags:** [ai], [swarm intelligence], [Ant Colony Optimization, structural prior, load-aware objective, overlap suppression, multi-robot path planning]
  - **authors:** Zikun Guo, Adeyinka P. Adedigba, Rammohan Mallipeddi, Heoncheol Lee
  - **institution:** Kyungpook National University, Kumoh National Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.21654
  - **contributions:** 1. Proposes a structure-induced exploration framework that integrates structural priors into ACO initialization to constrain the search space. 2. Designs a pheromone update rule that emphasizes structurally meaningful connections and incorporates a load-aware objective to balance total travel distance with individual robot workload. 3. Introduces an explicit overlap suppression strategy to ensure distinct and balanced task allocation across the robot team.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca4635b64758650f78e762004770f2a7ac8eb62cd36aa2db98d90af82d3f6eae_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of scalable and balanced multi-robot path planning. It proposes a new framework that integrates structural priors into Ant Colony Optimization, along with a load-aware objective and overlap suppression, to improve route compactness, stability, and workload distribution. The method demonstrates consistent improvements over metaheuristic baselines and offers a scalable solution for applications like logistics and search-and-rescue.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Structural Induced Exploration for Balanced and Scalable Multi-Robot Path Planning] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Multi-robot path planning is combinatorially complex and requires balancing global efficiency with fair task allocation. 传统方法难以扩展/Traditional methods struggle to scale.]
        C[主要方法/Method: A structure-induced ACO framework. 利用结构先验、负载感知目标和重叠抑制/Uses structural prior, load-aware objective, and overlap suppression.]
        D[关键结果/Results: Improves route compactness, stability, and workload distribution. 提供可扩展的框架/Provides a scalable framework.]
    ```

- **[arXiv251229] MAction-SocialNav: Multi-Action Socially Compliant Navigation via Reasoning-enhanced Prompt Tuning**
  - **tags:** [ai], [socially compliant navigation], [meta-cognitive prompt, vision language model, multi-action generation]
  - **authors:** Zishuo Wang, Xinyu Zhang, Zhuonan Liu, Tomohito Kawabata, Daeun Song, Xuesu Xiao, Ling Xiao
  - **institution:** Hokkaido University, George Mason University
  - **link:** https://arxiv.org/pdf/2512.21722
  - **contributions:** 1. Proposes MAction-SocialNav, a vision language model for socially compliant navigation that generates multiple plausible actions to handle real-world ambiguity. 2. Introduces a novel meta-cognitive prompt (MCP) method to enhance the model's reasoning capability. 3. Curates a new multi-action socially compliant navigation dataset with diverse conditions and dual human annotations, and designs five evaluation metrics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08864b9cd92dd7e9f4041ef22b9caf54fe559ad301e22a19b24957d3cb331538_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of action ambiguity in socially compliant robot navigation by proposing MAction-SocialNav, an efficient vision language model that generates multiple plausible actions per scenario using a novel meta-cognitive prompt tuning method. The method is evaluated on a newly curated dataset and shows superior decision quality, safety alignment, and real-time efficiency compared to large language models like GPT-4o and Claude.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["MAction-SocialNav: Multi-Action Socially Compliant Navigation via Reasoning-enhanced Prompt Tuning"] --> Problem["核心问题/Problem: Social norms are ambiguous; multiple actions may be acceptable, but existing methods assume a single correct action."]
        Root --> Method["主要方法/Method: Proposes an efficient VLM with a novel meta-cognitive prompt (MCP) to generate multiple plausible actions."]
        Root --> Results["关键结果/Results: Achieves higher decision quality and safety than GPT-4o/Claude while maintaining real-time efficiency."]
    ```

- **[arXiv251229] HELP: Hierarchical Embodied Language Planner for Household Tasks**
  - **tags:** [mlsys], [agent system], [embodied agent, hierarchical planning, large language model, household tasks, open source LLM]
  - **authors:** Alexandr V. Korchemnyi, Anatoly O. Onishchenko, Eva A. Bakaeva, Alexey K. Kovalev, Aleksandr I. Panov
  - **institution:** MIRAI, Cognitive AI Systems Lab
  - **link:** https://arxiv.org/pdf/2512.21723
  - **contributions:** 1. Proposes a Hierarchical Embodied Language Planner (HELP) architecture using multiple LLM-based agents for decomposing and grounding natural language instructions. 2. Demonstrates the approach on a real-world household task using an embodied agent. 3. Focuses on the use of relatively small, open-source LLMs to enable autonomous deployment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d5e8ef0910254268525eec44918d2562afe5a6df81ece96ba720311313fef5b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of planning for embodied agents following ambiguous natural language instructions in complex environments. It proposes HELP, a hierarchical planner using multiple LLM-based agents to decompose high-level instructions into grounded, executable subtasks. The method is evaluated on a household task with a real robot, showing the feasibility of using smaller, open-source LLMs for autonomous operation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HELP: Hierarchical Embodied Language Planner for Household Tasks] --> B[核心问题/Problem: Embodied agents need robust planning for ambiguous natural language instructions in complex environments.]
        A --> C[主要方法/Method: Hierarchical planner with multiple LLM-based agents to decompose and ground instructions into executable steps.]
        A --> D[关键结果/Results: Evaluated on real-world household task; demonstrates use of smaller open-source LLMs for autonomous deployment.]
    ```

- **[arXiv251229] MoonBot: Modular and On-Demand Reconfigurable Robot Toward Moon Base Construction**
  - **tags:** [other], [space robotics], [modular robot, reconfigurable robot, lunar construction, field demonstration, connector design]
  - **authors:** Kentaro Uno, Elian Neppel, Gustavo H. Diaz, Ashutosh Mishra, Shamistan Karimov, A. Sejal Jain, Ayesha Habib, Pascal Pama, Hazal Gozbasi, Shreya Santra, Kazuya Yoshida
  - **institution:** Space Robotics Laboratory (SRL), Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University
  - **link:** https://arxiv.org/pdf/2512.21853
  - **contributions:** 1. Introduces MoonBot, a modular and reconfigurable robotic system designed for lunar payload constraints and task adaptability. 2. Details the system's design and development, including a field demonstration simulating lunar infrastructure tasks like civil engineering and component deployment. 3. Systematically summarizes lessons learned, particularly on connector design, to inform future modular robotic systems for lunar missions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7ceec836e29be790b6ca39392714dc64e19923b0842210e75988ad1c5fdeeb2_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces MoonBot, a modular and reconfigurable robot designed for constructing lunar bases under strict mass constraints. It details the robot's design and validates its concept through field demonstrations of simulated construction tasks. The work concludes with lessons learned, especially regarding connector design, to guide future lunar robotic systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[MoonBot: 面向月球基地建设的模块化按需可重构机器人] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[月球探索与基地建设需求 / Lunar Exploration & Base Construction Needs]
        C --> C1[模块化可重构机器人系统 / Modular & Reconfigurable Robotic System]
        C --> C2[概念验证与现场演示 / Proof-of-Concept & Field Demonstration]
        D --> D1[成功执行模拟任务 / Successfully Executed Simulated Tasks]
        D --> D2[总结了连接器设计等经验教训 / Summarized Lessons (e.g., Connector Design)]
    ```

- **[arXiv251229] Optimal Trajectory Planning for Orbital Robot Rendezvous and Docking**
  - **tags:** [other], [space robotics], [trajectory planning, nonlinear optimization, dynamic keep-out sphere, ON/OFF thrusters, rendezvous and docking]
  - **authors:** Kenta Iizuka, Akiyoshi Uchida, Kentaro Uno, Kazuya Yoshida
  - **institution:** Tohoku University
  - **link:** https://arxiv.org/pdf/2512.21882
  - **contributions:** 1. A trajectory planning method based on nonlinear optimization for close-range rendezvous with a tumbling target. 2. The introduction of a dynamic keep-out sphere that adapts to approach conditions for safer access. 3. A control strategy to reproduce the optimized trajectory using discrete ON/OFF thrusters, considering practical implementation constraints.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0619d27a582b3a86da2ec2f90d52c42f5327490ba9737fc6b241e03569d2be3b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of safely approaching a tumbling space debris object for capture. It proposes a trajectory planning method using nonlinear optimization with a dynamic safety boundary and a control strategy for ON/OFF thrusters. The method enables closer and safer access as a preliminary step for robotic capture.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Optimal Trajectory Planning for Orbital Robot Rendezvous and Docking") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("安全接近翻滚目标/Safely approaching a tumbling target")
        Method --> M1("非线性优化轨迹规划/Nonlinear optimization-based trajectory planning")
        Method --> M2("动态禁入球体/Dynamic keep-out sphere")
        Method --> M3("ON/OFF推进器控制/ON/OFF thruster control strategy")
        Results --> R1("更近更安全的访问/Closer and safer access")
        Results --> R2("考虑实际约束/Practical implementation considered")
    ```

- **[arXiv251229] Online Inertia Parameter Estimation for Unknown Objects Grasped by a Manipulator Towards Space Applications**
  - **tags:** [other], [robotics, dynamics and control], [inertia parameter estimation, online identification, momentum conservation, floating-base robots, space robotics]
  - **authors:** Akiyoshi Uchida, Antonine Richard, Kentaro Uno, Miguel Olivares-Mendez, Kazuya Yoshida
  - **institution:** Tohoku University, University of Luxembourg
  - **link:** https://arxiv.org/pdf/2512.21886
  - **contributions:** 1. Extended an existing online inertia identification method to be applicable to floating-base robots by incorporating momentum conservation. 2. Validated the proposed method through numerical simulations for space applications like on-orbit servicing. 3. Demonstrated accurate estimation of unknown object inertia parameters during manipulation in a simulated microgravity environment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/56413666705f0b959b1c7926a7846dc2d7421e2c52ee8ac46620538562104026_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of estimating the inertia parameters of an unknown object grasped by a manipulator on a free-floating space robot. The authors extend an existing online identification method by incorporating momentum conservation to handle the floating base. Numerical simulations validate the method, showing accurate identification and highlighting its potential for on-orbit servicing missions.
  - **Mindmap:**

    ```mermaid
    graph TB
    Root(Online Inertia Parameter Estimation for Unknown Objects Grasped by a Manipulator Towards Space Applications) --> Problem(核心问题/Problem)
    Root --> Method(主要方法/Method)
    Root --> Results(关键结果/Results)
    Problem --> P1(估计未知被抓取物体的惯性参数/Estimate inertia parameters of unknown grasped object)
    Problem --> P2(面向自由漂浮基座的空间机器人/For floating-base space robots)
    Method --> M1(应用并扩展在线识别方法/Apply and extend online identification method)
    Method --> M2(结合动量守恒定律/Incorporate momentum conservation)
    Results --> R1(通过数值模拟验证/Validated via numerical simulation)
    Results --> R2(参数识别准确/Accurate parameter identification)
    Results --> R3(适用于在轨服务/Applicable to on-orbit servicing)
    ```

- **[arXiv251229] Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space**
  - **tags:** [cv], [visual navigation], [world model, future frame projection, 4-dof uav, long-horizon visual generation, aerial navigation]
  - **authors:** Weichen Zhang, Peizhi Tang, Xin Zeng, Fanhang Man, Shiquan Yu, Zichao Dai, Baining Zhao, Hongjin Chen, Yu Shang, Wei Wu, Chen Gao, Xinlei Chen, Xin Wang, Yong Li, Wenwu Zhu
  - **institution:** Tsinghua University
  - **link:** https://arxiv.org/pdf/2512.21887
  - **contributions:** 1. Proposes ANWM, an aerial navigation world model for predicting future visual observations to incorporate high-level semantics into UAV path planning. 2. Introduces a physics-inspired Future Frame Projection (FFP) module to provide coarse geometric priors and mitigate uncertainty in long-distance visual generation. 3. Demonstrates superior performance in long-distance visual forecasting and improves UAV navigation success rates in large-scale 3D environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02f69e3df37002aba4354016667950073739b574c3c8044ad15f65d9721e62db_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes ANWM, an aerial navigation world model that predicts future visual observations for UAVs using a novel Future Frame Projection module. It addresses the challenges of complex 4-DoF action spaces and long-horizon visual generation. The model outperforms existing methods in visual forecasting and enhances navigation success in large-scale environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[UAV导航缺乏高层语义规划能力/UAV navigation lacks high-level semantic planning]
        B --> B2[现有模型难以处理复杂动作空间与长距离视觉生成/Existing models struggle with complex action space & long-horizon visual generation]
        C --> C1[提出ANWM世界模型/Propose ANWM world model]
        C --> C2[引入未来帧投影模块/Introduce Future Frame Projection module]
        D --> D1[长距离视觉预测性能显著提升/Significantly outperforms in long-distance visual forecasting]
        D --> D2[提高大规模环境导航成功率/Improves UAV navigation success rates in large-scale environments]
    ```

- **[arXiv251229] Flexible Multitask Learning with Factorized Diffusion Policy**
  - **tags:** [mlsys], [diffusion models], [diffusion policy, modular architecture, multitask learning, imitation learning, mixture-of-experts]
  - **authors:** Chaoqi Liu, Haonan Chen, Sigmund H. Høeg, Shaoxiong Yao, Yunzhu Li, Kris Hauser, Yilun Du
  - **institution:** University of Illinois at Urbana-Champaign, Harvard University, Norwegian University of Science and Technology, Columbia University
  - **link:** https://arxiv.org/pdf/2512.21898
  - **contributions:** 1. Introduces a novel modular diffusion policy framework (FDP) that factorizes complex action distributions into a composition of specialized diffusion models. 2. Proposes continuous score aggregation via an observation-conditioned router for stable training and clear component specialization, addressing issues in standard MoE. 3. Demonstrates that the modular structure enables flexible policy adaptation to new tasks and mitigates catastrophic forgetting.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b261f496908cd892964760d9f52edb76c57a6126f2c6a9969b7e36d9d43b048e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of multitask imitation learning in robotics, where complex action distributions are difficult to model. It proposes a Factorized Diffusion Policy (FDP) that decomposes the policy into specialized diffusion components and composes them via a router. The method outperforms baselines in simulation and real-world manipulation and supports flexible adaptation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Flexible Multitask Learning with Factorized Diffusion Policy] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[机器人多任务学习/Robot Multitask Learning]
        B1 --> B2[动作分布复杂多模态/Action Distribution Highly Multimodal]
        B2 --> B3[单体模型欠拟合与不灵活/Monolithic Models Underfit & Inflexible]
        C --> C1[因子化扩散策略/Factorized Diffusion Policy (FDP)]
        C1 --> C2[模块化扩散专家/Modular Diffusion Experts]
        C2 --> C3[基于观察的路由器/Observation-Conditioned Router]
        C3 --> C4[连续分数聚合/Continuous Score Aggregation]
        D --> D1[性能超越基线/Outperforms Baselines]
        D1 --> D2[仿真与真实机器人验证/Simulation & Real-World Validation]
        D2 --> D3[支持灵活策略适应/Enables Flexible Policy Adaptation]
    ```

- **[arXiv251229] StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision**
  - **tags:** [cv], [robotic vision], [stereo vision, vision-language-action models, geometric-semantic fusion, depth estimation, robotic manipulation]
  - **authors:** Shengliang Deng, Mi Yan, Yixin Zheng, Jiayi Su, Wenhao Zhang, Xiaoguang Zhao, Heming Cui, Zhizheng Zhang, He Wang
  - **institution:** Peking University, The University of Hong Kong, Institute of Automation, Chinese Academy of Sciences, Beijing Academy of Artificial Intelligence
  - **link:** https://arxiv.org/pdf/2512.21970
  - **code:** https://shengliangd.github.io/StereoVLA-Webpage
  - **contributions:** 1. Proposed StereoVLA, a novel Vision-Language-Action model that leverages stereo vision for enhanced spatial perception. 2. Introduced a Geometric-Semantic Feature Extraction module to fuse geometric cues from stereo differences with semantic features from a monocular view. 3. Designed an auxiliary Interaction-Region Depth Estimation task to improve spatial understanding and accelerate model convergence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fbd07a25a843958488215748e8162f92542370bba173316326de44d4be3c65f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of single-view input in Vision-Language-Action (VLA) models for robotic manipulation by introducing StereoVLA, which utilizes stereo vision. The core method involves a novel module to extract and fuse geometric and semantic features, along with an auxiliary depth estimation task. Experiments show the model significantly outperforms baselines in stereo-based tasks and is robust to camera pose variations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1(单目VLA模型缺乏精确的几何感知/Single-view VLAs lack accurate geometry perception)
        C --> C1(提出StereoVLA模型/Propose StereoVLA model)
        C1 --> C2(几何-语义特征提取模块/Geometric-Semantic Feature Extraction)
        C2 --> C3(从立体视图提取几何特征/Extract geometric features from stereo views)
        C2 --> C4(从单目视图提取语义特征/Extract semantic features from monocular view)
        C1 --> C5(辅助交互区域深度估计任务/Auxiliary Interaction-Region Depth Estimation task)
        D --> D1(在立体设置下大幅超越基线/Large margin outperforms baselines under stereo setting)
        D --> D2(对相机位姿变化具有强鲁棒性/Strong robustness to camera pose variations)
    ```

- **[arXiv251229] Bab_Sak Robotic Intubation System (BRIS): A Learning-Enabled Control Framework for Safe Fiberoptic Endotracheal Intubation**
  - **tags:** [cv], [medical robotics], [robotic intubation, closed-loop control, shape sensing, depth estimation, human-in-the-loop]
  - **authors:** Saksham Gupta, Sarthak Mishra, Arshad Ayub, Kamran Farooque, Spandan Roy, Babita Gupta
  - **institution:** International Institute of Information Technology Hyderabad (IIIT-H), All India Institute of Medical Sciences, New Delhi (AIIMS)
  - **link:** https://arxiv.org/pdf/2512.21983
  - **contributions:** 1. A compact, integrated robotic platform (BRIS) for fiberoptic-guided intubation, featuring a steerable bronchoscope, an independent tube advancement mechanism, and a camera-augmented mouthpiece. 2. A learning-enabled closed-loop control framework that uses real-time shape sensing to map joystick inputs to precise bronchoscope tip motion, ensuring stable teleoperation despite tendon nonlinearities. 3. The use of monocular endoscopic depth estimation to classify airway regions and provide anatomy-aware guidance for safe endotracheal tube positioning relative to the carina.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c843dca48b820a7b40108d200bec7f3af89493cac93374b9ac37ec6874acfd9_w640_q70.webp
  - **Simple LLM Summary:** This paper presents the Bab Sak Robotic Intubation System (BRIS), a human-in-the-loop platform designed to assist with safe fiberoptic endotracheal intubation. It integrates a learning-enabled control framework for stable scope navigation and uses monocular depth estimation for anatomy-aware tube placement guidance. The system was validated on airway mannequins, demonstrating reliable performance as a step toward safer and more consistent robotic airway management.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[BRIS: 安全光纤插管系统 / BRIS: Safe Fiberoptic Intubation System] --> B[核心问题/Problem: 插管技术难度高，现有系统不完善 / Problem: Intubation is difficult, existing systems are limited]
        A --> C[主要方法/Method: 集成机器人平台与学习控制框架 / Method: Integrated robotic platform with learning-enabled control]
        A --> D[关键结果/Results: 在人体模型上验证可靠 / Results: Validated as reliable on mannequins]
        B --> B1[并发症风险高 / High risk of complications]
        B --> B2[缺乏集成管推进与深度验证 / Lacks integrated tube control & depth verification]
        C --> C1[闭环控制与形状感知 / Closed-loop control & shape sensing]
        C --> C2[单目深度估计引导 / Monocular depth estimation guidance]
        D --> D1[可靠导航 / Reliable navigation]
        D --> D2[可控置管 / Controlled tube placement]
    ```
