---
slug: /daily/csro/20260105-20260111
---
# 20260105-20260111 (cs.RO)

## 2026-01-05

- **[arXiv260105] Reinforcement learning with timed constraints for robotics motion planning**
  - **tags:** [ai], [reinforcement learning], [Metric Interval Temporal Logic (MITL), Timed Limit-Deterministic Generalized Büchi Automata (Timed-LDGBA), Q-learning, POMDP]
  - **authors:** Zhaoan Wang, Junchao Li, Mahdi Mohammad, Shaoping Xiao
  - **institution:** University of Iowa, Talus Renewables, Inc., Roma Tre University
  - **link:** https://arxiv.org/pdf/2601.00087
  - **contributions:** 1. Proposes a unified automata-based RL framework for synthesizing policies under MITL specifications in both MDPs and POMDPs. 2. Introduces a translation of MITL formulas into Timed-LDGBA and their synchronization with decision processes to create product timed models for Q-learning. 3. Validates the framework with simulation studies showing it satisfies time-bounded requirements, scales to larger state spaces, and works in partially observable environments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/556427a99f7edc810f0aa638c014e36ca104d451bbd5edf5c81df58176b568d9_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the challenge of integrating formal temporal logic (MITL) with reinforcement learning for robotic motion planning under stochastic and partially observable dynamics. It proposes a method that translates MITL specifications into timed automata and synchronizes them with the decision process to enable policy learning via Q-learning. The results demonstrate that the learned policies successfully satisfy strict time constraints in various simulated environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Reinforcement learning with timed constraints for robotics motion planning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[复杂任务序列与严格时间约束/Complex task sequences & strict temporal constraints]
        B --> B2[随机动态与部分可观测性/Stochastic dynamics & partial observability]
        C --> C1[MITL公式转换为Timed-LDGBA/MITL to Timed-LDGBA translation]
        C --> C2[构建产品定时模型与Q学习/Construct product timed models for Q-learning]
        C --> C3[简单而富有表现力的奖励结构/Simple yet expressive reward structure]
        D --> D1[满足时间约束的策略/Policies satisfy time-bounded requirements]
        D --> D2[扩展到更大状态空间/Scales to larger state spaces]
        D --> D3[在部分可观测环境中有效/Effective in partially observable environments]
    ```

- **[arXiv260105] GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments**
  - **tags:** [ai], [reinforcement learning], [geometric reinforcement learning, Hamiltonian optimization, simultaneous navigation and mapping, local sensory observations, path differential]
  - **authors:** Aditya Sai Ellendula, Yi Wang, Minh Nguyen, Chandrajit Bajaj
  - **institution:** University of Texas at Austin
  - **link:** https://arxiv.org/pdf/2601.00116
  - **code:** https://github.com/ (as per the abstract "The code is publicly available on Github." The specific URL is not provided in the given text, only a placeholder link.)
  - **contributions:** 1. Proposes a novel geometric reinforcement learning framework (GRL-SNAM) for Simultaneous Navigation and Mapping that relies exclusively on local sensory observations without constructing a global map. 2. Formulates navigation and mapping as a dynamic shortest path search using controlled Hamiltonian optimization, translating sensory inputs into local energy landscapes and evolving policies via updating Hamiltonians. 3. Demonstrates that the method enables high-quality navigation with minimal exploration through local energy refinement, preserving clearance and generalizing to unseen environments in 2D navigation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/776eec0810502d9188877dd04875e090e89eaeb9b6aaa3dec59b37da20fe81b7_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping (SNAM) in unknown environments. It formulates the problem as a dynamic shortest path search using Hamiltonian optimization, where local sensory data is used to update energy landscapes and refine trajectories without building a global map. The method is shown to achieve efficient, high-quality navigation with minimal exploration and good generalization in 2D tasks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GRL-SNAM: Geometric RL for SNAM] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Simultaneous Navigation and Mapping in mapless environments]
        C[主要方法/Method: Geometric RL with Path Differential Hamiltonians, local energy landscapes]
        D[关键结果/Results: High-quality navigation with minimal exploration, generalizes to unseen layouts]
    ```

- **[arXiv260105] Compositional Diffusion with Guided search for Long-Horizon Planning**
  - **tags:** [ai], [diffusion models], [compositional generation, mode averaging, guided search, diffusion denoising, long-horizon planning]
  - **authors:** Utkarsh A Mishra, David He, Yongxin Chen, Danfei Xu
  - **institution:** Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.00126
  - **code:** https://cdgsearch.github.io/
  - **contributions:** 1. Proposes Compositional Diffusion with Guided Search (CDGS) to solve the mode averaging problem in compositional generative models. 2. Embeds a search mechanism within the diffusion denoising process, combining population-based sampling, likelihood-based filtering, and iterative resampling. 3. Demonstrates strong performance on robot manipulation tasks and generalizes to domains like panoramic image synthesis and long video generation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41034b12b6ab0eabc5d0ac493a8094944df0b3944c3c4fe217daaa776e14f15b_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the mode averaging problem in compositional generative models for long-horizon planning. It proposes CDGS, a method that integrates guided search into the diffusion process to explore and prune local mode combinations for globally coherent outputs. The approach matches oracle performance on robot tasks and generalizes across domains without requiring long-horizon training data.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Compositional Diffusion with Guided Search for Long-Horizon Planning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Mode Averaging in Compositional Models<br/>组合模型中的模式平均问题]
        C --> C1[Embedded Search in Diffusion<br/>在扩散过程中嵌入搜索]
        C --> C2[Population Sampling & Filtering<br/>群体采样与过滤]
        C --> C3[Iterative Resampling<br/>迭代重采样]
        D --> D1[Matches Oracle Performance<br/>匹配Oracle性能]
        D --> D2[Generalizes Across Domains<br/>跨领域泛化]
    ```

- **[arXiv260105] SLEI3D: Simultaneous Exploration and Inspection via Heterogeneous Fleets under Limited Communication**
  - **tags:** [other], [multi-robot systems], [heterogeneous fleets, collaborative 3D exploration, intermittent communication, multi-layer planning, adaptive inspection]
  - **authors:** Junfeng Chen, Yuxiao Zhu, Xintong Zhang, Bing Luo, Meng Guo
  - **institution:** Peking University, Duke Kunshan University
  - **link:** https://arxiv.org/pdf/2601.00163
  - **contributions:** 1. A novel planning and coordination framework (SLEI3D) for simultaneous 3D exploration, adaptive inspection, and timely communication under limited communication constraints. 2. A multi-layer and multi-rate planning mechanism to handle uncertainties in feature number/location and coordinate plans within and between robot subgroups. 3. Validation of the framework through extensive high-fidelity simulations with up to 48 robots and hardware experiments with 7 robots, demonstrating efficiency and robustness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d02320f0074d134e681c8dbb5de6d7da4b9e27eafb70994ef7ddece708f1a6f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes SLEI3D, a planning framework for heterogeneous robot fleets to simultaneously explore unknown 3D environments, inspect identified features, and relay findings back to a control station under limited communication. The method employs a multi-layer, multi-rate planning mechanism and intermittent/proactive communication protocols to coordinate subgroups of robots online. The framework is validated as efficient and reliable through large-scale simulations and hardware experiments.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["SLEI3D: Simultaneous Exploration and Inspection via Heterogeneous Fleets under Limited Communication"] --> Problem["核心问题/Problem: Coordinating heterogeneous fleets for simultaneous exploration and inspection in unknown environments with limited communication"]
        Root --> Method["主要方法/Method: Multi-layer, multi-rate planning with intermittent/proactive communication protocols"]
        Root --> Results["关键结果/Results: Validated via large-scale simulation (48 robots) and hardware experiments (7 robots)"]
    ```

- **[arXiv260105] CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting**
  - **tags:** [cv], [3D instance segmentation], [Neural Radiance Field (NeRF), 3D instance segmentation, crop counting, mask consistency, view synthesis]
  - **authors:** Md Ahmed Al Muzaddid, William J. Beksi
  - **institution:** The University of Texas at Arlington
  - **link:** https://arxiv.org/pdf/2601.00207
  - **contributions:** 1. A novel framework for exact crop enumeration via 3D instance segmentation using multi-view images and NeRF. 2. Introduction of crop visibility and mask consistency scores to effectively segment instances in 3D. 3. Demonstration of consistent performance across diverse crops (cotton, apples, pears) without crop-specific parameter tuning and release of a new cotton plant dataset.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/47e945ab54ccf5cb00069822c1c6264667ea9ffbd12ce279cdcb2f58a39c38ec_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces CropNeRF, a framework for accurate crop counting in agriculture. It uses multi-view 2D images and instance masks to train a Neural Radiance Field (NeRF), incorporating novel visibility and consistency scores to perform 3D instance segmentation and count crops. The method shows superior counting performance across different crop types and releases a new dataset to advance research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[户外遮挡与聚类导致计数困难/Outdoor occlusions and clustering make counting hard]
        C --> C1[使用多视角图像与NeRF进行3D实例分割/Use multi-view images & NeRF for 3D instance segmentation]
        C --> C2[引入可见性与掩码一致性分数/Introduce visibility & mask consistency scores]
        D --> D1[在多种作物上实现准确计数/Achieve accurate counting on multiple crops]
        D --> D2[性能优于现有方法/Outperforms state-of-the-art]
        D --> D3[贡献棉花数据集/Contribute a cotton dataset]
    ```

- **[arXiv260105] Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection**
  - **tags:** [cv], [object detection], [CycleGAN, YOLOv8, infrared image generation, data augmentation, PCB defect detection]
  - **authors:** Chao Yang, Haoyuan Zheng, Yue Ma
  - **institution:** Xi’an Jiaotong Liverpool University
  - **link:** https://arxiv.org/pdf/2601.00237
  - **contributions:** 1. Proposes a cross-modal data augmentation framework using CycleGAN for unpaired translation from visible-light to infrared images to address IR data scarcity. 2. Introduces a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a YOLOv8 detector. 3. Demonstrates that the method significantly improves detection performance under low-data conditions, approaching fully supervised benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6328838143840b03119bcacf495d6f90fd2cfbf75f09c866a7d8dbf7d351c32_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the problem of scarce infrared data for PCB defect detection by using CycleGAN to generate synthetic infrared images from abundant visible-light images and training a YOLOv8 detector on this augmented dataset. The proposed method enhances feature learning with limited real data, significantly outperforming models trained only on real data and nearly matching the performance of fully supervised training.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection"] --> Problem["核心问题/Problem: 红外数据稀缺 / IR Data Scarcity"]
        Root --> Method["主要方法/Method: CycleGAN跨模态生成 + YOLOv8检测 / CycleGAN Cross-modal Generation + YOLOv8 Detection"]
        Root --> Results["关键结果/Results: 性能显著提升，接近全监督基准 / Performance Significantly Improved, Approaches Fully Supervised Benchmark"]
    ```

- **[arXiv260105] SLAP: Slapband-based Autonomous Perching Drone with Failure Recovery for Vertical Tree Trunks**
  - **tags:** [other], [robotics], [perching drone, slapband gripper, failure recovery, vertical surface, autonomous flight]
  - **authors:** Julia Di, Kenneth A. W. Hoffmann, Tony G. Chen, Tian-Ao Ren, Mark R. Cutkosky
  - **institution:** Stanford University, Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.00238
  - **contributions:** 1. A novel gentle perching approach for larger drones on vertical surfaces using a fast active elastic gripper with microspines made from commercially-available slapbands. 2. A system-level integration featuring vision-based perch site detection, IMU-based failure detection, and an attitude controller for soft perching. 3. Demonstrated autonomous perching with failure recovery, achieving a 75% success rate in initial indoor flight experiments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd4fbed8060d82defaf56320fa59f4bb60a1215cf321aee59a80fa75b633d2f4_w640_q70.webp
  - **Simple LLM Summary:** This paper presents SLAP, a system for enabling drones to autonomously and gently perch on vertical tree trunks. The key innovation is a gripper made from slapbands with microspines, combined with detection and control modules for soft landing and failure recovery. Initial experiments on a modified quadrotor showed a 75% perch success rate and 100% recovery from induced failures.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SLAP: Slapband-based Autonomous Perching Drone] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[垂直表面栖息困难/Vertical Surface Perching is Hard]
        B1 --> B2[现有方法高速且危险/Existing methods are high-speed and dangerous]
        C --> C1[系统集成/System Integration]
        C1 --> C2[基于视觉的栖息点检测/Vision-based perch site detector]
        C1 --> C3[基于IMU的失败检测/IMU-based failure detector]
        C1 --> C4[软栖息姿态控制器/Attitude controller for soft perching]
        C1 --> C5[拍腕带弹性夹爪/Slapband-based elastic gripper]
        D --> D1[75%栖息成功率/75% perch success rate]
        D --> D2[100%失败恢复率/100% failure recovery rate]
    ```

- **[arXiv260105] Vehicle Painting Robot Path Planning Using Hierarchical Optimization**
  - **tags:** [other], [robotic path planning], [hierarchical optimization, vehicle routing problem (VRP), constraint handling, evolutionary computation]
  - **authors:** Yuya Nagai, Hiromitsu Nakamura, Narito Shinmachi, Yuta Higashizono, Satoshi Ono
  - **institution:** Kagoshima University, TOYOTA Body Research & Development Co., Ltd.
  - **link:** https://arxiv.org/pdf/2601.00271
  - **contributions:** 1. Formulates vehicle painting robot path planning as a hierarchical optimization problem, separating high-level task assignment (VRP-like) from low-level detailed path planning. 2. Proposes a flexible constraint handling framework for the painting process through custom variable representation, repair operators, and initialization. 3. Demonstrates the method's effectiveness by automatically generating paths for commercial vehicles that are comparable in quality to manual designs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd6fcb32eb9c80960a0ed996281f691e7732ffdfe85f78eaf940b5a4d0c7ce64_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the manual and time-consuming task of planning paint paths for multiple robotic arms in vehicle factories. It proposes a hierarchical optimization method that treats the problem as a high-level vehicle routing task and a low-level detailed path planning task, enabling automated design. Experiments on real vehicle models show the method can generate constraint-satisfying paths of comparable quality to those created by human engineers.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Vehicle Painting Robot Path Planning Using Hierarchical Optimization") --> Problem("核心问题/Problem: Manual paint path design for multiple robotic arms is time-consuming")
        Root --> Method("主要方法/Method: Hierarchical optimization (Upper: VRP-like assignment, Lower: detailed path planning)")
        Root --> Results("关键结果/Results: Automatically generates constraint-satisfying paths comparable to manual designs")
    ```

- **[arXiv260105] Pure Inertial Navigation in Challenging Environments with Wheeled and Chassis Mounted Inertial Sensors**
  - **tags:** [other], [inertial navigation], [wheel-mounted inertial sensors, chassis-mounted inertial sensors, extended Kalman filter, pure inertial navigation]
  - **authors:** Dusan Nemec, Gal Versano, Itai Savin, Vojtech Simak, Juraj Kekelak, Itzik Klein
  - **institution:** University of Zilina, University of Haifa
  - **link:** https://arxiv.org/pdf/2601.00275
  - **contributions:** 1. Proposed WiCHINS, a novel wheeled and chassis inertial navigation system combining sensors from different vehicle locations. 2. Derived a three-stage estimation framework, each stage utilizing a dedicated Extended Kalman Filter. 3. Demonstrated improved accuracy for pure inertial navigation, achieving an average position error of 2.4% of the traveled distance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cf2c7ce1d6afe2abf0464e5b8ec3ff0435d40e0b4e57f8ff6a56d9f2f35553e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of inertial navigation drift for autonomous vehicles in GNSS-denied or visually degraded environments. It proposes WiCHINS, a system that fuses data from wheel-mounted and chassis-mounted inertial sensors using a three-stage Extended Kalman Filter framework. The method significantly reduces position error, enabling more robust pure inertial navigation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Pure Inertial Navigation in Challenging Environments<br/>挑战环境下的纯惯性导航] --> B(Problem: Inertial drift in GNSS/vision-limited conditions<br/>问题: GNSS/视觉受限下的惯性漂移)
        A --> C(Method: WiCHINS - Fuse wheel & chassis IMUs with 3-stage EKF<br/>方法: WiCHINS - 融合轮式与底盘IMU的三阶段EKF框架)
        A --> D(Results: 11.4m avg error (2.4% of distance)<br/>结果: 11.4米平均误差(距离的2.4%))
    ```

- **[arXiv260105] Replaceable Bit-based Gripper for Picking Cluttered Food Items**
  - **tags:** [other], [robotics, food handling], [replaceable gripper, bit-based system, weight-specific dropping, cluttered food, bento box automation]
  - **authors:** Prashant Kumar, Yukiyasu Domae, Weiwei Wan, Kensuke Harada
  - **institution:** Based on author names and context, likely a Japanese research institution (e.g., Osaka University, AIST). Specific institution not explicitly stated in provided text.
  - **link:** https://arxiv.org/pdf/2601.00305
  - **contributions:** 1. Proposed a novel replaceable bit-based gripper system designed for handling diverse, cluttered, and flexible food items. 2. Introduced specialized, food-specific attachment bits (e.g., for ikura and spaghetti) to enhance grasping capabilities for challenging food categories. 3. Demonstrated a system capable of weight-specific picking and dropping with high accuracy (&gt;80% for spaghetti, &gt;95% for ikura) and quick bit switching for operational flexibility.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b10fd54305281ee91551575494169fb7c342e6d6d74a74b115dfc4ee87dcd441_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of automating the handling of cluttered, flexible, and granular food items for bento box packaging. It proposes a gripper system with replaceable, food-specific bits and a belt replacement mechanism to grasp and accurately drop target weights of different foods. The system successfully demonstrated high-accuracy, weight-specific handling of ikura and spaghetti and allows for rapid adaptation between food types.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Replaceable Bit-based Gripper for Picking Cluttered Food Items] --> B(核心问题/Problem: Handling cluttered, flexible food items with weight control for packaging)
        A --> C(主要方法/Method: Replaceable bit-based gripper system with food-specific attachments)
        A --> D(关键结果/Results: Successful picking & >80%/95% weight-drop accuracy for spaghetti/ikura; Quick bit switching)
    ```

- **[arXiv260105] Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers**
  - **tags:** [cv], [semantic segmentation], [dense visual embeddings, knowledge distillation, RGB-D transformer, real-time inference, Alpha-CLIP]
  - **authors:** Söhnke Benedikt Fischedick, Daniel Seichter, Benedict Stephan, Robin Schmidt, Horst-Michael Gross
  - **institution:** Technische Universität Ilmenau
  - **link:** https://arxiv.org/pdf/2601.00359
  - **contributions:** 1. Proposes DVEFormer, an efficient RGB-D Transformer-based model for predicting dense, text-aligned visual embeddings via knowledge distillation from Alpha-CLIP. 2. Enables flexible, open-vocabulary scene understanding (e.g., text-based querying) beyond fixed-class semantic segmentation while maintaining the ability to perform classical segmentation. 3. Demonstrates real-time performance on embedded hardware (NVIDIA Jetson AGX Orin), making it suitable for mobile robotics applications like 3D mapping.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5eb4801e4f56b1c232cf2b5828f41733ec3576e1fe32d825febbfdde2e108d6c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the need for robots to have a detailed, open-vocabulary understanding of indoor environments. It proposes DVEFormer, an efficient model that uses an RGB-D Transformer and knowledge distillation from Alpha-CLIP to predict dense visual embeddings, enabling both classical segmentation and flexible text-based querying. The method achieves competitive performance and real-time inference speeds, making it a practical drop-in replacement for traditional segmentation in mobile robotics.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[机器人需要全面、开放词汇的场景理解/Robots need comprehensive, open-vocabulary scene understanding]
        C --> C1[使用RGB-D Transformer和知识蒸馏/Use RGB-D Transformer and Knowledge Distillation]
        C1 --> C2[从Alpha-CLIP教师模型学习密集视觉嵌入/Learn Dense Visual Embeddings from Alpha-CLIP teacher]
        D --> D1[实现实时性能与有竞争力的结果/Achieves real-time performance & competitive results]
        D --> D2[支持文本查询和3D映射/Enables text-based querying & 3D mapping]
    ```

- **[arXiv260105] Space Debris Removal using Nano-Satellites controlled by Low-Power Autonomous Agents**
  - **tags:** [mlsys], [agent system], [autonomous agents, multi-agent systems, low-power embedded systems, nano-satellites, space debris removal]
  - **authors:** Dennis Christmann, Juan F. Gutierrez, Sthiti Padhi, Patrick Plörer, Aditya Takur, Simona Silvestri, Andres Gomez
  - **institution:** Technische Universität Braunschweig (TU Braunschweig)
  - **link:** https://arxiv.org/pdf/2601.00465
  - **contributions:** 1. Proposes a novel application of low-power autonomous agents for space debris removal using nano-satellite swarms. 2. Implements autonomous agent software on resource-constrained wireless microcontrollers. 3. Demonstrates the feasibility and energy efficiency of the approach through experiments on a specialized test-bed.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/162af2b08fc214951045fe887fa77c6a53132c5f821aafaa9132122ac6d19730_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of space debris by proposing the use of autonomous nano-satellite swarms for de-orbiting. The method involves implementing low-power autonomous agent software on wireless microcontrollers to control these swarms. The work concludes by demonstrating the feasibility and energy efficiency of this approach through experimental validation.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Space Debris Removal using Nano-Satellites<br>空间碎片清除使用纳卫星"] --> Problem["空间碎片问题<br>Space Debris Problem"]
        Root --> Method["低功耗自主智能体控制纳卫星群<br>Low-Power Autonomous Agents Control Nano-Satellite Swarm"]
        Root --> Results["展示可行性与能效<br>Demonstrates Feasibility & Energy Efficiency"]
    ```

- **[arXiv260105] Variable Elimination in Hybrid Factor Graphs for Discrete-Continuous Inference & Estimation**
  - **tags:** [ai], [probabilistic graphical models], [hybrid factor graphs, variable elimination, conditional linear gaussian, exact inference, slam]
  - **authors:** Varun Agrawal, Frank Dellaert
  - **institution:** Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2601.00545
  - **contributions:** 1. Proposes a novel Hybrid Factor Graph framework with a hybrid Gaussian factor and hybrid conditional for modeling discrete-continuous problems. 2. Derives a hybrid variable elimination algorithm under the Conditional Linear Gaussian scheme to produce exact posteriors as a hybrid Bayes network. 3. Introduces a tree-structured factor representation with pruning and probabilistic assignment to bound discrete hypotheses and ensure tractable inference.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba63dbee87ea804f9a68c06addc0916e514ecc262180b1bcb37f36f06370de49_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of performing exact inference in hybrid problems involving both discrete and continuous variables, common in robotics. It proposes a new Hybrid Factor Graph framework and a variable elimination algorithm that yields exact Maximum A Posteriori estimates and marginals. The method is demonstrated to be accurate and tractable on a SLAM dataset with ambiguous data association.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Variable Elimination in Hybrid Factor Graphs<br>混合因子图中的变量消除] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[Hybrid discrete-continuous inference is difficult<br>混合离散-连续推理困难]
        B --> B2[Existing approaches are approximate<br>现有方法基于近似]
        C --> C1[Novel hybrid factor & conditional<br>新型混合因子与条件分布]
        C --> C2[Hybrid variable elimination algorithm<br>混合变量消除算法]
        C --> C3[Tree-structured pruning for tractability<br>树结构剪枝保证可处理性]
        D --> D1[Exact MAP estimation & marginalization<br>精确MAP估计与边缘化]
        D --> D2[Demonstrated on SLAM with ambiguous data<br>在SLAM模糊数据关联中验证]
        D --> D3[Shows accuracy, generality, simplicity<br>展示精度、通用性、简洁性]
    ```

- **[arXiv260105] Optimal Transport-Based Decentralized Multi-Agent Distribution Matching**
  - **tags:** [ai], [multi-agent systems], [optimal transport, Wasserstein distance, decentralized control, distribution matching, sequential weight-update]
  - **authors:** Kooktae Lee
  - **institution:** New Mexico Institute of Mining and Technology
  - **link:** https://arxiv.org/pdf/2601.00548
  - **contributions:** 1. Reformulated the global optimal transport distribution-matching problem into a tractable per-agent decision process using only local information. 2. Introduced a sequential weight-update rule and a memory-based correction mechanism to handle intermittent communication. 3. Established convergence guarantees for the proposed decentralized framework under both linear and nonlinear agent dynamics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8fe088e282f40c32d9ba8ce2686dcb5df3a1b0a69d86f1cf5042766dd92e8e1_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a decentralized control framework for multi-agent distribution matching using optimal transport theory. It enables each agent to determine its target location locally via a sequential weight-update rule and a memory-based correction mechanism, avoiding a centralized optimal transport solver. The method is proven to converge and is demonstrated through simulations to be effective and scalable.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Optimal Transport-Based Decentralized Multi-Agent Distribution Matching"] --> Problem["核心问题/Problem<br>Multi-agent systems need to achieve a prescribed terminal spatial distribution under decentralized, local information constraints."]
        Root --> Method["主要方法/Method<br>Reformulates global OT into per-agent process; uses sequential weight-update and memory-based correction for local plans."]
        Root --> Results["关键结果/Results<br>Convergence guarantees established; framework achieves effective, scalable distribution matching fully decentralized."]
    ```

- **[arXiv260105] LLM-Based Agentic Exploration for Robot Navigation & Manipulation with Skill Orchestration**
  - **tags:** [mlsys], [agent system], [semantic mapping, LLM-based decision, modular motion primitives, AprilTag, ROS]
  - **authors:** Abu Hanif Muhammad Syarubany, Farhan Zaki Rahmani, Trio Widianto
  - **institution:** Korea Advanced Institute of Science & Technology (KAIST)
  - **link:** https://arxiv.org/pdf/2601.00555
  - **contributions:** 1. An end-to-end LLM-based agentic exploration system for indoor shopping tasks, integrating perception, mapping, and action. 2. A lightweight semantic mapping approach that incrementally builds a map from detected signboards and uses AprilTags as repeatable anchors for navigation. 3. A modular ROS-based execution stack where an LLM provides high-level discrete commands and a finite-state controller gates low-level motion primitives for safe task execution.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/535aa877825dca3fad1c33dd6360354f727986e717cee5cc6c3ee4ffaea1881a_w640_q70.webp
  - **Simple LLM Summary:** This paper presents an LLM-based robotic system for autonomous indoor shopping. The robot explores an environment, builds a semantic map from visual cues like signboards and AprilTags, and uses an LLM to interpret natural language requests and generate navigation and manipulation decisions, which are executed by a modular ROS controller. The integrated system successfully demonstrates end-to-end task execution from instruction to object retrieval in both simulation and a real-world corridor setup.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["LLM-Based Agentic Exploration for Robot Navigation & Manipulation with Skill Orchestration"] --> Problem["核心问题/Problem: How to integrate perception, semantic mapping, and LLM decision-making for end-to-end robotic task execution in an unknown indoor environment?"]
        Root --> Method["主要方法/Method: Robot builds a lightweight semantic map from signboards and AprilTags; LLM generates discrete actions; ROS controller executes actions using modular motion primitives."]
        Root --> Results["关键结果/Results: The system can perform end-to-end shopping tasks from instruction to object retrieval in simulation and real-world, remaining modular and debuggable."]
    ```

- **[arXiv260105] Priority-Aware Multi-Robot Coverage Path Planning**
  - **tags:** [ai], [multi-robot path planning], [coverage path planning, priority-weighted latency, lexicographic optimization, spanning-tree, Steiner-tree]
  - **authors:** Kanghoon Lee, Hyeonjun Kim, Jiachen Li, Jinkyoo Park
  - **institution:** Korea Advanced Institute of Science and Technology (KAIST), Korea Military Academy (KMA), University of California, Riverside (UCR)
  - **link:** https://arxiv.org/pdf/2601.00580
  - **contributions:** 1. Formally defines the Priority-Aware Multi-Robot Coverage Path Planning (PA-MCPP) problem, introducing priority weights and a lexicographic objective to minimize priority-weighted latency and makespan. 2. Proposes a scalable two-phase framework combining greedy zone assignment with local search and Steiner-tree-guided residual coverage. 3. Demonstrates through experiments that the method significantly reduces priority-weighted latency compared to baselines while maintaining competitive makespan and scales well with the number of robots.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4091ae11f186a26844a6a1c27c13cf633fa92da4e6636d53275a7d839f775d9f_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limitation of standard multi-robot coverage path planning, which treats all areas equally, by introducing a priority-aware version (PA-MCPP) where certain zones have higher urgency. The authors propose a two-phase method that first assigns and covers priority zones efficiently and then handles the remaining area. Experiments show their approach successfully reduces coverage delay for high-priority zones without significantly compromising the overall completion time.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Priority-Aware Multi-Robot Coverage Path Planning] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[标准MCPP忽视区域优先级/Standard MCPP ignores zone priority]
        C --> C1[两阶段框架: 贪心分配与斯坦纳树引导覆盖/Two-phase framework: greedy assignment & Steiner-tree-guided coverage]
        D --> D1[显著降低优先级加权延迟/Significantly reduces priority-weighted latency]
        D --> D2[保持有竞争力的完工时间/Maintains competitive makespan]
    ```

- **[arXiv260105] NMPC-Augmented Visual Navigation and Safe Learning Control for Large-Scale Mobile Robots**
  - **tags:** [ai], [robotics control], [nonlinear model predictive control, robust adaptive control, deep neural network, visual pose estimation, safety module]
  - **authors:** Mehdi Heydari Shahna, Pauli Mustalahti, Jouni Mattila
  - **institution:** Tampere University
  - **link:** https://arxiv.org/pdf/2601.00609
  - **contributions:** 1. A comprehensive four-module navigation and control framework integrating visual pose estimation, high-level NMPC, a low-level DNN policy with robust adaptive control, and a safety module for large-scale mobile robots. 2. A low-level control framework that guarantees uniform exponential stability for the actuation subsystem. 3. A logarithmic safety module designed to monitor the entire robot stack and ensure system-level safety during operation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/858a2542ad097a42549017d22fa566990bbeaddab1e84e94c1b158ffa217822d_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a navigation and control framework for large-scale mobile robots operating on slip-prone terrain. The method combines visual pose estimation, nonlinear model predictive control, a deep neural network control policy augmented with robust adaptive control, and a safety module to ensure stability and safety. The framework was validated on a 6,000 kg robot, demonstrating robust operation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[NMPC-Augmented Visual Navigation and Safe Learning Control for Large-Scale Mobile Robots] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LSMR在松散地形上易打滑/LSMR prone to slip on loose terrain]
        C --> C1[视觉位姿估计/Visual Pose Estimation]
        C --> C2[高层NMPC/High-level NMPC]
        C --> C3[低层DNN控制策略/Low-level DNN Control Policy]
        C --> C4[安全模块/Safety Module]
        D --> D1[保证执行器子系统稳定/Guarantees actuation subsystem stability]
        D --> D2[确保系统级安全/Ensures system-level safety]
        D --> D3[在6000kg机器人上验证/Validated on a 6000kg robot]
    ```

- **[arXiv260105] From 2D to 3D terrain-following area coverage path planning**
  - **tags:** [other], [robotics path planning], [terrain-following, area coverage, inverse distance weighting, working height, agricultural robotics]
  - **authors:** Mogens Plessen
  - **institution:** Findklein GmbH
  - **link:** https://arxiv.org/pdf/2601.00614
  - **contributions:** 1. Proposes a novel 3D terrain-following area coverage path planning algorithm that simultaneously accounts for a specific working width and working height, a gap identified in existing literature. 2. Highlights algorithmic complexities compared to 2D planning, including uniformly spaced elevation data generation using Inverse Distance Weighting and a local search. 3. Validates the algorithm using real-world 3D terrain data within an agricultural context.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b87ce191d5ee1f6c0b66e89f7d4260d7328c4767f9b3668dbfe5ab4e429e010_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a new algorithm for generating 3D area coverage paths for ground vehicles that must follow terrain while maintaining a specific working width and height, such as for agricultural spraying. The method addresses limitations of prior 2D projection approaches by directly planning in 3D, using techniques like Inverse Distance Weighting for elevation data. It is validated with real-world agricultural terrain data.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[From 2D to 3D terrain-following area coverage path planning] --> B(核心问题/Problem: 2D路径规划方法在起伏地形上无法同时保证工作宽度和高度/2D path planning fails to maintain working width and height over 3D terrain)
        A --> C(主要方法/Method: 提出3D地形跟随区域覆盖路径规划算法/Propose 3D terrain-following area coverage path planning algorithm)
        C --> D(使用反距离加权生成均匀高程数据/Use Inverse Distance Weighting for elevation data)
        C --> E(使用局部搜索/Local search)
        A --> F(关键结果/Results: 在真实农业3D地形数据上验证算法/Validate algorithm on real-world agricultural 3D terrain data)
    ```

- **[arXiv260105] Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework**
  - **tags:** [ai], [reinforcement learning], [reinforcement learning, robust adaptive control, visual pose estimation, hierarchical learning, safety supervisor]
  - **authors:** Mehdi Heydari Shahna, Pauli Mustalahti, Jouni Mattila
  - **institution:** Tampere University
  - **link:** https://arxiv.org/pdf/2601.00610
  - **contributions:** 1. A hierarchical learning framework that decomposes the goal-reaching control problem into tightly coupled modules, including RL for planning and supervised learning for dynamics modeling. 2. Integration of a model-based robust adaptive controller with the learned dynamics model to guarantee wheel command tracking on slip-prone terrain, ensuring uniform exponential stability. 3. Design of a mathematical safety supervisor to autonomously monitor the robot, stop it on unsafe faults, and guide it back to a safe area, reducing human intervention.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/588ba572bdf33b4091ce883350b57f99b3a43b7383f0188394f0a36af791cfc3_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a hierarchical learning framework for safe, vision-based goal-reaching control of large mobile robots. The method combines reinforcement learning for motion planning, supervised learning for robot dynamics modeling, and a robust adaptive controller for stable actuation, all overseen by a safety supervisor. Experiments on a 6,000 kg robot confirm the framework's effectiveness and safety guarantees.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[RL探索不安全/Unsafe RL Exploration]
        B --> B2[大型机器人应用受限/Limited Application for Large Robots]
        C --> C1[视觉位姿估计/Visual Pose Estimation]
        C --> C2[RL运动规划器/RL Motion Planner]
        C --> C3[监督学习动力学模型/Supervised Learning Dynamics Model]
        C --> C4[鲁棒自适应控制器/Robust Adaptive Controller]
        C --> C5[数学安全监督器/Mathematical Safety Supervisor]
        D --> D1[保证稳定性/Guarantees Stability]
        D --> D2[实验验证有效性/Experimental Validation]
    ```

- **[arXiv260105] RoboReward: General-Purpose Vision-Language Reward Models for Robotics**
  - **tags:** [ai], [reinforcement learning], [vision-language models, reward modeling, reinforcement learning, data augmentation, robotics]
  - **authors:** Tony Lee, Andrew Wagenmaker, Karl Pertsch, Percy Liang, Sergey Levine, Chelsea Finn
  - **institution:** Stanford University, UC Berkeley
  - **link:** https://arxiv.org/pdf/2601.00675
  - **contributions:** 1. Introduces RoboReward, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment and RoboArena. 2. Proposes a negative examples data augmentation pipeline to generate calibrated negatives and near-misses for training. 3. Trains and deploys general-purpose 4B/8B vision-language reward models that outperform larger VLMs and improve real-robot RL policy learning.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a3d93ea0589a39158950d54cbe397e38c6b0ab250252ddc7e117e74f8d59010_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of designing rewards for robotic reinforcement learning by introducing RoboReward, a dataset and benchmark for training vision-language reward models. The method includes a data augmentation pipeline to create negative examples and trains compact 4B/8B parameter models. The results show these models outperform larger VLMs on short-horizon tasks and significantly improve real-robot policy learning compared to a frontier VLM.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RoboReward: General-Purpose Vision-Language Reward Models for Robotics] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Reward design for RL is labor-intensive or brittle/RL奖励设计费时或脆弱]
        C --> C1[Build dataset & benchmark from OXE & RoboArena/基于OXE和RoboArena构建数据集与基准]
        C --> C2[Propose negative examples augmentation pipeline/提出负样本数据增强流程]
        C --> C3[Train RoboReward 4B/8B VLMs/训练RoboReward 4B/8B VLM]
        D --> D1[No existing VLM excels across all tasks/现有VLM无全能模型]
        D --> D2[RoboReward models outperform larger VLMs/RoboReward模型优于更大VLM]
        D --> D3[Improves real-robot RL over Gemini Robotics-ER/在真实机器人RL中大幅超越Gemini]
    ```

- **[arXiv260105] DefVINS: Visual-Inertial Odometry for Deformable Scenes**
  - **tags:** [cv], [visual-inertial odometry], [deformable scenes, observability analysis, embedded deformation graph, IMU anchoring]
  - **authors:** Samuel Cerezo, Javier Civera
  - **institution:** Universidad de Zaragoza
  - **link:** https://arxiv.org/pdf/2601.00702
  - **contributions:** 1. A VIO framework (DefVINS) that explicitly separates rigid motion (IMU-anchored) from non-rigid deformation (modeled by an embedded deformation graph). 2. An observability analysis characterizing how inertial measurements constrain rigid motion and identify modes in deformable scenes. 3. A conditioning-based activation strategy that progressively enables non-rigid degrees of freedom to prevent ill-posed updates.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b312fb0bd7d9381dfbae957a5aabad3939766f96c58738070e2c5334cb31268_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces DefVINS, a visual-inertial odometry framework designed for deformable scenes. It separates rigid and non-rigid motion, uses an observability analysis to guide a progressive activation strategy for deformation, and shows improved robustness in non-rigid environments through ablation studies.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DefVINS: Visual-Inertial Odometry for Deformable Scenes] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[刚性假设失效 / Rigidity Assumption Violated]
        B --> B2[VIO在非刚性场景中漂移 / VIO Drift in Non-Rigid Scenes]
        C --> C1[分离刚性状态与非刚性形变 / Separate Rigid & Non-Rigid State]
        C --> C2[可观测性分析与IMU锚定 / Observability Analysis & IMU Anchoring]
        C --> C3[基于条件的渐进激活 / Conditioning-Based Progressive Activation]
        D --> D1[提升非刚性环境鲁棒性 / Improved Robustness in Non-Rigid Environments]
        D --> D2[消融实验验证有效性 / Ablation Studies Validate Benefits]
    ```

- **[arXiv260105] Bayesian Inverse Games with High-Dimensional Multi-Modal Observations**
  - **tags:** [ai], [inverse reinforcement learning], [Bayesian inference, variational autoencoder, Nash equilibrium, inverse games, multimodal observations]
  - **authors:** Yash Jain, Xinjie Liu, Lasse Peters, David Fridovich-Keil, Ufuk Topcu
  - **institution:** The University of Texas at Austin, Delft University of Technology
  - **link:** https://arxiv.org/pdf/2601.00696
  - **contributions:** 1. Proposes a Bayesian inference framework for inverse games to quantify uncertainty in estimating agent objectives, addressing the overconfidence of point-estimate methods. 2. Introduces a structured variational autoencoder with an embedded differentiable Nash game solver, enabling posterior sampling without requiring labeled objective data. 3. Demonstrates that multimodal inference reduces uncertainty when trajectory data is insufficient, leading to safer downstream planning decisions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9263c0ad6078bf92eb8f7a7ca21579f0a55a6e710fa80a06f40a66a735ce24a_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of inferring agents' hidden objectives in multi-agent interactions, where existing maximum likelihood methods produce overconfident point estimates. The authors propose a Bayesian inverse game framework using a structured variational autoencoder with a differentiable Nash solver to generate posterior samples from multimodal observations. Experiments show the method improves inference quality, quantifies uncertainty, and enables safer autonomous decision-making compared to prior approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Bayesian Inverse Games with High-Dimensional Multi-Modal Observations") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("MLE方法只提供点估计，导致不确定性被忽略/MLE methods provide only point estimates, ignoring uncertainty")
        Problem --> P2("下游规划可能过度自信，导致不安全动作/Downstream planning can be overconfident, leading to unsafe actions")
        Method --> M1("近似贝叶斯推理框架/Approximate Bayesian inference framework")
        Method --> M2("结构化变分自编码器嵌入可微纳什求解器/Structured VAE with embedded differentiable Nash solver")
        Method --> M3("利用多模态观测数据/Utilizes multi-modal observation data")
        Results --> R1("成功学习先验和后验分布/Successfully learns prior and posterior distributions")
        Results --> R2("推理质量优于MLE方法/Improves inference quality over MLE")
        Results --> R3("多模态推理进一步减少不确定性/Multimodal inference further reduces uncertainty")
    ```

- **[arXiv260105] RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization**
  - **tags:** [cv], [SLAM (Simultaneous Localization and Mapping)], [Gaussian Splatting, Dense Initialization, DINOv3, Multi-view Triangulation, Real-time Mapping]
  - **authors:** Wei-Tse Cheng, Yen-Jen Chiou, Yuan-Fu Yang
  - **institution:** National Yang Ming Chiao Tung University
  - **link:** https://arxiv.org/pdf/2601.00705
  - **contributions:** 1. Proposes a one-shot, training-free dense Gaussian initialization via multi-view correspondence triangulation, replacing the iterative densification in GS-SLAM. 2. Introduces a robust correspondence generation method using DINOv3 descriptors refined by a confidence-aware inlier classifier. 3. Achieves faster convergence (~20% speedup), higher rendering fidelity, and maintains real-time performance (up to 925 FPS) while being compatible with existing GS-SLAM pipelines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4161c36bfb3fee2a260166b1caa94cf7f49f3bda268754e5be2f18620346aa62_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces RGS-SLAM, a robust SLAM framework that improves upon Gaussian Splatting SLAM by replacing its iterative densification with a one-shot, dense Gaussian initialization from triangulated multi-view correspondences. This method, using refined DINOv3 features, stabilizes mapping, accelerates convergence, and enhances rendering quality. Evaluations show it achieves competitive or superior accuracy and real-time performance compared to state-of-the-art systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[GS-SLAM的残差驱动致密化效率低/Inefficient residual-driven densification in GS-SLAM]
        C --> C1[一次性密集初始化/One-shot dense initialization]
        C1 --> C2[使用DINOv3特征与置信内点分类器/Using DINOv3 features & confidence-aware inlier classifier]
        C2 --> C3[多视角三角化生成高斯先验/Multi-view triangulation for Gaussian prior]
        D --> D1[收敛加速~20%/~20% faster convergence]
        D --> D2[更高渲染保真度/Higher rendering fidelity]
        D --> D3[实时性能达925 FPS/Real-time performance up to 925 FPS]
    ```

- **[arXiv260105] Calling for Backup: How Children Navigate Successive Robot Communication Failures**
  - **tags:** [other], [human-robot interaction], [successive robot error, child-robot interaction, error recovery, performance error, social error]
  - **authors:** Maria Teresa Parreira, Isabel Neto, Filipa Rocha, Wendy Ju
  - **institution:** Cornell University, Universidade de Lisboa
  - **link:** https://arxiv.org/pdf/2601.00754
  - **contributions:** 1. Reproduced the successive robot failure paradigm with children (ages 8-10) to explore their unique responses to repeated conversational errors. 2. Identified key behavioral differences between children and adults, such as children's increased disengagement (e.g., ignoring the robot, seeking adult help) and more flexible conversational expectations. 3. Provided empirical findings to inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6516606de03da03b1c7297f4e0a7fcb61612ec1bea932c4290e5d1ba746ac52a_w640_q70.webp
  - **Simple LLM Summary:** This study investigates how children respond to repeated robot communication failures by reproducing an adult-focused error paradigm with child participants. The method involved children interacting with a robot that failed to understand their prompts three times, with their behavioral responses recorded and analyzed. The main conclusion is that while children share some error-response strategies with adults, they exhibit more disengagement behaviors and maintain a stable perception of the robot, suggesting different interaction needs that should guide robot design for young users.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Calling for Backup: How Children Navigate Successive Robot Communication Failures] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[儿童对连续机器人错误的反应/Children's response to successive robot errors]
        C --> C1[复制成人研究范式，与儿童进行机器人交互/Reproduce adult study paradigm, child-robot interaction]
        C --> C2[分析行为视频记录/Analyze behavioral video recordings]
        D --> D1[儿童与成人反应的异同/Similarities and differences vs. adult responses]
        D --> D2[更多脱离行为，如寻求成人帮助/More disengagement, e.g., seeking adult help]
        D --> D3[对机器人的感知未受影响/Robot perception unaffected]
    ```
