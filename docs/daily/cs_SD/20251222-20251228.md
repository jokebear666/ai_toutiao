---
slug: /daily/cssd/20251222-20251228
---
# 20251222-20251228 (cs.SD)

## 2025-12-22

- **[arXiv251222] Do Foundational Audio Encoders Understand Music Structure?**
  - **tags:** [ai], [music information retrieval], [music structure analysis, foundational audio encoders, self-supervised learning, masked language modeling, boundary detection, function prediction]
  - **authors:** Keisuke Toyama, Zhi Zhong, Akira Takahashi, Shusuke Takahashi, Yuki Mitsufuji
  - **institution:** Sony Group Corporation, Sony AI
  - **link:** https://arxiv.org/pdf/2512.17209
  - **Simple LLM Summary:** This paper investigates the use of pretrained foundational audio encoders (FAEs) for music structure analysis (MSA). Through comprehensive experiments on 11 FAE types, it finds that models using self-supervised learning with masked language modeling on music data are particularly effective for MSA tasks like boundary detection and function prediction.

- **[arXiv251222] LibriVAD: A Scalable Open Dataset with Deep Learning Benchmarks for Voice Activity Detection**
  - **tags:** [ai], [speech processing], [voice activity detection, vision transformer, MFCC, Gammatone filter bank cepstral coefficients, dataset augmentation, out-of-distribution evaluation]
  - **authors:** Ioannis Stylianou, Achintya kr. Sarkar, Nauman Dawalatabad, James Glass, Zheng-Hua Tan
  - **institution:** Aalborg University, Pioneer Centre for AI, IIIT SriCity, Zoom Communications Inc., Massachusetts Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.17281
  - **Simple LLM Summary:** This paper introduces LibriVAD, a scalable open dataset for voice activity detection (VAD) created by augmenting LibriSpeech with diverse noise sources. It benchmarks several feature-model combinations and proposes using a Vision Transformer (ViT) architecture for VAD. The main conclusion is that ViT with MFCC features outperforms established models across various conditions, and scaling the dataset size and balancing its silence-to-speech ratio consistently improves out-of-distribution generalization.

- **[arXiv251222] Robust TTS Training via Self-Purifying Flow Matching for the WildSpoof 2026 TTS Track**
  - **tags:** [mlsys], [diffusion training], [Self-Purifying Flow Matching (SPFM), flow matching, text-to-speech (TTS), Supertonic, fine-tuning, in-the-wild speech, label noise mitigation]
  - **authors:** June Young Yi, Hyeongju Kim, Juheon Lee
  - **institution:** Supertone Inc.
  - **link:** https://arxiv.org/pdf/2512.17293
  - **Simple LLM Summary:** This paper presents a lightweight TTS system that fine-tunes the Supertonic model using Self-Purifying Flow Matching (SPFM) to robustly adapt to noisy, in-the-wild speech data. SPFM handles label noise by comparing conditional and unconditional flow matching losses, routing suspicious samples for unconditional training while still using their acoustic information. The resulting model achieved the best word error rate in the WildSpoof 2026 challenge, demonstrating that open-weight architectures can be effectively adapted to real-world conditions with explicit noise-handling mechanisms.

- **[arXiv251222] When De-noising Hurts: A Systematic Study of Speech Enhancement Effects on Modern Medical ASR Systems**
  - **tags:** [mlsys], [others], [MetricGAN-plus-voicebank, semantic WER, noise robustness, speech enhancement]
  - **authors:** Sujal Chondhekar, Vasanth Murukuri, Rushabh Vasani, Sanika Goyal, Rajshree Badami, Anushree Rana, Sanjana SN, Karthik Pandia, Sulabh Katiyar, Neha Jagadeesh, Sankalp Gulati
  - **institution:** EkaCare (Orbi Health Private Limited)
  - **link:** https://arxiv.org/pdf/2512.17562
  - **Simple LLM Summary:** This paper systematically evaluates the effect of MetricGAN-plus-voicebank speech enhancement on four modern ASR systems using medical speech under nine noise conditions. The study finds that denoising preprocessing consistently degrades ASR performance across all models and conditions, suggesting modern ASR models are inherently noise-robust and enhancement may remove critical acoustic features.

## 2025-12-23

- **[arXiv251223] chatter: a Python library for applying information theory and AI/ML models to animal communication**
  - **tags:** TBD
  - **authors:** Mason Youngblood
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.17935
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/03a1f96f640c75358ed76ff8b7bb2631f43b52386c0c7724516992109d54aa7a_w640_q70.webp
  - **Simple LLM Summary:** chatter: a Python library for applying information theory and AI/ML models to animal communication

- **[arXiv251223] Let the Model Learn to Feel: Mode-Guided Tonality Injection for Symbolic Music Emotion Recognition**
  - **tags:** TBD
  - **authors:** Haiying Xia, Zhongyi Huang, Yumei Tan, Shuxiang Song
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.17946
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ae2757814d2b16837d9b7cb3f26503eda8c49afc87dd1795f588ae949df6650_w640_q70.webp
  - **Simple LLM Summary:** Let the Model Learn to Feel: Mode-Guided Tonality Injection for Symbolic Music Emotion Recognition

- **[arXiv251223] Influence of string register locations on vibratos among violoncellists**
  - **tags:** TBD
  - **authors:** Steven Hu, Sophia H. Kim, Helena H. Kim, Hugo Mackay, Eric J. Heller
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18162
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1976f9763c20928a682e746b3da0df875eff504fde311658b1b374a93a86593e_w640_q70.webp
  - **Simple LLM Summary:** Influence of string register locations on vibratos among violoncellists

- **[arXiv251223] A Data-Centric Approach to Generalizable Speech Deepfake Detection**
  - **tags:** TBD
  - **authors:** Wen Huang, Yuchen Mao, Yanmin Qian
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18210
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11c5c62108382427b9c65030ed5660aed9d27504a01d24a882c770942db88020_w640_q70.webp
  - **Simple LLM Summary:** A Data-Centric Approach to Generalizable Speech Deepfake Detection

- **[arXiv251223] AutoSchA: Automatic Hierarchical Music Representations via Multi-Relational Node Isolation**
  - **tags:** TBD
  - **authors:** Stephen Ni-Hahn, Rico Zhu, Jerry Yin, Yue Jiang, Cynthia Rudin, Simon Mak
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18232
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea758b7b2303802fc5c9547c032b22177a2accdeac3b36caed4230425fda6efa_w640_q70.webp
  - **Simple LLM Summary:** AutoSchA: Automatic Hierarchical Music Representations via Multi-Relational Node Isolation

- **[arXiv251223] Explainable Transformer-CNN Fusion for Noise-Robust Speech Emotion Recognition**
  - **tags:** TBD
  - **authors:** Sudip Chakrabarty, Pappu Bishwas, Rajdeep Chatterjee
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18298
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2d1fa5f1ea12d3598f0bd43290aa418e4ebda7629f53494201d317e1a493a95_w640_q70.webp
  - **Simple LLM Summary:** Explainable Transformer-CNN Fusion for Noise-Robust Speech Emotion Recognition

- **[arXiv251223] Task Vector in TTS: Toward Emotionally Expressive Dialectal Speech Synthesis**
  - **tags:** TBD
  - **authors:** Pengchao Feng, Yao Xiao, Ziyang Ma, Zhikang Niu, Shuai Fan, Yao Li, Sheng Wang, Xie Chen
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18699
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c759cfdab0e5242e7ed2d8eff42f898cd26dbf0e8845df8e26a3c8936e15_w640_q70.webp
  - **Simple LLM Summary:** Task Vector in TTS: Toward Emotionally Expressive Dialectal Speech Synthesis

- **[arXiv251223] X-Talk: On the Underestimated Potential of Modular Speech-to-Speech Dialogue System**
  - **tags:** TBD
  - **authors:** Zhanxun Liu, Yifan Duan, Mengmeng Wang, Pengchao Feng, Haotian Zhang, Xiaoyu Xing, Yijia Shan, Haina Zhu, Yuhang Dai, Chaochao Lu, Xipeng Qiu, Lei Xie, Lan Wang, Nan Yan, Zilong Zheng, Ziyang Ma, Kai Yu, Xie Chen
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18706
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91aa95b8cdf1da17e389c0ae53a6896f970612bb3bc4d4b3762866d213442d93_w640_q70.webp
  - **Simple LLM Summary:** X-Talk: On the Underestimated Potential of Modular Speech-to-Speech Dialogue System

- **[arXiv251223] Reliable Audio Deepfake Detection in Variable Conditions via Quantum-Kernel SVMs**
  - **tags:** TBD
  - **authors:** Lisan Al Amin, Vandana P. Janeja
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18797
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e389f385848f8816c83b5a1ff23be8e5adce564472d3ca92ed4e1c1107846a61_w640_q70.webp
  - **Simple LLM Summary:** Reliable Audio Deepfake Detection in Variable Conditions via Quantum-Kernel SVMs

- **[arXiv251223] Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform**
  - **tags:** TBD
  - **authors:** Yichuan Zhang, Chengxin Li, Yujie Gu
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18791
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/828d54530ed9add4098a79bb9dd1f4047ed230dfaa399d57cade241c18713658_w640_q70.webp
  - **Simple LLM Summary:** Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform

- **[arXiv251223] Tempo as the Stable Cue: Hierarchical Mixture of Tempo and Beat Experts for Music to 3D Dance Generation**
  - **tags:** TBD
  - **authors:** Guangtao Lyu, Chenghao Xu, Qi Liu, Jiexi Yan, Muli Yang, Fen Fang, Cheng Deng
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18804
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dab2ab51309551324dcfdba087c2e5ec1e6dfdae10633047423e7233f30fdf84_w640_q70.webp
  - **Simple LLM Summary:** Tempo as the Stable Cue: Hierarchical Mixture of Tempo and Beat Experts for Music to 3D Dance Generation

- **[arXiv251223] Speaker Recognition -- Wavelet Packet Based Multiresolution Feature Extraction Approach**
  - **tags:** TBD
  - **authors:** Saurabh Bhardwaj, Smriti Srivastava, Abhishek Bhandari, Krit Gupta, Hitesh Bahl, J.R.P. Gupta
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18902
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6caea0e80d84c68574b410a0a5b25554cd842375056a2d48aeaecfbde8e7de29_w640_q70.webp
  - **Simple LLM Summary:** Speaker Recognition -- Wavelet Packet Based Multiresolution Feature Extraction Approach

- **[arXiv251223] JoyVoice: Long-Context Conditioning for Anthropomorphic Multi-Speaker Conversational Synthesis**
  - **tags:** TBD
  - **authors:** Fan Yu, Tao Wang, You Wu, Lin Zhu, Wei Deng, Weisheng Han, Wenchao Wang, Lin Hu, Xiangyu Liang, Xiaodong He, Yankun Huang, Yu Gu, Yuan Liu, Yuxuan Wang, Zhangyu Xiao, Ziteng Wang, Boya Dong, Feng Dang, Jinming Chen, Jingdong Li, Jun Wang, Yechen Jin, Yuan Zhang, Zhengyan Sheng, Xin Wang
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19090
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f755dde99b4324e798ea9a6068c6ff699cdf819d3ac6581fe6856fcbfb048957_w640_q70.webp
  - **Simple LLM Summary:** JoyVoice: Long-Context Conditioning for Anthropomorphic Multi-Speaker Conversational Synthesis

- **[arXiv251223] DeepGESI: A Non-Intrusive Objective Evaluation Model for Predicting Speech Intelligibility in Hearing-Impaired Listeners**
  - **tags:** TBD
  - **authors:** Wenyu Luo, Jinhui Chen
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19374
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c0a852bcb45255507a3386c23b0bf527a541804415204b268f6689a7f82bed8_w640_q70.webp
  - **Simple LLM Summary:** DeepGESI: A Non-Intrusive Objective Evaluation Model for Predicting Speech Intelligibility in Hearing-Impaired Listeners

- **[arXiv251223] Pushing the Frontier of Audiovisual Perception with Large-Scale Multimodal Correspondence Learning**
  - **tags:** TBD
  - **authors:** Apoorv Vyas, Heng-Jui Chang, Cheng-Fu Yang, Po-Yao Huang, Luya Gao, Julius Richter, Sanyuan Chen, Matt Le, Piotr Dollár, Christoph Feichtenhofer, Ann Lee, Wei-Ning Hsu
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19687
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de3d411e351c730f5a4f6bcbb2b3a9ec59b568b77417127cf865aadf04270b18_w640_q70.webp
  - **Simple LLM Summary:** Pushing the Frontier of Audiovisual Perception with Large-Scale Multimodal Correspondence Learning

- **[arXiv251223] LIWhiz: A Non-Intrusive Lyric Intelligibility Prediction System for the Cadenza Challenge**
  - **tags:** TBD
  - **authors:** Ram C. M. C. Shekar, Iván López-Espejo
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.17937
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/233c21744d1a90963372126b2d4d2d816073bc137a142aacddff67d2c28bb772_w640_q70.webp
  - **Simple LLM Summary:** LIWhiz: A Non-Intrusive Lyric Intelligibility Prediction System for the Cadenza Challenge

- **[arXiv251223] MEGState: Phoneme Decoding from Magnetoencephalography Signals**
  - **tags:** TBD
  - **authors:** Shuntaro Suzuki, Chia-Chun Dan Hsu, Yu Tsao, Komei Sugiura
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.17978
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82b8623a222c1e415238f07bfd00f186b0fd97345fe3a78288d0e4e33530c69c_w640_q70.webp
  - **Simple LLM Summary:** MEGState: Phoneme Decoding from Magnetoencephalography Signals

- **[arXiv251223] Continual Learning for Acoustic Event Classification**
  - **tags:** TBD
  - **authors:** Yang Xiao
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.17932
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ab087a2804d86d0265d9e36f2c4b37428d7f82d8a8dbb1c750ee9c6811ecc4a_w640_q70.webp
  - **Simple LLM Summary:** Continual Learning for Acoustic Event Classification

- **[arXiv251223] Phoneme-based speech recognition driven by large language models and sampling marginalization**
  - **tags:** TBD
  - **authors:** Te Ma, Nanjie Li, Hao Huang, Zhijian Ou
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.18371
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5833ba374008a7d74b1de29306f41fcd84ac79c51363d046bb5612486395c04_w640_q70.webp
  - **Simple LLM Summary:** Phoneme-based speech recognition driven by large language models and sampling marginalization

- **[arXiv251223] Real-Time Streamable Generative Speech Restoration with Flow Matching**
  - **tags:** TBD
  - **authors:** Simon Welker, Bunlong Lay, Maris Hillemann, Tal Peer, Timo Gerkmann
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19442
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50f384e81e75842e398563da395c9a42cafd7dfeb79c90bc7c4489b17d033102_w640_q70.webp
  - **Simple LLM Summary:** Real-Time Streamable Generative Speech Restoration with Flow Matching

- **[arXiv251223] Sonified Quantum Seizures. Sonification of time series in epileptic seizures and simulation of seizures via quantum modelling**
  - **tags:** TBD
  - **authors:** Maria Mannone, Paulo Vitor Itaborai, Omar Costa Hamido, Miriam Goldack, Norbert Marwan, Peppino Fazio, Patrizia Ribino
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.19272
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9688c851d6f89a1c52df7b967d23351ceaa8d6d34b065ab9a2ccaf7e65fd9a17_w640_q70.webp
  - **Simple LLM Summary:** Sonified Quantum Seizures. Sonification of time series in epileptic seizures and simulation of seizures via quantum modelling
