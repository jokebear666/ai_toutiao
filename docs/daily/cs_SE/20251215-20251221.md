# 20251215-20251221 (cs.SE)

## 2025-12-18

- **[arXiv251218] Revisiting the Reliability of Language Models in Instruction-Following**
  - **tags:** [ai], [llm evaluation], [instruction-following, reliability, data augmentation, benchmark, IFEval++, reliable@k]
  - **authors:** Jianshuo Dong, Yutong Zhang, Yan Liu, Zhenyu Zhong, Tao Wei, Chao Zhang, Han Qiu
  - **institution:** Tsinghua University, Ant Group
  - **link:** https://arxiv.org/pdf/2512.14754
  - **Simple LLM Summary:** The paper introduces a new metric, reliable@k, and an automated data augmentation pipeline to generate "cousin prompts" for evaluating nuance-oriented reliability in LLMs, constructing the IFEval++ benchmark. It finds that current LLMs show significant performance drops (up to 61.8%) with nuanced prompt variations, highlighting a crucial gap in real-world reliability.

- **[arXiv251218] CAPE: Capability Achievement via Policy Execution**
  - **tags:** [mlsys], [post-training], [capability engineering, policy execution, specification language, verification, DPO, contextual objectivity, verification-fidelity scaling]
  - **authors:** David Ball
  - **institution:** Superficial Labs
  - **link:** https://arxiv.org/pdf/2512.14761
  - **Simple LLM Summary:** The paper introduces CAPE, a protocol for Capability Engineering that implements a Specify-&gt;Verify-&gt;Correct-&gt;Train loop to convert requirements into executable specifications and train models to satisfy them by default. It demonstrates that CAPE reduces policy violation rates by 81% compared to DPO and significantly lowers costs and development timelines by using reusable specifications.

- **[arXiv251218] Workflows vs Agents for Code Translation**
  - **tags:** [mlsys], [llm inference], [Model Context Protocol (MCP), syntax repair, code translation, MATLAB-to-HDL, agentic framework, conditional retrieval]
  - **authors:** Henry Gray, Tom Yotam, Octavian Udrea
  - **institution:** Code Metal
  - **link:** https://arxiv.org/pdf/2512.14762
  - **Simple LLM Summary:** This paper compares two LLM-driven methods for syntax repair in a MATLAB-to-hardware-description-language translation pipeline: a fixed expert-designed workflow and a more autonomous agentic approach using the Model Context Protocol (MCP). The agentic approach, which dynamically selects tools, was more effective at resolving syntax errors, especially for small and mid-sized models, leading to significant downstream improvements in simulation success rates.

- **[arXiv251218] IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection**
  - **tags:** [mlsys], [llm inference], [Retrieval-Augmented Generation (RAG), Graph RAG, knowledge injection, error taxonomy, Terraform, IaC-Eval benchmark]
  - **authors:** Roman Nekrasov, Stefano Fossati, Indika Kumara, Damian Andrew Tamburri, Willem-Jan van den Heuvel
  - **institution:** Jheronimus Academy of Data Science, Tilburg University, Eindhoven University of Technology, University of Sannio
  - **link:** https://arxiv.org/pdf/2512.14792
  - **Simple LLM Summary:** This paper investigates improving Large Language Model (LLM) generation of Infrastructure as Code (IaC) by injecting structured configuration knowledge using techniques from naive to Graph RAG. The study finds that while knowledge injection significantly boosts technical correctness, LLMs still struggle with nuanced user intent, revealing a "Correctness-Congruence Gap" where they are better coders than architects.

- **[arXiv251218] Let the Barbarians In: How AI Can Accelerate Systems Performance Research**
  - **tags:** [mlsys], [cluster infrastructure], [AI-Driven Research for Systems (ADRS), OpenEvolve, GEPA, ShinkaEvolve, multi-region cloud scheduling, mixture-of-experts load balancing, LLM-based SQL, transaction scheduling]
  - **authors:** Audrey Cheng, Shu Liu, Melissa Pan, Zhifei Li, Shubham Agarwal, Mert Cemri, Bowen Wang, Alexander Krentsel, Tian Xia, Jongseok Park, Shuo Yang, Jeff Chen, Lakshya Agrawal, Ashwin Naren, Shulu Li, Ruiying Ma, Aditya Desai, Jiarong Xing, Koushik Sen, Matei Zaharia, Ion Stoica
  - **institution:** UC Berkeley
  - **link:** https://arxiv.org/pdf/2512.14806
  - **Simple LLM Summary:** This paper introduces AI-Driven Research for Systems (ADRS), a method using AI to automate the generation, evaluation, and refinement of performance-optimizing algorithms for computer systems. Through case studies with frameworks like OpenEvolve, it demonstrates that ADRS can produce solutions matching or surpassing human-designed state-of-the-art. The work outlines best practices for applying ADRS and discusses its potential to shift researcher effort toward problem formulation and strategic oversight.

- **[arXiv251218] Imitation Game: Reproducing Deep Learning Bugs Leveraging an Intelligent Agent**
  - **tags:** [mlsys], [fault-tolerance], [bug reproduction, LLM, iterative generate-validate-refine, agentic AI]
  - **authors:** Mehil B Shah, Mohammad Masudur Rahman, Foutse Khomh
  - **institution:** Dalhousie University, Polytechnique Montreal
  - **link:** https://arxiv.org/pdf/2512.14990
  - **Simple LLM Summary:** The paper presents RepGen, an automated approach that uses an LLM-based intelligent agent to reproduce deep learning bugs by constructing a learning-enhanced context and employing an iterative generate-validate-refine mechanism. It achieves an 80.19% reproduction rate on real-world bugs, significantly outperforming the state-of-the-art, and a developer study confirms it improves success rates and reduces time and cognitive load for bug reproduction.

- **[arXiv251218] SeBERTis: A Framework for Producing Classifiers of Security-Related Issue Reports**
  - **tags:** [mlsys], [others], [masked language model, fine-tuning, semantic surrogates, deep neural network, BERT]
  - **authors:** Sogol Masoumzadeh, Yufei Li, Shane McIntosh, Dániel Varró, Lili Wei
  - **institution:** McGill University, University of Waterloo, Linköping University
  - **link:** https://arxiv.org/pdf/2512.15003
  - **Simple LLM Summary:** The paper proposes SEBERTIS, a framework that fine-tunes bidirectional transformer models (like BERT) as Masked Language Models using semantically equivalent vocabulary (Semantic Surrogates) to create classifiers for security-related issue reports. This method reduces reliance on lexical shortcuts, enabling better detection of complex issues. The resulting classifier significantly outperforms existing ML and LLM baselines in precision, recall, and F1-score, demonstrating high effectiveness for real-time issue triage.

- **[arXiv251218] The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops**
  - **tags:** [mlsys], [llm inference], [Meta-Prompting Protocol, Adversarial Trinity, DSPy, TextGrad, textual gradients, semantic computation graph]
  - **authors:** Fanzhe Fu
  - **institution:** Zhejiang University
  - **link:** https://arxiv.org/pdf/2512.15053
  - **Simple LLM Summary:** The paper introduces the Meta-Prompting Protocol, a framework that formalizes LLM orchestration as a programmable system using an adversarial topology (Generator, Auditor, Optimizer) to treat prompts as differentiable variables. It leverages textual critiques as gradients within a semantic computation graph to mitigate hallucination and improve reliability. The authors demonstrate its theoretical viability with tools like DSPy and TextGrad, proposing a foundation for deterministic "Observable Software Engineering" for probabilistic models.

- **[arXiv251218] On Assessing the Relevance of Code Reviews Authored by Generative Models**
  - **tags:** [mlsys], [llm inference], [multi-subjective ranking, code review generation, ChatGPT, human evaluation, CodeReview StackExchange]
  - **authors:** Robert Heumüller, Frank Ortmeier
  - **institution:** Otto von Guericke University Magdeburg
  - **link:** https://arxiv.org/pdf/2512.15466
  - **Simple LLM Summary:** This paper proposes a multi-subjective ranking method to evaluate AI-generated code review comments, comparing ChatGPT outputs against top human responses from CodeReview StackExchange. The results show that ChatGPT's comments were ranked significantly better than human-authored ones, even outperforming accepted answers. The method aims to provide a more meaningful assessment of generative AI in code review while highlighting risks of unchecked integration.

- **[arXiv251218] How Do Semantically Equivalent Code Transformations Impact Membership Inference on LLMs for Code?**
  - **tags:** [mlsys], [llm training], [membership inference, semantically equivalent code transformation, variable renaming, causal analysis, code obfuscation]
  - **authors:** Hua Yang, Alejandro Velasco, Thanh Le-Cong, Md Nazmul Haque, Bowen Xu, Denys Poshyvanyk
  - **institution:** North Carolina State University, William & Mary, The University of Melbourne
  - **link:** https://arxiv.org/pdf/2512.15468
  - **Simple LLM Summary:** This paper investigates how semantically equivalent code transformations, such as variable renaming, can be used to evade membership inference detection in large language models for code. It finds that these transformations, especially RenameVariable, can significantly reduce the success of membership inference attacks without substantially harming model performance. The results reveal a critical vulnerability in license compliance enforcement for code LLMs, showing that transformation-based obfuscation can weaken detection of unauthorized code usage.

- **[arXiv251218] FrontierCS: Evolving Challenges for Evolving Intelligence**
  - **tags:** [ai], [benchmarking], [benchmark, open-ended problems, competitive programming, NP-hard, automatic evaluation, expert reference solution]
  - **authors:** Qiuyang Mang, Wenhao Chai, Zhifei Li, Huanzhi Mao, Shang Zhou, Alexander Du, Hanchen Li, Shu Liu, Edwin Chen, Yichuan Wang, Xieting Chu, Zerui Cheng, Yuan Xu, Tian Xia, Zirui Wang, Tianneng Shi, Jianzhu Yao, Yilong Zhao, Qizheng Zhang, Charlie Ruan, Zeyu Shen, Kaiyuan Liu, Runyuan He, Dong Xing, Zerui Li, Zirong Zeng, Yige Jiang, Lufeng Cheng, Ziyi Zhao, Youran Sun, Wesley Zheng, Meiyuwang Zhang, Ruyi Ji, Xuechang Tu, Zihan Zheng, Zexing Chen, Kangyang Zhou, Zhaozi Wang, Jingbang Chen, Aleksandra Korolova, Peter Henderson, Pramod Viswanath, Vijay Ganesh, Saining Xie, Zhuang Liu, Dawn Song, Sewon Min, Ion Stoica, Joseph E. Gonzalez, Jingbo Shang, Alvin Cheung
  - **institution:** UC Berkeley, Princeton University, UCSD, X-camp Academy, Georgia Tech, Stanford University, University of Washington, Nanyang Technological University, University of Toronto, UIUC, University of Michigan, New York University, MIT
  - **link:** https://arxiv.org/pdf/2512.15699
  - **Simple LLM Summary:** The paper introduces FrontierCS, a benchmark of 156 open-ended computer science problems where the optimal solution is unknown but can be objectively evaluated, requiring models to generate executable programs. It finds that current frontier reasoning models significantly lag behind human experts, and that merely increasing reasoning budgets or generating workable code does not close this performance gap.

## 2025-12-19

- **[arXiv251219] Enhanced Web User Interface Design Via Cross-Device Responsiveness Assessment Using An Improved HCI-INTEGRATED DL Schemes**
  - **tags:** [mlsys], [others], [Finite Exponential Continuous State Machine (FECSM), Quokka Nonlinear Difference Swarm Optimization Algorithm (QNDSOA), Bidirectional Gated Luong and Mish Recurrent Unit (BiGLMRU), HDBSCAN, min-max normalization, User Interface Change Prediction Index (UICPI)]
  - **authors:** Shrinivass Arunachalam Balasubramanian
  - **institution:** Independent Researcher
  - **link:** https://arxiv.org/pdf/2512.15775
  - **Simple LLM Summary:** This paper proposes a dynamic web UI optimization method that uses a Finite Exponential Continuous State Machine for cross-device responsiveness assessment and a novel Quokka Nonlinear Difference Swarm Optimization Algorithm for design optimization. The core technique involves classifying user experience changes with a Bidirectional Gated Luong and Mish Recurrent Unit model. The main conclusion is that this integrated approach achieves an average fitness of 98.5632% for optimal UI design by incorporating cross-responsiveness assessment and user behavior patterns.

- **[arXiv251219] CodeMem: Architecting Reproducible Agents via Dynamic MCP and Procedural Memory**
  - **tags:** [mlsys], [others], [CodeAct, procedural memory, deterministic reliability, reusable agentic workflows, Python action space, dynamic MCP]
  - **authors:** Nishant Gaurav, Adit Akarsh, Tejas Ravishankar, Manoj Bajaj
  - **institution:** AgentR
  - **link:** https://arxiv.org/pdf/2512.15813
  - **Simple LLM Summary:** The paper proposes CodeMem, an architecture that uses code as procedural memory to build reproducible AI agents. It addresses probabilistic instability in LLM-based agents by shifting workflow logic from volatile context into deterministic, saved code blocks. The main conclusion is that this approach enables the creation of reusable agentic workflows with reliable, deterministic execution.

- **[arXiv251219] Optimizing Agentic Language Model Inference via Speculative Tool Calls**
  - **tags:** [mlsys], [llm inference], [speculative tool calls, tool cache, vLLM, prefix-caching]
  - **authors:** Daniel Nichols, Prajwal Singhania, Charles Jekel, Abhinav Bhatele, Harshitha Menon
  - **institution:** Lawrence Livermore National Laboratory, University of Maryland
  - **link:** https://arxiv.org/pdf/2512.15834
  - **Simple LLM Summary:** This paper introduces system optimizations for language model agents that use external tools, specifically by speculating future tool calls and keeping sequences resident in the inference engine to reduce overhead. These methods lead to significant throughput improvements of hundreds of tokens per second. The authors also propose a new "tool cache" API to facilitate adoption of these optimizations.

- **[arXiv251219] OLAF: Towards Robust LLM-Based Annotation Framework in Empirical Software Engineering**
  - **tags:** [ai], [empirical software engineering], [annotation framework, reliability, calibration, drift, consensus, aggregation, transparency]
  - **authors:** Mia Mohammad Imran, Tarannum Shaila Zaman
  - **institution:** Missouri University of Science and Technology, University of Maryland Baltimore County
  - **link:** https://arxiv.org/pdf/2512.15979
  - **Simple LLM Summary:** This position paper proposes OLAF, a conceptual framework for treating LLM-based annotation as a measurement process in empirical software engineering. It organizes key constructs like reliability, calibration, and drift to address current methodological gaps. The paper concludes that such a framework is necessary to improve the transparency and reproducibility of LLM-assisted annotation in software engineering research.

- **[arXiv251219] Embedding Software Intent: Lightweight Java Module Recovery**
  - **tags:** [sys], [software architecture recovery], [ClassLAR, JPMS, language models, fully-qualified class names, reverse engineering]
  - **authors:** Yirui He, Yuqi Huai, Xingyu Chen, Joshua Garcia
  - **institution:** University of California, Irvine
  - **link:** https://arxiv.org/pdf/2512.15980
  - **Simple LLM Summary:** This paper introduces ClassLAR, a lightweight approach for recovering Java modules from monolithic systems by using language models to extract semantic information from fully-qualified class names. The method captures structural and functional intent to map code to architectural modules. The evaluation shows ClassLAR outperforms state-of-the-art techniques in accuracy and is significantly faster in execution time.

- **[arXiv251219] Beyond Blind Spots: Analytic Hints for Mitigating LLM-Based Evaluation Pitfalls**
  - **tags:** [mlsys], [llm inference], [llm-as-a-judge, analytic checker, hybrid evaluation, prompt injection, cobol code generation]
  - **authors:** Ora Nova Fandina, Eitan Farchi, Shmulik Froimovich, Raviv Gal, Wesam Ibraheem, Rami Katan, Alice Podolsky
  - **institution:** IBM Research, Israel
  - **link:** https://arxiv.org/pdf/2512.16272
  - **Simple LLM Summary:** This paper proposes a hybrid evaluation method that combines an LLM-as-a-Judge (LaaJ) with a lightweight analytic checker that provides domain-specific hints, which are dynamically injected into the judge's prompt. The method was tested on COBOL code generation, where LaaJs alone missed many errors. The results show that the LaaJ+Hints configuration significantly improves error detection coverage and explanation quality, demonstrating the effectiveness of analytic-LLM hybrids for reliable evaluation.

- **[arXiv251219] ParamExplorer: A framework for exploring parameters in generative art**
  - **tags:** [ai], [generative art], [reinforcement learning, parameter exploration, human-in-the-loop, p5.js]
  - **authors:** Julien Gachadoat, Guillaume Lagarde
  - **institution:** University of Bordeaux
  - **link:** https://arxiv.org/pdf/2512.16529
  - **Simple LLM Summary:** This paper introduces ParamExplorer, an interactive and modular framework inspired by reinforcement learning to help explore the high-dimensional parameter spaces of generative art algorithms. It allows for exploration guided by human feedback and integrates with existing p5.js projects. The framework implements and evaluates several automated exploration strategies, referred to as agents, to discover aesthetically compelling outputs more efficiently than manual trial-and-error.
