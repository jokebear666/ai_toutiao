---
slug: /daily/csse/20251229-20260104
---
# 20251229-20260104 (cs.SE)

## 2025-12-29

- **[arXiv251229] Understanding the Role of Large Language Models in Software Engineering: Evidence from an Industry Survey**
  - **tags:** [se], [software development tools], [Large Language Models, Survey, Industry, Empirical Study, Software Engineering Practices]
  - **authors:** Vítor Mateus de Brito, Kleinner Farias
  - **institution:** University of Vale do Rio dos Sinos
  - **link:** https://arxiv.org/pdf/2512.21347
  - **contributions:** 1. Provides empirical evidence on the adoption and impact of LLMs in professional software engineering practice through an industry survey. 2. Identifies key perceived benefits (e.g., faster problem resolution, better documentation) and concerns (e.g., cognitive dependence, security risks) associated with LLM use. 3. Bridges the gap between academic discourse and real-world development, offering actionable insights for responsible LLM integration.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fdebd67326ef0fe8cc1a2f2e7ff34382bc7ee9e314bfea976a0e99b4b0eda04_w640_q70.webp
  - **Simple LLM Summary:** This paper conducts an empirical survey of 46 industry professionals to understand the adoption and impact of Large Language Models (LLMs) in software engineering. The study finds that while LLMs are perceived to accelerate technical tasks and improve documentation, significant concerns about over-reliance and security risks persist. The results highlight the need for critical and supervised use of LLM-based tools in software development.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Understanding the Role of LLMs in Software Engineering<br>理解LLM在软件工程中的作用] --> B(核心问题/Problem: How are LLMs adopted and perceived in industry software engineering?<br>LLM在工业界软件工程中的采用和认知如何？)
        A --> C(主要方法/Method: Empirical survey of 46 industry professionals<br>对46位行业专业人员的实证调查)
        A --> D(关键结果/Results: Positive perceptions (speed, documentation) but concerns about dependence and security<br>积极认知（速度、文档）但对依赖性和安全性的担忧)
    ```

- **[arXiv251229] CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation**
  - **tags:** [ai], [reinforcement learning], [dream-replay reinforcement learning, evolutionary algorithms, adaptive code generation]
  - **authors:** Santhosh Kumar Ravindran
  - **institution:** Microsoft Corporation
  - **link:** https://arxiv.org/pdf/2512.21351
  - **contributions:** 1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as "genomes" that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp
  - **Simple LLM Summary:** CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM代码生成缺乏适应性，难以应对API变化/LLM code generation lacks adaptability to API changes]
        C --> C1[将RL轨迹视为基因组进行进化操作/Treat RL trajectories as genomes for evolutionary operations]
        C --> C2[在夜间回放阶段进行突变与选择/Mutation and selection during nocturnal replay]
        D --> D1[解决方案新颖性提升35%/35% higher novelty in solutions]
        D --> D2[适应速度加快25%/25% faster adaptation]
    ```

- **[arXiv251229] Multi-Agent LLM Committees for Autonomous Software Beta Testing**
  - **tags:** [se], [automated software testing], [multi-agent system, large language model, vision-language model, consensus voting, beta testing]
  - **authors:** Sumanth Bharadwaj Hachalli Karanam, Dhiwahar Adhithya Kennady
  - **institution:** New York University
  - **link:** https://arxiv.org/pdf/2512.21352
  - **contributions:** 1. A novel multi-agent committee framework that uses a three-round voting protocol for consensus-based decision-making in software testing. 2. Integration of vision-enabled LLMs and diverse testing personas to systematically explore and understand web application user interfaces. 3. Demonstrated significant performance improvements over single-agent baselines in task success, bug detection (F1 score), and security vulnerability coverage on established benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40573d0b1209c41e9825c09111398107cc51ee9d86c5234b50bea2515d0ab37f_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high cost of manual software beta testing and the limitations of single-agent LLM approaches by proposing a multi-agent committee framework. The method employs diverse, vision-enabled LLMs that collaborate through a structured voting protocol and persona-driven behavior to autonomously test web applications. The results show that this multi-agent approach significantly outperforms single-agent baselines in task success rates, bug detection, and security testing coverage, making it suitable for real-time CI/CD integration.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multi-Agent LLM Committees for Autonomous Software Beta Testing] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[手动测试成本高，单智能体LLM存在幻觉/Manual testing costly, single-agent LLM hallucinates]
        C --> C1[多智能体委员会与三轮投票协议/Multi-agent committee & three-round voting]
        C --> C2[视觉LLM与角色多样性/Vision LLMs & persona diversity]
        D --> D1[任务成功率89.5%，超越基线/Task success 89.5%, beats baseline]
        D --> D2[动作延迟0.71秒，适合CI/CD/Action latency 0.71s, suitable for CI/CD]
        D --> D3[覆盖8/10 OWASP漏洞类别/Covers 8/10 OWASP Top 10]
    ```

- **[arXiv251229] Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software**
  - **tags:** [se], [software fairness], [correlation tuning, phi-coefficient, multi-objective optimization, pre-processing, bias mitigation]
  - **authors:** Ying Xiao, Shangwen Wang, Sicen Liu, Dingyuan Xue, Xian Zhan, Yepang Liu, Jie M. Zhang
  - **institution:** King’s College London, National University of Defense Technology, Southern University of Science and Technology, The Hong Kong Polytechnic University
  - **link:** https://arxiv.org/pdf/2512.21348
  - **contributions:** 1. Proposes a novel pre-processing bias mitigation method called Correlation Tuning (CoT) that adjusts data correlations. 2. Introduces the Phi-coefficient as an intuitive measure to quantify correlation between sensitive attributes and labels. 3. Employs multi-objective optimization to address proxy biases, demonstrating superior effectiveness over state-of-the-art methods in single and multiple attribute scenarios.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4f80681a9ac6a6c3ad7d2bd938623a06836acba00279d9cec368a5ebbe44df3_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Correlation Tuning (CoT), a novel pre-processing method to mitigate bias in ML software by adjusting data correlations using the Phi-coefficient and multi-objective optimization. It frames fairness as a core software quality issue. Extensive evaluation shows CoT significantly improves performance for unprivileged groups and reduces key bias metrics, outperforming existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统公平研究忽视软件质量维度/Traditional fairness research neglects software quality dimension]
        B --> B2[预处理方法效果不足/Pre-processing methods lack effectiveness]
        C --> C1[提出相关性调优 (CoT)/Propose Correlation Tuning (CoT)]
        C --> C2[使用Phi系数量化相关性/Use Phi-coefficient to quantify correlation]
        C --> C3[采用多目标优化/Employ multi-objective optimization]
        D --> D1[提高弱势群体TPR 17.5%/Increase unprivileged group TPR by 17.5%]
        D --> D2[关键偏差指标降低 >50%/Key bias metrics reduced by >50%]
        D --> D3[超越SOTA方法 3-10个百分点/Outperform SOTA by 3-10 percentage points]
    ```

- **[arXiv251229] Reflection-Driven Control for Trustworthy Code Agents**
  - **tags:** [mlsys], [agent system], [reflection-driven control, secure code generation, trustworthy agents, reflective memory, safety control]
  - **authors:** Bin Wang, Jiazheng Quan, Xingrui Yu, Hansen Hu, Yuhao, Ivor Tsang
  - **institution:** Peking University, Xiamen University, Agency for Science, Technology and Research (A*STAR)
  - **link:** https://arxiv.org/pdf/2512.21354
  - **contributions:** 1. Introduces Reflection-Driven Control, a standardized and pluggable control module that integrates self-reflection as an explicit, internal step in an agent's reasoning process. 2. Instantiates the method for secure code generation, using a reflection loop to monitor decisions and retrieve repair examples/guidelines from an evolving reflective memory to inject constraints. 3. Empirically demonstrates that the approach substantially improves security and policy compliance of generated code while preserving functional correctness, with minimal overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the lack of reliable safety controls in LLM agents by proposing Reflection-Driven Control, a module that makes self-reflection an explicit, continuous part of the agent's reasoning to monitor and constrain its decisions using evidence from a reflective memory. Evaluated on security-critical code generation tasks, the method significantly improves code security and compliance while maintaining functionality, offering a practical path toward trustworthy AI coding agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Reflection-Driven Control for Trustworthy Code Agents] --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[LLM代理缺乏可靠的安全控制/LLM agents lack reliable safety controls]
        Problem --> P2[可能产生有害输出/Can produce harmful outputs]
        Method --> M1[将自我反思作为推理的显式步骤/Elevates self-reflection to an explicit reasoning step]
        Method --> M2[内部反思循环监控决策路径/Internal reflection loop monitors decision path]
        Method --> M3[从反思记忆中检索修复示例/Retrieves repair examples from reflective memory]
        Results --> R1[显著提高生成代码的安全性和合规性/Substantially improves security & policy compliance]
        Results --> R2[基本保持功能正确性/Largely preserves functional correctness]
        Results --> R3[运行时和token开销最小/Minimal runtime & token overhead]
    ```

- **[arXiv251229] AInsteinBench: Benchmarking Coding Agents on Scientific Repositories**
  - **tags:** [se], [software engineering], [benchmark, scientific computing, code generation, pull requests, test-driven verification]
  - **authors:** Titouan Duston, Shuo Xin, Yang Sun, Daoguang Zan, Aoyan Li, Shulin Xin, Kai Shen, Yixiao Chen, Qiming Sun, Ge Zhang, Jiashuo Liu, Huan Zhou, Jingkai Liu, Zhichen Pu, Yuanheng Wang, Bo-Xuan Ge, Xin Tong, Fei Ye, Zhi-Chao Zhao, Wen-Biao Han, Zhoujian Cao, Yueran Zhao, Weiluo Ren, Qingshen Long, Yuxiao Liu, Anni Huang, Yidi Du, Yuanyuan Rong, Jiahao Peng
  - **institution:** ByteDance Seed, Princeton University
  - **link:** https://arxiv.org/pdf/2512.21373
  - **code:** https://github.com/ByteDance-Seed/AInsteinBench
  - **contributions:** 1. Introduces a novel benchmark (AInsteinBench) for evaluating LLM agents in end-to-end scientific development using real-world, production-grade codebases. 2. Curates tasks from maintainer-authored pull requests across six diverse scientific domains, ensuring scientific challenge and calibrated difficulty. 3. Employs executable environments and test-driven verification to measure core competencies beyond surface-level code generation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces AInsteinBench, a benchmark designed to evaluate LLM agents' ability to function as scientific computing developers by solving tasks derived from real pull requests in scientific repositories. It uses executable environments and test-driven verification to assess deeper competencies. The benchmark provides a new standard for measuring AI's role in computational scientific research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AInsteinBench: Benchmarking Coding Agents on Scientific Repositories] --> B[核心问题/Problem: Can LLM agents operate as scientific computing development agents?]
        A --> C[主要方法/Method: End-to-end evaluation using tasks from real scientific pull requests]
        A --> D[关键结果/Results: Measures ability beyond surface-level code generation]
    ```

- **[arXiv251229] What Makes a GitHub Issue Ready for Copilot?**
  - **tags:** [se], [ai-assisted software engineering], [GitHub Copilot, AI-agent, interpretable machine learning, pull request merge prediction, issue quality criteria]
  - **authors:** Mohammed Sayagh
  - **institution:** École de Technologie Supérieure, Université du Québec
  - **link:** https://arxiv.org/pdf/2512.21426
  - **contributions:** 1. Developed a set of 32 detailed criteria to measure the quality of GitHub issues for AI-agents like Copilot. 2. Built an interpretable machine learning model to predict the likelihood of a GitHub issue resulting in a merged pull request. 3. Identified key characteristics of successful issues (e.g., shorter, well-scoped) and those associated with failure (e.g., external references), providing actionable guidance for issue writing.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/998bd51b7cec267b5219b085eac5068f7a996cf57d816c17d8e06474fbae27f0_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates what makes a GitHub issue suitable for AI-agents like Copilot to successfully implement. The authors propose 32 quality criteria and build an interpretable machine learning model to predict if an issue will lead to a merged pull request. They conclude that successful issues are shorter, well-scoped, and provide clear implementation guidance, while issues with external references are less likely to succeed.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[What Makes a GitHub Issue Ready for Copilot?] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[AI-agent性能依赖输入质量/AI-agent performance depends on input quality]
        B --> B2[如何评估Issue对Copilot的适用性/How to evaluate Issue suitability for Copilot]
        C --> C1[定义32项质量评估标准/Define 32 quality criteria]
        C --> C2[构建可解释机器学习模型/Build interpretable ML model]
        C --> C3[比较合并与关闭的PR/Compare merged vs. closed PRs]
        D --> D1[成功Issue特征:简短、范围明确、指导清晰/Successful Issue traits: short, well-scoped, clear guidance]
        D --> D2[外部引用关联低合并率/External references linked to lower merge rate]
        D --> D3[模型AUC中位数72%/Model median AUC 72%]
    ```

- **[arXiv251229] Cerberus: Multi-Agent Reasoning and Coverage-Guided Exploration for Static Detection of Runtime Errors**
  - **tags:** [se], [software testing], [runtime error detection, coverage-guided testing, multi-agent reasoning, large language models, static analysis]
  - **authors:** Hridya Dhulipala, Xiaokai Rong, Tien N. Nguyen
  - **institution:** University of Texas at Dallas
  - **link:** https://arxiv.org/pdf/2512.21431
  - **contributions:** 1. Proposes Cerberus, a novel predictive, execution-free coverage-guided testing framework that uses LLMs for input generation, coverage prediction, and error detection without code execution. 2. Introduces a two-phase feedback loop that first maximizes code coverage and detects errors, then focuses solely on error detection after coverage is maximized, improving performance over single-phase prompting. 3. Empirically demonstrates that Cerberus outperforms conventional and learning-based testing frameworks for both complete and incomplete code snippets by generating high-coverage test cases more efficiently and discovering more runtime errors.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d41379a4c8476f7ed1a8a02b193c5fe427e6a274d56beccd85313ce47ba5e76_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes Cerberus, a framework that uses Large Language Models (LLMs) to statically detect runtime errors in code snippets without execution. It employs a multi-agent reasoning approach with a two-phase, coverage-guided feedback loop to generate test inputs and predict errors. The evaluation shows Cerberus is more efficient and effective at finding runtime errors than existing testing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cerberus: Multi-Agent Reasoning and Coverage-Guided Exploration for Static Detection of Runtime Errors] --> B(核心问题/Problem: Detecting runtime errors in code snippets without execution is crucial for software safety.)
        A --> C(主要方法/Method: Uses LLMs for execution-free, coverage-guided testing with a two-phase feedback loop.)
        A --> D(关键结果/Results: Outperforms conventional and learning-based frameworks by generating high-coverage tests and finding more errors.)
    ```

- **[arXiv251229] Fuzzwise: Intelligent Initial Corpus Generation for Fuzzing**
  - **tags:** [se], [fuzz testing], [initial corpus generation, large language models, multi-agent framework, predictive code coverage, mutation-based fuzzing]
  - **authors:** Hridya Dhulipala, Xiaokai Rong, Aashish Yadavally, Tien N. Nguyen
  - **institution:** University of Texas at Dallas
  - **link:** https://arxiv.org/pdf/2512.21440
  - **contributions:** 1. Proposes FuzzWise, a novel method that integrates initial corpus generation and minimization into a single, streamlined process using an LLM-based multi-agent framework., 2. Introduces a predictive code coverage module (an LLM agent) that assesses new test cases without requiring actual program execution, saving computational resources., 3. Demonstrates empirically that FuzzWise generates a smaller, higher-quality initial corpus that achieves higher code coverage and triggers more runtime errors more efficiently than baseline methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcb8eafec283e39ae04e0274dc4688aced924346193560581e8469f1151507f6_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of generating a high-quality initial seed corpus for mutation-based fuzzing. It proposes FuzzWise, a method that uses a multi-agent LLM framework to generate and intelligently select test cases based on predicted coverage without execution. The evaluation shows FuzzWise produces a smaller, more effective corpus that achieves higher coverage and finds more bugs efficiently.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FuzzWise: Intelligent Initial Corpus Generation for Fuzzing] --> B[核心问题/Problem: 为模糊测试生成高质量的初始种子语料库/Generating high-quality initial seed corpus for fuzzing]
        A --> C[主要方法/Method: 基于LLM的多智能体框架，集成生成与预测性覆盖评估/LLM-based multi-agent framework integrating generation and predictive coverage assessment]
        A --> D[关键结果/Results: 用更少的测试用例实现更高的代码覆盖率和错误发现率/Achieves higher code coverage and bug detection with fewer test cases]
    ```

- **[arXiv251229] Code Clone Refactoring in C# with Lambda Expressions**
  - **tags:** [se], [code refactoring], [lambda expressions, extract method, behavior parameterization, code clone, C#]
  - **authors:** Takuto Kawamoto, Yoshiki Higo
  - **institution:** Osaka University
  - **link:** https://arxiv.org/pdf/2512.21511
  - **contributions:** 1. Proposed a C#-specific technique for code clone refactoring using lambda expressions for behavior parameterization, addressing a gap in language-specific research beyond Java. 2. Developed an analysis method to determine the refactorability of clone pairs detected by the NiCad clone detector. 3. Conducted an empirical evaluation on 2,217 clone pairs from 22 projects, measuring the success rate of the proposed consolidation approach.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c89087084c80383647290bcc69c8c950eca517f6ba4f10a7237d77a54477bdd_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of consolidating code clones in C# programs using "Extract Method" refactoring. It proposes a novel technique that uses lambda expressions to parameterize behavioral differences between clones, which is tailored to C#'s language specifications. The evaluation on real-world projects showed that 35.0% of clone pairs were deemed refactorable by the approach, with 28.9% of those successfully refactored.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Code Clone Refactoring in C# with Lambda Expressions") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("Clone Refactoring with Differences/存在差异的克隆重构")
        Problem --> P2("Language-Specific Techniques Needed/需要语言特定技术")
        Method --> M1("C#-Specific Lambda Expressions/C#特定的Lambda表达式")
        Method --> M2("Behavior Parameterization/行为参数化")
        Results --> R1("35.0% Pairs Refactorable/35.0% 可重构")
        Results --> R2("28.9% Successfully Refactored/28.9% 成功重构")
    ```

- **[arXiv251229] XTrace: A Non-Invasive Dynamic Tracing Framework for Android Applications in Production**
  - **tags:** [sys], [mobile systems], [dynamic tracing, method interception, ART virtual machine, non-invasive proxying, runtime observability]
  - **authors:** Qi Hu, Jiangchao Liu, Xin Yu, Lin Zhang, Edward Jiang
  - **institution:** ByteDance
  - **link:** https://arxiv.org/pdf/2512.21555
  - **contributions:** 1. Proposes a novel non-invasive proxying paradigm for dynamic tracing that avoids modifying the ART VM's underlying data structures. 2. Achieves high-performance method interception by leveraging and optimizing the stable, built-in instrumentation mechanism of the Android ART virtual machine. 3. Demonstrates production-grade stability, minimal overhead, and broad compatibility through large-scale A/B experiments on a major app, successfully diagnosing severe online issues.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/35b382ca224e5947c252f1f122f264a5993cf96e0069d9fecd115eb850c5ea49_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes XTrace, a non-invasive dynamic tracing framework for Android that intercepts arbitrary methods at runtime without app releases by leveraging the ART VM's instrumentation. It shows minimal performance impact and high stability in large-scale production use, significantly improving the efficiency of diagnosing online crashes and performance bottlenecks.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[XTrace: 一个用于生产环境的Android应用非侵入式动态追踪框架 / XTrace: A Non-Invasive Dynamic Tracing Framework for Android Applications in Production]
        Root --> Problem[核心问题/Problem]
        Root --> Method[主要方法/Method]
        Root --> Results[关键结果/Results]
        Problem --> P1[移动应用复杂性 & 设备碎片化 / Mobile App Complexity & Device Fragmentation]
        Problem --> P2["传统方法(静态日志)缺乏实时上下文 / Traditional Methods Lack Real-time Context"]
        Problem --> P3["难以捕获'幽灵bug' / Difficulty in Catching 'Ghost Bugs'"]
        Method --> M1[非侵入式代理范式 / Non-Invasive Proxying Paradigm]
        Method --> M2[利用并优化ART内置插桩机制 / Leverage & Optimize ART's Built-in Instrumentation]
        Results --> R1[生产级稳定性 & 最小开销 / Production-Grade Stability & Minimal Overhead]
        Results --> R2[诊断严重线上崩溃 & 性能瓶颈 / Diagnosed Severe Online Crashes & Performance Bottlenecks]
        Results --> R3[根因定位效率提升>90% / Root-Cause Localization Efficiency Improved >90%]
    ```

- **[arXiv251229] Co-Evolution of Types and Dependencies: Towards Repository-Level Type Inference for Python Code**
  - **tags:** [se], [type inference], [Entity Dependency Graph, co-evolution, type-checker-in-the-loop, LLM, repository-level]
  - **authors:** Shuo Sun, Shixin Zhang, Jiwei Yan, Jun Yan, Jian Zhang
  - **institution:** Institute of Software, Chinese Academy of Sciences
  - **link:** https://arxiv.org/pdf/2512.21591
  - **contributions:** 1. An Entity Dependency Graph (EDG) model designed to capture repository-level type dependencies. 2. An iterative type inference approach where types and dependencies co-evolve in each iteration. 3. A type-checker-in-the-loop strategy that validates and corrects inferences on-the-fly to reduce error propagation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d664d948e35d5ccaf8cf1c7880d512bf91868eeaf908b4683c1db08768e3940_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes PyTIR, a novel approach for repository-level type inference in Python. It uses an Entity Dependency Graph (EDG) and an iterative co-evolution process between types and dependencies, enhanced by a type-checker-in-the-loop, to achieve accurate type annotations. The method significantly outperforms prior works, demonstrating a major improvement in automated type annotation for real-world Python code.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Co-Evolution of Types and Dependencies: Towards Repository-Level Type Inference for Python Code] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Python动态类型导致运行时错误/Python dynamic typing causes runtime errors]
        B --> B2[现有工具难以处理仓库级依赖/Existing tools struggle with repository-level dependencies]
        C --> C1[构建实体依赖图(EDG)/Construct Entity Dependency Graph (EDG)]
        C --> C2[类型与依赖协同进化迭代推理/Co-evolution iterative inference of types and dependencies]
        C --> C3[集成类型检查器循环验证/Type-checker-in-the-loop validation]
        D --> D1[TypeSim 0.89, TypeExact 0.84/TypeSim 0.89, TypeExact 0.84]
        D --> D2[相对基线提升27%和40%/27% and 40% relative improvement over baseline]
        D --> D3[减少92.7%的新类型错误/Reduced 92.7% of new type errors]
    ```

- **[arXiv251229] Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation**
  - **tags:** [sec], [software security], [backdoor attack, retrieval-augmented code generation, vulnerable code, supply-chain vulnerability, stealthy attack]
  - **authors:** Tian Li, Bo Lin, Shangwen Wang, Yusong Tan
  - **institution:** National University of Defense Technology
  - **link:** https://arxiv.org/pdf/2512.21681
  - **contributions:** 1. Conducted the first systematic exploration of backdoor attacks targeting the retriever component in Retrieval-Augmented Code Generation (RACG), identifying it as a critical supply-chain vulnerability. 2. Proposed VenomRACG, a new class of potent and stealthy attack that makes poisoned code statistically indistinguishable from benign code, enabling realistic threat analysis. 3. Demonstrated the severe practical impact of the attack, showing that injecting only 0.05% poisoned data can manipulate the retriever and cause downstream models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while evading current defenses.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74c266d46865bfe9ae8b97f18b92cf9b8209ecd63852c6f32f3fe8533329fe2_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the security threat of backdoor attacks on the retriever in Retrieval-Augmented Code Generation (RACG). To enable a realistic analysis, the authors developed a stealthy attack called VenomRACG. Their findings reveal that this attack is highly effective and evades current defenses, posing a practical threat to the software development ecosystem.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[Retriever Backdoor: 供应链漏洞/Supply-Chain Vulnerability]
        C --> C1[VenomRACG: 隐蔽攻击/Stealthy Attack]
        D --> D1[低投毒率有效/Low Poisoning Rate Effective]
        D --> D2[下游模型生成漏洞代码/Downstream Model Generates Vulnerable Code]
        D --> D3[防御机制失效/Defenses Ineffective]
    ```

- **[arXiv251229] How Do Agents Perform Code Optimization? An Empirical Study**
  - **tags:** [se], [code optimization], [AI coding agents, performance optimization, empirical study, pull request analysis, AIDev dataset]
  - **authors:** Huiyun Peng, Antonio Zhong, Ricardo Andrés Calvo Méndez, Kelechi G. Kalu, James C. Davis
  - **institution:** Purdue University
  - **link:** https://arxiv.org/pdf/2512.21757
  - **contributions:** 1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp
  - **Simple LLM Summary:** This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[How Do Agents Perform Code Optimization? An Empirical Study] --> B[核心问题/Problem: AI coding agents' effectiveness on real-world performance optimization tasks is unknown.]
        A --> C[主要方法/Method: Empirical comparison of 324 agent-generated and 83 human-authored performance PRs from AIDev dataset.]
        A --> D[关键结果/Results: AI-authored PRs use similar patterns but include less explicit performance validation (45.7% vs 63.6%).]
    ```

- **[arXiv251229] The State of the SBOM Tool Ecosystems: A Comparative Analysis of SPDX and CycloneDX**
  - **tags:** [se], [software supply chain security], [Software Bill of Materials, SBOM, SPDX, CycloneDX, tool ecosystem]
  - **authors:** Abdul Ali Bangash, Tongxu Ge, Zhimin Zhao, Arshdeep Singh, Zitao Wang, Bram Adams
  - **institution:** Lahore University of Management Sciences, Queen's University, Indian Institute of Technology Ropar, University of Waterloo
  - **link:** https://arxiv.org/pdf/2512.21781
  - **contributions:** 1. Conducted a quantitative comparison of use cases for 170 publicly advertised SBOM tools to identify enhancement areas for the SPDX and CycloneDX formats. 2. Compared health metrics of both ecosystems (171 CycloneDX vs. 470 SPDX tools) and analyzed 36,990 issue reports from open-source tools to evaluate robustness and identify challenges. 3. Investigated and compared the health metrics of the top 250 open-source projects using each tool ecosystem.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91bc1035c2c5b265034f618902937bd2da58ada7ea4b50d403537bd0f48a030c_w640_q70.webp
  - **Simple LLM Summary:** This paper conducts a comparative analysis of the two dominant Software Bill of Materials (SBOM) tool ecosystems, SPDX and CycloneDX. The authors quantitatively analyze tool use cases, ecosystem health metrics, issue reports, and project adoption. The findings reveal that CycloneDX tools show higher developer engagement in some areas, while SPDX benefits from a more mature ecosystem with broader tool availability and industry adoption.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[The State of the SBOM Tool Ecosystems: A Comparative Analysis of SPDX and CycloneDX] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[SBOM adoption depends on tool ecosystems<br/>SBOM采用依赖于工具生态系统]
        C --> C1[Quantitative comparison of tools, issues, and projects<br/>对工具、问题、项目进行定量比较]
        D --> D1[CycloneDX: higher developer engagement<br/>CycloneDX: 更高的开发者参与度]
        D --> D2[SPDX: more mature ecosystem & broader adoption<br/>SPDX: 更成熟的生态系统和更广泛的采用]
    ```

- **[arXiv251229] A Story About Cohesion and Separation: Label-Free Metric for Log Parser Evaluation**
  - **tags:** [se], [log parsing], [PMSS, label-free evaluation, silhouette analysis, Levenshtein distance, log parser]
  - **authors:** Qiaolin Qin, Jianchen Zhao, Heng Li, Weiyi Shang, Ettore Merlo
  - **institution:** Polytechnique Montreal, University of Waterloo
  - **link:** https://arxiv.org/pdf/2512.21811
  - **contributions:** 1. Proposed PMSS, a novel label-free metric for evaluating log parser performance that does not require ground-truth data. 2. Demonstrated that PMSS is significantly correlated with existing label-based metrics (FGA and FTA) and can lead to comparable parser selection conclusions. 3. Provided guidelines and discussion on interpreting evaluation results with PMSS, addressing challenges and its application when labels are unavailable or inconsistent.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4dbe635df301e13b1acf1f17c8fb241f287195f74aae223daca138f58797fb87_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that existing metrics for evaluating log parsers rely on labeled data, which is often unavailable or inconsistent. To solve this, it proposes PMSS, a label-free metric based on medoid silhouette analysis and Levenshtein distance. The results show PMSS is strongly correlated with label-based metrics, offering a viable alternative for parser evaluation and selection without ground truth.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Story About Cohesion and Separation: Label-Free Metric for Log Parser Evaluation<br>论文标题"]
        Root --> Problem["现有评估指标依赖标注数据，导致评估受限且结论不一致<br>Problem: Label-based metrics limit evaluation"]
        Root --> Method["提出PMSS，一种基于中心点轮廓分析和编辑距离的无标签评估指标<br>Method: Propose PMSS, a label-free metric"]
        Root --> Results["PMSS与FGA/FTA显著相关，为无标签场景提供有效替代方案<br>Results: PMSS correlates with label-based metrics"]
    ```

- **[arXiv251229] Analyzing Code Injection Attacks on LLM-based Multi-Agent Systems in Software Development**
  - **tags:** [mlsys], [agent system], [multi-agent system, code injection, threat model, security analysis agent, LLM]
  - **authors:** Brian Bowers, Smita Khapre, Jugal Kalita
  - **institution:** Loyola Marymount University, University of Colorado Colorado Springs
  - **link:** https://arxiv.org/pdf/2512.21818
  - **contributions:** 1. Proposed and evaluated LLM-based multi-agent architectures (coder, coder-tester, coder-reviewer-tester) for software implementation, assessing their accuracy, attack resilience, and efficiency. 2. Introduced a security analysis agent to mitigate code injection attacks, showing it improves resilience while recovering lost efficiency. 3. Demonstrated a vulnerability in the security analysis agent where embedding poisonous few-shot examples in injected code drastically increases attack success rate.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43b214bf9d80e3aaa2e2412bbf3ea1727db748cf0f33f818d81076fa53654f97_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the vulnerability of LLM-based multi-agent systems in software development to code injection attacks. It proposes and evaluates several agent architectures, finding that adding a security analysis agent improves resilience and efficiency. However, the study concludes that even this security agent can be compromised by advanced attacks using poisoned few-shot examples, significantly increasing the attack success rate.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Analyzing Code Injection Attacks on LLM-based Multi-Agent Systems] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: LLM-based multi-agent systems for software development are vulnerable to code injection attacks] --> Problem_Detail[缺乏人在环/No Human-in-the-Loop]
        Method[主要方法/Method: Propose and evaluate multi-agent architectures, then add a security analysis agent] --> Method_Arch[架构评估/Architecture Evaluation: coder, coder-tester, coder-reviewer-tester]
        Method --> Method_Sec[安全代理/Security Agent: Add a security analysis agent for mitigation]
        Results[关键结果/Results: Security agent improves resilience but is itself vulnerable to advanced attacks] --> Results_Resilience[韧性提升/Improved Resilience: coder-reviewer-tester is more resilient]
        Results --> Results_Vulnerability[新漏洞/New Vulnerability: Poisonous few-shot examples increase attack success to 71.95%]
    ```

- **[arXiv251229] Proceedings First Workshop on Adaptable Cloud Architectures**
  - **tags:** TBD
  - **authors:** Giuseppe De Palma, Saverio Giallorenzo
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.22054

- **[arXiv251229] HALF: Process Hollowing Analysis Framework for Binary Programs with the Assistance of Kernel Modules**
  - **tags:** [sec], [binary analysis], [process hollowing, dynamic binary instrumentation, kernel module, fine-grained analysis, malware analysis]
  - **authors:** Zhangbo Long, Letian Sha, Jiaye Pan, Dongpeng Xu, Yifei Huang, Fu Xiao
  - **institution:** Nanjing University of Posts and Telecommunications, The University of New Hampshire
  - **link:** https://arxiv.org/pdf/2512.22043
  - **contributions:** 1. Proposes a new binary program analysis framework that uses a kernel module to extend the capabilities of traditional dynamic binary instrumentation. 2. Introduces a novel method to construct the analysis environment within a container process using process hollowing techniques, enabling decoupled analysis. 3. Demonstrates the framework's practical value through validation with benchmarks, actual exploit programs, and malicious code on the Windows platform.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e19e32f77dc6c92df186a9244b45aa21db814a27ce5e27275643fa1e71537cf7_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes HALF, a new binary program analysis framework designed to improve the usability and performance of fine-grained analysis. It combines kernel modules with process hollowing to decouple the analysis environment from the target program, reducing its impact. The framework is validated on Windows, showing effectiveness in analyzing exploits and malware.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[HALF: Process Hollowing Analysis Framework<br>HALF: 进程镂空分析框架] --> B(Problem: Fine-grained binary analysis has deployability and performance issues<br>问题: 细粒度二进制分析存在部署性和性能问题)
        A --> C(Method: Uses kernel modules & process hollowing for decoupled analysis<br>方法: 使用内核模块和进程镂空进行解耦分析)
        A --> D(Results: Validated on Windows, effective for exploit/malware analysis<br>结果: 在Windows上验证，对漏洞利用/恶意软件分析有效)
    ```

- **[arXiv251229] Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications**
  - **tags:** [mlsys], [agent system], [root cause analysis, service dependency graph, program dependence graph, LLM agent, cloud incident]
  - **authors:** Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer
  - **institution:** University of Illinois at Urbana-Champaign, IBM Research
  - **link:** https://arxiv.org/pdf/2512.22113
  - **contributions:** 1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Agentic Structured Graph Traversal for Root Cause Analysis<br/>基于智能体结构化图遍历的云应用根因分析] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br/>High cost of unresolved cloud incidents; Need for effective root cause analysis]
        C[主要方法/Method<br/>PRAXIS: LLM-driven traversal over Service Dependency Graph and Program Dependence Graph]
        D[关键结果/Results<br/>3.1x higher RCA accuracy, 3.8x lower token consumption vs. ReAct baselines]
    ```

## 2025-12-30

- **[arXiv251230] Syntax Is Not Enough: An Empirical Study of Small Transformer Models for Neural Code Repair**
  - **tags:** [se], [automated program repair], [CodeT5, syntax validity, semantic correctness, neural code repair, transformer]
  - **authors:** Shaunak Samant
  - **institution:** MIT World Peace University
  - **link:** https://arxiv.org/pdf/2512.22216
  - **contributions:** 1. An empirical study demonstrating that a small transformer model (CodeT5-small) can achieve high syntactic correctness (94%) in code generation but fails to produce semantically correct repairs (0% exact match). 2. Identifies key failure factors: identifier abstraction removing semantic signals, cross-entropy training encouraging conservative copying, and insufficient model capacity for multi-step reasoning. 3. Argues that common evaluation metrics overestimate practical effectiveness and calls for future work to prioritize semantically informed datasets and execution-aware objectives.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5b419b9d06731756aa85f1747cb55b61006764a0f1afdd4eef702af659daca2_w640_q70.webp
  - **Simple LLM Summary:** This study investigates whether a small transformer model can effectively repair Java bugs. The authors fine-tune CodeT5-small on bug-fix pairs and find that while it generates syntactically valid code 94% of the time, it fails to produce correct repairs, often just copying the buggy input. The conclusion is that syntactic correctness is not a reliable proxy for semantic correctness, highlighting a significant gap in neural code repair evaluation.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Syntax Is Not Enough: An Empirical Study of Small Transformer Models for Neural Code Repair<br/>论文标题"]
        Root --> Problem["核心问题/Problem<br/>Can small transformer models meaningfully repair real-world bugs? Is syntactic correctness a reliable proxy for semantic correctness?"]
        Root --> Method["主要方法/Method<br/>Fine-tune CodeT5-small on Java bug-fix pairs from CodeXGLUE. Evaluate token-level performance and syntactic validity using AST parsing."]
        Root --> Results["关键结果/Results<br/>High syntax validity (94%) but zero correct repairs. Model copies buggy input 80% of the time. Syntax is not enough for semantic repair."]
    ```

- **[arXiv251230] Failure Analysis of Safety Controllers in Autonomous Vehicles Under Object-Based LiDAR Attacks**
  - **tags:** [sec], [autonomous vehicle security], [LiDAR attacks, safety controllers, adversarial perception, cut-in scenarios, time to collision]
  - **authors:** Daniyal Ganiuly, Nurzhau Bolatbek, Assel Smaiyl
  - **institution:** Astana IT University
  - **link:** https://arxiv.org/pdf/2512.22244
  - **contributions:** 1. Presents a systematic failure analysis of longitudinal safety controllers under object-based LiDAR attacks in highway scenarios., 2. Demonstrates that short-duration LiDAR-induced object hallucinations can trigger unsafe braking, delayed hazard responses, and unstable control., 3. Shows that controller failures are more influenced by the temporal consistency of spoofed objects than by spatial inaccuracies alone.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f08729d3ab6d3cb95ef74d24b6a8c9504767e34a79b6a8ed3d819b7a0449654_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes how object-based LiDAR attacks impact the safety controllers of autonomous vehicles. Using a high-fidelity simulation framework, it evaluates attacks in highway scenarios and finds they can cause unsafe braking and delayed responses. The key conclusion is that temporal consistency of adversarial objects is a stronger driver of controller failure than spatial errors, revealing a gap between perception robustness and control-level safety.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Failure Analysis of Safety Controllers in Autonomous Vehicles Under Object-Based LiDAR Attacks"] --> Problem["核心问题/Problem: Impact of LiDAR attacks on vehicle safety controllers is not well understood"]
        Root --> Method["主要方法/Method: High-fidelity simulation of attacks in cut-in and car-following scenarios"]
        Root --> Results["关键结果/Results: Attacks cause unsafe braking; failures depend more on temporal consistency than spatial accuracy"]
    ```

- **[arXiv251230] Hallucination Detection for LLM-based Text-to-SQL Generation via Two-Stage Metamorphic Testing**
  - **tags:** [se], [software testing], [metamorphic testing, hallucination detection, text-to-sql, large language models]
  - **authors:** Bo Yang, Yinfen Xia, Weisong Sun, Yang Liu
  - **institution:** Beijing Forestry University, Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.22250
  - **contributions:** 1. Proposes SQLHD, a novel hallucination detection method for LLM-based Text-to-SQL that does not require ground-truth SQL answers. 2. Introduces a two-stage metamorphic testing framework with structure-aware and logic-aware metamorphic relations to detect schema-linking and logical-synthesis hallucinations separately. 3. Demonstrates superior performance over existing methods, including LLM self-evaluation, with F1-scores ranging from 69.36% to 82.76%.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43979ca10fcd9708d38dc28b6f736979a5f93d12908536b02a9fbbaabdec599f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of detecting hallucinations in LLM-generated SQL queries without needing ground-truth data. It proposes SQLHD, a two-stage metamorphic testing method that uses structure-aware and logic-aware perturbations to cross-check model outputs. The method shows effective hallucination detection, outperforming baseline approaches.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Paper Title: Hallucination Detection for LLM-based Text-to-SQL Generation via Two-Stage Metamorphic Testing] --> B
        A --> C
        A --> D
        B[核心问题/Problem: LLM在Text-to-SQL中产生幻觉，难以检测且缺乏标准答案]
        C[主要方法/Method: SQLHD - 两阶段蜕变测试，使用结构感知和逻辑感知的蜕变关系进行交叉检查]
        D[关键结果/Results: F1分数69.36%至82.76%，性能优于LLM自评估方法]
    ```

- **[arXiv251230] Agentic Software Issue Resolution with Large Language Models: A Survey**
  - **tags:** [se], [automated software maintenance], [large language models, agentic systems, software issue resolution, reinforcement learning, software engineering]
  - **authors:** Zhonghao Jiang, David Lo, Zhongxin Liu
  - **institution:** Zhejiang University, Singapore Management University
  - **link:** https://arxiv.org/pdf/2512.22256
  - **code:** https://github.com/ZhonghaoJiang/Awesome-Issue-Solving
  - **contributions:** 1. Provides a systematic survey of 126 recent studies on LLM-based agentic software issue resolution. 2. Establishes a taxonomy for the field across three key dimensions: benchmarks, techniques, and empirical studies. 3. Highlights the paradigm shift brought by agentic reinforcement learning in designing and training agentic systems for software engineering.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp
  - **Simple LLM Summary:** This paper surveys the use of Large Language Model (LLM)-based agentic systems for automating complex software issue resolution, such as bug fixing. It reviews recent research, categorizes approaches, and discusses how agentic reinforcement learning is changing system design. The conclusion outlines current challenges and future research directions for improving automated software maintenance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Agentic Software Issue Resolution with LLMs: A Survey] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[传统方法依赖人工，效率低/Traditional methods rely on human expertise, inefficient]
        Method[主要方法/Method] --> M1[基于LLM的智能体系统/LLM-based Agentic Systems]
        Method --> M2[系统综述126项研究/Systematic survey of 126 studies]
        Method --> M3[建立三维分类法/Establishes a 3D taxonomy]
        Results[关键结果/Results] --> R1[增强软件维护效率/Enhances software maintenance efficiency]
        Results --> R2[为智能体系统提供验证环境/Provides a validation environment for agentic systems]
        Results --> R3[总结挑战与未来方向/Summarizes challenges & future directions]
    ```

- **[arXiv251230] AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents**
  - **tags:** [mlsys], [agent system], [reproducibility, dependency management, code generation, large language models, empirical study]
  - **authors:** Bhanu Prakash Vangala, Ali Adibifar, Tanu Malik, Ashish Gehani
  - **institution:** University of Missouri, SRI International
  - **link:** https://arxiv.org/pdf/2512.22387
  - **contributions:** 1. Introduces a three-layer dependency framework (claimed, working, runtime) to quantify the execution reproducibility of LLM-generated code. 2. Conducts an empirical study evaluating three state-of-the-art LLM coding agents across 300 projects in three programming languages, revealing low out-of-the-box execution success rates. 3. Discovers a significant hidden dependency problem, with an average 13.5x expansion from declared to actual runtime dependencies.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the reproducibility of code generated by LLM-based coding agents. It proposes a three-layer dependency framework and conducts an empirical study on 300 projects, finding that only 68.3% execute successfully out-of-the-box and that actual runtime dependencies are significantly larger than declared ones. The study concludes that AI-generated code currently suffers from major reproducibility issues due to dependency gaps and code generation errors.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents"] --> Problem["核心问题/Problem: Is AI-generated code reproducible?"]
        Root --> Method["主要方法/Method: Empirical study using a three-layer dependency framework on 300 projects from 3 LLM agents."]
        Root --> Results["关键结果/Results: Low out-of-the-box execution rate (68.3%) and large hidden dependencies (13.5x expansion)."]
    ```

- **[arXiv251230] Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection**
  - **tags:** [mlsys], [agent system], [multi-agent LLM framework, knowledge gap detection, student-AI dialogue analysis, QueryQuilt, educational technology]
  - **authors:** Quanzhi Fu, Qiyu Wu, Dan Williams
  - **institution:** Virginia Tech
  - **link:** https://arxiv.org/pdf/2512.22404
  - **contributions:** 1. Proposes QueryQuilt, a novel multi-agent LLM framework for automated detection of common student knowledge gaps in large lectures. 2. Introduces a two-agent design: a Dialogue Agent that engages students with probing questions and a Knowledge Gap Identification Agent that analyzes chat logs. 3. Demonstrates the system's potential with high accuracy (100%) on simulated data and high completeness (95%) on real student-AI dialogue data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/346f14200e9375ed815220f7c720c8952c5109e4bcf1c3f206a9c517e2f80947_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes QueryQuilt, a multi-agent LLM framework that analyzes student-AI chat logs to automatically identify common knowledge gaps in large-scale lectures. The system uses a Dialogue Agent to interact with students and a Knowledge Gap Identification Agent to analyze the dialogues, providing instructors with insights into class-wide understanding. Initial evaluation shows promising accuracy and completeness, indicating its potential for improving teaching in real classroom environments.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[大班教学难以及时发现学生的知识缺口/Large lectures make timely knowledge gap identification challenging]
    C --> C1[提出QueryQuilt: 一个多智能体LLM框架/Propose QueryQuilt: a multi-agent LLM framework]
    C1 --> C2[对话智能体: 回答并探查学生问题/Dialogue Agent: responds and probes student questions]
    C1 --> C3[知识缺口识别智能体: 分析对话识别共同缺口/Knowledge Gap Identification Agent: analyzes dialogues to identify common gaps]
    D --> D1[模拟学生数据: 100%准确率/Simulated student data: 100% accuracy]
    D --> D2[真实学生-AI对话数据: 95%完整性/Real student-AI dialogue data: 95% completeness]
    ```

- **[arXiv251230] Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding**
  - **tags:** [se], [human aspects of software engineering], [vibe coding, large language models, grounded theory, prompt engineering, software development practices]
  - **authors:** Yi-Hung Chou, Boyuan Jiang, Yi Wen Chen, Mingyue Weng, Victoria Jackson, Thomas Zimmermann, James A. Jones
  - **institution:** University of California, Irvine
  - **link:** https://arxiv.org/pdf/2512.22418
  - **contributions:** 1. Conducted a grounded theory study of "vibe coding" practices through analysis of 20 videos, providing empirical data on this emerging phenomenon. 2. Identified a spectrum of developer behaviors, from full reliance on AI without code inspection to active examination and adaptation of generated outputs. 3. Revealed that developers must contend with the stochastic nature of LLM generation, framing debugging as "rolling the dice," and that divergent mental models influence prompting, evaluation, and trust.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eab8ec990fa93b887bf7f5945d43ce53b02d7e23a90f66d7421522c4fb50f07c_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the emerging practice of "vibe coding," where developers build software primarily by prompting LLMs. Through a qualitative grounded theory study of 20 videos, the research reveals a spectrum of developer behaviors and the central challenge of dealing with stochastic AI outputs, described as "rolling the dice." The findings highlight how developers' mental models shape their interaction with AI and point to new research directions for the future of software engineering.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM驱动的"氛围编码"实践如何定义与进行?/How is LLM-driven "vibe coding" defined and practiced?]
        C --> C1[对20个视频进行扎根理论研究/Grounded theory study of 20 videos]
        C --> C2[分析直播与观点视频/Analyze live-streamed & opinion videos]
        D --> D1[行为谱系: 从完全依赖到检查适配/Spectrum of behaviors: from full reliance to inspection & adaptation]
        D --> D2[核心挑战: 生成的随机性/"掷骰子"/Core challenge: stochastic generation / "rolling the dice"]
        D --> D3[心智模型影响策略与信任/Mental models influence strategies & trust]
    ```

- **[arXiv251230] GraphLocator: Graph-guided Causal Reasoning for Issue Localization**
  - **tags:** [se], [issue localization], [causal issue graph, dynamic issue disentangling, symptom-to-cause mismatch, one-to-many mismatch]
  - **authors:** Wei Liu, Chao Peng, Pengfei Gao, Aofan Liu, Wei Zhang, Haiyan Zhao, Zhi Jin
  - **institution:** Peking University, Bytedance
  - **link:** https://arxiv.org/pdf/2512.22469
  - **contributions:** 1. Proposes GraphLocator, an LLM-based approach for issue localization that addresses the semantic gap between issue descriptions and code. 2. Introduces the Causal Issue Graph (CIG) to model sub-issues and their causal dependencies, mitigating symptom-to-cause and one-to-many mismatches. 3. Demonstrates significant performance improvements in localization accuracy and downstream task performance through a two-phase workflow of symptom locating and dynamic graph discovery.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7dff9ac90f028731aa3b3d082126f3d3de229d3c53b61e302fd7d16eba1e084_w640_q70.webp
  - **Simple LLM Summary:** This paper tackles the challenge of automatically localizing code that needs to be changed based on a natural language issue description. It proposes GraphLocator, a method that constructs a Causal Issue Graph to reason about underlying sub-issues and their dependencies, effectively bridging the semantic gap. Experiments show it significantly outperforms baselines in both recall and precision for issue localization.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GraphLocator: Graph-guided Causal Reasoning for Issue Localization] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[语义鸿沟/Semantic Gap]
        B1 --> B2[症状-原因不匹配/Symptom-to-Cause Mismatch]
        B1 --> B3[一对多不匹配/One-to-Many Mismatch]
        C --> C1[因果问题图/Causal Issue Graph (CIG)]
        C --> C2[两阶段工作流/Two-Phase Workflow]
        C2 --> C3[症状定位/Symptom Vertices Locating]
        C2 --> C4[动态图发现/Dynamic CIG Discovering]
        D --> D1[定位更准确/More Accurate Localization]
        D1 --> D2[召回率提升 +19.49%/Recall +19.49%]
        D1 --> D3[精确率提升 +11.89%/Precision +11.89%]
        D --> D4[下游任务性能提升/Downstream Task Improvement]
        D4 --> D5[性能提升 +28.74%/Performance +28.74%]
    ```

- **[arXiv251230] Isolating Compiler Faults via Multiple Pairs of Adversarial Compilation Configurations**
  - **tags:** [mlsys], [compiler & ir], [compiler fault localization, adversarial compilation configurations, spectrum-based fault localization (SBFL), weighted voting, GCC bugs]
  - **authors:** Qingyang Li, Yibiao Yang, Maolin Sun, Jiangchang Wu, Qingkai Shi, Yuming Zhou
  - **institution:** State Key Laboratory for Novel Software Technology, Nanjing University, China
  - **link:** https://arxiv.org/pdf/2512.22538
  - **contributions:** 1. Proposes MultiConf, a novel approach that automatically isolates compiler faults by constructing multiple pairs of adversarial compilation configurations (failing and passing). 2. Introduces a lightweight process to generate failing configurations and derives passing ones by selectively disabling bug-related fine-grained options. 3. Employs an SBFL formula and a weighted voting scheme to aggregate rankings from multiple configuration pairs, achieving more accurate and robust fault localization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/437f9126029a1a7c1875bde92aa42b0d549a6a8a506d4dcc1135cf46b3380620_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of localizing faults in complex compilers by proposing MultiConf, a method that uses multiple pairs of adversarial compilation configurations and a weighted voting scheme to rank suspicious source files. Evaluated on 60 real GCC bugs, MultiConf significantly outperforms existing techniques, localizing 27 bugs at the Top-1 file level.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Isolating Compiler Faults via Multiple Pairs of Adversarial Compilation Configurations<br>基于多对抗编译配置对的编译器故障隔离] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Compiler fault localization is challenging due to complexity.<br>编译器故障定位因复杂性而极具挑战] --> B1[Prior methods are costly and unstable.<br>现有方法成本高且不稳定]
        C[主要方法/Method<br>MultiConf: Constructs multiple adversarial configuration pairs.<br>构建多对抗配置对] --> C1[Generates failing & passing configs with fine-grained options.<br>生成细粒度选项的失败与通过配置]
        C --> C2[Uses SBFL and weighted voting for ranking.<br>使用SBFL和加权投票进行排序]
        D[关键结果/Results<br>Evaluation on 60 GCC bugs.<br>在60个GCC缺陷上评估] --> D1[Localizes 27 bugs at Top-1, outperforming state-of-the-art.<br>在Top-1定位27个缺陷，优于现有技术]
    ```

- **[arXiv251230] Rethinking the Capability of Fine-Tuned Language Models for Automated Vulnerability Repair**
  - **tags:** [se], [automated program repair], [automated vulnerability repair, fine-tuned language models, test-based evaluation, semantic-preserving transformations, generalization]
  - **authors:** Woorim Han, Yeongjun Kwak, Miseon Yu, Kyeongmin Kim, Younghan Lee, Hyungon Moon, Yunheung Paek
  - **institution:** Seoul National University, UNIST (Ulsan National Institute of Science and Technology), Sungshin Women’s University
  - **link:** https://arxiv.org/pdf/2512.22633
  - **contributions:** 1. Introduces semantic-preserving transformations to test sets to assess if models learn robust patterns or spurious features. 2. Re-splits datasets to be mutually exclusive to properly evaluate model generalization on unseen vulnerabilities. 3. Proposes L-AVRBench, a test-based benchmark, to overcome the limitations of token-level match-based evaluation metrics.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d770d836cf9a18ac948b50e2b265b8ff346227d4dd0f8e12930e2897a03429f4_w640_q70.webp
  - **Simple LLM Summary:** This paper critically examines the capabilities of fine-tuned language models for automated vulnerability repair (AVR). It finds that state-of-the-art models often overfit and are evaluated on non-exclusive data splits using inadequate metrics. To address this, the authors propose methods to test robustness and generalization, and introduce a new test-based benchmark (L-AVRBench) to better assess true repair capability.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题: Rethinking the Capability of Fine-Tuned Language Models for Automated Vulnerability Repair] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[模型过拟合 & 评估集非互斥/Models Overfit & Non-exclusive Evaluation Sets]
        B --> B2[基于匹配的评估指标有局限/Match-based Metrics are Limited]
        C --> C1[应用语义保持变换/Apply Semantic-preserving Transformations]
        C --> C2[重新划分互斥的数据集/Re-split Mutually Exclusive Datasets]
        C --> C3[引入测试基准 L-AVRBench/Introduce Test-based Benchmark L-AVRBench]
        D --> D1[揭示模型泛化能力不足/Revealed Insufficient Model Generalization]
        D --> D2[提出了更鲁棒的评估框架/Proposed a More Robust Evaluation Framework]
    ```

- **[arXiv251230] CFIghter: Automated Control-Flow Integrity Enablement and Evaluation for Legacy C/C++ Systems**
  - **tags:** [sec], [control-flow integrity], [control-flow integrity, compiler-based security, automated repair, legacy systems, runtime monitoring]
  - **authors:** Sabine Houy, Bruno Kreyssig, Alexandre Bartel
  - **institution:** Umeå University
  - **link:** https://arxiv.org/pdf/2512.22701
  - **contributions:** 1. Presents CFIghter, the first fully automated system for enabling strict, type-based CFI in real-world C/C++ projects by detecting, classifying, and repairing unintended policy violations. 2. Integrates whole-program analysis with guided runtime monitoring to iteratively apply minimal adjustments to CFI enforcement only where required. 3. Demonstrates high effectiveness by automatically repairing 95.8% of unintended CFI violations in a large codebase while retaining strict enforcement at over 89% of indirect control-flow sites, showing automated repair makes strict CFI practically deployable.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/436657782d1936c221bd69d6fb671fff796d4c4a2db996690bbe0d6bea5a3b55_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of deploying compiler-based Control-Flow Integrity (CFI) in large legacy C/C++ systems due to semantic mismatches that cause runtime crashes. It proposes CFIghter, an automated system that uses whole-program analysis and runtime monitoring to detect and repair these unintended violations, requiring minimal manual changes. The evaluation shows CFIghter successfully resolves most violations in real-world projects, making strict CFI practically deployable for mature software.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CFIghter: Automated Control-Flow Integrity Enablement and Evaluation for Legacy C/C++ Systems] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[CFI部署困难/CFI Deployment Challenges]
        B1 --> B2[语义不匹配导致崩溃/Semantic Mismatch Causes Crashes]
        C --> C1[自动化系统/Automated System]
        C1 --> C2[检测与修复/Detection & Repair]
        C2 --> C3[最小调整/Minimal Adjustments]
        D --> D1[高修复率/High Repair Rate]
        D1 --> D2[95.8% 违规修复/95.8% Violations Repaired]
        D --> D3[严格CFI保留/Strict CFI Retained]
        D3 --> D4[>89% 站点/>89% of Sites]
    ```

- **[arXiv251230] From Rookie to Expert: Manipulating LLMs for Automated Vulnerability Exploitation in Enterprise Software**
  - **tags:** [sec], [vulnerability exploitation], [LLM, social engineering, pretexting, Odoo ERP, RSA]
  - **authors:** Moustapha Awwalou Diouf, Maimouna Tamah Diao, Iyiola Emmanuel Olatunji, Abdoul Kader Kaboré, Jordan Samhi, Gervais Mendy, Samuel Ouya, Jacques Klein, Tegawendé F. Bissyandé
  - **institution:** University of Luxembourg
  - **link:** https://arxiv.org/pdf/2512.22753
  - **code:** https://anonymous.4open.science/r/From-Rookie-to-Attacker-D8B3
  - **contributions:** 1. Proposes RSA (Role-assignment, Scenario-pretexting, and Action-solicitation), a novel pretexting strategy to manipulate LLMs into generating functional exploits. 2. Demonstrates a 100% success rate in generating working exploits for tested CVEs against the Odoo ERP platform using five mainstream LLMs within 3-4 prompting rounds. 3. Shows that LLMs can eliminate the manual effort previously required for LLM-assisted attacks, fundamentally challenging core security principles about technical expertise and threat modeling.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9fa715a252b1e75790a16c013941796c349d193dcd31101439954451a3b63bf5_w640_q70.webp
  - **Simple LLM Summary:** This paper demonstrates how publicly available Large Language Models (LLMs) can be manipulated through a social engineering strategy called RSA to automatically generate functional software exploits, effectively enabling novices to become capable attackers. The method achieved a 100% success rate against a popular enterprise platform, showing that exploitation no longer requires deep technical expertise but only the ability to craft prompts. This finding invalidates traditional security assumptions and signals a paradigm shift requiring redesigned security practices.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[From Rookie to Expert: Manipulating LLMs for Automated Vulnerability Exploitation in Enterprise Software] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLMs的普及颠覆了软件安全的基本假设 / LLMs democratize access, undermining security assumptions]
        C --> C1[提出RSA策略:角色分配、场景预设、行动诱导 / Propose RSA: Role-assignment, Scenario-pretexting, Action-solicitation]
        D --> D1[在Odoo ERP上对5个主流LLM测试成功率达100% / 100% success rate on Odoo with 5 LLMs]
        D --> D2[攻击无需专业知识，仅需提示工程 / Exploitation requires prompting, not coding expertise]
    ```

- **[arXiv251230] FasterPy: An LLM-based Code Execution Efficiency Optimization Framework**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [Code Optimization, Retrieval-Augmented Generation (RAG), Low-Rank Adaptation (LoRA), Large Language Models (LLMs), Python]
  - **authors:** Yue Wu, Minghao Han, Ruiyin Li, Peng Liang, Amjed Tahir, Zengyang Li, Qiong Feng, Mojtaba Shahin
  - **institution:** Wuhan University, Carnegie Mellon University, Massey University, Central China Normal University, Nanjing University of Science and Technology, RMIT University
  - **link:** https://arxiv.org/pdf/2512.22827
  - **code:** https://github.com/WuYue22/fasterpy
  - **contributions:** 1. Proposes FasterPy, a low-cost and efficient framework that adapts LLMs for Python code execution efficiency optimization. 2. Combines Retrieval-Augmented Generation (RAG) with a knowledge base of performance-improving code pairs and Low-Rank Adaptation (LoRA) to enhance optimization performance. 3. Demonstrates superior performance over existing models on the Performance Improving Code Edits (PIE) benchmark.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49aae1b7cd12cfd30401a619c9b06d4bccc853d1d14eed57af87eb6c80858f31_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces FasterPy, a framework that uses Large Language Models (LLMs) enhanced with Retrieval-Augmented Generation (RAG) and Low-Rank Adaptation (LoRA) to automatically optimize Python code for better execution efficiency. It addresses the limitations of traditional rule-based and data-intensive ML methods by providing a more scalable and cost-effective solution. Experimental results show that FasterPy outperforms existing models on standard benchmarks.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FasterPy: An LLM-based Code Execution Efficiency Optimization Framework] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统方法成本高，可扩展性差/Traditional methods are costly and hard to scale]
        C --> C1[结合RAG与LoRA的LLM框架/LLM framework combining RAG and LoRA]
        D --> D1[在PIE基准上表现优异/Outperforms existing models on PIE benchmark]
    ```

- **[arXiv251230] Towards the analysis of team members well-being**
  - **tags:** [se], [software development team well-being], [well-being, software development, team members, positive feedback, prototype]
  - **authors:** Zan Xu, Sari Nurfauziyyah, Anastasia Romanova, Kaamesh G S, Yiqun Gao, Maria Spichkova
  - **institution:** RMIT University
  - **link:** https://arxiv.org/pdf/2512.22845
  - **contributions:** 1. Presents the results of a project focused on analyzing the well-being of software development team members. 2. Identifies the feeling of being appreciated and acknowledged as a critical factor for team member well-being. 3. Describes the development of a prototype tool-supported framework aimed at providing personalized positive feedback without creating significant additional workload.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44b6ecf51f08897fa2d6ed662014dae0fe49b0c593bf9e815394b288ffd9d465_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the growing concern for the well-being of software development team members, emphasizing the importance of feeling appreciated. It presents a project that developed a prototype for a tool-supported, personalized framework to provide positive feedback. The goal is to improve well-being without adding substantial extra work for team members.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Towards the analysis of team members well-being] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[软件团队成员幸福感/Software Team Member Well-being]
        B1 --> B2[关键因素：被赞赏与认可/Critical Factor: Feeling Appreciated & Acknowledged]
        C --> C1[项目分析与原型开发/Project Analysis & Prototype Development]
        D --> D1[提出工具支持的个性化框架/Proposed Tool-supported Personalized Framework]
    ```

- **[arXiv251230] Interpretable Gallbladder Ultrasound Diagnosis: A Lightweight Web-Mobile Software Platform with Real-Time XAI**
  - **tags:** [cv], [medical image classification], [MobResTaNet, Explainable AI (XAI), lightweight model, ultrasound diagnosis, web-mobile platform]
  - **authors:** Fuyad Hasan Bhoyan, Prashanta Sarker, Parsia Noor Ethila, Md. Emon Hossain, Md Kaviul Hossain, Md Humaion Kabir Mehedi
  - **institution:** University of Liberal Arts Bangladesh, BRAC University
  - **link:** https://arxiv.org/pdf/2512.23033
  - **contributions:** 1. Proposed a hybrid deep learning model (MobResTaNet) for classifying ten gallbladder conditions from ultrasound images with high accuracy (99.85%) and low parameter count (2.24M). 2. Developed an interpretable diagnostic system with real-time Explainable AI (XAI) visualizations to support transparent clinical decision-making. 3. Deployed the system as an efficient and accessible web-mobile software platform using technologies like HTML, CSS, JavaScript, Bootstrap, and Flutter for point-of-care use.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c6a6693ffd9f4375cd5a781c2544fba169bc30bc3cbb7590b1562ea78ba6678_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of interpreting gallbladder ultrasound images by developing an AI-driven diagnostic software. The core method is a lightweight hybrid deep learning model called MobResTaNet, which classifies diseases and provides real-time, interpretable predictions via XAI. The main conclusion is that the system achieves high accuracy with a small model size and is successfully deployed as accessible web and mobile applications for clinical support.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Interpretable Gallbladder Ultrasound Diagnosis] --> B[核心问题/Problem: Challenging ultrasound interpretation for gallbladder diseases]
        A --> C[主要方法/Method: AI software with lightweight MobResTaNet model & real-time XAI]
        A --> D[关键结果/Results: 99.85% accuracy, 2.24M parameters, deployed web-mobile platform]
    ```

- **[arXiv251230] An Architecture-Led Hybrid Report on Body Language Detection Project**
  - **tags:** [cv], [video understanding], [vision-language models, structured generation, bounding boxes, mixture-of-experts, video analysis]
  - **authors:** Thomson Tong, Diba Darooneh
  - **institution:** None
  - **link:** https://arxiv.org/pdf/2512.23028
  - **code:** BodyLanguageDetection repository [1]
  - **contributions:** 1. Provides an architecture-led analysis of two modern VLMs (Qwen2.5-VL-7B-Instruct and Llama-4-Scout-17B-16E-Instruct) for a practical task. 2. Maps model architectural properties to a concrete video-to-artifact pipeline for person detection and attribute extraction. 3. Explicitly defines and analyzes critical system constraints and limitations arising from model behavior, such as semantic vs. syntactic correctness and frame-local identifiers.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a618c048bc336ad2ade96a7a97cf301fb10fee2c9c8e7bc16556348f1c0c4b9d_w640_q70.webp
  - **Simple LLM Summary:** This report analyzes two vision-language models (VLMs) and connects their architectures to a practical system for detecting people and their emotions in video frames. The system prompts VLMs to generate structured outputs like bounding boxes, validates the output structure, and can render annotated videos. The core conclusion is that understanding model architecture is crucial for designing robust interfaces and making defensible claims, as VLMs can produce syntactically correct but semantically incorrect outputs.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[An Architecture-Led Hybrid Report on Body Language Detection Project] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[如何基于VLM架构构建可靠的应用系统/How to build reliable application systems based on VLM architecture]
        C --> C1[分析两种VLM架构并映射到视频处理流程/Analyze two VLM architectures and map to a video processing pipeline]
        C --> C2[系统采样视频帧，提示VLM生成结构化输出/System samples video frames, prompts VLM for structured output]
        C --> C3[使用预定义模式验证输出结构/Validate output structure with predefined schema]
        D --> D1[结构化输出可能语法正确但语义错误/Structured outputs can be syntactically valid but semantically incorrect]
        D --> D2[模式验证是结构性的，非几何正确性/Schema validation is structural, not geometric]
        D --> D3[理解架构对设计稳健接口和评估至关重要/Understanding architecture is critical for robust interface design and evaluation]
    ```

- **[arXiv251230] Reimagining the Traditional Flight Computer: E6BJA as a Modern, Multi-Platform Tool for Flight Calculations and Training**
  - **tags:** [other], [human-computer interaction], [flight computer, multi-platform software, aviation training, educational monographs, weight and balance]
  - **authors:** Jamie J. Alnasir
  - **institution:** None (Inferred from author's email domain: al-nasir.com, which appears to be a personal domain)
  - **link:** https://arxiv.org/pdf/2512.23055
  - **contributions:** 1. Development of E6BJA, a modern, multi-platform (iOS, Android, Windows, web) software flight computer that replicates and extends traditional flight calculations. 2. Integration of enhanced modeling capabilities (e.g., 1976 International Standard Atmosphere, carburetor icing risk) and aircraft-specific calculators with embedded educational explanations. 3. A comparative analysis demonstrating the tool's improvements over traditional devices in accuracy, error reduction, discoverability, and educational value for pilot training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/728f903c57bf352d1339c863c7cb1986de9a626a56f8a15516317cf7068bcb83_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of traditional mechanical and electronic flight computers by proposing E6BJA, a modern multi-platform software tool. E6BJA replicates core flight calculations while adding enhanced models and embedded educational content. The work concludes that this approach represents a meaningful evolution in pilot tools, improving safety, intuition, and instructional value in aviation training contexts.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Reimagining the Traditional Flight Computer") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("传统飞行计算机的局限性/Limitations of Traditional Flight Computers")
        Method --> M1("开发多平台软件E6BJA/Develop Multi-Platform Software E6BJA")
        Method --> M2("扩展计算与教育功能/Extend Calculations & Educational Features")
        Results --> R1("证明在准确性等方面的改进/Demonstrate Improvements in Accuracy, etc.")
        Results --> R2("支持更安全的飞行规划/Support Safer Flight Planning")
    ```

- **[arXiv251230] An Automated Grey Literature Extraction Tool for Software Engineering**
  - **tags:** [se], [grey literature extraction], [grey literature, semantic classifier, embedding, reproducibility, prompt-driven]
  - **authors:** Houcine Abdelkader Cherief, Brahim Mahmoudi, Zacharie Chenail-Larcher, Naouel Moha, Quentin Sti'evenart, Florent Avellaneda
  - **institution:** École de technologie supérieure, Université du Québec à Montréal
  - **link:** https://arxiv.org/pdf/2512.23066
  - **contributions:** 1. The GLiSE tool, a prompt-driven system for automated grey literature extraction from heterogeneous web sources. 2. A curated dataset of software engineering grey-literature search results classified by semantic relevance. 3. An empirical study evaluating the usability of the proposed tool.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcd8d541170e102d077ea8b0f0d18f0b4d898d754f2e5dea87a8696f74de7b5c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the difficulty of collecting and assessing grey literature in software engineering at scale due to heterogeneous sources and formats. It proposes GLiSE, a prompt-driven tool that generates platform-specific queries, gathers results from sources like GitHub and Stack Overflow, and uses embedding-based semantic classifiers to filter and rank results for relevance. The tool is designed for reproducibility and its usability is empirically evaluated.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[An Automated Grey Literature Extraction Tool for Software Engineering] --> B[核心问题/Problem: 收集和评估软件工程灰文献困难/Difficulty in collecting and assessing software engineering grey literature at scale]
        A --> C[主要方法/Method: GLiSE工具, 提示驱动, 嵌入语义分类器/GLiSE tool, prompt-driven, embedding-based semantic classifier]
        A --> D[关键结果/Results: 提供工具、数据集和可用性研究/Provides tool, curated dataset, and usability study]
    ```

- **[arXiv251230] Anka: A Domain-Specific Language for Reliable LLM Code Generation**
  - **tags:** [mlsys], [llm inference], [Domain-Specific Language, Constrained Syntax, Code Generation, Data Transformation Pipeline, In-Context Learning]
  - **authors:** Saif Khalfan Saif Al Mazrouei
  - **institution:** University of Wisconsin-Madison
  - **link:** https://arxiv.org/pdf/2512.23214
  - **contributions:** 1. Introduced Anka, a domain-specific language (DSL) with explicit, constrained syntax designed to reduce ambiguity in LLM code generation. 2. Demonstrated that LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy without prior training. 3. Showed that purposefully designed DSLs can outperform general-purpose languages (e.g., Python) on complex multi-step tasks, significantly reducing errors in operation sequencing and state management.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e450f3b6354a05c4c0dfa0c22c4f8b8dfc33c08282380080deb2d2f3a335d4_w640_q70.webp
  - **Simple LLM Summary:** This paper hypothesizes that the flexibility of general-purpose languages leads to systematic errors in LLM code generation for complex tasks. To test this, it introduces Anka, a constrained DSL for data transformation pipelines. The results show that LLMs can learn Anka from prompts and achieve significantly higher accuracy on multi-step tasks compared to Python, demonstrating the advantage of constrained syntax for reliable code generation.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Anka: A Domain-Specific Language for Reliable LLM Code Generation] --> B[核心问题/Problem: LLMs make systematic errors in complex multi-step code generation]
        A --> C[主要方法/Method: Design Anka, a constrained DSL for data transformation pipelines]
        A --> D[关键结果/Results: High parse success & task accuracy; Anka outperforms Python on multi-step tasks]
    ```

- **[arXiv251230] An Empirical Study of Generative AI Adoption in Software Engineering**
  - **tags:** [se], [AI4SE], [Generative AI, Software Engineering, Empirical Study, Survey, Adoption]
  - **authors:** Görkem Giray, Onur Demirörs, Marcos Kalinowski, Daniel Mendez
  - **institution:** Eindhoven University of Technology, Izmir Institute of Technology, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Blekinge Institute of Technology, fortiss
  - **link:** https://arxiv.org/pdf/2512.23327
  - **contributions:** 1. Provides an empirical overview of the current status of Generative AI adoption in software engineering practice. 2. Identifies and categorizes the key benefits, challenges, and organizational institutionalization patterns associated with GenAI use. 3. Investigates and reports on the anticipated long-term impacts of GenAI on the roles and job market for software engineering professionals.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45dc246f8337bce98d95170e37ed6c405c343b51bb32f568d576b057edc61ed3_w640_q70.webp
  - **Simple LLM Summary:** This paper conducts an international survey of 204 software engineering practitioners to empirically study the adoption of Generative AI tools. The results show widespread integration into daily tasks with reported benefits in productivity and quality, but also highlight persistent challenges like unreliable outputs and security concerns. The study concludes that a move from ad-hoc to systematic approaches is needed for sustainable and responsible GenAI integration in software engineering.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[An Empirical Study of Generative AI Adoption in Software Engineering] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[缺乏GenAI在SE中实际应用的实证证据/Lack of empirical evidence on practical GenAI use in SE]
        Method[主要方法/Method] --> M1[国际问卷调查/Internationally distributed questionnaire survey]
        Results[关键结果/Results] --> R1[广泛采用与深度集成/Wide adoption & deep integration]
        Results --> R2[显著收益与持续挑战/Substantial benefits & persistent challenges]
        Results --> R3[角色重定义而非替代/Role redefinition, not replacement]
    ```

- **[arXiv251230] Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?**
  - **tags:** [sec], [AI Security], [AI supply chain, security taxonomy, distilBERT classifier]
  - **authors:** Anh Nguyen, Triet Huynh Minh Le, M. Ali Babar
  - **institution:** University of Adelaide
  - **link:** https://arxiv.org/pdf/2512.23385
  - **contributions:** 1. Developed a pipeline combining keyword matching with a fine-tuned distilBERT classifier to identify 312,868 security discussions from Hugging Face and GitHub. 2. Conducted a thematic analysis to create a fine-grained taxonomy of 32 security issues and 24 solutions across four themes (System/Software, External Tools/Ecosystem, Model, Data). 3. Provided empirical insights revealing that security issues stem from complex dependencies and black-box AI components, with Model and Data challenges often lacking concrete solutions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates security issues in the AI supply chain by analyzing developer discussions from Hugging Face and GitHub. The authors use a keyword and classifier pipeline to build a large dataset and perform a thematic analysis to create a taxonomy of issues and solutions. They conclude that many security problems arise from dependencies and the black-box nature of AI, with solutions for Model and Data issues being particularly scarce.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Securing the AI Supply Chain] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[AI供应链安全格局复杂/Complex AI supply chain security landscape]
        Problem --> P2[缺乏对常见问题与解决方案的了解/Lack of knowledge on common issues & solutions]
        Method[主要方法/Method] --> M1[实证调查/Empirical investigation]
        M1 --> M1_1[数据源: Hugging Face, GitHub/Data Sources: Hugging Face, GitHub]
        M1 --> M1_2[构建分类管道/Build classification pipeline]
        M1_2 --> M1_2_1[关键词匹配+微调distilBERT/Keyword matching + fine-tuned distilBERT]
        Results[关键结果/Results] --> R1[数据集: 312,868个安全讨论/Dataset: 312,868 security discussions]
        Results --> R2[分类法: 32个问题, 24个解决方案/Taxonomy: 32 issues, 24 solutions]
        Results --> R3[洞察: 依赖复杂性和黑盒性导致问题/Insight: Issues from dependencies & black-box nature]
    ```

- **[arXiv251230] An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes**
  - **tags:** [mlsys], [cluster infrastructure], [Kubernetes, Autoscaling, AIOps, Service Level Objectives, Cost Optimization]
  - **authors:** Vinoth Punniyamoorthy, Bikesh Kumar, Sumit Saha, Lokesh Butra, Mayilsamy Palanigounder, Akash Kumar Agarwal, Kabilan Kannan
  - **institution:** IEEE, East West Bank, NTT Data, Albertsons
  - **link:** https://arxiv.org/pdf/2512.23415
  - **contributions:** 1. A gap-driven analysis of existing Kubernetes autoscaling approaches, highlighting their limitations. 2. A safe and explainable multi-signal autoscaling framework that integrates SLO-aware and cost-conscious control with demand forecasting. 3. Experimental evaluation demonstrating significant improvements in SLO violation duration, scaling response time, and infrastructure cost compared to baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce581ba4d1249deeba9f1bffa6739ebbe74df663542fef3893eee5e0a117ae2e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses SLO violations and cost inefficiencies in Kubernetes autoscaling by proposing an AIOps-driven framework that uses multi-signal control and lightweight forecasting. The method integrates SLO and cost awareness to improve responsiveness and stability. Evaluation shows it reduces SLO violations by up to 31%, improves response time by 24%, and lowers cost by 18% compared to standard Kubernetes autoscalers.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("SLO违反与成本低效/SLO Violations & Cost Inefficiency")
        Problem --> P2("反应式扩展与不透明逻辑/Reactive Scaling & Opaque Logic")
        Method --> M1("AIOps驱动的多信号框架/AIOps-Driven Multi-Signal Framework")
        Method --> M2("SLO与成本感知控制/SLO & Cost-Aware Control")
        Method --> M3("轻量级需求预测/Lightweight Demand Forecasting")
        Results --> R1("SLO违反时长减少31%/SLO Violation Duration Reduced by 31%")
        Results --> R2("扩展响应时间提升24%/Scaling Response Time Improved by 24%")
        Results --> R3("基础设施成本降低18%/Infrastructure Cost Lowered by 18%")
    ```

- **[arXiv251230] Embedding Quality Assurance in project-based learning**
  - **tags:** [se], [Software Engineering Education], [Quality Assurance, Project-based Learning, Agile/Scrum, Software Engineering Education, Experience Report]
  - **authors:** Maria Spichkova
  - **institution:** RMIT University
  - **link:** https://arxiv.org/pdf/2512.23488
  - **contributions:** 1. Shares over a decade of lessons learned from teaching software quality within Agile/Scrum-based Software Engineering courses, including final-year projects and a project management course. 2. Identifies specific challenges students face in understanding and applying Quality Assurance (QA) within Agile/Scrum project-based learning environments. 3. Provides practical recommendations for effectively embedding QA topics into project-based learning curricula with an Agile/Scrum context.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/77065f8ef568ef76fd85920a5579be34df22a20ec5cca17659010df66ea57edb_w640_q70.webp
  - **Simple LLM Summary:** This paper presents an experience report on teaching software quality assurance in Agile/Scrum-focused Software Engineering courses over ten years. It identifies student struggles with QA in project-based learning and provides recommendations for better integrating QA topics into such curricula. The main conclusion is that a focused pedagogical approach is needed to ensure students value and apply QA practices effectively in Agile settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Embedding Quality Assurance in Project-based Learning<br/>项目式学习中嵌入质量保证"] --> Problem["Students struggle with QA in Agile/Scrum PBL<br/>学生在敏捷/Scrum项目式学习中难以掌握质量保证"]
        Root --> Method["Experience report & lessons learned from 10+ years of teaching<br/>基于十多年教学的经验报告与经验教训"]
        Root --> Results["Recommendations for embedding QA in Agile/Scrum PBL<br/>为在敏捷/Scrum项目式学习中嵌入质量保证提供建议"]
    ```

- **[arXiv251230] Adaptable TeaStore: A Choreographic Approach**
  - **tags:** [sys], [choreographic programming], [adaptable microservices, choreographic programming, AIOCJ, runtime adaptation, communication correctness]
  - **authors:** Giuseppe De Palma, Saverio Giallorenzo, Ivan Lanese, Gianluigi Zavattaro
  - **institution:** Università di Bologna, INRIA
  - **link:** https://arxiv.org/pdf/2512.23497
  - **contributions:**  1. Presents an implementation of the Adaptable TeaStore reference model using the AIOCJ choreographic language. 2. Demonstrates that AIOCJ ensures by-construction correctness of communications (e.g., deadlock freedom) before, during, and after runtime adaptation. 3. Provides an analysis of the strengths and current limitations of the choreographic approach for adaptable cloud architectures, suggesting future refinements.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/185975480d365934f5e03c65e64353b019eae6a649d47d0cfc956b5c90524a0a_w640_q70.webp
  - **Simple LLM Summary:** This paper models the Adaptable TeaStore, a reference model for adaptable microservice architectures, using the AIOCJ choreographic programming language. The approach ensures communication correctness by construction and supports dynamic runtime adaptation. The work showcases the paradigm's strengths, identifies its limitations, and suggests future directions to better align it with real-world cloud systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Adaptable TeaStore: A Choreographic Approach") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("需要可适应的微服务架构/Need for adaptable microservice architectures")
        Method --> M1("使用AIOCJ编排语言/Use AIOCJ choreographic language")
        Method --> M2("确保通信正确性/Ensure communication correctness")
        Results --> R1("展示方法的优势与局限/Showcase strengths and limitations")
        Results --> R2("提出未来改进方向/Propose future refinements")
    ```

- **[arXiv251230] Decoupling Adaptive Control in TeaStore**
  - **tags:** [se], [self-adaptive systems], [self-adaptation, microservices, control loop, operator pattern, software architecture]
  - **authors:** Eddy Truyen
  - **institution:** DistriNet, KU Leuven
  - **link:** https://arxiv.org/pdf/2512.23495
  - **contributions:** 1. Analyzes how software architectural methods, the cloud-native Operator pattern, and legacy programming techniques can decouple adaptive control from the application logic in a microservice system. 2. Examines the trade-offs between fine-grained expressive adaptation and system-wide control, highlighting when reuse of adaptation strategies is effective. 3. Proposes that these approaches are complementary and can be combined into a multi-tiered architecture for self-adaptive microservices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78e96b6ab1b10ae0a32ddc4e7967c5bedce7be1b0fe5db13bec216c9e0b657ae_w640_q70.webp
  - **Simple LLM Summary:** This paper discusses the implementation of self-adaptation in the Adaptable TeaStore microservice benchmark. It examines different technical approaches (software architecture, Operator pattern, programming techniques) for decoupling the adaptive control logic from the application, analyzing their trade-offs. The main conclusion is that these approaches can be combined into a multi-tiered architecture for effective self-adaptive microservices.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Decoupling Adaptive Control in TeaStore] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[实现微服务中的细粒度自适应/Implementing fine-grained self-adaptation in microservices]
        C --> C1[软件架构方法/Software architectural methods]
        C --> C2[Operator模式/Operator pattern]
        C --> C3[传统编程技术/Legacy programming techniques]
        D --> D1[权衡细粒度与系统范围控制/Trade-offs between fine-grained and system-wide control]
        D --> D2[可组合的多层架构/Composable multi-tiered architecture]
    ```

- **[arXiv251230] Adaptable Teastore with Energy Consumption Awareness: A Case Study**
  - **tags:** [se], [self-adaptive systems], [energy consumption monitoring, self-adaptive systems, microservices, dynamic adaptation, cloud computing]
  - **authors:** Henrique De Medeiros, Denisse Muñante, Sophie Chabridon, César Perdigão Batista, Denis Conan
  - **institution:** Télécom SudParis, Institut Polytechnique de Paris, SAMOVAR, ENSIIE
  - **link:** https://arxiv.org/pdf/2512.23498
  - **contributions:** 1. Introduction of EnCoMSAS, a tool for monitoring energy consumption in distributed, self-adaptive software systems. 2. An empirical evaluation demonstrating EnCoMSAS's effectiveness and validating its measurements through correlation with CPU usage. 3. An analysis showing that the energy overhead of the monitoring tool itself is modest compared to the overall system.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ac42d90e6b95a7a182714a4c0e65c9755ffae7ca3f2ebec7e85bf313b892f10_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the gap in energy-aware monitoring for self-adaptive systems by introducing EnCoMSAS, a tool for collecting runtime energy consumption data. The tool was evaluated using the Adaptable TeaStore case study, where it effectively gathered energy data and revealed that consumption is influenced by both algorithmic complexity and deployment environment. The study concluded that EnCoMSAS is a valid monitoring solution with a relatively low impact on the overall system's energy footprint.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Adaptable Teastore with Energy Consumption Awareness: A Case Study] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Lack of effective energy monitoring tools for Self-Adaptive Systems (SAS) and unclear impact of such tools]
        C[主要方法/Method: Propose and evaluate EnCoMSAS tool using the Adaptable TeaStore case study on Grid5000]
        D[关键结果/Results: EnCoMSAS is effective; measurements are valid; tool's energy impact is modest]
    ```

- **[arXiv251230] AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices**
  - **tags:** [sys], [autonomic computing], [MAPE-K loop, decentralized adaptation, event-driven, rule-based, microservices]
  - **authors:** Brice Arléon Zemtsop Ndadji, Simon Bliudze, Clément Quinton
  - **institution:** Univ. Lille, CNRS, Inria, Centrale Lille, CRIStAL
  - **link:** https://arxiv.org/pdf/2512.23499
  - **contributions:** 1. A framework (AdaptiFlow) providing abstraction layers for the Monitor and Execute phases of the MAPE-K loop to enable autonomous microservices. 2. A lightweight, event-driven and rule-based mechanism for specifying adaptation logic, decoupling it from metrics collection and action execution. 3. A workflow for service instrumentation and evidence that decentralized adaptation can emerge from localized decisions without global coordination, validated through three adaptation scenarios (self-healing, self-protection, self-optimization).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cea3a497714ae1ca6ead099b1f31177f6fe2bf3d4bc5a184a21835b1744db4a_w640_q70.webp
  - **Simple LLM Summary:** This paper presents AdaptiFlow, a framework for building self-adaptive cloud microservices by decoupling metrics collection and action execution from adaptation logic using an event-driven, rule-based approach. It enables decentralized autonomy, allowing services to adapt locally without global coordination. The framework was validated on a benchmark, demonstrating practical implementation of self-healing, self-protection, and self-optimization scenarios with minimal code changes.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有方案集中式控制不适用于微服务/Existing centralized control ill-suited for microservices]
        C --> C1[基于MAPE-K的抽象层与事件驱动规则/MAPE-K abstraction layers & event-driven rules]
        C --> C2[解耦监控、执行与逻辑/Decouple Monitor/Execute from adaptation logic]
        D --> D1[实现三种自治场景/Implemented three autonomy scenarios]
        D --> D2[去中心化适应无需全局协调/Decentralized adaptation without global coordination]
    ```

- **[arXiv251230] Beyond Correctness: Exposing LLM-generated Logical Flaws in Reasoning via Multi-step Automated Theorem Proving**
  - **tags:** [nlp], [reasoning verification], [automated theorem proving, first-order logic, logical error detection, multi-step reasoning]
  - **authors:** Xinyi Zheng, Ningke Li, Xiaokun Luan, Kailong Wang, Ling Shi, Meng Sun, Haoyu Wang
  - **institution:** Huazhong University of Science and Technology, National University of Singapore, Peking University, Nanyang Technological University
  - **link:** https://arxiv.org/pdf/2512.23511
  - **contributions:** 1. Proposes MATP, a novel evaluation framework that uses Multi-step Automated Theorem Proving to verify LLM reasoning by translating it into First-Order Logic. 2. Provides a fine-grained classification of reasoning correctness, identifying hidden logical errors that are masked by fluent language. 3. Demonstrates superior performance over prompting-based baselines by over 42 percentage points and reveals disparities in logical coherence between different types of LLMs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b9201185009c06f76b12e788768ccb6a8e2846d1d6ae7c9dcca57af7e332cc0_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces MATP, a framework that translates LLM-generated natural language reasoning into First-Order Logic and uses automated theorem provers to verify its step-by-step logical validity. It effectively exposes subtle logical flaws that existing methods miss. Evaluations show MATP significantly outperforms baselines and can enhance the trustworthiness of LLM reasoning for critical applications.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Beyond Correctness: Exposing LLM-generated Logical Flaws<br>超越正确性：通过多步自动定理证明揭示LLM推理中的逻辑缺陷] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM推理存在被流畅语言掩盖的微妙逻辑错误<br>Subtle logical errors in LLM reasoning masked by fluent language]
        C --> C1[提出MATP框架：将自然语言推理转化为一阶逻辑<br>Propose MATP: Translates NL reasoning to FOL]
        C --> C2[使用自动定理证明器进行多步验证<br>Uses automated theorem provers for multi-step verification]
        D --> D1[在推理步骤验证上超越基线42个百分点<br>Surpasses baselines by over 42 percentage points]
        D --> D2[揭示推理模型比通用模型逻辑更一致<br>Reveals reasoning models are more logically coherent]
    ```

- **[arXiv251230] Beyond Per-Thread Lock Sets: Multi-Thread Critical Sections and Dynamic Deadlock Prediction**
  - **tags:** [se], [dynamic deadlock prediction], [lock sets, critical sections, partial order relations, false positives, false negatives]
  - **authors:** Martin Sulzmann
  - **institution:** Karlsruhe University of Applied Sciences
  - **link:** https://arxiv.org/pdf/2512.23552
  - **contributions:** 1. Introduces a novel trace-based characterization of critical sections that can span multiple threads, correcting the standard per-thread model., 2. Proposes a sound approximation of the multi-thread critical section concept using partial order relations, enabling an improved lock set construction., 3. Integrates the improved lock set construction into an extended SPDOffline deadlock predictor, reducing both false positives and false negatives without impacting performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d58fc411df804f4dd88c8339e7b2a1b64be70d9eca8844a0dbb324c049cdea_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies that standard per-thread lock set analysis for deadlock prediction is flawed because it ignores locks acquired across thread boundaries, leading to inaccurate results. To solve this, the authors propose a new model of multi-thread critical sections and a sound approximation method using partial order relations to construct more precise lock sets. This approach, integrated into an extended predictor, reduces false positives and false negatives while maintaining performance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Beyond Per-Thread Lock Sets: Multi-Thread Critical Sections and Dynamic Deadlock Prediction] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[标准每线程锁集分析忽略跨线程锁/Standard per-thread lock sets ignore cross-thread locks]
        B1 --> B2[导致假阳性和假阴性/Leads to false positives and false negatives]
        C --> C1[提出基于轨迹的多线程临界区概念/Propose trace-based multi-thread critical sections]
        C1 --> C2[使用偏序关系进行可靠近似/Use partial order relations for sound approximation]
        C2 --> C3[改进锁集构造/Improved lock set construction]
        D --> D1[减少假阳性和假阴性/Reduces false positives and false negatives]
        D1 --> D2[性能不受影响/Performance not affected]
    ```

- **[arXiv251230] Model-based Development for Autonomous Driving Software Considering Parallelization**
  - **tags:** [mlsys], [compiler & ir], [Model-Based Development, Parallelization, Multi-core Processor, Autonomous Driving Software, Real-time Performance]
  - **authors:** Kenshin Obi, Takumi Onozawa, Hiroshi Fujimoto, Takuya Azumi
  - **institution:** Saitama University, eSOL Co., Ltd.
  - **link:** https://arxiv.org/pdf/2512.23575
  - **contributions:** 1. Proposes a method to extend the existing Model-Based Parallelizer (MBP) to support complex processing blocks (like Simulink Toolbox blocks) for autonomous driving software. 2. Addresses the problem of decreasing the number of blocks available for parallelization when using high-level Toolbox blocks and code descriptions. 3. Demonstrates a reduction in execution time, showing the method's suitability for achieving real-time performance in autonomous driving software development.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdaf1e9de27edf6ed5439e7e3abd6bd6f053fa858fced85d7eae12b8159fc8b4_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a model-based development method for parallelizing autonomous driving software to meet real-time performance requirements. It extends the existing Model-Based Parallelizer (MBP) to handle complex processing blocks, thereby reducing execution time. The evaluation confirms the method's effectiveness for developing real-time autonomous driving systems.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Model-based Development for Autonomous Driving Software Considering Parallelization] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[自动驾驶软件需要实时性能/Autonomous driving software requires real-time performance]
        C --> C1[扩展基于模型的并行化方法/Extend Model-Based Parallelizer (MBP) method]
        D --> D1[执行时间减少/Execution time was reduced]
    ```

- **[arXiv251230] Parallelized Code Generation from Simulink Models for Event-driven and Timer-driven ROS 2 Nodes**
  - **tags:** [sys], [embedded systems], [model-based development, parallelization, ROS 2, Simulink, multi-core processors]
  - **authors:** Kenshin Obi, Ryo Yoshinaka, Hiroshi Fujimoto, Takuya Azumi
  - **institution:** Saitama University, eSOL Co., Ltd.
  - **link:** https://arxiv.org/pdf/2512.23605
  - **contributions:** 1. Proposes a model-based development framework that categorizes ROS 2-compatible Simulink models into event-driven and timer-driven types for targeted parallelization. 2. Extends conventional MBD parallelization to support ROS 2-based models with multiple inputs, addressing integration challenges. 3. Demonstrates the framework's effectiveness by showing reduced execution time for all tested patterns after parallelization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1cb6e7053c79e3517530163d94d50906a3c12983608458bcd92e238407357675_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of integrating automatic model-based parallelization with the ROS 2 framework for autonomous driving systems. It proposes a framework that categorizes Simulink models as event-driven or timer-driven to generate parallelized code for ROS 2 nodes. Evaluation results confirm that the approach successfully reduces execution time.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Parallelized Code Generation from Simulink Models for Event-driven and Timer-driven ROS 2 Nodes] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统MBD难以集成ROS 2/Traditional MBD struggles with ROS 2 integration]
        B --> B2[多输入场景的并行化挑战/Parallelization challenges in multi-input scenarios]
        C --> C1[将模型分类为事件驱动与定时驱动/Categorize models as event-driven & timer-driven]
        C --> C2[提出针对性并行化的MBD框架/Propose MBD framework for targeted parallelization]
        D --> D1[所有模式执行时间减少/All patterns show reduced execution time]
        D --> D2[验证了并行化的有效性/Confirms effectiveness of parallelization]
    ```

- **[arXiv251230] Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity**
  - **tags:** [mlsys], [federated learning], [L0 regularization, probabilistic gates, communication efficiency, model sparsity, federated stochastic gradient descent]
  - **authors:** Krishna Harsha Kovelakuntla Huthasana, Alireza Olama, Andreas Lundell
  - **institution:** Åbo Akademi University
  - **link:** https://arxiv.org/pdf/2512.23071
  - **contributions:** 1. Proposes a novel federated learning method that enforces an L0 constraint on model parameters using probabilistic gates and their continuous relaxation to achieve target sparsity. 2. Derives the L0 constrained stochastic minimization objective from an entropy maximization problem of the stochastic gates. 3. Demonstrates that the method can achieve high target sparsity (down to ρ=0.005) under data and client heterogeneity with minimal loss in statistical performance, outperforming magnitude pruning-based methods.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259d06fa8e807f154e153891f40b44308796040886ed51e218b65ee4e67a8c9c_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of poor generalizability and communication inefficiency in Federated Learning due to overly dense models. It proposes a method to enforce L0 sparsity constraints via probabilistic gates, deriving the objective from entropy maximization and implementing it with federated stochastic gradient descent. The method is shown to be communication-efficient and achieves high target sparsity with better statistical performance than pruning-based baselines on synthetic and real datasets.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: 数据与模型固有的稀疏性未被解决，导致模型过密、泛化性差，且存在数据和客户端参与异质性。]
        Method[主要方法/Method: 通过概率门及其连续松弛对非零参数密度施加L0约束，目标源自随机门的熵最大化问题，并基于联邦随机梯度下降。]
        Results[关键结果/Results: 在数据和客户端异质性下，能达到目标密度(ρ)，统计性能损失最小，且比基于幅度的剪枝方法更优、通信高效。]
    ```

- **[arXiv251230] LogosQ: A High-Performance and Type-Safe Quantum Computing Library in Rust**
  - **tags:** [mlsys], [compiler & ir], [Rust, type safety, quantum simulation, variational algorithms, parameter-shift rule]
  - **authors:** Shiwen An, Jiayi Wang, Konstantinos Slavakis
  - **institution:** Institute of Science Tokyo, Georgia Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.23183
  - **contributions:** 1. Introduces LogosQ, a quantum computing library in Rust that uses compile-time type safety to eliminate runtime errors, especially in gradient computations. 2. Proposes novel optimization techniques like direct state-vector manipulation, adaptive parallel processing, and an FFT-optimized QFT for significant performance gains. 3. Demonstrates superior numerical stability and accuracy in variational quantum eigensolver (VQE) experiments compared to existing frameworks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3869523633aebacf98c54bdd34569f2d2e445db13de6918d6fa0d76072c1a8df_w640_q70.webp
  - **Simple LLM Summary:** The paper presents LogosQ, a high-performance quantum computing library written in Rust that ensures correctness through compile-time type safety. It introduces several optimization techniques that achieve speedups of up to 900x for certain operations and shows improved numerical stability in variational algorithm experiments. The work establishes a new standard for reliable and efficient quantum simulation by combining systems programming safety with advanced circuit optimizations.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[LogosQ: Rust高性能类型安全量子库] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[Python框架动态性导致运行时错误/Runtime errors in dynamic Python frameworks]
        Problem --> P2[现有工具存在可扩展性瓶颈/Scalability bottlenecks in existing tools]
        Method[主要方法/Method] --> M1[Rust实现与编译时类型安全/Rust implementation with compile-time type safety]
        Method --> M2[引入新型优化技术/Novel optimization techniques]
        Results[关键结果/Results] --> R1[性能大幅提升/Significant speedups (up to 900x)]
        Results --> R2[数值稳定性验证/Validated numerical stability]
        Results --> R3[建立可靠高效新标准/Establishes new standard for reliability & efficiency]
    ```

## 2026-01-01

- **[arXiv260101] AgenticTCAD: A LLM-based Multi-Agent Framework for Automated TCAD Code Generation and Device Optimization**
  - **tags:** [mlsys], [agent system], [TCAD code generation, multi-agent framework, device optimization, LLM fine-tuning, DTCO]
  - **authors:** Guangxi Fan, Tianliang Ma, Xuguang Sun, Xun Wang, Kain Lu Low, Leilai Shao
  - **institution:** Shanghai Jiao Tong University, Xi’an Jiaotong–Liverpool University
  - **link:** https://arxiv.org/pdf/2512.23742
  - **contributions:** 1. Construction of an open-source, expert-curated TCAD dataset and fine-tuning of a domain-specific LLM for TCAD code generation. 2. Proposal of AgenticTCAD, a natural language-driven multi-agent framework for end-to-end automated device design and optimization. 3. Demonstration of the framework's efficiency, achieving target device specifications in 4.2 hours compared to 7.1 days for human experts.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9454cdfb5c93c8b3f9587f99a9e8982d695a9783f118909a0fd90f5e347f512e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of generating valid TCAD simulation code due to a lack of open-source data. It proposes AgenticTCAD, a multi-agent LLM framework that automates device design and optimization from natural language. The system was validated on a 2 nm nanosheet FET design, achieving target specifications significantly faster than human experts.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("AgenticTCAD: LLM多智能体框架 / AgenticTCAD: LLM-based Multi-Agent Framework") --> Problem("TCAD代码生成资源稀缺 / Scarcity of TCAD Code Generation Resources")
        Root --> Method("构建数据集与多智能体框架 / Dataset Construction & Multi-Agent Framework")
        Root --> Results("4.2小时达到IRDS规格 / Achieves IRDS Specs in 4.2 Hours")
    ```

- **[arXiv260101] A Comprehensive Study of Deep Learning Model Fixing Approaches**
  - **tags:** [se], [software testing and debugging], [deep learning model fixing, empirical study, robustness, fairness, backward compatibility]
  - **authors:** Hanmo You, Zan Wang, Zishuo Dong, Luanqi Mo, Jianjun Zhao, Junjie Chen
  - **institution:** Tianjin University, Kyushu University
  - **link:** https://arxiv.org/pdf/2512.23745
  - **contributions:** 1. Conducted a large-scale empirical study evaluating 16 state-of-the-art DL model fixing approaches across model-level, layer-level, and neuron-level categories. 2. Comprehensively assessed the approaches not only on fixing effectiveness but also on their impact on critical properties like robustness, fairness, and backward compatibility. 3. Provided key findings and insights for industry and academia, such as model-level approaches having superior fixing effectiveness and the trade-off between fixing performance and maintaining other model properties.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2da70efdc2c67bda59610794db06383b27cdc3ff0d3c9ab3e06c8ec8a0fac3a1_w640_q70.webp
  - **Simple LLM Summary:** This paper conducts a comprehensive empirical study on 16 deep learning model fixing approaches. It evaluates their effectiveness and impact on properties like robustness and fairness, finding that model-level approaches are most effective but no single approach excels in all aspects. The study concludes that future research should focus on mitigating the side effects of model fixing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Comprehensive Study of Deep Learning Model Fixing Approaches] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[DL模型存在故障，可能导致严重后果/DL models have faults causing severe consequences]
        C --> C1[对16种最新模型修复方法进行大规模实证研究/Large-scale empirical study on 16 SOTA model fixing approaches]
        C --> C2[评估修复效果及对鲁棒性、公平性等属性的影响/Evaluate fixing effectiveness and impact on robustness, fairness, etc.]
        D --> D1[模型级方法修复效果最佳/Model-level approaches have superior fixing effectiveness]
        D --> D2[没有方法能在所有属性上表现最佳/No single approach performs best on all properties]
    ```

- **[arXiv260101] State-of-the-art Small Language Coder Model: Mify-Coder**
  - **tags:** [mlsys], [llm training], [compute-optimal training, CPT-SFT, synthetic data generation, model quantization, quality filtering]
  - **authors:** Abhinav Parmar, Abhisek Panigrahi, Abhishek Kumar Dwivedi, Abhishek Bhattacharya, Adarsh Ramachandra, Aditya Choudhary, Aditya Garg, Aditya Raj, Alankrit Bhatt, Alpesh Yadav, Anant Vishnu, Ananthu Pillai, Ankush Kumar, Aryan Patnaik, Aswatha Narayanan S, Avanish Raj Singh, Bhavya Shree Gadda, Brijesh Pankajbhai Kachhadiya, Buggala Jahnavi, Chidurala Nithin Krishna, Chintan Shah, Chunduru Akshaya, Debarshi Banerjee, Debrup Dey, Deepa R., Deepika B G, Faiz ur Rahman, Gagan Gayari, Gudhi Jagadeesh Kumar Naidu, Gursimar Singh, Harshal Tyagi, Harshini K, James Mani Vathalloor, Jayarama Nettar, Jayashree Gajjam, Joe Walter Sugil George, Kamalakara Sri Krishna Tadepalli, Kamalkumar Rathinasamy, Karan Chaurasia, Karthikeyan S, Kashish Arora, Kaushal Desai, Khushboo Buwade, Kiran Manjrekar, Malikireddy Venkata Sai Likhitha, Manjunath A, Mitali Mahavir Bedmutha, Mohammed Rafee Tarafdar, Nikhil Tiwari, Nikitha K Gigi, Pavan Ravikumar, Pendyala Swarnanjali, Piyush Anand, Prakash Chandrasekar, Prasanna Bhalchandra Gawade, Prasanth Sivan, Preeti Khurana, Priyanshi Babbar, Rajab Ali Mondal, Rajesh Kumar Vissapragada, Rajeshwari Ganesan, Rajeswari Koppisetti, Ramjee R., Ramkumar Thiruppathisamy, Rani G. S., S Reka, Samarth Gupta, Sandeep Reddy Kothakota, Sarathy K, Sathyanarayana Sampath Kumar, Saurabh Kumar, Shashank Khasare, Shenbaga Devi Venkatesh Kumar, Shiva Rama Krishna Parvatham, Shoeb Shaikh, Shrishanmathi A, Shubham Pathak, Sree Samhita Koppaka, Sreenivasa Raghavan K S, Sreeram Venkatasubramanian, Suprabha Desai Bojja, Swetha R, Syed Ahmed, Chinmai Harshitha Thota, Tushar Yadav, Veeravelly Kusumitha, V V S S Prasanth Patnaik, Vidya Sri Sesetti, Vijayakeerthi K, Vikram Raj Bakshi, Vinay K K, Vinoth Kumar Loganathan, Vipin Tiwari, Vivek Kumar Shrivastav, V Venkata Sri Datta Charan, Wasim Akhtar Khan
  - **institution:** Infosys AI Research
  - **link:** https://arxiv.org/pdf/2512.23747
  - **contributions:** 1. Introduced Mify-Coder, a 2.5B-parameter code model trained with a compute-optimal strategy on 4.2T tokens, demonstrating that compact models can match frontier-grade performance. 2. Developed a training pipeline combining high-quality curated data with agentically generated synthetic data, refined using enterprise-grade evaluations and LLM-based quality filtering for high data density. 3. Showed that disciplined exploration of training objectives and data mixtures within a single continuous trajectory enables competitive accuracy, efficiency, and safety, with quantized variants enabling deployment on standard hardware.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13c8af9d7668bbc4ac7ae9ad0ed379feb93f982a5fecdc8491169bd4d6c33d30_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high computational cost of large code models by proposing Mify-Coder, a compact 2.5B-parameter model trained using a compute-optimal strategy that integrates curated and synthetic data with quality filtering. It demonstrates that this approach allows a small model to achieve performance comparable to much larger models on coding benchmarks while maintaining safety and enabling efficient desktop deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Mify-Coder] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[大模型成本高/High cost of large code models]
        C --> C1[计算最优训练/Compute-optimal training]
        C --> C2[合成数据生成/Synthetic data generation]
        C --> C3[质量过滤/Quality filtering]
        D --> D1[性能可比/Competitive performance]
        D --> D2[高效部署/Efficient deployment]
    ```

- **[arXiv260101] Hybrid-Code: A Privacy-Preserving, Redundant Multi-Agent Framework for Reliable Local Clinical Coding**
  - **tags:** [mlsys], [agent system], [neuro-symbolic AI, multi-agent framework, local inference, hallucination detection, deterministic fallback]
  - **authors:** Yunguo Yu
  - **institution:** Zyter|TruCare
  - **link:** https://arxiv.org/pdf/2512.23743
  - **contributions:** 1. A hybrid neuro-symbolic multi-agent framework (Hybrid-Code) for reliable, on-premise clinical coding that combines an LLM-based Coder with a deterministic fallback and a symbolic Auditor for verification. 2. A privacy-preserving architecture ensuring no patient data leaves the hospital firewall, addressing critical deployment barriers in healthcare. 3. Demonstration that system reliability through architectural redundancy (achieving 0% hallucinations within the knowledge base) is more valuable than pure model performance for production healthcare AI.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b1a7891d43346fbec0638fdd7970002ba8ac5fe529a855a4c41f35f8cc8ad1e_w640_q70.webp
  - **Simple LLM Summary:** The paper introduces Hybrid-Code, a framework for automated clinical coding that runs locally to preserve privacy. It uses a two-agent system where a Coder attempts semantic reasoning with a local LLM but falls back to keyword matching, and an Auditor verifies codes against a knowledge base to prevent hallucinations. The key conclusion is that this redundant, hybrid approach ensures production reliability where failures are unacceptable, even with a moderate coverage rate.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Hybrid-Code / Hybrid-Code] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[云LLM存在隐私与延迟风险 / Cloud LLMs pose privacy & latency risks]
        C --> C1[混合神经符号多智能体框架 / Hybrid Neuro-Symbolic Multi-Agent Framework]
        C1 --> C2[编码器: LLM推理 + 确定性回退 / Coder: LLM + Deterministic Fallback]
        C1 --> C3[审计器: 基于知识的验证 / Auditor: Knowledge-Based Verification]
        D --> D1[0% 知识库内幻觉 / 0% Hallucination within KB]
        D --> D2[34.11% 覆盖率 / 34.11% Coverage]
        D --> D3[无数据离开防火墙 / No Data Leaves Firewall]
    ```

- **[arXiv260101] DEFT: Differentiable Automatic Test Pattern Generation**
  - **tags:** [mlsys], [gpu kernels], [ATPG, differentiable programming, gradient-based optimization, hard-to-detect faults, CUDA kernel]
  - **authors:** Wei Li, Yan Zou, Yixin Liang, José Moura, Shawn Blanton
  - **institution:** Carnegie Mellon University
  - **link:** https://arxiv.org/pdf/2512.23746
  - **contributions:** 1. Reformulates the discrete ATPG problem as a continuous optimization task via a mathematically grounded reparameterization that aligns the continuous objective with discrete fault-detection semantics. 2. Introduces engineering innovations for scalability, including a custom CUDA kernel for efficient forward-backward propagation and gradient normalization to mitigate vanishing gradients. 3. Demonstrates significant performance improvements over a commercial tool, including higher HTD fault detection and support for partial assignment pattern generation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8455ae68cc8632f976be48293e15e901ab95e50d871c8ed7a4a7ad33fbd148fb_w640_q70.webp
  - **Simple LLM Summary:** This paper presents DEFT, a new ATPG approach that reformulates the discrete test pattern generation problem as a continuous, gradient-based optimization task to better target hard-to-detect faults. The method introduces a novel reparameterization to align continuous and discrete semantics and uses custom CUDA kernels for scalability. Results show DEFT significantly improves fault detection rates compared to a leading commercial tool under the same pattern budget.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[DEFT: Differentiable Automatic Test Pattern Generation] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Modern IC complexity leads to pattern growth, dominated by hard-to-detect faults.] --> P1[传统方法局限/Limitations of traditional heuristic and SAT-based ATPG.]
        Method[主要方法/Method: Reformulates discrete ATPG as continuous optimization.] --> M1[关键创新/Key Innovation: Mathematically grounded reparameterization aligns continuous objective with discrete semantics.]
        Method --> M2[工程实现/Engineering: Custom CUDA kernel for efficiency, gradient normalization for stability.]
        Results[关键结果/Results: Compared to a leading commercial tool.] --> R1[性能提升/Performance: Improves HTD fault detection by 21.1% and 48.9% on average.]
        Results --> R2[实用特性/Practical: Supports partial assignment, producing patterns with 19.3% fewer bits and 35% more fault detection.]
    ```

- **[arXiv260101] Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations**
  - **tags:** [ai], [algorithmic fairness], [discrimination clustering, individual fairness, hybrid verification, SMT solver, MILP solver]
  - **authors:** Ranit Debnath Akash, Ashish Kumar, Verya Monjezi, Ashutosh Trivedi, Gang, Saeid Tizpaz-Niari
  - **institution:** University of Illinois Chicago, University of Colorado Boulder, Pennsylvania State University
  - **link:** https://arxiv.org/pdf/2512.23769
  - **contributions:** 1. Introduced the concept of "discrimination clustering" as a generalization of individual fairness to uncover systematic bias patterns. 2. Proposed HyFair, a hybrid technique combining formal symbolic analysis (SMT/MILP) and randomized search for both certification and violation discovery. 3. Developed a novel explanation method to generate interpretable, decision-tree-style artifacts for inputs exhibiting high discrimination.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05da1223f6a1c9a93634f021d221ac5175d00dee272ded0b8782834941db9c55_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a limitation in individual fairness, which only detects isolated unfairness, and proposes the concept of "discrimination clustering" to uncover systematic bias patterns. It introduces HyFair, a hybrid method combining formal verification and randomized search to detect these clusters and generate explanations. Experiments show HyFair outperforms existing fairness verification and explanation methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Uncovering Discrimination Clusters") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("个体公平性检查的局限性/Limitations of individual fairness checks")
        P1 --> P2("无法捕捉系统性歧视模式/Fails to capture systematic bias patterns")
        Method --> M1("提出歧视聚类概念/Propose discrimination clustering concept")
        Method --> M2("开发HyFair混合技术/Develop HyFair hybrid technique")
        M2 --> M3("结合形式分析与随机搜索/Combine formal analysis & randomized search")
        Results --> R1("优于现有方法/Outperforms state-of-the-art methods")
        Results --> R2("揭示系统性偏差/Reveals substantial discrimination clustering")
        Results --> R3("提供可解释的说明/Provides intuitive explanations")
    ```

- **[arXiv260101] Test Case Specification Techniques and System Testing Tools in the Automotive Industry: A Review**
  - **tags:** [se], [system testing], [test case specification, requirements traceability, model-based testing, toolchain fragmentation, systematic literature review]
  - **authors:** Denesa Zyberaj, Pascal Hirmer, Marco Aiello, Stefan Wagner
  - **institution:** Mercedes-Benz AG, University of Stuttgart, Technical University of Munich
  - **link:** https://arxiv.org/pdf/2512.23780
  - **contributions:** 1. A systematic synthesis of nine recurring challenge areas in automotive system testing, such as requirements quality and toolchain fragmentation. 2. A curated catalog mapping challenges to test case specification techniques and testing tools, evaluated for suitability. 3. A prioritized criteria catalog with actionable recommendations like model-based planning and interoperable toolchains to guide future testing frameworks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/20173a3d224359e295ca69d26827bd8256a500fb0b73b4c79340bacf78548a85_w640_q70.webp
  - **Simple LLM Summary:** This paper reviews test case specification techniques and system testing tools in the automotive industry, identifying key challenges through a systematic literature review and industry experience. It maps these challenges to existing techniques and tools, evaluating their suitability. The main conclusion is a curated catalog and prioritized criteria to support systematic technique/tool selection and inform future testing improvements.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Test Case Specification Techniques and System Testing Tools in the Automotive Industry: A Review<br>汽车行业测试用例规范技术与系统测试工具：综述"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Shift to software-centric development increases complexity and strains testing; lacks coherent methodology<br>软件中心开发转型增加复杂性，测试能力紧张；缺乏连贯的方法论"] --> P1["挑战/Challenges<br>Toolchain fragmentation, requirements quality<br>工具链碎片化，需求质量"]
        Method["主要方法/Method<br>Systematic Literature Review (SLR) and industry experience<br>系统文献综述与行业经验"] --> M1["映射与评估/Mapping & Evaluation<br>Map challenges to techniques/tools using PRISMA<br>使用PRISMA将挑战映射到技术与工具"]
        Results["关键结果/Results<br>Curated catalog and prioritized criteria catalog<br>精选目录与优先级标准目录"] --> R1["建议/Recommendations<br>Model-based planning, interoperable toolchains, targeted AI<br>基于模型的规划，可互操作工具链，针对性AI"]
    ```

- **[arXiv260101] A Systematic Mapping on Software Fairness: Focus, Trends and Industrial Context**
  - **tags:** [se], [software fairness], [systematic mapping, fairness, software engineering, technology readiness level, group fairness]
  - **authors:** Kessia Nepomuceno, Fabio Petrillo
  - **institution:** École de Technologie Supérieure
  - **link:** https://arxiv.org/pdf/2512.23782
  - **contributions:** 1. A systematic literature mapping of 95 studies to categorize advancements in software fairness solutions. 2. A novel classification framework for analyzing software fairness research from the perspectives of trends, focus, and industrial viability. 3. An analysis revealing the field's focus on post-processing methods and group fairness, with limited industry collaboration and low-to-medium TRL, highlighting gaps for future work.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba1e54194de977ce396b8c19de44fec12f293e42ef1d03cfcc83d187b2d3da83_w640_q70.webp
  - **Simple LLM Summary:** This paper conducts a systematic mapping study to analyze research on fairness in software systems. It develops a classification framework applied to 95 studies, finding that current work is heavily algorithmic, focused on post-processing and group fairness, and lacks industrial collaboration and high readiness levels. The conclusion calls for integrating fairness across the entire software development lifecycle and increasing academia-industry partnerships.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[系统性映射研究:软件公平性<br/>A Systematic Mapping on Software Fairness] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br/>缺乏对软件公平性解决方案的全面理解<br/>Lack of comprehensive understanding of fairness solutions] --> Problem_Sub[挑战/Challenge<br/>研究分散，工业应用不明确<br/>Fragmented research, unclear industrial viability]
        Method[主要方法/Method<br/>系统性文献映射<br/>Systematic Literature Mapping] --> Method_Sub[应用分类框架分析95项研究<br/>Apply classification framework to 95 studies]
        Results[关键结果/Results<br/>研究发现/Findings] --> Results_Sub1[研究趋势/Research Trends<br/>扩展中但集中于算法<br/>Expanding but focused on algorithms]
        Results --> Results_Sub2[研究焦点/Research Focus<br/>后处理和群体公平性<br/>Post-processing & group fairness]
        Results --> Results_Sub3[工业背景/Industrial Context<br/>学术主导，TRL低至中<br/>Academic-led, low-to-medium TRL]
    ```

- **[arXiv260101] From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering**
  - **tags:** [se], [Human-AI Collaboration], [AI Agent Evaluation, Behavioral Taxonomy, Context-Adaptive Behavior Framework]
  - **authors:** Tao Dong, Harini Sampath, Ja Young Lee, Sherry Y. Shi, Andrew Macvean
  - **institution:** Google LLC
  - **link:** https://arxiv.org/pdf/2512.23844
  - **contributions:** 1. A foundational taxonomy of desirable AI agent behaviors for enterprise software engineering, derived from an analysis of 91 sets of user-defined agent rules. 2. The Context-Adaptive Behavior (CAB) Framework, which models how behavioral expectations shift based on context. 3. An empirical derivation of two key axes (Time Horizon and Type of Work) that drive behavioral expectation shifts in the CAB Framework.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7ee9d0c9d0b72de4dc6af2921706818c987d2f7c644977698965be6b535d20c_w640_q70.webp
  - **Simple LLM Summary:** This paper argues that current AI evaluation benchmarks focus too narrowly on code correctness and fail to assess the collaborative behaviors needed for AI to be an effective partner in software engineering. To address this, the authors propose a taxonomy of desirable agent behaviors and a Context-Adaptive Behavior (CAB) Framework that models how these expectations change with context. These contributions provide a human-centered foundation for evaluating and designing collaborative AI agents.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering<br/>从正确性到协作：评估软件工程中AI智能体行为的人本框架"] --> Problem
        Root --> Method
        Root --> Results
    
        Problem["核心问题/Problem<br/>Current benchmarks fail to capture collaborative AI agent behavior.<br/>当前基准测试无法评估AI智能体的协作行为。"]
        Method["主要方法/Method<br/>1. Taxonomy of agent behaviors.<br/>智能体行为分类法。<br/>2. Context-Adaptive Behavior (CAB) Framework.<br/>上下文自适应行为框架。"]
        Results["关键结果/Results<br/>Provides a human-centered foundation for evaluating collaborative AI agents.<br/>为评估协作型AI智能体提供了人本基础。"]
    ```

- **[arXiv260101] From Illusion to Insight: Change-Aware File-Level Software Defect Prediction Using Agentic AI**
  - **tags:** [se], [software defect prediction], [change-aware prediction, multi-agent debate, label-persistence bias]
  - **authors:** Mohsen Hesamolhokama, Behnam Rohani, Amirahmad Shafiee, MohammadAmin Fazli, Jafar Habibi
  - **institution:** Sharif University of Technology
  - **link:** https://arxiv.org/pdf/2512.23875
  - **code:** https://github.com/mhhokama/from-illusion-to-insight
  - **contributions:** 1. Reformulates Software Defect Prediction (SDP) as a change-aware prediction task to address the label-persistence bias in traditional evaluations. 2. Proposes a novel LLM-driven, change-aware, multi-agent debate framework for reasoning over code changes. 3. Demonstrates that traditional models have inflated performance metrics and fail on critical defect transitions, while the proposed framework improves sensitivity to defect introductions.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15d54d8c8ea7b2310c0741d517e512a7ded7a9f65f2adf65500f52454a05c0da_w640_q70.webp
  - **Simple LLM Summary:** The paper identifies a fundamental flaw in traditional file-level software defect prediction, where models achieve illusory accuracy due to label-persistence bias across software versions. To address this, the authors propose a change-aware prediction task and a novel LLM-driven multi-agent debate framework that reasons over code changes. Experiments show this approach yields more balanced performance and significantly improves sensitivity to defect introductions compared to traditional models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[From Illusion to Insight: Change-Aware File-Level Software Defect Prediction Using Agentic AI] --> B[核心问题/Problem: 传统缺陷预测存在标签持续性偏见/Label-Persistence Bias in Traditional SDP]
        A --> C[主要方法/Method: 变更感知的多智能体辩论框架/Change-Aware Multi-Agent Debate Framework]
        A --> D[关键结果/Results: 提升对缺陷引入的敏感性/Improved Sensitivity to Defect Introductions]
    ```

- **[arXiv260101] Coding With AI: From a Reflection on Industrial Practices to Future Computer Science and Software Engineering Education**
  - **tags:** [se], [AI-assisted Software Engineering], [vibe coding, agentic coding, LLM-based coding, code review, curricular shift]
  - **authors:** Hung-Fu Chang, MohammadShokrolah Shirazi, Lizhou Cao, Supannika Koolmanojwong Mobasser
  - **institution:** University of Indianapolis, Marian University, University of Maryland Eastern Shore, The Boehm Center for Systems and Software Engineering
  - **link:** https://arxiv.org/pdf/2512.23982
  - **contributions:** 1. Provides an industry-grounded investigation of LLM coding practices (vibe, AI-assisted, agentic coding) and their impact on professional workflows, based on qualitative analysis of practitioner reflections. 2. Identifies key risks and concerns associated with AI-based coding, including shifts in development bottlenecks to code review, code quality issues, security vulnerabilities, and skill erosion. 3. Proposes implications and guidance for computer science and software engineering education, advocating for curricular shifts toward problem-solving, architectural thinking, and early integration of LLM tools.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d32f497e3b36008891d37440a49e031ae3f31d7dcba8585c229352e091d83a3a_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how large language models (LLMs) are used in professional software development by qualitatively analyzing 57 YouTube videos from practitioners. The study identifies new coding paradigms, productivity gains, and associated risks like quality and security concerns. It concludes by discussing the need for educational reforms in computer science to align with these evolving industrial practices.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Coding With AI: From Industrial Practices to Future Education") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("工业实践中LLM编码工具的使用与风险未充分探索/LLM coding use & risks in industry underexplored")
        Method --> M1("对57个YouTube视频进行定性分析/Qualitative analysis of 57 YouTube videos")
        Results --> R1("定义AI编码实践，发现生产力提升与风险/Defines AI coding practices, finds productivity gains & risks")
        Results --> R2("提出计算机科学教育的课程改革建议/Proposes curricular shifts for CS education")
    ```

- **[arXiv260101] Developing controlled natural language for formal specification patterns using AI assistants**
  - **tags:** [se], [requirements engineering], [controlled natural language, formal specification patterns, AI assistant, temporal requirements, syntax formalization]
  - **authors:** Natalia Garanina, Vladimir Zyubin, Igor Anureev
  - **institution:** Institute of Automation and Electrometry, Siberian Branch of the Russian Academy of Sciences
  - **link:** https://arxiv.org/pdf/2512.24159
  - **contributions:** 1. A novel three-stage method for systematically constructing a Controlled Natural Language (CNL) for requirements using an AI assistant. 2. A prompt engineering approach that leverages a generalized template and formal semantics to generate a diverse corpus of natural language patterns. 3. Formalization of CNL syntax based on grammatical analysis of AI-generated patterns, specifically validated for event-driven temporal requirements.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16dd04888cb9a22a839acc0700d35470498034dd8676cff5e34d6cb903fd6ab9_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a method to systematically develop a controlled natural language (CNL) for formal requirements specification using an AI assistant. The method involves creating a generalized pattern, using an AI to generate a corpus of natural language variants, and then formalizing the CNL syntax from the results. The approach was successfully tested for specifying event-driven temporal requirements, producing a language with built-in formal semantics.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Developing controlled natural language for formal specification patterns using AI assistants] --> B(核心问题/Problem: How to systematically construct a Controlled Natural Language (CNL) for formal requirements specification?);
        A --> C(主要方法/Method: Three-stage method using AI assistant: 1. Compile generalized pattern, 2. Generate corpus via prompt, 3. Formalize syntax from grammar analysis.);
        A --> D(关键结果/Results: Method successfully tested for event-driven temporal requirements, yielding a CNL with formal semantics by design.);
    ```

- **[arXiv260101] CoHalLo: code hallucination localization via probing hidden layer vector**
  - **tags:** [se], [software testing and debugging], [hallucination localization, probing technique, abstract syntax tree, hidden representation]
  - **authors:** Nan Jia, Wangchao Sang, Pengfei Lin, Xiangping Chen, Yuan Huang, Yi Liu, Mingliang Li
  - **institution:** Hebei GEO University, Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.24183
  - **contributions:** 1. Proposes CoHalLo, a novel method for fine-grained, line-level code hallucination localization by probing hidden-layer vectors. 2. Introduces a probe network that projects latent vectors to a syntactic subspace and reconstructs a predicted AST for comparison with the original AST. 3. Creates and evaluates the method on a manually collected dataset of code hallucinations, demonstrating superior performance over baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9187bf780c0a716f22d40926c01fbd776d8da240f5d5322681106818a96f4b81_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces CoHalLo, a method for localizing hallucinations in AI-generated code to specific lines. It works by fine-tuning a detection model, probing its hidden vectors to reconstruct a predicted abstract syntax tree, and comparing it with the original AST to identify hallucinated syntactic structures. The experimental results show that CoHalLo outperforms baseline methods in localization accuracy.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CoHalLo: 代码幻觉定位 / Code Hallucination Localization] --> B[核心问题: 粗粒度检测缺乏细粒度定位 / Problem: Coarse-grained detection lacks fine-grained localization]
        A --> C[主要方法: 探测隐藏层向量与AST比较 / Method: Probing hidden vectors & AST comparison]
        A --> D[关键结果: 性能优于基线方法 / Results: Outperforms baseline methods]
        C --> C1[微调检测模型 / Fine-tune detection model]
        C --> C2[设计探针网络重建P-AST / Design probe network to reconstruct P-AST]
        C --> C3[比较P-AST与O-AST定位幻觉行 / Compare P-AST & O-AST to locate hallucinated lines]
    ```

- **[arXiv260101] Fast and Realistic Automated Scenario Simulations and Reporting for an Autonomous Racing Stack**
  - **tags:** [mlsys], [fault-tolerance], [Functional Mockup Unit (FMU), fault injection, Continuous Integration/Continuous Delivery (CI/CD)]
  - **authors:** Giovanni Lambertini, Matteo Pini, Eugenio Mascaro, Francesco Moretti, Ayoub Raji, Marko Bertogna
  - **institution:** University of Modena and Reggio Emilia
  - **link:** https://arxiv.org/pdf/2512.24402
  - **contributions:** 1. An automated simulation and reporting pipeline for an autonomous racing stack that can execute up to three times faster than real-time, locally or on GitHub for CI/CD. 2. A fault injection module capable of introducing sensor delays, perturbations, and modifying outputs of any node in the software stack. 3. A design for an automated reporting process aimed at maximizing the effectiveness of simulation analysis.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d172287ab1ffde29e52c3f7cde1a986f7a5d73ac371395320ced490d39f5dac_w640_q70.webp
  - **Simple LLM Summary:** This paper presents an automated simulation and reporting pipeline for validating an autonomous racing stack. The method uses a high-fidelity vehicle model as a Functional Mockup Unit (FMU) and includes a fault injection module to test system robustness. The pipeline enables fast, realistic scenario testing and automated reporting, which is crucial for efficiently validating critical autonomous driving functions like high-speed overtaking.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Fast and Realistic Automated Scenario Simulations and Reporting for an Autonomous Racing Stack"] --> Problem["核心问题/Problem: Need for efficient validation of autonomous racing stack modules, especially for high-speed maneuvers and localization."]
        Root --> Method["主要方法/Method: Automated simulation pipeline using high-fidelity FMU model, scenario initialization, and fault injection."]
        Root --> Results["关键结果/Results: Pipeline executes up to 3x faster than real-time, supports CI/CD, and includes automated reporting."]
    ```

- **[arXiv260101] SourceBroken: A large-scale analysis on the (un)reliability of SourceRank in the PyPI ecosystem**
  - **tags:** [sec], [software supply chain security], [SourceRank, PyPI, evasion attacks, URL confusion, threat model]
  - **authors:** Biagio Montaruli, Serena Elisa Ponta, Luca Compagna, Davide Balzarotti
  - **institution:** EURECOM, SAP, Endor Labs
  - **link:** https://arxiv.org/pdf/2512.24400
  - **contributions:** 1. Proposes a threat model for SourceRank, identifying evasion approaches for each of its 18 metrics, including the novel URL confusion technique. 2. Conducts a large-scale empirical analysis revealing that SourceRank distributions of benign and malicious packages significantly overlap in real-world PyPI data, limiting its reliability. 3. Quantifies the prevalence and impact of URL confusion as an emerging attack vector, showing its use alongside other techniques to inflate malicious package scores.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937ebee908f3f922e7d4e234d04ec0945535d6e38e06052bb2dad84c98f5f6b1_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the reliability of the SourceRank scoring system in the PyPI ecosystem against evasion attacks. It proposes a threat model and conducts a large-scale empirical study, finding that SourceRank cannot reliably distinguish benign from malicious packages in real-world scenarios due to overlapping score distributions and vulnerabilities like URL confusion.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("SourceBroken: SourceRank可靠性分析 / SourceBroken: SourceRank Reliability Analysis") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("SourceRank抗规避攻击的可靠性未知 / SourceRank's reliability against evasion attacks is unknown")
        Method --> M1("提出威胁模型 / Propose threat model")
        Method --> M2("大规模实证分析 / Large-scale empirical analysis")
        M1 --> M1a("识别URL混淆等技术 / Identify techniques like URL confusion")
        M2 --> M2a("分析恶意/良性包分布 / Analyze malicious/benign package distributions")
        Results --> R1("真实世界分数分布重叠 / Real-world score distributions overlap")
        Results --> R2("URL混淆攻击增加 / URL confusion attack is increasing")
        Results --> R3("SourceRank不可靠 / SourceRank is unreliable")
    ```

- **[arXiv260101] "Game Changer" or "Overenthusiastic Drunk Acquaintance"? Generative AI Use by Blind and Low Vision Software Professionals in the Workplace**
  - **tags:** [se], [accessibility], [generative AI, qualitative study, workplace accessibility, blind and low vision, software development]
  - **authors:** Yoonha Cha, Victoria Jackson, Lauren Shu, Stacy Branham, André van der Hoek
  - **institution:** University of California, Irvine, University of Southampton
  - **link:** https://arxiv.org/pdf/2512.24462
  - **contributions:** 1. Conducted the first qualitative study (39 interviews) exploring the workplace use of Generative AI by blind and low vision software professionals (BLVSPs). 2. Identified a dual impact of GenAI for BLVSPs, highlighting benefits like increased productivity and accessibility alongside unique, heightened risks like vulnerability to AI hallucinations. 3. Proposed the conceptual framework of "higher-risks and higher-returns" that BLVSPs must navigate when deciding to adopt GenAI tools in their work.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7281d6de4b659bbfdfc41aa14ddcbd59718a69ad03e270835217218242fcd1f5_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how blind and low vision software professionals (BLVSPs) use Generative AI in the workplace through 39 interviews. It finds that while GenAI offers significant benefits for productivity and accessibility, BLVSPs face unique costs, such as a greater susceptibility to AI hallucinations and restrictive organizational policies. The study concludes that BLVSPs experience a "higher-risk, higher-return" dynamic with GenAI, requiring careful consideration for its adoption.
  - **Mindmap:**

    ```mermaid
    graph TB
        A["“Game Changer" or "Overenthusiastic Drunk Acquaintance"?<br/>Generative AI Use by Blind and Low Vision Software Professionals<br/>盲/低视力软件专业人员的生成式AI使用"] --> B["核心问题/Problem<br/>BLVSPs face accessibility challenges; GenAI's impact on them is unknown.<br/>BLVSPs面临可访问性挑战；GenAI对他们的影响未知。"]
        A --> C["主要方法/Method<br/>Qualitative study with 39 semi-structured interviews.<br/>对39人进行半结构化访谈的定性研究。"]
        A --> D["关键结果/Results<br/>Benefits (productivity, accessibility) but higher risks (hallucinations, policies).<br/>有益（生产力、可访问性）但风险更高（幻觉、政策）。"]
    ```

- **[arXiv260101] A Magnified View into Heterogeneous-ISA Thread Migration Performance without State Transformation**
  - **tags:** [sys], [compiler & ir], [heterogeneous-ISA, thread migration, stack layout, LLVM, ABI]
  - **authors:** Nikolaos Mavrogeorgis, Christos Vasiladiotis, Pei Mu, Amir Khordadi, Björn Franke, Antonio Barbalace
  - **institution:** University of Edinburgh
  - **link:** https://arxiv.org/pdf/2512.24530
  - **contributions:** 1. Design and development of Unifico, a multi-ISA compiler that generates binaries with an identical stack layout across ISAs to eliminate runtime stack transformation overhead. 2. Implementation of a uniform ABI and virtual address space across ISAs within the compiler backend, built on the LLVM infrastructure for x86-64 and ARMv8. 3. Demonstrated minimal performance overhead (avg. &lt;6-10%) and a significant reduction in binary size overhead (~10% vs. ~200%) compared to the state-of-the-art Popcorn compiler.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7045223acda8a4e1008ca9cb0375719ce56e3d4b17ad8db282fd7af7ae7f0167_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the high overhead of runtime stack transformation in heterogeneous-ISA systems by introducing Unifico, a compiler that generates binaries with a uniform stack layout across architectures. This eliminates migration-time state conversion, resulting in minimal execution overhead and drastically reduced binary size compared to prior work. The evaluation on NAS benchmarks shows the approach is effective for enabling efficient thread migration between x86-64 and ARMv8 processors.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Magnified View into Heterogeneous-ISA Thread Migration Performance without State Transformation<br/>异构ISA线程迁移性能的放大视图（无需状态转换）"]
        Root --> Problem["核心问题/Problem<br/>Heterogeneous-ISA migration requires expensive runtime stack transformation<br/>异构ISA迁移需要昂贵的运行时栈转换"]
        Root --> Method["主要方法/Method<br/>Unifico compiler: generates binaries with identical stack layout across ISAs<br/>Unifico编译器：生成跨ISA栈布局一致的二进制文件"]
        Root --> Results["关键结果/Results<br/>~6-10% perf overhead, ~10% binary size overhead (vs. ~200%)<br/>~6-10%性能开销，~10%二进制大小开销（对比~200%）"]
    ```

- **[arXiv260101] Localized Calibrated Uncertainty in Code Language Models**
  - **tags:** [se], [code generation], [calibrated uncertainty, minimal intent aligning patches, white-box probing, Brier Skill Score, AI oversight]
  - **authors:** David Gros, Prem Devanbu
  - **institution:** University of California, Davis
  - **link:** https://arxiv.org/pdf/2512.24560
  - **contributions:** 1. Creation of a dataset of "Minimal Intent Aligning Patches" for LLM-generated code repairs. 2. Proposal and evaluation of techniques (white-box probing, black-box reflective, self-consistency) for assigning well-calibrated, localized uncertainty to code segments. 3. Demonstration that a small supervisor probe can effectively estimate edit likelihood on code from much larger models and shows preliminary signs of generalization to natural language errors.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e04860e78fa5e50071d58627500e751c212bb40e58f4d01943c9ad0eda5c5a9_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of LLM-generated code potentially deviating from user intent by proposing methods to localize where edits are likely needed. It introduces a dataset of minimal repair patches and compares techniques for assigning calibrated probabilities to code lines. The key finding is that a small white-box probing model can effectively estimate which lines will be edited, achieving good calibration and a Brier Skill Score of ~0.2, and shows some generalizability beyond code.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Localized Calibrated Uncertainty in Code Language Models] --> B[核心问题/Problem: LLM生成的代码可能偏离用户意图/LLM-generated code may deviate from user intent]
        A --> C[主要方法/Method: 创建最小意图对齐补丁数据集，比较白盒探测与黑盒方法/Create Minimal Intent Aligning Patches dataset, compare white-box probing vs. black-box methods]
        A --> D[关键结果/Results: 小监督模型可实现低校准误差，Brier Skill Score约0.2/Small supervisor model achieves low calibration error, Brier Skill Score ~0.2]
    ```

- **[arXiv260101] On the Effectiveness of Training Data Optimization for LLM-based Code Generation: An Empirical Study**
  - **tags:** [se], [code generation], [training data optimization, data synthesis, data refactoring, code quality, functional correctness]
  - **authors:** Shiqi Kuang, Zhao Tian, Tao Xiao, Dong Wang, Junjie Chen
  - **institution:** Tianjin University, Kyushu University
  - **link:** https://arxiv.org/pdf/2512.24570
  - **contributions:** 1. Conducts the first large-scale empirical study evaluating five training data optimization techniques and their pairwise combinations for LLM-based code generation. 2. Identifies data synthesis as the most effective technique for improving functional correctness and reducing code smells, while data refactoring, cleaning, and selection are better for code maintainability. 3. Reveals that combining data synthesis with data refactoring yields the strongest overall performance, and most combinations enhance code quality but not functional correctness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/713bceb6173afb63b2cb4d6aa4b83f1cb03830f04778d34a2b958b91647df3b2_w640_q70.webp
  - **Simple LLM Summary:** This paper systematically evaluates five training data optimization techniques and their combinations for improving LLM-based code generation. The study finds that data synthesis is best for functional correctness, while combinations like synthesis with refactoring best improve overall code quality. The work provides practical guidance for optimizing training data in code generation models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[论文标题 / Paper Title<br>On the Effectiveness of Training Data Optimization for LLM-based Code Generation] --> B
        A --> C
        A --> D
        B[核心问题 / Problem<br>训练数据优化技术的整体有效性缺乏系统评估 / Lack of systematic evaluation on training data optimization techniques] --> E
        C[主要方法 / Method<br>大规模实证研究 / Large-scale empirical study] --> F
        D[关键结果 / Results<br>数据合成最有效，组合策略提升代码质量 / Data synthesis most effective, combination strategies improve code quality] --> G
        E[评估五种技术及其组合 / Evaluate five techniques and their combinations]
        F[使用三个基准和四个大模型 / Use three benchmarks and four LLMs]
        G[数据合成+重构组合整体性能最强 / Data synthesis + refactoring achieves strongest overall performance]
    ```

- **[arXiv260101] A Tale of 1001 LoC: Potential Runtime Error-Guided Specification Synthesis for Verifying Large-Scale Programs**
  - **tags:** [se], [formal verification], [specification synthesis, deductive verification, static analysis, runtime error, large language models]
  - **authors:** Zhongyi Wang, Tengjie Lin, Mingshuai Chen, Haokun Li, Mingqi Yang, Xiao Yi, Shengchao Qin, Yixing Luo, Xiaofeng Li, Bin Gu, Liqiang Lu, Jianwei Yin
  - **institution:** Zhejiang University, Peking University, The Chinese University of Hong Kong, Xidian University, Beijing Institute of Control Engineering
  - **link:** https://arxiv.org/pdf/2512.24594
  - **contributions:** 1. A modular framework (Preguss) that synergizes static analysis and deductive verification for specification generation. 2. A potential runtime error-guided method to construct and prioritize verification units, enabling divide-and-conquer verification. 3. An LLM-aided approach for synthesizing interprocedural specifications at the unit level, overcoming long-context reasoning limitations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59ea3656fd77af57b3d01dd85b22b70b81b2bc6a890ef83bd4e98afe3dad61df_w640_q70.webp
  - **Simple LLM Summary:** This paper presents Preguss, a framework that combines static analysis and LLMs to automate the generation of formal specifications for verifying large-scale programs. It uses potential runtime errors to guide the creation of verification units and then synthesizes specifications for each unit, significantly reducing human effort. The method enables highly automated verification for programs over 1000 lines of code, reducing human verification effort by 80.6% to 88.9%.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Tale of 1001 LoC: Potential Runtime Error-Guided Specification Synthesis for Verifying Large-Scale Programs"]
        Root --> Problem["核心问题/Problem<br>LLMs struggle with automated verification of large-scale programs due to long-context reasoning and complex specification inference."]
        Root --> Method["主要方法/Method<br>Preguss framework synergizes static analysis and deductive verification via error-guided unit construction and LLM-aided specification synthesis."]
        Root --> Results["关键结果/Results<br>Enables verification of 1000+ LoC programs with 80.6%~88.9% reduction in human effort, outperforming SOTA."]
    ```

- **[arXiv260101] How Do Agentic AI Systems Address Performance Optimizations? A BERTopic-Based Analysis of Pull Requests**
  - **tags:** [se], [empirical software engineering], [BERTopic, Pull Request, Agentic AI, Performance Optimization, LLM-assisted detection]
  - **authors:** Md Nahidul Islam Opu, Shahidul Islam, Muhammad Asaduzzaman, Shaiful Chowdhury
  - **institution:** University of Manitoba, University of Windsor
  - **link:** https://arxiv.org/pdf/2512.24630
  - **contributions:** 1. Conducted an empirical study to identify 52 performance-related topics from AI-generated pull requests, categorized into 10 higher-level groups. 2. Discovered that the type of performance optimization significantly impacts pull request acceptance rates and review times. 3. Found that AI agents primarily introduce performance optimizations during the development phase rather than maintenance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/173802e86454f3282fd11ae6159e57fa8623800dae4d95e111c1a96f760c7ee7_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how AI agents address performance concerns in real-world software development by analyzing performance-related pull requests. Using LLM-assisted detection and BERTopic modeling, it categorizes optimization types and analyzes their impact on PR outcomes. The study concludes that AI agents apply optimizations across the software stack, but their effectiveness varies by optimization type and SDLC phase.
  - **Mindmap:**

    ```mermaid
    graph TB
    Root("How Do Agentic AI Systems Address Performance Optimizations? A BERTopic-Based Analysis of Pull Requests") --> Problem("核心问题/Problem: How do AI agents address performance in practice?")
    Root --> Method("主要方法/Method: LLM-assisted detection & BERTopic topic modeling")
    Root --> Results("关键结果/Results: Identified 52 topics in 10 categories; Optimization type affects PR acceptance & review time")
    ```

- **[arXiv260101] How Do Agentic AI Systems Deal With Software Energy Concerns? A Pull Request-Based Study**
  - **tags:** [se], [software energy efficiency], [AI coding agents, pull request analysis, energy optimization techniques]
  - **authors:** Tanjum Motin Mitul, Md. Masud Mazumder, Md Nahidul Islam Opu, Shaiful Chowdhury
  - **institution:** University of Manitoba
  - **link:** https://arxiv.org/pdf/2512.24636
  - **contributions:** 1. Conducted the first empirical study analyzing how AI coding agents explicitly address software energy concerns by examining agent-authored pull requests. 2. Developed a five-category taxonomy (Insight, Setup, Optimization, Trade-off, Maintenance) to classify energy-aware work performed by AI agents. 3. Identified that while AI agents employ research-aligned energy optimization techniques, related PRs have lower acceptance rates due to maintainability trade-offs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5170e1a453f7dde6a9f2f2be6b88d628eaf4de61acc3bcdb1f23cc0cce411073_w640_q70.webp
  - **Simple LLM Summary:** This study investigates how AI coding agents handle software energy concerns by analyzing 216 energy-explicit pull requests from a public dataset. Through thematic analysis, it develops a taxonomy of energy-aware work and finds that the agents' optimization techniques align with established research. The main conclusion is that while AI agents demonstrate energy awareness, optimization-related PRs are less frequently accepted due to negative impacts on code maintainability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("How Do Agentic AI Systems Deal With Software Energy Concerns? A Pull Request-Based Study") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("AI代理的能源意识不明确/Unclear energy awareness of AI agents")
        Problem --> P2("软件能源问题日益重要/Growing importance of software energy concerns")
        Method --> M1("分析AI编写的PR/Analyze agent-authored PRs")
        Method --> M2("主题分析与分类/Thematic analysis & taxonomy")
        Results --> R1("代理展现能源意识/Agents exhibit energy awareness")
        Results --> R2("优化PR接受率低/Lower acceptance of optimization PRs")
    ```

- **[arXiv260101] DynaFix: Iterative Automated Program Repair Driven by Execution-Level Dynamic Information**
  - **tags:** [se], [automated program repair], [large language models, dynamic analysis, iterative repair, execution-level information, Defects4J]
  - **authors:** Zhili Huang, Ling Xu, Chao Liu, Weifeng Sun, Xu Zhang, Yan Lei, Meng Yan, Hongyu Zhang
  - **institution:** Chongqing University
  - **link:** https://arxiv.org/pdf/2512.24635
  - **contributions:** 1. Proposes DynaFix, a novel APR method that iteratively leverages fine-grained, execution-level dynamic information (e.g., variable states, control-flow) to guide LLMs in patch generation. 2. Introduces an iterative repair loop where failed patches trigger re-execution to collect updated runtime feedback, mimicking human stepwise debugging. 3. Demonstrates significant effectiveness and efficiency improvements, repairing 186 bugs (10% more than SOTA) and reducing patch search space by 70% on Defects4J benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ca5f82c2ff7a5874dfaa7c320c9097716fe0d1514eca3eb69291b75f1a981d7_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes DynaFix, an automated program repair method that iteratively uses execution-level dynamic information (like variable states) to guide large language models in generating patches. This approach mimics human debugging by refining patches based on runtime feedback from failed attempts. Evaluation on Defects4J shows it repairs more bugs and reduces the search space more effectively than existing methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DynaFix: Iterative Automated Program Repair Driven by Execution-Level Dynamic Information] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有APR方法依赖静态分析或粗粒度反馈，难以模拟人类逐步调试/Existing APR relies on static or coarse feedback, failing to simulate stepwise debugging]
        C --> C1[迭代捕获执行级动态信息（变量状态、控制流等）指导LLM生成补丁/Iteratively captures execution-level info (variable states, control flow) to guide LLM patch generation]
        D --> D1[修复Defects4J中186个bug，性能提升10%/Repairs 186 bugs on Defects4J, 10% improvement over SOTA]
        D --> D2[将补丁搜索空间减少70%/Reduces patch search space by 70%]
    ```

- **[arXiv260101] Characterizing Bugs and Quality Attributes in Quantum Software: A Large-Scale Empirical Study**
  - **tags:** [se], [software testing and quality], [quantum software engineering, software defects, empirical study, automated testing, bug classification]
  - **authors:** Mir Mohammad Yousuf, Shabir Ahmad Sofi
  - **institution:** Department of Information Technology, National Institute of Technology Srinagar (NIT Srinagar)
  - **link:** https://arxiv.org/pdf/2512.24656
  - **contributions:** 1. Conducted the first large-scale longitudinal empirical study of bugs across 123 open-source quantum software repositories, analyzing 32,296 verified bug reports. 2. Characterized the distribution and root causes of bugs across eight functional categories (e.g., full-stack libraries, compilers) and their differential impact on classical vs. quantum-specific quality attributes. 3. Provided empirical evidence that automated testing is associated with a significant (~60%) reduction in expected defect incidence and faster issue resolution in quantum software projects.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ad642fc607a1ff35255355dbf65d2f121cde3093ee4cdca07fe0c43b749138f_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a large-scale empirical study characterizing bugs and quality attributes in quantum software. Using a mixed-method approach to analyze over 32,000 bug reports from 123 open-source repositories, it finds that defect types and impacts vary by software category and that automated testing significantly reduces defect incidence. The study concludes that the quantum software ecosystem is maturing and offers data-driven guidance for improving testing and maintainability practices.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Characterizing Bugs and Quality Attributes in Quantum Software] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[缺乏量子软件缺陷的实证证据/Lack of empirical evidence on quantum software bugs]
        C --> C1[混合方法: 仓库挖掘、静态分析、问题分类/Mixed-method: repo mining, static analysis, bug classification]
        C --> C2[分析 123 个仓库的 32,296 个缺陷报告/Analyze 32,296 bug reports from 123 repos]
        D --> D1[缺陷密度在 2017-2021 年达到峰值后下降/Defect density peaked 2017-2021 then declined]
        D --> D2[全栈库和编译器缺陷最多/Full-stack libs & compilers most defect-prone]
        D --> D3[自动化测试减少约 60% 的缺陷/Automated testing reduces defects by ~60%]
    ```

- **[arXiv260101] Feature Slice Matching for Precise Bug Detection**
  - **tags:** [se], [bug detection], [feature slice, similarity measurement, target noise mitigation, code embedding, Linux kernel]
  - **authors:** Ke Ma, Jianjun Huang, Wei You, Bin Liang, Jingzheng Wu, Yanjun Wu, Yuanjun Gong
  - **institution:** Renmin University of China, Institute of Software, Chinese Academy of Sciences, University of Trento
  - **link:** https://arxiv.org/pdf/2512.24858
  - **contributions:** 1. Proposes MATUS, a method to mitigate target noise in bug detection by extracting and matching feature slices guided by prior knowledge from buggy code. 2. Introduces an end-to-end approach that uses the buggy query to guide the slicing of target code, pinpointing the relevant criteria. 3. Demonstrates effectiveness by discovering 31 previously unknown bugs in the Linux kernel, with 11 assigned CVEs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4964f0c4a5f88dd3fe100012b4e45e6616118e0d0b933f6fdc36baab314d3dc7_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes MATUS, a method for precise bug detection by matching feature slices from buggy and target code to reduce noise. It guides target slicing using the buggy query and compares embedded slices via vector similarity. The approach successfully found 31 unknown bugs in the Linux kernel, showing its practical effectiveness.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Feature Slice Matching for Precise Bug Detection] --> B[核心问题/Problem: 目标代码中的噪声干扰相似性检测/Noise in target code impedes similarity-based bug detection]
        A --> C[主要方法/Method: 提出MATUS，利用有缺陷查询指导目标切片，进行特征嵌入与匹配/Propose MATUS, guides target slicing with buggy query, embeds and matches feature slices]
        A --> D[关键结果/Results: 在Linux内核中发现31个未知漏洞，11个获CVE编号/Spotted 31 unknown bugs in Linux kernel, 11 assigned CVEs]
    ```

- **[arXiv260101] SoK: Web3 RegTech for Cryptocurrency VASP AML/CFT Compliance**
  - **tags:** [sec], [blockchain security], [RegTech, AML/CFT, transaction graph analysis, cross-chain analytics, privacy-preserving verification]
  - **authors:** Qian'ang Mao, Jiaxin Wang, Ya Liu, Li Zhu, Jiaman Chen, Jiaqi Yan
  - **institution:** Nanjing University
  - **link:** https://arxiv.org/pdf/2512.24888
  - **contributions:** 1. Developed three taxonomies to organize the Web3 RegTech domain, including a regulatory paradigm evolution framework, a compliance protocol taxonomy, and a RegTech lifecycle framework. 2. Conducted a systematic analysis of 41 commercial platforms and 28 academic prototypes to demonstrate the novel capabilities of blockchain-native RegTech solutions. 3. Identified critical research gaps and synthesized architectural best practices for future Web3 compliance solutions that respect decentralization principles.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/436795f273ee49bee1ec9b9451624284da67c6c60b7f58ea946d5c0fd61ac8b8_w640_q70.webp
  - **Simple LLM Summary:** This paper systematically examines how blockchain-native regulatory technology (RegTech) addresses AML/CFT compliance challenges in Web3. It proposes new taxonomies and analyzes existing solutions, finding that Web3 RegTech enables novel capabilities like transaction graph analysis and cross-chain tracking but faces gaps between academic research and industry deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[SoK: Web3 RegTech for Cryptocurrency VASP AML/CFT Compliance] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[传统合规方案不适用于Web3/Traditional compliance inadequate for Web3]
        Problem --> P2[去中心化架构带来AML/CFT挑战/Decentralized architecture creates AML/CFT challenges]
        Method[主要方法/Method] --> M1[提出三个分类法/Propose three taxonomies]
        Method --> M2[分析69个平台与原型/Analyze 69 platforms & prototypes]
        Results[关键结果/Results] --> R1[Web3 RegTech实现新能力/Web3 RegTech enables novel capabilities]
        Results --> R2[揭示学术与产业间的差距/Reveals gaps between academia & industry]
    ```

- **[arXiv260101] Securing High-Concurrency Ticket Sales: A Framework Based on Microservice**
  - **tags:** [sys], [microservice architecture], [Microservices, Spring Cloud, High Concurrency, B/S Architecture, Security Design]
  - **authors:** Zhiyong Zhang, Xiaoyan Zhang, Xiaoqi Li
  - **institution:** Hainan University
  - **link:** https://arxiv.org/pdf/2512.24941
  - **contributions:** 1. Proposes a microservice-based framework specifically designed to address the high-concurrency and stability challenges in railway ticketing systems, moving away from traditional monolithic architectures. 2. Integrates multiple security design methods within the microservice architecture to ensure data consistency and system reliability under extreme load. 3. Implements and validates a complete online ticket purchase system with core functionalities (real-time inquiry, dynamic seat update, online selection) and demonstrates its performance and stability through testing of core interfaces.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee9d9d83852f82c9459fe42cd986170009c482b80c1bbf7bcfde8e9fc81224b4_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of handling high-concurrency user requests in railway ticketing systems by proposing a framework based on microservice architecture and Spring Cloud. The designed system integrates various security measures and functionalities to ensure stability, data consistency, and fast response. Testing results confirm the system's good performance and stability under high-concurrency scenarios.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Securing High-Concurrency Ticket Sales: A Framework Based on Microservice<br>基于微服务的高并发票务安全框架"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>传统架构无法应对高并发<br>Traditional architecture fails under high concurrency"] --> P1["用户同时大量访问<br>Massive simultaneous user access"]
        Problem --> P2["故障容忍性不足与能力低<br>Insufficient fault tolerance & low ability"]
        Method["主要方法/Method<br>采用微服务架构与Spring Cloud<br>Adopt Microservice & Spring Cloud"] --> M1["B/S架构设计<br>B/S Architecture Design"]
        Method --> M2["集成多重安全方法<br>Integrate multiple security methods"]
        Method --> M3["实现完整在线流程<br>Implement full online process"]
        Results["关键结果/Results<br>系统具备良好能力与稳定性<br>System has good ability & stability"] --> R1["核心接口测试通过<br>Core interface tests passed"]
        Results --> R2["高并发下性能稳定<br>Stable performance under high concurrency"]
    ```
