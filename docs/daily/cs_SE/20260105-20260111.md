---
slug: /daily/csse/20260105-20260111
---
# 20260105-20260111 (cs.SE)

## 2026-01-05

- **[arXiv260105] Understanding Security Risks of AI Agents' Dependency Updates**
  - **tags:** [sec], [software supply chain security], [dependency management, AI coding agents, vulnerability analysis, pull requests, software ecosystems]
  - **authors:** Tanmay Singla, Berk Çakar, Paschal C. Amusuo, James C. Davis
  - **institution:** Purdue University
  - **link:** https://arxiv.org/pdf/2601.00205
  - **contributions:** 1. Conducted a large-scale empirical study comparing dependency changes in AI agent-authored and human-authored pull requests across seven software ecosystems. 2. Quantified that AI agents select known-vulnerable dependency versions more frequently than humans and that their vulnerable selections are more disruptive to remediate, often requiring major-version upgrades. 3. Demonstrated that, at an aggregate level, agent-driven dependency work leads to a net increase in vulnerabilities, whereas human-authored work leads to a net reduction.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e340be99f3d9cc00ed390c752392deee81c8ecf465ac558d9d715ac49e66836_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the security risks of dependency updates introduced by AI coding agents. By analyzing over 117,000 dependency changes, the study finds that agents are more likely than humans to select vulnerable versions and that fixing these selections is more disruptive. The results indicate current AI agents can worsen a project's security posture, motivating the need for new guardrails.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[理解AI代理依赖更新的安全风险<br/>Understanding Security Risks of AI Agents' Dependency Updates] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem<br/>AI代理的依赖决策是否引入独特的安全风险?<br/>Do AI agents' dependency decisions introduce distinct security risks?]
        Method[主要方法/Method<br/>大规模实证研究: 分析来自7个生态系统的代理与人类PR中的依赖变更<br/>Large-scale empirical study: Analyze dependency changes in agent/human PRs across 7 ecosystems]
        Results[关键结果/Results<br/>代理更频繁选择已知漏洞版本且修复更困难; 代理工作导致漏洞净增加<br/>Agents select vulnerable versions more often & remediation is harder; Agent work yields net vulnerability increase]
    ```

- **[arXiv260105] Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback**
  - **tags:** [mlsys], [agent system], [semantic verification, execution feedback, generator-discriminator framework, reverse translation, conversational business analytics]
  - **authors:** Yan Sun, Ming Cai, Stanley Kok
  - **institution:** National University of Singapore
  - **link:** https://arxiv.org/pdf/2601.00224
  - **contributions:** 1. Proposes Q*, a verification technique that uses reverse translation and semantic matching to align generated code with user intent. 2. Introduces Feedback+, a mechanism that incorporates execution feedback to guide iterative code refinement. 3. Embeds these techniques within a generator-discriminator framework to shift validation responsibilities from users to the system, aiming to improve reliability.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2d07ef5c900d3b1d3d6067b2025a8ba0771149df2530b94a6a54885c8bd8685_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of verification in conversational business analytics systems by proposing two techniques, Q* and Feedback+, to improve the accuracy and executability of LLM-generated outputs. The methods are integrated into a generator-discriminator framework and evaluated on benchmark datasets, showing reduced error rates and task completion time. The work provides a design framework for building more reliable enterprise-grade GenAI assistants.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Talk Less, Verify More: Improving LLM Assistants<br>少说多验证：改进LLM助手] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>LLM助手缺乏验证机制<br>Lack of verification in LLM assistants]
        C[主要方法/Method<br>Q*与Feedback+验证<br>Q* and Feedback+ verification]
        D[关键结果/Results<br>降低错误率与任务时间<br>Reduced error rate & task time]
        C --> E[Q*: 逆向翻译与语义匹配<br>Q*: Reverse translation & semantic matching]
        C --> F[Feedback+: 执行反馈引导优化<br>Feedback+: Execution feedback guides refinement]
    ```

- **[arXiv260105] Advanced Vulnerability Scanning for Open Source Software: Detection and Mitigation of Log4j Vulnerabilities**
  - **tags:** [sec], [vulnerability detection], [Log4j, GitHub Actions, false positive reduction, exploitability analysis, continuous scanning]
  - **authors:** Victor Wen, Zedong Peng
  - **institution:** University of Montana
  - **link:** https://arxiv.org/pdf/2601.00235
  - **contributions:** 1. Developed an advanced Log4j scanning tool that evaluates real-world exploitability to reduce false positives, moving beyond simple version checking. 2. Integrated the tool with GitHub Actions to provide automated, continuous scanning and real-time feedback within existing development workflows. 3. Demonstrated the tool's effectiveness with an empirical evaluation on 28 open-source projects, achieving a 91.4% accuracy rate across 140 scans.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce02813346b1c26e8e56ff387c5098fa19b027663feb01a89a1ae6b8ffd49e2e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high rate of false positives in existing Log4j vulnerability scanners by developing a new tool that assesses the real-world exploitability of the software. The tool is integrated into GitHub Actions for automated, continuous scanning and provides mitigation recommendations. The evaluation on 28 projects shows the approach achieves 91.4% accuracy, offering a more reliable method for detecting and mitigating Log4j vulnerabilities in open-source software.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Advanced Vulnerability Scanning for OSS: Log4j] --> B[核心问题/Problem: High false positives in current Log4j scanners]
        A --> C[主要方法/Method: Advanced scanner evaluating real exploitability + GitHub Actions integration]
        A --> D[关键结果/Results: 91.4% accuracy on 28 OSS projects]
    ```

- **[arXiv260105] An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection: RAG, SFT, and Dual-Agent Systems**
  - **tags:** [mlsys], [rag (retrieval-augmented generation)], [Retrieval-Augmented Generation (RAG), Supervised Fine-Tuning (SFT), Dual-Agent LLM, QLoRA, Vulnerability Detection]
  - **authors:** Md Hasan Saju, Maher Muhtadi, Akramul Azim
  - **institution:** Ontario Tech University
  - **link:** https://arxiv.org/pdf/2601.00254
  - **contributions:** 1. Conducted a comparative empirical evaluation of three LLM-based approaches (RAG, SFT, and Dual-Agent) for code vulnerability detection. 2. Proposed a RAG framework that integrates external domain knowledge (e.g., from the internet and MITRE CWE database) to achieve state-of-the-art performance. 3. Introduced and evaluated a Dual-Agent LLM system designed to improve reasoning transparency and error mitigation with reduced resource overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85bf4a637927a306d9960d3a0ec1a16f810bb0755b9400e6b4b384627260154e_w640_q70.webp
  - **Simple LLM Summary:** This paper compares three LLM-based methods—RAG, SFT, and a Dual-Agent system—for detecting software vulnerabilities in code. The RAG approach, which augments the LLM with external knowledge, achieved the highest accuracy and F1 score, demonstrating the value of contextual information for this task.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection<br>LLM代码漏洞检测方法的实证评估"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>Automated detection of software vulnerabilities in codebases<br>代码库中软件漏洞的自动化检测"]
        Method["主要方法/Method<br>Comparative study of RAG, SFT, and Dual-Agent LLM frameworks<br>对RAG、SFT和双智能体LLM框架的比较研究"]
        Results["关键结果/Results<br>RAG achieved highest accuracy (0.86) & F1 (0.85)<br>RAG取得了最高的准确率(0.86)和F1分数(0.85)"]
    ```

- **[arXiv260105] In Line with Context: Repository-Level Code Generation via Context Inlining**
  - **tags:** [se], [code generation], [repository-level code generation, context inlining, call graph, perplexity-based confidence, bidirectional inlining]
  - **authors:** Chao Hu, Wenhao Zeng, Yuling Shi, Beijun Shen, Xiaodong Gu
  - **institution:** Shanghai Jiao Tong University
  - **link:** https://arxiv.org/pdf/2601.00376
  - **contributions:** 1. Introduces InlineCoder, a novel framework that reframes repository-level code generation as a function-level task by inlining the target function into its call graph., 2. Proposes a bidirectional inlining process combining an initial draft anchor, upstream inlining for usage scenarios, and downstream retrieval for dependency context., 3. Demonstrates substantial performance gains over state-of-the-art baselines on benchmarks like RepoExec, highlighting effectiveness in understanding repository contexts.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/042382406537daf6ffcdbb0e0a2311956fbf996d26fe6c18ea9b84304141abfa_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the challenge of repository-level code generation, where models must understand complex dependencies across an entire codebase. It proposes InlineCoder, a framework that first generates a draft function (anchor) and then enriches the context by inlining it into its callers (upstream) and retrieving its callees (downstream). This approach significantly outperforms existing methods on standard benchmarks, showing improved understanding of repository context.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["In Line with Context: Repository-Level Code Generation via Context Inlining<br>论文标题"]
        Root --> Problem["现有方法不足<br>Problem: Existing methods (e.g., RAG) rely on surface-level similarity and struggle with repository dependencies."]
        Root --> Method["提出InlineCoder框架<br>Method: Generates an anchor draft, then performs bidirectional context inlining (Upstream Inlining & Downstream Retrieval)."]
        Root --> Results["性能显著提升<br>Results: Outperforms SOTA baselines with substantial gains on RepoExec and DevEval benchmarks."]
    ```

- **[arXiv260105] On Plagiarism and Software Plagiarism**
  - **tags:** [se], [software plagiarism detection], [code similarity, software fingerprints, software birthmarks, code embeddings]
  - **authors:** Rares Folea, Emil Slusanschi
  - **institution:** National University of Science and Technology Politehnica Bucharest
  - **link:** https://arxiv.org/pdf/2601.00429
  - **contributions:** 1. Introduces Project Martial, an open-source software solution for detecting code similarity. 2. Provides a survey and categorization of detection challenges and existing techniques (e.g., fingerprinting, birthmarks, embeddings). 3. Examines the legal and academic landscape of software plagiarism, including notable lawsuits and copyright rulings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/724401c6b879de356cf1f44e824118ba2282721468abf31005821b6bbe265388_w640_q70.webp
  - **Simple LLM Summary:** This paper explores the challenges in automatically detecting software plagiarism and introduces Project Martial, an open-source tool for this purpose. It surveys existing detection techniques like fingerprinting and code embeddings, and analyzes the legal context of software copyright. The work aims to advance the understanding and tooling for identifying code similarity and intellectual property infringement.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["On Plagiarism and Software Plagiarism<br/>论文标题"] --> Problem["探索软件相似性自动检测的复杂性<br/>Complexities of automatic software similarity detection"]
        Root --> Method["介绍开源解决方案Project Martial<br/>Introduces open-source Project Martial"]
        Root --> Results["提供技术综述与法律背景分析<br/>Provides survey of techniques & legal context"]
    ```

- **[arXiv260105] DSL or Code? Evaluating the Quality of LLM-Generated Algebraic Specifications: A Case Study in Optimization at Kinaxis**
  - **tags:** [se], [Model-Driven Engineering], [EXEOS, AMPL, LLM-generated models, iterative refinement, algebraic specifications]
  - **authors:** Negin Ayoughi, David Dewar, Shiva Nejati, Mehrdad Sabetzadeh
  - **institution:** University of Ottawa, Kinaxis
  - **link:** https://arxiv.org/pdf/2601.00469
  - **contributions:** 1. Introduces EXEOS, an LLM-based approach that generates both AMPL (DSL) and Python code from NL descriptions and iteratively refines them using solver feedback. 2. Empirically evaluates the quality (executability and correctness) of LLM-generated AMPL models against Python code using a public dataset and real-world industrial cases. 3. Demonstrates through an ablation study that, contrary to expectations, generated AMPL specifications can be competitive with or even better than Python, and that EXEOS's design choices improve specification quality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a29f4922b58c22b6392fc5cf412729e7b287b830c59b6aeef101ba415d943fc4_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates whether LLMs generate lower-quality models for domain-specific languages (DSLs) like AMPL compared to mainstream code like Python. It proposes EXEOS, a method that generates and iteratively refines both AMPL and Python from natural language using solver feedback. The evaluation shows that LLM-generated AMPL is often competitive with or superior to Python, challenging the assumption about DSL inferiority.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DSL or Code? Evaluating LLM-Generated Algebraic Specifications] --> B(核心问题/Problem: LLM生成的DSL模型质量是否低于主流代码?);
        A --> C(主要方法/Method: 提出EXEOS方法，从NL生成AMPL/Python并利用求解器反馈迭代优化);
        A --> D(关键结果/Results: AMPL与Python质量相当甚至更好，EXEOS设计有效提升生成质量);
    ```

- **[arXiv260105] Security in the Age of AI Teammates: An Empirical Study of Agentic Pull Requests on GitHub**
  - **tags:** [sec], [software security, empirical software engineering], [autonomous coding agents, pull requests, software security, empirical study, GitHub]
  - **authors:** Mohammed Latif Siddiq, Xinye Zhao, Vinicius Carvalho Lopes, Beatrice Casey, Joanna C. S. Santos
  - **institution:** University of Notre Dame (inferred from author email domains and affiliations)
  - **link:** https://arxiv.org/pdf/2601.00477
  - **contributions:** 1. Quantified the prevalence and characteristics of security-related contributions from autonomous coding agents on GitHub, identifying 1,293 confirmed cases. 2. Analyzed acceptance outcomes and review latency, finding lower merge rates and longer review times for security-related PRs, indicating heightened human scrutiny. 3. Identified that PR rejection is more strongly associated with complexity and verbosity than with explicit security topics, and characterized the supportive security hardening activities agents perform.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/552f0e29d5e90f293ddef225bc41d40fffefe1a15da3287c3a8d69df70dcf6a8_w640_q70.webp
  - **Simple LLM Summary:** This paper conducts a large-scale empirical study to understand how autonomous AI coding agents contribute to software security via pull requests on GitHub. By analyzing over 33,000 agent-authored PRs, the authors find that security-related PRs constitute about 4% of agent activity, often involve supportive hardening tasks, and face lower acceptance rates and longer review times due to increased human scrutiny, with rejection linked more to PR complexity than security content.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Security in the Age of AI Teammates: An Empirical Study of Agentic Pull Requests on GitHub"] --> Problem["核心问题/Problem<br>How do autonomous AI coding agents impact software security in practice?"]
        Root --> Method["主要方法/Method<br>Large-scale empirical analysis of 33k+ agent-authored GitHub PRs using keyword filtering & manual validation"]
        Root --> Results["关键结果/Results<br>4% of agent PRs are security-related; Lower merge rates & longer review times; Rejection linked to complexity, not security terms"]
    ```

- **[arXiv260105] Multi-Agent Coordinated Rename Refactoring**
  - **tags:** [se], [refactoring], [multi-agent system, coordinated renaming, scope inference, refactoring automation, IDE integration]
  - **authors:** Abhiram Bellur, Mohammed Raihan Ullah, Fraol Batole, Mohit Kansara, Masaharu Morimoto, Kai Ishikawa, Haifeng Chen, Yaroslav Zharov, Timofey Bryksin, Tien N. Nguyen, Hridesh Rajan, Danny Dig
  - **institution:** University of Colorado, Tulane University, University of Texas at Dallas, NEC Corporation, NEC Laboratories America, JetBrains Research
  - **link:** https://arxiv.org/pdf/2601.00482
  - **contributions:** 1. Designed and implemented the first multi-agent framework for automating coordinated rename refactoring. 2. Introduced a novel approach where an initial developer refactoring is used as a clue to infer a Declared Scope, which guides subsequent automated refactorings. 3. Demonstrated significant performance improvements (2.3x-3.1x F1-score) over state-of-the-art methods through rigorous evaluation on established and new benchmarks, including successful integration into active open-source projects.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e6c46d36197d90e221024d6225c9bcd5170e720a7f8f29bef40ad31d151bbda_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the tedious and error-prone task of coordinated renaming in software development by proposing a novel multi-agent framework. The framework uses a developer's initial rename as a clue to infer a scope, which then guides specialized agents to safely identify and execute related refactorings using IDE APIs. The evaluation shows the system, CoRenameAgent, significantly outperforms existing methods in accuracy and demonstrates practical utility by having its automatically generated changes accepted into real projects.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Multi-Agent Coordinated Rename Refactoring] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[手动重命名易错且繁琐/Manual renaming is tedious & error-prone]
        B --> B2[现有方法假阳性高或不完整/Existing methods have high false positives or are incomplete]
        C --> C1[范围推断代理/Scope Inference Agent]
        C --> C2[计划执行代理/Planned Execution Agent]
        C --> C3[复制代理/Replication Agent]
        D --> D1[F1分数显著提升/Significant F1-score improvement]
        D --> D2[实际项目验证/Practical validation in open-source projects]
    ```

- **[arXiv260105] STELLAR: A Search-Based Testing Framework for Large Language Model Applications**
  - **tags:** [mlsys], [llm inference], [search-based testing, evolutionary optimization, failure detection, conversational systems]
  - **authors:** Lev Sorokin, Ivan Vasilev, Ken E. Friedl, Andrea Stocco
  - **institution:** BMW Group, Technical University of Munich, fortiss GmbH
  - **link:** https://arxiv.org/pdf/2601.00497
  - **contributions:** 1. Proposes STELLAR, a novel automated search-based testing framework that models test generation for LLM applications as an optimization problem. 2. Introduces a discretization of the LLM input space into stylistic, content-related, and perturbation features to guide the search. 3. Demonstrates the effectiveness of STELLAR, showing it uncovers significantly more failures (up to 4.3x) than existing baseline approaches on safety and navigation QA systems.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e74070a45961ce82126fcb74b49f51f3dc1496b6ab8569fa3562401f5a01ffd2_w640_q70.webp
  - **Simple LLM Summary:** The paper presents STELLAR, an automated search-based testing framework that uses evolutionary optimization to generate test inputs for LLM-based applications, aiming to systematically uncover failure-inducing prompts. It evaluates the framework on conversational question-answering systems, demonstrating it can find significantly more failures than existing baseline methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[STELLAR: A Search-Based Testing Framework for Large Language Model Applications] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: LLM应用易产生不准确或有害响应，且其高维输入空间使系统化测试极具挑战。]
        Method[主要方法/Method: 将测试生成建模为优化问题，使用进化算法动态探索更可能暴露故障的输入特征组合。]
        Results[关键结果/Results: 在三个对话问答系统上评估，相比基线方法，STELLAR暴露的故障数量最多达4.3倍。]
    ```

- **[arXiv260105] Cost-Performance Analysis of Cloud-Based Retail Point-of-Sale Systems: A Comparative Study of Google Cloud Platform and Microsoft Azure**
  - **tags:** [sys], [cloud computing], [cloud benchmarking, point-of-sale systems, performance analysis, cost optimization, retail technology]
  - **authors:** Ravi Teja Pagidoju
  - **institution:** Campbellsville University
  - **link:** https://arxiv.org/pdf/2601.00530
  - **contributions:** 1. Presents a systematic, repeatable, and transparent methodology for evaluating POS workloads on cloud platforms using free-tier resources and open-source benchmarking code. 2. Provides the first comprehensive, code-driven comparison of POS-specific workloads across Google Cloud Platform and Microsoft Azure, analyzing performance metrics and cost efficiency. 3. Establishes an open benchmarking framework and offers practical insights for merchants considering cloud POS implementation, linking architectural components to observed performance-cost trade-offs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/084205dec68906e341b24595e452d764be0491b5d3d16bfccff9cf4f8d4f1eca_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a systematic methodology to compare the performance and cost of cloud-based Point-of-Sale systems on Google Cloud Platform and Microsoft Azure using free-tier resources and open-source code. The analysis finds that GCP offers faster response times, while Azure demonstrates higher cost efficiency for steady-state operations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Cost-Performance Analysis of Cloud-Based Retail Point-of-Sale Systems: A Comparative Study of Google Cloud Platform and Microsoft Azure] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[缺乏零售工作负载的实证研究 / Lack of empirical research on retail workloads]
        C --> C1[使用免费资源和开源代码进行系统化基准测试 / Systematic benchmarking using free-tier resources and open-source code]
        D --> D1[GCP响应时间快23.0% / GCP 23.0% faster response]
        D --> D2[Azure成本效率高71.9% / Azure 71.9% higher cost efficiency]
    ```

- **[arXiv260105] Towards Understanding and Characterizing Vulnerabilities in Intelligent Connected Vehicles through Real-World Exploits**
  - **tags:** [sec], [automotive security], [Intelligent Connected Vehicles, vulnerability taxonomy, empirical study]
  - **authors:** Yuelin Wang, Yuqiao Ning, Yanbang Sun, Xiaofei Xie, Zhihua Xie, Yang Chen, Zhen Guo, Shihao Xue, Junjie Wang, Sen Chen
  - **institution:** Tianjin University, China Automotive Technology & Research Center Co., Ltd., Singapore Management University, Nankai University
  - **link:** https://arxiv.org/pdf/2601.00627
  - **contributions:** 1. Conducted the first large-scale empirical study on ICV vulnerabilities using a dataset of 649 real-world exploits. 2. Evaluated and extended existing vulnerability taxonomies, discovering one new vulnerability location and 13 new vulnerability types. 3. Categorized vulnerabilities into threat types and risk levels, providing a data-driven analysis for researchers and practitioners.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b54d1ae7155015517ea41f4712b72855a6ad2dca04602d214eb8c70115598c03_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the lack of systematic understanding of vulnerabilities in Intelligent Connected Vehicles (ICVs) by conducting a large-scale empirical study. The authors collected 649 real-world exploitable vulnerabilities, primarily from competitions, to assess and extend existing vulnerability taxonomies. The study provides a comprehensive, data-driven characterization of ICV vulnerabilities, identifying new types and offering actionable insights for security improvement.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Towards Understanding and Characterizing Vulnerabilities in Intelligent Connected Vehicles through Real-World Exploits"] --> Problem["核心问题/Problem: Lack of systematic, validated understanding of ICV vulnerabilities"]
        Root --> Method["主要方法/Method: Large-scale empirical study using 649 real-world exploits from competitions"]
        Root --> Results["关键结果/Results: Extended taxonomy with new location & types, categorized threats & risks"]
    ```

- **[arXiv260105] KELP: Robust Online Log Parsing Through Evolutionary Grouping Trees**
  - **tags:** [sys], [log parsing], [Evolutionary Grouping Tree, online clustering, schema drift, throughput, benchmark]
  - **authors:** Satyam Singh, Sai Niranjan Ramachandran
  - **institution:** StoneBuck Labs
  - **link:** https://arxiv.org/pdf/2601.00633
  - **code:** codeberg.org/stonebucklabs/kelp
  - **contributions:** 1. Proposes KELP, a high-throughput online log parser built on a novel Evolutionary Grouping Tree data structure. 2. Introduces a new benchmark designed to reflect the structural ambiguity and dynamism of modern production systems for rigorous evaluation. 3. Demonstrates that KELP maintains high accuracy on the new benchmark where traditional heuristic methods fail, without compromising throughput.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c825e5ac9adebe7efdf4817dd2c8251ed03ac18f0076eb3fd628e34ff8c37232_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the brittleness of existing online log parsers in dynamic production environments. It proposes KELP, a parser using an Evolutionary Grouping Tree to continuously cluster and adapt to log schema changes. The evaluation shows KELP achieves robust accuracy on a new, realistic benchmark without sacrificing throughput.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[KELP: Robust Online Log Parsing Through Evolutionary Grouping Trees] --> B[核心问题/Problem: Existing online parsers are brittle for dynamic production environments]
        A --> C[主要方法/Method: Evolutionary Grouping Tree for continuous online clustering]
        A --> D[关键结果/Results: High accuracy on rigorous benchmark, maintains throughput]
    ```

- **[arXiv260105] SEMODS: A Validated Dataset of Open-Source Software Engineering Models**
  - **tags:** [se], [AI for Software Engineering], [Hugging Face, model registry, software development lifecycle]
  - **authors:** Alexandra González, Xavier Franch, Silverio Martínez-Fernández
  - **institution:** Universitat Politècnica de Catalunya
  - **link:** https://arxiv.org/pdf/2601.00635
  - **contributions:** 1. Creation of SEMODS, a validated dataset of 3,427 open-source SE models from Hugging Face. 2. A methodology combining automated collection with rigorous validation (manual annotation and LLM assistance). 3. Linking models to SE tasks and activities, providing standardized evaluation results for applications like analysis, discovery, and benchmarking.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f0d2bc6ba395d9ae5bc8098852d3d24eb13e7d8ca61618dee3f954ebcd07cec1_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the difficulty of identifying software engineering (SE) models among millions on Hugging Face by creating SEMODS, a validated dataset of 3,427 models. It uses automated collection combined with manual and LLM-assisted validation to link models to SE tasks and standardize their evaluation. The main conclusion is that SEMODS provides a curated resource to support SE research and practice, enabling tasks like model discovery and benchmarking.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[SEMODS: A Validated Dataset of Open-Source Software Engineering Models] --> B[核心问题/Problem: 难以从海量模型中识别软件工程模型 / Hard to identify SE models from millions on Hugging Face]
        A --> C[主要方法/Method: 自动收集与严格验证(人工+LLM) / Automated collection & rigorous validation (manual + LLM)]
        A --> D[关键结果/Results: 包含3,427个模型的SE数据集，链接到开发周期任务 / SE dataset of 3,427 models linked to SDLC tasks]
    ```

- **[arXiv260105] Early-Stage Prediction of Review Effort in AI-Generated Pull Requests**
  - **tags:** [se], [mining software repositories], [pull request review, AI agents, ghosting, LightGBM, structural features]
  - **authors:** Dao Sy Duy Minh, Huynh Trung Kiet, Tran Chi Nguyen, Nguyen Lam Phu Quy, Phu Hoa Pham, Nguyen Dinh Ha Duong, Truong Bao Tran
  - **institution:** University of Science, VNU-HCM; University of Economics and Law, VNU-HCM
  - **link:** https://arxiv.org/pdf/2601.00753
  - **contributions:** 1. Operationalized and quantified the phenomenon of "agentic ghosting" in AI-generated pull requests. 2. Demonstrated that creation-time structural features (e.g., patch size, files touched) can predict high-review-effort PRs with high accuracy (AUC 0.957). 3. Proposed a "Circuit Breaker" triage model that can intercept 69% of total review effort by allocating a 20% review budget to the most complex PRs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/faf7bd0a84fef9e36db3f5fe7d99f87b1c9aec42bdd36b431dd092a8ab24ba72_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of managing review effort for AI-generated pull requests. It proposes a "Circuit Breaker" model that uses static structural features (like patch size) at PR creation to predict which PRs will require high review effort, achieving high predictive accuracy. The key finding is that review burden is dictated by what code the AI agent changes, not by the semantic content of the PR description.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Early-Stage Prediction of Review Effort in AI-Generated Pull Requests<br>AI生成PR中审查工作量的早期预测"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>AI agents generate many PRs, some are time sinks for reviewers.<br>AI代理生成大量PR，部分消耗大量审查精力"] --> P1["子问题/Sub-Problem<br>Can we predict high-effort PRs before review?<br>能否在审查前预测高工作量PR？"]
        Method["主要方法/Method<br>Circuit Breaker Triage Model<br>断路器分流模型"] --> M1["特征/Features<br>Static structural features (patch size, files)<br>静态结构特征"] --> M2["模型/Model<br>LightGBM classifier<br>LightGBM分类器"]
        Results["关键结果/Results"] --> R1["发现/Finding<br>Two-regime pattern: instant merges vs. iterative cycles<br>双模式：即时合并 vs. 迭代循环"] --> R2["性能/Performance<br>AUC 0.957, intercepts 69% effort at 20% budget<br>AUC 0.957，20%预算拦截69%工作量"] --> R3["结论/Conclusion<br>Review burden dictated by what agents touch, not what they say.<br>审查负担由代理修改内容决定，而非描述。"]
    ```
