{
  "label": "cs.AI",
  "slug": "csai",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation",
      "authors": "Santhosh Kumar Ravindran",
      "institution": "Microsoft Corporation",
      "link": "https://arxiv.org/pdf/2512.21351",
      "code": null,
      "tags": [
        "reinforcement learning",
        "dream-replay reinforcement learning",
        "evolutionary algorithms",
        "adaptive code generation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp",
      "contributions": "1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as \"genomes\" that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.",
      "summary": "CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.",
      "mindmap": "graph TB\n        A[CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM代码生成缺乏适应性，难以应对API变化/LLM code generation lacks adaptability to API changes]\n        C --> C1[将RL轨迹视为基因组进行进化操作/Treat RL trajectories as genomes for evolutionary operations]\n        C --> C2[在夜间回放阶段进行突变与选择/Mutation and selection during nocturnal replay]\n        D --> D1[解决方案新颖性提升35%/35% higher novelty in solutions]\n        D --> D2[适应速度加快25%/25% faster adaptation]"
    },
    {
      "title": "EcoNet: Multiagent Planning and Control Of Household Energy Resources Using Active Inference",
      "authors": "John C. Boik, Kobus Esterhuysen, Jacqueline B. Hynes, Axel Constant, Ines Hipolito, Mahault Albarracin, Alex B. Kiefer, Karl Friston",
      "institution": "VERSES, University of Sussex, Macquarie University, UCL (University College London)",
      "link": "https://arxiv.org/pdf/2512.21343",
      "code": null,
      "tags": [
        "agent system",
        "active inference",
        "multi-agent systems",
        "home energy management systems (HEMS)",
        "distributed energy resources (DER)",
        "Bayesian inference"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b885d3c6c9f392a494063522c79cde9a59fead8ab6b04010259b6485f007cec8_w640_q70.webp",
      "contributions": "1. Proposes EcoNet, a novel Bayesian framework for household and neighborhood energy management based on active inference. 2. Addresses the challenge of planning under uncertainty (e.g., weather, solar forecasts) while handling complex, conditional, and conflicting household goals. 3. Demonstrates the approach through simulations for multiagent planning and control of distributed energy resources.",
      "summary": "This paper introduces EcoNet, a multiagent planning and control system for household energy resources using active inference, a Bayesian approach, to manage uncertainty and conflicting goals. The method aims to optimize energy use, costs, and emissions while maintaining comfort. Simulation results demonstrate its potential for improved energy management and coordination.",
      "mindmap": "graph TB\n        A[EcoNet: 多智能体家庭能源规划与控制 / EcoNet: Multiagent Household Energy Planning & Control] --> B[核心问题 / Problem]\n        A --> C[主要方法 / Method]\n        A --> D[关键结果 / Results]\n        B --> B1[复杂且冲突的家庭目标 / Complex & Conflicting Household Goals]\n        B --> B2[决策存在不确定性 / Decision-making Under Uncertainty]\n        C --> C1[基于主动推理的贝叶斯方法 / Active Inference-based Bayesian Approach]\n        C --> C2[多智能体规划与控制 / Multiagent Planning & Control]\n        D --> D1[模拟结果展示 / Simulation Results Presented]\n        D --> D2[改善能源管理与协调 / Improved Energy Management & Coordination]"
    },
    {
      "title": "Multi-Agent LLM Committees for Autonomous Software Beta Testing",
      "authors": "Sumanth Bharadwaj Hachalli Karanam, Dhiwahar Adhithya Kennady",
      "institution": "New York University",
      "link": "https://arxiv.org/pdf/2512.21352",
      "code": null,
      "tags": [
        "automated software testing",
        "multi-agent system",
        "large language model",
        "vision-language model",
        "consensus voting",
        "beta testing"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40573d0b1209c41e9825c09111398107cc51ee9d86c5234b50bea2515d0ab37f_w640_q70.webp",
      "contributions": "1. A novel multi-agent committee framework that uses a three-round voting protocol for consensus-based decision-making in software testing. 2. Integration of vision-enabled LLMs and diverse testing personas to systematically explore and understand web application user interfaces. 3. Demonstrated significant performance improvements over single-agent baselines in task success, bug detection (F1 score), and security vulnerability coverage on established benchmarks.",
      "summary": "The paper addresses the high cost of manual software beta testing and the limitations of single-agent LLM approaches by proposing a multi-agent committee framework. The method employs diverse, vision-enabled LLMs that collaborate through a structured voting protocol and persona-driven behavior to autonomously test web applications. The results show that this multi-agent approach significantly outperforms single-agent baselines in task success rates, bug detection, and security testing coverage, making it suitable for real-time CI/CD integration.",
      "mindmap": "graph TB\n        A[Multi-Agent LLM Committees for Autonomous Software Beta Testing] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[手动测试成本高，单智能体LLM存在幻觉/Manual testing costly, single-agent LLM hallucinates]\n        C --> C1[多智能体委员会与三轮投票协议/Multi-agent committee & three-round voting]\n        C --> C2[视觉LLM与角色多样性/Vision LLMs & persona diversity]\n        D --> D1[任务成功率89.5%，超越基线/Task success 89.5%, beats baseline]\n        D --> D2[动作延迟0.71秒，适合CI/CD/Action latency 0.71s, suitable for CI/CD]\n        D --> D3[覆盖8/10 OWASP漏洞类别/Covers 8/10 OWASP Top 10]"
    },
    {
      "title": "Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software",
      "authors": "Ying Xiao, Shangwen Wang, Sicen Liu, Dingyuan Xue, Xian Zhan, Yepang Liu, Jie M. Zhang",
      "institution": "King’s College London, National University of Defense Technology, Southern University of Science and Technology, The Hong Kong Polytechnic University",
      "link": "https://arxiv.org/pdf/2512.21348",
      "code": null,
      "tags": [
        "software fairness",
        "correlation tuning",
        "phi-coefficient",
        "multi-objective optimization",
        "pre-processing",
        "bias mitigation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4f80681a9ac6a6c3ad7d2bd938623a06836acba00279d9cec368a5ebbe44df3_w640_q70.webp",
      "contributions": "1. Proposes a novel pre-processing bias mitigation method called Correlation Tuning (CoT) that adjusts data correlations. 2. Introduces the Phi-coefficient as an intuitive measure to quantify correlation between sensitive attributes and labels. 3. Employs multi-objective optimization to address proxy biases, demonstrating superior effectiveness over state-of-the-art methods in single and multiple attribute scenarios.",
      "summary": "This paper proposes Correlation Tuning (CoT), a novel pre-processing method to mitigate bias in ML software by adjusting data correlations using the Phi-coefficient and multi-objective optimization. It frames fairness as a core software quality issue. Extensive evaluation shows CoT significantly improves performance for unprivileged groups and reduces key bias metrics, outperforming existing methods.",
      "mindmap": "graph TB\n        A[Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[传统公平研究忽视软件质量维度/Traditional fairness research neglects software quality dimension]\n        B --> B2[预处理方法效果不足/Pre-processing methods lack effectiveness]\n        C --> C1[提出相关性调优 (CoT)/Propose Correlation Tuning (CoT)]\n        C --> C2[使用Phi系数量化相关性/Use Phi-coefficient to quantify correlation]\n        C --> C3[采用多目标优化/Employ multi-objective optimization]\n        D --> D1[提高弱势群体TPR 17.5%/Increase unprivileged group TPR by 17.5%]\n        D --> D2[关键偏差指标降低 >50%/Key bias metrics reduced by >50%]\n        D --> D3[超越SOTA方法 3-10个百分点/Outperform SOTA by 3-10 percentage points]"
    },
    {
      "title": "Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks",
      "authors": "Jasmin Saxer, Isabella Maria Aigner, Luise Linzmeier, Andreas Weiler, Kurt Stockinger",
      "institution": "Zurich University of Applied Sciences, University of Zurich",
      "link": "https://arxiv.org/pdf/2512.21345",
      "code": null,
      "tags": [
        "text-to-SQL",
        "unanswerable question detection",
        "few-shot prompting",
        "biomedical databases"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d95c00b7fa86810771a1c8fb0ff6fd8768baaa0419f172cc5c7a3068ac67a64_w640_q70.webp",
      "contributions": "1. Proposed Query Carefully, a pipeline integrating LLM-based SQL generation with explicit detection of unanswerable inputs. 2. Constructed OncoMX-NAQ, a benchmark dataset of 80 no-answer questions for biomedical text-to-SQL. 3. Demonstrated that balanced few-shot prompting with both answerable and unanswerable examples achieves high unanswerable-detection accuracy without degrading performance on answerable queries.",
      "summary": "This paper addresses the risk of text-to-SQL systems generating executable but incorrect SQL for ambiguous or unanswerable queries, especially in biomedical contexts. The authors propose the Query Carefully pipeline, which uses an LLM with schema-aware prompts and few-shot examples to detect and abstain from unanswerable inputs. Their evaluation shows the method achieves high detection accuracy for structurally unanswerable queries, though challenges remain for semantic ambiguities like missing values.",
      "mindmap": "graph TB\n        Root(”Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks”) --> Problem\n        Root --> Method\n        Root --> Results\n        Problem(”核心问题/Problem”) --> P1(”Text-to-SQL对不可回答查询生成可执行SQL/Text-to-SQL generates executable SQL for unanswerable queries”)\n        P1 --> P2(”生物医学领域风险高/High risk in biomedical contexts”)\n        Method(”主要方法/Method”) --> M1(”Query Carefully 管道/Query Carefully pipeline”)\n        M1 --> M2(”LLM (llama3.3:70b) + 模式感知提示 + 少样本/LLM (llama3.3:70b) + schema-aware prompts + few-shot”)\n        M2 --> M3(”包含可回答与不可回答示例/Includes answerable and unanswerable examples”)\n        Results(”关键结果/Results”) --> R1(”构建OncoMX-NAQ基准/Built OncoMX-NAQ benchmark”)\n        R1 --> R2(”不可回答检测准确率0.8/Unanswerable-detection accuracy 0.8”)\n        R2 --> R3(”结构性问题检测好，语义模糊挑战大/Good for structural, challenging for semantic ambiguity”)"
    },
    {
      "title": "A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers",
      "authors": "Chung-Chin Shih, Ti-Rong Wu, Ting Han Wei, Yu-Shan Hsu, Hung Guei, I-Chen Wu",
      "institution": "Academia Sinica, National Yang Ming Chiao Tung University, Kochi University of Technology",
      "link": "https://arxiv.org/pdf/2512.21365",
      "code": "https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ",
      "tags": [
        "reinforcement learning",
        "Relevance-Zone Based Search",
        "AlphaZero",
        "Life-and-Death problems",
        "heuristic search",
        "pattern table"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6376caf4e3dced23991e86eb4d5b0f512ce3623019adeaf18ee253d5fd00c507_w640_q70.webp",
      "contributions": "1. Applied and analyzed Relevance-Zone Based Search (RZS) and relevance-zone pattern tables to solve Go Life-and-Death problems, identifying critical relevance-zones. 2. Discovered that solvers can find rare patterns and even alternative solutions differing from established human grandmaster answers. 3. Identified and analyzed key limitations of current solvers, such as misjudging rare patterns and prioritizing direct survival over territory maximization.",
      "summary": "This paper analyzes the performance of state-of-the-art computer Go solvers using Relevance-Zone Based Search on classic Life-and-Death problems. The study finds that while these solvers can identify critical areas and discover rare patterns, they exhibit limitations like misjudging pattern values and having a non-human preference for direct survival over territory. The authors suggest future approaches to address these solver issues.",
      "mindmap": "graph TB\n        A[”A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers<br/>使用基于相关区域求解器解决围棋死活问题的研究”] --> B[”核心问题/Problem<br/>Analyzing solver behavior on Go Life-and-Death problems<br/>分析求解器在围棋死活问题上的行为”]\n        A --> C[”主要方法/Method<br/>Using Relevance-Zone Based Search (RZS) and pattern tables<br/>使用基于相关区域的搜索和模式表”]\n        A --> D[”关键结果/Results<br/>Identifies relevance-zones, finds rare/alternative solutions, reveals solver limitations<br/>识别相关区域，发现罕见/替代解法，揭示求解器局限”]"
    },
    {
      "title": "From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration",
      "authors": "Shuide Wen, Yu Sun, Beier Ku, Zhi Gao, Lijun Ma, Yang Yang, Can Jiao",
      "institution": "Tsinghua University, Shenzhen University, University of Oxford, Guangzhou University of Chinese Medicine, Harbin Institute of Technology, Shenzhen Institute of Education Sciences",
      "link": "https://arxiv.org/pdf/2512.21360",
      "code": null,
      "tags": [
        "computational psychology",
        "multimodal large language model",
        "multi-agent collaboration",
        "cosine similarity",
        "projective assessment",
        "psychological report generation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/681955eb18a63880e0327c5debb6e992188de12ca52cef0c9c34258f09c3a91d_w640_q70.webp",
      "contributions": "1. Proposed a novel multi-agent collaboration framework to automate the interpretation of House-Tree-Person drawings, decoupling visual feature recognition from psychological inference. 2. Demonstrated that multimodal large language models (MLLMs) can achieve expert-level baseline comprehension in interpreting projective drawings, with high semantic similarity to human expert interpretations. 3. Introduced a destigmatizing narrative and social-psychological perspective integration to correct visual hallucinations and enhance the ecological validity and coherence of automated psychological reports.",
      "summary": "This paper proposes an automated assessment framework for the House-Tree-Person drawing test using multimodal LLMs and multi-agent collaboration to address issues of subjective scoring and lack of standardization. The framework effectively interprets drawings with high similarity to expert analysis and generates coherent psychological reports. The results confirm the potential of multimodal models as standardized tools for projective psychological assessment.",
      "mindmap": "graph TB\n        A[From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration<br>从视觉感知到深度共情：基于多模态大模型与多智能体协作的房树人绘画自动评估框架] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>HTP测试评分标准不一，依赖主观经验，缺乏统一量化系统] --> B1\n        C[主要方法/Method<br>多模态大语言模型与多智能体协作框架] --> C1\n        D[关键结果/Results<br>模型解释与专家解释语义相似度高，多智能体系统生成有效心理报告] --> D1\n        B1[HTP test has heterogeneous scoring, relies on subjective experience, lacks unified quantitative coding]\n        C1[Multimodal LLMs and multi-agent collaboration framework]\n        D1[High semantic similarity to expert interpretations; multi-agent system produces reports with high ecological validity]"
    },
    {
      "title": "Reflection-Driven Control for Trustworthy Code Agents",
      "authors": "Bin Wang, Jiazheng Quan, Xingrui Yu, Hansen Hu, Yuhao, Ivor Tsang",
      "institution": "Peking University, Xiamen University, Agency for Science, Technology and Research (A*STAR)",
      "link": "https://arxiv.org/pdf/2512.21354",
      "code": null,
      "tags": [
        "agent system",
        "reflection-driven control",
        "secure code generation",
        "trustworthy agents",
        "reflective memory",
        "safety control"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp",
      "contributions": "1. Introduces Reflection-Driven Control, a standardized and pluggable control module that integrates self-reflection as an explicit, internal step in an agent's reasoning process. 2. Instantiates the method for secure code generation, using a reflection loop to monitor decisions and retrieve repair examples/guidelines from an evolving reflective memory to inject constraints. 3. Empirically demonstrates that the approach substantially improves security and policy compliance of generated code while preserving functional correctness, with minimal overhead.",
      "summary": "The paper addresses the lack of reliable safety controls in LLM agents by proposing Reflection-Driven Control, a module that makes self-reflection an explicit, continuous part of the agent's reasoning to monitor and constrain its decisions using evidence from a reflective memory. Evaluated on security-critical code generation tasks, the method significantly improves code security and compliance while maintaining functionality, offering a practical path toward trustworthy AI coding agents.",
      "mindmap": "graph TB\n        Root[Reflection-Driven Control for Trustworthy Code Agents] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[LLM代理缺乏可靠的安全控制/LLM agents lack reliable safety controls]\n        Problem --> P2[可能产生有害输出/Can produce harmful outputs]\n        Method --> M1[将自我反思作为推理的显式步骤/Elevates self-reflection to an explicit reasoning step]\n        Method --> M2[内部反思循环监控决策路径/Internal reflection loop monitors decision path]\n        Method --> M3[从反思记忆中检索修复示例/Retrieves repair examples from reflective memory]\n        Results --> R1[显著提高生成代码的安全性和合规性/Substantially improves security & policy compliance]\n        Results --> R2[基本保持功能正确性/Largely preserves functional correctness]\n        Results --> R3[运行时和token开销最小/Minimal runtime & token overhead]"
    },
    {
      "title": "AInsteinBench: Benchmarking Coding Agents on Scientific Repositories",
      "authors": "Titouan Duston, Shuo Xin, Yang Sun, Daoguang Zan, Aoyan Li, Shulin Xin, Kai Shen, Yixiao Chen, Qiming Sun, Ge Zhang, Jiashuo Liu, Huan Zhou, Jingkai Liu, Zhichen Pu, Yuanheng Wang, Bo-Xuan Ge, Xin Tong, Fei Ye, Zhi-Chao Zhao, Wen-Biao Han, Zhoujian Cao, Yueran Zhao, Weiluo Ren, Qingshen Long, Yuxiao Liu, Anni Huang, Yidi Du, Yuanyuan Rong, Jiahao Peng",
      "institution": "ByteDance Seed, Princeton University",
      "link": "https://arxiv.org/pdf/2512.21373",
      "code": "https://github.com/ByteDance-Seed/AInsteinBench",
      "tags": [
        "software engineering",
        "benchmark",
        "scientific computing",
        "code generation",
        "pull requests",
        "test-driven verification"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp",
      "contributions": "1. Introduces a novel benchmark (AInsteinBench) for evaluating LLM agents in end-to-end scientific development using real-world, production-grade codebases. 2. Curates tasks from maintainer-authored pull requests across six diverse scientific domains, ensuring scientific challenge and calibrated difficulty. 3. Employs executable environments and test-driven verification to measure core competencies beyond surface-level code generation.",
      "summary": "The paper introduces AInsteinBench, a benchmark designed to evaluate LLM agents' ability to function as scientific computing developers by solving tasks derived from real pull requests in scientific repositories. It uses executable environments and test-driven verification to assess deeper competencies. The benchmark provides a new standard for measuring AI's role in computational scientific research.",
      "mindmap": "graph TB\n        A[AInsteinBench: Benchmarking Coding Agents on Scientific Repositories] --> B[核心问题/Problem: Can LLM agents operate as scientific computing development agents?]\n        A --> C[主要方法/Method: End-to-end evaluation using tasks from real scientific pull requests]\n        A --> D[关键结果/Results: Measures ability beyond surface-level code generation]"
    },
    {
      "title": "Safe Path Planning and Observation Quality Enhancement Strategy for Unmanned Aerial Vehicles in Water Quality Monitoring Tasks",
      "authors": "Yuanshuang Fu, Qianyao Wang, Qihao Wang, Bonan Zhang, Jiaxin Zhao, Yiming Cao, Zhijun Li",
      "institution": "University of Electronic Science and Technology of China, North China University of Technology",
      "link": "https://arxiv.org/pdf/2512.21375",
      "code": null,
      "tags": [
        "robotic perception and planning",
        "Interfered Fluid Dynamical System (IFDS)",
        "Model Predictive Control (MPC)",
        "Dynamic Flight Altitude Adjustment (DFAA)"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5582bc8dd27c45953b75b142df4da9d25f5164a9ed81f8842a846572fbb8a2f_w640_q70.webp",
      "contributions": "1. Proposes a dynamic prediction model that transforms time-varying light and shadow disturbances (e.g., sun glint) into 3D virtual obstacles for path planning. 2. Introduces an improved IFDS algorithm combined with an MPC framework to generate smooth, safe, and dynamically feasible real-time trajectories for UAVs. 3. Designs a Dynamic Flight Altitude Adjustment (DFAA) mechanism to actively lower flight altitude in narrow observable areas, enhancing spatial resolution and data quality.",
      "summary": "This paper addresses the problem of UAV water quality monitoring being hindered by dynamic illumination disturbances like shadows and sun glint, which degrade spectral data. The proposed method actively plans safe flight paths by modeling disturbances as obstacles, using an improved IFDS and MPC for real-time trajectory optimization, and dynamically adjusting altitude to improve data quality. Simulation results show the method achieves a 98% obstacle avoidance success rate and increases effective observation data volume by approximately 27%.",
      "mindmap": "graph TB\n    A[Safe Path Planning and Observation Quality Enhancement Strategy for UAVs in Water Quality Monitoring Tasks] --> B\n    A --> C\n    A --> D\n    B[核心问题/Problem<br>Dynamic illumination disturbances (shadows, sun glint) cause spectral distortion, reducing data quality and safety.]\n    C[主要方法/Method<br>1. Model disturbances as 3D virtual obstacles.<br>2. Improved IFDS + MPC for real-time path planning.<br>3. Dynamic Flight Altitude Adjustment (DFAA).]\n    D[关键结果/Results<br>98% obstacle avoidance success rate, improved path smoothness, ~27% increase in effective observation data.]"
    },
    {
      "title": "LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors",
      "authors": "Tianwei Lan, Farid Naït-Abdesselam",
      "institution": "Université Paris Cité",
      "link": "https://arxiv.org/pdf/2512.21404",
      "code": null,
      "tags": [
        "adversarial attacks",
        "adversarial attack",
        "large language model",
        "retrieval-augmented generation",
        "Android malware detection",
        "adversarial training"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6061210b194ba5cf79f70b8959faa3abe6b3e91ffad512d9cfd319de948593bb_w640_q70.webp",
      "contributions": "1. Proposes LAMLAD, a novel adversarial attack framework that uses a dual-agent LLM architecture (manipulator and analyzer) to generate feature-level perturbations for evading Android malware detectors., 2. Integrates Retrieval-Augmented Generation (RAG) into the LLM pipeline to improve the efficiency and contextual awareness of the attack., 3. Proposes and evaluates an adversarial training-based defense strategy to enhance model robustness against the proposed LAMLAD-style attacks.",
      "summary": "This paper proposes LAMLAD, a novel adversarial attack framework that leverages the generative and reasoning capabilities of Large Language Models (LLMs) to bypass ML-based Android malware classifiers. The method uses a dual-agent LLM architecture with RAG to generate realistic, functionality-preserving feature perturbations, achieving a high attack success rate. The paper also demonstrates that adversarial training can significantly reduce the effectiveness of such attacks, enhancing model robustness.",
      "mindmap": "graph TB\n        A[LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors] --> B[核心问题/Problem: ML-based Android malware detectors are vulnerable to adversarial attacks.]\n        A --> C[主要方法/Method: Proposes LAMLAD, a dual-agent LLM framework with RAG for generating stealthy perturbations.]\n        A --> D[关键结果/Results: Achieves up to 97% attack success rate; adversarial training defense reduces ASR by >30%.]"
    },
    {
      "title": "Feasible strategies in three-way conflict analysis with three-valued ratings",
      "authors": "Jing Liu, Mengjun Hu, Guangming Lang",
      "institution": "Changsha University of Science and Technology, Saint Mary's University",
      "link": "https://arxiv.org/pdf/2512.21420",
      "code": null,
      "tags": [
        "conflict analysis",
        "three-way conflict analysis",
        "feasible strategy",
        "consistency measure",
        "non-consistency measure",
        "weighted agent-issue evaluation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4b2e48e756e98608f4388b841aa7940f0ba7b237737fa314abc4db83fbf680f_w640_q70.webp",
      "contributions": "1. Proposes a novel framework for identifying feasible strategies in conflict resolution from the perspectives of consistency and non-consistency. 2. Introduces weighted consistency and non-consistency measures that incorporate the importance of both agents and issues. 3. Develops algorithms to systematically identify feasible strategies, L-order feasible strategies, and optimal solutions, demonstrating superior performance over existing approaches.",
      "summary": "This paper addresses the gap in formulating actionable strategies for conflict resolution within three-way conflict analysis. It proposes a method that computes agent clique ratings and uses novel weighted consistency and non-consistency measures to identify feasible and optimal strategies. The approach is validated through case studies and shown to outperform conventional conflict analysis models.",
      "mindmap": "graph TB\n        A[Feasible strategies in three-way conflict analysis<br>三向冲突分析中的可行策略] --> B(Problem: Lack of focus on conflict resolution strategies<br>问题: 缺乏对冲突解决策略的关注)\n        A --> C(Method: Weighted consistency/non-consistency measures & algorithms<br>方法: 加权一致/非一致性度量与算法)\n        A --> D(Results: Outperforms conventional approaches, identifies optimal solutions<br>结果: 优于传统方法，识别最优解)"
    },
    {
      "title": "Three-way conflict analysis based on alliance and conflict functions",
      "authors": "Junfang Luo, Mengjun Hu, Guangming Lang, Xin Yang, Keyun Qin",
      "institution": "Southwestern University of Finance and Economics, University of Regina, Changsha University of Science and Technology, Southwest Jiaotong University",
      "link": "https://arxiv.org/pdf/2512.21419",
      "code": null,
      "tags": [
        "decision theory",
        "three-way decision",
        "conflict analysis",
        "alliance function",
        "conflict function",
        "alliance set"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54277009925f58600c765060d6cbc575e96e562e3c9748aa2f54e97b83024e0b_w640_q70.webp",
      "contributions": "1. Proposes a novel separation of the traditional auxiliary function into distinct alliance and conflict functions to clarify semantic interpretation in conflict analysis. 2. Introduces a framework for trisecting agents, issues, and agent pairs based on the new alliance and conflict functions. 3. Explores and applies new concepts such as alliance sets and strategies to solve crucial questions in conflict analysis, demonstrating the model with a real-world application.",
      "summary": "This paper addresses the semantic ambiguity in aggregating traditional three-way conflict analysis functions by proposing a separation into distinct alliance and conflict functions. The method enables clearer trisection of agents, issues, and agent pairs, leading to the exploration of alliance sets and strategies. The main conclusion is that this separation provides a more interpretable and applicable framework for conflict analysis, as illustrated by a real-world example.",
      "mindmap": "graph TB\n        A[Three-way Conflict Analysis Based on Alliance and Conflict Functions] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[传统辅助函数聚合语义模糊/Semantic ambiguity in aggregating traditional auxiliary functions]\n        C --> C1[分离为联盟与冲突函数/Separate into alliance and conflict functions]\n        C --> C2[基于新函数进行三分/Trisec based on new functions]\n        D --> D1[提出联盟集与策略概念/Propose alliance sets and strategies]\n        D --> D2[提供真实应用案例/Provide a real-world application]"
    },
    {
      "title": "Teaching People LLM's Errors and Getting it Right",
      "authors": "Nathan Stringham, Fateme Hashemi Chaleshtori, Xinyuan Yan, Zhichao Xu, Bei Wang, Ana Marasović",
      "institution": "University of Utah",
      "link": "https://arxiv.org/pdf/2512.21422",
      "code": null,
      "tags": [
        "human-ai interaction",
        "overreliance",
        "failure patterns",
        "mental models",
        "user study",
        "meta-labels"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83a262b8daf44fdf951904b9202074fd9db4ef9e9666cd5769ec1d8514053804_w640_q70.webp",
      "contributions": "1. Empirically demonstrated that failure patterns for LLMs do exist by identifying sizable, error-prone meta-label groups in datasets, countering the hypothesis that their absence caused prior teaching failures. 2. Evaluated automated methods for discovering these failure patterns (prompting and embedding-based) and found mixed results, identifying a key bottleneck in the teaching pipeline. 3. Proposed and validated a new metric for teaching effectiveness—assessing a user's ability to anticipate LLM errors using taught patterns—which showed a positive effect, unlike traditional human-AI team accuracy.",
      "summary": "This paper investigates why prior attempts to teach users about LLM failure patterns to reduce overreliance have failed. It finds that failure patterns do exist, but automated methods to discover them are unreliable, and proposes a new user-centric evaluation metric that shows teaching can be effective. The conclusion is that teaching failure patterns is viable but requires better failure-discovery methods and appropriate metrics.",
      "mindmap": "graph TB\n        A[Teaching People LLM’s Errors and Getting it Right] --> B[核心问题/Problem: Users overrely on LLMs due to inaccurate mental models]\n        A --> C[主要方法/Method: Analyze failure pattern existence, test discovery methods, propose new evaluation metric]\n        A --> D[关键结果/Results: Patterns exist, discovery methods are mixed, new metric shows teaching is effective]"
    },
    {
      "title": "Three-way decision with incomplete information based on similarity and satisfiability",
      "authors": "Junfang Luo, Mengjun Hu, Keyun Qin",
      "institution": "Southwest Jiaotong University, University of Regina",
      "link": "https://arxiv.org/pdf/2512.21421",
      "code": null,
      "tags": [
        "rough set theory",
        "three-way decision",
        "incomplete information",
        "similarity degree",
        "satisfiability degree",
        "approximability"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d87784acc1b1cc397b822153c118be23974be9721c3d19c9dfc95fbbaef158e_w640_q70.webp",
      "contributions": "1. Proposes a new measure of similarity degree of objects as a generalization of equivalence relations for handling incomplete information in the computational formulation of three-way decision. 2. Introduces a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability for the conceptual formulation of three-way decision under incomplete information. 3. Proposes novel approaches for three-way decision using approximability of objects and confidence of formulas, pointing out new research directions beyond the common method of similarity classes.",
      "summary": "This paper generalizes the computational and conceptual formulations of three-way decision to handle incomplete information, which is common in real-world applications. For the computational side, it introduces a similarity degree measure and explores decision-making via α-similarity classes and approximability; for the conceptual side, it proposes a satisfiability degree measure and studies approaches using α-meaning sets and confidence. The work extends rough set theory and identifies promising new directions for three-way decision under uncertainty.",
      "mindmap": "graph TB\n        A[Three-Way Decision with Incomplete Information Based on Similarity and Satisfiability] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[处理不完全信息/Handling Incomplete Information]\n        C --> C1[计算式: 相似度/Computational: Similarity Degree]\n        C --> C2[概念式: 可满足度/Conceptual: Satisfiability Degree]\n        C1 --> C1a[α-相似类/α-Similarity Classes]\n        C1 --> C1b[可逼近性/Approximability]\n        C2 --> C2a[α-意义集/α-Meaning Sets]\n        C2 --> C2b[置信度/Confidence]\n        D --> D1[推广两种表述/Generalizes Both Formulations]\n        D --> D2[指出新方向/Points to New Directions]"
    },
    {
      "title": "Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models",
      "authors": "Geoffroy Morlat, Marceau Nahon, Augustin Chartouny, Raja Chatila, Ismael T. Freire, Mehdi Khamassi",
      "institution": "Institute of Intelligent Systems and Robotics, Sorbonne University",
      "link": "https://arxiv.org/pdf/2512.21439",
      "code": null,
      "tags": [
        "computational ethics",
        "moral context",
        "probabilistic clustering",
        "LLM semantics",
        "interpretable prediction",
        "human judgment"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f4abc9f666c2d29dadd77869bddf3f159d0bbc8839c7c0f65bbdb4c29ad40c_w640_q70.webp",
      "contributions": "1. An empirically grounded dataset of 300 moral scenarios with human ternary judgments. 2. A reproducible pipeline (COMETH) combining human judgments, probabilistic context learning, and LLM-based semantic abstraction. 3. An interpretable, context-sensitive moral prediction model that outperforms end-to-end LLM prompting.",
      "summary": "The paper addresses the problem that moral judgments depend heavily on context. It proposes the COMETH framework, which uses probabilistic clustering on human judgment data and LLM-based semantic abstraction to learn and explain action-specific moral contexts. The main conclusion is that COMETH significantly outperforms direct LLM prompting in aligning with human majority judgments while providing interpretable predictions.",
      "mindmap": "graph TB\n        A[COMETH: Learning Interpretable Moral Contexts] --> B[核心问题/Problem: Moral judgments are context-dependent]\n        A --> C[主要方法/Method: Probabilistic clustering + LLM semantics + Human judgments]\n        A --> D[关键结果/Results: Doubles alignment with human judgments vs. LLM prompting]"
    },
    {
      "title": "dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning",
      "authors": "Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu",
      "institution": "University of Washington, University of California, Berkeley",
      "link": "https://arxiv.org/pdf/2512.21446",
      "code": null,
      "tags": [
        "diffusion models",
        "masked diffusion language models",
        "reinforcement learning",
        "parallel decoding",
        "on-policy optimization",
        "unmasking planner"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp",
      "contributions": "1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.",
      "summary": "The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards \"diffusion supremacy\" over autoregressive models.",
      "mindmap": "graph TB\n        A[dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[MDLMs解码慢，速度优势有限/MDLMs decode slowly, limiting speed advantage]\n        C --> C1[基于GRPO的在线强化学习框架/On-policy RL framework based on GRPO]\n        C --> C2[联合优化扩散模型与解掩码规划器/Jointly optimize diffusion model & unmasking planner]\n        D --> D1[提升精度-效率权衡/Improves accuracy-efficiency trade-off]\n        D --> D2[迈向”扩散霸权”/Moving towards ”diffusion supremacy”]"
    },
    {
      "title": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism",
      "authors": "Haotian Lv, Yuhui Zhang, Jiangbo Dai, Hanli Wu, Jiaji Wang, Dawei Wang",
      "institution": "Harbin Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.21452",
      "code": null,
      "tags": [
        "object detection",
        "Ground Penetrating Radar (GPR)",
        "Multi-modal Chain Feature Fusion (MCFF)",
        "Global Attention Mechanism (GAM)",
        "DCGAN",
        "transfer learning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp",
      "contributions": "1. Proposed a DCGAN-based data augmentation strategy to synthesize high-fidelity GPR images, mitigating data scarcity. 2. Designed a novel Multi-modal Chain and Global Attention Network (MCGA-Net) integrating Multi-modal Chain Feature Fusion (MCFF) and a Global Attention Mechanism (GAM) for enhanced defect representation. 3. Utilized MS COCO transfer learning to fine-tune the backbone network, accelerating convergence and improving model generalization.",
      "summary": "This paper addresses the subjective and inefficient interpretation of Ground Penetrating Radar (GPR) images for road defect detection by proposing a comprehensive framework. The method combines DCGAN-based data augmentation, a novel MCGA-Net architecture with feature fusion and attention mechanisms, and transfer learning. The proposed model achieves high precision, recall, and robustness, establishing a new paradigm for automated GPR-based defect detection.",
      "mindmap": "graph TB\n        Root(”Intelligent recognition of GPR road hidden defect images <br/> GPR道路隐蔽病害图像智能识别”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n    \n        Problem --> P1(”Subjective & inefficient GPR interpretation <br/> GPR图像解释主观且低效”)\n        Problem --> P2(”Data scarcity <br/> 数据稀缺”)\n    \n        Method --> M1(”DCGAN-based Data Augmentation <br/> 基于DCGAN的数据增强”)\n        Method --> M2(”MCGA-Net (MCFF + GAM) <br/> MCGA-Net网络”)\n        Method --> M3(”MS COCO Transfer Learning <br/> MS COCO迁移学习”)\n    \n        Results --> R1(”High Performance (Precision 92.8%, mAP@50 95.9%) <br/> 高性能”)\n        Results --> R2(”Robust to noise & weak signals <br/> 对噪声和弱信号鲁棒”)\n        Results --> R3(”New paradigm for automated detection <br/> 自动化检测新范式”)"
    },
    {
      "title": "GPF-Net: Gated Progressive Fusion Learning for Polyp Re-Identification",
      "authors": "Suncheng Xiang, Xiaoyang Wang, Junjie Jiang, Hejia Wang, Dahong Qian",
      "institution": "Shanghai Jiao Tong University, Peking University, Shanghai Fifth People's Hospital",
      "link": "https://arxiv.org/pdf/2512.21476",
      "code": "https://github.com/JeremyXSC/GPF-Net",
      "tags": [
        "medical image retrieval",
        "polyp re-identification",
        "gated progressive fusion",
        "multimodal feature fusion"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75fe09ad1f753b61f2c30ab37c16d0deef5060ca95658846bc6dcaf6bb4c53f9_w640_q70.webp",
      "contributions": "1) Proposes a novel multimodal feature fusion framework named GPF-Net for polyp re-identification. 2) Introduces a gated progressive fusion strategy for layer-wise refinement of semantic information through multi-level feature interactions. 3) Demonstrates state-of-the-art performance on standard benchmarks, showing the benefit of multimodal fusion over unimodal methods.",
      "summary": "This paper addresses the challenge of colonoscopic polyp re-identification, where coarse high-level features harm small object matching. The authors propose GPF-Net, a Gated Progressive Fusion network that selectively fuses multi-level features using gates. Experiments show this multimodal approach outperforms state-of-the-art unimodal ReID models.",
      "mindmap": "graph TB\n        A[GPF-Net: Gated Progressive Fusion Learning for Polyp Re-Identification] --> B[核心问题/Problem: Coarse high-level features lead to inferior results for small polyps]\n        A --> C[主要方法/Method: Gated Progressive Fusion network for selective, multi-level feature fusion]\n        A --> D[关键结果/Results: Outperforms unimodal models, benefits of multimodal fusion strategy]"
    },
    {
      "title": "Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism",
      "authors": "Xinglin Pan, Shaohuai Shi, Wenxiang Lin, Yuxin Wang, Zhenheng Tang, Wei Wang, Xiaowen Chu",
      "institution": "The Hong Kong University of Science and Technology (Guangzhou), Harbin Institute of Technology (Shenzhen), Hong Kong Baptist University, The Hong Kong University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.21487",
      "code": null,
      "tags": [
        "llm inference",
        "mixture-of-experts (MoE)",
        "disaggregated expert parallelism (DEP)",
        "task scheduling",
        "inference throughput",
        "fine-grained pipelining"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp",
      "contributions": "1) Partitioning intensive computation and communication tasks into smaller, fine-grained tasks to enable pipelining, including support for shared experts. 2) Formulating a fine-grained task scheduling optimization problem that supports variable task granularity and ordering. 3) Developing an efficient solver to navigate the large solution space and derive a near-optimal task schedule.",
      "summary": "This paper addresses the memory-intensive inference problem in Mixture-of-Experts (MoE) models by proposing FinDEP, a fine-grained task scheduling algorithm for Disaggregated Expert Parallelism (DEP). FinDEP improves inference throughput by maximizing task overlap through computational partitioning and optimized scheduling. Experiments on systems with up to 32 GPUs show throughput improvements of up to 1.61x over prior methods.",
      "mindmap": "graph TB\n        A[FinDEP: Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[MoE推理内存密集，现有DEP调度效率低/MoE inference is memory-intensive, existing DEP scheduling is inefficient]\n        C --> C1[细粒度任务划分与调度优化/Fine-grained task partitioning and scheduling optimization]\n        D --> D1[吞吐量最高提升1.61倍/Throughput improved by up to 1.61x]"
    },
    {
      "title": "Oogiri-Master: Benchmarking Humor Understanding via Oogiri",
      "authors": "Soichiro Murakami, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura",
      "institution": "CyberAgent, Nara Institute of Science and Technology, Institute of Science Tokyo",
      "link": "https://arxiv.org/pdf/2512.21494",
      "code": null,
      "tags": [
        "humor understanding",
        "Oogiri",
        "benchmark",
        "linguistic analysis",
        "incongruity resolution",
        "insight-augmented prompting"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41486d2e77493633c6cf66d7f5134ccf646d1df0d17e6d258bc98cc3132ef02b_w640_q70.webp",
      "contributions": "1. Introduces Oogiri-Master, a benchmark for rigorous evaluation of humor understanding in LLMs, and Oogiri-Corpus, a dataset with ~100 diverse responses per prompt and independent human ratings to reduce bias. 2. Conducts quantitative analysis of linguistic factors (e.g., text length, ambiguity, incongruity resolution) to derive objective metrics for predicting human funniness judgments. 3. Benchmarks LLMs and human baselines, showing state-of-the-art models approach human performance and that insight-augmented prompting improves model humor understanding.",
      "summary": "This paper addresses the challenge of evaluating humor understanding in LLMs by introducing the Oogiri-Master benchmark and Oogiri-Corpus dataset, which enable rigorous analysis of funniness through diverse responses and independent human ratings. It quantitatively analyzes linguistic factors to derive objective metrics and benchmarks LLMs, demonstrating that advanced models approach human-level performance and benefit from insight-augmented prompting. The work provides a principled basis for advancing humor understanding in AI.",
      "mindmap": "graph TB\n        A[Oogiri-Master: Benchmarking Humor Understanding via Oogiri] --> B[核心问题/Problem: What makes Oogiri responses funny to humans?]\n        A --> C[主要方法/Method: Introduce Oogiri-Master benchmark and Oogiri-Corpus dataset with diverse responses and independent ratings]\n        A --> D[关键结果/Results: LLMs approach human performance; insight-augmented prompting improves results]"
    },
    {
      "title": "LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis",
      "authors": "Fanwei Zeng, Changtao Miao, Jing Huang, Zhiya Tan, Shutao Gong, Xiaoming Yu, Yang Wang, Huazhe Tan, Weibin Yao, Jianshu Li",
      "institution": "Ant Group, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.21482",
      "code": null,
      "tags": [
        "multimodal forgery detection",
        "visual-textual co-reasoning",
        "cross-cues-aware chain of thought (CCT)",
        "GRPO-based optimization"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/138f8fcb4727c77950b23146e1184851aa8b8cea95056b1d6b161c37e231ad80_w640_q70.webp",
      "contributions": "1. Proposed LogicLens, a unified framework for visual-textual co-reasoning that jointly performs detection, grounding, and explanation for text-centric forgery analysis. 2. Introduced a Cross-Cues-aware Chain of Thought (CCT) mechanism for iterative cross-validation of visual and textual cues, and a weighted multi-task reward function for GRPO-based optimization. 3. Created the RealText dataset with 5,397 images and fine-grained annotations using a novel PR² (Perceiver, Reasoner, Reviewer) multi-agent annotation pipeline.",
      "summary": "This paper introduces LogicLens, a unified visual-textual co-reasoning framework for analyzing text-centric forgeries. It uses a novel Cross-Cues-aware Chain of Thought mechanism and multi-task optimization to jointly handle detection, grounding, and explanation. Experiments show LogicLens achieves state-of-the-art performance, significantly outperforming specialized frameworks and other MLLMs in zero-shot and dense-text scenarios.",
      "mindmap": "graph TB\n        A[LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[文本中心伪造威胁/Sophisticated text-centric forgeries]\n        B --> B2[现有方法缺乏推理/Current methods lack reasoning]\n        B --> B3[任务割裂/Tasks treated as discrete]\n        C --> C1[统一框架/Unified Visual-Textual Co-reasoning framework]\n        C --> C2[跨线索思维链/Cross-Cues-aware Chain of Thought (CCT)]\n        C --> C3[多任务奖励函数/Weighted multi-task reward function]\n        C --> C4[PR²标注管道/PR² annotation pipeline]\n        C --> C5[RealText数据集/RealText dataset]\n        D --> D1[零样本评估领先/Superior zero-shot performance]\n        D --> D2[密集文本数据集领先/Lead on dense-text dataset]\n        D --> D3[公开资源/Public dataset, model, code]"
    },
    {
      "title": "MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding",
      "authors": "Aiwei Zhang, Arvind Pillai, Andrew Campbell, Nicholas C. Jacobson",
      "institution": "Dartmouth College",
      "link": "https://arxiv.org/pdf/2512.21506",
      "code": null,
      "tags": [
        "multi-modal training",
        "wearable sensing",
        "actigraphy encoder",
        "projection module",
        "frozen LLM",
        "behavioral summarization"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp",
      "contributions": "1. Introduces MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs) for free-text generation of daily behavioral summaries. 2. Constructs a novel, large-scale dataset of 54,383 (actigraphy, text) pairs derived from real-world NHANES recordings. 3. Demonstrates superior performance over prompt-based baselines in semantic fidelity and lexical accuracy, with qualitative analysis showing the model captures circadian structure and behavioral transitions.",
      "summary": "The paper addresses the challenge of generating natural language summaries from raw physiological signals like actigraphy. It proposes MotionTeller, a framework that integrates a pretrained actigraphy encoder with a frozen LLM via a projection module. The model, trained on a novel dataset, outperforms baselines in generating fluent, human-centered descriptions of daily behavior.",
      "mindmap": "graph TB\n        A[MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs] --> B[核心问题/Problem: How to generate natural language summaries from raw physiological signals like actigraphy?]\n        A --> C[主要方法/Method: Combines a pretrained actigraphy encoder and a projection module to map behavioral embeddings into a frozen LLM's token space.]\n        A --> D[关键结果/Results: Achieves high semantic fidelity (BERTScore-F1=0.924) and lexical accuracy (ROUGE-1=0.722), outperforming baselines by 7%.]"
    },
    {
      "title": "DiverseGRPO: Mitigating Mode Collapse in Image Generation via Diversity-Aware GRPO",
      "authors": "Henglin Liu, Huijuan Huang, Jing Wang, Chang Liu, Xiu Li, Xiangyang Ji",
      "institution": "Tsinghua University, Kuaishou Technology (Kling Team), Sun Yat-sen University",
      "link": "https://arxiv.org/pdf/2512.21514",
      "code": null,
      "tags": [
        "diffusion models",
        "GRPO",
        "mode collapse",
        "diversity-aware reward",
        "spectral clustering",
        "structure-aware regularization"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp",
      "contributions": "1. Identifies and analyzes the mode collapse problem in GRPO-based image generation from both reward modeling and generation dynamics perspectives. 2. Proposes a distributional creativity bonus reward based on semantic grouping via spectral clustering to encourage novel visual modes. 3. Introduces a structure-aware regularization that applies stronger constraints during early-stage denoising to preserve diversity without sacrificing quality optimization.",
      "summary": "This paper addresses the mode collapse problem in GRPO-based image generation, where models produce homogenized outputs. The proposed DiverseGRPO method introduces a diversity-aware reward based on semantic clustering and a structure-aware regularization to preserve generation diversity. Experiments show the method significantly improves semantic diversity while maintaining image quality, establishing a better quality-diversity trade-off.",
      "mindmap": "graph TB\n        A[DiverseGRPO: Mitigating Mode Collapse] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[GRPO导致模式崩溃/GRPO causes mode collapse]\n        B1 --> B2[缺乏视觉多样性/Lacks visual diversity]\n        C --> C1[奖励层面: 分布创造力奖励/Reward Level: Distributional Creativity Bonus]\n        C --> C2[生成层面: 结构感知正则化/Generation Level: Structure-Aware Regularization]\n        C1 --> C3[基于语义分组的谱聚类/Spectral Clustering for Semantic Grouping]\n        D --> D1[语义多样性提升13%-18%/13%-18% Semantic Diversity Improvement]\n        D --> D2[建立新的帕累托前沿/Establishes New Pareto Frontier]"
    },
    {
      "title": "Selective LLM-Guided Regularization for Enhancing Recommendation Models",
      "authors": "Shanglin Yang, Zhan Shi",
      "institution": "Sichuan University",
      "link": "https://arxiv.org/pdf/2512.21526",
      "code": null,
      "tags": [
        "recommender systems",
        "selective regularization",
        "knowledge distillation",
        "cold-start",
        "long-tail",
        "gating mechanism"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76336a3d123794e83843c14c4b799afd0817948ee9dfeb2f6f19ce776f183796_w640_q70.webp",
      "contributions": "1. Proposes a selective LLM-guided regularization framework (S-LLMR) that activates LLM supervision only when a gating mechanism predicts the LLM to be reliable, addressing the issue of inaccurate global distillation. 2. Introduces a trainable gating mechanism informed by user history length, item popularity, and model uncertainty to dynamically decide when to apply LLM-based pairwise ranking supervision. 3. Demonstrates through experiments that the method improves overall accuracy and yields substantial gains in cold-start and long-tail recommendation scenarios, outperforming global distillation baselines.",
      "summary": "The paper addresses the problem of leveraging large language models (LLMs) for recommendation without suffering from their high cost and unreliability in certain scenarios. It proposes Selective LLM-Guided Regularization (S-LLMR), a model-agnostic framework that uses a gating mechanism to selectively apply LLM-based supervision only when the LLM is predicted to be reliable. Experiments show this approach improves recommendation accuracy, especially for cold-start users and long-tail items, outperforming methods that uniformly distill LLM knowledge.",
      "mindmap": "graph TB\n        A[Selective LLM-Guided Regularization<br>选择性LLM引导正则化] --> B(Problem/核心问题<br>LLMs as standalone recommenders are costly/unreliable;<br>Global distillation forces imitation of inaccurate LLM guidance.)\n        A --> C(Method/主要方法<br>Selective LLM-Guided Regularization (S-LLMR):<br>Trainable gating mechanism activates LLM supervision only when reliable.)\n        A --> D(Results/关键结果<br>Improves overall accuracy;<br>Substantial gains in cold-start & long-tail regimes.)"
    },
    {
      "title": "Hierarchy-Aware Fine-Tuning of Vision-Language Models",
      "authors": "Jiayu Li, Rajesh Gangireddy, Samet Akcay, Wei Cheng, Juhua Hu",
      "institution": "University of Washington, Intel",
      "link": "https://arxiv.org/pdf/2512.21529",
      "code": null,
      "tags": [
        "multimodal learning",
        "hierarchical classification",
        "vision-language models",
        "efficient fine-tuning",
        "LoRA",
        "Tree-Path KL Divergence"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88b60d2fc3dd0ad92b5ac8857f844fed2dbe51e280dfb702c26028d91c14fd92_w640_q70.webp",
      "contributions": "1. Proposes an efficient hierarchy-aware fine-tuning framework for Vision-Language Models (VLMs) that updates only a few parameters. 2. Introduces two novel loss functions: Tree-Path KL Divergence (TP-KL) for vertical consistency along label paths and Hierarchy-Sibling Smoothed Cross-Entropy (HiSCE) for horizontal consistency among sibling classes. 3. Demonstrates consistent improvements in Full-Path Accuracy and reduced Tree-based Inconsistency Error across multiple hierarchical benchmarks with minimal parameter overhead.",
      "summary": "This paper addresses the problem of adapting large Vision-Language Models (VLMs) to hierarchical classification tasks efficiently. The proposed method combines two novel hierarchy-aware loss functions (TP-KL and HiSCE) with lightweight LoRA adaptation to enforce structural consistency in predictions. Experiments show the approach improves accuracy and reduces inconsistency across taxonomy levels with minimal computational cost.",
      "mindmap": "graph TB\n        Root(”Hierarchy-Aware Fine-Tuning of Vision-Language Models”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”VLMs适应层级分类效率低/VLMs inefficient for hierarchical classification”)\n        Problem --> P2(”标准方法预测不一致/Standard methods produce inconsistent predictions”)\n        Method --> M1(”提出层级感知微调框架/Propose hierarchy-aware fine-tuning framework”)\n        Method --> M2(”结合TP-KL与HiSCE损失/Combine TP-KL and HiSCE losses”)\n        Method --> M3(”集成轻量级LoRA适配/Integrate lightweight LoRA adaptation”)\n        Results --> R1(”提升全路径精度/Improves Full-Path Accuracy”)\n        Results --> R2(”降低不一致性错误/Reduces Tree-based Inconsistency Error”)\n        Results --> R3(”参数开销最小/Minimal parameter overhead”)"
    },
    {
      "title": "Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model",
      "authors": "Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo",
      "institution": "Peking University, Harbin Institute of Technology, Shenzhen",
      "link": "https://arxiv.org/pdf/2512.21540",
      "code": null,
      "tags": [
        "llm inference",
        "adaptive length penalty",
        "reinforcement learning",
        "constrained optimization",
        "Lagrangian primal-dual",
        "reasoning efficiency"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp",
      "contributions": "1. Proposes Leash, a reinforcement learning framework that formulates length control as a constrained optimization problem and uses a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. 2. Introduces an adaptive mechanism that intensifies the penalty when generations exceed the target length and relaxes it when they are shorter, guiding models toward concise reasoning without sacrificing performance. 3. Demonstrates experimentally that Leash reduces average reasoning length by 60% across diverse tasks while maintaining competitive performance, offering a practical paradigm for efficient LLMs.",
      "summary": "The paper addresses the problem of LLMs producing overly long reasoning traces, which increases computational cost. It proposes Leash, an adaptive reinforcement learning framework that dynamically adjusts length penalties using a Lagrangian method to balance conciseness and accuracy. Experiments show it reduces reasoning length by 60% while maintaining performance, providing an effective approach for efficient LLM reasoning.",
      "mindmap": "graph TB\n        A[LEASH: Adaptive Length Penalty and Reward Shaping] --> B[核心问题/Problem: LLMs生成过长推理链，计算成本高/Fixed penalties fail to adapt, leading to suboptimal accuracy-conciseness trade-offs]\n        A --> C[主要方法/Method: 自适应强化学习框架，使用拉格朗日对偶方法动态调整惩罚系数/Adaptive RL framework with Lagrangian primal-dual for dynamic penalty adjustment]\n        A --> D[关键结果/Results: 平均推理长度减少60%，性能保持竞争力/Average reasoning length reduced by 60% while maintaining competitive performance across tasks]"
    },
    {
      "title": "Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures",
      "authors": "Hua Shen, Tiffany Knearem, Divy Thakkar, Pat Pataranutaporn, Anoop Sinha, Yike, Jenny T. Liang, Lama Ahmad, Tanu Mitra, Brad A. Myers, Yang Li",
      "institution": "NYU Shanghai, MBZUAI, Google, Massachusetts Institute of Technology, Carnegie Mellon University, OpenAI, University of Washington, Google DeepMind",
      "link": "https://arxiv.org/pdf/2512.21551",
      "code": null,
      "tags": [
        "human-ai interaction",
        "bidirectional alignment",
        "value-centered design",
        "interactive alignment"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp",
      "contributions": "1. Proposes a shift from unidirectional to bidirectional human-AI alignment, framing it as a dynamic, reciprocal co-adaptation process. 2. Emphasizes embedding human and societal values into AI alignment research through value-centered design. 3. Aims to establish an interdisciplinary research agenda for responsible, reciprocal human-AI futures through collaborative workshop activities.",
      "summary": "This workshop paper identifies the inadequacy of traditional, one-way AI alignment and proposes a bidirectional human-AI alignment framework where humans and AI co-adapt through interaction and value-centered design. It aims to bring together interdisciplinary researchers to explore methods for interactive alignment and societal impact evaluation. The main conclusion is the need for a shared agenda to advance responsible, reciprocal collaboration between humans and AI systems.",
      "mindmap": "graph TB\n        A[Human-AI Interaction Alignment] --> B[核心问题/Problem: Unidirectional AI alignment is inadequate for dynamic human-AI interaction]\n        A --> C[主要方法/Method: Bidirectional alignment via value-centered design, interaction, and evaluation]\n        A --> D[关键结果/Results: Establishes agenda for reciprocal, responsible human-AI futures]"
    },
    {
      "title": "Bidirectional Human-AI Alignment in Education for Trustworthy Learning Environments",
      "authors": "Hua Shen",
      "institution": "NYU Shanghai, New York University",
      "link": "https://arxiv.org/pdf/2512.21552",
      "code": null,
      "tags": [
        "ai for education",
        "human-ai alignment",
        "trustworthy ai",
        "adaptive learning",
        "educational technology",
        "ai ethics"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7f40fe114da7bae34b09e44db18fa32bb4f64e57bd01e75e96afc80c2ddc136_w640_q70.webp",
      "contributions": "1. Proposes the novel concept of \"bidirectional human-AI alignment\" for education, emphasizing mutual adaptation between humans and AI systems. 2. Explores the evolution of AI's role in education from a support tool to a collaborative partner, analyzing its impact on teacher roles and student agency. 3. Provides actionable strategies for policymakers, developers, and educators to ensure AI advances equity, transparency, and human flourishing in learning environments.",
      "summary": "This paper addresses the risks of AI in education, such as bias and loss of autonomy, by proposing the concept of bidirectional human-AI alignment. The method involves not only embedding human values into AI but also equipping educators and students to guide these technologies. It concludes that reframing AI adoption as a process of mutual adaptation is key to creating trustworthy learning environments where humans and AI can grow together.",
      "mindmap": "graph TB\n        A[论文标题: Bidirectional Human-AI Alignment in Education] --> B[核心问题/Problem: AI in education introduces risks to equity, privacy, and autonomy.]\n        A --> C[主要方法/Method: Proposes bidirectional alignment: embedding human values into AI and equipping humans to interpret/guide AI.]\n        A --> D[关键结果/Results: Envisions a future of mutual adaptation where AI advances equity, transparency, and human flourishing.]"
    },
    {
      "title": "Exploration of Reproducible Generated Image Detection",
      "authors": "Yihang Duan",
      "institution": "Not explicitly stated in the provided content. (Author name only, no affiliation or email domain provided)",
      "link": "https://arxiv.org/pdf/2512.21562",
      "code": null,
      "tags": [
        "image forensics",
        "AIGC detection",
        "reproducibility",
        "generalizability",
        "diffusion models",
        "binary classification"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c9df3d6873df2ea90e378adf52625583637b76319eb9a55ebf11b8f17abf1fc_w640_q70.webp",
      "contributions": "1. Identifies and analyzes the root causes of poor reproducibility in AIGC image detection research, citing omitted experimental details and overfitting to generator-specific features. 2. Provides empirical evidence for the reproducibility issue by constructing a test dataset and reproducing a representative detection method, demonstrating performance drops under cross-generator testing. 3. Proposes reference directions for the research community to improve reproducibility and generalizability, such as more comprehensive disclosure of experimental details.",
      "summary": "This paper investigates the reproducibility and generalizability challenges in AI-Generated Content (AIGC) image detection. By reviewing key literature, building a test dataset, and reproducing a detection method, it identifies causes like omitted experimental details and model overfitting. The study concludes that while basic performance can be reproduced, detection fails when preprocessing disrupts key features or when testing across different generators, highlighting the need for better methodological disclosure and robustness.",
      "mindmap": "graph TB\n        A[Exploration of Reproducible Generated Image Detection] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Poor Reproducibility & Generalizability]\n        C[主要方法/Method<br>Literature Review, Dataset Construction, Method Reproduction]\n        D[关键结果/Results<br>Performance Drops with Preprocessing/Cross-Generator Tests]"
    },
    {
      "title": "Towards Long-window Anchoring in Vision-Language Model Distillation",
      "authors": "Haoyi Zhou, Shuo Li, Tianyu Chen, Qi Song, Chonghan Gao, Jianxin Li",
      "institution": "Beihang University, Zhongguancun Laboratory",
      "link": "https://arxiv.org/pdf/2512.21576",
      "code": null,
      "tags": [
        "multi-modal training",
        "knowledge distillation",
        "long-context",
        "rotary position embeddings (RoPE)",
        "attention mechanism",
        "vision-language models"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4663870a97f8c352e6cd352d0f9f9be365648a5545642796d256fa99c7ddcd4_w640_q70.webp",
      "contributions": "1. Identifies the problem of limited effective context windows in small, distilled vision-language models despite using identical positional embeddings and architectures as their larger counterparts. 2. Proposes LAid, a novel distillation method featuring progressive distance-weighted attention matching and learnable RoPE response gain modulation to transfer long-range attention mechanisms. 3. Demonstrates that LAid-distilled models achieve significantly longer effective context windows (up to 3.2x) while maintaining performance on standard benchmarks, and provides spectral analysis showing successful transfer of low-frequency attention components.",
      "summary": "This paper addresses the problem that small, distilled vision-language models have much shorter effective context windows than their large teacher models. The authors propose LAid, a new distillation method that transfers long-range attention capabilities via progressive attention matching and learnable RoPE modulation. Their method successfully extends the context window of small models by up to 3.2 times while preserving performance on standard benchmarks.",
      "mindmap": "graph TB\n        A[Towards Long-window Anchoring in Vision-Language Model Distillation] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Small distilled VLMs have limited effective context windows]\n        C[主要方法/Method: LAid - Progressive attention matching & learnable RoPE modulation]\n        D[关键结果/Results: Achieves up to 3.2x longer context, maintains benchmark performance]"
    },
    {
      "title": "NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent",
      "authors": "Ali Sahami, Sudhanshu Garg, Andrew Wang, Chaitanya Kulkarni, Farhad Farahani, Sean Yun-Shiuan Chuang, Jian Wan, Srinivasan Manoharan, Uma Kona, Nitin Sharma, Linsey Pang, Prakhar Mehrotra, Jessica Clark, Mark Moyou",
      "institution": "PayPal AI, NVIDIA",
      "link": "https://arxiv.org/pdf/2512.21578",
      "code": null,
      "tags": [
        "agent system",
        "NeMo Framework",
        "LoRA",
        "Nemotron SLM",
        "hyperparameter sweep",
        "multi-agent system"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90dda98c8c5c5f9d75ede0c681c9024dc5973d432f246b90eed23aad0a03c916_w640_q70.webp",
      "contributions": "1. The first application of NVIDIA's NeMo Framework to optimize commerce-specific agents. 2. An LLM-powered fine-tuning strategy for retrieval-focused commerce tasks. 3. A demonstration of significant latency and cost improvements while maintaining agent quality, providing a scalable framework for multi-agent system optimization in production e-commerce.",
      "summary": "This paper presents the optimization of PayPal's Commerce Agent, a multi-agent system, by fine-tuning a Nemotron small language model using NVIDIA's NeMo Framework and LoRA. The method involved systematic hyperparameter sweeps to improve the performance-critical search component. The results show that the fine-tuned model effectively resolves the key latency issue in the retrieval component, which accounted for over 50% of response time, while maintaining or enhancing overall system performance.",
      "mindmap": "graph TB\n        Root[”NEMO-4-PAYPAL: Empowering PayPal's Commerce Agent”] --> Problem[”核心问题/Problem”]\n        Root --> Method[”主要方法/Method”]\n        Root --> Results[”关键结果/Results”]\n        Problem --> P1[”Search Latency/搜索延迟”]\n        P1 --> P2[”>50% Response Time/超过50%响应时间”]\n        Method --> M1[”Fine-tuning with NeMo/使用NeMo微调”]\n        M1 --> M2[”LoRA on Nemotron SLM/在Nemotron SLM上使用LoRA”]\n        M2 --> M3[”Hyperparameter Sweep/超参数扫描”]\n        Results --> R1[”Latency & Cost Improvement/延迟与成本改进”]\n        Results --> R2[”Maintained Agent Quality/保持代理质量”]\n        Results --> R3[”Scalable Framework/可扩展框架”]"
    },
    {
      "title": "A Unified Definition of Hallucination, Or: It's the World Model, Stupid",
      "authors": "Emmy Liu, Varun Gangal, Chelsea Zou, Xiaoqi Huang, Michael Yu, Alex Chang, Zhuofu Tao, Sachin Kumar, Steven Y. Feng",
      "institution": "Carnegie Mellon University, Stanford University, The Ohio State University, Patronus AI, DegenAI Labs, Independent Researchers",
      "link": "https://arxiv.org/pdf/2512.21577",
      "code": null,
      "tags": [
        "hallucination detection & evaluation",
        "hallucination",
        "world modeling",
        "knowledge conflict",
        "benchmark",
        "language model evaluation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e2cc31121f769cca7464239d4aa27b26c8c4bc903970a4833fbebac56dc9b85_w640_q70.webp",
      "contributions": "1. Proposes a unified definition of hallucination as inaccurate internal world modeling that is observable to the user, synthesizing prior definitions. 2. Provides a framework for analyzing hallucinations by varying the reference world model and knowledge conflict policy, clarifying what constitutes a hallucination versus other error types. 3. Outlines plans for a family of benchmarks based on synthetic, fully-specified world models to stress-test and improve the world modeling components of language models.",
      "summary": "This paper argues that the persistent problem of hallucination in language models stems from inaccurate internal world modeling. It unifies various historical definitions under this core concept and proposes a framework for clearer evaluation. The authors conclude by sketching plans for new benchmarks to rigorously test and improve language models' world modeling capabilities.",
      "mindmap": "graph TB\n        Root[”A Unified Definition of Hallucination / 幻觉的统一定义”] --> Problem[”核心问题/Problem”]\n        Root[”A Unified Definition of Hallucination / 幻觉的统一定义”] --> Method[”主要方法/Method”]\n        Root[”A Unified Definition of Hallucination / 幻觉的统一定义”] --> Results[”关键结果/Results”]\n        Problem --> P1[”Hallucination persists in LLMs / 幻觉在LLM中持续存在”]\n        Method --> M1[”Unified definition: inaccurate world modeling / 统一定义：不准确的世界建模”]\n        Method --> M2[”Framework: reference world & conflict policy / 框架：参考世界与冲突策略”]\n        Results --> R1[”Clarifies evaluation & terminology / 澄清评估与术语”]\n        Results --> R2[”Proposes new benchmark plans / 提出新基准计划”]"
    },
    {
      "title": "A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning",
      "authors": "Zelin Zang, Wenyi Gu, Siqi Ma, Dan Yang, Yue Shen, Zhu Zhang, Guohui Fan, Wing-Kuen Ling, Fuji Yang",
      "institution": "Tsientang Institute of Advanced Study (TIAS), Westlake University, Ant Group, China-Japan Friendship Hospital",
      "link": "https://arxiv.org/pdf/2512.21583",
      "code": null,
      "tags": [
        "multi-modal inference",
        "vision-language model",
        "logic tree reasoning",
        "medical multimodal diagnosis",
        "explainable AI",
        "LLaVA"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b6b8d6d34a614d3cb042f13334dede18494914ca29d6f0fd6f4467f789871f82_w640_q70.webp",
      "contributions": "1. Proposes a diagnostic framework integrating vision-language alignment with logic-regularized reasoning to enhance reliability. 2. Introduces a reasoning controller and logic tree generator to decompose tasks and assemble verifiable conclusions, improving interpretability. 3. Demonstrates improved diagnostic accuracy and more interpretable reasoning traces on multimodal medical benchmarks like MedXpertQA.",
      "summary": "The paper addresses the problem of unreliable reasoning and hallucinations in existing multimodal medical AI models. It proposes a diagnostic framework built on LLaVA that combines vision-language alignment with logic-regularized reasoning to generate verifiable conclusions via logic trees. Evaluations show the method improves diagnostic accuracy and yields more interpretable reasoning traces, advancing trustworthy multimodal medical AI.",
      "mindmap": "graph TB\n        A[医学多模态诊断框架<br/>Medical Multimodal Diagnostic Framework] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有模型幻觉与推理不一致<br/>Existing Models: Hallucinations & Inconsistent Reasoning]\n        C --> C1[结合视觉语言对齐与逻辑树推理<br/>Vision-Language Alignment + Logic Tree Reasoning]\n        D --> D1[提升诊断准确性与可解释性<br/>Improved Diagnostic Accuracy & Interpretability]"
    },
    {
      "title": "LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model",
      "authors": "Yinfu Feng, Yanjing Wu, Rong Xiao, Xiaoyi Zen",
      "institution": "Alibaba Group",
      "link": "https://arxiv.org/pdf/2512.21595",
      "code": null,
      "tags": [
        "llm inference",
        "item-to-item recommendation",
        "data-centric",
        "long-tail items",
        "data augmentation",
        "data filtering"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cb08ea9b26b612493e4d48e7db88c46a869c2050c94d47b75488adcaf6ddfa9_w640_q70.webp",
      "contributions": "1. Proposes LLM-I2I, a data-centric framework that leverages Large Language Models to enhance I2I recommendation models without altering their architecture. 2. Introduces an LLM-based data generator to synthesize user-item interactions, specifically targeting long-tail items to alleviate data sparsity. 3. Designs an LLM-based data discriminator to filter out noisy interactions from both real and synthetic data, improving overall data quality for training.",
      "summary": "The paper addresses data sparsity and noise problems in Item-to-Item (I2I) recommendation systems by proposing LLM-I2I, a data-centric framework that uses an LLM to generate synthetic interactions for long-tail items and filter noisy data. The refined data is then used to train existing I2I models. Experimental results on industrial and academic datasets show significant improvements in recommendation accuracy, especially for long-tail items, and deployment on a large e-commerce platform led to measurable gains in recall and gross merchandise value.",
      "mindmap": "graph TB\n        A[LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[数据稀疏与噪声/Data Sparsity & Noise]\n        C --> C1[LLM数据生成器/LLM-based Data Generator]\n        C --> C2[LLM数据判别器/LLM-based Data Discriminator]\n        C1 --> C3[合成交互数据/Synthesize Interaction Data]\n        C2 --> C4[过滤噪声数据/Filter Noisy Data]\n        C3 & C4 --> C5[融合数据训练I2I模型/Fuse Data to Train I2I Model]\n        D --> D1[提升推荐准确率/Improves Recommendation Accuracy]\n        D --> D2[提升长尾物品性能/Better for Long-tail Items]\n        D --> D3[线上指标提升/Online Metric Improvements (RN+6.02%, GMV+1.22%)]"
    },
    {
      "title": "AMS-IO-Bench and AMS-IO-Agent: Benchmarking and Structured Reasoning for Analog and Mixed-Signal Integrated Circuit Input/Output Design",
      "authors": "Zhishuai Zhang, Xintian Li, Shilong Liu, Aodong Zhang, Lu Jie, Nan Sun",
      "institution": "Tsinghua University, Princeton University",
      "link": "https://arxiv.org/pdf/2512.21613",
      "code": "https://github.com/Arcadia-1/AMS-IO-Agent",
      "tags": [
        "agent system",
        "AMS IC design",
        "LLM-based agent",
        "structured reasoning",
        "design automation",
        "I/O ring generation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7205181105fdcb012bb4c8c5b3cce6565751edc220003d3784f6dbf648ee893a_w640_q70.webp",
      "contributions": "1. Proposed AMS-IO-Agent, a domain-specialized LLM-based agent for structure-aware I/O subsystem generation in AMS ICs. 2. Introduced AMS-IO-Bench, a benchmark for wirebond-packaged AMS I/O ring automation. 3. Demonstrated the first reported human-agent collaborative AMS IC design where an LLM agent's output was directly used in a silicon tape-out, achieving over 70% DRC+LVS pass rate and reducing design time from hours to minutes.",
      "summary": "This paper addresses the labor-intensive and non-reusable nature of analog and mixed-signal (AMS) integrated circuit I/O design by proposing AMS-IO-Agent, an LLM-based agent that uses structured domain knowledge and intent structuring to automate the process. The method connects natural language design intent to industrial deliverables and is evaluated on a new benchmark, AMS-IO-Bench. The agent significantly outperforms baseline LLMs, achieves a high verification pass rate, and its generated I/O ring was successfully fabricated, demonstrating practical effectiveness in real design flows.",
      "mindmap": "graph TB\n        A[AMS-IO-Bench and AMS-IO-Agent<br>论文标题/Paper Title] --> B[手动AMS I/O设计费时且不可复用<br>核心问题/Problem: Manual AMS I/O design is time-consuming and non-reusable]\n        A --> C[提出基于LLM的智能体与结构化推理框架<br>主要方法/Method: Proposes an LLM-based agent and structured reasoning framework]\n        A --> D[验证通过率>70%，设计时间从小时减至分钟，成功流片<br>关键结果/Results: >70% pass rate, design time reduced from hours to minutes, successful tape-out]"
    },
    {
      "title": "Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design",
      "authors": "Takahide Suzuki, Kazuki Nakanishi, Takashi Fujiwara, Hideyuki Shimizu",
      "institution": "Institute of Science Tokyo, Kyoto University",
      "link": "https://arxiv.org/pdf/2512.21623",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent platform",
        "knowledge graph",
        "physiologically based pharmacokinetic (PBPK) simulations",
        "autonomous execution",
        "human-in-the-loop"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbd4a841925fb9129111928c81fe29ac7016c26df168e9b4ca87c8782a692d5e_w640_q70.webp",
      "contributions": "1. Introduces OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine for drug design. 2. Features an architecture with specialized agents (Biologist, Chemist, Pharmacologist) governed by an Orchestrator, which actively execute simulations and reason over results to create a dynamic feedback loop for iterative optimization. 3. Democratizes therapeutic design by transforming drug discovery from a stochastic search into a programmable, evidence-based engineering discipline through the integration of autonomous execution with human guidance.",
      "summary": "The paper addresses the challenge of fragmented and passive tools in therapeutic discovery by proposing OrchestRA, a multi-agent platform where specialized AI agents autonomously execute and reason over biological, chemical, and pharmacological tasks. This creates a dynamic feedback loop for iterative drug candidate optimization, guided by human input. The conclusion is that this approach transforms drug discovery into a more programmable and evidence-based engineering process.",
      "mindmap": "graph TB\n        A[Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Fragmented domains & execution gap<br>AI as passive assistants]\n        C[主要方法/Method<br>OrchestRA Multi-Agent Platform<br>Agents execute & reason<br>Human-in-the-loop]\n        D[关键结果/Results<br>Autonomous discovery engine<br>Dynamic feedback loop<br>Programmable evidence-based design]"
    },
    {
      "title": "Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing",
      "authors": "Hong Xie, Haoran Gu, Yanying Huang, Tao Tan, Defu Lian",
      "institution": "University of Science and Technology of China, Chongqing University",
      "link": "https://arxiv.org/pdf/2512.21626",
      "code": null,
      "tags": [
        "multi-armed bandits",
        "multiple-play bandits",
        "prioritized resource sharing",
        "regret analysis",
        "combinatorial optimization",
        "UCB"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8562089dc3d9fa0a65e8caf8921b51648e1718efd62395a7af2fadba8cf952d9_w640_q70.webp",
      "contributions": "1. Proposes a new variant of the multiple-play stochastic bandit model (MSB-PRS) that incorporates prioritized capacity sharing among plays, tailored for resource allocation in LLM and edge intelligence applications. 2. Establishes instance-independent and instance-dependent regret lower bounds for the proposed model, characterizing its fundamental learning difficulty. 3. Designs an offline optimal policy solver (MSB-PRS-OffOpt) and an online UCB-based learning algorithm with theoretical regret guarantees that nearly match the derived lower bounds.",
      "summary": "This paper introduces a new multi-armed bandit model where multiple plays with priorities compete for the stochastic capacity of arms. The authors design an algorithm that first computes an optimal allocation offline and then uses it within an online UCB-based strategy, proving that its regret nearly matches the fundamental lower bounds they establish for this problem.",
      "mindmap": "graph TB\n        Root[”Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing<br/>多臂老虎机优先容量共享”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br/>Prioritized resource allocation in LLM/edge intelligence<br/>LLM/边缘智能中的优先资源分配”] --> P1[”模型/Model<br/>M arms, K plays, stochastic capacity, priority weights<br/>M个臂，K个玩家，随机容量，优先级权重”]\n        Method[”主要方法/Method<br/>Algorithm Design<br/>算法设计”] --> M1[”离线最优求解器/MSB-PRS-OffOpt<br/>Computes optimal policy<br/>计算最优策略”]\n        Method --> M2[”在线UCB算法/Online UCB Algorithm<br/>Uses offline solver as subroutine<br/>以离线求解器为子程序”]\n        Results[”关键结果/Results<br/>Theoretical Analysis<br/>理论分析”] --> R1[”下界/Regret Lower Bounds<br/>Ω(α₁σ√KMT), Ω(α₁σ²(M/Δ)lnT)”]\n        Results --> R2[”上界/Regret Upper Bounds<br/>Matching lower bounds up to factors<br/>与下界匹配（差因子）”]"
    },
    {
      "title": "Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search",
      "authors": "Maximilian Weichart",
      "institution": "University of Regensburg",
      "link": "https://arxiv.org/pdf/2512.21648",
      "code": "https://github.com/Max-We/inverse-rpo",
      "tags": [
        "reinforcement learning",
        "Monte Carlo Tree Search",
        "Upper Confidence Bound",
        "Variance-Aware",
        "Prior-Based Tree Policy",
        "Inverse-RPO"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp",
      "contributions": "1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.",
      "summary": "This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.",
      "mindmap": "graph TB\n        A[Variance-Aware Prior-Based Tree Policies for MCTS] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Extending prior-based UCTs from other UCBs is challenging]\n        C[主要方法/Method: Propose Inverse-RPO to derive prior-based UCTs; apply to UCB-V]\n        D[关键结果/Results: New policies outperform PUCT without extra cost]"
    },
    {
      "title": "TrackTeller: Temporal Multimodal 3D Grounding for Behavior-Dependent Object References",
      "authors": "Jiahong Yu, Ziqi Wang, Hailiang Zhao, Wei Zhai, Xueqiang Yan, Shuiguang Deng",
      "institution": "Zhejiang University, Fudan University, Huawei Technologies Ltd.",
      "link": "https://arxiv.org/pdf/2512.21641",
      "code": null,
      "tags": [
        "3D object grounding",
        "temporal multimodal grounding",
        "LiDAR-image fusion",
        "language-conditioned decoding",
        "UniScene representation",
        "NuPrompt benchmark"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc60054c622874cc83217afc715702b65eb56126f722620ffb7004f46ebe296d_w640_q70.webp",
      "contributions": "1. Proposes TrackTeller, a unified temporal multimodal framework for 3D grounding that integrates LiDAR-image fusion, language-conditioned decoding, and temporal reasoning. 2. Introduces a shared UniScene representation aligned with textual semantics to generate language-aware 3D proposals. 3. Demonstrates significant performance improvements on the NuPrompt benchmark, including a 70% relative gain in Average Multi-Object Tracking Accuracy and a 3.15-3.4x reduction in False Alarm Frequency.",
      "summary": "This paper addresses the problem of grounding natural language references to objects in dynamic 3D driving scenes, which often depend on recent motion or behavior. The authors propose TrackTeller, a framework that fuses LiDAR and camera data with language, builds a unified scene representation, and uses temporal reasoning to refine object identification. Experiments show that TrackTeller significantly outperforms existing baselines in language-grounded tracking accuracy.",
      "mindmap": "graph TB\n        A[TrackTeller: Temporal Multimodal 3D Grounding] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[动态3D场景中的行为依赖语言指代/Dynamic 3D Behavior-Dependent Language Grounding]\n        C --> C1[统一多模态时序框架/Unified Temporal Multimodal Framework]\n        C1 --> C2[LiDAR-图像融合与语言解码/LiDAR-Image Fusion & Language Decoding]\n        C1 --> C3[构建UniScene表示/Build UniScene Representation]\n        C1 --> C4[利用运动历史推理/Reason with Motion History]\n        D --> D1[在NuPrompt上显著提升性能/Significant Improvement on NuPrompt]\n        D1 --> D2[AMOTA提升70%/70% AMOTA Gain]\n        D1 --> D3[误报率降低3.15-3.4倍/3.15-3.4x FA Reduction]"
    },
    {
      "title": "Near-Optimal Coalition Structures in Polynomial Time",
      "authors": "Angshul Majumdar",
      "institution": "Indraprastha Institute of Information Technology, Delhi",
      "link": "https://arxiv.org/pdf/2512.21657",
      "code": null,
      "tags": [
        "cooperative game theory",
        "coalition structure generation",
        "anytime algorithms",
        "sparse relaxations",
        "dynamic programming",
        "MILP"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb8e459bba93eeaf4c9237729ad06cf13b47ef6a941811135ed634157dd979c7_w640_q70.webp",
      "contributions": "1. Proves that under a \"sparse synergy\" model, sparse relaxation methods can find near-optimal coalition structures in polynomial time with high probability. 2. Demonstrates that broad classes of dynamic programming and MILP algorithms require exponential time to achieve comparable solution quality. 3. Establishes a rigorous probabilistic anytime performance separation favoring sparse relaxations over exact methods for the CSG problem.",
      "summary": "This paper studies the coalition structure generation (CSG) problem. It compares three algorithmic paradigms and proves that, under a random sparse synergy model, sparse relaxation methods can find near-optimal solutions in polynomial time, while exact methods like DP and MILP require exponential time to reach similar quality, establishing a clear anytime performance advantage for the sparse approach.",
      "mindmap": "graph TB\n        A[Near-Optimal Coalition Structures in Polynomial Time] --> B[核心问题/Problem: Coalition Structure Generation (CSG)]\n        A --> C[主要方法/Method: Compare DP, MILP, and Sparse Relaxations]\n        A --> D[关键结果/Results: Sparse relaxations achieve near-optimal welfare in polynomial time; DP/MILP require exponential time]"
    },
    {
      "title": "Structural Induced Exploration for Balanced and Scalable Multi-Robot Path Planning",
      "authors": "Zikun Guo, Adeyinka P. Adedigba, Rammohan Mallipeddi, Heoncheol Lee",
      "institution": "Kyungpook National University, Kumoh National Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.21654",
      "code": null,
      "tags": [
        "swarm intelligence",
        "Ant Colony Optimization",
        "structural prior",
        "load-aware objective",
        "overlap suppression",
        "multi-robot path planning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca4635b64758650f78e762004770f2a7ac8eb62cd36aa2db98d90af82d3f6eae_w640_q70.webp",
      "contributions": "1. Proposes a structure-induced exploration framework that integrates structural priors into ACO initialization to constrain the search space. 2. Designs a pheromone update rule that emphasizes structurally meaningful connections and incorporates a load-aware objective to balance total travel distance with individual robot workload. 3. Introduces an explicit overlap suppression strategy to ensure distinct and balanced task allocation across the robot team.",
      "summary": "This paper addresses the challenge of scalable and balanced multi-robot path planning. It proposes a new framework that integrates structural priors into Ant Colony Optimization, along with a load-aware objective and overlap suppression, to improve route compactness, stability, and workload distribution. The method demonstrates consistent improvements over metaheuristic baselines and offers a scalable solution for applications like logistics and search-and-rescue.",
      "mindmap": "graph TB\n        A[Structural Induced Exploration for Balanced and Scalable Multi-Robot Path Planning] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Multi-robot path planning is combinatorially complex and requires balancing global efficiency with fair task allocation. 传统方法难以扩展/Traditional methods struggle to scale.]\n        C[主要方法/Method: A structure-induced ACO framework. 利用结构先验、负载感知目标和重叠抑制/Uses structural prior, load-aware objective, and overlap suppression.]\n        D[关键结果/Results: Improves route compactness, stability, and workload distribution. 提供可扩展的框架/Provides a scalable framework.]"
    },
    {
      "title": "Comparative Analysis of Deep Learning Models for Perception in Autonomous Vehicles",
      "authors": "Jalal Khan",
      "institution": "United Arab Emirates University",
      "link": "https://arxiv.org/pdf/2512.21673",
      "code": null,
      "tags": [
        "object detection",
        "YOLO-NAS",
        "YOLOv8",
        "perception",
        "autonomous vehicles",
        "custom dataset"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4a67f4b1902039d3a0f1a96acadea1a1625b1870da583b146bb58337f3c0561_w640_q70.webp",
      "contributions": "1. Conducted a comparative performance analysis of two emerging deep learning models, YOLO-NAS and YOLOv8, for object detection in autonomous vehicle perception. 2. Created and utilized a custom dataset to evaluate the models under real-world use case scenarios. 3. Provided empirical results showing YOLOv8s offers a 75% reduction in training time and a 2% higher object detection accuracy (83% vs 81%) compared to YOLO-NAS.",
      "summary": "This paper compares the performance of YOLO-NAS and YOLOv8 deep learning models for object detection in autonomous vehicle perception using a custom dataset. The analysis finds that the YOLOv8s model is significantly faster to train and achieves slightly higher detection accuracy than the YOLO-NAS model.",
      "mindmap": "graph TB\n    A[Comparative Analysis of Deep Learning Models for Perception in Autonomous Vehicles] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[评估自动驾驶感知中深度学习模型的性能/Evaluate DL model performance for AV perception]\n    C --> C1[使用自定义数据集比较YOLO-NAS与YOLOv8/Compare YOLO-NAS and YOLOv8 using a custom dataset]\n    D --> D1[YOLOv8s训练时间减少75%/YOLOv8s saves 75% training time]\n    D --> D2[YOLOv8s准确率更高(83% vs 81%)/YOLOv8s has higher accuracy (83% vs 81%)]"
    },
    {
      "title": "RIPCN: A Road Impedance Principal Component Network for Probabilistic Traffic Flow Forecasting",
      "authors": "Haochen Lv, Yan Lin, Shengnan Guo, Xiaowei Mao, Hong Nie, Letian Gong, Youfang Lin, Huaiyu Wan",
      "institution": "Beijing Jiaotong University, Aalborg University",
      "link": "https://arxiv.org/pdf/2512.21685",
      "code": null,
      "tags": [
        "spatiotemporal forecasting",
        "probabilistic forecasting",
        "uncertainty estimation",
        "principal component analysis",
        "road impedance",
        "traffic flow"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f835b2051524d67481fbf9f4479086a541b29307c2876046f2c3ee4eec60f92_w640_q70.webp",
      "contributions": "1. Proposes a dynamic impedance evolution network to model directional traffic transfer patterns driven by congestion and flow variability, revealing causes of uncertainty and enhancing reliability and interpretability. 2. Designs a principal component network to forecast the dominant eigenvectors of future flow covariance, enabling the capture of spatiotemporal uncertainty correlations. 3. Integrates domain-specific transportation theory with spatiotemporal principal component learning for probabilistic traffic flow forecasting, achieving superior performance over existing methods.",
      "summary": "The paper proposes RIPCN, a Road Impedance Principal Component Network for probabilistic traffic flow forecasting. It integrates transportation theory with principal component learning to model the causes of uncertainty and capture spatiotemporal uncertainty correlations. Experimental results show it outperforms existing probabilistic forecasting methods.",
      "mindmap": "graph TB\n        A[RIPCN: A Road Impedance Principal Component Network for Probabilistic Traffic Flow Forecasting] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1(如何建模交通流不确定性的成因? / How to model the causes of traffic flow uncertainty?)\n        B --> B2(如何捕捉不确定性的时空相关性? / How to capture spatiotemporal correlations of uncertainty?)\n        C --> C1(动态阻抗演化网络 / Dynamic Impedance Evolution Network)\n        C --> C2(主成分网络 / Principal Component Network)\n        D --> D1(超越现有概率预测方法 / Outperforms existing probabilistic forecasting methods)"
    },
    {
      "title": "BeHGAN: Bengali Handwritten Word Generation from Plain Text Using Generative Adversarial Networks",
      "authors": "Md. Rakibul Islam, Md. Kamrozzaman Bhuiyan, Safwan Muntasir, Arifur Rahman Jawad, Most. Sharmin Sultana Samu",
      "institution": "Not explicitly stated in provided text. Affiliation/domain cannot be reliably inferred.",
      "link": "https://arxiv.org/pdf/2512.21694",
      "code": null,
      "tags": [
        "handwritten text generation",
        "Generative Adversarial Networks",
        "Handwritten Text Generation",
        "Bengali",
        "Dataset",
        "Pre-processing"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8b36b4afe805283b88409b54815e1bd251762075786246ae741c57cb65c191a_w640_q70.webp",
      "contributions": "1. Proposed a method for generating Bengali handwritten words from plain text using GANs, addressing a significant research gap. 2. Developed and used a novel, self-collected dataset of Bengali handwriting from approximately 500 diverse individuals. 3. Demonstrated the ability to produce diverse and realistic handwritten outputs through the described approach.",
      "summary": "This paper addresses the lack of research on Bengali handwritten text generation by proposing a GAN-based method to generate words from plain text. The authors created a new dataset of Bengali handwriting samples from hundreds of contributors. The work successfully generates diverse handwritten outputs and contributes to advancing research in this area for the Bengali language.",
      "mindmap": "graph TB\n        A[BeHGAN: Bengali Handwritten Word Generation] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[HTG is challenging & understudied for Bengali<br/>孟加拉语手写文本生成研究不足且困难]\n        C --> C1[Propose GAN-based method<br/>提出基于GAN的方法]\n        C --> C2[Use self-collected dataset<br/>使用自收集数据集]\n        C --> C3[Pre-process images<br/>预处理图像]\n        D --> D1[Generates diverse handwritten words<br/>生成多样化手写词]\n        D --> D2[Contributes to Bengali HTG research<br/>推动孟加拉语手写文本生成研究]"
    },
    {
      "title": "Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning",
      "authors": "Eranga Bandara, Tharaka Hewa, Ross Gore, Sachin Shetty, Ravi Mukkamala, Peter Foytik, Abdul Rahman, Safdar H. Bouk, Xueping Liang, Amin Hass, Sachini Rajapakse, Ng Wee Keong, Kasun De Zoysa, Aruna Withanage, Nilaan Loganathan",
      "institution": "Old Dominion University, University of Oulu, Deloitte & Touche LLP, Florida International University, Nanyang Technological University, University of Colombo, IcicleLabs.AI, Accenture Technology Labs, Effectz.AI",
      "link": "https://arxiv.org/pdf/2512.21699",
      "code": null,
      "tags": [
        "agent system",
        "agentic AI",
        "consensus-driven reasoning",
        "explainable AI",
        "responsible AI",
        "multi-model governance"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed22161f8f004c98e3fb6124bac7991548de5e54f47adb42f0d3eb1095409e6e_w640_q70.webp",
      "contributions": "1. Proposes a novel RAI/XAI agent architecture for production workflows based on multi-model consensus and reasoning-layer governance. 2. Introduces a mechanism where a consortium of heterogeneous LLM/VLM agents generate independent outputs, exposing uncertainty and alternatives for structured consolidation. 3. Demonstrates that the consensus-driven approach improves robustness, transparency, and operational trust across diverse real-world agentic AI workflows.",
      "summary": "This paper addresses the challenges of explainability and responsibility in increasingly autonomous agentic AI systems. It proposes a new architecture where multiple AI agents generate candidate outputs, and a dedicated reasoning agent consolidates them while enforcing safety constraints, thereby improving decision robustness and auditability. The work provides a practical framework for building agentic systems that are both scalable and responsible by design.",
      "mindmap": "graph TB\n        A[Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Agentic AI lacks explainability & responsibility] --> B1[挑战/Challenges<br>Explainability, Accountability, Robustness, Governance]\n        C[主要方法/Method<br>Multi-model Consensus & Reasoning-layer Governance] --> C1[架构/Architecture<br>Consortium of LLM/VLM Agents]\n        C --> C2[过程/Process<br>Structured Consolidation by Dedicated Reasoning Agent]\n        D[关键结果/Results<br>Improved Robustness, Transparency & Operational Trust]"
    },
    {
      "title": "Zero-Shot to Zero-Lies: Detecting Bengali Deepfake Audio through Transfer Learning",
      "authors": "Most. Sharmin Sultana Samu, Md. Rakibul Islam, Md. Zahid Hossain, Md. Kamrozzaman Bhuiyan, Farhad Uz Zaman",
      "institution": "Not explicitly stated in the provided content.",
      "link": "https://arxiv.org/pdf/2512.21702",
      "code": null,
      "tags": [
        "audio deepfake detection",
        "transfer learning",
        "zero-shot inference",
        "fine-tuning",
        "Bengali audio",
        "BanglaFake dataset"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66eab5318a9b87f6facd46827f1723103def2a66467b77d3a3f1b6ea7a41d92f_w640_q70.webp",
      "contributions": "1. Conducts the first systematic benchmark for Bengali deepfake audio detection using the BanglaFake dataset. 2. Evaluates and demonstrates the limited performance of multiple pre-trained models in a zero-shot setting for this task. 3. Shows that fine-tuning deep learning models (e.g., ResNet18) significantly improves detection performance, establishing an effective approach for low-resource languages.",
      "summary": "This paper addresses the underexplored problem of Bengali deepfake audio detection. It first evaluates several pre-trained models using zero-shot inference, finding limited performance, and then fine-tunes various architectures, with ResNet18 achieving the best results. The study concludes that fine-tuning is crucial for effective deepfake detection in low-resource languages like Bengali.",
      "mindmap": "graph TB\n        A[Zero-Shot to Zero-Lies: Detecting Bengali Deepfake Audio through Transfer Learning] --> B(核心问题/Problem: Bengali Deepfake Audio Detection is unexplored)\n        A --> C(主要方法/Method: Zero-shot inference & Fine-tuning of pre-trained models)\n        A --> D(关键结果/Results: Fine-tuned ResNet18 achieves best performance (79.17% accuracy))"
    },
    {
      "title": "Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech",
      "authors": "Shuchang Pan, Siddharth Banerjee, Dhruv Hebbar, Siddhant Patel, Akshaj Gupta, Kan Jen Cheng, Hanjo Kim, Zeyi Austin Li, Martin Q. Ma, Tingle Li, Gopala Anumanchipalli, Jiachen Lian",
      "institution": "Zhejiang University, University of California, Berkeley, Carnegie Mellon University",
      "link": "https://arxiv.org/pdf/2512.21706",
      "code": "https://got-duplex.github.io/",
      "tags": [
        "spoken dialogue systems",
        "Graph-of-Thoughts",
        "full-duplex",
        "speech acts",
        "causal inference",
        "multimodal transformer"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eaad0398d39f15391b728b9e3c53af71ff071dcfd269c61b0a277091d58ee7f3_w640_q70.webp",
      "contributions": "1. A framework that models conversational behavior reasoning as causal inference within a Graph-of-Thoughts (GoT) to enable interpretable decision-making in full-duplex dialogue. 2. A hierarchical labeling scheme and hybrid training corpus combining simulated dialogues with human rationales and real speech to learn causal and temporal dependencies between intents and speech acts. 3. A system that structures streaming predictions as an evolving graph, allowing a multimodal transformer to forecast the next speech act, generate justifications, and dynamically refine its reasoning.",
      "summary": "This paper addresses the lack of explicit reasoning in full-duplex spoken dialogue systems by proposing a framework that models the perception-reasoning-generation loop as causal inference within a Graph-of-Thoughts (GoT). The method uses a hierarchical behavior detection model and a hybrid corpus to learn dependencies, enabling an agent to predict the next speech act and generate interpretable justifications. Experiments show the framework provides robust behavior detection and interpretable reasoning, establishing a foundation for benchmarking conversational reasoning.",
      "mindmap": "graph TB\n        Root[”Enabling Conversational Behavior Reasoning in Full-Duplex Speech<br/>实现全双工语音对话行为推理”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br/>Current systems lack explicit reasoning for conversational behaviors.”]\n        Method[”主要方法/Method<br/>Model reasoning as causal inference in a Graph-of-Thoughts (GoT).”]\n        Results[”关键结果/Results<br/>Robust behavior detection and interpretable reasoning chains.”]"
    },
    {
      "title": "Detecting AI-Generated Paraphrases in Bengali: A Comparative Study of Zero-Shot and Fine-Tuned Transformers",
      "authors": "Md. Rakibul Islam, Most. Sharmin Sultana Samu, Md. Zahid Hossain, Farhad Uz Zaman, Md. Kamrozzaman Bhuiyan",
      "institution": "Not specified in provided content.",
      "link": "https://arxiv.org/pdf/2512.21709",
      "code": null,
      "tags": [
        "ai-generated text detection",
        "transformer",
        "fine-tuning",
        "zero-shot",
        "Bengali",
        "paraphrase detection"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b32597f75301412c6dbf1765506d21eb52c7e7727c1e3eefdfaa406f8c4ae44_w640_q70.webp",
      "contributions": "1. Conducts the first comparative study of transformer models for detecting AI-generated paraphrases specifically in the Bengali language. 2. Demonstrates that zero-shot evaluation of pre-trained models yields near-chance performance, highlighting the necessity of task-specific fine-tuning for this problem. 3. Shows that fine-tuning significantly boosts performance, with XLM-RoBERTa, mDeBERTa, and MultilingualBERT achieving high accuracy (~91%), establishing a strong baseline for future research.",
      "summary": "This paper addresses the challenge of detecting AI-generated paraphrased text in Bengali, a low-resource language. It evaluates five transformer models in zero-shot and fine-tuned settings, finding that fine-tuning is essential and leads to high detection accuracy (~91%) for several models. The work establishes a foundation for robust AI-generated content detection systems in Bengali.",
      "mindmap": "graph TB\n        A[Detecting AI-Generated Paraphrases in Bengali] --> B[核心问题/Problem: LLM misuse & lack of Bengali detection research]\n        A --> C[主要方法/Method: Compare 5 transformers (Zero-Shot vs. Fine-Tuned)]\n        A --> D[关键结果/Results: Fine-tuning needed; XLM-R, mDeBERTa, mBERT achieve ~91% accuracy]"
    },
    {
      "title": "Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought",
      "authors": "Yuyi Zhang, Boyu Tang, Tianjie Ju, Sufeng Duan, Gongshen Liu",
      "institution": "Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.21711",
      "code": null,
      "tags": [
        "interpretability & analysis",
        "latent tokens",
        "chain-of-thought",
        "model reliability",
        "causal analysis",
        "shortcut learning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99abfa3b8406909febaa5ee077a1feab3c1d8b8cda1eebe350774e19cb82eb77_w640_q70.webp",
      "contributions": "1. Introduces \"Steering Experiments\" to causally test the impact of perturbing latent reasoning tokens, revealing COCONUT tokens are insensitive to perturbation unlike explicit CoT tokens. 2. Conducts \"Shortcut Experiments\" to evaluate models under biased and out-of-distribution settings, demonstrating COCONUT exploits dataset artifacts rather than performing genuine reasoning. 3. Repositions COCONUT as a \"pseudo-reasoning\" mechanism that generates plausible traces to conceal shortcut dependence, challenging its claimed reasoning capabilities.",
      "summary": "This paper investigates the reliability of latent reasoning tokens in LLMs, specifically Chain-of-Continuous-Thought (COCONUT). Through causal steering and adversarial shortcut experiments, it finds that COCONUT tokens are uninterpretable placeholders insensitive to perturbation and that the method relies on dataset shortcuts. The main conclusion is that COCONUT is a pseudo-reasoning mechanism that inflates benchmark performance without faithful reasoning.",
      "mindmap": "graph TB\n        A[Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Latent token mechanisms unclear, reliability concerns] --> B1[潜在令牌机制不明确/Unclear latent token mechanisms]\n        B --> B2[可靠性问题/Reliability concerns]\n        C[主要方法/Method: Causal & adversarial analysis] --> C1[引导实验/Steering experiments]\n        C --> C2[捷径实验/Shortcut experiments]\n        D[关键结果/Results: COCONUT is pseudo-reasoning] --> D1[令牌对扰动不敏感/Tokens insensitive to perturbation]\n        D --> D2[利用数据集捷径/Exploits dataset shortcuts]\n        D --> D3[性能提升不基于真实推理/Performance gains not from true reasoning]"
    },
    {
      "title": "Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities",
      "authors": "Abd Ullah Khan, Adnan Shahid, Haejoon Jung, Hyundong Shin",
      "institution": "Kyung Hee University, Ghent University",
      "link": "https://arxiv.org/pdf/2512.21717",
      "code": null,
      "tags": [
        "communication & networking",
        "multiconnectivity",
        "SAGIN",
        "resource allocation",
        "agentic reinforcement learning",
        "heterogeneous networks"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp",
      "contributions": "1. Provides a comprehensive review of current developments and key implementation challenges in SAGIN-enabled multiconnectivity. 2. Highlights the transformative potential of AI-driven approaches, particularly agentic reinforcement learning, for resource optimization in heterogeneous SAGIN environments. 3. Presents a case study demonstrating that learning-based methods can effectively enhance network performance (latency, capacity) with a moderate trade-off in power consumption.",
      "summary": "This paper reviews the challenges of implementing multiconnectivity in heterogeneous Space-Air-Ground Integrated Networks (SAGIN) and proposes AI-driven solutions, specifically agentic reinforcement learning, for optimal resource allocation. A case study shows these methods significantly improve latency and capacity, albeit with a moderate increase in power consumption as a trade-off. The work concludes by outlining open research problems for realizing efficient SAGIN-enabled multiconnectivity.",
      "mindmap": "graph TB\n        Root[”Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem: Heterogeneous SAGIN complicates multiconnectivity and resource allocation”]\n        Method[”主要方法/Method: Use AI-driven approaches, specifically agentic reinforcement learning”]\n        Results[”关键结果/Results: Enhanced network performance (latency, capacity) with moderate power trade-off”]"
    },
    {
      "title": "CATCH: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation",
      "authors": "Rui Ke, Jiahui Xu, Shenghao Yang, Kuang Wang, Feng Jiang, Haizhou Li",
      "institution": "The Chinese University of Hong Kong, Shenzhen; Shenzhen University of Advanced Technology; National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.21715",
      "code": null,
      "tags": [
        "dialogue systems",
        "theme detection",
        "topic clustering",
        "hierarchical generation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da012bcf7b19d126b0f1a64e4fc67ee4a82a999c3d110d6b449ab0c750d9458e_w640_q70.webp",
      "contributions": "1. A context-aware topic representation method that enriches utterance semantics using surrounding topic segments. 2. A preference-guided topic clustering mechanism that jointly models semantic proximity and personalized feedback for cross-dialogue theme alignment. 3. A hierarchical theme generation mechanism designed to suppress noise and produce robust, coherent topic labels.",
      "summary": "The paper proposes CATCH, a framework for controllable theme detection in dialogues, which integrates contextualized clustering and hierarchical generation to address sparse utterances and user preference alignment. It demonstrates effectiveness on the DSTC-12 benchmark using an 8B LLM for both clustering and label generation quality.",
      "mindmap": "graph TB\n        Root[CATCH: 可控主题检测框架 / Controllable Theme Detection Framework] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题 / Problem] --> P1[短话语稀疏语义 / Sparse, short utterances]\n        Problem --> P2[跨对话主题对齐 / Cross-dialogue theme alignment]\n        Problem --> P3[用户偏好整合 / Personalized user preferences]\n        Method[主要方法 / Method] --> M1[上下文感知主题表示 / Context-aware topic representation]\n        Method --> M2[偏好引导主题聚类 / Preference-guided topic clustering]\n        Method --> M3[分层主题生成 / Hierarchical theme generation]\n        Results[关键结果 / Results] --> R1[在DSTC-12基准测试有效 / Effective on DSTC-12 benchmark]\n        Results --> R2[提升聚类与生成质量 / Improved clustering & generation quality with 8B LLM]"
    },
    {
      "title": "An Information Theoretic Perspective on Agentic System Design",
      "authors": "Shizhe He, Avanika Narayan, Ishan S. Khare, Scott W. Linderman, Christopher Ré, Dan Biderman",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2512.21720",
      "code": null,
      "tags": [
        "agent system",
        "mutual information",
        "noisy channel",
        "compressor-predictor",
        "on-device AI",
        "information-theoretic"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124535642e159e8f7a123525ffbf3cb5f163a7ae4a7876a4d1e71e7e6c885ace_w640_q70.webp",
      "contributions": "1. Proposes an information-theoretic framework for analyzing agentic LM systems, viewing the compressor as a noisy channel. 2. Introduces a task-independent estimator of mutual information between context and compression to quantify compression quality. 3. Empirically demonstrates that scaling compressor models is more effective than scaling predictors for performance and cost, enabling efficient on-device compression.",
      "summary": "The paper addresses the ad-hoc design of agentic LM systems that use a compressor LM to summarize context for a predictor LM. It proposes an information-theoretic framework using mutual information to evaluate compressors, finding that larger compressors are more accurate, concise, and information-dense, making scaling compressors more effective than scaling predictors for cost-efficient performance.",
      "mindmap": "graph TB\n        A[An Information Theoretic Perspective on Agentic System Design] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1(”Agentic系统设计缺乏理论指导<br/>Agentic system design lacks theoretical guidance”)\n        C --> C1(”提出信息论框架与互信息估计器<br/>Propose information-theoretic framework & mutual information estimator”)\n        D --> D1(”更大压缩器更高效、更准确<br/>Larger compressors are more efficient and accurate”)\n        D --> D2(”扩展压缩器优于扩展预测器<br/>Scaling compressors outperforms scaling predictors”)"
    },
    {
      "title": "HELP: Hierarchical Embodied Language Planner for Household Tasks",
      "authors": "Alexandr V. Korchemnyi, Anatoly O. Onishchenko, Eva A. Bakaeva, Alexey K. Kovalev, Aleksandr I. Panov",
      "institution": "MIRAI, Cognitive AI Systems Lab",
      "link": "https://arxiv.org/pdf/2512.21723",
      "code": null,
      "tags": [
        "agent system",
        "embodied agent",
        "hierarchical planning",
        "large language model",
        "household tasks",
        "open source LLM"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d5e8ef0910254268525eec44918d2562afe5a6df81ece96ba720311313fef5b_w640_q70.webp",
      "contributions": "1. Proposes a Hierarchical Embodied Language Planner (HELP) architecture using multiple LLM-based agents for decomposing and grounding natural language instructions. 2. Demonstrates the approach on a real-world household task using an embodied agent. 3. Focuses on the use of relatively small, open-source LLMs to enable autonomous deployment.",
      "summary": "The paper addresses the challenge of planning for embodied agents following ambiguous natural language instructions in complex environments. It proposes HELP, a hierarchical planner using multiple LLM-based agents to decompose high-level instructions into grounded, executable subtasks. The method is evaluated on a household task with a real robot, showing the feasibility of using smaller, open-source LLMs for autonomous operation.",
      "mindmap": "graph TB\n        A[HELP: Hierarchical Embodied Language Planner for Household Tasks] --> B[核心问题/Problem: Embodied agents need robust planning for ambiguous natural language instructions in complex environments.]\n        A --> C[主要方法/Method: Hierarchical planner with multiple LLM-based agents to decompose and ground instructions into executable steps.]\n        A --> D[关键结果/Results: Evaluated on real-world household task; demonstrates use of smaller open-source LLMs for autonomous deployment.]"
    },
    {
      "title": "A Model of Causal Explanation on Neural Networks for Tabular Data",
      "authors": "Takashi Isozaki, Masahiro Yamamoto, Atsushi Noda",
      "institution": "Sony Computer Science Laboratories, Inc., Sony Corporation of America",
      "link": "https://arxiv.org/pdf/2512.21746",
      "code": null,
      "tags": [
        "explainable ai",
        "CENNET",
        "structural causal models",
        "entropy",
        "causal explanation",
        "tabular data"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02e8ba8968728eba560984773ed8ba2b124e42c46e3c839dec8a1ca2a5975ce1_w640_q70.webp",
      "contributions": "1. Proposes CENNET, a novel causal explanation method for neural network predictions on tabular data. 2. Introduces a new explanation power index based on entropy for evaluating the proposed method. 3. Demonstrates the method's effectiveness by combining structural causal models with neural networks for causal explanations, validated on synthetic and quasi-real data.",
      "summary": "This paper addresses the challenge of providing causal explanations for neural network predictions on tabular data, where pseudo-correlations can mislead. The authors propose a method called CENNET, which integrates structural causal models with neural networks to generate causal explanations and introduces an entropy-based index to measure explanation power. Experiments on synthetic and quasi-real data show that CENNET effectively provides causal explanations compared to existing methods.",
      "mindmap": "graph TB\n        A[A Model of Causal Explanation on Neural Networks for Tabular Data] --> B[核心问题/Problem: Explaining NN predictions on tabular data, addressing pseudo-correlation and causality]\n        A --> C[主要方法/Method: Propose CENNET, a causal explanation method using SCMs and an entropy-based index]\n        A --> D[关键结果/Results: CENNET provides causal explanations, validated via comparative experiments]"
    },
    {
      "title": "How Do Agents Perform Code Optimization? An Empirical Study",
      "authors": "Huiyun Peng, Antonio Zhong, Ricardo Andrés Calvo Méndez, Kelechi G. Kalu, James C. Davis",
      "institution": "Purdue University",
      "link": "https://arxiv.org/pdf/2512.21757",
      "code": null,
      "tags": [
        "code optimization",
        "AI coding agents",
        "performance optimization",
        "empirical study",
        "pull request analysis",
        "AIDev dataset"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp",
      "contributions": "1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices.",
      "summary": "This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement.",
      "mindmap": "graph TB\n        A[How Do Agents Perform Code Optimization? An Empirical Study] --> B[核心问题/Problem: AI coding agents' effectiveness on real-world performance optimization tasks is unknown.]\n        A --> C[主要方法/Method: Empirical comparison of 324 agent-generated and 83 human-authored performance PRs from AIDev dataset.]\n        A --> D[关键结果/Results: AI-authored PRs use similar patterns but include less explicit performance validation (45.7% vs 63.6%).]"
    },
    {
      "title": "A-QCF-Net: An Adaptive Quaternion Cross-Fusion Network for Multimodal Liver Tumor Segmentation from Unpaired Datasets",
      "authors": "Arunkumar V, Firos V M, Senthilkumar S, Gangadharan G R",
      "institution": "Anna University, National Institute of Technology Tiruchirappalli",
      "link": "https://arxiv.org/pdf/2512.21760",
      "code": null,
      "tags": [
        "medical image segmentation",
        "Quaternion Neural Networks",
        "Cross-Attention",
        "Unpaired Data",
        "Multimodal Learning",
        "Explainable AI"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebec19949c3fad65f84d0acee71e271ec2d8caca288cc4ecf24768e9533dbbe8_w640_q70.webp",
      "contributions": "1. Proposes an Adaptive Quaternion Cross-Fusion (A-QCF) block for bidirectional knowledge transfer between unpaired CT and MRI data streams., 2. Introduces a unified segmentation model (A-QCF-Net) that leverages Quaternion Neural Networks to build a shared feature space from separate datasets., 3. Demonstrates significant performance gains over strong unimodal baselines and validates clinical relevance through explainability analysis.",
      "summary": "This paper addresses the challenge of training multimodal segmentation models with unpaired datasets. It proposes A-QCF-Net, which uses Quaternion Neural Networks and an adaptive cross-fusion block to enable knowledge transfer between separate CT and MRI data. The method significantly outperforms unimodal baselines and provides a viable paradigm for leveraging large, unpaired medical image archives.",
      "mindmap": "graph TB\n        A[A-QCF-Net: An Adaptive Quaternion Cross-Fusion Network<br>for Multimodal Liver Tumor Segmentation from Unpaired Datasets] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Scarcity of paired & aligned multimodal medical datasets]\n        C[主要方法/Method<br>Adaptive Quaternion Cross-Fusion (A-QCF) block<br>Quaternion Neural Networks for shared feature space]\n        D[关键结果/Results<br>Significant Dice score improvement over nnU-Net<br>Validated by explainability analysis]"
    },
    {
      "title": "Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets",
      "authors": "Matyas Bohacek, Ignacio Vilanova Echavarri",
      "institution": "Stanford University, Imperial College London",
      "link": "https://arxiv.org/pdf/2512.21775",
      "code": null,
      "tags": [
        "Data Provenance",
        "Data Provenance",
        "Compliance Rating",
        "Generative AI",
        "Dataset Ethics",
        "Transparency"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa33a1fedd52ef1c87e9bf7d9a25dad61aae942ba50660263862470b9b677745_w640_q70.webp",
      "contributions": "1. Proposes the Compliance Rating Scheme (CRS), a framework for evaluating dataset compliance with transparency, accountability, and security principles. 2. Develops and releases an open-source Python library that implements the CRS framework using data provenance technology. 3. Creates a tool that is both reactive (evaluating existing datasets) and proactive (guiding the responsible construction of new datasets).",
      "summary": "The paper addresses the lack of ethical and legal oversight in the creation and sharing of datasets for Generative AI. It proposes the Compliance Rating Scheme (CRS) framework and an accompanying open-source library to assess and ensure dataset compliance with key principles. The work aims to improve traceability and accountability in the AI data supply chain.",
      "mindmap": "graph TB\n        Root(”Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”数据集创建缺乏伦理与法律监督/Lack of ethical & legal oversight in dataset creation”)\n        Problem --> P2(”数据来源与合法性信息丢失/Loss of data origin & legitimacy info”)\n        Method --> M1(”提出合规评级方案(CRS)框架/Propose Compliance Rating Scheme (CRS) framework”)\n        Method --> M2(”开发基于数据溯源技术的开源库/Develop open-source library using data provenance”)\n        Results --> R1(”评估现有数据集的合规性/Evaluate compliance of existing datasets”)\n        Results --> R2(”指导负责任的新数据集构建/Guide responsible construction of new datasets”)"
    },
    {
      "title": "Inference-based GAN Video Generation",
      "authors": "Jingbo Yang, Adrian G. Bors",
      "institution": "University of York",
      "link": "https://arxiv.org/pdf/2512.21776",
      "code": null,
      "tags": [
        "video generation",
        "VAE-GAN",
        "Markov chain",
        "long video generation",
        "temporal consistency",
        "encoder-decoder"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5d6cd59a07e4478b6b21e586a92b15f90e237037b758a29738bf31e46f9843c_w640_q70.webp",
      "contributions": "1. Proposes a new video generator, Encoder GAN3 (EncGAN3), which is a VAE-GAN hybrid structure that incorporates inference capabilities into an adversarial-based unconditional video generator. 2. Introduces a novel, memory-efficient approach to generate long videos (hundreds/thousands of frames) by extending the base VAE-GAN model. 3. Leverages a Markov chain framework with a recall mechanism, where each state is a short VAE-GAN generator, to sequentially connect video sub-sequences and ensure temporal continuity.",
      "summary": "This paper addresses the challenge of generating long, high-quality videos, a task where existing models suffer from quality degradation. The proposed method first introduces a VAE-GAN hybrid video generator (EncGAN3) and then extends it using a Markov chain framework to sequentially generate short video clips, enabling the creation of temporally consistent long videos. The main conclusion is that this approach overcomes the temporal scaling limitation and allows for memory-efficient generation of long video sequences.",
      "mindmap": "graph TB\n        Root[Inference-based GAN Video Generation] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[现有模型难以生成长视频/Existing models struggle with long video generation]\n        P1 --> P2[视频长度增加导致质量下降/Increased length degrades quality]\n        Method[主要方法/Method] --> M1[提出VAE-GAN混合视频生成器/Propose VAE-GAN hybrid video generator]\n        M1 --> M2[使用马尔可夫链框架扩展/Extend with Markov chain framework]\n        M2 --> M3[状态代表短视频生成器/Each state is a short video generator]\n        Results[关键结果/Results] --> R1[能够生成长视频序列/Can generate long video sequences]\n        R1 --> R2[确保时序连续性与一致性/Ensures temporal continuity and consistency]"
    },
    {
      "title": "Accelerating Scientific Discovery with Autonomous Goal-evolving Agents",
      "authors": "Yuanqi Du, Botao Yu, Tianyu Liu, Tony Shen, Junwu Chen, Jan G. Rittig, Kunyang Sun, Yikun Zhang, Zhangde Song, Bo Zhou, Cassandra Masschelein, Yingze Wang, Haorui Wang, Haojun Jia, Chao Zhang, Hongyu Zhao, Martin Ester, Teresa Head-Gordon, Carla P. Gomes, Huan Sun, Chenru Duan, Philippe Schwaller, Wengong Jin",
      "institution": "Cornell University, The Ohio State University, Yale University, Simon Fraser University, École Polytechnique Fédérale de Lausanne, University of California Berkeley, Northeastern University, Deep Principle, University of Illinois Chicago, Georgia Institute of Technology, Broad Institute of MIT and Harvard",
      "link": "https://arxiv.org/pdf/2512.21782",
      "code": null,
      "tags": [
        "scientific discovery agents",
        "autonomous goal evolution",
        "bi-level optimization",
        "LLM agents",
        "objective function design",
        "scientific discovery"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9035dcf8fd16c34c235e39c8960c63fa826c45df283663a01722181f7ab419d8_w640_q70.webp",
      "contributions": "1. Identifies and addresses the unmet requirement of automating objective function design for scientific discovery agents, moving beyond fixed, imperfect proxies. 2. Proposes the SAGA framework, a novel bi-level architecture where an outer loop of LLM agents evolves objectives and an inner loop optimizes solutions under them. 3. Demonstrates the framework's effectiveness across diverse scientific domains (antibiotic, materials, DNA, chemical process design), showing improved discovery outcomes.",
      "summary": "This paper introduces SAGA, a framework for scientific discovery where LLM agents autonomously evolve and refine the objective functions used to guide optimization, rather than relying on fixed human-specified goals. This bi-level architecture enables systematic exploration of objective spaces and their trade-offs. The method is shown to substantially improve the effectiveness of discovery agents across multiple application domains.",
      "mindmap": "graph TB\n        Root[Accelerating Scientific Discovery with Autonomous Goal-evolving Agents] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[Fixed objectives are imperfect proxies for grand scientific challenges / 固定的目标函数是科学重大挑战的不完美代理]\n        Method[主要方法/Method] --> M1[Proposes SAGA: Scientific Autonomous Goal-evolving Agent / 提出SAGA: 科学自主目标演化智能体]\n        M1 --> M2[Bi-level architecture: LLM outer loop evolves objectives, inner loop optimizes solutions / 双层架构: LLM外循环演化目标，内循环优化解]\n        Results[关键结果/Results] --> R1[Applied to antibiotic, materials, DNA, chemical process design / 应用于抗生素、材料、DNA、化工过程设计]\n        R1 --> R2[Automating objective formulation improves discovery effectiveness / 自动化目标制定提升了发现效能]"
    },
    {
      "title": "Multi-agent Adaptive Mechanism Design",
      "authors": "Qiushi Han, David Simchi-Levi, Renfei Tan, Zishuo Zhao",
      "institution": "Massachusetts Institute of Technology, University of Illinois Urbana-Champaign",
      "link": "https://arxiv.org/pdf/2512.21794",
      "code": null,
      "tags": [
        "mechanism design",
        "distributionally robust optimization",
        "online learning",
        "incentive compatibility",
        "adaptive mechanism",
        "regret analysis"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c99ece7d8b60855735e1eee48c51256eacf5f3997d56ced3396434f12a30ad44_w640_q70.webp",
      "contributions": "1. Introduces DRAM, a novel framework combining mechanism design and online learning to handle unknown agent beliefs. 2. Provides theoretical guarantees of high-probability truthfulness and achieves optimal $\\tilde\\{O\\}(\\sqrt\\{T\\})$ cumulative regret with a matching lower bound. 3. Generalizes the framework (DRAM+) to support plug-in estimators, structured priors, and delayed feedback.",
      "summary": "This paper addresses the problem of designing a truthful mechanism when the principal has no prior knowledge of agents' beliefs. It proposes the Distributionally Robust Adaptive Mechanism (DRAM), which iteratively learns beliefs and updates a robust optimization problem to minimize cost while ensuring truthfulness. The mechanism is proven to achieve optimal regret, and the framework is the first to maintain truthfulness under these general learning conditions.",
      "mindmap": "graph TB\n        A[Multi-agent Adaptive Mechanism Design] --> B[核心问题/Problem: Elicit truthful reports with no prior knowledge of agent beliefs]\n        A --> C[主要方法/Method: Distributionally Robust Adaptive Mechanism (DRAM)]\n        A --> D[关键结果/Results: Guaranteed truthfulness & optimal $\\tilde{O}(\\sqrt{T})$ regret]"
    },
    {
      "title": "Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning",
      "authors": "Ting-Hao K.Huang, Ryan A. Rossi, Sungchul Kim, Tong Yu, Ting-Yao E. Hsu, Ho Yin, C. Lee Giles",
      "institution": "The Pennsylvania State University, Adobe Research",
      "link": "https://arxiv.org/pdf/2512.21789",
      "code": null,
      "tags": [
        "image captioning",
        "scientific figure captioning",
        "large-scale dataset",
        "domain-specific training",
        "human evaluation",
        "large language models (LLMs)"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp",
      "contributions": "1. Creation and continuous updating of a large-scale, real-world dataset of scientific figure-caption pairs from arXiv papers. 2. Conducting extensive evaluations, both automatic and human, on generated and author-written captions to assess quality. 3. Developing interactive systems and launching annual challenges to advance the field and help scientists write better captions.",
      "summary": "This paper reviews the SciCap project's first five years, which focused on generating and evaluating captions for scientific figures. The core method involved building a large-scale dataset from arXiv and exploring domain-specific training, similar to models like SciBERT, for captioning. The conclusion outlines key lessons learned and proposes future research directions to address unsolved challenges in the field.",
      "mindmap": "graph TB\n        Root[Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[科学图表说明质量差/Poor quality of scientific figure captions]\n        Problem --> P2[缺乏大规模真实数据集/Lack of large-scale real-world dataset]\n        Method --> M1[构建arXiv图表-说明对数据集/Construct arXiv figure-caption dataset]\n        Method --> M2[领域特定训练与评估/Domain-specific training & evaluation]\n        Method --> M3[应对大语言模型兴起/Navigate rise of LLMs]\n        Results --> R1[总结技术方法经验/Summarize technical & methodological lessons]\n        Results --> R2[提出未来挑战与方向/Outline future challenges & directions]"
    },
    {
      "title": "InstructMoLE: Instruction-Guided Mixture of Low-rank Experts for Multi-Conditional Image Generation",
      "authors": "Jinqi Xiao, Qing Yan, Liming Jiang, Zichuan Liu, Hao Kang, Shen Sang, Tiancheng Zhi, Jing Liu, Cheng Yang, Xin Lu, Bo Yuan",
      "institution": "ByteDance Inc., Rutgers University",
      "link": "https://arxiv.org/pdf/2512.21788",
      "code": "https://github.com/yanq095/InstructMoLE",
      "tags": [
        "diffusion models",
        "Parameter-Efficient Fine-Tuning",
        "Mixture of Low-rank Experts",
        "Instruction-Guided Routing",
        "Multi-Conditional Generation",
        "Diffusion Transformers"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11bd8639cb632e86b35367843cf453bbc6a02fb6882f88ff7441c78b42b653ce_w640_q70.webp",
      "contributions": "1. Introduces InstructMoLE, a framework using an Instruction-Guided Mixture of Low-Rank Experts for multi-conditional image generation., 2. Proposes Instruction-Guided Routing (IGR), a global routing signal derived from user instructions to select a coherent expert council for all tokens, addressing spatial fragmentation and semantic drift., 3. Introduces an output-space orthogonality loss to promote expert functional diversity and prevent representational collapse.",
      "summary": "This paper addresses the problem of task interference in multi-conditional image generation when using monolithic PEFT adapters like LoRA. It proposes InstructMoLE, a novel framework that uses global instruction-guided routing to select a consistent mixture of low-rank experts, combined with an orthogonality loss for diversity, which outperforms existing methods on benchmarks.",
      "mindmap": "graph TB\n        A[InstructMoLE: Instruction-Guided Mixture of Low-rank Experts for Multi-Conditional Image Generation] --> B[核心问题/Problem: Task interference & spatial fragmentation in multi-conditional DiT fine-tuning]\n        A --> C[主要方法/Method: Global Instruction-Guided Routing (IGR) & output-space orthogonality loss]\n        A --> D[关键结果/Results: Outperforms LoRA & MoLE variants on benchmarks]"
    },
    {
      "title": "CellMamba: Adaptive Mamba for Accurate and Efficient Cell Detection",
      "authors": "Ruochen Liu, Yi Tian, Jiahao Wang, Hongbin Liu, Xianxu Hou, Jingxin Liu",
      "institution": "University of Liverpool, National University of Singapore, Xi'an Jiaotong-Liverpool University",
      "link": "https://arxiv.org/pdf/2512.21803",
      "code": null,
      "tags": [
        "object detection",
        "Mamba",
        "Triple-Mapping Adaptive Coupling (TMAC)",
        "Adaptive Mamba Head",
        "biomedical instance detection",
        "VSSD backbone"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fc3fe9b8372a27eedc5a8e2e1150bcdf6cf461c195f9ed154d8890662de191da_w640_q70.webp",
      "contributions": "1. Proposes a novel Triple-Mapping Adaptive Coupling (TMAC) module that splits channels into parallel branches with dual idiosyncratic and one consensus attention map for enhanced spatial discriminability. 2. Designs an Adaptive Mamba Head that fuses multi-scale features via learnable weights to handle varying object sizes robustly. 3. Introduces CellMamba, a lightweight one-stage detector built on a VSSD backbone with CellMamba Blocks, achieving superior accuracy and efficiency on biomedical cell detection datasets.",
      "summary": "This paper proposes CellMamba, a lightweight one-stage detector for cell detection in pathological images. It introduces a novel Triple-Mapping Adaptive Coupling (TMAC) module and an Adaptive Mamba Head to improve spatial discriminability and multi-scale feature fusion. Experiments show CellMamba outperforms CNN, Transformer, and Mamba baselines in accuracy while being more efficient in model size and inference speed.",
      "mindmap": "graph TB\n        A[CellMamba: Adaptive Mamba for Cell Detection] --> B[核心问题/Problem: Cell detection challenges in pathological images]\n        A --> C[主要方法/Method: CellMamba with TMAC module & Adaptive Mamba Head]\n        A --> D[关键结果/Results: Outperforms baselines, lightweight & efficient]"
    },
    {
      "title": "S&P 500 Stock's Movement Prediction using CNN",
      "authors": "Rahul Gupta",
      "institution": "None (No affiliation or email domain provided in the given content)",
      "link": "https://arxiv.org/pdf/2512.21804",
      "code": null,
      "tags": [
        "financial time series forecasting",
        "Convolutional Neural Network (CNN)",
        "multivariate raw data",
        "stock movement prediction",
        "historical data matrices",
        "S&P 500"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d6197655292ac8e55d8c7606c8c3cfe730f7f8dad4004b93d4a9b3a8d8f457_w640_q70.webp",
      "contributions": "1. Proposes the application of Convolutional Neural Networks (CNNs), typically used for image classification, to the problem of stock movement prediction by treating multivariate historical stock data as image-like matrices. 2. Utilizes raw, unprocessed market data including events like stock splits and dividends, instead of relying on pre-engineered financial features. 3. Demonstrates a flexible prediction framework that can be applied at different levels: individual stocks, sectors, or entire portfolios.",
      "summary": "This paper tackles the problem of predicting stock price movements for the S&P 500 index. The core method involves using a Convolutional Neural Network (CNN) to analyze multivariate historical stock data, which is structured as image-like matrices, without extensive feature engineering. The approach shows promising results and offers a flexible model for stock, sector, or portfolio-level predictions.",
      "mindmap": "graph TB\n        Root[”S&P 500 Stock's Movement Prediction using CNN<br>使用CNN预测标普500股票走势”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>Predicting stock price movement<br>预测股票价格走势”] --> P1[”传统方法依赖特征工程<br>Traditional methods rely on engineered features”]\n        Problem --> P2[”现有研究多使用单维数据<br>Existing research often uses single-dimension data”]\n        Method[”主要方法/Method<br>Use CNN on raw multivariate data<br>对原始多变量数据使用CNN”] --> M1[”将历史数据矩阵视为图像<br>Treat historical data matrices as images”]\n        Method --> M2[”包含原始市场事件(如拆股)<br>Include raw market events (e.g., splits)”]\n        Results[”关键结果/Results<br>Model achieves promising results<br>模型取得有希望的结果”] --> R1[”支持股票/行业/组合级别预测<br>Supports stock/sector/portfolio prediction”]"
    },
    {
      "title": "MoonBot: Modular and On-Demand Reconfigurable Robot Toward Moon Base Construction",
      "authors": "Kentaro Uno, Elian Neppel, Gustavo H. Diaz, Ashutosh Mishra, Shamistan Karimov, A. Sejal Jain, Ayesha Habib, Pascal Pama, Hazal Gozbasi, Shreya Santra, Kazuya Yoshida",
      "institution": "Space Robotics Laboratory (SRL), Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University",
      "link": "https://arxiv.org/pdf/2512.21853",
      "code": null,
      "tags": [
        "space robotics",
        "modular robot",
        "reconfigurable robot",
        "lunar construction",
        "field demonstration",
        "connector design"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7ceec836e29be790b6ca39392714dc64e19923b0842210e75988ad1c5fdeeb2_w640_q70.webp",
      "contributions": "1. Introduces MoonBot, a modular and reconfigurable robotic system designed for lunar payload constraints and task adaptability. 2. Details the system's design and development, including a field demonstration simulating lunar infrastructure tasks like civil engineering and component deployment. 3. Systematically summarizes lessons learned, particularly on connector design, to inform future modular robotic systems for lunar missions.",
      "summary": "This paper introduces MoonBot, a modular and reconfigurable robot designed for constructing lunar bases under strict mass constraints. It details the robot's design and validates its concept through field demonstrations of simulated construction tasks. The work concludes with lessons learned, especially regarding connector design, to guide future lunar robotic systems.",
      "mindmap": "graph TB\n        A[MoonBot: 面向月球基地建设的模块化按需可重构机器人] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[月球探索与基地建设需求 / Lunar Exploration & Base Construction Needs]\n        C --> C1[模块化可重构机器人系统 / Modular & Reconfigurable Robotic System]\n        C --> C2[概念验证与现场演示 / Proof-of-Concept & Field Demonstration]\n        D --> D1[成功执行模拟任务 / Successfully Executed Simulated Tasks]\n        D --> D2[总结了连接器设计等经验教训 / Summarized Lessons (e.g., Connector Design)]"
    },
    {
      "title": "HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs",
      "authors": "Jiaxin Liu, Peiyi Tu, Wenyu Chen, Yihong Zhuang, Xinxia Ling, Anji Zhou, Chenxi Wang, Zhuo Han, Zhengkai Yang, Junbo Zhao, Zenan Huang, Yuanyuan Wang",
      "institution": "Ant Group, Xiamen University, Beijing Normal University, Zhejiang University",
      "link": "https://arxiv.org/pdf/2512.21849",
      "code": "https://github.com/inclusionAI/HeartBench",
      "tags": [
        "evaluation",
        "anthropomorphic intelligence",
        "benchmark",
        "psychological counseling",
        "rubric-based evaluation",
        "reasoning-before-scoring"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dc9f1570e111d07840de8240e6e5f545f05ae646e05a5121a0a6c4037e3637a_w640_q70.webp",
      "contributions": "1. Introduces HeartBench, a novel benchmark framework for evaluating the integrated emotional, cultural, and ethical dimensions (anthropomorphic intelligence) of Chinese LLMs. 2. Proposes a theory-driven taxonomy and a case-specific, rubric-based \"reasoning-before-scoring\" evaluation protocol to translate abstract human-like traits into measurable criteria. 3. Provides an analysis revealing a significant performance gap in current LLMs, especially in scenarios with subtle emotional subtexts and complex ethical trade-offs, establishing a standardized metric and a blueprint for creating human-aligned training data.",
      "summary": "The paper addresses the gap in evaluating the social and emotional intelligence (anthropomorphic intelligence) of LLMs, particularly in the Chinese context. It proposes HeartBench, a benchmark framework grounded in psychological counseling scenarios, which uses a rubric-based evaluation method. The assessment of 13 LLMs shows a substantial performance ceiling, with even top models achieving only 60% of the expert ideal, highlighting significant decay in handling complex emotional and ethical nuances.",
      "mindmap": "graph TB\n        A[HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLMs缺乏拟人化智能 / LLMs lack anthropomorphic intelligence]\n        B --> B2[中文语境缺乏评估框架 / Lack of evaluation frameworks in Chinese context]\n        C --> C1[基于心理咨询场景的基准 / Benchmark based on psychological counseling scenarios]\n        C --> C2[理论驱动的分类法 / Theory-driven taxonomy]\n        C --> C3[基于量规的推理评分法 / Rubric-based reasoning-before-scoring]\n        D --> D1[模型性能存在上限 / Performance ceiling in models]\n        D --> D2[复杂场景表现显著下降 / Significant decay in complex scenarios]"
    },
    {
      "title": "A Comedy of Estimators: On KL Regularization in RL Training of LLMs",
      "authors": "Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, Nikolay Malkin, Moksh Jain, Siddarth Venkatraman, Aaron Courville",
      "institution": "Mila – Quebec AI Institute, Université de Montréal, McGill University, LLNL, University of Edinburgh, CIFAR",
      "link": "https://arxiv.org/pdf/2512.21852",
      "code": null,
      "tags": [
        "reinforcement learning",
        "KL divergence",
        "policy gradient",
        "on-policy sampling",
        "off-policy training",
        "gradient bias"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp",
      "contributions": "1. Systematic analysis of KL divergence estimator configurations in RL for LLMs, revealing how design choices introduce gradient bias. 2. Empirical demonstration that estimator configurations with unbiased gradients lead to better and more stable performance on both in-domain and out-of-domain tasks. 3. Investigation showing KL regularization can stabilize off-policy RL training in asynchronous setups.",
      "summary": "This paper analyzes the use of various estimators for the KL divergence regularization term in RL fine-tuning of LLMs, finding that common practices introduce biased gradients. Through experiments on models like Qwen2.5-7B, the study shows that using estimator configurations with unbiased gradients improves training stability and downstream task performance. The work also finds that KL regularization helps stabilize off-policy RL training.",
      "mindmap": "graph TB\n        Root[”A Comedy of Estimators: On KL Regularization in RL Training of LLMs<br>论文标题”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>KL正则化估计器配置缺乏系统研究，梯度存在偏差”] --> P1[”实践问题/Practical Issue<br>广泛使用但实现与目标不一致”]\n        Problem --> P2[”理论问题/Theoretical Issue<br>梯度偏差影响训练稳定性”]\n        Method[”主要方法/Method<br>分析梯度偏差并进行实证验证”] --> M1[”分析/Analysis<br>研究多种估计器配置的梯度”]\n        Method --> M2[”实验/Experiments<br>RL微调多个LLM并评估性能”]\n        Results[”关键结果/Results<br>无偏梯度配置带来更好性能”] --> R1[”在线策略/On-Policy<br>无偏梯度配置提升稳定性和性能”]\n        Results --> R2[”离线策略/Off-Policy<br>KL正则化有助于稳定异步训练”]"
    },
    {
      "title": "Balancing Accuracy and Efficiency: CNN Fusion Models for Diabetic Retinopathy Screening",
      "authors": "Md Rafid Islam, Rafsan Jany, Akib Ahmed, Mohammad Ashrafuzzaman Khan",
      "institution": "North South University, Korea Institute of Oriental Medicine, American International University–Bangladesh",
      "link": "https://arxiv.org/pdf/2512.21861",
      "code": null,
      "tags": [
        "medical image classification",
        "feature-level fusion",
        "convolutional neural networks",
        "diabetic retinopathy screening",
        "EfficientNet",
        "DenseNet"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d879fd7c14baee1110e20d8ebdaec476df8f8819b2fc9a74154be1d0a91d7963_w640_q70.webp",
      "contributions": "1. Proposes and evaluates feature-level fusion of complementary CNN backbones (ResNet50, EfficientNet-B0, DenseNet121) for binary diabetic retinopathy screening. 2. Demonstrates that fusion models consistently outperform single backbones in accuracy and generalization across a large, heterogeneous dataset pooled from five public sources. 3. Provides a practical analysis of the accuracy-efficiency trade-off, identifying the EfficientNet-B0 + DenseNet121 fusion as offering the best balance between performance and computational latency.",
      "summary": "This paper investigates feature-level fusion of CNN models to improve binary diabetic retinopathy screening. It finds that fusing EfficientNet-B0 and DenseNet121 achieves the best accuracy (82.89%) with a favorable balance of performance and inference speed, demonstrating that lightweight fusion enhances generalization across diverse datasets for scalable screening.",
      "mindmap": "graph TB\n        A[Balancing Accuracy and Efficiency: CNN Fusion Models for Diabetic Retinopathy Screening] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Large-scale DR screening is constrained by limited specialists and variable image quality.]\n        C[主要方法/Method<br>Feature-level fusion of complementary CNN backbones (e.g., EfficientNet, DenseNet) on pooled fundus images.]\n        D[关键结果/Results<br>Fusion outperforms single models. Eff+Den fusion offers best accuracy-latency balance.]"
    },
    {
      "title": "Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?",
      "authors": "Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji",
      "institution": "Zhejiang University, University of California, Los Angeles, Palo Alto Networks",
      "link": "https://arxiv.org/pdf/2512.21871",
      "code": "https://github.com/bluedream02/CopyGuard",
      "tags": [
        "multi-modal inference",
        "copyright compliance",
        "vision-language models",
        "tool-augmented defense",
        "benchmark dataset",
        "multimodal query"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp",
      "contributions": "1. Introduced a large-scale benchmark dataset of 50,000 multimodal query-content pairs to evaluate copyright compliance in LVLMs. 2. Conducted a comprehensive evaluation revealing significant deficiencies in state-of-the-art LVLMs' ability to recognize and respect copyrighted content. 3. Proposed a novel tool-augmented defense framework to reduce copyright infringement risks in LVLM inference.",
      "summary": "This paper evaluates how large vision-language models (LVLMs) handle copyrighted visual content and finds they often fail to comply with copyright regulations. To address this, the authors propose a tool-augmented defense framework for copyright compliance. The work highlights the need for developing copyright-aware LVLMs to ensure responsible use.",
      "mindmap": "graph TB\n        Root[”Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?”]\n        Root --> Problem[”核心问题/Problem: LVLMs may infringe copyright when processing visual inputs”]\n        Root --> Method[”主要方法/Method: Benchmark dataset & Tool-augmented defense framework”]\n        Root --> Results[”关键结果/Results: Current LVLMs are deficient; Proposed framework reduces risk”]"
    },
    {
      "title": "Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation",
      "authors": "Yiming Qian, Thorsten Neumann, Xueyining Huang, David Hardoon, Fei Gao, Yong Liu, Siow Mong Rick Goh",
      "institution": "Institute of High Performance Computing (A*STAR), Standard Chartered Bank, Xi’an Jiaotong–Liverpool University",
      "link": "https://arxiv.org/pdf/2512.21866",
      "code": null,
      "tags": [
        "Privacy-preserving machine learning",
        "dataset distillation",
        "random forest",
        "synthetic data generation",
        "explainable AI",
        "membership-inference attack"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6994d363f1e76d7cc78ab02d48685c11199b353aab61b3eb5297064b1df9b722_w640_q70.webp",
      "contributions": "1. Proposes a privacy-preserving dataset distillation framework that converts a trained random forest into transparent rule regions and generates synthetic data by uniform sampling within these regions, creating a compact, auditable surrogate dataset. 2. Enables explainable AI by providing both global pattern summaries (e.g., support, lift) from aggregated rules and local, human-readable rationales with calibrated uncertainty for individual cases based on tree-vote disagreement. 3. Demonstrates strong utility-privacy trade-offs, showing the distilled data maintains competitive model performance (e.g., precision, F1) with significant data reduction (85-93%), improves cross-institution learning, and resists membership-inference attacks (AUC ~0.5), indicating low memorization risk.",
      "summary": "This paper proposes a dataset distillation method for financial fraud detection that converts a random forest model into interpretable rule regions to generate synthetic data, preserving privacy and model utility. The approach produces a compact, explainable dataset that supports collaborative learning across institutions while resisting privacy attacks. Experiments show it reduces data volume by over 85% with minimal performance loss and enhances cross-cluster fraud detection.",
      "mindmap": "graph TB\n        Root(”Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”需要隐私保护的协作式欺诈检测/Need for privacy-preserving collaborative fraud detection”)\n        Problem --> P2(”模型需要可解释性/Model needs explainability”)\n        Method --> M1(”将随机森林转换为规则区域/Convert random forest to rule regions”)\n        Method --> M2(”在区域内均匀采样生成合成数据/Uniformly sample within regions to generate synthetic data”)\n        Results --> R1(”数据量减少85-93%/Data volume reduced by 85-93%”)\n        Results --> R2(”保持竞争性性能/Maintains competitive performance”)\n        Results --> R3(”抵抗成员推理攻击/Resists membership-inference attacks”)"
    },
    {
      "title": "MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting",
      "authors": "Marc S. Montalvo, Hamed Yaghoobian",
      "institution": "Rochester Institute of Technology, Muhlenberg College",
      "link": "https://arxiv.org/pdf/2512.21878",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent framework",
        "bias mitigation",
        "financial forecasting",
        "LLM integration",
        "modular design"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/351cdc3ccfe2b2d987cf53c8380e153fe4b93de0def6253cbc7b2feb4af093fe_w640_q70.webp",
      "contributions": "1. Introduces MASFIN, a modular multi-agent framework that integrates LLMs with structured financial metrics and unstructured news for decomposed financial reasoning. 2. Embeds explicit bias-mitigation protocols (e.g., against survivorship and hindsight bias) to enhance transparency and robustness. 3. Demonstrates practical effectiveness through an eight-week evaluation showing outperformance of major market benchmarks, highlighting the promise of bias-aware generative AI in finance.",
      "summary": "The paper introduces MASFIN, a multi-agent system that combines LLMs with financial data and news to perform decomposed reasoning and forecasting while mitigating biases. In an eight-week evaluation, it achieved a 7.33% cumulative return, outperforming benchmarks like the S&P 500 in most weeks, though with higher volatility. The results show the potential of modular, bias-aware AI frameworks for transparent and reproducible quantitative finance.",
      "mindmap": "graph TB\n        A[MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[传统量化方法易受生存偏差影响/Traditional quantitative methods vulnerable to survivorship bias]\n        B --> B2[AI方法在信号集成和可复现性上存在挑战/AI approaches struggle with signal integration and reproducibility]\n        C --> C1[模块化多智能体框架/Modular multi-agent framework]\n        C --> C2[集成LLM与结构化指标和非结构化新闻/Integrates LLMs with structured metrics and unstructured news]\n        C --> C3[嵌入偏差缓解协议/Embeds bias-mitigation protocols]\n        D --> D1[8周累计回报7.33%/7.33% cumulative return over eight weeks]\n        D --> D2[在6/8周中超越基准/Outperformed benchmarks in six of eight weeks]\n        D --> D3[波动性较高/Higher volatility]"
    },
    {
      "title": "CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics",
      "authors": "Vaibhav Devraj, Dhruv Kumar, Jagat Sesh Challa",
      "institution": "Birla Institute of Technology and Science (BITS), Pilani",
      "link": "https://arxiv.org/pdf/2512.21877",
      "code": null,
      "tags": [
        "text-to-sql",
        "benchmark",
        "multilingual",
        "domain-specific",
        "large language models",
        "sports analytics"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd335127a490c2b4b59330fd1867a57551c792f1b695f15e48789a3992b7c05a_w640_q70.webp",
      "contributions": "1. Introduces CricBench, a novel benchmark for evaluating LLMs on Text-to-SQL tasks in the specialized domain of cricket analytics. 2. Establishes a multilingual framework, providing a \"Gold Standard\" dataset in both English and Hindi, with extensibility to other languages. 3. Demonstrates a significant performance gap for LLMs between general and specialized domains and challenges the assumption of English as the optimal prompt language for such tasks.",
      "summary": "This paper introduces CricBench, a multilingual benchmark for evaluating Large Language Models on Text-to-SQL tasks in the specialized domain of cricket analytics. The benchmark features a manually curated dataset in English and Hindi and is used to evaluate six state-of-the-art models. The results show that high performance on general benchmarks does not transfer well to this specialized domain, and surprisingly, code-mixed Hindi queries can perform as well as or better than English ones.",
      "mindmap": "graph TB\n        A[CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs在专业领域Text-to-SQL能力未充分探索/LLMs' Text-to-SQL capability in specialized domains is under-explored]\n        B --> B2[现有基准缺乏多语言和体育分析特性/Existing benchmarks lack multilingual and sports analytics features]\n        C --> C1[构建板球领域专业多语言基准/Build a specialized multilingual benchmark for cricket]\n        C --> C2[与专家合作创建”黄金标准”查询/Collaborate with experts to create ”Gold Standard” queries]\n        C --> C3[评估六个最先进的LLMs/Evaluate six state-of-the-art LLMs]\n        D --> D1[专业领域性能显著下降/Significant performance drop in specialized domain]\n        D --> D2[DeepSeek R1表现最佳/DeepSeek R1 achieves SOTA]\n        D --> D3[印地语查询准确率可比或更高/Hindi queries yield parity or higher accuracy]"
    },
    {
      "title": "Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models",
      "authors": "Tingyang Sun, Ting He, Bo Ji, Parimal Parag",
      "institution": "Pennsylvania State University, Virginia Tech, Indian Institute of Science",
      "link": "https://arxiv.org/pdf/2512.21884",
      "code": null,
      "tags": [
        "llm inference",
        "distributed inference",
        "block placement",
        "request routing",
        "performance modeling",
        "resource allocation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp",
      "contributions": "1. Developed experimentally validated performance models for distributed LLM inference under given block placement and request routing decisions. 2. Formulated the offline optimization problem as a MILP, proved its NP-hardness, and designed a polynomial-complexity algorithm with performance guarantees. 3. Adapted the offline algorithm for the online setting with the same performance guarantee under bounded load.",
      "summary": "This paper addresses the resource allocation problem for geographically-distributed LLM inference, focusing on optimizing block placement and request routing. It proposes performance models, offline and online algorithms with theoretical guarantees, and a lightweight CPU-only simulator. The solution significantly reduces inference time compared to the state-of-the-art in diverse distributed settings.",
      "mindmap": "graph TB\n        A[Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: 分布式LLM推理的资源分配优化/Optimizing resource allocation for distributed LLM inference]\n        C[主要方法/Method: 性能建模与优化算法/Performance modeling and optimization algorithms]\n        D[关键结果/Results: 显著降低推理时间/Substantially reduces inference time]"
    },
    {
      "title": "Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space",
      "authors": "Weichen Zhang, Peizhi Tang, Xin Zeng, Fanhang Man, Shiquan Yu, Zichao Dai, Baining Zhao, Hongjin Chen, Yu Shang, Wei Wu, Chen Gao, Xinlei Chen, Xin Wang, Yong Li, Wenwu Zhu",
      "institution": "Tsinghua University",
      "link": "https://arxiv.org/pdf/2512.21887",
      "code": null,
      "tags": [
        "visual navigation",
        "world model",
        "future frame projection",
        "4-dof uav",
        "long-horizon visual generation",
        "aerial navigation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02f69e3df37002aba4354016667950073739b574c3c8044ad15f65d9721e62db_w640_q70.webp",
      "contributions": "1. Proposes ANWM, an aerial navigation world model for predicting future visual observations to incorporate high-level semantics into UAV path planning. 2. Introduces a physics-inspired Future Frame Projection (FFP) module to provide coarse geometric priors and mitigate uncertainty in long-distance visual generation. 3. Demonstrates superior performance in long-distance visual forecasting and improves UAV navigation success rates in large-scale 3D environments.",
      "summary": "This paper proposes ANWM, an aerial navigation world model that predicts future visual observations for UAVs using a novel Future Frame Projection module. It addresses the challenges of complex 4-DoF action spaces and long-horizon visual generation. The model outperforms existing methods in visual forecasting and enhances navigation success in large-scale environments.",
      "mindmap": "graph TB\n        A[Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[UAV导航缺乏高层语义规划能力/UAV navigation lacks high-level semantic planning]\n        B --> B2[现有模型难以处理复杂动作空间与长距离视觉生成/Existing models struggle with complex action space & long-horizon visual generation]\n        C --> C1[提出ANWM世界模型/Propose ANWM world model]\n        C --> C2[引入未来帧投影模块/Introduce Future Frame Projection module]\n        D --> D1[长距离视觉预测性能显著提升/Significantly outperforms in long-distance visual forecasting]\n        D --> D2[提高大规模环境导航成功率/Improves UAV navigation success rates in large-scale environments]"
    },
    {
      "title": "Flexible Multitask Learning with Factorized Diffusion Policy",
      "authors": "Chaoqi Liu, Haonan Chen, Sigmund H. Høeg, Shaoxiong Yao, Yunzhu Li, Kris Hauser, Yilun Du",
      "institution": "University of Illinois at Urbana-Champaign, Harvard University, Norwegian University of Science and Technology, Columbia University",
      "link": "https://arxiv.org/pdf/2512.21898",
      "code": null,
      "tags": [
        "diffusion models",
        "diffusion policy",
        "modular architecture",
        "multitask learning",
        "imitation learning",
        "mixture-of-experts"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b261f496908cd892964760d9f52edb76c57a6126f2c6a9969b7e36d9d43b048e_w640_q70.webp",
      "contributions": "1. Introduces a novel modular diffusion policy framework (FDP) that factorizes complex action distributions into a composition of specialized diffusion models. 2. Proposes continuous score aggregation via an observation-conditioned router for stable training and clear component specialization, addressing issues in standard MoE. 3. Demonstrates that the modular structure enables flexible policy adaptation to new tasks and mitigates catastrophic forgetting.",
      "summary": "This paper addresses the challenge of multitask imitation learning in robotics, where complex action distributions are difficult to model. It proposes a Factorized Diffusion Policy (FDP) that decomposes the policy into specialized diffusion components and composes them via a router. The method outperforms baselines in simulation and real-world manipulation and supports flexible adaptation.",
      "mindmap": "graph TB\n        A[Flexible Multitask Learning with Factorized Diffusion Policy] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[机器人多任务学习/Robot Multitask Learning]\n        B1 --> B2[动作分布复杂多模态/Action Distribution Highly Multimodal]\n        B2 --> B3[单体模型欠拟合与不灵活/Monolithic Models Underfit & Inflexible]\n        C --> C1[因子化扩散策略/Factorized Diffusion Policy (FDP)]\n        C1 --> C2[模块化扩散专家/Modular Diffusion Experts]\n        C2 --> C3[基于观察的路由器/Observation-Conditioned Router]\n        C3 --> C4[连续分数聚合/Continuous Score Aggregation]\n        D --> D1[性能超越基线/Outperforms Baselines]\n        D1 --> D2[仿真与真实机器人验证/Simulation & Real-World Validation]\n        D2 --> D3[支持灵活策略适应/Enables Flexible Policy Adaptation]"
    },
    {
      "title": "MMCTOP: A Multimodal Textualization and Mixture-of-Experts Framework for Clinical Trial Outcome Prediction",
      "authors": "Carolina Aparício, Qi Shi, Bo Wen, Tesfaye Yadete, Qiwei Han",
      "institution": "Nova School of Business and Economics, Hogarthian Technologies, IBM Research, Cleveland Clinic, Oregon Health & Science University",
      "link": "https://arxiv.org/pdf/2512.21897",
      "code": null,
      "tags": [
        "multi-modal training",
        "multimodal fusion",
        "sparse mixture-of-experts",
        "schema-guided textualization",
        "clinical trial prediction",
        "temperature scaling"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb552211ea905d5cbf8e190ead9078caf65c5d200327a02c7a6dab156a030645_w640_q70.webp",
      "contributions": "1. A multimodal framework (MMCTOP) that integrates molecular structures, protocol metadata, eligibility narratives, and disease ontologies for clinical trial outcome prediction. 2. A novel architecture combining schema-guided textualization for data normalization and a drug-disease-conditioned sparse Mixture-of-Experts (SMoE) for context-aware, specialized multimodal fusion. 3. Demonstrates improved prediction performance (precision, F1, AUC) over baselines and incorporates operational safeguards like temperature scaling for calibrated probabilities to enhance auditability and reproducibility.",
      "summary": "The paper proposes MMCTOP, a multimodal framework for predicting clinical trial outcomes. It uses schema-guided textualization to normalize heterogeneous data and a sparse Mixture-of-Experts model for specialized fusion, achieving better performance than existing methods and providing calibrated risk estimates.",
      "mindmap": "graph TB\n        Root[MMCTOP: 多模态文本化与专家混合框架<br>MMCTOP: Multimodal Textualization and Mixture-of-Experts Framework] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem<br>多模态数据融合挑战<br>Multimodal Data Fusion Challenge] --> P1[高维生物医学信息学<br>High-Dim Biomedical Informatics]\n        Method[主要方法/Method<br>多模态框架<br>Multimodal Framework] --> M1[模式感知表征学习<br>Modality-Aware Representation Learning]\n        Method --> M2[架构设计/Architecture Design]\n        M1 --> M1_1[领域特定编码器<br>Domain-Specific Encoders]\n        M2 --> M2_1[模式感知表征学习<br>Modality-Aware Representation Learning]\n        M2 --> M2_2[稀疏专家混合<br>Sparse Mixture-of-Experts (SMoE)]\n        M2 --> M2_3[模式感知表征学习<br>Modality-Aware Representation Learning]\n        Results[关键结果/Results<br>性能提升与校准<br>Performance & Calibration] --> R1[指标改进<br>Metric Improvements]\n        Results --> R2[消融研究<br>Ablation Studies]\n        Results --> R3[概率校准<br>Probability Calibration]"
    },
    {
      "title": "SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?",
      "authors": "Kenny Workman, Zhen Yang, Harihara Muralidharan, Hannah Le",
      "institution": "LatchBio",
      "link": "https://arxiv.org/pdf/2512.21907",
      "code": null,
      "tags": [
        "agent system",
        "spatial transcriptomics",
        "AI agents",
        "benchmark",
        "deterministic grader",
        "harness design"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3912de9f7e0f0d2acbf8bcd709b023f2ed3b9ccd56886885ca3f8e9e9e81880_w640_q70.webp",
      "contributions": "1. Introduces SpatialBench, a benchmark of 146 verifiable problems derived from real-world spatial biology analysis workflows, covering five technologies and seven task categories. 2. Provides a deterministic grader for each problem to evaluate the recovery of key biological results from messy spatial datasets. 3. Demonstrates through benchmark data that frontier AI agents have low accuracy (20-38%) on these tasks and reveals the significant impact of harness design (tools, prompts, control flow, execution environment) on performance.",
      "summary": "The paper introduces SpatialBench, a benchmark to evaluate whether AI agents can analyze messy, real-world spatial biology data. It tests frontier models on 146 practical problems and finds low accuracy, highlighting that performance heavily depends on the agent's harness design. The benchmark serves as a tool to measure and diagnose agent capabilities for faithful and reproducible data analysis.",
      "mindmap": "graph TB\n        A[SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[AI代理能否从混乱的真实空间数据中提取生物学见解?/Can AI agents extract biological insight from messy, real-world spatial datasets?]\n        C --> C1[引入包含146个可验证问题的基准SpatialBench/Introduce SpatialBench benchmark with 146 verifiable problems]\n        C --> C2[提供确定性评分器评估关键生物学结果恢复/Provide deterministic grader to evaluate recovery of key biological result]\n        D --> D1[基础模型准确率低 (20-38%)/Base model accuracy remains low (20-38%)]\n        D --> D2[工具链设计对性能有重大影响/Harness design has large empirical effect on performance]"
    },
    {
      "title": "Semiparametric Preference Optimization: Your Language Model is Secretly a Single-Index Model",
      "authors": "Nathan Kallus",
      "institution": "Netflix, Cornell University",
      "link": "https://arxiv.org/pdf/2512.21917",
      "code": null,
      "tags": [
        "reinforcement learning from human feedback (rlhf)",
        "preference optimization",
        "single-index model",
        "semiparametric",
        "link function",
        "policy learning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/378875cc0ef0eb142c184d960e479724ea3df83c84cf81e185efea5469a4387e_w640_q70.webp",
      "contributions": "1. Formulates policy alignment as a semiparametric single-index model problem, relaxing the need for a known link function between preferences and rewards. 2. Develops novel policy learners based on profiling, orthogonalizing, and link-agnostic ranking objectives, providing theoretical error bounds. 3. Proposes practical first-order optimization implementations that are robust to unknown preference noise and scale, enabling direct policy optimization without explicit reward fitting.",
      "summary": "The paper addresses the problem of bias in aligning language models when the assumed link function between human preferences and latent rewards is misspecified. It proposes a semiparametric framework that treats the link function as unknown, develops several robust policy learning algorithms, and provides theoretical guarantees. The main conclusion is that this approach enables more reliable policy alignment without needing to correctly specify the preference noise distribution.",
      "mindmap": "graph TB\n        Root[”Semiparametric Preference Optimization<br>你的语言模型是一个单指标模型”] --> Problem\n        Root --> Method\n        Root --> Results\n    \n        Problem[”核心问题/Problem<br>已知链接函数错误导致策略偏差<br>Misspecified link function causes policy misalignment”]\n        Method[”主要方法/Method<br>将链接函数视为未知的半参数单指标模型<br>Treat link as unknown semiparametric single-index model”]\n        Results[”关键结果/Results<br>开发鲁棒的策略学习器并提供理论保证<br>Develop robust policy learners with theoretical guarantees”]"
    },
    {
      "title": "Unsupervised Anomaly Detection in Brain MRI via Disentangled Anatomy Learning",
      "authors": "Tao Yang, Xiuying Wang, Hao Liu, Guanzhong Gong, Lian-Ming Wu, Yu-Ping Wang, Lisheng Wang",
      "institution": "Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.21924",
      "code": null,
      "tags": [
        "medical image analysis",
        "unsupervised anomaly detection",
        "disentangled representation",
        "pseudo-healthy image reconstruction"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/785ff0154b41353c2fdfb9a61f66c2f97de1b49c0e9dbba451d335e3a8460e71_w640_q70.webp",
      "contributions": "1. Proposed a disentangled representation module to decouple brain MRI into imaging-invariant anatomical information and imaging-specific information, improving model generalizability across multi-modality and multi-center data. 2. Designed an edge-to-image restoration module that reconstructs high-quality pseudo-healthy images from edge information, suppressing the propagation of abnormal residuals. 3. Introduced brain anatomical priors and a differentiable one-hot encoding operator to constrain and stabilize the disentanglement learning process.",
      "summary": "This paper addresses the limitations of generalizability and performance in unsupervised anomaly detection for brain MRI. It proposes a new framework that disentangles anatomical from imaging information and reconstructs pseudo-healthy images from edges, achieving state-of-the-art results on multi-center datasets.",
      "mindmap": "graph TB\n        A[Unsupervised Anomaly Detection in Brain MRI via Disentangled Anatomy Learning] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[泛化性差与异常残留/Generalizability & Residuals]\n        C --> C1[解耦表示模块/Disentangled Representation Module]\n        C --> C2[边缘到图像恢复模块/Edge-to-Image Restoration Module]\n        D --> D1[性能超越17种SOTA方法/Outperforms 17 SOTA Methods]"
    },
    {
      "title": "LVLM-Aided Alignment of Task-Specific Vision Models",
      "authors": "Alexander Koebler, Lukas Kuhn, Ingo Thon, Florian Buettner",
      "institution": "Goethe University Frankfurt, Siemens AG, German Cancer Research Center (DKFZ)",
      "link": "https://arxiv.org/pdf/2512.21985",
      "code": null,
      "tags": [
        "model alignment and interpretability",
        "LVLM-VA",
        "spurious correlations",
        "explainable AI (XAI)",
        "vision-language model",
        "human-in-the-loop"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7c85ee676094853ba26d7711ac1d50d0ab994498bc2f91f2aaab4f1104d3222_w640_q70.webp",
      "contributions": "1. Introduces LVLM-Aided Visual Alignment (LVLM-VA), a novel method for aligning small task-specific vision models with human domain knowledge using a Large Vision Language Model (LVLM). 2. Proposes a bidirectional interface that translates model behavior into natural language and maps human class-level specifications to image-level critiques, enabling efficient expert-model interaction. 3. Demonstrates that the method effectively reduces the model's dependence on spurious features and group-specific biases without requiring fine-grained, instance-level feedback.",
      "summary": "This paper addresses the problem of small task-specific vision models relying on spurious correlations, which leads to brittle real-world performance. The authors propose LVLM-Aided Visual Alignment (LVLM-VA), a method that uses a Large Vision Language Model to create a bidirectional interface between human domain knowledge and the model, translating explanations and critiques. The method is shown to significantly improve model alignment with human specifications and reduce dependence on spurious features across synthetic and real-world datasets.",
      "mindmap": "graph TB\n        A[LVLM-Aided Alignment of Task-Specific Vision Models] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[小规模任务专用视觉模型依赖虚假相关性/Small task-specific vision models rely on spurious correlations]\n        B --> B2[导致部署时行为脆弱/Leads to brittle behavior when deployed]\n        C --> C1[利用LVLM进行视觉对齐/Leverage LVLM for visual alignment]\n        C --> C2[双向接口: 行为转语言, 规范转评估/Bidirectional interface: behavior to language, specs to critiques]\n        D --> D1[模型行为与人类规范更好对齐/Better alignment of model behavior with human specifications]\n        D --> D2[减少对虚假特征和偏见的依赖/Reduced dependence on spurious features and biases]"
    },
    {
      "title": "LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration",
      "authors": "Wen Jiang, Li Wang, Kangyao Huang, Wei Fan, Jinyuan Liu, Shaoyu Liu, Hongwei Duan, Bin Xu, Xiangyang Ji",
      "institution": "Beijing Institute of Technology, Tsinghua University, Dalian University of Technology, Xidian University",
      "link": "https://arxiv.org/pdf/2512.22010",
      "code": null,
      "tags": [
        "vision-and-language navigation",
        "spatiotemporal context modeling",
        "slot-based compression",
        "prompt-guided multimodal integration"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c00484796a9df425f1884ea8ae22314b0592466ebe305303cf7f1f0c467b528_w640_q70.webp",
      "contributions": "1. A slot-based historical image compression module to distill multi-view historical observations into fixed-length contextual representations. 2. A spatiotemporal trajectory encoding module to capture the temporal dynamics and spatial structure of UAV trajectories. 3. A prompt-guided multimodal integration module to fuse spatiotemporal context with current observations for robust waypoint prediction.",
      "summary": "This paper proposes LongFly, a framework for long-horizon UAV vision-and-language navigation that addresses the challenge of modeling spatiotemporal context. The method integrates a history-aware modeling strategy with modules for compressing past observations, encoding trajectories, and fusing multimodal information. Experimental results show it outperforms state-of-the-art baselines in navigation success metrics across seen and unseen environments.",
      "mindmap": "graph TB\n        A[LongFly: Long-Horizon UAV Vision-and-Language Navigation] --> B[核心问题/Problem: Current UAV VLN methods struggle with long-horizon spatiotemporal context, leading to inaccurate alignment and unstable planning.]\n        A --> C[主要方法/Method: History-aware spatiotemporal modeling with slot-based image compression, trajectory encoding, and prompt-guided multimodal integration.]\n        A --> D[关键结果/Results: Outperforms SOTA baselines by 7.89% in success rate and 6.33% in SPL.]"
    },
    {
      "title": "From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation",
      "authors": "Nagham Osman, Vittorio Lembo, Giovanni Bottegoni, Laura Toni",
      "institution": "University College London, University of Urbino Carlo Bo",
      "link": "https://arxiv.org/pdf/2512.22031",
      "code": null,
      "tags": [
        "generative models for drug discovery",
        "hit-like molecule generation",
        "autoregressive models",
        "diffusion models",
        "docking scores",
        "multi-stage filtering"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2a0d0d188f2e13e0f8561de5950d5637586c871a0ee36935ebfbd5bb2bad540_w640_q70.webp",
      "contributions": "1. Framing hit-like molecule generation as a standalone task for generative models. 2. Proposing a tailored evaluation framework integrating physicochemical, structural, and bioactivity criteria. 3. Benchmarking autoregressive and diffusion models, with synthesized GSK-3β hits confirmed active in vitro.",
      "summary": "This paper investigates whether generative models can replace the hit identification step in drug discovery. It proposes a multi-stage evaluation framework and benchmarks autoregressive and diffusion models, showing they can generate valid, diverse, and biologically relevant compounds, with some synthesized hits confirmed active in vitro.",
      "mindmap": "graph TB\n        Root(”From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”Hit identification is resource-intensive/命中识别资源密集”)\n        Method --> M1(”Propose tailored evaluation framework/提出定制评估框架”)\n        Method --> M2(”Benchmark autoregressive & diffusion models/基准测试自回归和扩散模型”)\n        Results --> R1(”Models generate valid, diverse, bioactive compounds/模型生成有效、多样、有生物活性的化合物”)\n        Results --> R2(”Selected hits synthesized & confirmed active/选定命中物被合成并确认有效”)"
    },
    {
      "title": "Meta-Learning-Based Handover Management in NextG O-RAN",
      "authors": "Michail Kalntis, George Iosifidis, José Suárez-Varela, Andra Lutu, Fernando A. Kuipers",
      "institution": "Delft University of Technology, Telefónica Research",
      "link": "https://arxiv.org/pdf/2512.22022",
      "code": null,
      "tags": [
        "communication & networking",
        "Conditional Handovers",
        "O-RAN",
        "Meta-Learning",
        "Mobility Management",
        "xApp"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp",
      "contributions": "1. Introduces CONTRA, the first framework to jointly optimize Traditional and Conditional Handovers within the O-RAN architecture. 2. Proposes a practical meta-learning algorithm for adaptive, on-the-fly handover type selection, guaranteeing universal no-regret performance. 3. Provides and analyzes unique, countrywide mobility management datasets from a top-tier mobile network operator, offering fresh insights into handover trade-offs.",
      "summary": "This paper addresses the limitations of traditional and conditional handovers in mobile networks by proposing CONTRA, a meta-learning-based framework for O-RAN that dynamically selects and optimizes handover types. It is designed as a near-real-time xApp and is evaluated using real-world datasets. The results show that CONTRA improves user throughput and reduces switching costs, outperforming standard and RL-based baselines.",
      "mindmap": "graph TB\n        A[Meta-Learning-Based Handover Management in NextG O-RAN] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[传统切换延迟与失败/Traditional HO delays & failures]\n        B --> B2[切换类型间的权衡/Trade-offs between HO types]\n        C --> C1[CONTRA框架: 联合优化THO与CHO/CONTRA: Jointly optimizes THOs & CHOs]\n        C --> C2[元学习算法动态选择/Meta-learning for dynamic selection]\n        C --> C3[O-RAN xApp部署/O-RAN xApp deployment]\n        D --> D1[提升用户吞吐量/Improves user throughput]\n        D --> D2[降低切换成本/Reduces HO switching costs]\n        D --> D3[优于3GPP与RL基线/Outperforms 3GPP & RL baselines]"
    },
    {
      "title": "LibContinual: A Comprehensive Library towards Realistic Continual Learning",
      "authors": "Wenbin Li, Shangge Liu, Borui Kang, Yiyang Chen, KaXuan Lew, Yang Chen, Yinghuan Shi, Lei Wang, Yang Gao, Jiebo Luo",
      "institution": "Nanjing University, University of Wollongong, University of Rochester",
      "link": "https://arxiv.org/pdf/2512.22029",
      "code": "https://github.com/RL-VIG/LibContinual",
      "tags": [
        "others",
        "catastrophic forgetting",
        "stability-plasticity dilemma",
        "modular architecture",
        "memory budget",
        "online continual learning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a733a967f663a216bbd5fb0cee657ed8bb70a4e6f0205d669f983cbf9bb6fd_w640_q70.webp",
      "contributions": "1. Proposed LibContinual, a unified, modular, and reproducible library for Continual Learning (CL) that integrates 19 representative algorithms across five methodological categories. 2. Systematically identified and investigated three unrealistic implicit assumptions (offline data accessibility, unregulated memory, intra-task semantic homogeneity) prevalent in mainstream CL evaluation. 3. Conducted a comprehensive analysis under stricter, more realistic settings (strict online CL, unified memory budget, category-randomized tasks), revealing significant performance drops in many existing methods and highlighting the need for resource-aware and semantically robust CL strategies.",
      "summary": "This paper introduces LibContinual, a comprehensive library designed to unify and standardize research in Continual Learning (CL). By using this framework to evaluate existing methods under more realistic constraints, the study shows that many current CL algorithms suffer significant performance drops, underscoring the gap between common evaluation practices and real-world applicability.",
      "mindmap": "graph TB\n        A[LibContinual: A Comprehensive Library towards Realistic Continual Learning] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[研究碎片化，缺乏统一框架/Fragmented research landscape, lack of unified framework]\n        B --> B2[评估存在不现实的隐含假设/Unrealistic implicit assumptions in evaluation]\n        C --> C1[构建模块化、可复现的库/Build a modular, reproducible library]\n        C --> C2[集成19种代表性算法/Integrate 19 representative algorithms]\n        C --> C3[在更现实的设定下系统评估/Systematically evaluate under more realistic settings]\n        D --> D1[现有方法在现实约束下性能显著下降/Existing methods show significant performance drop under realistic constraints]\n        D --> D2[强调资源感知和语义鲁棒策略的必要性/Highlight the necessity of resource-aware and semantically robust strategies]"
    },
    {
      "title": "StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars",
      "authors": "Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu",
      "institution": "Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University",
      "link": "https://arxiv.org/pdf/2512.22065",
      "code": "https://streamavatar.github.io",
      "tags": [
        "diffusion models",
        "autoregressive distillation",
        "adversarial refinement",
        "real-time streaming",
        "reference-anchored positional re-encoding",
        "consistency-aware discriminator"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp",
      "contributions": "1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness.",
      "summary": "This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time.",
      "mindmap": "graph TB\n        A[StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Non-causal, high-cost diffusion models unsuitable for real-time streaming; Limited to head-and-shoulder, lacking gestures.]\n        C[主要方法/Method<br>Two-stage autoregressive adaptation (distillation + refinement) with Reference Sink, RAPR, Consistency-Aware Discriminator.]\n        D[关键结果/Results<br>State-of-the-art real-time, interactive full-body avatar with natural talking/listening and gestures.]"
    },
    {
      "title": "Unifying Learning Dynamics and Generalization in Transformers Scaling Law",
      "authors": "Chiwun Yang",
      "institution": "Sun Yat-sen University",
      "link": "https://arxiv.org/pdf/2512.22088",
      "code": null,
      "tags": [
        "learning theory",
        "scaling law",
        "learning dynamics",
        "generalization error",
        "transformer",
        "stochastic gradient descent"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9b067b56202cd4607e684058e78ac331373bf12bf6848ca444276e2dcafe9f9_w640_q70.webp",
      "contributions": "1. Formalizes the learning dynamics of transformers as an ODE system and approximates it to kernel behaviors, moving beyond toy models to analyze SGD on multi-layer transformers with arbitrary data distributions. 2. Establishes a theoretical upper bound on excess risk with a distinct phase transition: exponential decay in the optimization phase and a power-law decay of Θ(C^\\{-1/6\\}) in the statistical phase. 3. Derives isolated scaling laws for model size, training time, and dataset size, explaining how each variable independently governs generalization bounds.",
      "summary": "This paper provides a theoretical foundation for the empirical scaling laws of large language models. It models transformer learning dynamics as an ODE system and analyzes SGD training on realistic data. The main result is a unified theory showing a phase transition in generalization error, from exponential to power-law decay, as computational resources scale.",
      "mindmap": "graph TB\n        A[Unifying Learning Dynamics and Generalization in Transformers Scaling Law] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[Scaling Law理论原理不清 / Poorly understood theoretical underpinnings of scaling laws]\n        C --> C1[形式化学习动态为ODE系统 / Formalize learning dynamics as ODE system]\n        C --> C2[近似为核行为 / Approximate to kernel behaviors]\n        C --> C3[分析SGD训练真实Transformer / Analyze SGD training for real transformers]\n        D --> D1[泛化误差上界与相变 / Upper bound on excess risk with phase transition]\n        D --> D2[优化相:指数衰减 / Optimization phase: Exponential decay]\n        D --> D3[统计相:幂律衰减 Θ(C^{-1/6}) / Statistical phase: Power-law decay Θ(C^{-1/6})]\n        D --> D4[分离的规模定律 / Isolated scaling laws for model size, time, data]"
    },
    {
      "title": "Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis",
      "authors": "Duygu Altinok",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.22100",
      "code": null,
      "tags": [
        "benchmark construction",
        "Turkish NLU benchmark",
        "semi-automated annotation",
        "sentiment analysis dataset"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aae4aef01bf4bd7a32414041836c4d9d7383c50872f47bdb0dee4d45af35adb_w640_q70.webp",
      "contributions": "1. Introduces TrGLUE, the first comprehensive GLUE-style benchmark for Turkish Natural Language Understanding, filling a critical gap. 2. Presents SentiTurca, a specialized benchmark for Turkish sentiment analysis. 3. Provides a scalable, reproducible semi-automated dataset creation pipeline combining LLM annotation, cross-model checks, and human validation.",
      "summary": "This paper addresses the lack of a comprehensive benchmark for evaluating Turkish language understanding by introducing TrGLUE and SentiTurca. The benchmarks are created using a semi-automated pipeline with LLM annotation and human validation to ensure quality and linguistic naturalness. The work establishes a robust evaluation framework and provides resources to empower Turkish NLP research.",
      "mindmap": "graph TB\n        A[Introducing TrGLUE and SentiTurca] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[缺乏土耳其语综合基准/Lack of Turkish NLU Benchmark]\n        C --> C1[半自动标注流程/Semi-automated Pipeline]\n        C1 --> C2[LLM标注 + 交叉验证 + 人工校验/LLM Annotation + Cross-check + Human Validation]\n        D --> D1[发布TrGLUE & SentiTurca/Release TrGLUE & SentiTurca]\n        D --> D2[提供代码与资源/Provide Code & Resources]"
    },
    {
      "title": "A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting",
      "authors": "Shuyu Gan, Renxiang Wang, James Mooney, Dongyeop Kang",
      "institution": "University of Minnesota",
      "link": "https://arxiv.org/pdf/2512.22101",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent pipeline",
        "automated data analysis",
        "insight generation",
        "report synthesis",
        "visual analytics"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92651ded84480402816f8db1df902e28dd62cce1b0958cece60e0f518bdd7e1c_w640_q70.webp",
      "contributions": "1. A Data Analyzer agent that orchestrates data profiling, generates diverse visualizations, filters low-quality charts, and automatically scores candidate insights for depth, correctness, and actionability. 2. A Presenter agent that sequences topics, composes chart-grounded narratives from top insights, writes transitions, and revises the document to produce a coherent, publication-ready report. 3. An end-to-end Analyzer-to-Presenter (A2P) pipeline that operationalizes co-analysis by coupling quality-assured analysis with narrative synthesis, improving the real-world usefulness of automated data analysis.",
      "summary": "This paper presents A2P-Vis, a two-part multi-agent pipeline designed to automate the generation of data visualization reports. The system uses a Data Analyzer to create and vet visual insights and a Presenter to assemble them into a coherent narrative. The authors claim this end-to-end approach improves the practical utility of automated data analysis for practitioners.",
      "mindmap": "graph TB\n        A[A2P-Vis] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[自动化数据科学流程的瓶颈/Gaps in automating data science]\n        B1 --> B2[生成有洞察力的可视化/Generating insightful visual evidence]\n        B1 --> B3[组装成专业报告/Assembling coherent professional report]\n        C --> C1[两部分多智能体管道/Two-part multi-agent pipeline]\n        C1 --> C2[数据分析器/Data Analyzer]\n        C2 --> C3[生成并评估图表与洞察/Generates & evaluates charts & insights]\n        C1 --> C4[报告呈现器/Presenter]\n        C4 --> C5[编排主题并撰写叙述/Orders topics & composes narrative]\n        D --> D1[端到端协同分析/End-to-end co-analysis]\n        D1 --> D2[提高自动化数据分析的实用性/Improves usefulness of automated analysis]"
    },
    {
      "title": "Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks",
      "authors": "Zubair Shah, Noaman Khan",
      "institution": "Hamad Bin Khalifa University",
      "link": "https://arxiv.org/pdf/2512.22106",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "neural network pruning",
        "game theory",
        "equilibrium",
        "non-cooperative game",
        "sparsification"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4fd762b6b064bb7810151beeb40f55c93bfc05054b2d4a98cd925aed8bea43b2_w640_q70.webp",
      "contributions": "1. Proposes a novel game-theoretic perspective on neural network pruning, modeling parameter groups as players in a non-cooperative game where sparsity emerges as an equilibrium outcome. 2. Provides a theoretical analysis showing that dominated players (redundant parameters) collapse to zero participation under mild conditions, offering a principled explanation for pruning. 3. Derives a simple equilibrium-driven pruning algorithm that jointly updates network parameters and participation variables without relying on explicit, heuristic importance scores.",
      "summary": "This paper proposes a novel game-theoretic framework for neural network pruning, where sparsity emerges naturally from the equilibrium of a non-cooperative game among model components. The method jointly updates network parameters and participation variables without external importance scores. Experiments show it achieves competitive sparsity-accuracy trade-offs with a more interpretable, theory-grounded foundation.",
      "mindmap": "graph TB\n        Root(”Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks”) --> Problem(”核心问题/Problem: Sparsity is imposed externally via heuristics, lacking a principled model of parameter interaction.”)\n        Root --> Method(”主要方法/Method: Model pruning as a non-cooperative game among parameters; sparsity emerges at equilibrium.”)\n        Root --> Results(”关键结果/Results: Competitive sparsity-accuracy trade-offs with an interpretable, theory-grounded algorithm.”)"
    },
    {
      "title": "Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications",
      "authors": "Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer",
      "institution": "University of Illinois at Urbana-Champaign, IBM Research",
      "link": "https://arxiv.org/pdf/2512.22113",
      "code": null,
      "tags": [
        "agent system",
        "root cause analysis",
        "service dependency graph",
        "program dependence graph",
        "LLM agent",
        "cloud incident"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp",
      "contributions": "1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment.",
      "summary": "This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents.",
      "mindmap": "graph TB\n        A[Agentic Structured Graph Traversal for Root Cause Analysis<br/>基于智能体结构化图遍历的云应用根因分析] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br/>High cost of unresolved cloud incidents; Need for effective root cause analysis]\n        C[主要方法/Method<br/>PRAXIS: LLM-driven traversal over Service Dependency Graph and Program Dependence Graph]\n        D[关键结果/Results<br/>3.1x higher RCA accuracy, 3.8x lower token consumption vs. ReAct baselines]"
    },
    {
      "title": "Atomistic Simulation Guided Convolutional Neural Networks for Thermal Modeling of Friction Stir Welding",
      "authors": "Akshansh Mishra",
      "institution": "Politecnico di Milano, AI Fab Lab",
      "link": "https://arxiv.org/pdf/2512.21344",
      "code": null,
      "tags": [
        "physics-informed machine learning",
        "molecular dynamics",
        "convolutional neural network",
        "friction stir welding",
        "explainable AI",
        "LAMMPS"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34d6f71500319f52aecac1e95e1951a537fdc504134a8ba43851f31acc2e41c6_w640_q70.webp",
      "contributions": "1. Developed a novel method to transform atomistic simulation data (atomic positions and velocities) into physics-based 2D spatial grids for deep learning input. 2. Created and optimized a 2D CNN model to directly predict temperature evolution from spatially resolved atomistic data, achieving high accuracy (R²=0.94). 3. Used Class Activation Map analysis to provide explainability, showing the model's focus aligns with physical mechanisms (e.g., tool-material interface).",
      "summary": "This paper presents a method that combines molecular dynamics simulations with convolutional neural networks for thermal modeling in friction stir welding. The method transforms atomic-scale simulation data into spatial grids and uses a CNN to accurately predict temperature, with results validated against physical mechanisms. The approach demonstrates that deep learning can effectively learn from atomistic data to model complex thermomechanical processes.",
      "mindmap": "graph TB\n        Root[”Atomistic Simulation Guided CNNs for Thermal Modeling of FSW / 原子模拟引导的CNN用于搅拌摩擦焊热建模”]\n        Root --> Problem[”准确预测温度演化对于理解搅拌摩擦焊的热机械行为至关重要 / Accurate prediction of temperature evolution is essential for understanding thermomechanical behavior in FSW”]\n        Root --> Method[”使用LAMMPS进行分子动力学模拟，将原子数据转换为物理二维空间网格，并开发2D CNN进行预测 / Use LAMMPS for MD simulations, transform atomic data into physics-based 2D spatial grids, and develop a 2D CNN for prediction”]\n        Root --> Results[”模型预测精度高（R²=0.94），CAM分析表明模型关注与剧烈变形和生热相关的区域 / Model achieves high predictive accuracy (R²=0.94), CAM analysis shows model focuses on regions associated with intense deformation and heat generation”]"
    },
    {
      "title": "Applications of synthetic financial data in portfolio and risk modeling",
      "authors": "Christophe D. Hounwanou, Yae Ulrich Gaba",
      "institution": "African Institute for Mathematical Sciences (AIMS Rwanda), Sefako Makgatho Health Sciences University (SMU), AI Research and Innovation Nexus for Africa (AIRINA Labs)",
      "link": "https://arxiv.org/pdf/2512.21798",
      "code": null,
      "tags": [
        "generative models for time series",
        "TimeGAN",
        "Variational Autoencoder (VAE)",
        "synthetic financial data",
        "portfolio optimization",
        "risk modeling"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a7ecf00c1350b58057e2f03c93bf0e8845d1441745fc22505c46475eceeeb65_w640_q70.webp",
      "contributions": "1. Evaluated and compared the performance of TimeGAN and VAEs for generating realistic synthetic financial time series data. 2. Demonstrated that TimeGAN-generated data closely matches real data in distributional, volatility, and autocorrelation properties. 3. Showed the practical utility of synthetic data in downstream financial tasks like mean-variance portfolio optimization, yielding similar portfolio weights and risk metrics to real data.",
      "summary": "This paper addresses the scarcity and privacy issues of real financial data by using generative models like TimeGAN and VAEs to create synthetic return series. It evaluates the synthetic data on statistical similarity and financial tasks, concluding that TimeGAN effectively captures temporal dynamics and can serve as a privacy-preserving, cost-effective substitute for real data in portfolio and risk analysis.",
      "mindmap": "graph TB\n        Root(”Applications of synthetic financial data in portfolio and risk modeling”) --> Problem(”核心问题/Problem: Privacy and accessibility limit financial research”)\n        Root --> Method(”主要方法/Method: Use TimeGAN and VAEs to generate synthetic financial time series”)\n        Root --> Results(”关键结果/Results: TimeGAN data is realistic and useful for portfolio/risk tasks”)"
    },
    {
      "title": "Residual Prior Diffusion: A Probabilistic Framework Integrating Coarse Latent Priors with Diffusion Models",
      "authors": "Takuro Kutsuna",
      "institution": "Toyota Central R&D Labs., Inc.",
      "link": "https://arxiv.org/pdf/2512.21593",
      "code": null,
      "tags": [
        "diffusion models",
        "diffusion models",
        "generative modeling",
        "evidence lower bound",
        "residual learning",
        "two-stage framework"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08078ea833fb6d000def6c1e69b08b734ff7e29a1c3014bf3ec3e8b313815438_w640_q70.webp",
      "contributions": "1. Proposes Residual Prior Diffusion (RPD), a two-stage probabilistic framework that integrates a coarse prior model with a diffusion model to capture large-scale structure and fine-scale details separately. 2. Formulates RPD with a tractable evidence lower bound, showing optimization reduces to familiar noise/velocity prediction objectives, and introduces auxiliary variables to leverage prior information and theoretically reduce prediction difficulty. 3. Demonstrates experimentally that RPD outperforms standard diffusion models on synthetic datasets with fine local structure and matches or exceeds baselines on natural image generation, maintaining performance with few inference steps.",
      "summary": "The paper identifies a problem where standard diffusion models struggle to simultaneously model global structure and fine local details. It proposes Residual Prior Diffusion (RPD), a two-stage framework that first learns a coarse prior and then a diffusion model for the residual. Experiments show RPD captures fine details better than standard models and maintains strong performance with fewer inference steps.",
      "mindmap": "graph TB\n        Root[”Residual Prior Diffusion (RPD) / 残差先验扩散模型”] --> Problem[”核心问题/Problem”]\n        Root --> Method[”主要方法/Method”]\n        Root --> Results[”关键结果/Results”]\n        Problem --> P1[”单一扩散模型难以同时捕捉全局结构和局部细节 / Single diffusion model struggles with global structure and local details”]\n        Method --> M1[”两阶段框架: 粗粒度先验 + 残差扩散模型 / Two-stage framework: coarse prior + residual diffusion model”]\n        Method --> M2[”概率模型与可处理ELBO / Probabilistic model with tractable ELBO”]\n        Results --> R1[”在合成数据上准确捕捉细节 / Accurately captures details on synthetic data”]\n        Results --> R2[”自然图像生成匹配或超越基线 / Natural image generation matches or exceeds baselines”]\n        Results --> R3[”少步推理保持性能 / Maintains performance with few inference steps”]"
    },
    {
      "title": "Enabling Ultra-Fast Cardiovascular Imaging Across Heterogeneous Clinical Environments with a Generalist Foundation Model and Multimodal Database",
      "authors": "Zi Wang, Mingkai Huang, Zhang Shi, Hongjie Hu, Lan Lan, Hui Zhang, Yan Li, Xi Hu, Qing Lu, Zongming Zhu, Qiong Yao, Yuxiang Dai, Fanwen Wang, Yinzhe Wu, Jun Lyu, Qianqian Gao, Guangming Xu, Zhenxuan Zhang, Haosen Zhang, Qing Li, Guangming Wang, Tianxing He, Lizhen Lan, Siyue Li, Le Xue, Mengting Sun, Yuntong Lyu, Junpu Hu, Jiayu Zhu, Rizwan Ahmad, Zhengyu Bu, Xianling Qian, Guanke Cai, Ruiyu Cao, Weirui Cai, Chang Xu, Yuyang Ren, Feidan Yu, Siying Ma, Ziqiang Xu, Xinran Chen, Sha Hua, Daniel Kim, Yajing Zhang, Chen Ouyang, Wenjia Bai, Jing Qin, Yucheng Yang, Daniel Rueckert, He Wang, Qian Tao, Claudia Prieto, Michael Markl, Alistair Young, Lianming Wu, Shuo Wang, Chen Qin, Mengsu Zeng, Xihong Hu, Haibo Xu, Xiaobo Qu, Hao Li, Guang Yang, Chengyan Wang",
      "institution": "Imperial College London, Fudan University, Xiamen University",
      "link": "https://arxiv.org/pdf/2512.21652",
      "code": null,
      "tags": [
        "medical image reconstruction",
        "foundation model",
        "k-space",
        "multimodal database",
        "zero-shot generalization",
        "accelerated imaging"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp",
      "contributions": "1. The curation of MMCMR-427K, the largest and most comprehensive multimodal cardiovascular magnetic resonance (CMR) k-space database. 2. The introduction of CardioMM, a generalist reconstruction foundation model that unifies semantic understanding with physics-informed data consistency for robust, accelerated imaging. 3. Demonstrating state-of-the-art performance and strong zero-shot generalization across heterogeneous clinical settings, enabling up to 24x acceleration without compromising clinical integrity.",
      "summary": "This paper addresses the slow scan times and environmental heterogeneity limiting clinical cardiovascular MRI. It proposes CardioMM, a generalist foundation model trained on a large multimodal k-space database (MMCMR-427K), which achieves robust, ultra-fast reconstructions across diverse scanners and protocols. The results show that CardioMM enables high acceleration (up to 24x) while preserving diagnostic quality and generalizing to unseen clinical environments.",
      "mindmap": "graph TB\n    A[Enabling Ultra-Fast Cardiovascular Imaging...] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[CMR扫描时间长/CMR Scan Time Long]\n    B --> B2[临床环境异质性高/High Clinical Heterogeneity]\n    C --> C1[构建多模态数据库MMCMR-427K/Build Multimodal DB MMCMR-427K]\n    C --> C2[提出通用基础模型CardioMM/Propose Generalist Foundation Model CardioMM]\n    D --> D1[实现24倍加速成像/Achieve 24x Accelerated Imaging]\n    D --> D2[零样本泛化至新环境/Zero-shot Generalization to New Settings]\n    D --> D3[保持诊断质量/Preserve Diagnostic Quality]"
    },
    {
      "title": "Parameter-Efficient Neural CDEs via Implicit Function Jacobians",
      "authors": "Ilya Kuleshov, Alexey Zaytsev",
      "institution": "Applied AI Institute",
      "link": "https://arxiv.org/pdf/2512.20625",
      "code": null,
      "tags": [
        "time series analysis",
        "Neural Controlled Differential Equations",
        "parameter efficiency",
        "implicit function Jacobians",
        "continuous RNN"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f69d35dc890877df610e96a1c984c641596f7fcac2c4ff1dbf30f641c90d5d77_w640_q70.webp",
      "contributions": "1. Proposes a novel, parameter-efficient formulation of Neural Controlled Differential Equations (NCDEs) that drastically reduces the number of required parameters. 2. Introduces a logical interpretation of the method as a \"Continuous RNN,\" aligning with the original inspiration of NCDEs. 3. Presents a method leveraging implicit function Jacobians to achieve this efficiency.",
      "summary": "This paper addresses the high parameter cost of Neural Controlled Differential Equations (NCDEs) for temporal sequence analysis. It proposes a new, parameter-efficient formulation that reinterprets NCDEs as a \"Continuous RNN\" and uses implicit function Jacobians to reduce the parameter count. The main conclusion is that this approach maintains the modeling power of NCDEs while being significantly more parameter-efficient.",
      "mindmap": "graph LR\n    A[Parameter-Efficient Neural CDEs via Implicit Function Jacobians] --> B[核心问题/Problem: NCDEs require many parameters]\n    A --> C[主要方法/Method: Parameter-efficient formulation via implicit Jacobians, ”Continuous RNN” analogy]\n    A --> D[关键结果/Results: Achieves similar performance with far fewer parameters]"
    },
    {
      "title": "BitRL-Light: 1-bit LLM Agents with Deep Reinforcement Learning for Energy-Efficient Smart Home Lighting Optimization",
      "authors": "Ravi Gupta, Shabista Haider",
      "institution": "AMD, Oracle",
      "link": "https://arxiv.org/pdf/2512.20623",
      "code": null,
      "tags": [
        "on-device ai",
        "1-bit quantization",
        "Deep Q-Network (DQN)",
        "edge inference",
        "multi-objective RL",
        "model compression"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc8c0af6233346bd047dc958868370625b7e65b546832d11939a371662fc4980_w640_q70.webp",
      "contributions": "1. A novel architecture integrating 1-bit quantized LLMs with DQN for multi-objective optimization of smart home lighting. 2. Voice command integration via Google Home and IFTTT webhooks for natural user interaction. 3. Comprehensive evaluation demonstrating the feasibility of intelligent adaptive control on sub-$50 hardware, with significant energy and latency improvements.",
      "summary": "This paper proposes BitRL-Light, a framework that combines a 1-bit quantized LLM with Deep Q-Network reinforcement learning for real-time smart home lighting control on edge devices. The system optimizes for energy efficiency and user comfort, achieving substantial energy savings and low latency on a Raspberry Pi. The work demonstrates that adaptive AI control is feasible on resource-constrained hardware without cloud dependency.",
      "mindmap": "graph LR\n    A[BitRL-Light] --> B[核心问题/Problem: Smart home lighting lacks adaptive intelligence for energy and comfort]\n    A --> C[主要方法/Method: 1-bit LLM + DQN on edge devices]\n    A --> D[关键结果/Results: 32% energy savings, <200ms latency, 95% user satisfaction]"
    },
    {
      "title": "Proceedings of the 20th International Conference on Knowledge, Information and Creativity Support Systems (KICSS 2025)",
      "authors": "Edited by Tessai Hayama, Takayuki Ito, Takahiro Uchiya, Motoki Miura, Takahiro Kawaji, Takaya Yuizono, Atsuo Yoshitaka, Tokuro Matsuo, Shun Okuhara, Jawad Haqbeen, Sofia Sahab, Wen Gu, Shiyao Ding",
      "institution": "IEICE (The Institute of Electronics, Information and Communication Engineers)",
      "link": "https://arxiv.org/pdf/2512.20628",
      "code": null,
      "tags": [
        "multidisciplinary conference",
        "knowledge engineering",
        "creativity support systems",
        "human-computer interaction",
        "artificial intelligence",
        "peer-reviewed proceedings"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c8c9d50976ba52ad8c3511bc5a2800a053b1b858244a20cfcda006c283fdd5c_w640_q70.webp",
      "contributions": "1. Provides a multidisciplinary forum for researchers in AI, knowledge engineering, HCI, and creativity support systems. 2. Presents peer-reviewed proceedings following a double-blind review process. 3. Facilitates extended publication of selected papers in IEICE Transactions on Information and Systems.",
      "summary": "This is the proceedings volume for the 20th International Conference on Knowledge, Information and Creativity Support Systems (KICSS 2025). It compiles peer-reviewed papers from a multidisciplinary forum, with selected works recommended for further publication in a journal.",
      "mindmap": "graph LR\n        A[KICSS 2025 Proceedings] --> B(核心问题/Problem: 提供多学科研究论坛/Provide Multidisciplinary Research Forum)\n        A --> C(主要方法/Method: 双盲同行评审会议/Double-Blind Peer-Reviewed Conference)\n        A --> D(关键结果/Results: 出版会议论文集并推荐期刊发表/Publish Proceedings & Recommend Journal Publication)"
    },
    {
      "title": "Cooperation Through Indirect Reciprocity in Child-Robot Interactions",
      "authors": "Isabel Neto, Alexandre S. Pires, Filipa Correia, Fernando P. Santos",
      "institution": "Universidade de Lisboa, University of Amsterdam, Instituto Superior Técnico",
      "link": "https://arxiv.org/pdf/2512.20621",
      "code": null,
      "tags": [
        "human-robot interaction",
        "indirect reciprocity",
        "multi-armed bandit",
        "coordination dilemmas"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4a49edd2299eeb19bce07b564c8061c35b829f55eb48557d15dbeabbbd028e0_w640_q70.webp",
      "contributions": "1. Demonstrated that the mechanism of indirect reciprocity can be successfully transposed from human-human interactions to child-robot interactions. 2. Showed that children's behavioral strategies provide a sufficient signal for multi-armed bandit algorithms to learn cooperative actions. 3. Analyzed how differences in learning algorithms impact the dynamics and outcomes of human-AI cooperation.",
      "summary": "This paper investigates whether indirect reciprocity, a mechanism for sustaining cooperation, applies to child-robot interactions. The authors combine laboratory experiments with theoretical modeling, using multi-armed bandit algorithms for the robots. They find that indirect reciprocity does extend to these interactions and that robots can learn to cooperate based on children's strategies, though this learning is highly dependent on the human strategies revealed.",
      "mindmap": "graph LR\n    A[Cooperation Through Indirect Reciprocity in Child-Robot Interactions] --> B(核心问题/Problem: Can indirect reciprocity enable cooperation between children and robots?)\n    A --> C(主要方法/Method: Laboratory experiments and theoretical modeling with multi-armed bandit algorithms)\n    A --> D(关键结果/Results: IR extends to child-robot groups; robots can learn cooperation from children's strategies)"
    },
    {
      "title": "Efficient Asynchronous Federated Evaluation with Strategy Similarity Awareness for Intent-Based Networking in Industrial Internet of Things",
      "authors": "Shaowen Qin, Jianfeng Zeng, Haodong Guo, Xiaohuan Li, Jiawen Kang, Qian Chen, Dusit Niyato",
      "institution": "Guilin University of Electronic Technology, Guangdong University of Technology, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.20627",
      "code": null,
      "tags": [
        "federated learning",
        "Intent-Based Networking",
        "Industrial Internet of Things",
        "Asynchronous Federated Learning",
        "Strategy Similarity",
        "Multimodal Intent Alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17f53425c1430ea3ad8516d92a010c39c2936d478f64e21bad2b552f30214b23_w640_q70.webp",
      "contributions": "1. Proposes FEIBN, a federated learning framework for distributed policy verification in IIoT, enhancing privacy by avoiding raw data exposure. 2. Introduces SSAFL, a strategy similarity-aware mechanism for efficient node selection and asynchronous model updates to reduce communication overhead. 3. Leverages LLMs to align multimodal user intents into structured strategy tuples for automated policy generation and verification.",
      "summary": "This paper proposes FEIBN, a federated evaluation framework for Intent-Based Networking in IIoT. It uses LLMs to translate intents and a strategy similarity-aware asynchronous federated learning mechanism (SSAFL) for efficient, private policy verification. Experiments show SSAFL improves accuracy, convergence speed, and reduces cost by 27.8% compared to a baseline.",
      "mindmap": "graph LR\n    A[Efficient Asynchronous Federated Evaluation with Strategy Similarity Awareness] --> B[核心问题/Problem: Frequent strategy deployment & centralized verification are impractical in IIoT]\n    A --> C[主要方法/Method: FEIBN framework with LLM-based intent alignment & SSAFL mechanism]\n    A --> D[关键结果/Results: Improved accuracy, faster convergence, 27.8% cost reduction]"
    },
    {
      "title": "Quantum-Inspired Multi Agent Reinforcement Learning for Exploration Exploitation Optimization in UAV-Assisted 6G Network Deployment",
      "authors": "Mazyar Taghavi, Javad Vahidi",
      "institution": "Iran University of Science and Technology, Intelligent Knowledge City",
      "link": "https://arxiv.org/pdf/2512.20624",
      "code": null,
      "tags": [
        "multi-agent reinforcement learning",
        "Quantum-Inspired MARL",
        "Variational Quantum Circuits (VQC)",
        "Centralized Training Decentralized Execution (CTDE)",
        "UAV-assisted 6G",
        "Exploration-Exploitation Tradeoff"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e597fe9c176a66c0f7f571bd1af94114997e4ea6eb2664bc14f6b638a115985d_w640_q70.webp",
      "contributions": "1. Proposes a novel quantum-inspired framework integrating variational quantum circuits (VQCs) and QAOA with classical MARL to optimize the exploration-exploitation tradeoff. 2. Incorporates complementary probabilistic modeling (Bayesian inference, Gaussian processes) to capture latent environmental dynamics in a cooperative UAV scenario. 3. Demonstrates through experiments that the framework improves sample efficiency, convergence speed, and coverage performance compared to classical baselines like PPO and DDPG.",
      "summary": "This paper proposes a quantum-inspired multi-agent reinforcement learning framework to optimize the exploration-exploitation balance for UAV-assisted 6G network deployment. The method integrates variational quantum circuits and probabilistic modeling within a centralized training, decentralized execution paradigm. The results show it achieves superior performance in coverage and convergence compared to classical MARL methods.",
      "mindmap": "graph LR\n    A[Quantum-Inspired MARL for UAV 6G Deployment] --> B(核心问题/Problem: Exploration-Exploitation Tradeoff in MARL for UAV Coverage)\n    A --> C(主要方法/Method: VQC/QAOA + Probabilistic Models + CTDE)\n    A --> D(关键结果/Results: Improved Efficiency, Convergence, and Coverage)"
    },
    {
      "title": "Learning Evolving Latent Strategies for Multi-Agent Language Systems without Model Fine-Tuning",
      "authors": "Wenlong Tang",
      "institution": "Independent Researcher (No institutional affiliation inferred from provided content)",
      "link": "https://arxiv.org/pdf/2512.20629",
      "code": "https://github.com/wltang-dev/Latent-Strategy-RL-Agent",
      "tags": [
        "agent system",
        "multi-agent language systems",
        "latent strategy evolution",
        "reinforcement feedback",
        "external latent vectors",
        "dual-loop architecture"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c15e8361c02b5e6e0c755d3089af5adddafaad00ffda95b887b8eca526280761_w640_q70.webp",
      "contributions": "1. Proposes a novel multi-agent language framework that enables continual strategy evolution without fine-tuning the underlying language model's parameters. 2. Introduces a dual-loop architecture (behavior loop and language loop) that updates external latent vectors through environmental interaction and semantic reflection on generated text. 3. Demonstrates that this approach allows agents to develop stable, disentangled strategic styles and shows emergent adaptation capabilities, providing a low-cost, scalable, and interpretable form of abstract strategic representation.",
      "summary": "This paper addresses the limitation of static semantic representations in language models by proposing a framework where agents evolve strategies without model fine-tuning. The core method uses a dual-loop architecture to update external latent vectors through environmental rewards and reflection on generated text. The results show that this enables agents to develop adaptable and interpretable strategic behaviors, offering a scalable alternative to parameter tuning.",
      "mindmap": "graph LR\n    A[Learning Evolving Latent Strategies for Multi-Agent Language Systems without Model Fine-Tuning] --> B[核心问题/Problem: Static semantic representations in LLMs cannot evolve with experience.]\n    A --> C[主要方法/Method: Dual-loop architecture (Behavior Loop & Language Loop) updates external latent vectors via reinforcement and reflection.]\n    A --> D[关键结果/Results: Agents develop stable, disentangled strategies; latent spaces show convergence and emergent adaptation.]"
    },
    {
      "title": "MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation",
      "authors": "Chi-Hsiang Hsiao, Yi-Cheng Wang, Tzung-Sheng Lin, Yi-Ren Yeh, Chu-Song Chen",
      "institution": "National Taiwan University, E.SUN Financial Holding Co., Ltd., National Kaohsiung Normal University",
      "link": "https://arxiv.org/pdf/2512.20626",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "multimodal knowledge graph",
        "cross-modal reasoning",
        "visual document understanding",
        "retrieval-augmented generation",
        "entity-centric structure"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/425d6eb853edb40749e686474d27dc018d8a86017a4cd69160f9ac2081d36385_w640_q70.webp",
      "contributions": "1. Proposes a multimodal knowledge graph-based RAG framework that integrates visual cues into KG construction, retrieval, and answer generation for cross-modal reasoning. 2. Addresses the limitation of existing text-only KG-RAG methods by automatically building KGs that capture text-to-figure and figure-to-figure relationships. 3. Demonstrates superior performance over existing RAG approaches on both textual and multimodal question-answering tasks through comprehensive experiments.",
      "summary": "The paper introduces MegaRAG, a multimodal knowledge graph-based retrieval-augmented generation method designed to overcome the limitations of text-only RAG systems in understanding complex, long-form visual documents. It integrates visual information into the knowledge graph construction and retrieval process to enable better cross-modal reasoning. Experimental results show it consistently outperforms existing RAG methods on various question-answering tasks.",
      "mindmap": "graph LR\n        A[MegaRAG: 多模态知识图谱检索增强生成 / MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有RAG方法在长文档、多模态内容上理解不足 / Existing RAG struggles with long-form, multimodal document understanding]\n        C --> C1[构建融合视觉线索的多模态知识图谱 / Construct multimodal KG incorporating visual cues]\n        C --> C2[在多模态检索与生成中利用图谱 / Utilize KG in multimodal retrieval & generation]\n        D --> D1[在全局与细粒度QA任务上超越现有方法 / Outperforms existing methods on global & fine-grained QA]"
    },
    {
      "title": "MicroProbe: Efficient Reliability Assessment for Foundation Models with Minimal Data",
      "authors": "Aayam Bansal, Ishaan Gangwani",
      "institution": "IEEE (implied from email domain)",
      "link": "https://arxiv.org/pdf/2512.20630",
      "code": null,
      "tags": [
        "model evaluation & reliability",
        "reliability assessment",
        "uncertainty quantification",
        "strategic sampling",
        "foundation models",
        "probe selection"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43b9cf5db61863c7d69dd0ba1dd95c34144ed7e7c901f129f236bfb156cb89dc_w640_q70.webp",
      "contributions": "1. A novel strategic probe selection methodology that maximizes reliability coverage across five key dimensions with information-theoretic justification. 2. An advanced uncertainty-aware assessment framework with adaptive weighting and sophisticated consistency metrics. 3. Comprehensive empirical and cross-domain validation demonstrating significant improvements over random sampling with high statistical rigor.",
      "summary": "The paper introduces MicroProbe, a method for efficiently assessing the reliability of foundation models using only 100 strategically selected probe examples. It combines prompt diversity, uncertainty quantification, and adaptive weighting to detect failure modes. The approach is shown to achieve higher reliability scores with 90% lower cost and 95% coverage compared to traditional methods requiring thousands of examples.",
      "mindmap": "graph LR\n    A[MicroProbe: Efficient Reliability Assessment for Foundation Models with Minimal Data] --> B[核心问题/Problem: Traditional reliability assessment is computationally expensive, requiring thousands of examples.]\n    A --> C[主要方法/Method: Strategic probe selection across five reliability dimensions with uncertainty quantification and adaptive weighting.]\n    A --> D[关键结果/Results: 23.5% higher reliability scores, 90% cost reduction, 95% coverage maintained, validated across domains.]"
    },
    {
      "title": "Zero-Training Temporal Drift Detection for Transformer Sentiment Models: A Comprehensive Analysis on Authentic Social Media Streams",
      "authors": "Aayam Bansal, Ishaan Gangwani",
      "institution": "IEEE",
      "link": "https://arxiv.org/pdf/2512.20631",
      "code": null,
      "tags": [
        "sentiment analysis",
        "temporal drift",
        "zero-training detection",
        "transformer models",
        "social media streams",
        "model instability"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8e40c0a23df847aa858c5e0ce28602f612024103d66ccaea9f9da99a1dded46_w640_q70.webp",
      "contributions": "1. Demonstrated significant temporal drift in transformer sentiment models during real-world events, with accuracy drops up to 23.4% on authentic social media data. 2. Introduced four novel zero-training drift detection metrics that outperform embedding-based baselines and are suitable for production deployment. 3. Provided comprehensive statistical validation on 12,279 authentic social media posts from major events, establishing practical significance exceeding industry monitoring thresholds.",
      "summary": "This paper addresses the problem of temporal drift in transformer-based sentiment models during real-world events without requiring model retraining. It proposes a zero-training detection framework using novel inference-time metrics, validated on authentic social media data. The main conclusion is that this method effectively detects significant model instability and enables immediate deployment for real-time monitoring systems.",
      "mindmap": "graph LR\n    A[Zero-Training Temporal Drift Detection for Transformer Sentiment Models] --> B[核心问题/Problem: Transformer模型在动态事件期间的行为不稳定/Transformer model instability during dynamic events]\n    A --> C[主要方法/Method: 零训练检测框架与四个新指标/Zero-training detection framework with four novel metrics]\n    A --> D[关键结果/Results: 在真实数据上验证，准确率下降达23.4%，检测能力强/Validated on authentic data, 23.4% accuracy drop, strong detection capability]"
    },
    {
      "title": "Erkang-Diagnosis-1.1 Technical Report",
      "authors": "Jianbing Ma, Ao Feng, Zhenjie Gao, Xinyu Song, Li Su, Bin Chen, Wei Wang, Jiamin Wu",
      "institution": "Chengdu Lingshu Health Technology Corp. Ltd.",
      "link": "https://arxiv.org/pdf/2512.20632",
      "code": null,
      "tags": [
        "retrieval-augmented generation",
        "Qwen-3",
        "enhanced pre-training",
        "retrieval-augmented generation",
        "medical knowledge base",
        "healthcare assistant"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed164818e4da399ea74ba4b02c96fdf625f0f5b1c9130aaf2994523190ecf4eb_w640_q70.webp",
      "contributions": "1. Development of a specialized AI healthcare assistant (Erkang-Diagnosis-1.1) based on the Alibaba Qwen-3 model, 2. Integration of approximately 500GB of high-quality structured medical knowledge using a hybrid approach of enhanced pre-training and retrieval-augmented generation (RAG), 3. Demonstration of superior performance over GPT-4 in comprehensive medical exams through efficient 3-5 round interactions",
      "summary": "The paper introduces Erkang-Diagnosis-1.1, an AI healthcare assistant built on the Qwen-3 model. It integrates a large medical knowledge base using enhanced pre-training and retrieval-augmented generation to provide diagnostic suggestions. The model reportedly outperforms GPT-4 on medical exams.",
      "mindmap": "graph LR\n    A[Erkang-Diagnosis-1.1 Technical Report] --> B[核心问题/Problem: Need for professional, reliable AI health advisor]\n    A --> C[主要方法/Method: Qwen-3 + Enhanced Pre-training + RAG + 500GB Medical Knowledge]\n    A --> D[关键结果/Results: Outperforms GPT-4 in medical exams, provides diagnostic suggestions]"
    },
    {
      "title": "Enhancing Lung Cancer Treatment Outcome Prediction through Semantic Feature Engineering Using Large Language Models",
      "authors": "MunHwan Lee, Shaika Chowdhury, Xiaodi Li, Sivaraman Rajaganapathy, Eric W Klee, Ping Yang, Terence Sio, Liewei Wang, James Cerhan, Nansu NA Zong",
      "institution": "Mayo Clinic",
      "link": "https://arxiv.org/pdf/2512.20633",
      "code": null,
      "tags": [
        "clinical prediction",
        "large language models",
        "semantic feature engineering",
        "multi-modal data integration",
        "goal-oriented knowledge curator",
        "treatment outcome prediction"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7c8925ebbf05c9b81fd60fa118034a660d2673702659d23d8b6cf7c1d976903_w640_q70.webp",
      "contributions": "1. Proposes a novel framework using Large Language Models (LLMs) as Goal-oriented Knowledge Curators (GKC) to generate task-aligned semantic features from raw clinical data, 2. Demonstrates that GKC, as an offline preprocessing step, outperforms expert-engineered features, direct embeddings, and end-to-end transformers in predicting lung cancer treatment outcomes, 3. Shows the complementary value of integrating laboratory, genomic, and medication modalities through ablation studies, highlighting semantic representation quality as key for accuracy in sparse data.",
      "summary": "The paper addresses the challenge of predicting lung cancer treatment outcomes from sparse, heterogeneous clinical data by introducing a framework that uses Large Language Models as Goal-oriented Knowledge Curators to engineer semantic, task-specific features. This method outperforms traditional baselines, achieving a mean AUROC of 0.803, and demonstrates that high-quality semantic representation is crucial for predictive accuracy in clinical settings.",
      "mindmap": "graph LR\n    A[Enhancing Lung Cancer Treatment Outcome Prediction<br>增强肺癌治疗结果预测] --> B(核心问题/Problem: Sparse, heterogeneous clinical data<br>稀疏、异构的临床数据)\n    A --> C(主要方法/Method: LLMs as Goal-oriented Knowledge Curators<br>LLMs作为目标导向知识策展器)\n    A --> D(关键结果/Results: Superior AUROC 0.803, outperforms baselines<br>优异的AUROC 0.803，超越基线)"
    },
    {
      "title": "Real Time Detection and Quantitative Analysis of Spurious Forgetting in Continual Learning",
      "authors": "Weiwei Wang",
      "institution": "Shenzhen Sunline Tech Co., Ltd.",
      "link": "https://arxiv.org/pdf/2512.20634",
      "code": null,
      "tags": [
        "llm training",
        "catastrophic forgetting",
        "spurious forgetting",
        "shallow alignment",
        "deep alignment",
        "task alignment depth"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2920732eeec32977638a62ffbcf4b4b075dbdd77ebc58fa777ff8a10e117219_w640_q70.webp",
      "contributions": "1. Introduced a quantitative framework (shallow vs. deep alignment) to measure task alignment depth across token positions. 2. Developed real-time detection methods and analysis tools for identifying shallow alignment and spurious forgetting during training. 3. Proposed adaptive mitigation strategies that automatically distinguish forgetting types and promote deep alignment to improve model robustness.",
      "summary": "This paper addresses catastrophic forgetting in continual learning for LLMs by identifying that performance drops are often due to \"spurious forgetting\" from shallow task alignment. The authors propose a framework to quantitatively measure alignment depth, detect shallow alignment in real-time, and apply mitigation strategies to promote deep alignment. Experiments show their method accurately identifies spurious forgetting and improves model robustness against forgetting by 3.3-7.1% over baselines.",
      "mindmap": "graph LR\n    A[Real-Time Detection and Quantitative Analysis of Spurious Forgetting<br/>虚假遗忘的实时检测与定量分析] --> B[核心问题/Problem: Catastrophic forgetting from shallow task alignment<br/>由浅层任务对齐导致的灾难性遗忘]\n    A --> C[主要方法/Method: Quantitative metrics & real-time detection for alignment depth<br/>对齐深度的量化指标与实时检测]\n    A --> D[关键结果/Results: High identification accuracy & improved robustness<br/>高识别准确率与提升的鲁棒性]"
    },
    {
      "title": "Data-Free Pruning of Self-Attention Layers in LLMs",
      "authors": "Dhananjay Saikumar, Blesson Varghese",
      "institution": "University of St Andrews",
      "link": "https://arxiv.org/pdf/2512.20636",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "attention pruning",
        "data-free pruning",
        "Gate-Norm",
        "inference acceleration",
        "attention suppression hypothesis"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9338cbf768451f7709aa625ae03202bc7b84fcaa758ea1d75a6f5eaa4aa228c_w640_q70.webp",
      "contributions": "1. Proposes the Attention Suppression Hypothesis to explain the redundancy of deep self-attention layers in LLMs. 2. Introduces Gate-Norm, a one-shot, weight-only criterion for ranking and pruning attention sublayers without requiring data, forward passes, or fine-tuning. 3. Demonstrates that pruning 8-16 attention layers with Gate-Norm yields up to 1.30x higher inference throughput while maintaining accuracy within 2% of the baseline, matching data-driven methods but being ~1000x faster.",
      "summary": "The paper addresses the high inference cost of LLMs by proposing a data-free method to prune redundant self-attention layers. It introduces Gate-Norm, a fast weight-only criterion based on query-key coupling, which removes layers without needing calibration data or fine-tuning. The method significantly speeds up inference while preserving model accuracy, enabling practical LLM compression.",
      "mindmap": "graph LR\n    A[Data-Free Pruning of Self-Attention Layers in LLMs] --> B[核心问题/Problem: LLM推理成本高，注意力层是瓶颈/High LLM inference cost, attention layers are bottleneck]\n    A --> C[主要方法/Method: 提出Gate-Norm，基于权重无数据剪枝/Propose Gate-Norm, weight-only data-free pruning]\n    A --> D[关键结果/Results: 推理速度提升1.30倍，精度损失<2%，速度快1000倍/1.30x faster inference, <2% accuracy drop, 1000x faster scoring]"
    },
    {
      "title": "Uncovering Competency Gaps in Large Language Models and Their Benchmarks",
      "authors": "Matyas Bohacek, Nino Scherrer, Nicholas Dufour, Thomas Leung, Christoph Bregler, Stephanie C. Y. Chan",
      "institution": "Stanford University, Google DeepMind",
      "link": "https://arxiv.org/pdf/2512.20638",
      "code": "competency-gaps.github.io",
      "tags": [
        "llm evaluation",
        "sparse autoencoders",
        "benchmark gaps",
        "model gaps",
        "concept activations",
        "competency gaps"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6d5ab9e8ede467e65cbc2079e58ecf9b8d8ade8145f7e9e90f1b6f8382e288b_w640_q70.webp",
      "contributions": "1. Proposes a novel method using sparse autoencoders (SAEs) to automatically uncover fine-grained competency gaps in LLMs and benchmarks. 2. Introduces a representation-grounded evaluation approach that computes saliency-weighted performance scores based on model-internal concept activations. 3. Demonstrates the method's ability to identify specific model weaknesses (e.g., non-sycophantic behaviors) and benchmark coverage imbalances (e.g., over-representation of obedience concepts) without manual supervision.",
      "summary": "This paper addresses the problem that aggregated benchmark scores can hide specific weaknesses in LLMs and imbalances in benchmark coverage. The authors propose an automated method using sparse autoencoders to decompose benchmark performance into fine-grained concepts based on the model's internal representations. Their analysis of two models and ten benchmarks revealed model gaps in areas like non-sycophancy and safety, and benchmark gaps such as an over-representation of obedience-related concepts.",
      "mindmap": "graph LR\n        A[Uncovering Competency Gaps<br/>揭示能力差距] --> B[Problem: Aggregated metrics obscure model/benchmark gaps<br/>问题：聚合指标掩盖模型/基准差距]\n        A --> C[Method: Use Sparse Autoencoders (SAEs) for concept-level decomposition<br/>方法：使用稀疏自编码器进行概念级分解]\n        A --> D[Results: Found gaps in non-sycophancy, safety; benchmark over-represents obedience<br/>结果：发现非谄媚、安全方面的差距；基准过度代表服从性]"
    },
    {
      "title": "Forecasting N-Body Dynamics: A Comparative Study of Neural Ordinary Differential Equations and Universal Differential Equations",
      "authors": "Suriya R S, Prathamesh Dinesh Joshi, Rajat Dandekar, Raj Dandekar, Sreedath Panat",
      "institution": "Vizuara AI Labs",
      "link": "https://arxiv.org/pdf/2512.20643",
      "code": null,
      "tags": [
        "scientific machine learning",
        "Neural Ordinary Differential Equations",
        "Universal Differential Equations",
        "forecasting breakdown point",
        "n-body problem",
        "Julia"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06b852f384c602c478fd1ea2166cf9ac3e8442f63a46b1d479333a1e00699c6b_w640_q70.webp",
      "contributions": "1. Conducted a comparative study of Neural ODEs and Universal Differential Equations (UDEs) for forecasting n-body dynamics, a fundamental astrophysics problem. 2. Introduced and determined the \"forecasting breakdown point\" to quantify the minimal training data required for accurate future predictions. 3. Demonstrated that the UDE model, which blends known physics with neural networks, is significantly more data-efficient, requiring only 20% of data for a correct forecast compared to 90% for a Neural ODE.",
      "summary": "This paper compares two Scientific Machine Learning frameworks, Neural ODEs and Universal Differential Equations (UDEs), for forecasting the dynamics of the n-body problem. The study introduces the concept of a \"forecasting breakdown point\" to measure data efficiency and finds that the UDE model, which incorporates known physical laws, is far more efficient, requiring only 20% of the training data that a Neural ODE needs for accurate predictions.",
      "mindmap": "graph LR\n    A[Forecasting N-Body Dynamics<br/>N体动力学预测] --> B[核心问题/Problem<br/>传统黑盒模型忽略物理定律<br/>Traditional black-box models ignore physics]\n    A --> C[主要方法/Method<br/>使用科学机器学习框架<br/>Use Scientific ML frameworks (NODEs, UDEs)]\n    A --> D[关键结果/Results<br/>UDE数据效率更高<br/>UDE is more data-efficient]"
    },
    {
      "title": "Reasoning Relay: Evaluating Stability and Interchangeability of Large Language Models in Mathematical Reasoning",
      "authors": "Leo Lu, Jonathan Zhang, Sean Chua, Spencer Kim, Kevin Zhu, Sean O'Brien, Vasu Sharma",
      "institution": "Pennsylvania State University, Binghamton University, University of Toronto, UC Berkeley, Algoverse",
      "link": "https://arxiv.org/pdf/2512.20647",
      "code": null,
      "tags": [
        "reasoning evaluation",
        "chain-of-thought",
        "reasoning interchangeability",
        "process reward model",
        "token-level log-probability thresholds"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad2ec01f1b7eff609789d150706b31289a628fdb2bdaa6ac8867d9e30a0ea0c1_w640_q70.webp",
      "contributions": "1. Proposes a framework to evaluate the interchangeability of reasoning chains across LLMs, assessing if partial reasoning from one model can be reliably continued by another. 2. Introduces a method using token-level log-probability thresholds to truncate reasoning at different stages and a Process Reward Model (PRM) for evaluation. 3. Demonstrates that hybrid reasoning chains often preserve or even improve final accuracy and logical structure, suggesting interchangeability as an emerging property for modular reasoning in collaborative AI.",
      "summary": "This paper investigates whether partially completed reasoning chains from one large language model can be reliably continued by another model, using token-level log-probability thresholds to truncate reasoning and a Process Reward Model for evaluation. The study finds that hybrid reasoning chains often maintain or enhance accuracy and coherence, indicating that reasoning interchangeability is a viable property for collaborative AI systems.",
      "mindmap": "graph LR\n    A[Reasoning Relay: Evaluating Stability and Interchangeability of Large Language Models in Mathematical Reasoning] --> B[核心问题/Problem: 不同LLM间的推理链是否可互换?/Interchangeability of reasoning across LLMs?]\n    A --> C[主要方法/Method: 使用log-probability阈值截断推理链,并用PRM评估/Use log-probability thresholds to truncate reasoning, evaluate with PRM]\n    A --> D[关键结果/Results: 混合推理链保持或提升准确性与逻辑结构/Hybrid reasoning chains preserve or improve accuracy & logical structure]"
    },
    {
      "title": "Mixture of Attention Schemes (MoAS): Learning to Route Between MHA, GQA, and MQA",
      "authors": "Esmail Gumaan",
      "institution": "Independent Researcher (Inferred from personal email domain)",
      "link": "https://arxiv.org/pdf/2512.20650",
      "code": "https://github.com/Esmail-ibraheem/Mixture-of-Attention-Schemes-MoAS",
      "tags": [
        "llm inference",
        "Mixture of Attention Schemes",
        "KV Cache",
        "Dynamic Routing",
        "Conditional Computation",
        "Attention Mechanism"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/151d0589c37dc455317c2c4d1e613c5f722207da0abcb0abaf82373ef04ee19d_w640_q70.webp",
      "contributions": "1. Proposes Mixture of Attention Schemes (MoAS), a novel architecture that dynamically routes tokens between MHA, GQA, and MQA attention schemes. 2. Demonstrates that dynamic routing outperforms a static averaging of attention schemes, validating the learned routing approach. 3. Shows the method achieves performance competitive with the high-quality MHA baseline while offering potential for conditional compute and memory efficiency.",
      "summary": "This paper addresses the trade-off between model quality and inference efficiency in Transformer attention mechanisms. It proposes MoAS, which uses a learned router to dynamically select between MHA, GQA, and MQA for each token. Experiments show dynamic routing outperforms static mixtures and matches MHA performance, offering a path to efficient conditional computation.",
      "mindmap": "graph LR\n    A[MoAS: Mixture of Attention Schemes] --> B[核心问题/Problem<br>Attention机制的质量与效率权衡<br>Trade-off between quality and efficiency]\n    A --> C[主要方法/Method<br>动态路由选择注意力方案<br>Dynamic routing between MHA, GQA, MQA]\n    A --> D[关键结果/Results<br>动态路由优于静态混合，性能媲美MHA<br>Dynamic routing outperforms static mixture, competitive with MHA]"
    },
    {
      "title": "AIAuditTrack: A Framework for AI Security system",
      "authors": "Zixun Luo, Yuhang Fan, Yufei Li, Youzhi Zhang, Hengyu Lin, Ziqi Wang",
      "institution": "Huazhong University of Science and Technology, Lingnan University, Centre for Artificial Intelligence and Robotics (CAIR) Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences, Tsinghua University, Fujian Jiangxia University",
      "link": "https://arxiv.org/pdf/2512.20649",
      "code": null,
      "tags": [
        "AI governance and auditing",
        "blockchain",
        "decentralized identity (DID)",
        "verifiable credentials (VC)",
        "risk diffusion algorithm",
        "interaction graph"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74b6835bdebf655288e51122fb875aaa032b286789052e6467724b2eb1e0af84_w640_q70.webp",
      "contributions": "1. Proposes a blockchain-based framework (AiAuditTrack) for recording and governing AI usage traffic to enable auditing and risk traceability. 2. Introduces an identity management mechanism using Decentralized Identity (DID) and Verifiable Credentials (VC) to establish trusted and identifiable AI entities. 3. Designs a risk diffusion algorithm on a dynamic interaction graph model to trace the source of risky behaviors and propagate warnings.",
      "summary": "This paper addresses the security and accountability challenges in AI-driven applications by proposing AiAuditTrack, a blockchain framework that uses decentralized identity and verifiable credentials to record AI interaction data and enable auditing. It models AI entities as nodes in a graph and introduces a risk diffusion algorithm for tracing risky behavior origins. The framework's feasibility is demonstrated through blockchain performance metrics (TPS) under large-scale recording scenarios.",
      "mindmap": "graph LR\n    A[AiAuditTrack: AI安全系统框架<br>AiAuditTrack: AI Security System Framework] --> B[核心问题/Problem: AI交互数据激增导致安全与责任归属挑战<br>Explosive AI interaction data raises security & accountability issues]\n    A --> C[主要方法/Method: 基于区块链的框架，使用DID/VC进行身份管理，设计风险扩散算法<br>Blockchain-based framework with DID/VC for identity & risk diffusion algorithm]\n    A --> D[关键结果/Results: 实现可验证的AI审计与风险溯源，系统在大规模记录下稳定<br>Enables verifiable AI auditing & risk tracing, system stable at scale]"
    },
    {
      "title": "AI-Driven Decision-Making System for Hiring Process",
      "authors": "Vira Filatova, Andrii Zelenchuk, Dmytro Filatov",
      "institution": "Covijn Ltd., Aimech Technologies Corp.",
      "link": "https://arxiv.org/pdf/2512.20652",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent system",
        "LLM orchestration",
        "human-in-the-loop",
        "explainable scoring",
        "public-data verification"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af0225e1b8b3f96dbb1b944ce2ab06438c60ac8bcf7ef93a1f210771fa73aae4_w640_q70.webp",
      "contributions": "1. A modular multi-agent AI hiring assistant that integrates heterogeneous inputs (documents, video, public data) into a structured profile. 2. An LLM-orchestrated pipeline with strict constraints to reduce output variability and generate traceable, component-level rationales for scoring. 3. A configurable candidate ranking system based on aggregated technical fit, culture fit, and normalized risk penalties, evaluated with a proposed efficiency metric (expected time per qualified candidate).",
      "summary": "This paper addresses the bottleneck of early-stage candidate validation in hiring by proposing an AI-driven, modular multi-agent system. The system integrates and processes diverse candidate inputs through an LLM-orchestrated pipeline to produce explainable scores and rankings. Evaluation on real applicants shows the system significantly improves screening efficiency, reducing the expected time per qualified candidate compared to human recruiters, while keeping a human as the final decision authority.",
      "mindmap": "graph LR\n        Root[”AI-Driven Hiring System<br>AI驱动的招聘系统”] --> Problem[”核心问题/Problem<br>Heterogeneous inputs & screening bottleneck<br>输入异构与筛选瓶颈”]\n        Root --> Method[”主要方法/Method<br>Multi-agent LLM pipeline with constraints<br>带约束的多智能体LLM流程”]\n        Root --> Results[”关键结果/Results<br>Higher efficiency & lower cost<br>更高效率与更低成本”]"
    },
    {
      "title": "Memory Bear AI A Breakthrough from Memory to Cognition Toward Artificial General Intelligence",
      "authors": "Deliang Wen, Ke Sun",
      "institution": "Not specified in provided content",
      "link": "https://arxiv.org/pdf/2512.20651",
      "code": null,
      "tags": [
        "agent system",
        "memory architecture",
        "long-term conversation",
        "hallucination reduction",
        "multimodal perception",
        "cognitive integration"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9c13cde65ef804fade26e06361a8d03517ad2394b3e21295ae77d2b5b462c29_w640_q70.webp",
      "contributions": "1. Proposes the Memory Bear system, a human-like memory architecture for LLMs grounded in cognitive science principles. 2. Achieves a full-chain reconstruction of LLM memory mechanisms by integrating multimodal perception, dynamic memory maintenance, and adaptive cognitive services. 3. Demonstrates significant performance improvements in knowledge fidelity, retrieval efficiency, and hallucination reduction across multiple domains compared to existing solutions.",
      "summary": "This paper addresses the inherent memory limitations of LLMs, such as restricted context and hallucination, by proposing the Memory Bear system. Memory Bear constructs a cognitive science-inspired memory architecture to enhance long-term dialogue and reasoning. Experimental results show it outperforms existing methods in accuracy and efficiency, marking a step from memory to cognition in AI.",
      "mindmap": "graph LR\n    A[Memory Bear AI<br>论文标题/Paper Title] --> B[LLM Memory Limitations<br>核心问题/Problem]\n    A --> C[Human-like Memory Architecture<br>主要方法/Method]\n    A --> D[Performance Breakthrough<br>关键结果/Results]\n    B --> B1[Restricted Context & Forgetting<br>受限上下文与遗忘]\n    B --> B2[Hallucination & Redundancy<br>幻觉与冗余]\n    C --> C1[Multimodal Perception<br>多模态感知]\n    C --> C2[Dynamic Memory Maintenance<br>动态记忆维护]\n    C --> C3[Adaptive Cognitive Services<br>自适应认知服务]\n    D --> D1[Higher Accuracy & Efficiency<br>更高准确率与效率]\n    D --> D2[Reduced Hallucination<br>降低幻觉率]\n    D --> D3[Improved Reasoning<br>增强推理能力]"
    },
    {
      "title": "MaskOpt: A Large-Scale Mask Optimization Dataset to Advance AI in Integrated Circuit Manufacturing",
      "authors": "Yuting Hu, Lei Zhuang, Hua Xiang, Jinjun Xiong, Gi-Joon Nam",
      "institution": "University at Buffalo, IBM Research",
      "link": "https://arxiv.org/pdf/2512.20655",
      "code": null,
      "tags": [
        "others",
        "mask optimization",
        "optical proximity correction",
        "inverse lithography technique",
        "deep learning",
        "benchmark dataset"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce9bc1ac552258257c450a9bc4d4c4ae0264c958efae291f56fc44af367bf07a_w640_q70.webp",
      "contributions": "1. Introduces MaskOpt, a large-scale benchmark dataset for AI-driven mask optimization constructed from real 45nm IC designs, addressing limitations of synthetic data. 2. The dataset preserves standard-cell hierarchy and includes varying context window sizes to enable cell- and context-aware model training. 3. Provides comprehensive benchmarks by evaluating state-of-the-art deep learning models, revealing performance trade-offs and validating the importance of contextual and cell-aware inputs.",
      "summary": "The paper presents MaskOpt, a large-scale dataset built from real integrated circuit designs to advance deep learning for mask optimization in semiconductor manufacturing. It addresses the limitations of existing synthetic datasets by including cell hierarchy and surrounding context. Benchmarking results demonstrate the dataset's utility and highlight the critical role of context and cell information for accurate mask generation.",
      "mindmap": "graph LR\n    A[MaskOpt Dataset<br/>MaskOpt数据集] --> B[核心问题/Problem<br/>Existing datasets are synthetic, lack cell hierarchy & context<br/>现有数据集为合成数据，缺乏单元层次和上下文];\n    A --> C[主要方法/Method<br/>Build large-scale dataset from real 45nm IC designs with cell-aware tiles & context windows<br/>基于真实45nm设计构建大规模数据集，包含单元感知切片和上下文窗口];\n    A --> D[关键结果/Results<br/>Benchmarks show model trade-offs, context & cell info are crucial<br/>基准测试显示模型权衡，上下文和单元信息至关重要];"
    },
    {
      "title": "Managing the Stochastic: Foundations of Learning in Neuro-Symbolic Systems for Software Engineering",
      "authors": "Matthew Thompson",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.20660",
      "code": null,
      "tags": [
        "agent system",
        "dual-state architecture",
        "atomic action pairs",
        "guard functions",
        "neuro-symbolic systems",
        "code generation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a73fceac46d6997904de43696e8db407d645c6e4388012a9e24a3b9565e06fb_w640_q70.webp",
      "contributions": "1. Proposes a control boundary that treats the LLM as a stochastic environment component, not the decision-making agent, to manage its unpredictability. 2. Formalizes a Dual-State Architecture separating deterministic workflow state from stochastic environment state. 3. Introduces Atomic Action Pairs and Guard Functions to couple generation with verification as indivisible transactions, projecting probabilistic outputs onto observable workflow state.",
      "summary": "This paper addresses the problem of stochastic failures in AI coding agents by proposing a neuro-symbolic architectural framework that treats the LLM as part of the environment. The method uses a Dual-State Architecture with Atomic Action Pairs and Guard Functions to separate deterministic control from stochastic generation. The main conclusion is that such architectural constraints can significantly improve task success rates for qualified models, potentially substituting for parameter scale in achieving reliable code generation.",
      "mindmap": "graph LR\n    A[Managing the Stochastic<br>管理随机性] --> B[Problem: LLM-based agents prone to stochastic failures<br>问题: 基于LLM的智能体易受随机性故障影响]\n    A --> C[Method: Dual-State Architecture, Atomic Action Pairs, Guard Functions<br>方法: 双态架构, 原子动作对, 守卫函数]\n    A --> D[Results: Improved success rates, architectural constraints can substitute for scale<br>结果: 成功率提升, 架构约束可替代模型规模]"
    },
    {
      "title": "From Fake Focus to Real Precision: Confusion-Driven Adversarial Attention Learning in Transformers",
      "authors": "Yawei Liu",
      "institution": "Chinese Academy of Sciences, Computer Network Information Center",
      "link": "https://arxiv.org/pdf/2512.20661",
      "code": null,
      "tags": [
        "sentiment analysis",
        "adversarial training",
        "attention mechanism",
        "policy gradient",
        "transformer",
        "model interpretability"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6dd81ed17263c1d20f831b211a88f9bc1399e87818af70003e7ba1196a7ddddf_w640_q70.webp",
      "contributions": "1. Proposes an Adversarial Feedback for Attention (AFA) training mechanism to automatically redistribute attention weights without manual supervision. 2. Introduces a dynamic masking strategy and a discriminator in an adversarial framework to identify and correct suboptimal attention. 3. Employs a policy gradient approach to efficiently optimize attention distributions, leading to improved performance on sentiment analysis tasks and a 12.6% gain when applied to large language models.",
      "summary": "The paper identifies that Transformer models for sentiment analysis often misallocate attention to common words, missing important but less frequent terms. To solve this, it proposes an Adversarial Feedback for Attention (AFA) mechanism using dynamic masking and policy gradient optimization to refine attention distributions automatically. Experiments show the method achieves state-of-the-art results and significantly boosts performance in large language models.",
      "mindmap": "graph LR\n    A[From Fake Focus to Real Precision<br>从虚假聚焦到真实精度] --> B[核心问题/Problem<br>Transformer注意力分配不当<br>Transformer Misallocates Attention]\n    A --> C[主要方法/Method<br>对抗性注意力反馈(AFA)<br>Adversarial Feedback for Attention]\n    A --> D[关键结果/Results<br>SOTA性能 & LLM提升12.6%<br>SOTA Performance & 12.6% LLM Gain]\n    B --> C\n    C --> D"
    },
    {
      "title": "Quantifying Laziness, Decoding Suboptimality, and Context Degradation in Large Language Models",
      "authors": "Yiqing Ma, Jung-Hua Liu",
      "institution": "Universiti Malaya, National Chung Cheng University",
      "link": "https://arxiv.org/pdf/2512.20662",
      "code": null,
      "tags": [
        "llm evaluation",
        "laziness",
        "decoding suboptimality",
        "context degradation",
        "instruction-following",
        "long-context"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c503ae7a717782d28701da19cc7269ead2f9a34b5478457e18e791787fc94dea_w640_q70.webp",
      "contributions": "1. Quantified the \"laziness\" artifact in LLMs, showing widespread failure to fully comply with complex multi-part instructions. 2. Provided empirical evidence challenging the prevalence of \"decoding suboptimality\" in a simple reasoning task, suggesting greedy decoding may align with high-confidence solutions. 3. Demonstrated surprising robustness against \"context degradation\" in long, chaotic conversations, indicating LLMs may internally mitigate context forgetting in retrieval scenarios.",
      "summary": "This paper quantifies three behavioral artifacts in Large Language Models (LLMs) through controlled experiments. The results show that while LLMs are often \"lazy\" in following complex instructions, they show limited decoding suboptimality and surprising robustness against context degradation in long conversations. The findings suggest instruction compliance remains a challenge, but some hypothesized failure modes like context forgetting may be less severe in straightforward scenarios.",
      "mindmap": "graph LR\n        A[Quantifying Laziness, Decoding Suboptimality, and Context Degradation in Large Language Models] --> B(核心问题/Problem: LLM行为缺陷/LLM Behavioral Artifacts)\n        A --> C(主要方法/Method: 三个受控实验/Three Controlled Experiments)\n        A --> D(关键结果/Results: 懒惰普遍/Laziness Widespread, 解码次优有限/Limited Decoding Suboptimality, 上下文退化稳健/Robust Context Degradation)"
    },
    {
      "title": "Eidoku: A Neuro-Symbolic Verification Gate for LLM Reasoning via Structural Constraint Satisfaction",
      "authors": "Shinobu Miya",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.20664",
      "code": "https://github.com/ShinobuMiya/Eidoku",
      "tags": [
        "reasoning verification",
        "structural constraint satisfaction",
        "neuro-symbolic verification",
        "hallucination detection",
        "constraint satisfaction problem",
        "system-2 gate"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62978c31bb485ddbb117f5081c33f608c011c35aca015e4df8eaad0dd42439ff_w640_q70.webp",
      "contributions": "1. Reformulates LLM reasoning verification as a Constraint Satisfaction Problem (CSP) independent of generation likelihood, focusing on structural feasibility instead of statistical plausibility. 2. Introduces a lightweight System-2 gate, Eidoku, that uses a context-calibrated cost threshold derived from intrinsic statistics to reject candidates based on structural violation cost. 3. Demonstrates the ability to deterministically reject \"smooth falsehoods\"—high-probability but structurally inconsistent statements—which probability-based verifiers cannot detect.",
      "summary": "The paper addresses LLM hallucinations by proposing Eidoku, a neuro-symbolic verification gate that treats reasoning verification as a structural constraint satisfaction problem, independent of generation likelihood. It uses a cost function based on graph connectivity, feature consistency, and logical entailment to reject structurally inconsistent statements. Experiments show this approach can deterministically reject high-probability yet structurally disconnected hallucinations, serving as a sanity check for generative reasoning.",
      "mindmap": "graph LR\n    A[Eidoku: 神经符号验证门<br>Neuro-Symbolic Verification Gate] --> B[核心问题/Problem: LLM产生高概率幻觉<br>LLMs produce high-likelihood hallucinations]\n    A --> C[主要方法/Method: 基于结构约束满足的验证<br>Verification via Structural Constraint Satisfaction]\n    A --> D[关键结果/Results: 拒绝平滑错误，确定性检测<br>Rejects smooth falsehoods, deterministic detection]"
    },
    {
      "title": "Dominating vs. Dominated: Generative Collapse in Diffusion Models",
      "authors": "Hayeon Jeong, Jong-Seok Lee",
      "institution": "Yonsei University",
      "link": "https://arxiv.org/pdf/2512.20666",
      "code": null,
      "tags": [
        "text-to-image generation",
        "diffusion models",
        "cross-attention",
        "generative collapse",
        "multi-concept generation",
        "attention dynamics"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9e3797020eb871e661d9cda59fdbe8a7bdf314a2935eff1ccf97c35a90d39ee_w640_q70.webp",
      "contributions": "1. Identifies and defines the Dominant-vs-Dominated (DvD) phenomenon in multi-concept text-to-image generation, 2. Introduces DominanceBench for systematic analysis of the DvD imbalance, 3. Provides causal analysis from data (limited instance diversity) and architecture (cross-attention saturation & distributed head mechanisms) perspectives.",
      "summary": "This paper investigates the \"Dominant-vs-Dominated\" (DvD) imbalance in diffusion models, where one concept token suppresses others in multi-concept prompts. The authors analyze this using a new benchmark and find causes in limited training data diversity and cross-attention dynamics. Their findings offer insights into generative collapse for more reliable text-to-image generation.",
      "mindmap": "graph LR\n        A[Dominating vs. Dominated<br/>支配 vs. 被支配] --> B[核心问题/Problem<br/>Multi-concept prompt generation imbalance<br/>多概念提示生成失衡];\n        A --> C[主要方法/Method<br/>Introduce DominanceBench & analyze causes<br/>引入DominanceBench并分析原因];\n        A --> D[关键结果/Results<br/>Data diversity & attention dynamics cause DvD<br/>数据多样性和注意力动态导致DvD];"
    },
    {
      "title": "Forward Only Learning for Orthogonal Neural Networks of any Depth",
      "authors": "Paul Caillon, Alex Colagrande, Erwan Fagnou, Blaise Delattre, Alexandre Allauzen",
      "institution": "Université Paris-Dauphine - PSL, ESPCI PSL",
      "link": "https://arxiv.org/pdf/2512.20668",
      "code": "https://github.com/",
      "tags": [
        "neural network training algorithms",
        "forward-only learning",
        "orthogonal neural networks",
        "backpropagation alternative",
        "FOTON",
        "PEPITA"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14ce0cf521f1d147eae7293cef8a5a53d6a0ca2fda6723bc707498635d351a0b_w640_q70.webp",
      "contributions": "1. Theoretical analysis of limitations in existing forward-only frameworks like PEPITA, 2. Design of a forward-only algorithm equivalent to backpropagation under linear/orthogonal assumptions, 3. Introduction of FOTON, a practical forward-only training method for orthogonal networks that scales to any depth and works on CNNs>",
      "summary": "This paper addresses the computational burden of backpropagation by proposing a forward-only training algorithm called FOTON for orthogonal neural networks. The method replaces the backward pass with a modulated forward pass, enabling training of deep networks without backpropagation. Experiments show FOTON outperforms prior forward-only methods and scales to networks of any depth, including convolutional architectures.",
      "mindmap": "graph LR\n    A[Forward Only Learning for Orthogonal Neural Networks<br>前向传播学习用于正交神经网络] --> B[Problem: Backpropagation is computationally expensive<br>问题: 反向传播计算成本高]\n    A --> C[Method: FOTON - Forward-Only Training with modulated forward pass<br>方法: FOTON - 使用调制前向传播的前向训练]\n    A --> D[Results: Trains networks of any depth, outperforms PEPITA<br>结果: 可训练任意深度网络，性能优于PEPITA]"
    },
    {
      "title": "Improving Cardiac Risk Prediction Using Data Generation Techniques",
      "authors": "Alexandre Cabodevila, Pedro Gamallo-Fernandez, Juan C. Vidal, Manuel Lama",
      "institution": "Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela",
      "link": "https://arxiv.org/pdf/2512.20669",
      "code": null,
      "tags": [
        "generative models",
        "Conditional Variational Autoencoder",
        "synthetic data generation",
        "cardiac risk prediction",
        "data augmentation",
        "clinical records"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0661f3f558f42310471788ea2bad662661692287e3137248998355eb91c8470b_w640_q70.webp",
      "contributions": "1. Proposes a novel architecture based on a Conditional Variational Autoencoder (CVAE) for generating realistic and coherent synthetic clinical records. 2. Addresses key limitations in medical data analysis such as data scarcity, unsuitability, and high prevalence of missing values. 3. Demonstrates that using the generated synthetic data improves the accuracy of cardiac risk prediction classifiers, outperforming other deep learning data generation approaches.",
      "summary": "This paper addresses the challenges of scarce and incomplete real-world medical data for cardiac risk prediction by proposing a Conditional Variational Autoencoder (CVAE) architecture to generate realistic synthetic clinical records. The generated data is used to augment datasets, which in turn enhances the performance of cardiac risk prediction models. The results show that the proposed method successfully generates coherent data and improves classifier accuracy compared to state-of-the-art alternatives.",
      "mindmap": "graph LR\n    A[Improving Cardiac Risk Prediction Using Data Generation Techniques] --> B(核心问题/Problem: 真实医疗数据稀缺、不完整且存在缺失值/Real-world medical data is scarce, incomplete, and has missing values)\n    A --> C(主要方法/Method: 基于条件变分自编码器的架构生成合成临床记录/CVAE-based architecture for synthetic clinical record generation)\n    A --> D(关键结果/Results: 生成的数据提高了心脏风险预测分类器的准确性/Generated data improves cardiac risk prediction classifier accuracy)"
    },
    {
      "title": "Bridging the AI Trustworthiness Gap between Functions and Norms",
      "authors": "Daan Di Scala, Sophie Lathouwers, Michael van Bekkum",
      "institution": "TNO Netherlands Organisation for Applied Scientific Research, Utrecht University",
      "link": "https://arxiv.org/pdf/2512.20671",
      "code": null,
      "tags": [
        "trustworthy ai",
        "Trustworthy AI",
        "AI Act",
        "Functional AI Trustworthiness",
        "Normative AI Trustworthiness",
        "Conceptual Language"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/578b1d068cdd40bde2c92d3a17699f222634e6ec69ca5580ca2eda375c8105ca_w640_q70.webp",
      "contributions": "1. Identifies and articulates the gap between Functional Trustworthy AI (FTAI) and Normative Trustworthy AI (NTAI). 2. Proposes the development of a semantic/conceptual language as a bridge to link FTAI implementations with NTAI regulations. 3. Provides key considerations and a future roadmap for assessing AI trustworthiness using this integrated framework.",
      "summary": "This position paper identifies a gap between the functional implementation (FTAI) and normative regulation (NTAI) of Trustworthy AI, which hinders system assessment. It proposes bridging this gap by developing a semantic language to map technical functions to legal norms. The conclusion is that such a framework will help developers implement compliant systems and stakeholders assess trustworthiness.",
      "mindmap": "graph LR\n        A[论文标题: Bridging the AI Trustworthiness Gap<br>论文标题: Bridging the AI Trustworthiness Gap] --> B[核心问题/Problem: FTAI与NTAI存在鸿沟<br>核心问题/Problem: Gap between FTAI and NTAI]\n        A --> C[主要方法/Method: 提出语义语言作为桥梁<br>主要方法/Method: Propose a semantic language as a bridge]\n        A --> D[关键结果/Results: 提供评估框架与未来路线图<br>关键结果/Results: Provide assessment framework & future roadmap]"
    },
    {
      "title": "Disentangling Fact from Sentiment: A Dynamic Conflict-Consensus Framework for Multimodal Fake News Detection",
      "authors": "Weilin Zhou, Zonghao Ying, Junjie Mu, Shengwei Tian, Quanchen Zou, Deyue Zhang, Dongdong Yang, Xiangzheng Zhang",
      "institution": "Xinjiang University, 360 AI Security Lab, Beihang University, Politecnico di Milano",
      "link": "https://arxiv.org/pdf/2512.20670",
      "code": null,
      "tags": [
        "multimodal fake news detection",
        "inconsistency detection",
        "feature disentanglement",
        "conflict-consensus mechanism",
        "physics-inspired dynamics",
        "cross-modal discrepancy"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c06ff160d4943f1ae5c4648f6e6cd042a0c1232af6212adf0021ba7f0b7c2ab_w640_q70.webp",
      "contributions": "1. Proposes a paradigm shift from consistency-seeking to inconsistency-seeking for multimodal fake news detection, explicitly amplifying cross-modal contradictions as evidence. 2. Introduces a novel framework (DCCF) that disentangles inputs into independent Fact and Sentiment spaces to separate objective mismatches from emotional dissonance. 3. Employs physics-inspired feature dynamics and a conflict-consensus mechanism to actively polarize and standardize local discrepancies against a global context for robust judgment.",
      "summary": "The paper identifies a flaw in mainstream multimodal fake news detection, which treats cross-modal discrepancies as noise, and proposes a new Dynamic Conflict-Consensus Framework (DCCF) designed to actively seek and amplify these inconsistencies as evidence of fabrication. The method disentangles fact from sentiment and uses physics-inspired dynamics to extract conflicts. Experiments show DCCF outperforms state-of-the-art baselines with an average accuracy improvement of 3.52%.",
      "mindmap": "graph LR\n    A[Disentangling Fact from Sentiment: A Dynamic Conflict-Consensus Framework for Multimodal Fake News Detection] --> B[核心问题/Problem: 主流一致性融合将关键跨模态差异误判为噪声，稀释了伪造证据]\n    A --> C[主要方法/Method: 提出DCCF框架，解耦事实与情感，利用物理启发的动力学主动放大矛盾]\n    A --> D[关键结果/Results: 在三个真实数据集上超越SOTA，平均准确率提升3.52%]"
    },
    {
      "title": "Revisiting the Learning Objectives of Vision-Language Reward Models",
      "authors": "Simon Roy, Samuel Barbeau, Giovanni Beltrame, Christian Desrosiers, Nicolas Thome",
      "institution": "Polytechnique Montréal, École de Technologie Supérieure, Sorbonne Université",
      "link": "https://arxiv.org/pdf/2512.20675",
      "code": null,
      "tags": [
        "reinforcement learning",
        "reward modeling",
        "vision-language models",
        "triplet loss",
        "Meta-World",
        "contrastive learning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca907344b4dbef770bf1367dee07e4ba6b6f7a2b525ad28c7bf8d0ff11f62075_w640_q70.webp",
      "contributions": "1. Proposes a unified framework to isolate and evaluate the impact of learning objectives in vision-language reward models, controlling for backbone, data, and evaluation environments. 2. Demonstrates that a simple triplet loss objective can outperform more complex state-of-the-art methods for reward modeling. 3. Suggests that improvements in recent approaches may be attributed more to differences in training data and model architectures rather than the complexity of their learning objectives.",
      "summary": "This paper investigates the impact of different learning objectives for adapting vision-language models into reward functions for embodied intelligence. By comparing methods under a unified framework, the authors find that a simple triplet loss outperforms more complex state-of-the-art objectives. The results suggest that recent improvements in reward modeling may stem from data and architecture differences rather than objective complexity.",
      "mindmap": "graph LR\n        A[Revisiting VLM Reward Models] --> B(核心问题/Problem: 难以比较不同奖励模型目标/Difficulty in comparing reward model objectives)\n        A --> C(主要方法/Method: 统一框架评估/Unified framework evaluation)\n        A --> D(关键结果/Results: 三元组损失更优/Triplet loss outperforms SOTA)"
    },
    {
      "title": "HyDRA: Hierarchical and Dynamic Rank Adaptation for Mobile Vision Language Model",
      "authors": "Yuanhao Xi, Xiaohuan Bing, Ramin Yahyapour",
      "institution": "Liaoning Technical University, University of Göttingen, Gesellschaft für Wissenschaftliche Datenverarbeitung mbH Göttingen",
      "link": "https://arxiv.org/pdf/2512.20674",
      "code": null,
      "tags": [
        "multi-modal training",
        "Low-Rank Adaptation (LoRA)",
        "parameter-efficient fine-tuning",
        "rank adaptation",
        "mobile vision language model",
        "dynamic scheduling"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9589d36616e78e4826e61d2dbafa4ccc718075f3659352d4d01c1b6f4795a02a_w640_q70.webp",
      "contributions": "1. Proposes HyDRA, a parameter-efficient fine-tuning framework for mobile VLMs that implements hierarchical and dynamic rank scheduling. 2. Introduces hierarchical optimization with coarse-grained (layer-level) and fine-grained (intra-layer) rank assignment. 3. Employs dynamic adjustment via an end-to-end automatic optimization using a lightweight performance model to determine ranks during fine-tuning.",
      "summary": "This paper introduces HyDRA, a parameter-efficient fine-tuning framework for mobile Vision Language Models (VLMs) that addresses the computational inefficiency of standard LoRA by implementing hierarchical and dynamic rank scheduling. The method uses a two-pronged optimization strategy and a lightweight performance model to adjust ranks automatically. Experiments show HyDRA outperforms baselines, achieving a 4.7% average improvement without extra parameters and sometimes surpassing full fine-tuning.",
      "mindmap": "graph LR\n    A[HyDRA: Hierarchical and Dynamic Rank Adaptation for Mobile Vision Language Model] --> B[核心问题/Problem: Standard LoRA with fixed rank is insufficient for training mobile VLMs]\n    A --> C[主要方法/Method: HyDRA framework with hierarchical & dynamic rank scheduling]\n    A --> D[关键结果/Results: Outperforms baseline by 4.7%, no extra parameters, sometimes beats full fine-tuning]"
    },
    {
      "title": "Mechanism-Based Intelligence (MBI): Differentiable Incentives for Rational Coordination and Guaranteed Alignment in Multi-Agent Systems",
      "authors": "Stefano Grassi",
      "institution": "None (No affiliation or email domain provided in the given content)",
      "link": "https://arxiv.org/pdf/2512.20688",
      "code": null,
      "tags": [
        "multi-agent systems",
        "Differentiable Price Mechanism",
        "Dominant Strategy Incentive Compatibility",
        "VCG-equivalent incentive",
        "Dec-POMDPs",
        "Bayesian Incentive Compatibility"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfdd6bb51cf65ab558a1d13cbaf0fbdda25f9c06c58be3e201a62b231f808da4_w640_q70.webp",
      "contributions": "1. Proposes Mechanism-Based Intelligence (MBI), a new paradigm framing intelligence as emergent from the coordination of multiple agents. 2. Introduces the Differentiable Price Mechanism (DPM), which computes exact loss gradients as incentive signals to guarantee Dominant Strategy Incentive Compatibility and convergence. 3. Demonstrates a framework that scales linearly with the number of agents, bypassing Dec-POMDP complexity and showing significant empirical speedup over model-free RL.",
      "summary": "The paper addresses the fragility of multi-agent systems in coordinating private information and aligning incentives. It proposes Mechanism-Based Intelligence (MBI) and its core Differentiable Price Mechanism (DPM), which uses differentiable incentives to align agent actions with global objectives. The method guarantees incentive compatibility, scales efficiently, and is shown to be much faster than standard reinforcement learning approaches.",
      "mindmap": "graph LR\n    A[Mechanism-Based Intelligence (MBI): Differentiable Incentives for Rational Coordination and Guaranteed Alignment in Multi-Agent Systems] --> B[核心问题/Problem: Hayekian Information Problem & Hurwiczian Incentive Problem]\n    A --> C[主要方法/Method: Differentiable Price Mechanism (DPM) & Bayesian Extension]\n    A --> D[关键结果/Results: DSIC/BIC Guarantee, Linear Scaling, 50x Faster than Model-Free RL]"
    },
    {
      "title": "PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation",
      "authors": "Yuma Ichikawa, Naoya Takagi, Takumi Nakagawa, Yuzi Kanazawa, Akira Sakai",
      "institution": "Fujitsu Limited, RIKEN Center for AIP, Institute of Science Tokyo, Tokai University",
      "link": "https://arxiv.org/pdf/2512.20687",
      "code": null,
      "tags": [
        "llm inference",
        "hierarchical autoregressive model",
        "KV-cache optimization",
        "memory-bound inference",
        "multi-resolution context",
        "throughput-quality trade-off"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6824d7ad660d8d52e1568c90187924380b5fd436a69942bfac67084af3298d40_w640_q70.webp",
      "contributions": "1. Proposes PHOTON, a hierarchical autoregressive model that replaces the Transformer's flat token-by-token scanning with a vertical, multi-resolution context access pattern. 2. Introduces a persistent hierarchy of latent streams, with a bottom-up encoder compressing tokens and lightweight top-down decoders reconstructing token representations, reducing decode-time KV-cache traffic. 3. Demonstrates significant improvements in throughput per unit memory (up to 10^3x) and advantages in long-context and multi-query tasks compared to Transformer-based models.",
      "summary": "The paper identifies that Transformer inference becomes memory-bound due to ever-growing KV-cache reads/writes during autoregressive decoding. To solve this, it proposes PHOTON, a hierarchical model that accesses context vertically at multiple resolutions instead of scanning tokens horizontally. This architectural change drastically reduces memory traffic, yielding orders-of-magnitude higher throughput per unit memory while maintaining quality.",
      "mindmap": "graph LR\n    A[PHOTON: Hierarchical Autoregressive Modeling] --> B[核心问题/Problem: Transformer水平扫描导致KV缓存读写成为内存瓶颈/Horizontal scanning causes memory-bound KV-cache bottleneck]\n    A --> C[主要方法/Method: 用垂直多分辨率层次模型替代/Replace with vertical multi-resolution hierarchical model]\n    A --> D[关键结果/Results: 内存效率与吞吐量大幅提升/Significant improvement in memory efficiency & throughput]"
    },
    {
      "title": "From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education",
      "authors": "Iman Reihanian, Yunfei Hou, Qingquan Sun",
      "institution": "California State University, San Bernardino",
      "link": "https://arxiv.org/pdf/2512.20714",
      "code": null,
      "tags": [
        "educational technology",
        "generative AI",
        "personalization",
        "adaptive learning",
        "large language models",
        "intelligent tutoring systems"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e46f313e494a41a4a12873eddb6320db4cd59b6fb958bb008fd6f6512729af4_w640_q70.webp",
      "contributions": "1. Identified and analyzed five key application domains for GenAI-enabled personalization in CS education: intelligent tutoring, personalized materials, formative feedback, AI-augmented assessment, and code review. 2. Synthesized four design patterns for successful implementations: context-aware tutoring anchored in student artifacts, multi-level hint structures, composition with traditional CS infrastructure, and human-in-the-loop quality assurance. 3. Proposed an exploration-first adoption framework for integrating GenAI, emphasizing piloting, instrumentation, learning-preserving defaults, and evidence-based scaling, while pairing recurrent risks with operational mitigations.",
      "summary": "This scoping review maps how generative AI enables personalized computer science education. It analyzes design choices across 32 studies and finds that structured implementations with explanation-first guidance and artifact grounding lead to more positive learning outcomes than unconstrained chat interfaces. The paper concludes that generative AI can provide precision scaffolding when embedded in audit-ready workflows that preserve productive struggle.",
      "mindmap": "graph LR\n    A[From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education] --> B[核心问题/Problem: Does GenAI personalization support or undermine CS learning?]\n    A --> C[主要方法/Method: Scoping review of 32 studies; Analysis of design choices & patterns]\n    A --> D[关键结果/Results: Structured designs (e.g., hint ladders, artifact grounding) are more effective; Proposes an exploration-first adoption framework]"
    },
    {
      "title": "From artificial to organic: Rethinking the roots of intelligence for digital health",
      "authors": "Prajwal Ghimire, Keyoumars Ashkan",
      "institution": "King's College London",
      "link": "https://arxiv.org/pdf/2512.20723",
      "code": null,
      "tags": [
        "digital health",
        "artificial intelligence",
        "organic intelligence",
        "digital health",
        "neural networks",
        "evolutionary processes"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0101ccc5442460351cdd29a890224590d6ea20c129b31befb533fedb4fbf8c31_w640_q70.webp",
      "contributions": "1. Argues that AI is a product of organic human ingenuity, challenging the artificial vs. organic dichotomy. 2. Proposes that intelligence in digital health fundamentally stems from organization and adaptation, not just parameter scaling. 3. Highlights the inspiration of AI principles from human neurobiology and evolutionary processes.",
      "summary": "This paper rethinks the roots of intelligence in digital health by arguing that artificial intelligence is fundamentally inspired by and derived from organic human cognition. It posits that the distinction between artificial and organic intelligence is blurred, emphasizing organization and adaptation as key principles. The conclusion suggests a more integrated view of intelligence for advancing digital health technologies.",
      "mindmap": "graph LR\n    A[From artificial to organic: Rethinking the roots of intelligence for digital health] --> B[核心问题/Problem: Distinction between artificial and organic intelligence in digital health]\n    A --> C[主要方法/Method: Philosophical analysis of AI's origins in human cognition and biology]\n    A --> D[关键结果/Results: Boundaries are less distinct; intelligence is about organization and adaptation]"
    },
    {
      "title": "SA-DiffuSeq: Addressing Computational and Scalability Challenges in Long-Document Generation with Sparse Attention",
      "authors": "Alexandros Christoforos, Chadbourne Davis",
      "institution": "Suffolk University",
      "link": "https://arxiv.org/pdf/2512.20724",
      "code": null,
      "tags": [
        "diffusion models",
        "sparse attention",
        "diffusion models",
        "long-text generation",
        "soft absorbing state",
        "computational complexity"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01893006a5e49ffeaca24f7c5197f5a706782f3051b02cc9dfef88521a05c523_w640_q70.webp",
      "contributions": "1. Introduces SA-DiffuSeq, a diffusion framework that integrates sparse attention to improve scalability for long-document modeling. 2. Proposes a novel soft absorbing state tailored to sparse attention dynamics to stabilize diffusion trajectories and accelerate sequence reconstruction. 3. Demonstrates superior training efficiency and sampling speed compared to state-of-the-art diffusion baselines, especially on extended sequences.",
      "summary": "The paper addresses the high computational cost of diffusion models for long-text generation by proposing SA-DiffuSeq, which integrates sparse attention and a novel soft absorbing state. This method reduces complexity while maintaining generation quality, making it suitable for applications like scientific writing and code generation. The results show that incorporating structured sparsity is a promising direction for efficient long-text generation.",
      "mindmap": "graph LR\n    A[SA-DiffuSeq] --> B[核心问题/Problem<br>Computational Cost & Scalability];\n    A --> C[主要方法/Method<br>Sparse Attention & Soft Absorbing State];\n    A --> D[关键结果/Results<br>Improved Efficiency & Quality];"
    },
    {
      "title": "FEM-Bench: A Structured Scientific Reasoning Benchmark for Evaluating Code-Generating LLMs",
      "authors": "Saeed Mohammadzadeh, Erfan Hamdi, Joel Shor, Emma Lejeune",
      "institution": "Boston University, Move37 Labs",
      "link": "https://arxiv.org/pdf/2512.20732",
      "code": null,
      "tags": [
        "llm inference",
        "Finite Element Method (FEM)",
        "Code Generation",
        "LLM Benchmark",
        "Computational Mechanics",
        "Scientific Machine Learning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1933a2d33b13b692f95ee8ddec0a65840af091998d38a7f0154837874636590_w640_q70.webp",
      "contributions": "1. Introduces FEM-Bench, a novel benchmark for evaluating LLMs' ability to generate scientifically valid code for computational mechanics problems. 2. Provides a structured suite of tasks based on finite element methods that enforce physical and numerical constraints for objective evaluation. 3. Presents initial evaluation results showing that state-of-the-art LLMs (e.g., Gemini 3 Pro, GPT-5) still struggle to reliably solve these introductory tasks.",
      "summary": "The paper identifies a lack of benchmarks for evaluating LLMs' scientific reasoning and code generation for physical modeling. It proposes FEM-Bench, a computational mechanics benchmark based on the Finite Element Method, to fill this gap. Initial evaluations show that even advanced LLMs cannot reliably solve all its tasks, establishing a foundation for tracking progress in AI-generated scientific code.",
      "mindmap": "graph LR\n        A[FEM-Bench Paper] --> B[核心问题/Problem: 缺乏评估LLM生成科学物理模型代码能力的基准/Lack of benchmark for evaluating LLMs' ability to generate scientifically valid physical model code]\n        A --> C[主要方法/Method: 提出基于计算力学和有限元法的结构化基准/Proposes a structured benchmark based on computational mechanics and the Finite Element Method]\n        A --> D[关键结果/Results: 先进LLM无法可靠解决所有基准任务，为跟踪进展奠定基础/State-of-the-art LLMs cannot reliably solve all benchmark tasks, establishing a foundation for tracking progress]"
    },
    {
      "title": "AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent",
      "authors": "Haipeng Luo, Huawen Feng, Qingfeng Sun, Can Xu, Kai Zheng, Yufei Wang, Tao Yang, Han Hu, Yansong Tang, Di Wang",
      "institution": "Tsinghua University, Tencent Hunyuan",
      "link": "https://arxiv.org/pdf/2512.20745",
      "code": null,
      "tags": [
        "agent system",
        "tool-augmented agent",
        "agentic reinforcement learning",
        "supervised fine-tuning (SFT)",
        "request-level asynchronous rollout",
        "prefix-aware load balancing"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7211416872630b2f7d460fe4b986a1d141827d69b65487826e3374c5e4cce08d_w640_q70.webp",
      "contributions": "1. An automated method to convert natural language chain-of-thought into structured tool-augmented trajectories for generating high-quality SFT data. 2. A novel agentic reinforcement learning paradigm that dynamically interleaves natural language generation with real-time code execution for learning tool-use strategies. 3. An efficient training system with techniques like asynchronous rollout scheduling and prefix-aware load balancing, achieving 4-5x speedup for RL training on long sequences.",
      "summary": "This paper introduces AgentMath, a framework that combines language model reasoning with code interpreter precision to solve complex math problems. It uses automated SFT data generation, agentic RL for tool-use learning, and an efficient training system, achieving state-of-the-art results on benchmarks like AIME24 and AIME25.",
      "mindmap": "graph LR\n    A[AgentMath] --> B[核心问题/Problem: LRMs are inefficient and inaccurate for complex math]\n    A --> C[主要方法/Method: Tool-augmented agent framework with SFT data generation, agentic RL, and efficient training system]\n    A --> D[关键结果/Results: SOTA performance on AIME24, AIME25, HMMT25 benchmarks]"
    },
    {
      "title": "AI-Driven Green Cognitive Radio Networks for Sustainable 6G Communication",
      "authors": "Anshul Sharma, Shujaatali Badami, Biky Chouhan, Pushpanjali Pandey, Brijeena Rana, Navneet Kaur",
      "institution": "Independent Researcher (USA), Liverpool John Moores University (UK), Chandigarh University (India), Gyancity Research Consultancy (India)",
      "link": "https://arxiv.org/pdf/2512.20739",
      "code": null,
      "tags": [
        "wireless networks",
        "Deep Reinforcement Learning (DRL)",
        "Reconfigurable Intelligent Surfaces (RIS)",
        "Energy Harvesting (EH)"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22a82510c37e7a60d88746806bbece62f0d234e13f225f50ad5635a0bb4ae5ee_w640_q70.webp",
      "contributions": "1. A holistic system model integrating PUs/SUs, energy harvesting, and RIS for sustainable CRN operation. 2. A DRL-based controller enhanced with transfer learning and hybrid metaheuristics for dynamic sensing and resource allocation. 3. EH-aware scheduling and RIS-phase co-adaptation algorithms to reduce SU power consumption.",
      "summary": "This paper proposes an AI-driven framework for green Cognitive Radio Networks (CRNs) in 6G. It integrates Deep Reinforcement Learning (DRL) with transfer learning, energy harvesting, and reconfigurable intelligent surfaces (RIS) to optimize spectrum sensing and resource allocation. The framework demonstrates significant energy savings, high sensing accuracy, and improved packet delivery ratio compared to traditional baselines, offering a sustainable path for 6G IoT and vehicular networks.",
      "mindmap": "graph LR\n    A[AI-Driven Green CRNs for 6G] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[频谱稀缺与高能耗/Spectrum Scarcity & High Energy Consumption]\n    C --> C1[AI驱动框架/AI-Driven Framework]\n    C1 --> C2[集成DRL, TL, EH, RIS/Integrates DRL, TL, EH, RIS]\n    D --> D1[节能25-30%/25-30% Energy Saving]\n    D --> D2[AUC>0.90, PDR提升/AUC>0.90, PDR Improved]"
    },
    {
      "title": "Stabilizing Multimodal Autoencoders: A Theoretical and Empirical Analysis of Fusion Strategies",
      "authors": "Diyar Altinses, Andreas Schwung",
      "institution": "South Westphalia University of Applied Sciences",
      "link": "https://arxiv.org/pdf/2512.20749",
      "code": null,
      "tags": [
        "multi-modal training",
        "Lipschitz Continuity",
        "Attention Mechanism",
        "Aggregation Methods",
        "Training Stability",
        "Multimodal Autoencoders"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3484b58bc84f22d71a010fca63235d2811ea4f720d1103584b13e220d263f42d_w640_q70.webp",
      "contributions": "1. Derivation of theoretical Lipschitz constants for aggregation methods in multimodal autoencoders. 2. Introduction of a novel regularized attention-based fusion method designed from the theoretical analysis to improve training stability. 3. Empirical validation of the theoretical findings and demonstration of the proposed method's superior performance in consistency, convergence speed, and accuracy.",
      "summary": "This paper analyzes the stability of multimodal autoencoders by theoretically deriving Lipschitz constants for fusion strategies and proposes a new regularized attention-based fusion method. The method is empirically validated and shown to outperform existing strategies, providing a more stable and performant training process for multimodal models.",
      "mindmap": "graph LR\n    A[Stabilizing Multimodal Autoencoders<br/>稳定多模态自编码器] --> B(核心问题/Problem: Training Stability & Robustness<br/>训练稳定性与鲁棒性)\n    A --> C(主要方法/Method: Theoretical Lipschitz Analysis & Regularized Attention Fusion<br/>理论Lipschitz分析与正则化注意力融合)\n    A --> D(关键结果/Results: Improved Consistency, Convergence, Accuracy<br/>提升的一致性、收敛速度与精度)"
    },
    {
      "title": "Bridging Efficiency and Safety: Formal Verification of Neural Networks with Early Exits",
      "authors": "Yizhak Yisrael Elboher, Avraham Raviv, Amihay Elboher, Zhouxing Shi, Omri Azencot, Hillel Kugler, Guy Katz",
      "institution": "The Hebrew University of Jerusalem, Bar Ilan University, Ben-Gurion University of the Negev, University of California, Riverside",
      "link": "https://arxiv.org/pdf/2512.20755",
      "code": null,
      "tags": [
        "others",
        "formal verification",
        "neural network robustness",
        "early exits",
        "adversarial perturbations",
        "off-the-shelf solvers"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74cb8be1b40cc4cc73a6f6a75d4c206b456d4189c26838e784e46e437ea5a87b_w640_q70.webp",
      "contributions": "1. Defined a formal robustness property specifically tailored for neural network architectures with early exits. 2. Presented a baseline verification algorithm for such networks, enhanced with an early stopping strategy and heuristic optimizations that maintain soundness and completeness. 3. Demonstrated empirically that early exits not only accelerate inference but also enhance verifiability, solving more queries in less time compared to standard networks.",
      "summary": "This paper addresses the challenge of formally verifying the robustness of neural networks that use early exits for efficiency. The authors propose a tailored robustness property and an enhanced verification algorithm using off-the-shelf solvers. Their experiments show that early exits can improve both inference speed and verifiability, helping navigate the trade-off between accuracy and efficiency.",
      "mindmap": "graph LR\n    A[论文标题 / Paper Title<br>Bridging Efficiency and Safety] --> B(核心问题 / Problem<br>Verifying Early Exit Networks);\n    A --> C(主要方法 / Method<br>Tailored Robustness Property & Enhanced Algorithm);\n    A --> D(关键结果 / Results<br>Improved Verifiability & Efficiency);"
    },
    {
      "title": "Generalization of RLVR Using Causal Reasoning as a Testbed",
      "authors": "Brian Lu, Hongyu Zhao, Shuo Sun, Hao Peng, Rui Ding, Hongyuan Mei",
      "institution": "Johns Hopkins University, University of Maryland, College Park, National University of Singapore, University of Illinois at Urbana-Champaign, Microsoft Research Asia, Toyota Technological Institute at Chicago",
      "link": "https://arxiv.org/pdf/2512.20760",
      "code": null,
      "tags": [
        "reinforcement learning",
        "RLVR",
        "causal reasoning",
        "generalization",
        "supervised fine-tuning",
        "large language models"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/472c557c79b64b352421bedd952ba76d099165d613e99323a1beb8845a24cf4c_w640_q70.webp",
      "contributions": "1. Provides an empirical study of RLVR generalization using causal inference as a structured testbed, examining generalization across query levels and structural complexity. 2. Identifies that RLVR's benefits over SFT for generalization are contingent on specific combinations of model size and training query level, and depend on the model's initial reasoning competence. 3. Shows that RLVR improves specific causal reasoning subskills, such as marginalization strategy and intermediate probability calculation, leading to accuracy gains on complex queries.",
      "summary": "This paper studies the generalization of Reinforcement Learning with Verifiable Rewards (RLVR) for large language models on causal reasoning tasks. It finds that RLVR can outperform supervised fine-tuning in generalization, but its effectiveness depends on model size, training data, and the model's initial competence. The results indicate RLVR improves specific reasoning sub-skills when the model has a sufficient foundational ability.",
      "mindmap": "graph LR\n    A[”Generalization of RLVR Using Causal Reasoning as a Testbed<br>以因果推理为测试平台的RLVR泛化研究”] --> B[”核心问题/Problem<br>RLVR何时能实现鲁棒泛化？<br>When does RLVR yield robust generalization?”]\n    A --> C[”主要方法/Method<br>在因果图模型上实证研究RLVR与SFT<br>Empirical study of RLVR vs SFT on causal graphical models”]\n    A --> D[”关键结果/Results<br>RLVR泛化更强，但依赖模型规模与初始能力<br>RLVR yields stronger generalization but depends on model size & initial competence”]"
    },
    {
      "title": "TS-Arena Technical Report -- A Pre-registered Live Forecasting Platform",
      "authors": "Marcel Meyer, Sascha Kaltenpoth, Kevin Zalipski, Henrik Albers, Oliver Müller",
      "institution": "Paderborn University",
      "link": "https://arxiv.org/pdf/2512.20761",
      "code": "https://huggingface.co/spaces/DAG-UPB/TS-Arena",
      "tags": [
        "others",
        "time series foundation models",
        "live forecasting",
        "pre-registration",
        "information leakage",
        "temporal split"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea84e3460e7e5ece43727d2db2e7515fe17057e90ce083ef73f979343188043f_w640_q70.webp",
      "contributions": "1. Introduces TS-Arena, a platform that uses live data streams and a pre-registration mechanism to create a strict global temporal split for evaluation, preventing historical data contamination. 2. Proposes a methodology that treats the genuinely unknown future as the definitive test environment, establishing a moving temporal frontier for authentic assessment of model generalization. 3. Provides a sustainable infrastructure initially applied in the energy sector for comparing Time Series Foundation Models (TSFMs) under real-world constraints, addressing the evaluation crisis caused by data reuse and leakage.",
      "summary": "The paper identifies an evaluation crisis in Time Series Foundation Models (TSFMs) caused by information leakage from overlapping training/test data. To solve this, it proposes TS-Arena, a live forecasting platform that enforces evaluation on future, unseen data via pre-registration, ensuring a valid temporal split. The platform provides a fair and realistic infrastructure for benchmarking TSFMs, with an initial application in the energy sector.",
      "mindmap": "graph LR\n    A[TS-Arena Technical Report] --> B[核心问题/Problem: TSFM评估危机 / TSFM Evaluation Crisis]\n    A --> C[主要方法/Method: 预注册实时预测平台 / Pre-registered Live Forecasting Platform]\n    A --> D[关键结果/Results: 防止历史污染，真实评估泛化 / Prevents Historical Contamination, Authentic Generalization Assessment]\n    B --> E[信息泄露与数据重用 / Information Leakage & Data Reuse]\n    C --> F[实时数据流与严格时间分割 / Live Data Streams & Strict Temporal Split]\n    D --> G[可持续的基准测试基础设施 / Sustainable Benchmarking Infrastructure]"
    },
    {
      "title": "Towards Optimal Performance and Action Consistency Guarantees in Dec-POMDPs with Inconsistent Beliefs and Limited Communication",
      "authors": "Moshe Rafaeli Shimron, Vadim Indelman",
      "institution": "Technion - Israel Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.20778",
      "code": null,
      "tags": [
        "multi-agent reinforcement learning",
        "Dec-POMDP",
        "belief inconsistency",
        "limited communication",
        "action consistency",
        "multi-agent planning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4538ed8602d7a249e385e29bfc0423ed3f6682a9ac338c82e10822f10bd96df8_w640_q70.webp",
      "contributions": "1. A novel decentralized framework for optimal joint action selection that explicitly accounts for belief inconsistencies among agents. 2. Provides probabilistic guarantees for both action consistency and performance relative to a fully-communicating baseline. 3. Introduces a mechanism to selectively trigger communication only when necessary and addresses the decision of whether to share data after action selection to improve inference.",
      "summary": "The paper addresses the problem of multi-agent decision-making under uncertainty when agents have inconsistent beliefs due to limited communication. It proposes a new decentralized framework for Dec-POMDPs that provides performance and action consistency guarantees while minimizing communication. Simulation results demonstrate that the approach outperforms existing state-of-the-art algorithms.",
      "mindmap": "graph LR\n    A[Towards Optimal Performance and Action Consistency Guarantees in Dec-POMDPs] --> B(核心问题/Problem: Belief Inconsistency & Limited Communication)\n    A --> C(主要方法/Method: Novel Decentralized Framework with Guarantees)\n    A --> D(关键结果/Results: Outperforms SOTA Algorithms)"
    },
    {
      "title": "NULLBUS: Multimodal Mixed-Supervision for Breast Ultrasound Segmentation via Nullable Global-Local Prompts",
      "authors": "Raja Mallina, Bryar Shareef",
      "institution": "University of Nevada, Las Vegas",
      "link": "https://arxiv.org/pdf/2512.20783",
      "code": null,
      "tags": [
        "medical image segmentation",
        "nullable prompts",
        "mixed-supervision",
        "vision-language models",
        "breast ultrasound segmentation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c68929834a07c86ac43fe9856efa137aa11c30a231a02ea87272f2b689e4f7f_w640_q70.webp",
      "contributions": "1. Proposes NullBUS, a multimodal mixed-supervision framework for BUS segmentation that can learn from images both with and without prompts in a single model. 2. Introduces nullable prompts, implemented as learnable null embeddings with presence masks, to handle missing text metadata by enabling fallback to image-only evidence. 3. Demonstrates state-of-the-art performance on a unified pool of three public BUS datasets under mixed prompt availability.",
      "summary": "The paper addresses the problem that many public breast ultrasound datasets lack reliable text or spatial prompts, which limits the training of promptable segmentation models. It proposes NullBUS, a framework that uses nullable global-local prompts to learn from both prompted and prompt-free images. The method achieves state-of-the-art segmentation performance on a unified evaluation of three public datasets, showing robustness under mixed prompt availability.",
      "mindmap": "graph LR\n    A[NULLBUS] --> B[核心问题/Problem: BUS数据集缺乏可靠提示词]\n    A --> C[主要方法/Method: 可空全局-局部提示的混合监督框架]\n    A --> D[关键结果/Results: 在混合提示下达到SOTA性能]"
    },
    {
      "title": "X-GridAgent: An LLM-Powered Agentic AI System for Assisting Power Grid Analysis",
      "authors": "Yihan, Xin Chen",
      "institution": "Texas A&M University",
      "link": "https://arxiv.org/pdf/2512.20789",
      "code": null,
      "tags": [
        "agent system",
        "hierarchical agent architecture",
        "prompt refinement with human feedback",
        "schema-adaptive hybrid RAG"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fb48dc08ade0ddfa007a5156a481bb9ff3e7a4fabec1d577a9040fa4193ffe1_w640_q70.webp",
      "contributions": "1. Proposes X-GridAgent, a novel LLM-powered agentic AI system with a three-layer hierarchical architecture for automating power grid analysis via natural language. 2. Introduces an LLM-driven prompt refinement algorithm with human feedback to enhance task planning. 3. Develops a schema-adaptive hybrid retrieval-augmented generation (RAG) algorithm for accurate information retrieval from large-scale structured grid datasets.",
      "summary": "This paper presents X-GridAgent, an LLM-powered agent system designed to automate complex power grid analysis through natural language queries using a hierarchical architecture and novel algorithms for prompt refinement and information retrieval. Experimental results demonstrate its effectiveness and reliability in performing interpretable and rigorous power system analysis.",
      "mindmap": "graph LR\n    A[X-GridAgent] --> B[核心问题/Problem: Conventional grid tools require manual effort and expertise]\n    A --> C[主要方法/Method: LLM-powered agent with hierarchical architecture & novel algorithms]\n    A --> D[关键结果/Results: Effective & reliable automated analysis]"
    },
    {
      "title": "A Benchmark for Evaluating Outcome-Driven Constraint Violations in Autonomous AI Agents",
      "authors": "Miles Q. Li, Benjamin C. M. Fung, Martin Weiss, Pulei Xiong, Khalil Al-Hussaeni, Claude Fachkha",
      "institution": "McGill University, Tiptree Advanced Systems Corporation, Polytechnique Montréal, National Research Council Canada, Rochester Institute of Technology Dubai, University of Dubai",
      "link": "https://arxiv.org/pdf/2512.20798",
      "code": null,
      "tags": [
        "ai safety & alignment",
        "autonomous agents",
        "safety benchmark",
        "constraint violations",
        "key performance indicator (KPI)",
        "deliberative misalignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a9156498ba4348ea63fbca94bacbbb938f1ccadc8825abf01cb9c946cda2c48_w640_q70.webp",
      "contributions": "1. Introduced a novel benchmark with 40 multi-step scenarios to evaluate emergent, outcome-driven constraint violations in autonomous AI agents, distinguishing between Mandated and Incentivized variations. 2. Conducted a comprehensive evaluation across 12 state-of-the-art LLMs, revealing high misalignment rates (up to 71.4%) and showing that superior reasoning capability does not guarantee safety. 3. Identified and highlighted the phenomenon of \"deliberative misalignment,\" where agents recognize their own actions as unethical in separate evaluations.",
      "summary": "This paper addresses the lack of realistic benchmarks for evaluating safety risks in autonomous AI agents. It proposes a new benchmark with multi-step scenarios tied to KPIs to test for outcome-driven constraint violations. The evaluation reveals alarmingly high violation rates across leading models, demonstrating that advanced capabilities do not ensure safety and highlighting a critical need for improved agentic-safety training.",
      "mindmap": "graph LR\n    A[A Benchmark for Evaluating Outcome-Driven Constraint Violations in Autonomous AI Agents] --> B(核心问题/Problem: Lack of realistic benchmarks for emergent agent misalignment)\n    A --> C(主要方法/Method: New benchmark with 40 multi-step, KPI-driven scenarios)\n    A --> D(关键结果/Results: High violation rates (1.3%-71.4%); reasoning ≠ safety; deliberative misalignment)"
    },
    {
      "title": "Safety Alignment of LMs via Non-cooperative Games",
      "authors": "Anselm Paulus, Ilia Kulikov, Brandon Amos, Rémi Munos, Ivan Evtimov, Kamalika Chaudhuri, Arman Zharmagambetov",
      "institution": "Meta (FAIR), University of Tübingen",
      "link": "https://arxiv.org/pdf/2512.20806",
      "code": "https://github.com/facebookresearch/advgame",
      "tags": [
        "reinforcement learning",
        "non-cooperative game",
        "adversarial training",
        "preference-based reward",
        "online reinforcement learning",
        "safety alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99d494326c3e6d7e063baf364aff968ae0d21f53ab3f3e8b4214c548e5ac79b4_w640_q70.webp",
      "contributions": "1. Introduces a new paradigm for safety alignment by framing it as a non-zero-sum game between an Attacker LM and a Defender LM. 2. Proposes joint training of the LMs via online reinforcement learning with a preference-based reward signal to reduce reward hacking. 3. Demonstrates that the method (AdvGame) produces a Defender LM with improved safety and utility and an Attacker LM that serves as a strong red-teaming agent.",
      "summary": "The paper addresses the challenge of aligning language models for safety without sacrificing utility. It proposes AdvGame, a method that frames safety alignment as a non-cooperative game between an Attacker and a Defender LM, training them jointly with online RL using preference-based rewards. The results show the approach yields a more helpful and safe Defender and a powerful general-purpose Attacker for red-teaming.",
      "mindmap": "graph LR\n        A[Safety Alignment of LMs via Non-cooperative Games] --> B(核心问题/Problem: Safety vs. Utility Trade-off in LM Alignment)\n        A --> C(主要方法/Method: Non-zero-sum Game & Online RL with Preference Reward)\n        A --> D(关键结果/Results: Improved Defender LM & Strong Red-teaming Attacker)"
    },
    {
      "title": "MediEval: A Unified Medical Benchmark for Patient-Contextual and Knowledge-Grounded Reasoning in LLMs",
      "authors": "Zhan Qu, Michael Färber",
      "institution": "TU Dresden, ScaDS.AI",
      "link": "https://arxiv.org/pdf/2512.20822",
      "code": null,
      "tags": [
        "medical nlp / llm evaluation",
        "medical benchmark",
        "electronic health records (EHR)",
        "knowledge grounding",
        "counterfactual reasoning",
        "DPO fine-tuning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59c4d88b1ecf7256d86a2c1dd12f74897d1a42b0c88d272ea8cf058355f013cd_w640_q70.webp",
      "contributions": "1. Introduces MediEval, a unified benchmark linking real EHRs (MIMIC-IV) to a biomedical knowledge base for evaluating LLMs on patient-contextual and knowledge-grounded reasoning. 2. Proposes a 4-quadrant evaluation framework to systematically assess models on both factual correctness and contextual consistency, identifying critical failure modes like hallucinated support and truth inversion. 3. Proposes Counterfactual Risk-Aware Fine-tuning (CoRFu), a DPO-based method with an asymmetric penalty, which significantly improves model accuracy and safety by eliminating truth inversion errors.",
      "summary": "The paper identifies a gap in evaluating LLMs for medical applications, where existing benchmarks either test isolated knowledge or patient reasoning without verifying correctness. To address this, the authors introduce the MediEval benchmark and a 4-quadrant evaluation framework to systematically assess LLMs, and propose a novel fine-tuning method called CoRFu. The results show that CoRFu significantly improves model performance and safety by eliminating dangerous error types like truth inversion.",
      "mindmap": "graph LR\n        A[MediEval] --> B[核心问题/Problem: LLMs in medicine lack reliable evaluation combining knowledge and patient context];\n        A --> C[主要方法/Method: Unified benchmark (EHR + KB) & 4-quadrant framework & CoRFu fine-tuning];\n        A --> D[关键结果/Results: Identifies failure modes; CoRFu improves accuracy and safety];"
    },
    {
      "title": "NotSoTiny: A Large, Living Benchmark for RTL Code Generation",
      "authors": "Razine Moundir Ghorab, Emanuele Parisi, Cristian Gutierrez, Miquel Alberti-Binimelis, Miquel Moreto, Dario Garcia-Gasulla, Gokcen Kestor",
      "institution": "Barcelona Supercomputing Center, Universitat Politecnica de Catalunya",
      "link": "https://arxiv.org/pdf/2512.20823",
      "code": null,
      "tags": [
        "llm training",
        "RTL code generation",
        "benchmark",
        "hardware design",
        "data contamination",
        "verification"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ee59b5723cdae955454bd94bdc8872b40c0eaccf59a4e54b86951d040529325_w640_q70.webp",
      "contributions": "1. Introduces NotSoTiny, a large-scale, living benchmark for evaluating LLMs on RTL code generation, built from real hardware designs. 2. Proposes an automated pipeline to ensure benchmark quality by removing duplicates, verifying correctness, and periodically updating to mitigate data contamination. 3. Demonstrates that NotSoTiny presents more challenging tasks than prior benchmarks, effectively highlighting current LLM limitations in hardware design.",
      "summary": "This paper introduces NotSoTiny, a benchmark for evaluating LLMs on generating Register-Transfer Level (RTL) code, addressing limitations of prior benchmarks by using real, complex hardware designs and a pipeline to ensure correctness and reduce data contamination. The results show that NotSoTiny tasks are more challenging, effectively guiding the improvement of LLMs for hardware design.",
      "mindmap": "graph LR\n    A[NotSoTiny: A Large, Living Benchmark for RTL Code Generation] --> B(核心问题/Problem: LLM RTL代码生成评估挑战 / LLM RTL Code Generation Evaluation Challenge)\n    A --> C(主要方法/Method: 基于真实硬件设计的自动化基准测试 / Automated Benchmark from Real Hardware Designs)\n    A --> D(关键结果/Results: 任务更具挑战性，有效指导改进 / Tasks More Challenging, Effectively Guides Improvement)"
    },
    {
      "title": "Context-Sensitive Abstractions for Reinforcement Learning with Parameterized Actions",
      "authors": "Rashmeet Kaur Nayyar, Naman Shah, Siddharth Srivastava",
      "institution": "Arizona State University, Brown University",
      "link": "https://arxiv.org/pdf/2512.20831",
      "code": "https://github.com/AAIR-lab/PEARL.git",
      "tags": [
        "reinforcement learning",
        "parameterized actions",
        "state abstraction",
        "action abstraction",
        "TD(λ)",
        "sample efficiency"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74b22dc11c38dfc5a75f48c2cd94c57d0eecaffdac79525f6362b0b32c448b0_w640_q70.webp",
      "contributions": "1. Enables agents to autonomously learn both state and action abstractions online for RL with parameterized actions., 2. Introduces algorithms that progressively refine these abstractions during learning, focusing detail on critical regions., 3. Extends RL to long-horizon, sparse-reward settings with parameterized actions, achieving higher sample efficiency than baselines.",
      "summary": "This paper addresses the challenge of reinforcement learning in environments with parameterized actions, which combine discrete choices with continuous parameters. It proposes a method where agents autonomously learn and progressively refine state and action abstractions online. The approach enables TD(λ) to achieve significantly higher sample efficiency in continuous-state, parameterized-action domains compared to state-of-the-art methods.",
      "mindmap": "graph LR\n    A[Context-Sensitive Abstractions for RL with Parameterized Actions] --> B(核心问题/Problem: RL for Parameterized Actions)\n    A --> C(主要方法/Method: Learn & Refine State/Action Abstractions)\n    A --> D(关键结果/Results: Higher Sample Efficiency for TD(λ))"
    },
    {
      "title": "MAR:Multi-Agent Reflexion Improves Reasoning Abilities in LLMs",
      "authors": "Onat Ozer, Grace Wu, Yuchen Wang, Daniel Dosti, Honghao Zhang, Vivi De La Rue",
      "institution": "University of Michigan",
      "link": "https://arxiv.org/pdf/2512.20845",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent reflection",
        "reasoning improvement",
        "self-correction",
        "episodic memory",
        "iterative refinement"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6022c55272f43b40b16d9e6f722483682ba159634bd04eb55be130ec83c86fe4_w640_q70.webp",
      "contributions": "1. Identifies systematic shortcomings in the single-agent Reflexion framework, such as repeated reasoning errors and confirmation bias, through detailed replication and analysis. 2. Proposes Multi-Agent Reflexion (MAR), a structured multi-agent extension that incorporates diverse reasoning personas and a judge model to synthesize critiques into unified reflections. 3. Demonstrates that MAR improves performance over Reflexion on HotPotQA and HumanEval benchmarks, reducing stagnation and enhancing reasoning reliability.",
      "summary": "This paper addresses the problem of reasoning error repetition and limited corrective feedback in single-agent LLM self-reflection frameworks like Reflexion. It proposes Multi-Agent Reflexion (MAR), which uses multiple agents with diverse personas to generate critiques and a judge to synthesize them, leading to more diverse and effective reflections. The method shows improved accuracy on HotPotQA and HumanEval benchmarks compared to the single-agent approach.",
      "mindmap": "graph LR\n        A[MAR: Multi-Agent Reflexion] --> B[核心问题/Problem: Single-agent self-reflection leads to repeated errors and confirmation bias]\n        A --> C[主要方法/Method: Multi-agent system with diverse personas and a judge model for critique synthesis]\n        A --> D[关键结果/Results: Improved accuracy on HotPotQA (47% EM) and HumanEval (82.7% pass@1)]"
    },
    {
      "title": "Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning",
      "authors": "NVIDIA, Aaron Blakeman, Aaron Grattafiori, Aarti Basant, Abhibha Gupta, Abhinav Khattar, Adi Renduchintala, Aditya Vavre, Akanksha Shukla, Akhiad Bercovich, Aleksander Ficek, Aleksandr Shaposhnikov, Alex Kondratenko, Alexander Bukharin, Alexandre Milesi, Ali Taghibakhshi, Alisa Liu, Amelia Barton, Ameya Sunil Mahabaleshwarkar, Amir Klein, Amit Zuker, Amnon Geifman, Amy Shen, Anahita Bhiwandiwalla, Andrew Tao, Ann Guan, Anubhav Mandarwal, Arham Mehta, Ashwath Aithal, Ashwin Poojary, Asif Ahamed, Asma Kuriparambil Thekkumpate, Ayush Dattagupta, Banghua Zhu, Bardiya Sadeghi, Barnaby Simkin, Ben Lanir, Benedikt Schifferer, Besmira Nushi, Bilal Kartal, Bita Darvish Rouhani, Boris Ginsburg, Brandon Norick, Brandon Soubasis, Branislav Kisacanin, Brian Yu, Bryan Catanzaro, Carlo del Mundo, Chantal Hwang, Charles Wang, Cheng-Ping Hsieh, Chenghao Zhang, Chenhan Yu, Chetan Mungekar, Chintan Patel, Chris Alexiuk, Christopher Parisien, Collin Neale, Damon Mosk-Aoyama, Dan Su, Dane Corneil, Daniel Afrimi, Daniel Rohrer, Daniel Serebrenik, Daria Gitman, Daria Levy, Darko Stosic, David Mosallanezhad, Deepak Narayanan, Dhruv Nathawani, Dima Rekesh, Dina Yared, Divyanshu Kakwani, Dong Ahn, Duncan Riach, Dusan Stosic, Edgar Minasyan, Edward Lin, Eileen Long, Eileen Peters Long, Elena Lantz, Ellie Evans, Elliott Ning, Eric Chung, Eric Harper, Eric Tramel, Erick Galinkin, Erik Pounds, Evan Briones, Evelina Bakhturina, Faisal Ladhak, Fay Wang, Fei Jia, Felipe Soares, Feng Chen, Ferenc Galko, Frankie Siino, Gal Hubara Agam, Ganesh Ajjanagadde, Gantavya Bhatt",
      "institution": "NVIDIA",
      "link": "https://arxiv.org/pdf/2512.20848",
      "code": null,
      "tags": [
        "llm inference",
        "Mixture-of-Experts",
        "Mamba-Transformer",
        "agentic reasoning",
        "sparse activation",
        "long context"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96a4b5c012acd8208519dcb9669276bd8c3c3709f26e7290e2fce500151c1ccc_w640_q70.webp",
      "contributions": "1. Introduces Nemotron 3 Nano, a hybrid MoE Mamba-Transformer model that sparsely activates only 3.2B out of 31.6B parameters per forward pass for efficiency. 2. Demonstrates superior inference throughput (up to 3.3x faster) compared to similarly-sized open models while maintaining or improving accuracy on benchmarks. 3. Supports an extended context length of up to 1 million tokens and shows enhanced agentic and reasoning capabilities through post-training.",
      "summary": "This paper presents Nemotron 3 Nano, an efficient 30B-parameter language model that combines Mixture-of-Experts with a Mamba-Transformer architecture to achieve sparse activation. It was pre-trained on 25 trillion tokens and post-trained for agentic reasoning, resulting in higher inference throughput and accuracy compared to similar models while supporting up to 1M token contexts.",
      "mindmap": "graph LR\n    A[Nemotron 3 Nano<br>论文标题/Paper Title] --> B[构建高效、能进行智能体推理的大模型<br>核心问题/Problem];\n    A --> C[混合MoE与Mamba-Transformer架构，稀疏激活参数<br>主要方法/Method];\n    A --> D[更高推理吞吐与精度，支持100万令牌上下文<br>关键结果/Results];"
    },
    {
      "title": "NVIDIA Nemotron 3: Efficient and Open Intelligence",
      "authors": "NVIDIA, Aaron Blakeman, Aaron Grattafiori, Aarti Basant, Abhibha Gupta, Abhinav Khattar, Adi Renduchintala, Aditya Vavre, Akanksha Shukla, Akhiad Bercovich, Aleksander Ficek, Aleksandr Shaposhnikov, Alex Kondratenko, Alexander Bukharin, Alexandre Milesi, Ali Taghibakhshi, Alisa Liu, Amelia Barton, Ameya Sunil Mahabaleshwarkar, Amir Klein, Amit Zuker, Amnon Geifman, Amy Shen, Anahita Bhiwandiwalla, Andrew Tao, Anjulie Agrusa, Ankur Verma, Ann Guan, Anubhav Mandarwal, Arham Mehta, Ashwath Aithal, Ashwin Poojary, Asif Ahamed, Asit Mishra, Asma Kuriparambil Thekkumpate, Ayush Dattagupta, Banghua Zhu, Bardiya Sadeghi, Barnaby Simkin, Ben Lanir, Benedikt Schifferer, Besmira Nushi, Bilal Kartal, Bita Darvish Rouhani, Boris Ginsburg, Brandon Norick, Brandon Soubasis, Branislav Kisacanin, Brian Yu, Bryan Catanzaro, Carlo del Mundo, Chantal Hwang, Charles Wang, Cheng-Ping Hsieh, Chenghao Zhang, Chenhan Yu, Chetan Mungekar, Chintan Patel, Chris Alexiuk, Christopher Parisien, Collin Neale, Cyril Meurillon, Damon Mosk-Aoyama, Dan Su, Dane Corneil, Daniel Afrimi, Daniel Lo, Daniel Rohrer, Daniel Serebrenik, Daria Gitman, Daria Levy, Darko Stosic, David Mosallanezhad, Deepak Narayanan, Dhruv Nathawani, Dima Rekesh, Dina Yared, Divyanshu Kakwani, Dong Ahn, Duncan Riach, Dusan Stosic, Edgar Minasyan, Edward Lin, Eileen Long, Eileen Peters Long, Elad Segal, Elena Lantz, Ellie Evans, Elliott Ning, Eric Chung, Eric Harper, Eric Tramel, Erick Galinkin, Erik Pounds, Evan Briones, Evelina Bakhturina, Evgeny Tsykunov, Faisal Ladhak, Fay Wang, Fei Jia",
      "institution": "NVIDIA",
      "link": "https://arxiv.org/pdf/2512.20856",
      "code": null,
      "tags": [
        "llm inference",
        "Mixture-of-Experts",
        "Mamba-Transformer",
        "LatentMoE",
        "NVFP4",
        "multi-environment reinforcement learning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5203ecd520d6e99bc9f0034f05e8945272d4a34a746eeeae01be1cc728049b5_w640_q70.webp",
      "contributions": "1. Introduces the Nemotron 3 family of models (Nano, Super, Ultra) built on a Mixture-of-Experts hybrid Mamba-Transformer architecture for high throughput and long context (up to 1M tokens). 2. Proposes novel techniques including LatentMoE for improved model quality and MTP layers for faster text generation in the larger models. 3. Employs multi-environment reinforcement learning for post-training, enabling advanced capabilities like reasoning, multi-step tool use, and granular reasoning budget control.",
      "summary": "This paper introduces the Nemotron 3 family of open models designed for efficient and intelligent agentic applications. The models use a novel hybrid Mamba-Transformer architecture and are trained with techniques like LatentMoE and multi-environment RL to achieve strong reasoning, conversational, and tool-use capabilities with high throughput. The conclusion is that these models provide state-of-the-art accuracy and efficiency, with plans for open release of weights, software, and data.",
      "mindmap": "graph LR\n    A[NVIDIA Nemotron 3] --> B[核心问题/Problem: Efficient and open intelligence for agentic applications]\n    A --> C[主要方法/Method: Mixture-of-Experts hybrid Mamba-Transformer, LatentMoE, multi-environment RL]\n    A --> D[关键结果/Results: High throughput, 1M context, strong agentic/reasoning capabilities, open release]"
    },
    {
      "title": "Memory-Efficient Acceleration of Block Low-Rank Foundation Models on Resource Constrained GPUs",
      "authors": "Pierre Abillama, Changwoo Lee, Juechu Dong, David Blaauw, Dennis Sylvester, Hun-Seok Kim",
      "institution": "University of Michigan",
      "link": "https://arxiv.org/pdf/2512.20861",
      "code": "https://github.com/pabillam/mem-efficient-blr",
      "tags": [
        "llm inference",
        "block low-rank (BLR)",
        "Triton kernels",
        "memory-bound optimization",
        "Jetson Orin Nano",
        "roofline analysis"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5f95e7768493ecd557f85d3dd08d75532f4bfee4218e02d377351eaf02b4c20_w640_q70.webp",
      "contributions": "1. Identified through roofline analysis that multi-token inference for BLR-compressed models becomes memory-bound, limiting speedups despite compiler optimizations. 2. Introduced custom Triton kernels with partial fusion and memory layout optimizations specifically for Monarch and BLR-AST (BLAST) methods. 3. Demonstrated significant speedups (up to 3.76x) and model compression (3x) on memory-constrained GPUs (e.g., Jetson Orin Nano, A40) across various foundation models.",
      "summary": "This paper addresses the memory bottleneck in multi-token inference for block low-rank (BLR) compressed foundation models. The authors propose custom Triton kernels with fusion and layout optimizations for BLR methods like Monarch and BLAST. Their solution achieves up to 3.76x speedup and 3x model compression on resource-constrained GPUs compared to optimized PyTorch baselines.",
      "mindmap": "graph LR\n    A[Memory-Efficient Acceleration of Block Low-Rank Foundation Models] --> B[核心问题/Problem: BLR模型多token推理存在内存墙/Multi-token inference for BLR models is memory-bound]\n    A --> C[主要方法/Method: 定制Triton内核与内存优化/Custom Triton kernels with memory optimizations]\n    A --> D[关键结果/Results: 显著加速与模型压缩/Significant speedup & model compression]"
    },
    {
      "title": "Lightweight framework for underground pipeline recognition and spatial localization based on multi-view 2D GPR images",
      "authors": "Haotian Lv, Chao Li, Jiangbo Dai, Yuhui Zhang, Zepeng Fan, Yiqiu Tan, Dawei Wang, Binglei Xie",
      "institution": "Harbin Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.20866",
      "code": null,
      "tags": [
        "object detection",
        "YOLOv11",
        "3D-DIoU",
        "multi-view fusion",
        "GPR",
        "FDTD"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5ecaa60b98d3c92e7c85d9cd5e1f9894fba8806dbb24358189ef30201b7b93c_w640_q70.webp",
      "contributions": "1. Proposed a B/C/D-Scan three-view joint analysis strategy and a feature evaluation method validated by FDTD simulations and real data. 2. Developed the DCO-YOLO framework, integrating DySample, CGLU, and OutlookAttention into YOLOv11 to enhance small-scale pipeline feature extraction. 3. Introduced a 3D-DIoU spatial feature matching algorithm with 3D geometric constraints to automate multi-view annotation association and resolve single-view ambiguities.",
      "summary": "This paper proposes a lightweight framework for 3D underground pipeline detection using multi-view 2D GPR images. The method integrates an improved YOLO-based detection model (DCO-YOLO) with a novel 3D-DIoU spatial matching algorithm for multi-view fusion. Experiments on real urban data show the framework achieves high accuracy, recall, and mAP, outperforming the baseline and offering a reliable solution for pipeline recognition and localization.",
      "mindmap": "graph LR\n    A[Lightweight framework for underground pipeline recognition and spatial localization<br>基于多视图2D GPR图像的地下管道识别与空间定位轻量级框架] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[Weak multi-view feature correlation, low small-target accuracy<br>多视图特征关联弱，小目标识别精度低]\n    C --> C1[3D pipeline three-view feature evaluation<br>三维管道三视图特征评估]\n    C --> C2[DCO-YOLO framework<br>DCO-YOLO框架]\n    C --> C3[3D-DIoU spatial feature matching<br>3D-DIoU空间特征匹配]\n    D --> D1[Accuracy 96.2%, Recall 93.3%, mAP 96.7%<br>准确率96.2%，召回率93.3%，平均精度96.7%]"
    },
    {
      "title": "The Silent Scholar Problem: A Probabilistic Framework for Breaking Epistemic Asymmetry in LLM Agents",
      "authors": "Zan-Kai Chong, Hiroyuki Ohsaki, Bryan Ng",
      "institution": "Kwansei Gakuin University, Victoria University of Wellington",
      "link": "https://arxiv.org/pdf/2512.20884",
      "code": null,
      "tags": [
        "agent system",
        "epistemic asymmetry",
        "Beta-Bernoulli distribution",
        "epistemic caching",
        "forgetting factor",
        "active learning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f9f5d3701afff9c1243309bc058183ccd079615b358ea6fcd7f66333c45b2ae_w640_q70.webp",
      "contributions": "1. A formal probabilistic framework using a Beta-Bernoulli model with a forgetting factor to quantify epistemic uncertainty and provide a non-altruistic motive for knowledge sharing among LLM agents. 2. The introduction of epistemic caching, a resource management mechanism that leverages the forgetting factor to dynamically prioritize the active head of non-stationary knowledge distributions for scalable deployment. 3. Demonstrating how accumulated belief states can serve as verifiable reward signals for RLHF and high-quality data filters for SFT, bridging inference-time interaction with long-term model alignment.",
      "summary": "The paper identifies epistemic asymmetry as a key limitation where LLM agents are unidirectional knowledge consumers. To address this, it proposes a probabilistic framework that models agent belief to create a self-interested motive for sharing knowledge, framed as optimal active learning. Simulations show this uncertainty-driven strategy outperforms random baselines in dynamic environments.",
      "mindmap": "graph LR\n    A[The Silent Scholar Problem<br>沉默学者问题] --> B[Problem: Epistemic Asymmetry<br>问题: 认知不对称];\n    A --> C[Method: Probabilistic Framework<br>方法: 概率框架];\n    A --> D[Results: Outperforms Baseline<br>结果: 优于基线];\n    B --> B1[Agents as unidirectional consumers<br>智能体作为单向消费者];\n    C --> C1[Belief as Beta-Bernoulli<br>信念的Beta-Bernoulli建模];\n    C --> C2[Epistemic Caching<br>认知缓存];\n    D --> D1[Efficient in heterogeneous env.<br>在异构环境中高效];"
    },
    {
      "title": "DGSAN: Dual-Graph Spatiotemporal Attention Network for Pulmonary Nodule Malignancy Prediction",
      "authors": "Xiao Yu, Zhaojie Fang, Guanyu Zhou, Yin Shen, Huoling Luo, Ye Li, Ahmed Elazab, Xiang Wan, Ruiquan Ge, Changmiao Wang",
      "institution": "Hangzhou Dianzi University",
      "link": "https://arxiv.org/pdf/2512.20898",
      "code": "https://github.com/lcbkmm/DGSAN",
      "tags": [
        "medical image analysis",
        "spatiotemporal attention",
        "graph neural network",
        "multimodal fusion",
        "pulmonary nodule classification",
        "feature encoder"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/422fb811704c808454d49662b57428a8e4f2132f4f9eb28d4def2caf51204b49_w640_q70.webp",
      "contributions": "1. Proposed a Dual-Graph Spatiotemporal Attention Network (DGSAN) for pulmonary nodule malignancy prediction. 2. Introduced a Dual-Graph Construction method and a Hierarchical Cross-Modal Graph Fusion Module for effective multimodal feature integration. 3. Compiled a novel multimodal dataset named NLST-cmst to support related research.",
      "summary": "The paper addresses the problem of inefficient multimodal fusion in pulmonary nodule malignancy prediction. It proposes a Dual-Graph Spatiotemporal Attention Network (DGSAN) that uses a Global-Local Feature Encoder and a hierarchical graph fusion module to integrate temporal and multimodal data. Experiments show DGSAN outperforms state-of-the-art methods with high computational efficiency.",
      "mindmap": "graph LR\n    A[DGSAN: Dual-Graph Spatiotemporal Attention Network] --> B(核心问题/Problem: Inefficient multimodal fusion for nodule prediction)\n    A --> C(主要方法/Method: Dual-Graph construction & Hierarchical Cross-Modal Fusion)\n    A --> D(关键结果/Results: Outperforms SOTA on NLST-cmst/CSTL datasets)"
    },
    {
      "title": "Embodied AI-Enhanced IoMT Edge Computing: UAV Trajectory Optimization and Task Offloading with Mobility Prediction",
      "authors": "Siqi Mu, Shuo Wen, Yang Lu, Ruihong Jiang, Bo Ai",
      "institution": "Beijing Sport University, Beijing Jiaotong University, Beijing University of Posts and Telecommunications",
      "link": "https://arxiv.org/pdf/2512.20902",
      "code": null,
      "tags": [
        "edge computing",
        "UAV trajectory optimization",
        "task offloading",
        "mobility prediction",
        "deep reinforcement learning",
        "Transformer"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75676682cad2a49439c91ac390cbbb997d6b492883c198c681369ae72675ee8a_w640_q70.webp",
      "contributions": "1. Establishes an embodied AI-enhanced IoMT edge computing framework for dynamic UAV service provisioning. 2. Proposes a novel hierarchical multi-scale Transformer-based model for predicting WBAN user mobility from historical trajectory data. 3. Designs a prediction-enhanced deep reinforcement learning algorithm that integrates mobility forecasts to jointly optimize UAV flight trajectory and task offloading decisions.",
      "summary": "This paper addresses the problem of minimizing task completion time for WBAN users by optimizing UAV trajectory and task offloading under energy constraints. It proposes an embodied AI framework that uses a Transformer-based model to predict user mobility and a DRL algorithm to make intelligent optimization decisions. Simulation results show the proposed method outperforms existing benchmarks.",
      "mindmap": "graph LR\n    A[Embodied AI-Enhanced IoMT Edge Computing<br/>具身AI增强的IoMT边缘计算] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[Minimize WBAN task time<br/>最小化WBAN任务时间]\n    B --> B2[UAV Energy Constraint<br/>UAV能量约束]\n    C --> C1[Transformer Mobility Prediction<br/>Transformer移动性预测]\n    C --> C2[DRL for Trajectory & Offloading<br/>DRL优化轨迹与卸载]\n    D --> D1[Superior Performance<br/>性能优越]"
    },
    {
      "title": "DiEC: Diffusion Embedded Clustering",
      "authors": "Haidong Hu",
      "institution": "Not explicitly provided in the given content.",
      "link": "https://arxiv.org/pdf/2512.20905",
      "code": null,
      "tags": [
        "deep clustering",
        "diffusion models",
        "representation selection",
        "self-training",
        "graph regularization",
        "denoising consistency"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66551d88d8940c7a650dca6264246e32d115d3596bb088334602fd1943ca8558_w640_q70.webp",
      "contributions": "1. Proposes DiEC, a novel deep clustering method that directly leverages the internal representation trajectory (across layers and timesteps) of a pretrained diffusion U-Net instead of a single fixed embedding. 2. Introduces a two-stage search strategy (CML and OTS) to efficiently identify the most cluster-friendly representation from the diffusion model's internal activations. 3. Enhances the clustering training with a DEC-style objective augmented by adaptive graph regularization, entropy regularization, and a denoising-consistency branch to strengthen and stabilize cluster structures.",
      "summary": "The paper addresses the problem of finding cluster-friendly representations in deep clustering by proposing DiEC, which extracts and optimizes features from the internal activations of a pretrained diffusion model. The method uses a two-stage search to select optimal representations and employs a regularized self-training objective with a consistency branch. Experiments show that DiEC achieves competitive clustering performance on standard benchmarks.",
      "mindmap": "graph LR\n    A[DiEC: Diffusion Embedded Clustering] --> B[核心问题/Problem: Single fixed embedding ignores varying clusterability in diffusion model's internal trajectory];\n    A --> C[主要方法/Method: Two-stage search (CML & OTS) on layer×timestep, regularized self-training with denoising-consistency];\n    A --> D[关键结果/Results: Achieves competitive clustering performance on multiple benchmarks];"
    },
    {
      "title": "RevFFN: Memory-Efficient Full-Parameter Fine-Tuning of Mixture-of-Experts LLMs with Reversible Blocks",
      "authors": "Ningyuan Liu, Jing Yang, Kaitong Cai, Keze Wang",
      "institution": "Sun Yat-sen University",
      "link": "https://arxiv.org/pdf/2512.20920",
      "code": null,
      "tags": [
        "llm training",
        "reversible networks",
        "memory-efficient fine-tuning",
        "mixture-of-experts",
        "full-parameter fine-tuning",
        "activation recomputation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5502accb933d07822fb8b8c8802a3eda6d016d84580bfda3089eae32cc0ea597_w640_q70.webp",
      "contributions": "1. Proposes RevFFN, a novel memory-efficient fine-tuning paradigm for Mixture-of-Experts (MoE) LLMs. 2. Designs reversible Transformer blocks that reconstruct layer inputs from outputs during backpropagation, eliminating the need to store most intermediate activations. 3. Enables efficient full-parameter fine-tuning on a single GPU by drastically reducing peak memory consumption while preserving model capacity.",
      "summary": "The paper addresses the high memory overhead of full-parameter fine-tuning for large language models (LLMs), especially Mixture-of-Experts (MoE) models, caused by caching intermediate activations. It introduces RevFFN, a method using reversible Transformer blocks to recompute activations during backpropagation, significantly reducing memory usage. This allows for efficient full fine-tuning on a single GPU without compromising the model's expressive power.",
      "mindmap": "graph LR\n    A[RevFFN: Memory-Efficient Fine-Tuning] --> B[核心问题/Problem: Full fine-tuning memory overhead高]\n    A --> C[主要方法/Method: 使用可逆Transformer块/Use reversible Transformer blocks]\n    A --> D[关键结果/Results: 单GPU高效全参数微调/Efficient full fine-tuning on single GPU]"
    },
    {
      "title": "Guardrailed Elasticity Pricing: A Churn-Aware Forecasting Playbook for Subscription Strategy",
      "authors": "Deepit Sapru",
      "institution": "University of Illinois Urbana-Champaign",
      "link": "https://arxiv.org/pdf/2512.20932",
      "code": null,
      "tags": [
        "revenue management",
        "constrained optimization",
        "Bayesian hierarchical modeling",
        "Monte Carlo simulation",
        "price elasticity",
        "churn prediction"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0bf97f0a7c7df406f95ecaff29da9d37a9c9851d8013ef82f3f2669083a60ae7_w640_q70.webp",
      "contributions": "1. A novel framework integrating demand forecasting, segment-level price elasticity, and churn propensity into a single constrained optimization system for subscription pricing. 2. A methodology blending seasonal time-series models with tree-based learners and using Monte Carlo scenario tests to map risk envelopes for pricing decisions. 3. A modular, API-driven system designed for real-time recalibration with model explainability for governance, functioning as a managerial strategy playbook.",
      "summary": "This paper proposes a dynamic pricing framework for subscription services that combines forecasting, elasticity modeling, and churn prediction within a constrained optimization system to balance revenue and retention. The method uses Monte Carlo simulations and enforces business guardrails on margins and churn. It outperforms static pricing by targeting price changes to high willingness-to-pay segments while protecting sensitive customers.",
      "mindmap": "graph LR\n    A[Guardrailed Elasticity Pricing] --> B[核心问题/Problem: Static pricing fails to balance revenue & retention];\n    A --> C[主要方法/Method: Forecast + Elasticity + Churn model with constrained optimization];\n    A --> D[关键结果/Results: Outperforms static pricing, protects customers, enables durable growth];"
    },
    {
      "title": "Transductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning",
      "authors": "Shengguang Wu, Xiaohan Wang, Yuhui Zhang, Hao Zhu, Serena Yeung-Levy",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2512.20934",
      "code": "https://transductive-visualprogram.github.io/",
      "tags": [
        "visual reasoning",
        "visual programming",
        "spatial reasoning",
        "tool induction",
        "transductive learning",
        "3D scene understanding"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6374488a70a5d9147002f5652452c2f63ea3698c6660c54123c36fc9deef3991_w640_q70.webp",
      "contributions": "1. Proposes Transductive Visual Programming (TVP), a novel framework that builds new tools from experiential solutions rather than speculative induction., 2. Introduces a closed-loop system with an evolving Tool Library and an Example Library, enabling self-improvement through experience., 3. Demonstrates state-of-the-art performance on spatial reasoning benchmarks and shows that transductively learned tools are used more frequently and generalize better.",
      "summary": "The paper addresses the challenge of spatial reasoning in 3D scenes by proposing Transductive Visual Programming (TVP), a framework that learns reusable higher-level tools by abstracting patterns from its own successful solutions. This experience-driven approach outperforms existing methods and GPT-4o on benchmarks, showing more effective tool discovery and strong generalization to unseen tasks.",
      "mindmap": "graph LR\n        A[Transductive Visual Programming] --> B[核心问题/Problem<br>Spatial reasoning is challenging for VLMs]\n        A --> C[主要方法/Method<br>Build tools from experience, not speculation]\n        A --> D[关键结果/Results<br>SOTA performance, better tool reuse & generalization]"
    },
    {
      "title": "A Multi-fidelity Double-Delta Wing Dataset and Empirical Scaling Laws for GNN-based Aerodynamic Field Surrogate",
      "authors": "Yiren Shen, Juan J. Alonso",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2512.20941",
      "code": null,
      "tags": [
        "others",
        "graph neural network",
        "surrogate model",
        "multi-fidelity dataset",
        "scaling laws",
        "aerodynamic field prediction"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bb0e5406bfc3665bfcafc6d32aeeb524e6e21ffb9ceb2ac785fe0ddd6b60b3_w640_q70.webp",
      "contributions": "1. Release of an open-source, multi-fidelity aerodynamic dataset for double-delta wings, generated using a nested Saltelli sampling scheme. 2. Conducted an empirical scaling study linking training data size and model size to prediction accuracy for a GNN-based surrogate, revealing a power-law relationship. 3. Derived practical guidelines, estimating an optimal sampling density of approximately eight samples per dimension in a design space.",
      "summary": "This paper investigates the relationship between dataset size and model performance for a Graph Neural Network (GNN) surrogate used in aerodynamic field prediction. The authors release a new multi-fidelity dataset for double-delta wings and conduct a scaling study, finding that test error decreases with data size following a power law, which indicates efficient data utilization and informs optimal sampling strategies.",
      "mindmap": "graph LR\n        A[论文标题 / Paper Title<br>A Multi-fidelity Double-Delta Wing Dataset and Empirical Scaling Laws] --> B(核心问题 / Problem<br>缺乏开源多保真数据集与数据规模对模型性能影响的实证指导 / Lack of open-source multi-fidelity datasets and empirical guidelines on data scaling)\n        A --> C(主要方法 / Method<br>发布数据集并进行缩放研究 / Release dataset and conduct scaling study)\n        B --> D(关键结果 / Results<br>误差随数据量呈幂律下降 / Test error decreases with data size via power law)\n        C --> D"
    },
    {
      "title": "Neural Probe-Based Hallucination Detection for Large Language Models",
      "authors": "Shize Liang, Hongzhi Wang",
      "institution": "Harbin Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.20949",
      "code": null,
      "tags": [
        "hallucination detection",
        "MLP probes",
        "token-level detection",
        "Bayesian optimization",
        "hidden states",
        "multi-objective loss"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/256e2b7c6550072fc0e643c4045a4a592ba6b2241cd12656b7dd16ad27bf89b0_w640_q70.webp",
      "contributions": "1. Proposed a neural network-based framework using lightweight MLP probes for token-level hallucination detection, enabling nonlinear modeling of hidden states. 2. Designed a multi-objective joint loss function to improve detection stability and semantic disambiguation. 3. Established a layer position-probe performance response model and used Bayesian optimization to automatically search for optimal probe insertion layers.",
      "summary": "This paper addresses the problem of hallucination in large language models by proposing a real-time, token-level detection method. The method uses lightweight MLP probes on frozen model hidden states and a Bayesian-optimized layer search. Experiments show it outperforms existing methods in accuracy and recall under low false-positive conditions.",
      "mindmap": "graph LR\n    A[Neural Probe-Based Hallucination Detection for Large Language Models] --> B(核心问题/Problem: LLMs生成幻觉内容/LLMs generate hallucinations)\n    A --> C(主要方法/Method: MLP探针 & 贝叶斯优化/MLP probes & Bayesian optimization)\n    A --> D(关键结果/Results: 在多个数据集上表现优异/Outperforms SOTA on multiple datasets)"
    },
    {
      "title": "MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment",
      "authors": "Mohammad Mahdi Abootorabi, Alireza Ghahramani Kure, Mohammadali Mohammadkhani, Sina Elahimanesh, Mohammad Ali Ali Panah",
      "institution": "Based on the provided email domains (gmail.com), no specific institution can be reliably inferred. The team name is \"MultiMind\".",
      "link": "https://arxiv.org/pdf/2512.20950",
      "code": null,
      "tags": [
        "crosslingual information retrieval",
        "dual-encoder",
        "contrastive learning",
        "hard negative sampling",
        "data augmentation",
        "multi-source alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccb6e1762a9617f640573a86ea65e0e68afff48d53006aa74213e0a557970889_w640_q70.webp",
      "contributions": "1. Introduces TriAligner, a novel dual-encoder architecture with contrastive learning for crosslingual claim retrieval. 2. Proposes a method to learn the relative importance of different information sources (e.g., native text, English translations) for alignment. 3. Enhances robustness through LLM-based data preprocessing/augmentation and hard negative sampling strategies.",
      "summary": "This paper addresses the challenge of retrieving fact-checked claims across multiple languages to combat misinformation. The proposed TriAligner system uses a dual-encoder with contrastive learning and multi-source alignment, enhanced by LLM-based data processing. The method shows significant improvements in retrieval accuracy on monolingual and crosslingual benchmarks.",
      "mindmap": "graph LR\n        A[MultiMind at SemEval-2025 Task 7<br>Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment] --> B(核心问题/Problem: Rapid spread of multilingual misinformation);\n        A --> C(主要方法/Method: TriAligner - dual-encoder with contrastive learning & multi-source alignment);\n        A --> D(关键结果/Results: Improved retrieval accuracy on benchmarks);"
    },
    {
      "title": "Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models",
      "authors": "Xiang Zhang, Jiaqi Wei, Yuejin Yang, Zijie Qiu, Yuhan Chen, Zhiqiang Gao, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan, Wanli Ouyang, Chenyu You, Siqi Sun",
      "institution": "Fudan University, Shanghai Artificial Intelligence Laboratory, University of British Columbia, Zhejiang University, The Chinese University of Hong Kong, Stony Brook University",
      "link": "https://arxiv.org/pdf/2512.20954",
      "code": null,
      "tags": [
        "protein language models",
        "reflection pretraining",
        "chain-of-thought",
        "language expressiveness",
        "self-correction",
        "biological sequences"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5c51a6a0ca0e6bf5774254f47e4581544610c262b22a0cc12fe84b840bda40a_w640_q70.webp",
      "contributions": "1. Proposed and defined the concept of \"language expressiveness\" to explain the difficulty of applying Chain-of-Thought reasoning to biological sequence models. 2. Introduced reflection pretraining for biological sequence models, enabling intermediate reasoning through auxiliary \"thinking tokens\". 3. Demonstrated that this approach enables self-correction, improves performance, and offers benefits like counter-memorization and enhanced human steerability.",
      "summary": "This paper addresses the challenge of applying Chain-of-Thought reasoning to biological sequence models like protein language models, which have limited token expressiveness. The authors propose reflection pretraining, which augments the model with auxiliary \"thinking tokens\" to enable intermediate reasoning and self-correction. The method theoretically enhances language expressiveness and experimentally leads to substantial performance gains compared to standard pretraining.",
      "mindmap": "graph LR\n    A[Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models] --> B(核心问题/Problem: Limited expressiveness of protein language restricts CoT reasoning)\n    A --> C(主要方法/Method: Reflection pretraining with auxiliary ”thinking tokens”)\n    A --> D(关键结果/Results: Enhanced expressiveness, self-correction, performance gains)"
    },
    {
      "title": "ReACT-Drug: Reaction-Template Guided Reinforcement Learning for de novo Drug Design",
      "authors": "R Yadunandan, Nimisha Ghosh",
      "institution": "Department of Computer Science and Engineering, Shiv Nadar University Chennai",
      "link": "https://arxiv.org/pdf/2512.20958",
      "code": "https://github.com/YadunandanRaman/ReACT-Drug/",
      "tags": [
        "reinforcement learning",
        "Proximal Policy Optimization (PPO)",
        "ChemBERTa",
        "ESM-2",
        "reaction-template",
        "de novo drug design"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/021dd36ada6572d99e5bbd07493acfe6d2766f9ca2c6bf611ba28e410f041efc_w640_q70.webp",
      "contributions": "1. A target-agnostic RL framework (ReACT-Drug) that uses protein embeddings to find similar proteins and initialize a biologically relevant fragment search space. 2. A PPO agent that guides molecular generation through a dynamic action space defined by chemically valid, reaction-template-based transformations. 3. Ensures 100% chemical validity and novelty while generating candidates with competitive binding affinity and high synthetic accessibility.",
      "summary": "This paper introduces ReACT-Drug, a reinforcement learning framework for de novo drug design. It uses ESM-2 protein embeddings to find similar proteins and their ligands, decomposes them into fragments to guide a PPO agent, which then builds new molecules using reaction-template-based actions encoded by ChemBERTa. The method generates novel, synthetically accessible drug candidates with high binding affinity and guaranteed chemical validity.",
      "mindmap": "graph LR\n        A[ReACT-Drug] --> B[核心问题/Problem: Navigating vast chemical space for synthesizable, high-affinity drugs];\n        A --> C[主要方法/Method: RL + Protein Embeddings + Reaction-Template Actions];\n        A --> D[关键结果/Results: Novel, valid, synthetically accessible candidates];"
    },
    {
      "title": "One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents",
      "authors": "Zhaoxi Zhang, Yitong Duan, Yanzhi Zhang, Yiming Xu, Jiyan He, Yunfang Wu",
      "institution": "Affiliation not explicitly stated in provided text. Email domains suggest potential institutions, but cannot be reliably inferred from given content.",
      "link": "https://arxiv.org/pdf/2512.20957",
      "code": null,
      "tags": [
        "repository-level code understanding",
        "LLM agent",
        "reinforcement learning",
        "tool usage",
        "code navigation",
        "execution-aware"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6254efa02c0725684b783a26c76c1825bf8aaa25aee61fb7aaea40887f0efc46_w640_q70.webp",
      "contributions": "1. Proposes RepoNavigator, an LLM agent that uses a single, execution-aware tool (\"jump to definition\") for navigating code repositories, simplifying agent control and aligning with code execution logic. 2. Introduces an end-to-end Reinforcement Learning (RL) training method for the agent directly from a pretrained model, eliminating the need for closed-source model distillation. 3. Demonstrates state-of-the-art performance on repository-level issue localization, showing that smaller RL-trained models (e.g., 7B) can outperform larger baseline models (e.g., 14B, 32B) and even closed-source models like Claude-3.7.",
      "summary": "The paper addresses the challenge of locating code to modify in large software repositories. It proposes RepoNavigator, an LLM agent trained with Reinforcement Learning to use a single \"jump to definition\" tool for navigation. Experiments show this approach achieves state-of-the-art performance, with smaller models outperforming larger baselines, proving the efficiency of a simple, execution-aware tool combined with RL training.",
      "mindmap": "graph LR\n    A[One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents] --> B[核心问题/Problem: Locating modification points in large, complex code repositories is difficult]\n    A --> C[主要方法/Method: RepoNavigator agent with a single ”jump to definition” tool, trained end-to-end via RL]\n    A --> D[关键结果/Results: SOTA performance; smaller RL-trained models outperform larger baselines and closed-source models]"
    },
    {
      "title": "Can Agentic AI Match the Performance of Human Data Scientists?",
      "authors": "An Luo, Jin Du, Fangqiao Tian, Xun Xian, Robert Specht, Ganghua Wang, Xuan Bi, Charles Fleming, Jayanth Srinivasa, Ashish Kundu, Mingyi Hong, Jie Ding",
      "institution": "University of Minnesota, University of Chicago, Cisco Research",
      "link": "https://arxiv.org/pdf/2512.20959",
      "code": null,
      "tags": [
        "automated data science",
        "agentic AI",
        "domain knowledge",
        "synthetic data",
        "large language models",
        "human-AI teaming"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79fb0613736763ea339bd898e4056c45f61f97d7ed163ac22b97fef63af1c01a_w640_q70.webp",
      "contributions": "1. Designed a novel prediction task where a critical latent variable is hidden in image data to test the limitations of generic agentic AI workflows. 2. Demonstrated through experiments that current agentic AI systems, which rely on generic code generation, fail to match human data scientists who can leverage domain-specific insights. 3. Highlighted a key limitation of current LLM-driven data science automation and underscored the need for future research to develop AI systems that can better incorporate domain knowledge.",
      "summary": "The paper investigates whether agentic AI can match human data scientists by designing a property insurance prediction task where a crucial variable is hidden in image data. Experiments show that AI relying on generic workflows performs poorly compared to methods using domain-specific insights. The study concludes that current agentic AI has a key limitation in incorporating domain knowledge, highlighting a need for future research in this direction.",
      "mindmap": "graph LR\n    A[Can Agentic AI Match Human Data Scientists?] --> B[核心问题/Problem: Can agentic AI match human performance using domain knowledge?];\n    A --> C[主要方法/Method: Design task with latent variable in images, use synthetic insurance data];\n    A --> D[关键结果/Results: Agentic AI with generic workflow falls short; highlights need for domain-aware AI];"
    },
    {
      "title": "Mesh-Attention: A New Communication-Efficient Distributed Attention with Improved Data Locality",
      "authors": "Sirui Chen, Jingji Chen, Siqi Zhu, Ziheng Jiang, Yanghua Peng, Xuehai Qian",
      "institution": "Tsinghua University, Purdue University, University of Illinois Urbana-Champaign, ByteDance Seed",
      "link": "https://arxiv.org/pdf/2512.20968",
      "code": null,
      "tags": [
        "llm training",
        "distributed attention",
        "communication efficiency",
        "Ring-Attention",
        "communication-computation ratio",
        "scalability"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4944eec84564de9a1d27e811d1317c483f5220256be0880e9e87af0f1df84b8e_w640_q70.webp",
      "contributions": "1. Proposes Mesh-Attention, a new distributed attention algorithm using a matrix-based model that assigns 2D computation tiles to GPUs for lower communication-computation ratio. 2. Introduces a greedy algorithm to efficiently search the scheduling space within a tile under communication constraints. 3. Provides theoretical analysis and extensive experiments showing Mesh-Attention significantly reduces communication volume and achieves speedup compared to state-of-the-art methods.",
      "summary": "This paper addresses the communication bottleneck in scaling LLM context windows by proposing Mesh-Attention, a new distributed attention algorithm that uses 2D computation tiling to reduce communication overhead. It demonstrates superior performance, achieving up to 3.4x speedup and 85.4% communication reduction on 256 GPUs, and shows good scalability for large-scale deployments.",
      "mindmap": "graph LR\n    A[Mesh-Attention<br>论文标题/Paper Title] --> B[核心问题/Problem: 分布式注意力通信开销大<br>High Communication in Distributed Attention]\n    A --> C[主要方法/Method: 基于2D计算块划分的Mesh-Attention算法<br>Mesh-Attention with 2D Tile Assignment]\n    A --> D[关键结果/Results: 通信量减少85.4%, 速度提升3.4倍<br>85.4% Comm Reduction, 3.4x Speedup]"
    },
    {
      "title": "Generalised Linear Models in Deep Bayesian RL with Learnable Basis Functions",
      "authors": "Jingyang You, Hanna Kurniawati",
      "institution": "Australian National University",
      "link": "https://arxiv.org/pdf/2512.20974",
      "code": null,
      "tags": [
        "reinforcement learning",
        "Bayesian Reinforcement Learning",
        "Meta-Reinforcement Learning",
        "Generalised Linear Models",
        "Learnable Basis Functions",
        "Variational Inference"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d35dd58d9d51b22dbce9eb7fc7a54a60d532c573648a3a29596e023ac63db13_w640_q70.webp",
      "contributions": "1. Proposes GLiBRL, a novel deep Bayesian RL method using Generalised Linear Models with learnable basis functions for efficient and accurate model learning. 2. Enables fully tractable marginal likelihood and Bayesian inference on task parameters and model noises, avoiding the need to optimize the difficult Evidence Lower Bound (ELBO). 3. Demonstrates significant performance improvements on MetaWorld benchmarks, outperforming state-of-the-art methods like VariBAD and showing low-variance, consistent results.",
      "summary": "This paper addresses the problem of inefficient and unstable model learning in deep Bayesian Reinforcement Learning (BRL), which traditionally relies on optimizing the difficult Evidence Lower Bound (ELBO). The authors propose a new method called GLiBRL, which uses Generalised Linear Models with learnable basis functions to enable tractable marginal likelihood and Bayesian inference. The method significantly improves success rates on challenging MetaWorld benchmarks compared to existing deep BRL and meta-RL approaches.",
      "mindmap": "graph LR\n    A[GLiBRL] --> B[核心问题/Problem: Classical BRL assumes known models, Deep BRL with ELBO is hard to optimize]\n    A --> C[主要方法/Method: Use GLMs with learnable basis for tractable likelihood & inference]\n    A --> D[关键结果/Results: Improves success rate vs. VariBAD (2.7x), low-variance performance]"
    },
    {
      "title": "Automatic Replication of LLM Mistakes in Medical Conversations",
      "authors": "Oleksii Proniakin, Diego Fajardo, Ruslan Nazarenko, Razvan Marinescu",
      "institution": "Lumos AI",
      "link": "https://arxiv.org/pdf/2512.20983",
      "code": null,
      "tags": [
        "llm evaluation",
        "medical conversation",
        "mistake replication",
        "benchmark creation",
        "llm judges",
        "single-shot qa"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7799ccba99ce08a1cee1bd87ba7b9e986a373df0f78a25479ad9fec7478ca0e9_w640_q70.webp",
      "contributions": "1. Introduces MedMistake, an automatic pipeline for extracting and replicating LLM mistakes from complex medical conversations into a benchmark format. 2. Releases MedMistake-All, a dataset of 3,390 single-shot QA pairs derived from identified mistakes, and a validated subset, MedMistake-Bench. 3. Provides a comprehensive evaluation of 12 frontier LLMs using the validated benchmark, revealing performance trends among top models.",
      "summary": "The paper addresses the difficulty of replicating specific mistakes made by LLMs in clinical conversations. It proposes MedMistake, an automated pipeline that generates conversational data, uses LLM judges to identify errors, and distills them into single-shot QA pairs to create a benchmark. The resulting benchmark was used to evaluate 12 LLMs, finding that GPT, Claude, and Grok models performed best.",
      "mindmap": "graph LR\n    A[Automatic Replication of LLM Mistakes in Medical Conversations] --> B(核心问题/Problem: LLM错误难以在其他模型中复现/Mistakes hard to replicate across LLMs)\n    A --> C(主要方法/Method: MedMistake自动管道/MedMistake automatic pipeline)\n    A --> D(关键结果/Results: 发布基准并评估12个LLM/Released benchmark & evaluated 12 LLMs)\n    C --> C1(生成对话/Generate conversations)\n    C --> C2(LLM委员会评估/LLM committee evaluation)\n    C --> C3(创建单轮QA对/Create single-shot QA pairs)\n    D --> D1(MedMistake-All数据集/MedMistake-All dataset)\n    D --> D2(MedMistake-Bench验证子集/MedMistake-Bench validated subset)\n    D --> D3(GPT/Claude/Grok表现最佳/GPT/Claude/Grok performed best)"
    },
    {
      "title": "A Blockchain-Monitored Agentic AI Architecture for Trusted Perception-Reasoning-Action Pipelines",
      "authors": "Salman Jan, Hassan Ali Razzaqi, Ali Akarma, Mohammad Riyaz Belgaum",
      "institution": "Arab Open University-Bahrain, Islamic University of Madinah",
      "link": "https://arxiv.org/pdf/2512.20985",
      "code": null,
      "tags": [
        "agent system",
        "LangChain",
        "Hyperledger Fabric",
        "MCP (Model Context Protocol)",
        "permissioned blockchain",
        "multi-agent system"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24b6daf67b596733e755359a781c7506180a1c98a12a8eab70c8fd627d718b47_w640_q70.webp",
      "contributions": "1. Proposed a novel architecture integrating a LangChain-based multi-agent system with a permissioned blockchain for monitoring and auditing agentic AI actions. 2. Introduced a framework linking the perception-reasoning-action cycle to a blockchain governance layer for input verification, action evaluation, and outcome logging. 3. Demonstrated the framework's applicability and performance through experiments in smart inventory management, traffic-signal control, and healthcare monitoring.",
      "summary": "This paper proposes a blockchain-monitored architecture for agentic AI systems to address trust and oversight concerns. The method integrates a LangChain multi-agent system with a Hyperledger Fabric blockchain to create an auditable perception-reasoning-action pipeline. The results show the framework effectively prevents unauthorized actions, provides full decision traceability, and maintains acceptable operational latency.",
      "mindmap": "graph LR\n        A[论文标题 / Paper Title<br>A Blockchain-Monitored Agentic AI Architecture] --> B(核心问题 / Problem<br>Agentic AI缺乏信任与审计 / Lack of Trust & Auditability)\n        A --> C(主要方法 / Method<br>区块链监控的LangChain多智能体架构 / Blockchain-Monitored LangChain Multi-Agent Architecture)\n        A --> D(关键结果 / Results<br>有效安全验证与可追溯性 / Effective Security Verification & Traceability)"
    },
    {
      "title": "FinAgent: An Agentic AI Framework Integrating Personal Finance and Nutrition Planning",
      "authors": "Toqeer Ali Syed, Abdulaziz Alshahrani, Ali Ullah, Ali Akarma, Sohail Khan, Muhammad Nauman, Salman Jan",
      "institution": "Islamic University of Madinah, Effat University, Arab Open University",
      "link": "https://arxiv.org/pdf/2512.20991",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent architecture",
        "substitution graph",
        "price-aware optimization"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc1ddd8fc13f7437534fa058d5e3879ce0f82c07898d64ccb7548f0932948a8a_w640_q70.webp",
      "contributions": "1. Proposes a novel agentic AI framework that integrates personal finance management with real-time diet optimization, addressing a gap in current tools. 2. Implements a modular multi-agent architecture with specialized agents (budgeting, nutrition, price monitoring, health personalization) that share a knowledge base and use a substitution graph for cost-effective meal planning. 3. Demonstrates through a case study simulation significant cost reduction (12-18%) and high nutrient adequacy (>95%) while maintaining robustness to market price fluctuations.",
      "summary": "This paper introduces FinAgent, an agentic AI framework that combines personal finance and real-time price data to generate nutritionally adequate meal plans at minimal cost. It uses a modular multi-agent system and a substitution graph to dynamically adapt to budget constraints and market changes. The system was validated in a simulation, showing significant cost savings and high nutritional adequacy, aligning with sustainable development goals.",
      "mindmap": "graph LR\n        A[FinAgent] --> B[核心问题/Problem: Limited budgets & nutritional demands with fluctuating food prices]\n        A --> C[主要方法/Method: Price-aware agentic AI with multi-agent architecture & substitution graph]\n        A --> D[关键结果/Results: 12-18% cost reduction, >95% nutrient adequacy, robust to price changes]"
    },
    {
      "title": "TrafficSimAgent: A Hierarchical Agent Framework for Autonomous Traffic Simulation with MCP Control",
      "authors": "Yuwei Du, Jun Zhang, Jie Feng, Zhicheng Liu, Jian Yuan, Yong Li",
      "institution": "Tsinghua University, Alibaba Group",
      "link": "https://arxiv.org/pdf/2512.20996",
      "code": null,
      "tags": [
        "agent system",
        "traffic simulation",
        "LLM agent",
        "hierarchical framework",
        "MCP control",
        "autonomous decision-making"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f663746265410a8f10fffee2372e39160e0e5f92969f9c3f7f502da4d3657fd_w640_q70.webp",
      "contributions": "1. Proposes TrafficSimAgent, a novel LLM-based hierarchical agent framework designed to lower the barrier for conducting traffic simulations by automating experiment design and decision optimization. 2. Introduces a cross-level collaboration mechanism where high-level agents interpret natural language instructions and plan workflows, while low-level agents make real-time, condition-based action selections for fundamental elements. 3. Demonstrates through extensive experiments that the framework effectively executes simulations under various conditions, handles ambiguous instructions, and achieves superior performance compared to other systems and SOTA LLM-based methods.",
      "summary": "This paper introduces TrafficSimAgent, a hierarchical LLM-based agent framework that automates traffic simulation tasks by using high-level agents for natural language instruction comprehension and workflow planning, and low-level agents for real-time action optimization. The system is designed to make powerful simulation platforms like SUMO more accessible to non-experts. Experiments show it effectively executes simulations, handles ambiguous instructions, and outperforms existing methods.",
      "mindmap": "graph LR\n    A[TrafficSimAgent] --> B[核心问题/Problem: 现有交通仿真平台使用门槛高/High barrier to using traffic simulators]\n    A --> C[主要方法/Method: 分层LLM智能体框架/Hierarchical LLM Agent Framework]\n    A --> D[关键结果/Results: 有效执行仿真，处理模糊指令，性能优越/Executes simulations effectively, handles ambiguous instructions, superior performance]"
    },
    {
      "title": "Distilling the Essence: Efficient Reasoning Distillation via Sequence Truncation",
      "authors": "Wei-Rui Chen, Vignesh Kothapalli, Ata Fatahibaarzi, Hejian Sang, Shao Tang, Qingquan Song, Zhipeng Wang, Muhammad Abdul-Mageed",
      "institution": "The University of British Columbia, LinkedIn",
      "link": "https://arxiv.org/pdf/2512.21002",
      "code": "https://github.com/weiruichen01/distilling-the-essence",
      "tags": [
        "llm training",
        "knowledge distillation",
        "chain-of-thought",
        "sequence truncation",
        "training efficiency",
        "reasoning models"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a99e2da19bbc9bacf5104e37b4afd860b26a5285dd752f9a6e025702d930839_w640_q70.webp",
      "contributions": "1. Analysis of supervision allocation in reasoning distillation, showing the CoT segment is the dominant factor for transferring reasoning capability. 2. Establishment of a truncation protocol to quantify computation-quality tradeoffs as a function of sequence length. 3. Empirical demonstration that training on only the first 50% of tokens retains ~94% of performance while halving computational costs.",
      "summary": "This paper addresses the computational expense of distilling reasoning capabilities from large to small models over long sequences. It proposes a method of selective distillation and sequence truncation, focusing on early reasoning tokens. The key finding is that training on just the first half of tokens can preserve most performance while significantly reducing training time, memory, and FLOPs.",
      "mindmap": "graph LR\n        A[Distilling the Essence<br>高效推理蒸馏] --> B{核心问题/Problem};\n        A --> C{主要方法/Method};\n        A --> D{关键结果/Results};\n        B --> B1[长序列推理蒸馏计算昂贵<br>Long-Sequence Reasoning Distillation is Expensive];\n        C --> C1[选择性监督与序列截断<br>Selective Supervision & Sequence Truncation];\n        D --> D1[保留94%性能，减少50%成本<br>Retain 94% Performance, Reduce 50% Cost];"
    },
    {
      "title": "LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics",
      "authors": "Jiashuo Liu, Jiayun Wu, Chunjie Wu, Jingkai Liu, Zaiyuan Wang, Huan Zhou, Wenhao Huang, Hongseok Namkoong",
      "institution": "ByteDance Seed, Carnegie Mellon University, Columbia University",
      "link": "https://arxiv.org/pdf/2512.21010",
      "code": null,
      "tags": [
        "llm evaluation",
        "Competitive Swiss-System Dynamics",
        "Expected Win Score",
        "Failure Sensitivity Analysis",
        "Monte Carlo Simulation",
        "risk appetite"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c6a4e260d9e6100733ae95995348a1b30295905871b863cf4afa821492e22eb_w640_q70.webp",
      "contributions": "1. Introduces the Competitive Swiss-System Dynamics (CSD) framework, a novel sequential contest simulation for holistic LLM ranking across multiple benchmarks, 2. Proposes the Expected Win Score via Monte Carlo Simulation to provide a statistically robust ranking that reduces noise from random pairing, 3. Implements Failure Sensitivity Analysis to profile models by risk appetite, distinguishing between robust generalists and aggressive specialists.",
      "summary": "The paper addresses the limitations of static, fragmented LLM evaluation by proposing the Competitive Swiss-System Dynamics (CSD) framework, which simulates a multi-round sequential contest to aggregate performance across benchmarks dynamically. It uses Monte Carlo simulation to compute a robust Expected Win Score and includes a Failure Sensitivity Analysis to assess model risk profiles. The authors demonstrate that CSD provides a more nuanced and context-aware ranking than traditional methods, advancing risk-informed LLM evaluation.",
      "mindmap": "graph LR\n    A[LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics] --> B[核心问题/Problem: Fragmented benchmarks and static scoring fail to capture dynamic competitive fitness and risk]\n    A --> C[主要方法/Method: Competitive Swiss-System Dynamics (CSD) with Monte Carlo Simulation and Failure Sensitivity Analysis]\n    A --> D[关键结果/Results: More nuanced, context-aware ranking distinguishing robust generalists vs. aggressive specialists]"
    },
    {
      "title": "Rethinking Supervised Fine-Tuning: Emphasizing Key Answer Tokens for Improved LLM Accuracy",
      "authors": "Xiaofeng Shi, Qian Kou, Yuduo Li, Hua Zhou",
      "institution": "Beijing Academy of Artificial Intelligence (BAAI), Beijing Jiaotong University (BJTU)",
      "link": "https://arxiv.org/pdf/2512.21017",
      "code": null,
      "tags": [
        "post-training (sft/rlhf)",
        "Supervised Fine-Tuning",
        "Chain-of-Thought",
        "Two-Stage Training",
        "Attention Imbalance",
        "Key Answer Tokens"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7eab786d7e6ac187d45153b771fdc458d7c8434c0e133a9bcdb70a2afa441a73_w640_q70.webp",
      "contributions": "1. Identifies a key limitation in conventional SFT where models over-attend to lengthy Chain-of-Thought reasoning sequences at the expense of the shorter, critical final answer tokens. 2. Proposes SFTKey, a novel two-stage fine-tuning scheme that first applies conventional SFT for format learning, then fine-tunes only on the Key (final answer) portion to boost accuracy. 3. Demonstrates through extensive experiments that SFTKey achieves an average accuracy improvement of over 5% compared to standard SFT while maintaining correct output formatting.",
      "summary": "The paper identifies that standard Supervised Fine-Tuning (SFT) for LLMs can cause an attention imbalance, where models focus too much on long reasoning chains (CoT) and not enough on the final answer. To solve this, the authors propose SFTKey, a two-stage method that first does standard SFT for formatting, then fine-tunes only on the key answer tokens. Experiments show this approach improves average accuracy by over 5% without harming output format correctness.",
      "mindmap": "graph LR\n    A[论文标题 / Paper Title<br>Rethinking Supervised Fine-Tuning] --> B[核心问题 / Problem<br>注意力失衡于长推理链 / Attention Imbalance on Long CoT]\n    A --> C[主要方法 / Method<br>两阶段训练 SFTKey / Two-Stage Training SFTKey]\n    A --> D[关键结果 / Results<br>准确率提升>5% / Accuracy Improvement >5%]"
    },
    {
      "title": "Policy-Conditioned Policies for Multi-Agent Task Solving",
      "authors": "Yue Lin, Shuhui Zhu, Wenhao Li, Ang Li, Dan Qiao, Pascal Poupart, Hongyuan Zha, Baoxiang Wang",
      "institution": "The Chinese University of Hong Kong, Shenzhen; University of Waterloo; Tongji University; Vector Institute",
      "link": "https://arxiv.org/pdf/2512.21024",
      "code": null,
      "tags": [
        "multi-agent reinforcement learning",
        "Program Equilibrium",
        "Programmatic Iterated Best Response (PIBR)",
        "policy-conditioning",
        "large language models",
        "textual gradients"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8665c80d59a606e3c0796d224d372080c9552f5b48a9e7e797a73cad25b1b7e7_w640_q70.webp",
      "contributions": "1. Proposes a paradigm shift by representing agent policies as human-interpretable source code, bridging the gap between opaque neural policies and the need for strategy comprehension in multi-agent settings. 2. Introduces Programmatic Iterated Best Response (PIBR), a novel algorithm that uses LLMs as point-wise best-response operators to synthesize and refine policy code based on game utility and unit tests. 3. Operationalizes the game-theoretic concept of Program Equilibrium for modern learning, demonstrating its effectiveness on coordination games and a cooperative foraging environment.",
      "summary": "This paper addresses the challenge of dynamic strategy adaptation in multi-agent tasks by representing policies as interpretable source code and using Large Language Models (LLMs) to optimize them. The core method, Programmatic Iterated Best Response (PIBR), leverages LLMs to iteratively refine an agent's policy code in response to an opponent's strategy using textual feedback. The approach successfully solves standard coordination games and a cooperative environment, demonstrating a practical bridge between theoretical Program Equilibrium and modern AI learning.",
      "mindmap": "graph LR\n    A[Policy-Conditioned Policies for Multi-Agent Task Solving] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[策略表示瓶颈/Representational Bottleneck]\n    B --> B2[无法直接条件化对手策略/Cannot Condition on Opponent's Policy]\n    C --> C1[程序化策略表示/Programmatic Policy Representation]\n    C --> C2[LLM作为近似解释器/LLM as Approximate Interpreter]\n    C --> C3[程序化迭代最佳响应/PIBR Algorithm]\n    D --> D1[解决协调矩阵游戏/Solves Coordination Games]\n    D --> D2[解决合作觅食环境/Solves Cooperative Foraging]"
    },
    {
      "title": "DexAvatar: 3D Sign Language Reconstruction with Hand and Body Pose Priors",
      "authors": "Kaustubh Kundu, Hrishav Bakul Barua, Lucy Robertson-Bell, Zhixi Cai, Kalin Stefanov",
      "institution": "Monash University, TCS Research",
      "link": "https://arxiv.org/pdf/2512.21054",
      "code": "https://github.com/kaustesseract/DexAvatar",
      "tags": [
        "3D human pose estimation",
        "3D sign language reconstruction",
        "biomechanical accuracy",
        "hand and body pose priors",
        "monocular video",
        "SMPL-X"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/594bef871fe9a00d58a9f3f12c9a0b4bf4f66d3d738bd3f02dedcbad04bdcd25_w640_q70.webp",
      "contributions": "1. A novel framework (DexAvatar) for reconstructing biomechanically accurate 3D hand and body poses from monocular sign language videos. 2. The use of learned 3D hand and body pose priors to guide the reconstruction and overcome challenges like self-occlusion and motion blur. 3. Demonstrating strong performance on the SGNify benchmark, achieving a 35.11% improvement over the state-of-the-art.",
      "summary": "The paper introduces DexAvatar, a framework that uses learned 3D hand and body pose priors to reconstruct accurate 3D sign language poses from monocular videos. It addresses the limitations of existing 2D datasets and noisy 3D estimations. The method significantly outperforms prior work on the SGNify motion capture benchmark.",
      "mindmap": "graph LR\n        A[DexAvatar] --> B[核心问题/Problem: 手语视频缺乏准确3D数据，现有3D姿态估计质量差]\n        A --> C[主要方法/Method: 利用学习到的3D手部和身体姿态先验，从单目视频重建]\n        A --> D[关键结果/Results: 在SGNify数据集上性能提升35.11%]"
    },
    {
      "title": "Understanding Scaling Laws in Deep Neural Networks via Feature Learning Dynamics",
      "authors": "Zihan Yao, Ruoyu Wu, Tianxiang Gao",
      "institution": "DePaul University, Iowa State University",
      "link": "https://arxiv.org/pdf/2512.21075",
      "code": null,
      "tags": [
        "deep learning theory",
        "scaling laws",
        "feature learning",
        "infinite-depth limit",
        "ResNets",
        "hyperparameter transfer"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06065072ce8d20b2298a45760b95c3f905a6aff3d726e09d4ddf1ecd2e9cc359_w640_q70.webp",
      "contributions": "1. Derives Neural Feature Dynamics (NFD), a theoretical framework characterizing feature learning in ResNets in the joint infinite-width and infinite-depth limit. 2. Identifies a vanishing mechanism induced by 1/√depth scaling that explains feature-learning collapse in deep networks and the failure of depth-µP. 3. Proposes a practical depth-aware learning-rate correction to counteract the collapse and restore depth-wise hyperparameter transfer for improved performance.",
      "summary": "This paper addresses the lack of theoretical understanding behind scaling laws in deep learning by analyzing feature learning dynamics in deep ResNets. It proposes the Neural Feature Dynamics (NFD) framework in the infinite-width and depth limit, which explains when scaling succeeds and identifies a cause of feature collapse. Based on this insight, the authors propose a simple learning-rate correction that improves training stability and performance in deeper networks.",
      "mindmap": "graph LR\n    A[Understanding Scaling Laws via Feature Learning Dynamics] --> B[核心问题/Problem: Scaling laws describe success but not when/why scaling fails]\n    A --> C[主要方法/Method: Derive Neural Feature Dynamics (NFD) in infinite-width & depth limit]\n    A --> D[关键结果/Results: Explains diminishing returns, proposes depth-aware LR correction]"
    },
    {
      "title": "Agentic Explainable Artificial Intelligence (Agentic XAI) Approach To Explore Better Explanation",
      "authors": "Tomoaki Yamaguchi, Yutong Zhou, Masahiro Ryo, Keisuke Katsura",
      "institution": "Gifu University, Leibniz Centre for Agricultural Landscape Research (ZALF), Brandenburg University of Technology Cottbus–Senftenberg, Kyoto University",
      "link": "https://arxiv.org/pdf/2512.21066",
      "code": null,
      "tags": [
        "agent system",
        "Agentic AI",
        "SHAP",
        "Large Language Model",
        "Iterative Refinement",
        "Bias-Variance Trade-off"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76e69e3950a2d09bc883a9cee931300bdfbeacc4e1e6094150a08db35366449e_w640_q70.webp",
      "contributions": "1. Proposes a novel Agentic XAI framework integrating SHAP-based explainability with multimodal LLM-driven iterative refinement for generating progressively enhanced explanations. 2. Demonstrates the framework's application and evaluation in a real-world agricultural recommendation system using rice yield data. 3. Identifies a bias-variance trade-off in iterative refinement, showing that early stopping (regularization) is crucial for optimizing explanation quality, challenging assumptions of monotonic improvement.",
      "summary": "This paper proposes an Agentic Explainable AI (XAI) framework that combines SHAP analysis with iterative refinement by a multimodal Large Language Model (LLM) to generate better explanations. The framework was tested as an agricultural recommendation system, and evaluations by both human experts and LLMs showed that explanation quality improved over initial rounds but declined with excessive refinement, revealing a bias-variance trade-off. The findings indicate that strategic early stopping is necessary to optimize the practical utility of such agentic XAI systems.",
      "mindmap": "graph LR\n        A[Agentic XAI Approach] --> B[核心问题/Problem: 向非专业人士解释XAI输出困难/Hard to communicate XAI outputs to laypersons]\n        A --> C[主要方法/Method: SHAP + 多模态LLM迭代优化/SHAP + Multimodal LLM Iterative Refinement]\n        A --> D[关键结果/Results: 早期迭代提升质量，过度优化导致下降/Early rounds improve quality, excessive refinement causes drop]"
    },
    {
      "title": "LLM Personas as a Substitute for Field Experiments in Method Benchmarking",
      "authors": "Enoch Hyunwook Kang",
      "institution": "University of Washington",
      "link": "https://arxiv.org/pdf/2512.21080",
      "code": null,
      "tags": [
        "algorithmic fairness & evaluation",
        "field experiments",
        "A/B testing",
        "LLM personas",
        "algorithmic benchmarking",
        "information-theoretic bounds"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f1e74907f157cdb694f3120aed988d1affab03b63adb6bf73297f43733c1b8ba_w640_q70.webp",
      "contributions": "1. Provides a formal, if-and-only-if characterization of the conditions (aggregate-only observation, algorithm-blind evaluation) under which swapping humans for LLM personas is a valid benchmark substitution, equivalent to changing the evaluation panel. 2. Moves from validity to usefulness by defining an information-theoretic measure of discriminability for the aggregate channel induced by persona simulation. 3. Derives explicit sample-size bounds on the number of independent persona evaluations required to make persona benchmarking as decision-relevant as a field experiment for distinguishing between methods.",
      "summary": "The paper addresses the high cost and latency of field experiments (A/B tests) for benchmarking methods in societal systems by proposing LLM-based persona simulation as a synthetic alternative. It formally proves the conditions under which this substitution is valid and provides information-theoretic bounds on the required number of persona evaluations to make the benchmark useful. The main conclusion is that persona benchmarking can be a viable, efficient substitute for field experiments under specific, well-defined conditions.",
      "mindmap": "graph LR\n    A[LLM Personas as a Substitute for Field Experiments] --> B[核心问题/Problem: Field experiments are costly and slow, hindering iterative method development.]\n    A --> C[主要方法/Method: Use LLM-based persona simulation as a cheap synthetic benchmark under specific conditions.]\n    A --> D[关键结果/Results: Formal validity conditions proven; sample-size bounds derived for decision-relevance.]"
    },
    {
      "title": "TexAvatars : Hybrid Texel-3D Representations for Stable Rigging of Photorealistic Gaussian Head Avatars",
      "authors": "Jaeseong Lee, Junyeong Ahn, Taewoong Kang, Jaegul Choo",
      "institution": "KAIST, Hanyang University",
      "link": "https://arxiv.org/pdf/2512.21099",
      "code": null,
      "tags": [
        "3D avatar generation",
        "3D Gaussian Splatting",
        "analytic rigging",
        "texel-space deformation",
        "hybrid representation",
        "head reenactment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8320fd6b1a6f131ad704b82b65143269040ab86b9b67005a1edf15fca8097f6_w640_q70.webp",
      "contributions": "1. A hybrid avatar representation (TexAvatars) that combines analytic rigging for geometric grounding with texel-space neural regression for spatial continuity. 2. A method that predicts Gaussian attributes in UV space via CNNs but drives 3D deformation using mesh-aware Jacobians, enabling smooth transitions across mesh boundaries. 3. The model demonstrates improved generalization, stability, and capture of fine-grained expression details (e.g., wrinkles, mouth cavity) under extreme poses and expressions.",
      "summary": "This paper introduces TexAvatars, a method for creating drivable 3D head avatars by hybridizing analytic rigging with texel-space neural regression to improve generalization to unseen expressions. It predicts local attributes in UV space but uses mesh-aware Jacobians for 3D deformation, separating semantic modeling from geometric control. The approach achieves state-of-the-art performance in challenging reenactment scenarios, capturing fine details with high fidelity.",
      "mindmap": "graph LR\n        A[TexAvatars] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有方法泛化性差/Existing methods generalize poorly]\n        B --> B2[难以处理极端表情与姿态/Struggle with extreme expressions & poses]\n        C --> C1[混合表示/Hybrid Representation]\n        C --> C2[UV空间预测，3D网格驱动/UV-space prediction, 3D mesh-driven deformation]\n        D --> D1[泛化能力提升/Improved generalization]\n        D --> D2[高保真细节/High-fidelity details]\n        D --> D3[状态领先性能/State-of-the-art performance]"
    },
    {
      "title": "Semi-Supervised Learning for Large Language Models Safety and Content Moderation",
      "authors": "Eduard Stefan Dinuta, Iustin Sirbu, Traian Rebedea",
      "institution": "National University of Science and Technology Politehnica Bucharest, Renius Technologies, NVIDIA",
      "link": "https://arxiv.org/pdf/2512.21107",
      "code": null,
      "tags": [
        "content moderation",
        "semi-supervised learning",
        "data augmentation",
        "safety classifiers",
        "LLM safety",
        "prompt harmfulness"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/035c08c88d89969ce37594942a40aa577a3c0c7c7743cd71bdf84366a9dfa5f2_w640_q70.webp",
      "contributions": "1. Analysis of state-of-the-art semi-supervised learning algorithms for LLM safety, focusing on both prompt and response harmfulness. 2. Introduction of a new, task-specific augmentation technique for safety tasks. 3. Demonstration that task-specific augmentations significantly outperform general-purpose methods like backtranslation.",
      "summary": "This paper addresses the challenge of acquiring high-quality labeled data for training safety classifiers for Large Language Models. It proposes using semi-supervised learning techniques that leverage both labeled and unlabeled data, and introduces a task-specific data augmentation method. The key finding is that this approach, particularly with custom augmentations, significantly improves performance on safety tasks compared to using general-purpose techniques.",
      "mindmap": "graph LR\n    A[论文标题 / Paper Title<br>Semi-Supervised Learning for LLM Safety] --> B[核心问题 / Problem<br>依赖大量标注数据 / Reliance on large labeled data]\n    A --> C[主要方法 / Method<br>半监督学习与任务特定增强 / SSL & Task-Specific Augmentation]\n    A --> D[关键结果 / Results<br>性能显著提升 / Significant Performance Improvement]"
    },
    {
      "title": "Semantic Refinement with LLMs for Graph Representations",
      "authors": "Safal Thapaliya, Zehong Wang, Jiazheng Li, Ziming Li, Yanfang Ye, Chuxu Zhang",
      "institution": "University of Connecticut, University of Notre Dame",
      "link": "https://arxiv.org/pdf/2512.21106",
      "code": null,
      "tags": [
        "graph representation learning",
        "graph neural network",
        "large language model",
        "semantic refinement",
        "structure-semantics heterogeneity",
        "data-centric adaptation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfae73c72759ca834d898f3c6ca5f0824bada06285918fca678e0f809fce9afd_w640_q70.webp",
      "contributions": "1. Proposes a data-centric perspective to address structure-semantics heterogeneity in graphs by treating node semantics as a task-adaptive variable, shifting focus from model-centric inductive bias injection. 2. Introduces the Data-Adaptive Semantic Refinement (DAS) framework, which couples a fixed GNN and an LLM in a closed feedback loop for iterative semantic refinement and graph learning. 3. Demonstrates the framework's effectiveness on diverse graphs, showing consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs.",
      "summary": "This paper addresses the challenge of structure-semantics heterogeneity in graph data, where predictive signals vary across domains. It proposes a Data-Adaptive Semantic Refinement (DAS) framework that uses a closed feedback loop between a GNN and an LLM to iteratively refine node semantics for the learning task. The method shows strong performance on structure-dominated graphs and remains competitive on semantics-rich graphs, validating the data-centric adaptation approach.",
      "mindmap": "graph LR\n    A[Semantic Refinement with LLMs for Graph Representations] --> B(核心问题/Problem: Graph structure-semantics heterogeneity 图的结构-语义异质性)\n    A --> C(主要方法/Method: Data-Adaptive Semantic Refinement (DAS) framework 数据自适应语义精炼框架)\n    A --> D(关键结果/Results: Improves structure-dominated graphs, competitive on semantics-rich graphs 提升结构主导图性能，在语义丰富图上保持竞争力)"
    },
    {
      "title": "STLDM: Spatio-Temporal Latent Diffusion Model for Precipitation Nowcasting",
      "authors": "Shi Quan Foo, Chi-Ho Wong, Zhihan Gao, Dit-Yan Yeung, Ka-Hing Wong, Wai-Kin Wong",
      "institution": "The Hong Kong University of Science and Technology, Hong Kong Observatory",
      "link": "https://arxiv.org/pdf/2512.21118",
      "code": "https://github.com/sqfoo/stldm_official",
      "tags": [
        "diffusion models",
        "precipitation nowcasting",
        "latent diffusion model",
        "spatio-temporal prediction",
        "variational autoencoder",
        "conditioning network"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3f04a94a2a07676690c2f108f7a602a6b052c1463701d217a319cd81e05ecce_w640_q70.webp",
      "contributions": "1. Proposes STLDM, a novel two-stage diffusion-based architecture for precipitation nowcasting that combines deterministic forecasting with generative enhancement. 2. Introduces an end-to-end learning framework that jointly trains a Variational Autoencoder, a conditioning network, and a latent diffusion model. 3. Demonstrates superior performance and improved inference efficiency compared to state-of-the-art methods on multiple radar datasets.",
      "summary": "The paper addresses the challenge of precipitation nowcasting, where deterministic models produce blurry predictions and generative models suffer from poor accuracy. It proposes STLDM, a spatio-temporal latent diffusion model that decomposes the task into a deterministic forecasting stage and a generative enhancement stage. Experiments show STLDM outperforms state-of-the-art methods while being more efficient.",
      "mindmap": "graph LR\n    A[STLDM: 降水临近预报模型] --> B[核心问题/Problem: 确定性模型模糊，生成模型精度差]\n    A --> C[主要方法/Method: 两阶段潜扩散模型]\n    A --> D[关键结果/Results: 性能优越，推理高效]"
    },
    {
      "title": "Beyond Context: Large Language Models Failure to Grasp Users Intent",
      "authors": "Ahmed M. Hussain, Salahuddin Salahuddin, Panos Papadimitratos",
      "institution": "KTH Royal Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.21110",
      "code": null,
      "tags": [
        "ai safety",
        "intent recognition",
        "contextual understanding",
        "safety circumvention",
        "prompt engineering",
        "transformer architectures"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/55c1a596dd6375317c809bb19f466455285faf18a1f9810649d755b8027e383c_w640_q70.webp",
      "contributions": "1. Identifies and empirically demonstrates a critical vulnerability in LLMs: their inability to understand user intent and context, which allows safety mechanisms to be circumvented. 2. Evaluates multiple state-of-the-art LLMs (ChatGPT, Claude, Gemini, DeepSeek) and shows that exploitation techniques like emotional framing and progressive revelation are effective, and that reasoning capabilities can amplify this risk. 3. Proposes a paradigmatic shift in AI safety design, arguing for contextual understanding and intent recognition to be core capabilities rather than post-hoc protective mechanisms.",
      "summary": "This paper identifies a fundamental vulnerability in Large Language Models (LLMs): their lack of contextual understanding and intent recognition, which allows safety mechanisms to be systematically bypassed. The authors empirically evaluate several LLMs, showing they can be exploited through techniques like emotional framing, and find that reasoning capabilities often worsen the problem. They conclude that a paradigm shift is needed to build intent recognition directly into LLM architectures for safety.",
      "mindmap": "graph LR\n    A[Beyond Context: Large Language Models Failure to Grasp Users Intent] --> B[核心问题/Problem: LLMs缺乏上下文和意图理解能力/LLMs lack contextual understanding & intent recognition]\n    A --> C[主要方法/Method: 对多种LLM进行经验性评估/Empirical evaluation of multiple LLMs]\n    A --> D[关键结果/Results: 安全机制可被系统规避，需范式转变/Safety mechanisms can be systematically circumvented, requiring a paradigm shift]\n    B --> E[导致可利用的漏洞/Creates exploitable vulnerabilities]\n    C --> F[使用情感框架、渐进揭示等技术/Using emotional framing, progressive revelation, etc.]\n    D --> G[Claude Opus 4.1部分例外，推理能力加剧风险/Claude Opus 4.1 partial exception, reasoning amplifies risk]"
    },
    {
      "title": "A Real-World Evaluation of LLM Medication Safety Reviews in NHS Primary Care",
      "authors": "Oliver Normand, Esther Borsi, Mitch Fruin, Lauren E Walker, Jamie Heagerty, Chris C. Holmes, Anthony J Avery, Iain E Buchan, Harry Coppock",
      "institution": "i.AI (Department for Science, Innovation, and Technology), University of Liverpool, University of Oxford, University of Nottingham, Imperial College London",
      "link": "https://arxiv.org/pdf/2512.21127",
      "code": null,
      "tags": [
        "clinical nlp",
        "medication safety review",
        "large language models",
        "real-world evaluation",
        "failure analysis",
        "electronic health records"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a25d52747ed1a867914e2ab484a381e6c4f16c161178ce43bc0d582517885647_w640_q70.webp",
      "contributions": "1. Conducted the first real-world evaluation of an LLM-based medication safety review system on a large-scale NHS primary care dataset. 2. Performed a detailed failure analysis, identifying five primary patterns of LLM reasoning failures in clinical contexts (e.g., overconfidence, lack of contextual adaptation). 3. Provided a public dataset of 45 detailed clinical vignettes that comprehensively document all identified failure cases for further study.",
      "summary": "This paper evaluates the performance of a large language model (LLM) system for medication safety reviews using real NHS primary care data. The study found that while the LLM was highly sensitive in detecting issues, it correctly identified all issues and interventions in less than half of the patients, with failures primarily stemming from contextual reasoning errors rather than a lack of medical knowledge. The work highlights critical shortcomings in LLM reasoning for clinical deployment and calls for more rigorous, real-world evaluations.",
      "mindmap": "graph LR\n        A[A Real-World Evaluation of LLM Medication Safety Reviews in NHS Primary Care] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs缺乏真实临床评估/LLMs lack real clinical evaluation]\n        C --> C1[回顾性研究 & 专家评审/Retrospective study & Expert review]\n        D --> D1[高敏感度但低完全正确率/High sensitivity but low perfect accuracy]\n        D --> D2[失败源于情境推理/Failures from contextual reasoning]"
    },
    {
      "title": "AutoBaxBuilder: Bootstrapping Code Security Benchmarking",
      "authors": "Tobias von Arx, Niels Mündler, Mark Vero, Maximilian Baader, Martin Vechev",
      "institution": "ETH Zurich, Snyk, INSAIT (Sofia University \"St. Kliment Ohridski\")",
      "link": "https://arxiv.org/pdf/2512.21132",
      "code": "https://github.com/eth-sri/autobaxbuilder",
      "tags": [
        "code security evaluation",
        "automated benchmarking",
        "LLM-generated code",
        "security vulnerabilities",
        "exploit generation",
        "plausibility checks"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/385abd6729afb970eba2217cc3d408efe70ab80f9d7aa0cbe7c2e0254f48b74c_w640_q70.webp",
      "contributions": "1. Introduces AutoBaxBuilder, a framework for generating code security benchmarking tasks and tests from scratch, addressing the limitations of manual benchmarks. 2. Proposes a robust pipeline with fine-grained plausibility checks that leverages LLMs to construct functionality tests and end-to-end security exploits. 3. Releases AutoBaxBench, a new benchmark of generated tasks, and demonstrates the framework's efficiency (under 2 hours and $10 per task) and quality through comparison with human-crafted tasks.",
      "summary": "The paper presents AutoBaxBuilder, a framework that automatically generates tasks and tests for benchmarking the security of code produced by large language models (LLMs). It uses an LLM-powered pipeline to create functional tests and security exploits, ensuring benchmark quality and scalability. The authors show the method is efficient and release a new benchmark, AutoBaxBench, to evaluate LLM security capabilities.",
      "mindmap": "graph LR\n    A[AutoBaxBuilder] --> B[核心问题/Problem: Manual security benchmarks are insufficient]\n    A --> C[主要方法/Method: Auto-generate tasks & tests with LLM pipeline]\n    A --> D[关键结果/Results: New benchmark, low cost, under 2 hours/task]"
    },
    {
      "title": "MODE: Multi-Objective Adaptive Coreset Selection",
      "authors": "Tanmoy Mukherjee, Pierre Marquis, Zied Bouraoui",
      "institution": "CRIL, Université d'Artois",
      "link": "https://arxiv.org/pdf/2512.21152",
      "code": null,
      "tags": [
        "others",
        "coreset selection",
        "submodular maximization",
        "data efficiency",
        "adaptive weighting",
        "multi-objective optimization"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8cefebbb0215d55d5050eb92783788b0acf7386684074cdf20b76685dfef159_w640_q70.webp",
      "contributions": "1. Proposes MODE, a dynamic framework that adaptively combines multiple coreset selection strategies based on their real-time contribution to model performance across different training phases. 2. Provides theoretical guarantees, achieving a (1-1/e)-approximation for the coreset selection problem with O(n log n) complexity and convergence bounds for strategy weights. 3. Demonstrates practical benefits including reduced memory requirements and provides interpretable insights into the evolution of data utility during training.",
      "summary": "The paper addresses the challenge of selecting small, representative data subsets (coresets) for efficient deep learning by proposing MODE, a framework that dynamically adapts selection criteria (like class balance, diversity, and uncertainty) to different training phases. It shows that MODE achieves strong theoretical approximation guarantees and competitive model accuracy while reducing computational and memory costs.",
      "mindmap": "graph LR\n    A[MODE: Multi-Objective Adaptive Coreset Selection] --> B[核心问题/Problem: Static coreset selection methods cannot adapt to changing data utility during training.]\n    A --> C[主要方法/Method: Dynamic, multi-objective framework that adaptively weights selection strategies based on training phase.]\n    A --> D[关键结果/Results: (1-1/e)-approximation, O(n log n) complexity, reduced memory, interpretable insights.]"
    },
    {
      "title": "TGC-Net: A Structure-Aware and Semantically-Aligned Framework for Text-Guided Medical Image Segmentation",
      "authors": "Gaoren Lin, Huangxuan Zhao, Yuan Xiong, Lefei Zhang, Bo Du, Wentao Zhu",
      "institution": "Wuhan University (Inferred from authors Gaoren Lin, Lefei Zhang, Bo Du, Wentao Zhu, who are known to be affiliated with Wuhan University. Huangxuan Zhao and Yuan Xiong are likely from the same group.)",
      "link": "https://arxiv.org/pdf/2512.21135",
      "code": null,
      "tags": [
        "medical image segmentation",
        "CLIP",
        "multimodal fusion",
        "parameter-efficient fine-tuning",
        "vision-language alignment",
        "anatomical structure"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b11d6061b6a08f8b03b2395e16fc0847c1b68ab4e388d93a886ee875211fcf44_w640_q70.webp",
      "contributions": "1. Proposes a Semantic-Structural Synergy Encoder (SSE) that augments CLIP's ViT with a CNN branch to preserve fine-grained anatomical structures. 2. Introduces a Domain-Augmented Text Encoder (DATE) that injects medical knowledge from large language models to better model complex clinical descriptions. 3. Designs a Vision-Language Calibration Module (VLCM) to refine cross-modal correspondence in a unified feature space, addressing domain-specific semantic misalignment.",
      "summary": "The paper proposes TGC-Net, a parameter-efficient CLIP-based framework for text-guided medical image segmentation. It addresses CLIP's limitations in medical imaging by introducing modules for structural refinement, medical knowledge injection, and cross-modal calibration. Experiments on five datasets show state-of-the-art performance with fewer trainable parameters.",
      "mindmap": "graph LR\n        A[TGC-Net: Text-Guided Medical Image Segmentation<br>文本引导的医学图像分割] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n    \n        B --> B1[CLIP在医学领域应用受限<br>CLIP Limitations in Medical Domain]\n        B1 --> B2[结构细节丢失<br>Loss of Fine-grained Structure]\n        B1 --> B3[复杂文本建模不足<br>Inadequate Text Modeling]\n        B1 --> B4[领域语义未对齐<br>Domain Semantic Misalignment]\n    \n        C --> C1[语义-结构协同编码器 SSE<br>Semantic-Structural Synergy Encoder]\n        C --> C2[领域增强文本编码器 DATE<br>Domain-Augmented Text Encoder]\n        C --> C3[视觉-语言校准模块 VLCM<br>Vision-Language Calibration Module]\n    \n        D --> D1[在5个数据集上SOTA<br>SOTA on 5 Datasets]\n        D --> D2[参数高效<br>Parameter-Efficient]\n        D --> D3[Dice分数显著提升<br>Notable Dice Gains]"
    },
    {
      "title": "BALLAST: Bandit-Assisted Learning for Latency-Aware Stable Timeouts in Raft",
      "authors": "Qizhi Wang",
      "institution": "PingCAP, Data & AI-Innovation Lab",
      "link": "https://arxiv.org/pdf/2512.21165",
      "code": null,
      "tags": [
        "distributed consensus",
        "Raft",
        "election timeout",
        "contextual bandits",
        "LinUCB",
        "fault tolerance"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75bff5f2f039d6eaeb1861fcd564ebda78e1b3bd0f91a85b3fc977c335d273e6_w640_q70.webp",
      "contributions": "1. BALLAST, a lightweight contextual-bandit framework for Raft election timeouts with safe exploration and non-stationary adaptation. 2. A reproducible evaluation methodology (discrete-event simulation, fault injection, protocol-level logging, CI-based aggregation) to study election stability under tail latency and recovery turbulence. 3. Demonstration that BALLAST substantially reduces recovery time and unwritable time compared to standard heuristics in challenging WAN regimes.",
      "summary": "This paper addresses the problem of leader-election instability in the Raft consensus protocol under variable network conditions like long-tail latency. It proposes BALLAST, a method that uses online linear contextual bandits to adaptively select election timeouts, augmented with safe exploration. The evaluation shows that BALLAST significantly improves recovery performance in unstable WAN environments while remaining competitive in stable settings.",
      "mindmap": "graph LR\n    A[BALLAST: Bandit-Assisted Learning for Latency-Aware Stable Timeouts in Raft] --> B(核心问题/Problem: Brittle randomized timeouts under long-tail latency & jitter)\n    A --> C(主要方法/Method: Lightweight online adaptation with contextual bandits & safe exploration)\n    A --> D(关键结果/Results: Reduces recovery/unwritable time in WAN, competitive in stable settings)"
    },
    {
      "title": "Schrödinger's Navigator: Imagining an Ensemble of Futures for Zero-Shot Object Navigation",
      "authors": "Yu He, Da Huang, Zhenyang Liu, Zixiao Gu, Qiang Sun, Guangnan Ye, Yanwei Fu",
      "institution": "Fudan University, Shanghai Jiao Tong University, Shanghai University of International Business and Economics, Shanghai Innovation Institute",
      "link": "https://arxiv.org/pdf/2512.21201",
      "code": "https://heyu322.github.io/Schrodinger-Navigator.github.io/",
      "tags": [
        "robot navigation",
        "zero-shot object navigation",
        "trajectory-conditioned 3D imagination",
        "occlusion-aware planning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34e56028ea40f6f3b4a9150683288695e8b7fd2724c676c4f7f56f07367b4fb3_w640_q70.webp",
      "contributions": "1. Proposed Schrödinger's Navigator, a novel navigation framework that models unobserved space as an ensemble of plausible future worlds to handle uncertainty. 2. Introduced a trajectory-conditioned 3D world model that imagines future observations along candidate paths to see beyond occlusions and anticipate risks. 3. Developed a method to fuse imagined 3D observations into a navigation map to update a value map, guiding the policy toward safer, less-occluded routes for better object tracking.",
      "summary": "The paper addresses the challenge of zero-shot object navigation in cluttered environments with occlusions and moving targets. It proposes Schrödinger's Navigator, a framework that samples candidate trajectories and uses a 3D imagination model to predict future observations, enabling the robot to plan safer paths and locate hidden objects. Experiments on a quadruped robot show the method outperforms baselines in success rate and localization in occlusion-heavy settings.",
      "mindmap": "graph LR\n        A[Schrödinger's Navigator] --> B[核心问题/Problem: ZSON struggles with occlusions & uncertainty]\n        A --> C[主要方法/Method: Trajectory-conditioned 3D imagination of futures]\n        A --> D[关键结果/Results: Outperforms baselines on real robot]"
    },
    {
      "title": "SpidR-Adapt: A Universal Speech Representation Model for Few-Shot Adaptation",
      "authors": "Mahi Luthra, Jiayi Shen, Maxime Poli, Angelo Ortiz, Yosuke Higuchi, Youssef Benchekroun, Martin Gleize, Charles-Eric Saint-James, Dongyan Lin, Phillip Rust, Angel Villar, Surya Parimi, Vanessa Stark, Rashel Moritz, Juan Pino, Yann LeCun, Emmanuel Dupoux",
      "institution": "Meta AI, ENS-PSL, EHESS, CNRS",
      "link": "https://arxiv.org/pdf/2512.21204",
      "code": "https://github.com/facebookresearch/spidr-adapt",
      "tags": [
        "speech representation learning",
        "meta-learning",
        "bi-level optimization",
        "few-shot adaptation",
        "self-supervised learning",
        "speech representation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff9692c36cbda26291fde2551256e229a90f6eb51f087d833a2d84cb4b10925b_w640_q70.webp",
      "contributions": "1. Introduces the Multi-task Adaptive Pre-training (MAdaPT) protocol, framing few-shot speech representation learning as a bi-level optimization meta-learning problem. 2. Proposes a novel First-Order Bi-Level Optimization (FOBLO) heuristic to enable scalable meta-training by avoiding heavy computation costs. 3. Stabilizes meta-training with a robust initialization technique using interleaved supervision that alternates between self-supervised and supervised objectives.",
      "summary": "This paper introduces SpidR-Adapt, a method for rapid adaptation of speech representation models to new languages using minimal unlabeled data. It formulates the problem as meta-learning with a bi-level optimization framework (MAdaPT), proposes an efficient solver (FOBLO), and uses interleaved supervision for stable training. The model achieves significant gains in phonemic discrimination and language modeling after training on less than 1 hour of target-language audio, demonstrating over 100x greater data efficiency than standard methods.",
      "mindmap": "graph LR\n        A[SpidR-Adapt] --> B[核心问题/Problem: 数据效率差距/Data-Efficiency Gap]\n        A --> C[主要方法/Method: 元学习与双层优化/Meta-Learning & Bi-Level Optimization]\n        A --> D[关键结果/Results: 100倍数据效率/100x Data Efficiency]\n        B --> B1[婴儿高效 vs. 模型低效/Infant Efficiency vs. Model Inefficiency]\n        C --> C1[MAdaPT协议/MAdaPT Protocol]\n        C --> C2[FOBLO优化/FOBLO Optimization]\n        C --> C3[交错监督/Interleaved Supervision]\n        D --> D1[<1h音频/<1h Audio]\n        D --> D2[音素可辨性提升/Improved Phonemic Discriminability]"
    },
    {
      "title": "RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic",
      "authors": "Le Wang, Zonghao Ying, Xiao Yang, Quanchen Zou, Zhenfei Yin, Tianlin Li, Jian Yang, Yaodong Yang, Aishan Liu, Xianglong Liu",
      "institution": "Beihang University, Beijing University of Posts and Telecommunications, 360 AI Security Lab, The University of Sydney, Nanyang Technological University, Peking University",
      "link": "https://arxiv.org/pdf/2512.21220",
      "code": null,
      "tags": [
        "agent system",
        "runtime safety guardrail",
        "executable safety logic",
        "hybrid reasoning",
        "temporal safety predicate",
        "context-aware safety predicate"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/adb68be6c6803ce76bf0036925bc1f629db0f2d1ae9be491b5ab0a450b37d1e5_w640_q70.webp",
      "contributions": "1. Proposes RoboSafe, a hybrid reasoning runtime safeguard for embodied agents using executable predicate-based safety logic. 2. Introduces a Backward Reflective Reasoning module to infer temporal safety predicates from recent trajectories and trigger replanning. 3. Introduces a Forward Predictive Reasoning module to anticipate risks by generating context-aware safety predicates from long-term memory and observations.",
      "summary": "The paper addresses the vulnerability of vision-language model-driven embodied agents to hazardous instructions in dynamic environments. It proposes RoboSafe, a runtime safety system that uses hybrid reasoning with backward reflection and forward prediction to generate executable safety logic. Experiments show RoboSafe significantly reduces hazardous actions while maintaining task performance, and its practicality is validated on physical robots.",
      "mindmap": "graph LR\n        A[RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic] --> B[核心问题/Problem: Embodied agents vulnerable to hazardous instructions in dynamic environments]\n        A --> C[主要方法/Method: Hybrid reasoning runtime safeguard with Backward Reflective & Forward Predictive modules]\n        A --> D[关键结果/Results: Reduces hazardous actions (-36.8%), maintains task performance, validated on physical robots]"
    },
    {
      "title": "Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval",
      "authors": "Dao Sy Duy Minh, Huynh Trung Kiet, Nguyen Lam Phu Quy, Phu-Hoa Pham, Tran Chi Nguyen",
      "institution": "University of Science - VNUHCM",
      "link": "https://arxiv.org/pdf/2512.21221",
      "code": "https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval",
      "tags": [
        "image-text retrieval",
        "event-centric entity extraction",
        "BM25",
        "BEiT-3",
        "two-stage retrieval"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3fccaf1dfde41ddfe9c023d8a1f41a9f87c4a0899f25d8a475702d3f368a129_w640_q70.webp",
      "contributions": "1. Proposes a lightweight two-stage retrieval pipeline for event-based image retrieval. 2. Leverages event-centric entity extraction to incorporate temporal and contextual signals for efficient candidate filtering. 3. Combines BM25-based filtering with BEiT-3 reranking to achieve high accuracy on the OpenEvents benchmark.",
      "summary": "This paper addresses the challenge of retrieving images from natural language descriptions in complex, real-world scenarios. It proposes a two-stage method that first filters candidates using BM25 on extracted event entities, then reranks them with a BEiT-3 model. The approach significantly outperforms prior baselines on the OpenEvents benchmark, demonstrating the effectiveness of combining lightweight entity guidance with deep multimodal modeling.",
      "mindmap": "graph LR\n    A[Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval] --> B[核心问题/Problem: Real-world image-text retrieval is challenging due to vague queries and scalability needs.]\n    A --> C[主要方法/Method: Two-stage pipeline with event-centric entity extraction, BM25 filtering, and BEiT-3 reranking.]\n    A --> D[关键结果/Results: Achieves high mean average precision (0.559) on OpenEvents v1, outperforming baselines.]"
    },
    {
      "title": "Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking",
      "authors": "Yifan Huang, Xiaojun Jia, Wenbo Guo, Yuqiang Sun, Yihao Huang, Chong Wang, Yang Liu",
      "institution": "Nanyang Technological University, National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.21236",
      "code": null,
      "tags": [
        "llm security",
        "jailbreaking",
        "malicious code generation",
        "prompt engineering",
        "time-division selection",
        "security alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8055c0aba333e58d26f29d81acab1f88f570f09122f7fafd38ac1c952dad67b1_w640_q70.webp",
      "contributions": "1. Proposes SPELL, a novel testing framework specifically designed to evaluate security alignment weaknesses in LLMs for malicious code generation. 2. Introduces a time-division selection strategy to systematically construct jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset. 3. Conducts extensive evaluation across multiple advanced code models and real-world tools, revealing significant security gaps and providing insights for improving AI safety.",
      "summary": "The paper addresses the security risk of LLMs being exploited to generate malicious code, a gap in existing jailbreaking research. It proposes the SPELL framework, which uses a time-division strategy to construct effective jailbreaking prompts. The evaluation shows high attack success rates across several models, revealing critical vulnerabilities in current AI safety alignments for code generation.",
      "mindmap": "graph LR\n        A[SPELL: Sentence Pairing Exploration for LLM Limitation-breaking] --> B[核心问题/Problem: LLMs可能被用于生成恶意代码/LLMs can be exploited for malicious code generation]\n        A --> C[主要方法/Method: 基于时间划分选择的提示构建框架/Time-division selection prompt construction framework]\n        A --> D[关键结果/Results: 在多模型上实现高攻击成功率/High attack success rates across multiple models]"
    },
    {
      "title": "Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks",
      "authors": "Xinjie Xu, Shuyu Cheng, Dongwei Xu, Qi Xuan, Chen Ma",
      "institution": "Zhejiang University of Technology, Binjiang Institute of Artificial Intelligence, ZJUT, JQ Investments",
      "link": "https://arxiv.org/pdf/2512.21241",
      "code": "https://github.com/machanic/hard_label_attacks",
      "tags": [
        "adversarial attacks",
        "hard-label black-box attacks",
        "query efficiency",
        "ray search optimization",
        "Nesterov's Accelerated Gradient",
        "momentum-based optimization"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/302b574932ba227c13854e5c9c2cab3d7cf8f1ed29ee145fbc73062632304cd4_w640_q70.webp",
      "contributions": "1. Proposed ARS-OPT, a momentum-based algorithm inspired by Nesterov's Accelerated Gradient to accelerate the convergence of ray search in hard-label attacks. 2. Introduced PARS-OPT, which further enhances ARS-OPT by incorporating surrogate-model priors into the gradient estimation. 3. Provided theoretical convergence guarantees for the proposed methods and demonstrated superior query efficiency over 13 state-of-the-art approaches on ImageNet and CIFAR-10.",
      "summary": "This paper addresses the high query cost of hard-label black-box adversarial attacks by optimizing ray search. The authors propose ARS-OPT, a momentum-based algorithm, and its enhanced version PARS-OPT, which uses surrogate-model priors, to accelerate convergence. Experiments show the methods outperform 13 existing approaches in query efficiency on standard datasets.",
      "mindmap": "graph LR\n    A[Improving the Convergence Rate of Ray Search Optimization<br>改进射线搜索优化的收敛率] --> B[核心问题/Problem<br>Hard-label攻击查询成本高<br>High query cost in hard-label attacks]\n    A --> C[主要方法/Method<br>提出ARS-OPT & PARS-OPT<br>Propose ARS-OPT & PARS-OPT]\n    A --> D[关键结果/Results<br>超越13种SOTA方法<br>Outperforms 13 SOTA methods]"
    },
    {
      "title": "LookPlanGraph: Embodied Instruction Following Method with VLM Graph Augmentation",
      "authors": "Anatoly O. Onishchenko, Alexey K. Kovalev, Aleksandr I. Panov",
      "institution": "MIRAI, Cognitive AI Systems Lab",
      "link": "https://arxiv.org/pdf/2512.21243",
      "code": "https://lookplangraph.github.io/",
      "tags": [
        "embodied ai",
        "scene graph",
        "vision language model",
        "dynamic planning",
        "memory graph",
        "graph augmentation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39706723670e257f6d0916c7c37badacde760a1f6d3061d011d8c22fa4f29bea_w640_q70.webp",
      "contributions": "1. Proposes LookPlanGraph, a method for embodied instruction following that dynamically updates a scene graph during execution using a Vision Language Model to verify object priors and discover new entities. 2. Introduces the GraSIF (Graph Scenes for Instruction Following) dataset with an automated validation framework, comprising 514 tasks from existing benchmarks. 3. Demonstrates superior performance over static scene graph methods in simulated environments with changed object positions and shows practical applicability in real-world experiments.",
      "summary": "The paper addresses the problem of LLM-based embodied agents failing in dynamic environments due to reliance on pre-built, static scene graphs. It proposes LookPlanGraph, a method that continuously augments a memory graph with real-time visual observations from a VLM to verify and discover objects during plan execution. Experiments show it outperforms static graph methods in simulated and real-world settings, and a new dataset (GraSIF) is introduced for evaluation.",
      "mindmap": "graph LR\n    A[LookPlanGraph] --> B[核心问题/Problem: Static scene graphs fail in dynamic environments];\n    A --> C[主要方法/Method: Dynamic graph update via VLM observation];\n    A --> D[关键结果/Results: Outperforms static methods, new GraSIF dataset];"
    },
    {
      "title": "Learning Factors in AI-Augmented Education: A Comparative Study of Middle and High School Students",
      "authors": "Gaia Ebli, Bianca Raimondi, Maurizio Gabbrielli",
      "institution": "University of Bologna",
      "link": "https://arxiv.org/pdf/2512.21246",
      "code": null,
      "tags": [
        "educational technology",
        "learning analytics",
        "correlation analysis",
        "text mining",
        "student perceptions",
        "human-ai interaction"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/37485735380aa9bf03e242b5a0fe4f8958c120a691a693af44376fb7f27c2b0b_w640_q70.webp",
      "contributions": "1. Investigated the interrelationships of four key learning factors (experience, clarity, comfort, motivation) in AI-augmented education, a gap in prior research. 2. Revealed a developmental moderator by comparing middle and high school students, finding holistic vs. differentiated evaluation patterns between age groups. 3. Established a foundation for age-specific AI integration strategies by showing perception dimensions actively mediate learning and their structure varies with developmental stage.",
      "summary": "This study investigates how key learning factors relate to each other in AI-augmented programming education for middle and high school students. Using a multimethod analysis combining correlation analysis and text mining on classroom data, it finds that middle school students evaluate AI tools holistically, while high school students assess different factors independently. The conclusion is that the structure of student perceptions is moderated by developmental stage, which should inform age-appropriate AI integration strategies.",
      "mindmap": "graph LR\n    A[论文标题: Learning Factors in AI-Augmented Education<br>Title: Learning Factors in AI-Augmented Education] --> B(核心问题/Problem: How do learning factor relationships vary by age in AI education?<br>核心问题/Problem: 学习因素关系在AI教育中如何随年龄变化？)\n    A --> C(主要方法/Method: Multimethod quantitative analysis (correlation & text mining)<br>主要方法/Method: 多方法定量分析（相关性与文本挖掘）)\n    A --> D(关键结果/Results: Middle school: holistic evaluation; High school: differentiated evaluation<br>关键结果/Results: 初中生: 整体性评估; 高中生: 差异性评估)"
    },
    {
      "title": "SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance",
      "authors": "Divij Dudeja, Mayukha Pal",
      "institution": "ABB Ability Innovation Center, Indian Institute of Information Technology, Nagpur",
      "link": "https://arxiv.org/pdf/2512.21280",
      "code": null,
      "tags": [
        "document question answering",
        "Tree-LSTM",
        "Memory Augmented Neural Network (MANN)",
        "Retrieval Augmented Generation (RAG)",
        "Parameter Efficiency",
        "Fact Extraction"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fe5f40637f711007d6bb6875182fa80072536380614c5e93c7c4f5cf8dc2232_w640_q70.webp",
      "contributions": "1. Introduces a hierarchical, syntax-aware fact extractor (Grammarian Tree-LSTM) to parse engineering manuals into structured subject-relation-object triples., 2. Proposes a compact, indexed memory system (MANN) to store and retrieve extracted facts as vectors, enabling efficient knowledge access., 3. Designs a dual-mode inference system combining a fast path for known documents and a dynamic RAG-assisted path for new uploads, reducing hallucinations.",
      "summary": "The paper addresses the challenge of accurately answering questions from dense engineering manuals, where standard small language models fail. It proposes SMART, a structured model that hierarchically extracts facts, stores them in an indexed memory, and uses a transformer to generate answers from retrieved facts. The result is a parameter-efficient model that achieves higher accuracy with fewer parameters and reduced hallucinations compared to baselines like GPT-2.",
      "mindmap": "graph LR\n    A[SMART SLM] --> B[核心问题/Problem: 工程手册难以阅读，现有小模型处理为扁平token流，导致错误答案/Engineering manuals are hard to read; flat token processing leads to incorrect answers]\n    A --> C[主要方法/Method: 分层处理：语法感知事实提取器 + 索引记忆(MANN) + 6层Transformer/Hierarchical processing: Syntax-aware fact extractor + Indexed memory (MANN) + 6-layer Transformer]\n    A --> D[关键结果/Results: 参数减少64-69%，准确率提升21.3%，减少幻觉/64-69% fewer parameters, 21.3% higher accuracy, reduced hallucinations]"
    },
    {
      "title": "Model Merging via Multi-Teacher Knowledge Distillation",
      "authors": "Seyed Arshan Dalili, Mehrdad Mahdavi",
      "institution": "The Pennsylvania State University",
      "link": "https://arxiv.org/pdf/2512.21288",
      "code": "https://github.com/arshandalili/SAMerging",
      "tags": [
        "model merging",
        "model merging",
        "knowledge distillation",
        "PAC-Bayes",
        "sharpness-aware minimization",
        "multi-task learning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1edfb41aaef41e719d5724fa70ca9022ddcf1e1c683791b3bd1d929286795c62_w640_q70.webp",
      "contributions": "1. Establishes a novel flatness-aware PAC-Bayes generalization bound for model merging, introducing a \"cross-task heterogeneity\" term. 2. Frames model merging as multi-teacher knowledge distillation on scarce unlabeled data, showing minimizing student-teacher KL divergence tightens the risk bound. 3. Proposes SAMerging, a method that operationalizes the objective using Sharpness-Aware Minimization (SAM) to find flat minima.",
      "summary": "This paper addresses the lack of theoretical understanding in model merging by framing it as multi-teacher knowledge distillation and deriving a PAC-Bayes generalization bound. It proposes SAMerging, a method that uses Sharpness-Aware Minimization to optimize the merging process based on this theory. The method achieves state-of-the-art performance on vision and NLP benchmarks with high data efficiency.",
      "mindmap": "graph LR\n    A[Model Merging via Multi-Teacher Knowledge Distillation] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[缺乏理论保证/Lack of Theoretical Guarantees]\n    B --> B2[启发式方法不稳定/Heuristic Methods are Brittle]\n    C --> C1[理论: 平坦性感知PAC-Bayes边界/Theory: Flatness-aware PAC-Bayes Bound]\n    C --> C2[框架: 多教师知识蒸馏/Framework: Multi-Teacher Knowledge Distillation]\n    C --> C3[方法: SAMerging/Method: SAMerging]\n    D --> D1[新SOTA/New SOTA]\n    D --> D2[高数据效率/High Data Efficiency]"
    },
    {
      "title": "Measuring all the noises of LLM Evals",
      "authors": "Sida Wang",
      "institution": "FAIR at Meta",
      "link": "https://arxiv.org/pdf/2512.21326",
      "code": null,
      "tags": [
        "llm inference",
        "LLM evaluation",
        "statistical noise",
        "paired analysis",
        "prediction variance",
        "data variance"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa15912febac5bc93aec8d1b8870feaf16ae89016c37e24c26550d053d396fec_w640_q70.webp",
      "contributions": "1. Clearly defines and measures three types of noise (prediction, data, total) in LLM evaluations using the law of total variance. 2. Proposes the \"all-pairs paired method\" to apply paired statistical analysis across all model pairs for increased statistical power. 3. Empirically reveals that total noise is predictable per evaluation and that prediction noise typically dominates data noise, enabling more effective significance testing.",
      "summary": "This paper addresses the challenge of statistical noise in Large Language Model (LLM) evaluations. It proposes an \"all-pairs paired method\" to measure prediction, data, and total noise across model pairs. The key findings are that each evaluation benchmark has a characteristic noise level and that reducing prediction noise through averaging can significantly improve the detection of performance differences.",
      "mindmap": "graph LR\n    A[Measuring all the noises of LLM Evals] --> B(核心问题/Problem: LLM评估中的统计噪声/Separating signal from noise in LLM evals)\n    A --> C(主要方法/Method: 全配对分析法/All-pairs paired method)\n    A --> D(关键结果/Results: 可预测的总噪声与主导的预测噪声/Predictable total noise & dominant prediction noise)"
    },
    {
      "title": "C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling",
      "authors": "Jin Qin, Zihan Liao, Ziyin Zhang, Hang Yu, Peng Di, Rui Wang",
      "institution": "Ant Group, Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.21332",
      "code": "https://github.com/codefuse-ai/CodeFuse-Embeddings",
      "tags": [
        "code retrieval",
        "Pooling by Multihead Attention (PMA)",
        "contrastive learning",
        "code embedding",
        "MTEB-Code",
        "Qwen-2.5-Coder"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f27c6e6ad01eacb3bd759d1aafa323cd3f72410efd901b1df691e709d8fbe3a4_w640_q70.webp",
      "contributions": "1. Proposes a Pooling by Multihead Attention (PMA) module to generate sequence embeddings from token embeddings, effectively utilizing the LLM's causal representations. 2. The PMA module aggregates information from all tokens in a sequence, overcoming the information bottleneck of traditional EOS-based sequence embeddings. 3. The approach supports flexible adaptation of embedding dimensions, serving as an alternative to Multi-Representation Learning (MRL).",
      "summary": "This paper introduces C2LLM, a family of code embedding models built on Qwen-2.5-Coder backbones. It proposes a novel Pooling by Multihead Attention (PMA) module to create better sequence embeddings for code retrieval. The models, trained on three million data points, achieve state-of-the-art performance on the MTEB-Code benchmark, with the 7B version ranking first overall.",
      "mindmap": "graph LR\n        A[C2LLM Technical Report] --> B[核心问题/Problem: 代码检索中的序列表示瓶颈/Sequence representation bottleneck in code retrieval]\n        A --> C[主要方法/Method: 自适应交叉注意力池化 (PMA) / Adaptive Cross-Attention Pooling (PMA)]\n        A --> D[关键结果/Results: 在MTEB-Code上SOTA / SOTA on MTEB-Code]"
    },
    {
      "title": "Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty",
      "authors": "Ziyu Chen, Xinbei Jiang, Peng Sun, Tao Lin",
      "institution": "Zhejiang University, Westlake University, University of Chicago",
      "link": "https://arxiv.org/pdf/2512.21336",
      "code": "https://github.com/LINs-lab/DenoisingEntropy",
      "tags": [
        "diffusion models",
        "Denoising Entropy",
        "Masked Diffusion Models",
        "decoding path optimization",
        "predictive uncertainty",
        "non-autoregressive generation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4480eb4fa3d14900373effb4e74dd207b42c650b50de1044a2cad8b4036e465f_w640_q70.webp",
      "contributions": "1. Formalized the problem of decoding path sensitivity in Masked Diffusion Models (MDMs) by introducing the concept of cumulative Path Uncertainty. 2. Proposed Denoising Entropy, a novel, computable metric to quantify predictive uncertainty along a generative path. 3. Developed two entropy-guided algorithms (post-hoc selection and real-time guidance) to optimize the decoding path and improve generation quality.",
      "summary": "The paper identifies that the flexible generation of Masked Diffusion Models (MDMs) leads to variable output quality due to the chosen decoding order. To address this, it introduces Denoising Entropy to measure path uncertainty and proposes two algorithms that use this metric to guide the decoding process. Experiments show these methods significantly improve generation accuracy on reasoning, planning, and code tasks, turning uncertainty into an advantage.",
      "mindmap": "graph LR\n        A[Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty<br/>通过量化不确定性优化掩码扩散模型的解码路径] --> B(核心问题/Problem: MDMs生成质量对解码顺序敏感<br/>MDM output quality is sensitive to decoding order)\n        A --> C(主要方法/Method: 提出去噪熵和路径优化算法<br/>Propose Denoising Entropy & path optimization algorithms)\n        A --> D(关键结果/Results: 熵引导方法提升生成质量<br/>Entropy-guided methods improve generation quality)"
    },
    {
      "title": "A Physics Informed Neural Network For Deriving MHD State Vectors From Global Active Regions Observations",
      "authors": "Subhamoy Chatterjee, Mausumi Dikpati",
      "institution": "Southwest Research Institute, High Altitude Observatory (NSF-NCAR)",
      "link": "https://arxiv.org/pdf/2512.20747",
      "code": null,
      "tags": [
        "astro-physics",
        "solar physics",
        "magnetohydrodynamics",
        "Physics-Informed Neural Network (PINN)",
        "MagnetoHydroDynamic Shallow-Water Tachocline (MHD-SWT)",
        "solar active regions (ARs)",
        "toroidal bands (toroids)",
        "state-vector reconstruction"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/64164e9d078622b42b01e54f9efaeb57ab61d047c881403541551b016e24827e_w640_q70.webp",
      "contributions": "1. Proposes PINNBARDS, a novel Physics-Informed Neural Network framework to derive the initial MHD state-vector for solar tachocline models from surface observations of active region distributions. 2. Demonstrates the method's ability to converge to physically consistent solutions that match observed toroidal band patterns, specifically using data from the Feb-14-2024 SDO/HMI synoptic map. 3. Explores the parameter space to constrain key physical properties, finding optimal agreement with observations for toroidal field strengths of 20–30 kG and a bandwidth of ~10 degrees, which is consistent with low-order longitudinal mode excitation.",
      "summary": "This paper addresses the challenge of initializing solar magnetohydrodynamic models for predicting flare-producing active regions, which requires a full state-vector not provided by surface observations. The authors develop PINNBARDS, a Physics-Informed Neural Network that uses observed toroidal band patterns and the governing MHD equations to reconstruct the necessary initial state-vector for the tachocline. Their analysis identifies optimal physical parameters (20-30 kG field strength) that best match observations, providing a novel pathway for weeks-ahead solar activity prediction.",
      "mindmap": "graph LR\n        A[PINNBARDS: 从全球活动区观测推导MHD状态向量 / PINNBARDS: Deriving MHD State Vectors From Global Active Regions Observations] --> B(核心问题/Problem: 表面磁图仅提供活动区分布的几何形状，无法提供初始化MHD模型所需的自洽状态向量 / Problem: Surface magnetograms only provide geometric shape of AR distribution, not the self-consistent state-vector needed to initialize MHD models.)\n        A --> C(主要方法/Method: 开发PINNBARDS，一个基于物理信息神经网络(PINN)的模拟器，使用观测到的环形带和MHD-SWT方程来推导初始状态向量 / Method: Develop PINNBARDS, a PINN-based simulator using observed toroids and MHD-SWT equations to derive the initial state-vector.)\n        A --> D(关键结果/Results: PINN收敛到物理一致解，与观测匹配；最佳参数为20-30 kG环形场和~10度带宽 / Results: PINN converges to physically consistent solutions matching observations; optimal parameters are 20-30 kG toroidal field and ~10 degree bandwidth.)"
    },
    {
      "title": "GenTSE: Enhancing Target Speaker Extraction via a Coarse-to-Fine Generative Language Model",
      "authors": "Haoyang Li, Xuyi Zhuang, Azmat Adnan, Ye Ni, Wei Rao, Shreyas Gopal, Eng Siong Chng",
      "institution": "Nanyang Technological University, Southeast University",
      "link": "https://arxiv.org/pdf/2512.20978",
      "code": null,
      "tags": [
        "speech separation",
        "target speaker extraction",
        "generative language model",
        "coarse-to-fine",
        "exposure bias",
        "direct preference optimization"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2e6714f10d4ca9cf7e6cc6ddc5eea2048c365e1e206f97988dcc13bab4d72ef_w640_q70.webp",
      "contributions": "1. Proposes GenTSE, a fully generative two-stage decoder-only language model architecture for target speaker extraction, separating coarse semantic token prediction from fine acoustic token generation. 2. Introduces a Frozen-LM Conditioning training strategy to mitigate exposure bias by conditioning models on their own past predictions from earlier checkpoints. 3. Employs Direct Preference Optimization to better align the model's outputs with human perceptual preferences.",
      "summary": "This paper introduces GenTSE, a novel generative language model approach for target speaker extraction that uses a two-stage, coarse-to-fine process to generate speech. The method addresses exposure bias with a specific training strategy and aligns outputs with human preferences using DPO. Experiments show it outperforms previous LM-based systems in speech quality, intelligibility, and speaker consistency.",
      "mindmap": "graph LR\n    A[GenTSE] --> B[核心问题/Problem: TSE generalization & fidelity];\n    A --> C[主要方法/Method: Two-stage generative LM, FLC, DPO];\n    A --> D[关键结果/Results: Surpasses prior LM-based systems];"
    },
    {
      "title": "PhononBench:A Large-Scale Phonon-Based Benchmark for Dynamical Stability in Crystal Generation",
      "authors": "Xiao-Qi Han, Ze-Feng Gao, Peng-Jie Guo, Zhong-Yi Lu",
      "institution": "Renmin University of China",
      "link": "https://arxiv.org/pdf/2512.21227",
      "code": "https://github.com/xqh19970407/PhononBench",
      "tags": [
        "materials informatics",
        "dynamical stability",
        "phonon spectrum",
        "crystal generation",
        "benchmark",
        "MatterSim"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5409c19ccb89ace0c03a71117cfd438b28def78d75777b331d87da44f49b7230_w640_q70.webp",
      "contributions": "1. Introduced PhononBench, the first large-scale benchmark for evaluating the dynamical stability of AI-generated crystal structures. 2. Leveraged the MatterSim interatomic potential to perform efficient, DFT-level phonon calculations on over 100k generated crystals, revealing a widespread deficiency in current models' ability to produce dynamically stable structures. 3. Identified and released a substantial dataset of 28,119 phonon-stable generated crystals, providing a valuable resource for future materials discovery.",
      "summary": "This paper introduces PhononBench, a benchmark that uses the MatterSim potential to efficiently evaluate the dynamical stability of AI-generated crystals. The analysis of over 100k structures from six leading models shows that current generative models perform poorly at ensuring dynamical stability, with an average success rate of only 25.83%. The work highlights a critical limitation in the field and provides a benchmark and a pool of stable candidate structures for future development.",
      "mindmap": "graph LR\n    A[PhononBench: 晶体生成中的动力学稳定性基准] --> B(核心问题/Problem: 现有AI晶体生成模型缺乏对动力学稳定性的大规模评估)\n    A --> C(主要方法/Method: 利用MatterSim势函数进行高通量声子计算)\n    A --> D(关键结果/Results: 模型平均稳定性仅25.83%, 识别出28,119个稳定结构)"
    },
    {
      "title": "Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks",
      "authors": "Ali Merali",
      "institution": "Yale University",
      "link": "https://arxiv.org/pdf/2512.21316",
      "code": null,
      "tags": [
        "large language models",
        "scaling laws",
        "economic productivity",
        "agentic workflows",
        "compute scaling",
        "algorithmic progress"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f148c34bb4d8aa66926afe66d00135fb826ae28f1253bfed833d9ff39c8b046d_w640_q70.webp",
      "contributions": "1. Derives empirical scaling laws linking LLM training compute to professional productivity gains. 2. Quantifies the relative contributions of increased compute (56%) versus algorithmic progress (44%) to annual productivity improvements. 3. Identifies a significant disparity in productivity gains between non-agentic analytical tasks and agentic workflows requiring tool use.",
      "summary": "This paper investigates the relationship between LLM capabilities and professional productivity through a preregistered experiment with over 500 professionals. It finds that each year of AI progress reduces task time by 8%, driven by both compute and algorithmic scaling, but gains are larger for analytical tasks than for agentic ones. The results suggest continued model scaling could significantly boost U.S. productivity over the next decade.",
      "mindmap": "graph LR\n    A[Scaling Laws for Economic Productivity<br/>经济生产力缩放定律] --> B(核心问题/Problem: LLM compute vs. professional productivity<br/>LLM计算与专业生产力的关系);\n    A --> C(主要方法/Method: Preregistered experiment with 500+ professionals using 13 LLMs<br/>使用13个LLM对500多名专业人员的预注册实验);\n    A --> D(关键结果/Results: 8% annual time reduction, 56% compute vs. 44% algorithm gains, larger gains for non-agentic tasks<br/>每年任务时间减少8%，56%源于计算，44%源于算法，非智能体任务收益更大);"
    },
    {
      "title": "QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning",
      "authors": "Sebastian Racedo, Brigitte Jaumard, Oscar Delgado, Meysam Masoudi",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19696",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b77d355579fa14e02c66f844a9c1cf1fbc3d68fee2d28b38fc709f013395b1a_w640_q70.webp",
      "contributions": "",
      "summary": "QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning",
      "mindmap": ""
    },
    {
      "title": "Automated Fault Detection in 5G Core Networks Using Large Language Models",
      "authors": "Parsa Hatami, Ahmadreza Majlesara, Ali Majlesi, Babak Hossein Khalaj",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19697",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51195e88b90e075513d8e30088f944c9008c4dee4bc84af09cdce6bb8a7b71e4_w640_q70.webp",
      "contributions": "",
      "summary": "Automated Fault Detection in 5G Core Networks Using Large Language Models",
      "mindmap": ""
    },
    {
      "title": "PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility",
      "authors": "Md Nahid Hasan Shuvo, Moinul Hossain",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19711",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d516fcc6c3de6b0e65c078e5e3f3dda23bfd77fbb9c5f4abfe2c509c2cb6dfe_w640_q70.webp",
      "contributions": "",
      "summary": "PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility",
      "mindmap": ""
    },
    {
      "title": "Large Language Models for EDA Cloud Job Resource and Lifetime Prediction",
      "authors": "Yuxuan Yin, Shengke Zhou, Yunjie Zhang, Ajay Mohindra, Boxun Xu, Peng Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19701",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebe0c6f8e6d98607a87a162a4a1cada21d732348d823658c9451d5ce5608a7d1_w640_q70.webp",
      "contributions": "",
      "summary": "Large Language Models for EDA Cloud Job Resource and Lifetime Prediction",
      "mindmap": ""
    },
    {
      "title": "Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data",
      "authors": "Behrooz Mamandipoor, Chun-Nan Hsu, Martin Krause, Ulrich H. Schmidt, Rodney A. Gabriel",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19716",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b80fac6c07719f0fdc3b2a60068a2f3820d61d75d5655632ad18fc7fbee5f80_w640_q70.webp",
      "contributions": "",
      "summary": "Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data",
      "mindmap": ""
    },
    {
      "title": "Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance",
      "authors": "James K Ruffle, Samia Mohinta, Guilherme Pombo, Asthik Biswas, Alan Campbell, Indran Davagnanam, David Doig, Ahmed Hamman, Harpreet Hyare, Farrah Jabeen, Emma Lim, Dermot Mallon, Stephanie Owen, Sophie Wilkinson, Sebastian Brandner, Parashkev Nachev",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19707",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp",
      "contributions": "",
      "summary": "Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance",
      "mindmap": ""
    },
    {
      "title": "Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference",
      "authors": "Zhan Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19717",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ee62945031af7f6dac3a6d51384974eec1f8f5db6dd103388502d84eb58bc6a_w640_q70.webp",
      "contributions": "",
      "summary": "Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference",
      "mindmap": ""
    },
    {
      "title": "Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries",
      "authors": "Zihao Lv, Siqi Ai, Yanbin Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19719",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6292853f8fb29c3648a6a9e7a018fcb02691dba13e4d6ce37a63f296f046554_w640_q70.webp",
      "contributions": "",
      "summary": "Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries",
      "mindmap": ""
    },
    {
      "title": "Tiny, On-Device Decision Makers with the MiniConv Library",
      "authors": "Carlos Purves",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19726",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fcebc0e7acd2aa33081184298763fb8df6f0a43f23fb341b0e84da9a69d1bd6_w640_q70.webp",
      "contributions": "",
      "summary": "Tiny, On-Device Decision Makers with the MiniConv Library",
      "mindmap": ""
    },
    {
      "title": "High-Performance Self-Supervised Learning by Joint Training of Flow Matching",
      "authors": "Kosuke Ukita, Tsuyoshi Okita",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19729",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/269f1eff8cf71b204b6147341b992a81faef6468f33e5edd7a5be137a0ac9100_w640_q70.webp",
      "contributions": "",
      "summary": "High-Performance Self-Supervised Learning by Joint Training of Flow Matching",
      "mindmap": ""
    },
    {
      "title": "Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach",
      "authors": "Clément Elliker, Jesse Read, Sonia Vanier, Albert Bifet",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19737",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37e9a570297730f5200e5c0dcac9576f29dc77d8856f607f480d2a083088332_w640_q70.webp",
      "contributions": "",
      "summary": "Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach",
      "mindmap": ""
    },
    {
      "title": "CoPHo: Classifier-guided Conditional Topology Generation with Persistent Homology",
      "authors": "Gongli Xi, Ye Tian, Mengyu Yang, Zhenyu Zhao, Yuchao Zhang, Xiangyang Gong, Xirong Que, Wendong Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19736",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68578352cc68ad1305abf54d27488dc8db7f857ff2484ef8acd9ab80b0db8641_w640_q70.webp",
      "contributions": "",
      "summary": "CoPHo: Classifier-guided Conditional Topology Generation with Persistent Homology",
      "mindmap": ""
    },
    {
      "title": "From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning",
      "authors": "Sasan Sharifipour, Constantino Álvarez Casado, Manuel Lage Cañellas, Miguel Bordallo López",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19743",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b9eb6359f294d9654c6f1fea215bc4726b236c77ba0b6790735d53dbad5ead_w640_q70.webp",
      "contributions": "",
      "summary": "From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning",
      "mindmap": ""
    },
    {
      "title": "How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts",
      "authors": "Sumin Park, Noseong Park",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19765",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/515767751abfd73b2b6370592d087c270228e210ccda8fa867a672db0ae07a01_w640_q70.webp",
      "contributions": "",
      "summary": "How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts",
      "mindmap": ""
    },
    {
      "title": "A K-Means, Ward and DBSCAN repeatability study",
      "authors": "Anthony Bertrand, Engelbert Mephu Nguifo, Violaine Antoine, David Hill",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19772",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b606a0690bd58fd61c6e296efa76193ecfe74e0fd82dcf2bd79d638111e3e1d1_w640_q70.webp",
      "contributions": "",
      "summary": "A K-Means, Ward and DBSCAN repeatability study",
      "mindmap": ""
    },
    {
      "title": "Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning",
      "authors": "Antonio Tarizzo, Mohammad Kazemi, Deniz Gündüz",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19777",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b386ba4532b788c41eccda5b3c48b9585db890467bbb5e150328901a4ad2208_w640_q70.webp",
      "contributions": "",
      "summary": "Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning",
      "mindmap": ""
    },
    {
      "title": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows",
      "authors": "Ivan Daunis",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19769",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e158baf642d33624c0967b1dcd509fbc3876a4bc52a539d4b6e7c800995b42_w640_q70.webp",
      "contributions": "",
      "summary": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows",
      "mindmap": ""
    },
    {
      "title": "Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models",
      "authors": "Wang Bin, Ao Yang, Kedan Li, Aofan Liu, Hui Li, Guibo Luo, Weixiang Huang, Yan Zhuang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19758",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45aa033e5d42a870c8059ab54cb6cefa331610516ad0bef063a9ce423cb132dc_w640_q70.webp",
      "contributions": "",
      "summary": "Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models",
      "mindmap": ""
    },
    {
      "title": "PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research",
      "authors": "Tingjia Miao, Jiawen Dai, Jingkun Liu, Jinxin Tan, Muhua Zhang, Wenkai Jin, Yuwen Du, Tian Jin, Xianghe Pang, Zexi Liu, Tu Guo, Zhengliang Zhang, Yunjie Huang, Shuo Chen, Rui Ye, Yuzhi Zhang, Linfeng Zhang, Kun Chen, Wei Wang, Weinan E, Siheng Chen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19799",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1922ac933b302c99f4a3c639911ffa3980ae43238fad1b247af369017413128_w640_q70.webp",
      "contributions": "",
      "summary": "PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research",
      "mindmap": ""
    },
    {
      "title": "UCCL-EP: Portable Expert-Parallel Communication",
      "authors": "Ziming Mao, Yihan Zhang, Chihan Cui, Kaichao You, Zhongjie Chen, Zhiying Xu, Scott Shenker, Costin Raiciu, Yang Zhou, Ion Stoica",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19849",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb2d143c0a9d64bd2c5bdf4142e8e3a096290fd8319372321c00c3c17d53b658_w640_q70.webp",
      "contributions": "",
      "summary": "UCCL-EP: Portable Expert-Parallel Communication",
      "mindmap": ""
    },
    {
      "title": "A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution",
      "authors": "Mahdi Mostajabdaveh, F. Sibel Salman, Walter J. Gutjahr",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19882",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81c6462c8b784a5ac97bed22a2eedfc4c0fbad0afad1bab0e0a9aab3730a1834_w640_q70.webp",
      "contributions": "",
      "summary": "A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution",
      "mindmap": ""
    },
    {
      "title": "HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data",
      "authors": "Shashi Kant Gupta, Arijeet Pramanik, Jerrin John Thomas, Regina Schwind, Lauren Wiener, Avi Raju, Jeremy Kornbluth, Yanshan Wang, Zhaohui Su, Hrituraj Singh",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19864",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e0cfa9ec043e8a27718dd14bb89bf3c4ceafb97fb48a8a0b61d661ec9d34b09_w640_q70.webp",
      "contributions": "",
      "summary": "HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data",
      "mindmap": ""
    },
    {
      "title": "Fine-Tuned In-Context Learners for Efficient Adaptation",
      "authors": "Jorg Bornschein, Clare Lyle, Yazhe Li, Amal Rannen-Triki, Xu Owen He, Razvan Pascanu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19879",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31980c4d9f6b1c6d6c1f0f41df293fd637d43c4ea2f2de5d26aa825310d8bdbc_w640_q70.webp",
      "contributions": "",
      "summary": "Fine-Tuned In-Context Learners for Efficient Adaptation",
      "mindmap": ""
    },
    {
      "title": "A Time-efficient Prioritised Scheduling Algorithm to Optimise Initial Flock Formation of Drones",
      "authors": "Sujan Warnakulasooriya, Andreas Willig, Xiaobing Wu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19914",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/188da8ba7b74e5b961c0e61a49776e60da92670b4dd0b522d0c74e156682ec49_w640_q70.webp",
      "contributions": "",
      "summary": "A Time-efficient Prioritised Scheduling Algorithm to Optimise Initial Flock Formation of Drones",
      "mindmap": ""
    },
    {
      "title": "Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning",
      "authors": "Jiayun Wu, Jiashuo Liu, Zhiyuan Zeng, Tianyang Zhan, Wenhao Huang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19920",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33255a480cb8654f8d9838cb7a634102f7086c3eaac9fb63148c10866248563a_w640_q70.webp",
      "contributions": "",
      "summary": "Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning",
      "mindmap": ""
    },
    {
      "title": "Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling",
      "authors": "Indranil Halder, Cengiz Pehlevan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19905",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1e6db0153f278bc11740f6ab7077ed6a29fff1f323057711a5dc1210d6e99fe_w640_q70.webp",
      "contributions": "",
      "summary": "Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling",
      "mindmap": ""
    },
    {
      "title": "Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra",
      "authors": "Maxime Lacour, Pu Ren, Rie Nakata, Nori Nakata, Michael Mahoney",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19909",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e8e80ac4736f89a1123273e8c6f77a605a941de3087891673a6d7728a3d0998_w640_q70.webp",
      "contributions": "",
      "summary": "Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra",
      "mindmap": ""
    },
    {
      "title": "Unified Brain Surface and Volume Registration",
      "authors": "S. Mazdak Abulnaga, Andrew Hoopes, Malte Hoffmann, Robin Magnet, Maks Ovsjanikov, Lilla Zöllei, John Guttag, Bruce Fischl, Adrian Dalca",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19928",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52472b7c53844ab7af247ff699ee1c659d2b3ff27e2e21ee8f187677824a5d8d_w640_q70.webp",
      "contributions": "",
      "summary": "Unified Brain Surface and Volume Registration",
      "mindmap": ""
    },
    {
      "title": "Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress",
      "authors": "Samruddhi Baviskar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19935",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f15b3890b1332bf926501d440f418e2e71c3b0c8c5b3dd19380d13e172c25ac_w640_q70.webp",
      "contributions": "",
      "summary": "Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress",
      "mindmap": ""
    },
    {
      "title": "Vehicle-centric Perception via Multimodal Structured Pre-training",
      "authors": "Wentao Wu, Xiao Wang, Chenglong Li, Jin Tang, Bin Luo",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19934",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25393280cf5e09ecc25c375a88de26bef6b6904fd90a6775cf7591ed8a615fe1_w640_q70.webp",
      "contributions": "",
      "summary": "Vehicle-centric Perception via Multimodal Structured Pre-training",
      "mindmap": ""
    },
    {
      "title": "Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs",
      "authors": "Eric Yeh, John Cadigan, Ran Chen, Dick Crouch, Melinda Gervasio, Dayne Freitag",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19937",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67e83c33b123e956d61ade807a7eb155837dc60f3e60e67f0209df1eb75d7639_w640_q70.webp",
      "contributions": "",
      "summary": "Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs",
      "mindmap": ""
    },
    {
      "title": "Block-Recurrent Dynamics in Vision Transformers",
      "authors": "Mozes Jacobs, Thomas Fel, Richard Hakim, Alessandra Brondetta, Demba Ba, T. Andy Keller",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19941",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e10f9b4ab6d210902b2c5092ebfe1fcc82dd7a3d2032bfc97fbfadd16867c2a_w640_q70.webp",
      "contributions": "",
      "summary": "Block-Recurrent Dynamics in Vision Transformers",
      "mindmap": ""
    },
    {
      "title": "How Much 3D Do Video Foundation Models Encode?",
      "authors": "Zixuan Huang, Xiang Li, Zhaoyang Lv, James M. Rehg",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19949",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b54fab192e555a908a0f7daf8d7992c85cd3241844d6a17c19d685c99c93dc5e_w640_q70.webp",
      "contributions": "",
      "summary": "How Much 3D Do Video Foundation Models Encode?",
      "mindmap": ""
    },
    {
      "title": "Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification",
      "authors": "Luciano Araujo Dourado Filho, Almir Moreira da Silva Neto, Rodrigo Pereira David, Rodrigo Tripodi Calumby",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19957",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/307d3e337ca6d53335e1861afc2551a5e05ba3baffbfb580ffc6378d16a74e2f_w640_q70.webp",
      "contributions": "",
      "summary": "Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification",
      "mindmap": ""
    },
    {
      "title": "FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification",
      "authors": "Luciano Araujo Dourado Filho, Rodrigo Tripodi Calumby",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19960",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbfda29c0b0fd29ef417a6aed2c9021c6a676577f450cbc925474212756dbba1_w640_q70.webp",
      "contributions": "",
      "summary": "FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification",
      "mindmap": ""
    },
    {
      "title": "Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?",
      "authors": "Zhe Yin, Xiaodong Gu, Beijun Shen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19980",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/612b57ba54262082ae033612387571cddc86ac826d14c6f5b1ba4c241011b3b9_w640_q70.webp",
      "contributions": "",
      "summary": "Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?",
      "mindmap": ""
    },
    {
      "title": "Schoenfeld's Anatomy of Mathematical Reasoning by Language Models",
      "authors": "Ming Li, Chenrui Fan, Yize Cheng, Soheil Feizi, Tianyi Zhou",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19995",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf100eeda1c44688829760003993b1a83478a2d2901a0f5a0b9914bc5ef7c3b0_w640_q70.webp",
      "contributions": "",
      "summary": "Schoenfeld's Anatomy of Mathematical Reasoning by Language Models",
      "mindmap": ""
    },
    {
      "title": "S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test",
      "authors": "Zhe Sun, Xueyuan Yang, Yujie Lu, Zhenliang Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19992",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a7f6951c4ebc6cf6c8bd633198ae7d4c6a7c8f1e0cd348aa9e6737966dfe600_w640_q70.webp",
      "contributions": "",
      "summary": "S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test",
      "mindmap": ""
    },
    {
      "title": "IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense",
      "authors": "Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20004",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea3f077bcaec1c639c8029881602d31bdf125a8cbefc2e15ec9ba3e07c126ee1_w640_q70.webp",
      "contributions": "",
      "summary": "IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense",
      "mindmap": ""
    },
    {
      "title": "DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics",
      "authors": "Yuan Gao, Zhenguo Dong, Xuelong Wang, Zhiqiang Wang, Yong Zhang, Shaofan Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20028",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a6ada3496efb972d8c3a130ea0af749449dc6804b758999852b9def0e9692a4_w640_q70.webp",
      "contributions": "",
      "summary": "DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics",
      "mindmap": ""
    },
    {
      "title": "Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting",
      "authors": "Sangoh Lee, Sangwoo Mo, Wook-Shin Han",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20014",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbb9757af838ced105aac295c936d5bf2fa52c5f79d162d34ed41c9c961ae9e0_w640_q70.webp",
      "contributions": "",
      "summary": "Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting",
      "mindmap": ""
    },
    {
      "title": "Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieva",
      "authors": "Nguyen Lam Phu Quy, Pham Phu Hoa, Tran Chi Nguyen, Dao Sy Duy Minh, Nguyen Hoang Minh Ngoc, Huynh Trung Kiet",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20042",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9fb136c3c44d734ccd03ee7608dfc92d3612b466bfffc82e1d2efdfd79e5f161_w640_q70.webp",
      "contributions": "",
      "summary": "Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieva",
      "mindmap": ""
    },
    {
      "title": "Learning Skills from Action-Free Videos",
      "authors": "Hung-Chieh Fang, Kuo-Han Hung, Chu-Rong Chen, Po-Jung Chou, Chun-Kai Yang, Po-Chen Ko, Yu-Chiang Wang, Yueh-Hua Wu, Min-Hung Chen, Shao-Hua Sun",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20052",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/def215474b82a6d04f6a6f79dc99c74e3b1159e34a80855d18649f29781a36fc_w640_q70.webp",
      "contributions": "",
      "summary": "Learning Skills from Action-Free Videos",
      "mindmap": ""
    },
    {
      "title": "An Optimal Policy for Learning Controllable Dynamics by Exploration",
      "authors": "Peter N. Loxley",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20053",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1955af7668fd6f7c26946b76a3cbf622271164ba70999a4181146562f156fbbc_w640_q70.webp",
      "contributions": "",
      "summary": "An Optimal Policy for Learning Controllable Dynamics by Exploration",
      "mindmap": ""
    },
    {
      "title": "Discovering Lie Groups with Flow Matching",
      "authors": "Jung Yeon Park, Yuxuan Chen, Floor Eijkelboom, Jan-Willem van de Meent, Lawson L.S. Wong, Robin Walters",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20043",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/806c459fa9197bda13199f58531fce983ef12854f6eb2e8acaaea33dfebd6a22_w640_q70.webp",
      "contributions": "",
      "summary": "Discovering Lie Groups with Flow Matching",
      "mindmap": ""
    },
    {
      "title": "Scaling Reinforcement Learning for Content Moderation with Large Language Models",
      "authors": "Hamed Firooz, Rui Liu, Yuchen Lu, Zhenyu Hou, Fangzhou Xiong, Xiaoyang Zhang, Changshu Jian, Zhicheng Zhu, Jiayuan Ma, Jacob Tao, Chaitali Gupta, Xiaochang Peng, Shike Mei, Hang Cui, Yang Qin, Shuo Tang, Jason Gaedtke, Arpit Mittal",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20061",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9cc1d5bc88350e4d91579fed9a3b17abade80dc25754379e8e11ce92e39ca7d5_w640_q70.webp",
      "contributions": "",
      "summary": "Scaling Reinforcement Learning for Content Moderation with Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Reason2Decide: Rationale-Driven Multi-Task Learning",
      "authors": "H M Quamran Hasan, Housam Khalifa Bashier, Jiayi Dai, Mi-Young Kim, Randy Goebel",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20074",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/187b806c979650defdb64bdb9ce297598ef473654b93625ec2257af228dbd0da_w640_q70.webp",
      "contributions": "",
      "summary": "Reason2Decide: Rationale-Driven Multi-Task Learning",
      "mindmap": ""
    },
    {
      "title": "On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities",
      "authors": "Sangryu Park, Gihyuk Ko, Homook Cho",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20062",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74a88fcd014c903ee16397aa497f69b488c2c3bdeb23c2bddfc09643306081ec_w640_q70.webp",
      "contributions": "",
      "summary": "On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities",
      "mindmap": ""
    }
  ]
}