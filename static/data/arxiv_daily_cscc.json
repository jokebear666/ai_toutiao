{
  "label": "cs.CC",
  "slug": "cscc",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "A Study of NP-Completeness and Undecidable Word Problems in Semigroups",
      "authors": "Duaa Abdullah, Jasem Hamoud",
      "institution": "Moscow Institute of Physics and Technology",
      "link": "https://arxiv.org/pdf/2512.22123",
      "code": null,
      "tags": [
        "computational complexity theory",
        "NP-completeness",
        "undecidable word problem",
        "associative calculus",
        "polynomial reducibility",
        "Turing machines"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9ade75d90324f1eb4f6ee92ec609932e78897f10c8103547d100966beb841a9_w640_q70.webp",
      "contributions": "1. Explores the relationship between complexity classes P and NP and the concept of polynomial reducibility. 2. Demonstrates the construction of an associative calculus (semigroup) with an algorithmically undecidable word problem. 3. Establishes a direct connection between a Turing machine computing a non-recursive function and the equivalence condition in the constructed calculus, linking computational complexity and algebraic undecidability.",
      "summary": "This paper investigates fundamental limits in computation by studying NP-completeness and undecidable problems. It constructs an associative calculus whose word problem is undecidable, linking it to a Turing machine that computes a non-recursive function. The work highlights the intrinsic boundaries of algorithmic solutions by connecting computational complexity theory with algebraic undecidability.",
      "mindmap": "graph TB\n        Root[”A Study of NP-Completeness and Undecidable Word Problems in Semigroups”] --> Problem[”核心问题/Problem<br>Computational complexity & decidability limits”]\n        Root --> Method[”主要方法/Method<br>Polynomial reducibility & Associative calculus construction”]\n        Root --> Results[”关键结果/Results<br>Undecidable word problem linked to non-recursive Turing machine”]"
    },
    {
      "title": "Lower bounds on pure dynamic programming for connectivity problems on graphs of bounded path-width",
      "authors": "Kacper Kluk, Jesper Nederlof",
      "institution": "University of Warsaw, Utrecht University",
      "link": "https://arxiv.org/pdf/2512.23121",
      "code": null,
      "tags": [
        "parameterized complexity",
        "tropical circuits",
        "pathwidth",
        "communication complexity",
        "Traveling Salesperson Problem",
        "dynamic programming"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/86590df9819e19ad7303e5df124f5b2189c5e6ab6d542206119582e1e6c83135_w640_q70.webp",
      "contributions": "1. Proves unconditional lower bounds on the size of tropical circuits (modeling pure dynamic programming) for solving connectivity problems like TSP on graphs of bounded pathwidth. 2. Establishes a connection between tropical circuit complexity and the nondeterministic communication complexity of compatibility matrices. 3. Shows that any tropical circuit for TSP on a certain graph of pathwidth k requires at least 2^Ω(k log log k) gates, which is higher than known algebraic algorithms, suggesting algebra is necessary for competitive worst-case times.",
      "summary": "This paper studies the limitations of pure dynamic programming, modeled by tropical circuits, for solving connectivity problems like the Traveling Salesperson Problem on graphs with small pathwidth. It proves an unconditional lower bound of 2^Ω(k log log k) gates for any tropical circuit solving TSP on a specific graph of pathwidth k. This result, established via a link to communication complexity, suggests that algebraic techniques are unavoidable for achieving the fastest known worst-case running times for these problems.",
      "mindmap": "graph TB\n        A[Lower bounds on pure dynamic programming for connectivity problems on graphs of bounded path-width] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[评估纯动态规划对连通性问题的能力/Assess capability of pure DP for connectivity problems]\n        C --> C1[将热带电路复杂度与通信复杂性关联/Link tropical circuit complexity to communication complexity]\n        D --> D1[证明下界高于已知代数算法/Prove lower bound higher than known algebraic algorithms]"
    },
    {
      "title": "Pseudodeterministic Algorithms for Minimum Cut Problems",
      "authors": "Aryan Agarwala, Nithin Varma",
      "institution": "Max-Planck-Institut für Informatik, Saarland Informatics Campus; University of Cologne",
      "link": "https://arxiv.org/pdf/2512.23468",
      "code": null,
      "tags": [
        "graph algorithms",
        "pseudodeterministic algorithms",
        "global minimum cut",
        "minimum s-t cut",
        "streaming algorithms",
        "cut-query models"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c06a5f7252dc9f1337880cbdb49ac90f3b180fa63fe8a5b0eb2c22a487cedbbd_w640_q70.webp",
      "contributions": "1. Presents efficient pseudodeterministic algorithms for the global minimum cut and minimum s-t cut problems. 2. Achieves an asymptotic running time for global minimum cut that is better than the fastest known sequential deterministic algorithm. 3. Implements the algorithm in multiple computational models (sequential, streaming, PRAM, cut-query) where efficient deterministic algorithms were previously unknown.",
      "summary": "This paper introduces pseudodeterministic algorithms for finding global minimum cuts and minimum s-t cuts in graphs. The proposed method offers replicability by consistently outputting the same answer with high probability, while being faster than the best known deterministic algorithm for global minimum cut. The algorithms are also successfully adapted to work in sequential, streaming, PRAM, and cut-query models.",
      "mindmap": "graph TB\n        A[Pseudodeterministic Algorithms for Minimum Cut Problems] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1(确定性算法效率低 / Deterministic algorithms are inefficient)\n        B --> B2(随机算法输出不一致 / Randomized algorithms lack replicability)\n        C --> C1(伪确定性算法 / Pseudodeterministic Algorithms)\n        C --> C2(高概率输出相同解 / Outputs same solution with high probability)\n        D --> D1(渐近更快 / Asymptotically faster)\n        D --> D2(多模型实现 / Implemented in multiple models)"
    },
    {
      "title": "Coloring Hardness on Low Twin-Width Graphs",
      "authors": "Édouard Bonnet",
      "institution": "Univ Lyon, CNRS, ENS de Lyon, Université Claude Bernard Lyon 1, LIP UMR5668",
      "link": "https://arxiv.org/pdf/2512.23680",
      "code": null,
      "tags": [
        "graph theory",
        "computational complexity",
        "twin-width",
        "graph coloring",
        "NP-hardness",
        "computational complexity",
        "graph classes"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f77a33f460e61bf2610b2bc5a51fb237df8e78440e7279dd902d4d1e4a4dbc60_w640_q70.webp",
      "contributions": "1. Proves that the Min Coloring problem is NP-hard on the class of graphs with twin-width at most 3 (T3). 2. Proves that for every k &gt;= 3, the k-Coloring problem is NP-hard on the class of graphs with twin-width at most 4 (T4). 3. Provides structural observations about the T3 and T4 classes, highlighting their distinct properties and raising open questions about complexity transitions.",
      "summary": "This paper studies the computational complexity of graph coloring problems on graphs with low twin-width. It proves that Min Coloring is NP-hard on graphs of twin-width at most 3, and that k-Coloring is NP-hard on graphs of twin-width at most 4 for all k&gt;=3. These results establish the first hardness for a problem on T3 that is easy on simpler graph classes like trees and cographs.",
      "mindmap": "graph TB\n    A[Coloring Hardness on Low Twin-Width Graphs] --> B[核心问题/Problem: Coloring complexity on bounded twin-width graphs]\n    A --> C[主要方法/Method: NP-hardness proofs via reductions]\n    A --> D[关键结果/Results: Min Coloring hard on T3, k-Coloring hard on T4]"
    },
    {
      "title": "A Note on the NP-Hardness of PARTITION Via First-Order Projections",
      "authors": "Paúl Risco Iturralde",
      "institution": "Independent researcher",
      "link": "https://arxiv.org/pdf/2512.21448",
      "code": null,
      "tags": [
        "computational complexity theory",
        "NP-hardness",
        "first-order reductions",
        "AC0 reductions",
        "PARTITION problem",
        "descriptive complexity"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b5d9f8d4b42755b482904c0cf03df329316dc9a10936a82fe27b6ce034a1e56_w640_q70.webp",
      "contributions": "1. Demonstrates NP-hardness of the PARTITION problem via first-order projections, 2. Overcomes the obstacle of requiring large sums in the standard reduction by using descriptive complexity techniques, 3. Fills a gap in the literature regarding the hardness of PARTITION under restricted reductions like AC0.",
      "summary": "This note addresses the open question of whether the PARTITION problem is NP-hard under restricted reductions like AC0. It modifies classic reductions from 3SAT to SUBSET-SUM to PARTITION, defining them using first-order logical formulas (first-order projections). The main conclusion is that PARTITION is indeed NP-hard via first-order projections, which implies hardness under polynomial-size AC0 reductions, thereby resolving the gap mentioned in prior work.",
      "mindmap": "graph TB\n        A[论文标题: A Note on the NP-Hardness of PARTITION Via First-Order Projections] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[PARTITION的NP-hardness在受限归约下是否成立?/Is PARTITION NP-hard under restricted reductions?]\n        C --> C1[使用一阶逻辑公式定义归约/Define reductions using first-order logic formulas]\n        C --> C2[修改经典归约(3SAT到SUBSET-SUM到PARTITION)/Modify classic reductions (3SAT to SUBSET-SUM to PARTITION)]\n        D --> D1[PARTITION对一阶投影是NP-hard的/PARTITION is NP-hard via first-order projections]\n        D --> D2[暗示对多项式大小AC0归约也是NP-hard的/Implies NP-hard under polynomial-size AC0 reductions]\n        D --> D3[填补了文献中的空白/Fills a gap in the literature]"
    },
    {
      "title": "A Note on Avoid vs MCSP",
      "authors": "Edward A. Hirsch, Ilya Volkovich",
      "institution": "Ariel University, Boston College",
      "link": "https://arxiv.org/pdf/2512.21764",
      "code": null,
      "tags": [
        "computational complexity theory",
        "Range Avoidance Problem",
        "Minimal Circuit Size Problem",
        "AM ∩ coAM",
        "Turing reductions"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/918e4b50a4df8fcc5a358172ac9f315b25fd82440914a13e94eb45224863b78a_w640_q70.webp",
      "contributions": "1. Presents an alternative approach to a known result linking languages reducible to the Range Avoidance Problem (Avoid) to the complexity class AM ∩ coAM. 2. Proposes using the Minimal Circuit Size Problem (MCSP) as a potential avenue to derive this containment result. 3. Highlights the connection between two central problems in complexity theory (Avoid and MCSP) for understanding the power of reductions.",
      "summary": "This note explores the complexity of the Range Avoidance Problem (Avoid). It proposes a new potential method, using the Minimal Circuit Size Problem (MCSP), to show that any language reducible to Avoid via deterministic or randomized Turing reductions is contained in the complexity class AM ∩ coAM, offering an alternative to a recent proof.",
      "mindmap": "graph TB\n        Root[”A Note on Avoid vs MCSP”] --> Problem[”核心问题/Problem<br>Complexity of Range Avoidance (Avoid)”]\n        Root --> Method[”主要方法/Method<br>Using Minimal Circuit Size Problem (MCSP)”]\n        Root --> Results[”关键结果/Results<br>Languages reducible to Avoid are in AM ∩ coAM”]"
    },
    {
      "title": "Conserved active information",
      "authors": "Yanchen Chen, Daniel Andrés Díaz-Pachón",
      "institution": "University of Miami",
      "link": "https://arxiv.org/pdf/2512.21834",
      "code": null,
      "tags": [
        "information theory",
        "conserved active information",
        "No-Free-Lunch",
        "KL divergence",
        "search space",
        "information conservation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1371f9cf2f5be050a2495fc2f2b19865fddd5c4a8834df1cd98fc2da7eea7111_w640_q70.webp",
      "contributions": "1. Introduces conserved active information (I⊕), a symmetric measure of net information gain/loss across a search space that respects No-Free-Lunch conservation. 2. Demonstrates that I⊕ can reveal regimes (e.g., strong knowledge reducing global disorder) that are hidden from traditional measures like KL divergence. 3. Applies the framework to resolve a longstanding critique of active information and illustrates its utility in domains like Markov chains and cosmological fine-tuning.",
      "summary": "This paper proposes a new information-theoretic measure called conserved active information (I⊕) to quantify net information change in search problems while respecting conservation laws. It shows that I⊕ uncovers scenarios, such as strong knowledge imposing order, which are missed by standard divergence measures. The work resolves a key critique of active information and enables applications in search and optimization.",
      "mindmap": "graph TB\n        Root[Conserved active information] --> Problem[核心问题/Problem: Limitations of average-focused information measures like KL divergence]\n        Root --> Method[主要方法/Method: Introduce conserved active information I⊕, a symmetric extension respecting No-Free-Lunch]\n        Root --> Results[关键结果/Results: I⊕ reveals hidden regimes (e.g., strong knowledge reduces disorder), resolves critique of active information]"
    },
    {
      "title": "Poincaré Duality and Multiplicative Structures on Quantum Codes",
      "authors": "Yiming Li, Zimu Li, Zi-Wen Liu, Quynh T. Nguyen",
      "institution": "Tsinghua University, Harvard University",
      "link": "https://arxiv.org/pdf/2512.21922",
      "code": null,
      "tags": [
        "quantum error correction",
        "sheaf codes",
        "Poincaré duality",
        "quantum LDPC codes",
        "transversal gates",
        "cup/cap product"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76fcb4213084226768ada35e1a65f3fff10489254aaaafade43391ca7096cc47_w640_q70.webp",
      "contributions": "1. Generalizing Poincaré duality from manifolds to sheaf-based classical and quantum codes, establishing a rigorous duality relationship between chain and cochain complexes. 2. Constructing multiplicative structures (cup and cap products) on sheaved chain complexes, leading to an explicit isomorphism between (co)homology groups. 3. Applying the framework to obtain transversal logical gates (CZ, CCZ, higher-order controlled-Z) on families of good qLDPC and quantum locally testable codes, pointing towards fault-tolerant non-Clifford gates.",
      "summary": "This paper generalizes Poincaré duality and multiplicative structures from topology to sheaf-based quantum codes. The authors rigorously prove duality relationships and construct cup/cap products, leading to an isomorphism between homology groups. As an application, they demonstrate how to construct transversal logical non-Clifford gates on good quantum LDPC codes, advancing fault-tolerant quantum computing.",
      "mindmap": "graph TB\n        Root(”Poincaré Duality and Multiplicative Structures on Quantum Codes<br>量子代码的庞加莱对偶与乘法结构”)\n        Root --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”Generalize Poincaré duality to codes<br>将对偶性推广至编码”)\n        Method --> M1(”Sheaf theory on cell complexes<br>胞腔复形上的层理论”)\n        Method --> M2(”Build cup/cap products<br>构建杯积/卡积”)\n        Results --> R1(”Duality & isomorphism proven<br>证明对偶与同构”)\n        Results --> R2(”Transversal logical gates<br>横截逻辑门”)"
    },
    {
      "title": "Shifted Partial Derivative Polynomial Rank and Codimension",
      "authors": "Darren J. Edwards",
      "institution": "Swansea University",
      "link": "https://arxiv.org/pdf/2512.20729",
      "code": null,
      "tags": [
        "computational complexity theory",
        "shifted partial derivatives",
        "circuit lower bounds",
        "algebraic complexity",
        "polynomial rank",
        "codimension"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/838d2ea35d688f3271f22d39361a703e1bf3cca6d055420f190d38fc6357ee14_w640_q70.webp",
      "contributions": "1. Introduced the Shifted Partial Derivative Polynomial (SPDP) framework, packaging classical SPD methods into an explicit coefficient-matrix formalism. 2. Proved structural properties of the framework, including monotonicity, invariance under symmetries, and robustness across embeddings. 3. Provided generic width-to-rank upper-bound templates for local circuit models via combinatorial profile counting, separating the model-agnostic toolkit from specific refinements.",
      "summary": "This paper develops a new algebraic framework called Shifted Partial Derivative Polynomial (SPDP) to formalize the study of circuit lower bounds. It packages the shifted partial derivative method into a concrete linear-algebraic matrix formalism, defining dual measures of rank and codimension. The framework is proven to have robust structural properties and provides generic templates for bounding circuit complexity.",
      "mindmap": "graph LR\n    A[Shifted Partial Derivative Polynomial Rank and Codimension] --> B(核心问题/Problem: Measuring circuit complexity via algebraic dimension)\n    A --> C(主要方法/Method: SPDP framework - coefficient-matrix formalism for shifted derivatives)\n    A --> D(关键结果/Results: Structural properties proven, generic upper-bound templates provided)"
    },
    {
      "title": "Stochastic well-structured transition systems",
      "authors": "James Aspnes",
      "institution": "Yale University",
      "link": "https://arxiv.org/pdf/2512.20939",
      "code": null,
      "tags": [
        "distributed computing theory",
        "well-structured transition systems",
        "population protocols",
        "probabilistic scheduling",
        "computational complexity",
        "BPP"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6b86e00331b0080766e8bd0e99c46088867daf6771188ff7f0462c5c277cb00_w640_q70.webp",
      "contributions": "1. Defines a new class of stochastic well-structured transition systems (SWSTSs) that unifies models like population protocols and chemical reaction networks under a probabilistic scheduling rule. 2. Proves fundamental limitations on phase clocks in SWSTSs, showing they either stop or tick too fast in expected polynomial time. 3. Provides an exact characterization of computational power, showing augmented SWSTSs compute exactly BPP languages, while unaugmented ones compute symmetric BPL languages.",
      "summary": "This paper extends the theory of well-structured transition systems by incorporating probabilistic scheduling, creating a new class called stochastic well-structured transition systems (SWSTSs). It proves that any phase clock implementation in these systems has polynomial expected duration, and that terminating computations finish in expected polynomial time. These results lead to an exact characterization of computational power, showing that augmented SWSTSs compute exactly the languages in BPP.",
      "mindmap": "graph LR\n    A[Stochastic well-structured transition systems] --> B(核心问题/Problem: Extend WSTS theory to probabilistic scheduling models)\n    A --> C(主要方法/Method: Define SWSTS class unifying population protocols, CRNs, gossip models)\n    A --> D(关键结果/Results: Phase clock limitations; Polynomial expected termination; Computational power = BPP/BPL)"
    },
    {
      "title": "Adjusted Kolmogorov Complexity of Binary Words with Empirical Entropy Normalization",
      "authors": "Brani Vidakovic",
      "institution": "Texas A&M University",
      "link": "https://arxiv.org/pdf/2512.21193",
      "code": null,
      "tags": [
        "algorithmic information theory",
        "Kolmogorov complexity",
        "empirical entropy",
        "algorithmic randomness",
        "entropy normalization"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d7810b075904c2bbfd2f2bea9585a558beed86eb55fe1de2591efdd870e8c51_w640_q70.webp",
      "contributions": "1. Introduces a new entropy-normalized complexity measure for binary words, defined as the ratio of Kolmogorov complexity to empirical entropy, to separate intrinsic descriptive complexity from symbol imbalance. 2. Proves that for Martin-Löf random sequences under constructive exchangeable measures, the adjusted complexity grows linearly and converges to one. 3. Demonstrates through a pathological construction that the regularity of the underlying measure is essential for this convergence result.",
      "summary": "This paper introduces a new measure of complexity for binary words by normalizing Kolmogorov complexity with the word's empirical entropy, aiming to isolate intrinsic algorithmic structure from the combinatorial effect of imbalanced symbol frequencies. The authors prove that for random sequences under certain measures, this adjusted complexity converges to one, and show that the regularity of the measure is crucial. The framework connects Kolmogorov complexity, entropy, and randomness, with potential applications in randomness testing and structured data analysis.",
      "mindmap": "graph LR\n    A[Adjusted Kolmogorov Complexity<br>调整后的柯尔莫哥洛夫复杂度] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[标准复杂度受符号分布影响<br>Standard complexity affected by symbol distribution]\n    C --> C1[引入熵归一化度量<br>Introduce entropy-normalized measure]\n    D --> D1[调整后复杂度收敛于1<br>Adjusted complexity converges to 1]\n    D --> D2[度量正则性至关重要<br>Measure regularity is essential]"
    },
    {
      "title": "On the complexity of computing Strahler numbers",
      "authors": "Moses Ganardi, Markus Lohrey",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19060",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/766e6fd373709e1db6e154a2587de62f4f4e26874de556b197f9b8ce5acbd6c2_w640_q70.webp",
      "contributions": "",
      "summary": "On the complexity of computing Strahler numbers",
      "mindmap": ""
    },
    {
      "title": "Negations are powerful even in small depth",
      "authors": "Bruno Cavalar, Théo Borém Fabris, Partha Mukhopadhyay, Srikanth Srinivasan, Amir Yehudayoff",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19515",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aac7e20e03b10f3eec41314aef3ae6875b189b18ff94a23b98b224f3e0816d64_w640_q70.webp",
      "contributions": "",
      "summary": "Negations are powerful even in small depth",
      "mindmap": ""
    },
    {
      "title": "Assembly Addition Chains",
      "authors": "Leroy Cronin, Juan Carlos Morales Parra, Keith Y. Patarroyo",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18030",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/10ea7d39b17a64fe0479e71c1b2c378efd134d84b95b0ee41ddb001f5c7ab6cd_w640_q70.webp",
      "contributions": "",
      "summary": "Assembly Addition Chains",
      "mindmap": ""
    },
    {
      "title": "Classical billiards can compute",
      "authors": "Eva Miranda, Isaac Ramos",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19156",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7724a2d94526af4f01b67bbf44e70aa6699225be8d35d64024a661c94737371b_w640_q70.webp",
      "contributions": "",
      "summary": "Classical billiards can compute",
      "mindmap": ""
    }
  ]
}