{
  "label": "cs.CL",
  "slug": "cscl",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks",
      "authors": "Jasmin Saxer, Isabella Maria Aigner, Luise Linzmeier, Andreas Weiler, Kurt Stockinger",
      "institution": "Zurich University of Applied Sciences, University of Zurich",
      "link": "https://arxiv.org/pdf/2512.21345",
      "code": null,
      "tags": [
        "text-to-SQL",
        "unanswerable question detection",
        "few-shot prompting",
        "biomedical databases"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d95c00b7fa86810771a1c8fb0ff6fd8768baaa0419f172cc5c7a3068ac67a64_w640_q70.webp",
      "contributions": "1. Proposed Query Carefully, a pipeline integrating LLM-based SQL generation with explicit detection of unanswerable inputs. 2. Constructed OncoMX-NAQ, a benchmark dataset of 80 no-answer questions for biomedical text-to-SQL. 3. Demonstrated that balanced few-shot prompting with both answerable and unanswerable examples achieves high unanswerable-detection accuracy without degrading performance on answerable queries.",
      "summary": "This paper addresses the risk of text-to-SQL systems generating executable but incorrect SQL for ambiguous or unanswerable queries, especially in biomedical contexts. The authors propose the Query Carefully pipeline, which uses an LLM with schema-aware prompts and few-shot examples to detect and abstain from unanswerable inputs. Their evaluation shows the method achieves high detection accuracy for structurally unanswerable queries, though challenges remain for semantic ambiguities like missing values.",
      "mindmap": "graph TB\n        Root(”Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks”) --> Problem\n        Root --> Method\n        Root --> Results\n        Problem(”核心问题/Problem”) --> P1(”Text-to-SQL对不可回答查询生成可执行SQL/Text-to-SQL generates executable SQL for unanswerable queries”)\n        P1 --> P2(”生物医学领域风险高/High risk in biomedical contexts”)\n        Method(”主要方法/Method”) --> M1(”Query Carefully 管道/Query Carefully pipeline”)\n        M1 --> M2(”LLM (llama3.3:70b) + 模式感知提示 + 少样本/LLM (llama3.3:70b) + schema-aware prompts + few-shot”)\n        M2 --> M3(”包含可回答与不可回答示例/Includes answerable and unanswerable examples”)\n        Results(”关键结果/Results”) --> R1(”构建OncoMX-NAQ基准/Built OncoMX-NAQ benchmark”)\n        R1 --> R2(”不可回答检测准确率0.8/Unanswerable-detection accuracy 0.8”)\n        R2 --> R3(”结构性问题检测好，语义模糊挑战大/Good for structural, challenging for semantic ambiguity”)"
    },
    {
      "title": "Teaching People LLM's Errors and Getting it Right",
      "authors": "Nathan Stringham, Fateme Hashemi Chaleshtori, Xinyuan Yan, Zhichao Xu, Bei Wang, Ana Marasović",
      "institution": "University of Utah",
      "link": "https://arxiv.org/pdf/2512.21422",
      "code": null,
      "tags": [
        "human-ai interaction",
        "overreliance",
        "failure patterns",
        "mental models",
        "user study",
        "meta-labels"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83a262b8daf44fdf951904b9202074fd9db4ef9e9666cd5769ec1d8514053804_w640_q70.webp",
      "contributions": "1. Empirically demonstrated that failure patterns for LLMs do exist by identifying sizable, error-prone meta-label groups in datasets, countering the hypothesis that their absence caused prior teaching failures. 2. Evaluated automated methods for discovering these failure patterns (prompting and embedding-based) and found mixed results, identifying a key bottleneck in the teaching pipeline. 3. Proposed and validated a new metric for teaching effectiveness—assessing a user's ability to anticipate LLM errors using taught patterns—which showed a positive effect, unlike traditional human-AI team accuracy.",
      "summary": "This paper investigates why prior attempts to teach users about LLM failure patterns to reduce overreliance have failed. It finds that failure patterns do exist, but automated methods to discover them are unreliable, and proposes a new user-centric evaluation metric that shows teaching can be effective. The conclusion is that teaching failure patterns is viable but requires better failure-discovery methods and appropriate metrics.",
      "mindmap": "graph TB\n        A[Teaching People LLM’s Errors and Getting it Right] --> B[核心问题/Problem: Users overrely on LLMs due to inaccurate mental models]\n        A --> C[主要方法/Method: Analyze failure pattern existence, test discovery methods, propose new evaluation metric]\n        A --> D[关键结果/Results: Patterns exist, discovery methods are mixed, new metric shows teaching is effective]"
    },
    {
      "title": "Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models",
      "authors": "Geoffroy Morlat, Marceau Nahon, Augustin Chartouny, Raja Chatila, Ismael T. Freire, Mehdi Khamassi",
      "institution": "Institute of Intelligent Systems and Robotics, Sorbonne University",
      "link": "https://arxiv.org/pdf/2512.21439",
      "code": null,
      "tags": [
        "computational ethics",
        "moral context",
        "probabilistic clustering",
        "LLM semantics",
        "interpretable prediction",
        "human judgment"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f4abc9f666c2d29dadd77869bddf3f159d0bbc8839c7c0f65bbdb4c29ad40c_w640_q70.webp",
      "contributions": "1. An empirically grounded dataset of 300 moral scenarios with human ternary judgments. 2. A reproducible pipeline (COMETH) combining human judgments, probabilistic context learning, and LLM-based semantic abstraction. 3. An interpretable, context-sensitive moral prediction model that outperforms end-to-end LLM prompting.",
      "summary": "The paper addresses the problem that moral judgments depend heavily on context. It proposes the COMETH framework, which uses probabilistic clustering on human judgment data and LLM-based semantic abstraction to learn and explain action-specific moral contexts. The main conclusion is that COMETH significantly outperforms direct LLM prompting in aligning with human majority judgments while providing interpretable predictions.",
      "mindmap": "graph TB\n        A[COMETH: Learning Interpretable Moral Contexts] --> B[核心问题/Problem: Moral judgments are context-dependent]\n        A --> C[主要方法/Method: Probabilistic clustering + LLM semantics + Human judgments]\n        A --> D[关键结果/Results: Doubles alignment with human judgments vs. LLM prompting]"
    },
    {
      "title": "Oogiri-Master: Benchmarking Humor Understanding via Oogiri",
      "authors": "Soichiro Murakami, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura",
      "institution": "CyberAgent, Nara Institute of Science and Technology, Institute of Science Tokyo",
      "link": "https://arxiv.org/pdf/2512.21494",
      "code": null,
      "tags": [
        "humor understanding",
        "Oogiri",
        "benchmark",
        "linguistic analysis",
        "incongruity resolution",
        "insight-augmented prompting"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41486d2e77493633c6cf66d7f5134ccf646d1df0d17e6d258bc98cc3132ef02b_w640_q70.webp",
      "contributions": "1. Introduces Oogiri-Master, a benchmark for rigorous evaluation of humor understanding in LLMs, and Oogiri-Corpus, a dataset with ~100 diverse responses per prompt and independent human ratings to reduce bias. 2. Conducts quantitative analysis of linguistic factors (e.g., text length, ambiguity, incongruity resolution) to derive objective metrics for predicting human funniness judgments. 3. Benchmarks LLMs and human baselines, showing state-of-the-art models approach human performance and that insight-augmented prompting improves model humor understanding.",
      "summary": "This paper addresses the challenge of evaluating humor understanding in LLMs by introducing the Oogiri-Master benchmark and Oogiri-Corpus dataset, which enable rigorous analysis of funniness through diverse responses and independent human ratings. It quantitatively analyzes linguistic factors to derive objective metrics and benchmarks LLMs, demonstrating that advanced models approach human-level performance and benefit from insight-augmented prompting. The work provides a principled basis for advancing humor understanding in AI.",
      "mindmap": "graph TB\n        A[Oogiri-Master: Benchmarking Humor Understanding via Oogiri] --> B[核心问题/Problem: What makes Oogiri responses funny to humans?]\n        A --> C[主要方法/Method: Introduce Oogiri-Master benchmark and Oogiri-Corpus dataset with diverse responses and independent ratings]\n        A --> D[关键结果/Results: LLMs approach human performance; insight-augmented prompting improves results]"
    },
    {
      "title": "MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding",
      "authors": "Aiwei Zhang, Arvind Pillai, Andrew Campbell, Nicholas C. Jacobson",
      "institution": "Dartmouth College",
      "link": "https://arxiv.org/pdf/2512.21506",
      "code": null,
      "tags": [
        "multi-modal training",
        "wearable sensing",
        "actigraphy encoder",
        "projection module",
        "frozen LLM",
        "behavioral summarization"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp",
      "contributions": "1. Introduces MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs) for free-text generation of daily behavioral summaries. 2. Constructs a novel, large-scale dataset of 54,383 (actigraphy, text) pairs derived from real-world NHANES recordings. 3. Demonstrates superior performance over prompt-based baselines in semantic fidelity and lexical accuracy, with qualitative analysis showing the model captures circadian structure and behavioral transitions.",
      "summary": "The paper addresses the challenge of generating natural language summaries from raw physiological signals like actigraphy. It proposes MotionTeller, a framework that integrates a pretrained actigraphy encoder with a frozen LLM via a projection module. The model, trained on a novel dataset, outperforms baselines in generating fluent, human-centered descriptions of daily behavior.",
      "mindmap": "graph TB\n        A[MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs] --> B[核心问题/Problem: How to generate natural language summaries from raw physiological signals like actigraphy?]\n        A --> C[主要方法/Method: Combines a pretrained actigraphy encoder and a projection module to map behavioral embeddings into a frozen LLM's token space.]\n        A --> D[关键结果/Results: Achieves high semantic fidelity (BERTScore-F1=0.924) and lexical accuracy (ROUGE-1=0.722), outperforming baselines by 7%.]"
    },
    {
      "title": "Perplexity-Aware Data Scaling Law: Perplexity Landscapes Predict Performance for Continual Pre-training",
      "authors": "Lei Liu, Hao Zhu, Yue Shen, Zhixuan Chu, Jian Wang, Jinjie Gu, Kui Ren",
      "institution": "Ant Group, Zhejiang University",
      "link": "https://arxiv.org/pdf/2512.21515",
      "code": null,
      "tags": [
        "llm training",
        "continual pre-training",
        "scaling laws",
        "perplexity",
        "data selection",
        "knowledge gap"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d01b1cad6e908309c7e813cb1d98f2c41345aa1e4d78cbdaf163996c5d111b4_w640_q70.webp",
      "contributions": "1. Proposes a novel perplexity-aware data scaling law that predicts model test loss from the perplexity landscape of domain data, moving beyond dataset size. 2. Introduces the concept of \"perplexity landscapes\" to quantify the informational value and knowledge gap of candidate training samples. 3. Enables adaptive selection of high-utility data subsets for Continual Pre-training, improving efficiency and performance by prioritizing informative content and reducing redundancy.",
      "summary": "This paper addresses the inefficiency of scaling data for Continual Pre-training (CPT) of LLMs, where simply adding more data yields diminishing returns. The authors propose a new scaling law that uses the model's perplexity on domain data as a proxy for the knowledge gap, allowing for the predictive selection of optimal training subsets. Experiments show this method consistently identifies high-utility data, leading to superior performance on domain-specific benchmarks.",
      "mindmap": "graph TB\n        A[Perplexity-Aware Data Scaling Law<br>困惑度感知数据缩放定律] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[CPT中单纯增加数据收益递减<br>Diminishing returns from scaling data in CPT]\n        C --> C1[提出基于困惑度景观的缩放定律<br>Propose perplexity-landscape-based scaling law]\n        C1 --> C2[利用困惑度量化知识差距<br>Use perplexity to quantify knowledge gap]\n        C2 --> C3[自适应选择高价值数据子集<br>Adaptively select high-utility data subsets]\n        D --> D1[识别接近最优的训练子集<br>Identifies near-optimal training subsets]\n        D1 --> D2[在领域基准上取得优越性能<br>Achieves superior performance on domain benchmarks]"
    },
    {
      "title": "Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures",
      "authors": "Hua Shen, Tiffany Knearem, Divy Thakkar, Pat Pataranutaporn, Anoop Sinha, Yike, Jenny T. Liang, Lama Ahmad, Tanu Mitra, Brad A. Myers, Yang Li",
      "institution": "NYU Shanghai, MBZUAI, Google, Massachusetts Institute of Technology, Carnegie Mellon University, OpenAI, University of Washington, Google DeepMind",
      "link": "https://arxiv.org/pdf/2512.21551",
      "code": null,
      "tags": [
        "human-ai interaction",
        "bidirectional alignment",
        "value-centered design",
        "interactive alignment"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp",
      "contributions": "1. Proposes a shift from unidirectional to bidirectional human-AI alignment, framing it as a dynamic, reciprocal co-adaptation process. 2. Emphasizes embedding human and societal values into AI alignment research through value-centered design. 3. Aims to establish an interdisciplinary research agenda for responsible, reciprocal human-AI futures through collaborative workshop activities.",
      "summary": "This workshop paper identifies the inadequacy of traditional, one-way AI alignment and proposes a bidirectional human-AI alignment framework where humans and AI co-adapt through interaction and value-centered design. It aims to bring together interdisciplinary researchers to explore methods for interactive alignment and societal impact evaluation. The main conclusion is the need for a shared agenda to advance responsible, reciprocal collaboration between humans and AI systems.",
      "mindmap": "graph TB\n        A[Human-AI Interaction Alignment] --> B[核心问题/Problem: Unidirectional AI alignment is inadequate for dynamic human-AI interaction]\n        A --> C[主要方法/Method: Bidirectional alignment via value-centered design, interaction, and evaluation]\n        A --> D[关键结果/Results: Establishes agenda for reciprocal, responsible human-AI futures]"
    },
    {
      "title": "Beyond Heuristics: A Decision-Theoretic Framework for Agent Memory Management",
      "authors": "Changzhi Sun, Xiangyu Chen, Jixiang Luo, Dell Zhang, Xuelong Li",
      "institution": "Institute of Artificial Intelligence (TeleAI), China Telecom",
      "link": "https://arxiv.org/pdf/2512.21567",
      "code": "https://github.com/TeleAI-UAGI/telemem",
      "tags": [
        "agent system",
        "external memory",
        "sequential decision-making",
        "value functions",
        "uncertainty estimators",
        "hierarchical storage"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d30748df565a671b29899dffbfb153dca58fed0398e13cc6871dfe6f450f11a1_w640_q70.webp",
      "contributions": "1. Proposes a decision-theoretic reframing of agent memory management as a sequential decision-making problem under uncertainty, 2. Introduces the DAM framework that decomposes memory operations into immediate access and hierarchical maintenance, 3. Provides a foundation for future research by evaluating operations via value functions and uncertainty estimators for long-term utility and risk",
      "summary": "This paper argues that current heuristic-based memory management for LLM agents is inadequate due to delayed and uncertain utility. It proposes DAM, a decision-theoretic framework that uses value functions and uncertainty estimators to make memory decisions based on long-term consequences. The main contribution is a principled reframing of the problem to guide future research on uncertainty-aware memory systems.",
      "mindmap": "graph TB\n        A[Beyond Heuristics: A Decision-Theoretic Framework for Agent Memory Management] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[启发式内存管理缺乏对长期和不确定后果的洞察/Heuristic memory management lacks insight into long-term & uncertain consequences]\n        C --> C1[提出DAM框架，将内存管理视为序列决策问题/Propose DAM framework, viewing memory as a sequential decision problem]\n        C --> C2[使用价值函数和不确定性估计器评估操作/Evaluate operations via value functions & uncertainty estimators]\n        D --> D1[原则性重构，为不确定性感知内存系统奠定基础/Principled reframing, provides foundation for uncertainty-aware memory systems]"
    },
    {
      "title": "A Unified Definition of Hallucination, Or: It's the World Model, Stupid",
      "authors": "Emmy Liu, Varun Gangal, Chelsea Zou, Xiaoqi Huang, Michael Yu, Alex Chang, Zhuofu Tao, Sachin Kumar, Steven Y. Feng",
      "institution": "Carnegie Mellon University, Stanford University, The Ohio State University, Patronus AI, DegenAI Labs, Independent Researchers",
      "link": "https://arxiv.org/pdf/2512.21577",
      "code": null,
      "tags": [
        "hallucination detection & evaluation",
        "hallucination",
        "world modeling",
        "knowledge conflict",
        "benchmark",
        "language model evaluation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e2cc31121f769cca7464239d4aa27b26c8c4bc903970a4833fbebac56dc9b85_w640_q70.webp",
      "contributions": "1. Proposes a unified definition of hallucination as inaccurate internal world modeling that is observable to the user, synthesizing prior definitions. 2. Provides a framework for analyzing hallucinations by varying the reference world model and knowledge conflict policy, clarifying what constitutes a hallucination versus other error types. 3. Outlines plans for a family of benchmarks based on synthetic, fully-specified world models to stress-test and improve the world modeling components of language models.",
      "summary": "This paper argues that the persistent problem of hallucination in language models stems from inaccurate internal world modeling. It unifies various historical definitions under this core concept and proposes a framework for clearer evaluation. The authors conclude by sketching plans for new benchmarks to rigorously test and improve language models' world modeling capabilities.",
      "mindmap": "graph TB\n        Root[”A Unified Definition of Hallucination / 幻觉的统一定义”] --> Problem[”核心问题/Problem”]\n        Root[”A Unified Definition of Hallucination / 幻觉的统一定义”] --> Method[”主要方法/Method”]\n        Root[”A Unified Definition of Hallucination / 幻觉的统一定义”] --> Results[”关键结果/Results”]\n        Problem --> P1[”Hallucination persists in LLMs / 幻觉在LLM中持续存在”]\n        Method --> M1[”Unified definition: inaccurate world modeling / 统一定义：不准确的世界建模”]\n        Method --> M2[”Framework: reference world & conflict policy / 框架：参考世界与冲突策略”]\n        Results --> R1[”Clarifies evaluation & terminology / 澄清评估与术语”]\n        Results --> R2[”Proposes new benchmark plans / 提出新基准计划”]"
    },
    {
      "title": "Gamayun's Path to Multilingual Mastery: Cost-Efficient Training of a 1.5B-Parameter LLM",
      "authors": "Alexander Podolskiy, Semen Molokov, Timofey Gerasin, Maksim Titov, Alexey Rukhovich, Artem Khrapov, Kirill Morozov, Evgeny Tetin, Constantine Korikov, Pavel Efimov, Polina Lazukova, Yuliya Skripkar, Nikita Okhotnikov, Irina Piontkovskaya, Meng Xiaojun, Zou Xueyi, Zhang Zhenhe",
      "institution": "Gamayun Team",
      "link": "https://arxiv.org/pdf/2512.21580",
      "code": null,
      "tags": [
        "multilingual language modeling",
        "two-stage pre-training",
        "cross-lingual alignment",
        "English enrichment",
        "cost-efficient training",
        "Russian LLM"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b7ebd17e8a0b7536938c0d12aa8812a6376542abde4f40239a4622472c17ea0_w640_q70.webp",
      "contributions": "1. Introduces a novel two-stage pre-training strategy (balanced multilingual training followed by high-quality English enrichment) for efficient cross-lingual knowledge transfer. 2. Presents Gamayun, a 1.5B-parameter multilingual LLM trained from scratch on 2.5T tokens, designed for resource-constrained environments. 3. Demonstrates state-of-the-art performance for its size (1-2B parameters) on Russian benchmarks and competitive results on English and multilingual tasks, despite a significantly smaller training budget than comparable models.",
      "summary": "This paper presents Gamayun, a cost-efficient 1.5B-parameter multilingual language model. It addresses the lack of small non-English-centric LLMs through a novel two-stage pre-training strategy for cross-lingual alignment. The model achieves state-of-the-art results in Russian and outperforms larger models on many tasks, despite being trained on far fewer tokens.",
      "mindmap": "graph TB\n        A[Gamayun's Path to Multilingual Mastery<br/>Gamayun的多语言精通之路] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br/>Lack of small, efficient, non-English-centric LLMs<br/>缺乏小型、高效、非英语中心的LLM]\n        C[主要方法/Method<br/>Two-stage pre-training<br/>两阶段预训练<br/>1. Balanced multilingual training<br/>平衡多语言训练<br/>2. High-quality English enrichment<br/>高质量英语增强]\n        D[关键结果/Results<br/>Outperforms LLaMA3.2-1B & Qwen2.5-1.5B<br/>超越LLaMA3.2-1B和Qwen2.5-1.5B<br/>SOTA in Russian (MERA)<br/>俄语任务达到SOTA]"
    },
    {
      "title": "Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards",
      "authors": "Xinyu Tang, Yuliang Zhan, Zhixun Li, Wayne Xin Zhao, Zhenduo Zhang, Zujie Wen, Zhiqiang Zhang, Jun Zhou",
      "institution": "Renmin University of China, The Chinese University of Hong Kong, Ant Group",
      "link": "https://arxiv.org/pdf/2512.21625",
      "code": null,
      "tags": [
        "reinforcement learning",
        "RLVR",
        "sample polarity",
        "advantage shaping",
        "policy optimization",
        "reasoning models"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp",
      "contributions": "1. A systematic investigation into the distinct roles of positive and negative samples (sample polarity) in RLVR training dynamics, showing positive samples sharpen existing patterns while negative samples encourage exploration. 2. An exploration of how adjusting advantage values for different sample polarities at both the sample and token levels affects training. 3. The proposal of A3PO, an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, which precisely allocates advantage signals to key tokens.",
      "summary": "This paper investigates the distinct roles of positive and negative samples in Reinforcement Learning with Verifiable Rewards (RLVR) for training large reasoning models. It finds positive samples refine correct patterns while negative samples promote exploration, and proposes a new method called A3PO for adaptive, asymmetric token-level advantage shaping. Experiments on five reasoning benchmarks demonstrate the effectiveness of the proposed approach.",
      "mindmap": "graph TB\n        Root[Rethinking Sample Polarity in RLVR] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[RLVR中正负样本的角色?/Roles of +/- samples in RLVR?]\n        Method[主要方法/Method] --> M1[分析样本极性/Analyze Sample Polarity]\n        Method --> M2[提出A3PO方法/Propose A3PO Method]\n        Results[关键结果/Results] --> R1[正样本锐化模式/Positive samples sharpen patterns]\n        Results --> R2[负样本鼓励探索/Negative samples encourage exploration]\n        Results --> R3[A3PO有效/A3PO is effective]"
    },
    {
      "title": "Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations",
      "authors": "Chengxu Yang, Jingling Yuan, Siqi Cai, Jiawei Jiang, Chuang Hu",
      "institution": "Wuhan University of Technology, Wuhan University",
      "link": "https://arxiv.org/pdf/2512.21635",
      "code": "https://github.com/chujiguangniao/HIC-bench",
      "tags": [
        "hallucination evaluation",
        "HIC-Bench",
        "Intelligent Hallucinations",
        "Defective Hallucinations",
        "Torrance Tests of Creative Thinking",
        "Dynamic Hallucination Prompt"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb581f42c65746c28519ac82f0996a0d7ab8f6413a85636583ec1e0abecba3c_w640_q70.webp",
      "contributions": "1. Proposes HIC-Bench, a novel evaluation framework that categorizes LLM hallucinations into Intelligent Hallucinations (IH) and Defective Hallucinations (DH) for systematic study. 2. Introduces a structured multi-dimensional assessment matrix combining TTCT creativity metrics (Originality, Feasibility, Value) with hallucination-specific dimensions (scientific plausibility, factual deviation). 3. Features cross-domain applicability across ten scientific domains and a Dynamic Prompt Optimization technique (DHP) to guide model outputs.",
      "summary": "This paper addresses the challenge of evaluating LLM hallucinations beyond factual errors by proposing HIC-Bench, a framework that distinguishes between creative (Intelligent) and erroneous (Defective) hallucinations using a multi-metric assessment. It demonstrates that creativity and correctness can be jointly optimized, revealing a nonlinear relationship between the two types of hallucinations and positioning intelligent hallucinations as a catalyst for scientific innovation.",
      "mindmap": "graph TB\n        A[Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[现有方法难以平衡LLM幻觉的创造性与准确性/Existing methods struggle to balance creativity and accuracy in LLM hallucinations]\n        C --> C1[提出HIC-Bench评估框架/Propose HIC-Bench evaluation framework]\n        C1 --> C2[分类智能与缺陷幻觉/Categorize IH and DH]\n        C1 --> C3[多维度评估矩阵/Multi-dimensional metric matrix]\n        C1 --> C4[动态提示优化/Dynamic Prompt Optimization]\n        D --> D1[创造力与正确性可共同优化/Creativity and correctness can be jointly optimized]\n        D --> D2[智能幻觉是创造力的催化剂/IH is a catalyst for creativity]"
    },
    {
      "title": "Semantic Codebooks as Effective Priors for Neural Speech Compression",
      "authors": "Liuyang Bai, Weiyi Lu, Li Guo",
      "institution": "NYU Shanghai",
      "link": "https://arxiv.org/pdf/2512.21653",
      "code": null,
      "tags": [
        "speech compression",
        "semantic codebooks",
        "residual vector quantization (RVQ)",
        "HuBERT",
        "FiLM-conditioned decoder",
        "neural audio codec"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a14c953c6c23139c4473b8d6e59b36c7615f79f4316119e168deb19de30eced_w640_q70.webp",
      "contributions": "1. Proposes SemDAC, a semantic-aware neural audio codec that uses semantic codebooks as priors for compression., 2. Introduces a design where the first RVQ quantizer is distilled from HuBERT to capture phonetic content, and a FiLM-conditioned decoder uses these semantic tokens., 3. Demonstrates superior performance over baseline DAC in perceptual metrics and ASR (Whisper) WER at significantly lower bitrates.",
      "summary": "The paper proposes SemDAC, a neural speech codec that uses semantic codebooks distilled from HuBERT as priors within an RVQ framework to separate phonetic from acoustic information. This method achieves better perceptual quality and lower word error rates for speech recognition at much lower bitrates compared to traditional neural codecs. The results show that semantic priors provide an effective inductive bias for efficient, recognition-friendly speech compression.",
      "mindmap": "graph TB\n        Root[”Semantic Codebooks as Effective Priors for Neural Speech Compression”] --> Problem[”核心问题/Problem: Traditional codecs inefficiently allocate bits for acoustic detail, neglecting linguistic structure.”]\n        Root --> Method[”主要方法/Method: Propose SemDAC, using HuBERT-distilled semantic codebooks in RVQ and a FiLM-conditioned decoder.”]\n        Root --> Results[”关键结果/Results: Outperforms DAC in perceptual metrics & ASR WER at lower bitrates (e.g., 0.95 vs 2.5 kbps).”]"
    },
    {
      "title": "Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech",
      "authors": "Shuchang Pan, Siddharth Banerjee, Dhruv Hebbar, Siddhant Patel, Akshaj Gupta, Kan Jen Cheng, Hanjo Kim, Zeyi Austin Li, Martin Q. Ma, Tingle Li, Gopala Anumanchipalli, Jiachen Lian",
      "institution": "Zhejiang University, University of California, Berkeley, Carnegie Mellon University",
      "link": "https://arxiv.org/pdf/2512.21706",
      "code": "https://got-duplex.github.io/",
      "tags": [
        "spoken dialogue systems",
        "Graph-of-Thoughts",
        "full-duplex",
        "speech acts",
        "causal inference",
        "multimodal transformer"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eaad0398d39f15391b728b9e3c53af71ff071dcfd269c61b0a277091d58ee7f3_w640_q70.webp",
      "contributions": "1. A framework that models conversational behavior reasoning as causal inference within a Graph-of-Thoughts (GoT) to enable interpretable decision-making in full-duplex dialogue. 2. A hierarchical labeling scheme and hybrid training corpus combining simulated dialogues with human rationales and real speech to learn causal and temporal dependencies between intents and speech acts. 3. A system that structures streaming predictions as an evolving graph, allowing a multimodal transformer to forecast the next speech act, generate justifications, and dynamically refine its reasoning.",
      "summary": "This paper addresses the lack of explicit reasoning in full-duplex spoken dialogue systems by proposing a framework that models the perception-reasoning-generation loop as causal inference within a Graph-of-Thoughts (GoT). The method uses a hierarchical behavior detection model and a hybrid corpus to learn dependencies, enabling an agent to predict the next speech act and generate interpretable justifications. Experiments show the framework provides robust behavior detection and interpretable reasoning, establishing a foundation for benchmarking conversational reasoning.",
      "mindmap": "graph TB\n        Root[”Enabling Conversational Behavior Reasoning in Full-Duplex Speech<br/>实现全双工语音对话行为推理”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br/>Current systems lack explicit reasoning for conversational behaviors.”]\n        Method[”主要方法/Method<br/>Model reasoning as causal inference in a Graph-of-Thoughts (GoT).”]\n        Results[”关键结果/Results<br/>Robust behavior detection and interpretable reasoning chains.”]"
    },
    {
      "title": "Detecting AI-Generated Paraphrases in Bengali: A Comparative Study of Zero-Shot and Fine-Tuned Transformers",
      "authors": "Md. Rakibul Islam, Most. Sharmin Sultana Samu, Md. Zahid Hossain, Farhad Uz Zaman, Md. Kamrozzaman Bhuiyan",
      "institution": "Not specified in provided content.",
      "link": "https://arxiv.org/pdf/2512.21709",
      "code": null,
      "tags": [
        "ai-generated text detection",
        "transformer",
        "fine-tuning",
        "zero-shot",
        "Bengali",
        "paraphrase detection"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b32597f75301412c6dbf1765506d21eb52c7e7727c1e3eefdfaa406f8c4ae44_w640_q70.webp",
      "contributions": "1. Conducts the first comparative study of transformer models for detecting AI-generated paraphrases specifically in the Bengali language. 2. Demonstrates that zero-shot evaluation of pre-trained models yields near-chance performance, highlighting the necessity of task-specific fine-tuning for this problem. 3. Shows that fine-tuning significantly boosts performance, with XLM-RoBERTa, mDeBERTa, and MultilingualBERT achieving high accuracy (~91%), establishing a strong baseline for future research.",
      "summary": "This paper addresses the challenge of detecting AI-generated paraphrased text in Bengali, a low-resource language. It evaluates five transformer models in zero-shot and fine-tuned settings, finding that fine-tuning is essential and leads to high detection accuracy (~91%) for several models. The work establishes a foundation for robust AI-generated content detection systems in Bengali.",
      "mindmap": "graph TB\n        A[Detecting AI-Generated Paraphrases in Bengali] --> B[核心问题/Problem: LLM misuse & lack of Bengali detection research]\n        A --> C[主要方法/Method: Compare 5 transformers (Zero-Shot vs. Fine-Tuned)]\n        A --> D[关键结果/Results: Fine-tuning needed; XLM-R, mDeBERTa, mBERT achieve ~91% accuracy]"
    },
    {
      "title": "MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles",
      "authors": "Jing Han, Binwei Yan, Tianyu Guo, Zheyuan Bai, Mengyu Zheng, Hanting Chen, Ying Nie",
      "institution": "Beijing University of Posts and Telecommunications, Huawei Noah's Ark Lab",
      "link": "https://arxiv.org/pdf/2512.21708",
      "code": "https://mor-agent.github.io/",
      "tags": [
        "agent system",
        "Parameter-Efficient Fine-Tuning (PEFT)",
        "Low-Rank Adaptation (LoRA)",
        "Mixture-of-Roles (MoR)",
        "Agent Tuning",
        "Data Generation Pipeline"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c303f17ce31b4315bdd80c394b9ba486dc14690a542d268175927115df139559_w640_q70.webp",
      "contributions": "1. Decomposes agent capabilities into three distinct roles (reasoner, executor, summarizer) based on the Reason+Action paradigm. 2. Proposes the Mixture-of-Roles (MoR) framework, which uses three specialized LoRA groups, each dedicated to a specific role, to collaboratively accomplish agent tasks. 3. Develops a multi-role data generation pipeline for effective fine-tuning, incorporating role-specific content completion and reliability verification.",
      "summary": "This paper addresses the underexplored area of parameter-efficient fine-tuning (PEFT) for AI agents. It proposes MoRAgent, a framework that decomposes agent tasks into three roles (reasoner, executor, summarizer) and assigns a specialized LoRA module to each, enabling efficient and collaborative task completion. Extensive experiments demonstrate the method's effectiveness in tuning LLMs for agent tasks while maintaining parameter efficiency.",
      "mindmap": "graph TB\n        Root[MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: PEFT for agent tasks is largely unexplored] --> P1[挑战/Challenges: Full fine-tuning is resource-heavy and harms general capabilities]\n        Method[主要方法/Method: Mixture-of-Roles (MoR) Framework] --> M1[策略1/Strategy 1: Decompose agent into three roles]\n        M1 --> M1_1[角色/Roles: Reasoner, Executor, Summarizer]\n        Method --> M2[策略2/Strategy 2: Three specialized LoRA groups for the three roles]\n        Method --> M3[策略3/Strategy 3: Multi-role data generation pipeline]\n        Results[关键结果/Results: Effectiveness demonstrated] --> R1[实验/Experiments: Extensive tests on various LLMs & benchmarks]"
    },
    {
      "title": "Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought",
      "authors": "Yuyi Zhang, Boyu Tang, Tianjie Ju, Sufeng Duan, Gongshen Liu",
      "institution": "Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.21711",
      "code": null,
      "tags": [
        "interpretability & analysis",
        "latent tokens",
        "chain-of-thought",
        "model reliability",
        "causal analysis",
        "shortcut learning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99abfa3b8406909febaa5ee077a1feab3c1d8b8cda1eebe350774e19cb82eb77_w640_q70.webp",
      "contributions": "1. Introduces \"Steering Experiments\" to causally test the impact of perturbing latent reasoning tokens, revealing COCONUT tokens are insensitive to perturbation unlike explicit CoT tokens. 2. Conducts \"Shortcut Experiments\" to evaluate models under biased and out-of-distribution settings, demonstrating COCONUT exploits dataset artifacts rather than performing genuine reasoning. 3. Repositions COCONUT as a \"pseudo-reasoning\" mechanism that generates plausible traces to conceal shortcut dependence, challenging its claimed reasoning capabilities.",
      "summary": "This paper investigates the reliability of latent reasoning tokens in LLMs, specifically Chain-of-Continuous-Thought (COCONUT). Through causal steering and adversarial shortcut experiments, it finds that COCONUT tokens are uninterpretable placeholders insensitive to perturbation and that the method relies on dataset shortcuts. The main conclusion is that COCONUT is a pseudo-reasoning mechanism that inflates benchmark performance without faithful reasoning.",
      "mindmap": "graph TB\n        A[Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Latent token mechanisms unclear, reliability concerns] --> B1[潜在令牌机制不明确/Unclear latent token mechanisms]\n        B --> B2[可靠性问题/Reliability concerns]\n        C[主要方法/Method: Causal & adversarial analysis] --> C1[引导实验/Steering experiments]\n        C --> C2[捷径实验/Shortcut experiments]\n        D[关键结果/Results: COCONUT is pseudo-reasoning] --> D1[令牌对扰动不敏感/Tokens insensitive to perturbation]\n        D --> D2[利用数据集捷径/Exploits dataset shortcuts]\n        D --> D3[性能提升不基于真实推理/Performance gains not from true reasoning]"
    },
    {
      "title": "CATCH: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation",
      "authors": "Rui Ke, Jiahui Xu, Shenghao Yang, Kuang Wang, Feng Jiang, Haizhou Li",
      "institution": "The Chinese University of Hong Kong, Shenzhen; Shenzhen University of Advanced Technology; National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.21715",
      "code": null,
      "tags": [
        "dialogue systems",
        "theme detection",
        "topic clustering",
        "hierarchical generation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da012bcf7b19d126b0f1a64e4fc67ee4a82a999c3d110d6b449ab0c750d9458e_w640_q70.webp",
      "contributions": "1. A context-aware topic representation method that enriches utterance semantics using surrounding topic segments. 2. A preference-guided topic clustering mechanism that jointly models semantic proximity and personalized feedback for cross-dialogue theme alignment. 3. A hierarchical theme generation mechanism designed to suppress noise and produce robust, coherent topic labels.",
      "summary": "The paper proposes CATCH, a framework for controllable theme detection in dialogues, which integrates contextualized clustering and hierarchical generation to address sparse utterances and user preference alignment. It demonstrates effectiveness on the DSTC-12 benchmark using an 8B LLM for both clustering and label generation quality.",
      "mindmap": "graph TB\n        Root[CATCH: 可控主题检测框架 / Controllable Theme Detection Framework] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题 / Problem] --> P1[短话语稀疏语义 / Sparse, short utterances]\n        Problem --> P2[跨对话主题对齐 / Cross-dialogue theme alignment]\n        Problem --> P3[用户偏好整合 / Personalized user preferences]\n        Method[主要方法 / Method] --> M1[上下文感知主题表示 / Context-aware topic representation]\n        Method --> M2[偏好引导主题聚类 / Preference-guided topic clustering]\n        Method --> M3[分层主题生成 / Hierarchical theme generation]\n        Results[关键结果 / Results] --> R1[在DSTC-12基准测试有效 / Effective on DSTC-12 benchmark]\n        Results --> R2[提升聚类与生成质量 / Improved clustering & generation quality with 8B LLM]"
    },
    {
      "title": "An Information Theoretic Perspective on Agentic System Design",
      "authors": "Shizhe He, Avanika Narayan, Ishan S. Khare, Scott W. Linderman, Christopher Ré, Dan Biderman",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2512.21720",
      "code": null,
      "tags": [
        "agent system",
        "mutual information",
        "noisy channel",
        "compressor-predictor",
        "on-device AI",
        "information-theoretic"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124535642e159e8f7a123525ffbf3cb5f163a7ae4a7876a4d1e71e7e6c885ace_w640_q70.webp",
      "contributions": "1. Proposes an information-theoretic framework for analyzing agentic LM systems, viewing the compressor as a noisy channel. 2. Introduces a task-independent estimator of mutual information between context and compression to quantify compression quality. 3. Empirically demonstrates that scaling compressor models is more effective than scaling predictors for performance and cost, enabling efficient on-device compression.",
      "summary": "The paper addresses the ad-hoc design of agentic LM systems that use a compressor LM to summarize context for a predictor LM. It proposes an information-theoretic framework using mutual information to evaluate compressors, finding that larger compressors are more accurate, concise, and information-dense, making scaling compressors more effective than scaling predictors for cost-efficient performance.",
      "mindmap": "graph TB\n        A[An Information Theoretic Perspective on Agentic System Design] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1(”Agentic系统设计缺乏理论指导<br/>Agentic system design lacks theoretical guidance”)\n        C --> C1(”提出信息论框架与互信息估计器<br/>Propose information-theoretic framework & mutual information estimator”)\n        D --> D1(”更大压缩器更高效、更准确<br/>Larger compressors are more efficient and accurate”)\n        D --> D2(”扩展压缩器优于扩展预测器<br/>Scaling compressors outperforms scaling predictors”)"
    },
    {
      "title": "Ara-HOPE: Human-Centric Post-Editing Evaluation for Dialectal Arabic to Modern Standard Arabic Translation",
      "authors": "Abdullah Alabdullah, Lifeng Han, Chenghua Lin",
      "institution": "University of Edinburgh, University of Manchester, Leiden University Medical Center (LUMC) / Leiden University",
      "link": "https://arxiv.org/pdf/2512.21787",
      "code": null,
      "tags": [
        "machine translation",
        "dialectal arabic",
        "modern standard arabic",
        "post-editing evaluation",
        "error taxonomy",
        "human evaluation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81517a8ae79cb17e9997772074cacae30aa2d04d3b344341b5fa0c68a1bc551b_w640_q70.webp",
      "contributions": "1. Introduces Ara-HOPE, a human-centric post-editing evaluation framework specifically designed for Dialectal Arabic to Modern Standard Arabic (DA-MSA) translation. 2. Proposes a five-category error taxonomy and a decision-tree annotation protocol to systematically identify dialect-specific translation errors. 3. Provides a comparative evaluation of three MT systems (Jais, GPT-3.5, NLLB-200), highlighting persistent challenges like dialect-specific terminology and semantic preservation.",
      "summary": "This paper addresses the challenge of evaluating machine translation from Dialectal Arabic (DA) to Modern Standard Arabic (MSA), where existing metrics fail to capture dialect-specific errors. It proposes Ara-HOPE, a human-centric post-editing evaluation framework with a specialized error taxonomy and annotation protocol. The framework's application reveals that dialect-specific terminology and semantic preservation are the most persistent challenges for current MT systems.",
      "mindmap": "graph TB\n        Root[Ara-HOPE: Human-Centric Post-Editing Evaluation for Dialectal Arabic to Modern Standard Arabic Translation] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: DA-MSA翻译评估困难 / DA-MSA Translation Evaluation is Difficult]\n        Method[主要方法/Method: 提出Ara-HOPE框架 / Proposes Ara-HOPE Framework]\n        Results[关键结果/Results: 方言术语和语义保留是主要挑战 / Dialect Terminology & Semantic Preservation are Key Challenges]"
    },
    {
      "title": "Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning",
      "authors": "Ting-Hao K.Huang, Ryan A. Rossi, Sungchul Kim, Tong Yu, Ting-Yao E. Hsu, Ho Yin, C. Lee Giles",
      "institution": "The Pennsylvania State University, Adobe Research",
      "link": "https://arxiv.org/pdf/2512.21789",
      "code": null,
      "tags": [
        "image captioning",
        "scientific figure captioning",
        "large-scale dataset",
        "domain-specific training",
        "human evaluation",
        "large language models (LLMs)"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp",
      "contributions": "1. Creation and continuous updating of a large-scale, real-world dataset of scientific figure-caption pairs from arXiv papers. 2. Conducting extensive evaluations, both automatic and human, on generated and author-written captions to assess quality. 3. Developing interactive systems and launching annual challenges to advance the field and help scientists write better captions.",
      "summary": "This paper reviews the SciCap project's first five years, which focused on generating and evaluating captions for scientific figures. The core method involved building a large-scale dataset from arXiv and exploring domain-specific training, similar to models like SciBERT, for captioning. The conclusion outlines key lessons learned and proposes future research directions to address unsolved challenges in the field.",
      "mindmap": "graph TB\n        Root[Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[科学图表说明质量差/Poor quality of scientific figure captions]\n        Problem --> P2[缺乏大规模真实数据集/Lack of large-scale real-world dataset]\n        Method --> M1[构建arXiv图表-说明对数据集/Construct arXiv figure-caption dataset]\n        Method --> M2[领域特定训练与评估/Domain-specific training & evaluation]\n        Method --> M3[应对大语言模型兴起/Navigate rise of LLMs]\n        Results --> R1[总结技术方法经验/Summarize technical & methodological lessons]\n        Results --> R2[提出未来挑战与方向/Outline future challenges & directions]"
    },
    {
      "title": "On The Conceptualization and Societal Impact of Cross-Cultural Bias",
      "authors": "Vitthal Bhandari",
      "institution": "University of Washington",
      "link": "https://arxiv.org/pdf/2512.21809",
      "code": null,
      "tags": [
        "bias and fairness",
        "cultural bias",
        "literature survey",
        "societal impact",
        "harm evaluation",
        "bias mitigation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2702d319a8125ee471012d7f7a71a4d4530da34216397d1647aba76a8e4a3842_w640_q70.webp",
      "contributions": "1. Conducts a focused survey of 20 recent (2025) papers on cultural bias in NLP, identifying gaps in current research practices. 2. Critiques the literature for lacking concrete definitions of bias, failing to identify affected stakeholders, and inadequately evaluating the harms of biased systems. 3. Advocates for a future research agenda that emphasizes robust societal impact assessment, concrete bias conceptualization, and engagement with real-world stakeholders.",
      "summary": "This paper surveys recent literature on cultural bias in NLP, finding that current research often fails to concretely define bias, engage with affected stakeholders, or thoroughly evaluate societal harms. The author proposes a set of observations to guide future work towards more robust and impactful assessments of cross-cultural bias in language technologies.",
      "mindmap": "graph TB\n    Root(”On The Conceptualization and Societal Impact of Cross-Cultural Bias”) --> Problem(”核心问题/Problem: LLMs exhibit cross-cultural bias; research often avoids real-world stakeholder engagement.”)\n    Root --> Method(”主要方法/Method: Survey and analyze 20 recent (2025) papers on cultural bias in NLP.”)\n    Root --> Results(”关键结果/Results: Identifies gaps in bias definition, harm evaluation; advocates for robust societal impact assessment.”)"
    },
    {
      "title": "Method Decoration (DeMe): A Framework for LLM-Driven Adaptive Method Generation in Dynamic IoT Environments",
      "authors": "Hong Su",
      "institution": "Chengdu University of Information Technology",
      "link": "https://arxiv.org/pdf/2512.21817",
      "code": null,
      "tags": [
        "agent system",
        "method decoration",
        "large language models",
        "adaptive method generation",
        "IoT intelligence",
        "on-device reasoning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c4e12db053492542eb54d5fe131cf8b2ac404f1af94254b9d2abeed75d055a7_w640_q70.webp",
      "contributions": "1. Proposes the Method Decoration (DeMe) framework, a novel approach that modifies an LLM's method-generation path using explicit, non-hardcoded decorations derived from hidden goals, learned methods, and environmental feedback. 2. Formalizes two major categories of decorations (whole-process and step-level) and mechanisms (pre-decoration, post-decoration, etc.) to enable context-aware and adaptive method reshaping. 3. Demonstrates experimentally that the framework allows IoT devices to generate more appropriate methods in unknown or faulty operating conditions without modifying the underlying LLM's internal weights.",
      "summary": "The paper addresses the problem that LLM-driven IoT devices struggle to adapt to novel situations due to fixed, pre-trained models. It proposes the Method Decoration (DeMe) framework, which augments an LLM's reasoning path with contextual decorations from experience and environment to generate adaptive methods. Experimental results show DeMe enables devices to derive more appropriate methods for unseen or faulty conditions.",
      "mindmap": "graph TB\n        A[”Method Decoration (DeMe): A Framework for LLM-Driven Adaptive Method Generation in Dynamic IoT Environments”] --> B[”核心问题/Problem: LLMs in IoT lack adaptability to unseen situations and rely on fixed logic.”]\n        A --> C[”主要方法/Method: DeMe framework modifies LLM method-generation using decorations from goals, experience, and feedback.”]\n        A --> D[”关键结果/Results: Enables derivation of more appropriate methods for unknown/faulty conditions.”]"
    },
    {
      "title": "Knowledge Reasoning of Large Language Models Integrating Graph-Structured Information for Pest and Disease Control in Tobacco",
      "authors": "Siyu Li, Chenwei Song, Wan Zhou, Xinyi Liu",
      "institution": "Chongqing Jiaotong University",
      "link": "https://arxiv.org/pdf/2512.21837",
      "code": null,
      "tags": [
        "knowledge-augmented reasoning",
        "GraphRAG",
        "Knowledge Graph",
        "Graph Neural Network",
        "LoRA",
        "ChatGLM"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85aaa4f0b61b3033af1966c2105126130730ca9d346945b5a0ca02e3f706eb1a_w640_q70.webp",
      "contributions": "1. Proposes an LLM-based approach integrating a domain-specific knowledge graph for reasoning in tobacco pest and disease control, built upon the GraphRAG framework. 2. Employs a GNN to learn expressive node representations that capture relational information within the knowledge graph, enhancing the model's reasoning capability. 3. Demonstrates effective parameter-efficient fine-tuning of a ChatGLM backbone using LoRA, achieving superior performance in complex reasoning scenarios like multi-hop and comparative reasoning.",
      "summary": "This paper proposes a method that enhances large language models for agricultural knowledge reasoning by integrating graph-structured information. It constructs a tobacco pest and disease knowledge graph, uses a GNN to learn node representations, and fine-tunes a ChatGLM model with LoRA. The approach outperforms baselines, significantly improving reasoning accuracy and depth, especially in complex scenarios.",
      "mindmap": "graph TB\n    A[Knowledge Reasoning of LLMs Integrating Graph Information for Tobacco Pest Control<br>LLM集成图信息的烟草病虫害知识推理] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[传统方法依赖专家经验，效率低、错误率高<br>Traditional methods rely on expert experience, low efficiency & high error]\n    C --> C1[基于GraphRAG框架，构建烟草病虫害知识图谱<br>Built on GraphRAG, construct tobacco pest/disease KG]\n    C --> C2[使用GNN学习图谱节点表示，ChatGLM+LoRA微调<br>Use GNN for node representations, fine-tune ChatGLM with LoRA]\n    D --> D1[在多指标上超越基线方法<br>Outperforms baselines across multiple metrics]\n    D --> D2[显著提升复杂推理（多跳、比较）的准确性和深度<br>Significantly improves accuracy & depth in complex reasoning]"
    },
    {
      "title": "AlignAR: Generative Sentence Alignment for Arabic-English Parallel Corpora of Legal and Literary Texts",
      "authors": "Baorong Huang, Ali Asiri",
      "institution": "Huaihua University, Umm al-Qura University",
      "link": "https://arxiv.org/pdf/2512.21842",
      "code": "https://github.com/XXX",
      "tags": [
        "machine translation",
        "sentence alignment",
        "parallel corpora",
        "Arabic-English",
        "legal texts",
        "large language models (LLMs)"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f00c37d022ef71644588277bad96472223331ff4180059a6a3d353133f3a205_w640_q70.webp",
      "contributions": "1. Proposed AlignAR, a generative sentence alignment method for Arabic-English parallel corpora. 2. Introduced a new dataset of complex legal and literary texts, featuring a \"Hard\" subset with reduced one-to-one mappings to better evaluate alignment methods. 3. Developed a hybrid LLM-plus-human-validation workflow and a bilingual annotation tool for creating gold-standard alignments.",
      "summary": "This paper addresses the scarcity of high-quality Arabic-English parallel corpora by proposing AlignAR, a generative sentence alignment method. The method, along with a new dataset of complex legal and literary texts, demonstrates that LLM-based approaches are more robust than traditional methods, achieving an 85.5% F1-score and a 9% improvement.",
      "mindmap": "graph TB\n        A[AlignAR: Generative Sentence Alignment for Arabic-English Parallel Corpora of Legal and Literary Texts] --> B[核心问题/Problem: Arabic-English parallel corpora are scarce and lack complex mappings]\n        A --> C[主要方法/Method: Proposes AlignAR, a generative sentence alignment method using LLMs and a new dataset]\n        A --> D[关键结果/Results: LLM-based methods show superior robustness, achieving 85.5% F1-score, a 9% improvement]"
    },
    {
      "title": "HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs",
      "authors": "Jiaxin Liu, Peiyi Tu, Wenyu Chen, Yihong Zhuang, Xinxia Ling, Anji Zhou, Chenxi Wang, Zhuo Han, Zhengkai Yang, Junbo Zhao, Zenan Huang, Yuanyuan Wang",
      "institution": "Ant Group, Xiamen University, Beijing Normal University, Zhejiang University",
      "link": "https://arxiv.org/pdf/2512.21849",
      "code": "https://github.com/inclusionAI/HeartBench",
      "tags": [
        "evaluation",
        "anthropomorphic intelligence",
        "benchmark",
        "psychological counseling",
        "rubric-based evaluation",
        "reasoning-before-scoring"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dc9f1570e111d07840de8240e6e5f545f05ae646e05a5121a0a6c4037e3637a_w640_q70.webp",
      "contributions": "1. Introduces HeartBench, a novel benchmark framework for evaluating the integrated emotional, cultural, and ethical dimensions (anthropomorphic intelligence) of Chinese LLMs. 2. Proposes a theory-driven taxonomy and a case-specific, rubric-based \"reasoning-before-scoring\" evaluation protocol to translate abstract human-like traits into measurable criteria. 3. Provides an analysis revealing a significant performance gap in current LLMs, especially in scenarios with subtle emotional subtexts and complex ethical trade-offs, establishing a standardized metric and a blueprint for creating human-aligned training data.",
      "summary": "The paper addresses the gap in evaluating the social and emotional intelligence (anthropomorphic intelligence) of LLMs, particularly in the Chinese context. It proposes HeartBench, a benchmark framework grounded in psychological counseling scenarios, which uses a rubric-based evaluation method. The assessment of 13 LLMs shows a substantial performance ceiling, with even top models achieving only 60% of the expert ideal, highlighting significant decay in handling complex emotional and ethical nuances.",
      "mindmap": "graph TB\n        A[HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLMs缺乏拟人化智能 / LLMs lack anthropomorphic intelligence]\n        B --> B2[中文语境缺乏评估框架 / Lack of evaluation frameworks in Chinese context]\n        C --> C1[基于心理咨询场景的基准 / Benchmark based on psychological counseling scenarios]\n        C --> C2[理论驱动的分类法 / Theory-driven taxonomy]\n        C --> C3[基于量规的推理评分法 / Rubric-based reasoning-before-scoring]\n        D --> D1[模型性能存在上限 / Performance ceiling in models]\n        D --> D2[复杂场景表现显著下降 / Significant decay in complex scenarios]"
    },
    {
      "title": "TimeBill: Time-Budgeted Inference for Large Language Models",
      "authors": "Qi Fan, An Zou, Yehan Ma",
      "institution": "Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.21859",
      "code": null,
      "tags": [
        "llm inference",
        "time-budgeted inference",
        "KV cache eviction",
        "response length prediction",
        "execution time estimation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a21a4204d1665c895b35788196ab3a0e5b32216d06abc37bfaaa9aefac4cb2f5_w640_q70.webp",
      "contributions": "1. Proposed a fine-grained response length predictor (RLP) and an execution time estimator (ETE) for accurate end-to-end LLM inference time modeling. 2. Developed a time-budgeted efficient inference approach that adaptively adjusts the KV cache eviction ratio based on predicted execution time and a given time budget. 3. Demonstrated through experiments that TimeBill improves task completion rate and maintains response performance under various time constraints.",
      "summary": "The paper proposes TimeBill, a framework for performing LLM inference within a strict time budget. It uses predictors to estimate response length and execution time, then dynamically adjusts the KV cache eviction ratio to meet deadlines while preserving output quality. Experiments show it improves task completion rates and maintains performance compared to fixed strategies.",
      "mindmap": "graph TB\n        A[TimeBill: Time-Budgeted Inference for Large Language Models] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM推理时间不确定/Uncertain LLM Inference Time]\n        B --> B2[固定KV缓存策略不灵活/Fixed KV Cache Strategy Inflexible]\n        C --> C1[响应长度预测器 (RLP)/Response Length Predictor (RLP)]\n        C --> C2[执行时间估计器 (ETE)/Execution Time Estimator (ETE)]\n        C --> C3[自适应KV缓存驱逐/Adaptive KV Cache Eviction]\n        D --> D1[提高任务完成率/Improves Task Completion Rate]\n        D --> D2[保持响应性能/Maintains Response Performance]"
    },
    {
      "title": "Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?",
      "authors": "Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji",
      "institution": "Zhejiang University, University of California, Los Angeles, Palo Alto Networks",
      "link": "https://arxiv.org/pdf/2512.21871",
      "code": "https://github.com/bluedream02/CopyGuard",
      "tags": [
        "multi-modal inference",
        "copyright compliance",
        "vision-language models",
        "tool-augmented defense",
        "benchmark dataset",
        "multimodal query"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp",
      "contributions": "1. Introduced a large-scale benchmark dataset of 50,000 multimodal query-content pairs to evaluate copyright compliance in LVLMs. 2. Conducted a comprehensive evaluation revealing significant deficiencies in state-of-the-art LVLMs' ability to recognize and respect copyrighted content. 3. Proposed a novel tool-augmented defense framework to reduce copyright infringement risks in LVLM inference.",
      "summary": "This paper evaluates how large vision-language models (LVLMs) handle copyrighted visual content and finds they often fail to comply with copyright regulations. To address this, the authors propose a tool-augmented defense framework for copyright compliance. The work highlights the need for developing copyright-aware LVLMs to ensure responsible use.",
      "mindmap": "graph TB\n        Root[”Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?”]\n        Root --> Problem[”核心问题/Problem: LVLMs may infringe copyright when processing visual inputs”]\n        Root --> Method[”主要方法/Method: Benchmark dataset & Tool-augmented defense framework”]\n        Root --> Results[”关键结果/Results: Current LVLMs are deficient; Proposed framework reduces risk”]"
    },
    {
      "title": "CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics",
      "authors": "Vaibhav Devraj, Dhruv Kumar, Jagat Sesh Challa",
      "institution": "Birla Institute of Technology and Science (BITS), Pilani",
      "link": "https://arxiv.org/pdf/2512.21877",
      "code": null,
      "tags": [
        "text-to-sql",
        "benchmark",
        "multilingual",
        "domain-specific",
        "large language models",
        "sports analytics"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd335127a490c2b4b59330fd1867a57551c792f1b695f15e48789a3992b7c05a_w640_q70.webp",
      "contributions": "1. Introduces CricBench, a novel benchmark for evaluating LLMs on Text-to-SQL tasks in the specialized domain of cricket analytics. 2. Establishes a multilingual framework, providing a \"Gold Standard\" dataset in both English and Hindi, with extensibility to other languages. 3. Demonstrates a significant performance gap for LLMs between general and specialized domains and challenges the assumption of English as the optimal prompt language for such tasks.",
      "summary": "This paper introduces CricBench, a multilingual benchmark for evaluating Large Language Models on Text-to-SQL tasks in the specialized domain of cricket analytics. The benchmark features a manually curated dataset in English and Hindi and is used to evaluate six state-of-the-art models. The results show that high performance on general benchmarks does not transfer well to this specialized domain, and surprisingly, code-mixed Hindi queries can perform as well as or better than English ones.",
      "mindmap": "graph TB\n        A[CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs在专业领域Text-to-SQL能力未充分探索/LLMs' Text-to-SQL capability in specialized domains is under-explored]\n        B --> B2[现有基准缺乏多语言和体育分析特性/Existing benchmarks lack multilingual and sports analytics features]\n        C --> C1[构建板球领域专业多语言基准/Build a specialized multilingual benchmark for cricket]\n        C --> C2[与专家合作创建”黄金标准”查询/Collaborate with experts to create ”Gold Standard” queries]\n        C --> C3[评估六个最先进的LLMs/Evaluate six state-of-the-art LLMs]\n        D --> D1[专业领域性能显著下降/Significant performance drop in specialized domain]\n        D --> D2[DeepSeek R1表现最佳/DeepSeek R1 achieves SOTA]\n        D --> D3[印地语查询准确率可比或更高/Hindi queries yield parity or higher accuracy]"
    },
    {
      "title": "Explainable Statute Prediction via Attention-based Model and LLM Prompting",
      "authors": "Sachin Pawar, Girish Keshav Palshikar, Anindita Sinha Banerjee, Nitin Ramrakhiyani, Basit Ali",
      "institution": "TCS Research, Tata Consultancy Services Limited",
      "link": "https://arxiv.org/pdf/2512.21902",
      "code": null,
      "tags": [
        "legal text processing",
        "statute prediction",
        "explainable AI",
        "attention mechanism",
        "large language models",
        "chain-of-thought prompting"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0a88ac95c85beb5da693179a57fced56221862f49b2b3f82a7923e814deb844_w640_q70.webp",
      "contributions": "1. Proposes AoS, an attention-based supervised model using sentence transformers for explainable statute prediction. 2. Proposes LLMPrompt, a zero-shot method using large language models with standard and Chain-of-Thought prompting for prediction and explanation. 3. Evaluates both prediction performance and explanation quality across two datasets using automated and human evaluation methods.",
      "summary": "This paper tackles the problem of automatically predicting relevant legal statutes from case descriptions and providing human-understandable explanations. It proposes two methods: a supervised attention-based model (AoS) and a zero-shot LLM prompting approach (LLMPrompt). The study compares their prediction performance against baselines and evaluates the quality of the generated explanations.",
      "mindmap": "graph TB\n        Root[”Explainable Statute Prediction via Attention-based Model and LLM Prompting<br>基于注意力模型和LLM提示的可解释法规预测”] --> Problem[”核心问题/Problem<br>Automatic prediction of relevant statutes from case descriptions with explanations<br>从案例描述中自动预测相关法规并提供解释”]\n        Root --> Method[”主要方法/Method<br>Two proposed techniques: AoS (supervised attention) and LLMPrompt (zero-shot LLM prompting)<br>两种方法: AoS(监督注意力)和LLMPrompt(零样本LLM提示)”]\n        Root --> Results[”关键结果/Results<br>Comparison of prediction performance and evaluation of explanation quality<br>比较预测性能并评估解释质量”]"
    },
    {
      "title": "Accelerate Speculative Decoding with Sparse Computation in Verification",
      "authors": "Jikai Wang, Jianchao Tan, Yuxuan Hu, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Juntao Li, Min Zhang",
      "institution": "Soochow University, Meituan",
      "link": "https://arxiv.org/pdf/2512.21911",
      "code": null,
      "tags": [
        "llm inference",
        "speculative decoding",
        "sparse computation",
        "verification stage",
        "mixture-of-experts (MoE)",
        "efficiency-accuracy trade-off"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp",
      "contributions": "1. Systematically analyzes and identifies structured computational redundancy across attention, FFN, and MoE components during the verification stage of speculative decoding. 2. Proposes a sparse verification framework that jointly sparsifies these components to reduce the dominant computation cost. 3. Introduces an inter-draft token and inter-layer retrieval reuse strategy to further reduce redundant computation without additional training.",
      "summary": "This paper addresses the computational bottleneck in the verification stage of speculative decoding for LLMs, especially for long-context and MoE models. It proposes a framework that applies sparse computation techniques to the verification stage and employs a retrieval reuse strategy to reduce redundant calculations. Experiments show the method achieves a favorable efficiency-accuracy trade-off while maintaining stable acceptance length.",
      "mindmap": "graph TB\n        A[Accelerate Speculative Decoding with Sparse Computation in Verification] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[验证阶段成为瓶颈/Verification stage is bottleneck]\n        B1 --> B2[长上下文与MoE模型/Long-context & MoE models]\n        C --> C1[稀疏验证框架/Sparse Verification Framework]\n        C1 --> C2[联合稀疏化注意力、FFN、MoE/Jointly sparsifies Attention, FFN, MoE]\n        C1 --> C3[检索重用策略/Retrieval Reuse Strategy]\n        D --> D1[有利的效率-精度权衡/Favorable efficiency-accuracy trade-off]\n        D --> D2[稳定的接受长度/Stable acceptance length]"
    },
    {
      "title": "SWE-RM: Execution-free Feedback For Software Engineering Agents",
      "authors": "KaShun Shum, Binyuan Hui, Jiawei Chen, Lei Zhang, X. W., Jiaxi Yang, Yuzhen Huang, Junyang Lin, Junxian He",
      "institution": "The Hong Kong University of Science and Technology, Alibaba Group (Qwen Team)",
      "link": "https://arxiv.org/pdf/2512.21919",
      "code": null,
      "tags": [
        "software engineering agents",
        "reward model",
        "test-time scaling",
        "reinforcement learning",
        "mixture-of-experts",
        "SWE-Bench"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp",
      "contributions": "1. Identified that high TTS performance does not guarantee effective RL training, and introduced classification accuracy and calibration as crucial metrics for robust reward models. 2. Conducted comprehensive experiments to analyze factors (data scale, policy mixtures, data source) impacting reward model training for SWE agents. 3. Proposed SWE-RM, a large-scale mixture-of-experts reward model that significantly improves agent performance on both TTS and RL, achieving new SOTA on SWE-Bench Verified.",
      "summary": "The paper addresses the limitations of execution-based feedback for software engineering agents by proposing an execution-free reward model. It introduces SWE-RM, a robust reward model trained with insights from controlled experiments, which substantially improves agent performance on both test-time scaling and reinforcement learning, setting a new state-of-the-art on the SWE-Bench benchmark.",
      "mindmap": "graph TB\n        Root[”SWE-RM: Execution-free Feedback For Software Engineering Agents”] --> Problem[”核心问题/Problem”]\n        Root --> Method[”主要方法/Method”]\n        Root --> Results[”关键结果/Results”]\n        Problem --> P1[”执行反馈的局限性/Limitations of Execution-based Feedback”]\n        Problem --> P2[”无执行反馈未被充分探索/Execution-free Feedback Underexplored”]\n        Method --> M1[”识别RL关键指标/Identify Key RL Metrics (Accuracy, Calibration)”]\n        Method --> M2[”可控实验分析/Controlled Experiments on Training Factors”]\n        Method --> M3[”提出SWE-RM模型/Propose SWE-RM (MoE Reward Model)”]\n        Results --> R1[”提升TTS性能/Improves TTS Performance (e.g., Qwen3-Coder-Max to 74.6%)”]\n        Results --> R2[”提升RL性能/Improves RL Performance (+3 points)”]\n        Results --> R3[”开源模型SOTA/New SOTA Among Open-Source Models”]"
    },
    {
      "title": "Broken Words, Broken Performance: Effect of Tokenization on Performance of LLMs",
      "authors": "Sachin Pawar, Manoj Apte, Kshitij Jadhav, Girish Keshav Palshikar, Nitin Ramrakhiyani",
      "institution": "TCS Research, Tata Consultancy Services Limited",
      "link": "https://arxiv.org/pdf/2512.21933",
      "code": null,
      "tags": [
        "tokenization",
        "tokenization penalty",
        "large language models",
        "byte-pair encoding",
        "vocabulary size",
        "natural word splitting"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/015399929e56260633eb709a56e41948acd324ce4065b0fcb286daa6d5ea6e33_w640_q70.webp",
      "contributions": "1. Proposes the hypothesis that breaking natural words into multiple tokens negatively impacts LLM performance on NLP tasks. 2. Introduces a set of penalty functions to quantify the \"badness\" of tokenization for a given text and LLM. 3. Establishes the statistical significance of the hypothesis across multiple NLP tasks and different LLMs.",
      "summary": "This paper investigates how tokenization, specifically the splitting of natural words into multiple sub-tokens due to limited vocabulary, affects the performance of Large Language Models (LLMs). The authors propose penalty functions to measure this tokenization effect and demonstrate its statistically significant negative impact on various NLP tasks.",
      "mindmap": "graph TB\n        A[Broken Words, Broken Performance: Effect of Tokenization on Performance of LLMs] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM分词将自然词拆分为多个子词/LLM tokenization splits natural words into multiple sub-tokens]\n        B --> B2[假设这会损害模型性能/Hypothesized to hurt model performance]\n        C --> C1[提出量化分词影响的惩罚函数/Propose penalty functions to quantify tokenization effect]\n        D --> D1[在多任务和多模型上验证假设的显著性/Validate hypothesis significance on multiple tasks & models]"
    },
    {
      "title": "Self-attention vector output similarities reveal how machines pay attention",
      "authors": "Tal Halevi, Yarden Tzach, Ronit D. Gross, Shalom Rosner, Ido Kanter",
      "institution": "Bar-Ilan University",
      "link": "https://arxiv.org/pdf/2512.21956",
      "code": null,
      "tags": [
        "attention mechanisms",
        "self-attention",
        "BERT",
        "attention heads",
        "vector similarity",
        "token representation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ef3aef5be4139745b138137e89a3f21de053bd91a9fedbe345ad6f90900a98b_w640_q70.webp",
      "contributions": "1. Introduced a new method for quantifying information processing within the self-attention mechanism using a context similarity matrix derived from token vectors. 2. Revealed that different attention heads specialize in distinct linguistic features, such as identifying token repetitions or common contextual tokens. 3. Demonstrated a progression from long-range to short-range token similarities across layers, culminating in a focus on intra-sentence relationships and unique token-centric similarity patterns in final layers.",
      "summary": "This paper proposes a novel approach to analyze the self-attention mechanism in transformer models by examining vector output similarities. The analysis on BERT-12 shows that attention heads specialize in different linguistic features and that similarity patterns evolve from long-range to short-range, focusing on sentence-level structures in deeper layers.",
      "mindmap": "graph TB\n        Root[”Self-attention vector output similarities reveal how machines pay attention<br/>自注意力向量输出相似性揭示机器如何关注”] --> Problem[”核心问题/Problem: Quantitative characterization of self-attention learning process<br/>自注意力学习过程的定量表征”]\n        Root --> Method[”主要方法/Method: Context similarity matrix from self-attention head vectors<br/>基于自注意力头向量的上下文相似性矩阵”]\n        Root --> Results[”关键结果/Results: Heads specialize linguistically; similarity shifts from long to short range<br/>头部语言专业化;相似性从长程转向短程”]"
    },
    {
      "title": "Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management",
      "authors": "Sunil Arora, John Hastings",
      "institution": "Dakota State University",
      "link": "https://arxiv.org/pdf/2512.22060",
      "code": null,
      "tags": [
        "AI Governance & Compliance",
        "lifecycle management",
        "bias detection",
        "differential privacy",
        "federated learning",
        "terminology drift"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/113703d05215aac7e8678f24cb38d882fa4c99927066ea2264ef3d1b4c3a1d67_w640_q70.webp",
      "contributions": "1. Proposes the SC-NLP-LMF, a comprehensive six-phase framework for secure and compliant NLP model lifecycle management. 2. Integrates established technical methods (e.g., bias detection, differential privacy) with leading organizational standards (e.g., NIST AI RMF, EU AI Act). 3. Validates the framework's practicality through a healthcare case study demonstrating detection of and response to terminology drift.",
      "summary": "This paper introduces the Secure and Compliant NLP Lifecycle Management Framework (SC-NLP-LMF), a six-phase model developed from a systematic review to address security, privacy, and compliance risks in NLP systems. It integrates methods like bias detection and differential privacy with standards like NIST AI RMF and the EU AI Act. The framework provides a practical structure for organizations to manage NLP systems in high-risk environments, as illustrated by a healthcare case study on handling terminology drift.",
      "mindmap": "graph TB\n        Root[”Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>NLP systems in sensitive domains face unaddressed security, privacy, and compliance risks.”]\n        Method[”主要方法/Method<br>Proposes SC-NLP-LMF, a six-phase framework integrating standards (NIST, ISO, EU AI Act) and techniques (bias detection, differential privacy).”]\n        Results[”关键结果/Results<br>Provides a practical lifecycle structure for secure, accountable NLP systems, validated via a healthcare case study.”]"
    },
    {
      "title": "Context as a Tool: Context Management for Long-Horizon SWE-Agents",
      "authors": "Shukai Liu, Jian Yang, Bo Jiang, Yizhi Li, Jinyang Guo, Xianglong Liu, Bryan Dai",
      "institution": "Beihang University, University of Manchester, Ubiquant",
      "link": "https://arxiv.org/pdf/2512.22087",
      "code": null,
      "tags": [
        "agent system",
        "context management",
        "long-horizon reasoning",
        "SWE-agents",
        "trajectory compression",
        "structured workspace"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/554c080cfd26463c6d73be16144f677075ea893401e3c8ae26ee7321c48b2be8_w640_q70.webp",
      "contributions": "1. Proposes CAT, a new paradigm that treats context management as an integrated, callable tool for agents, enabling proactive control. 2. Introduces a structured context workspace with stable semantics, condensed long-term memory, and high-fidelity short-term interactions. 3. Presents CAT-GENERATOR, a trajectory-level supervision framework for training the SWE-Compressor model, which achieves state-of-the-art performance on SWE-Bench-Verified.",
      "summary": "The paper addresses the problem of context explosion and semantic drift in long-horizon software engineering agents by proposing CAT, a paradigm that integrates proactive context management as a tool. It introduces a structured workspace and a training framework to produce the SWE-Compressor model. Experiments show this model significantly outperforms existing baselines on a software engineering benchmark while maintaining stable reasoning under a bounded context budget.",
      "mindmap": "graph TB\n        A[Context as a Tool: Context Management for Long-Horizon SWE-Agents] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有代理上下文爆炸、语义漂移/Existing agents suffer context explosion & semantic drift]\n        C --> C1[CAT: 将上下文管理作为可调用工具/CAT: Context management as a callable tool]\n        C --> C2[结构化上下文工作区/Structured context workspace]\n        C --> C3[CAT-GENERATOR 训练框架/CAT-GENERATOR training framework]\n        D --> D1[SWE-Compressor 达到 57.6% 解决率/SWE-Compressor achieves 57.6% solved rate]\n        D --> D2[显著优于基准/Significantly outperforms baselines]"
    },
    {
      "title": "Unifying Learning Dynamics and Generalization in Transformers Scaling Law",
      "authors": "Chiwun Yang",
      "institution": "Sun Yat-sen University",
      "link": "https://arxiv.org/pdf/2512.22088",
      "code": null,
      "tags": [
        "learning theory",
        "scaling law",
        "learning dynamics",
        "generalization error",
        "transformer",
        "stochastic gradient descent"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9b067b56202cd4607e684058e78ac331373bf12bf6848ca444276e2dcafe9f9_w640_q70.webp",
      "contributions": "1. Formalizes the learning dynamics of transformers as an ODE system and approximates it to kernel behaviors, moving beyond toy models to analyze SGD on multi-layer transformers with arbitrary data distributions. 2. Establishes a theoretical upper bound on excess risk with a distinct phase transition: exponential decay in the optimization phase and a power-law decay of Θ(C^\\{-1/6\\}) in the statistical phase. 3. Derives isolated scaling laws for model size, training time, and dataset size, explaining how each variable independently governs generalization bounds.",
      "summary": "This paper provides a theoretical foundation for the empirical scaling laws of large language models. It models transformer learning dynamics as an ODE system and analyzes SGD training on realistic data. The main result is a unified theory showing a phase transition in generalization error, from exponential to power-law decay, as computational resources scale.",
      "mindmap": "graph TB\n        A[Unifying Learning Dynamics and Generalization in Transformers Scaling Law] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[Scaling Law理论原理不清 / Poorly understood theoretical underpinnings of scaling laws]\n        C --> C1[形式化学习动态为ODE系统 / Formalize learning dynamics as ODE system]\n        C --> C2[近似为核行为 / Approximate to kernel behaviors]\n        C --> C3[分析SGD训练真实Transformer / Analyze SGD training for real transformers]\n        D --> D1[泛化误差上界与相变 / Upper bound on excess risk with phase transition]\n        D --> D2[优化相:指数衰减 / Optimization phase: Exponential decay]\n        D --> D3[统计相:幂律衰减 Θ(C^{-1/6}) / Statistical phase: Power-law decay Θ(C^{-1/6})]\n        D --> D4[分离的规模定律 / Isolated scaling laws for model size, time, data]"
    },
    {
      "title": "Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis",
      "authors": "Duygu Altinok",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.22100",
      "code": null,
      "tags": [
        "benchmark construction",
        "Turkish NLU benchmark",
        "semi-automated annotation",
        "sentiment analysis dataset"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aae4aef01bf4bd7a32414041836c4d9d7383c50872f47bdb0dee4d45af35adb_w640_q70.webp",
      "contributions": "1. Introduces TrGLUE, the first comprehensive GLUE-style benchmark for Turkish Natural Language Understanding, filling a critical gap. 2. Presents SentiTurca, a specialized benchmark for Turkish sentiment analysis. 3. Provides a scalable, reproducible semi-automated dataset creation pipeline combining LLM annotation, cross-model checks, and human validation.",
      "summary": "This paper addresses the lack of a comprehensive benchmark for evaluating Turkish language understanding by introducing TrGLUE and SentiTurca. The benchmarks are created using a semi-automated pipeline with LLM annotation and human validation to ensure quality and linguistic naturalness. The work establishes a robust evaluation framework and provides resources to empower Turkish NLP research.",
      "mindmap": "graph TB\n        A[Introducing TrGLUE and SentiTurca] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[缺乏土耳其语综合基准/Lack of Turkish NLU Benchmark]\n        C --> C1[半自动标注流程/Semi-automated Pipeline]\n        C1 --> C2[LLM标注 + 交叉验证 + 人工校验/LLM Annotation + Cross-check + Human Validation]\n        D --> D1[发布TrGLUE & SentiTurca/Release TrGLUE & SentiTurca]\n        D --> D2[提供代码与资源/Provide Code & Resources]"
    },
    {
      "title": "A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting",
      "authors": "Shuyu Gan, Renxiang Wang, James Mooney, Dongyeop Kang",
      "institution": "University of Minnesota",
      "link": "https://arxiv.org/pdf/2512.22101",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent pipeline",
        "automated data analysis",
        "insight generation",
        "report synthesis",
        "visual analytics"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92651ded84480402816f8db1df902e28dd62cce1b0958cece60e0f518bdd7e1c_w640_q70.webp",
      "contributions": "1. A Data Analyzer agent that orchestrates data profiling, generates diverse visualizations, filters low-quality charts, and automatically scores candidate insights for depth, correctness, and actionability. 2. A Presenter agent that sequences topics, composes chart-grounded narratives from top insights, writes transitions, and revises the document to produce a coherent, publication-ready report. 3. An end-to-end Analyzer-to-Presenter (A2P) pipeline that operationalizes co-analysis by coupling quality-assured analysis with narrative synthesis, improving the real-world usefulness of automated data analysis.",
      "summary": "This paper presents A2P-Vis, a two-part multi-agent pipeline designed to automate the generation of data visualization reports. The system uses a Data Analyzer to create and vet visual insights and a Presenter to assemble them into a coherent narrative. The authors claim this end-to-end approach improves the practical utility of automated data analysis for practitioners.",
      "mindmap": "graph TB\n        A[A2P-Vis] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[自动化数据科学流程的瓶颈/Gaps in automating data science]\n        B1 --> B2[生成有洞察力的可视化/Generating insightful visual evidence]\n        B1 --> B3[组装成专业报告/Assembling coherent professional report]\n        C --> C1[两部分多智能体管道/Two-part multi-agent pipeline]\n        C1 --> C2[数据分析器/Data Analyzer]\n        C2 --> C3[生成并评估图表与洞察/Generates & evaluates charts & insights]\n        C1 --> C4[报告呈现器/Presenter]\n        C4 --> C5[编排主题并撰写叙述/Orders topics & composes narrative]\n        D --> D1[端到端协同分析/End-to-end co-analysis]\n        D1 --> D2[提高自动化数据分析的实用性/Improves usefulness of automated analysis]"
    },
    {
      "title": "MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation",
      "authors": "Chi-Hsiang Hsiao, Yi-Cheng Wang, Tzung-Sheng Lin, Yi-Ren Yeh, Chu-Song Chen",
      "institution": "National Taiwan University, E.SUN Financial Holding Co., Ltd., National Kaohsiung Normal University",
      "link": "https://arxiv.org/pdf/2512.20626",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "multimodal knowledge graph",
        "cross-modal reasoning",
        "visual document understanding",
        "retrieval-augmented generation",
        "entity-centric structure"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/425d6eb853edb40749e686474d27dc018d8a86017a4cd69160f9ac2081d36385_w640_q70.webp",
      "contributions": "1. Proposes a multimodal knowledge graph-based RAG framework that integrates visual cues into KG construction, retrieval, and answer generation for cross-modal reasoning. 2. Addresses the limitation of existing text-only KG-RAG methods by automatically building KGs that capture text-to-figure and figure-to-figure relationships. 3. Demonstrates superior performance over existing RAG approaches on both textual and multimodal question-answering tasks through comprehensive experiments.",
      "summary": "The paper introduces MegaRAG, a multimodal knowledge graph-based retrieval-augmented generation method designed to overcome the limitations of text-only RAG systems in understanding complex, long-form visual documents. It integrates visual information into the knowledge graph construction and retrieval process to enable better cross-modal reasoning. Experimental results show it consistently outperforms existing RAG methods on various question-answering tasks.",
      "mindmap": "graph LR\n        A[MegaRAG: 多模态知识图谱检索增强生成 / MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有RAG方法在长文档、多模态内容上理解不足 / Existing RAG struggles with long-form, multimodal document understanding]\n        C --> C1[构建融合视觉线索的多模态知识图谱 / Construct multimodal KG incorporating visual cues]\n        C --> C2[在多模态检索与生成中利用图谱 / Utilize KG in multimodal retrieval & generation]\n        D --> D1[在全局与细粒度QA任务上超越现有方法 / Outperforms existing methods on global & fine-grained QA]"
    },
    {
      "title": "Zero-Training Temporal Drift Detection for Transformer Sentiment Models: A Comprehensive Analysis on Authentic Social Media Streams",
      "authors": "Aayam Bansal, Ishaan Gangwani",
      "institution": "IEEE",
      "link": "https://arxiv.org/pdf/2512.20631",
      "code": null,
      "tags": [
        "sentiment analysis",
        "temporal drift",
        "zero-training detection",
        "transformer models",
        "social media streams",
        "model instability"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8e40c0a23df847aa858c5e0ce28602f612024103d66ccaea9f9da99a1dded46_w640_q70.webp",
      "contributions": "1. Demonstrated significant temporal drift in transformer sentiment models during real-world events, with accuracy drops up to 23.4% on authentic social media data. 2. Introduced four novel zero-training drift detection metrics that outperform embedding-based baselines and are suitable for production deployment. 3. Provided comprehensive statistical validation on 12,279 authentic social media posts from major events, establishing practical significance exceeding industry monitoring thresholds.",
      "summary": "This paper addresses the problem of temporal drift in transformer-based sentiment models during real-world events without requiring model retraining. It proposes a zero-training detection framework using novel inference-time metrics, validated on authentic social media data. The main conclusion is that this method effectively detects significant model instability and enables immediate deployment for real-time monitoring systems.",
      "mindmap": "graph LR\n    A[Zero-Training Temporal Drift Detection for Transformer Sentiment Models] --> B[核心问题/Problem: Transformer模型在动态事件期间的行为不稳定/Transformer model instability during dynamic events]\n    A --> C[主要方法/Method: 零训练检测框架与四个新指标/Zero-training detection framework with four novel metrics]\n    A --> D[关键结果/Results: 在真实数据上验证，准确率下降达23.4%，检测能力强/Validated on authentic data, 23.4% accuracy drop, strong detection capability]"
    },
    {
      "title": "Real Time Detection and Quantitative Analysis of Spurious Forgetting in Continual Learning",
      "authors": "Weiwei Wang",
      "institution": "Shenzhen Sunline Tech Co., Ltd.",
      "link": "https://arxiv.org/pdf/2512.20634",
      "code": null,
      "tags": [
        "llm training",
        "catastrophic forgetting",
        "spurious forgetting",
        "shallow alignment",
        "deep alignment",
        "task alignment depth"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2920732eeec32977638a62ffbcf4b4b075dbdd77ebc58fa777ff8a10e117219_w640_q70.webp",
      "contributions": "1. Introduced a quantitative framework (shallow vs. deep alignment) to measure task alignment depth across token positions. 2. Developed real-time detection methods and analysis tools for identifying shallow alignment and spurious forgetting during training. 3. Proposed adaptive mitigation strategies that automatically distinguish forgetting types and promote deep alignment to improve model robustness.",
      "summary": "This paper addresses catastrophic forgetting in continual learning for LLMs by identifying that performance drops are often due to \"spurious forgetting\" from shallow task alignment. The authors propose a framework to quantitatively measure alignment depth, detect shallow alignment in real-time, and apply mitigation strategies to promote deep alignment. Experiments show their method accurately identifies spurious forgetting and improves model robustness against forgetting by 3.3-7.1% over baselines.",
      "mindmap": "graph LR\n    A[Real-Time Detection and Quantitative Analysis of Spurious Forgetting<br/>虚假遗忘的实时检测与定量分析] --> B[核心问题/Problem: Catastrophic forgetting from shallow task alignment<br/>由浅层任务对齐导致的灾难性遗忘]\n    A --> C[主要方法/Method: Quantitative metrics & real-time detection for alignment depth<br/>对齐深度的量化指标与实时检测]\n    A --> D[关键结果/Results: High identification accuracy & improved robustness<br/>高识别准确率与提升的鲁棒性]"
    },
    {
      "title": "Uncovering Competency Gaps in Large Language Models and Their Benchmarks",
      "authors": "Matyas Bohacek, Nino Scherrer, Nicholas Dufour, Thomas Leung, Christoph Bregler, Stephanie C. Y. Chan",
      "institution": "Stanford University, Google DeepMind",
      "link": "https://arxiv.org/pdf/2512.20638",
      "code": "competency-gaps.github.io",
      "tags": [
        "llm evaluation",
        "sparse autoencoders",
        "benchmark gaps",
        "model gaps",
        "concept activations",
        "competency gaps"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6d5ab9e8ede467e65cbc2079e58ecf9b8d8ade8145f7e9e90f1b6f8382e288b_w640_q70.webp",
      "contributions": "1. Proposes a novel method using sparse autoencoders (SAEs) to automatically uncover fine-grained competency gaps in LLMs and benchmarks. 2. Introduces a representation-grounded evaluation approach that computes saliency-weighted performance scores based on model-internal concept activations. 3. Demonstrates the method's ability to identify specific model weaknesses (e.g., non-sycophantic behaviors) and benchmark coverage imbalances (e.g., over-representation of obedience concepts) without manual supervision.",
      "summary": "This paper addresses the problem that aggregated benchmark scores can hide specific weaknesses in LLMs and imbalances in benchmark coverage. The authors propose an automated method using sparse autoencoders to decompose benchmark performance into fine-grained concepts based on the model's internal representations. Their analysis of two models and ten benchmarks revealed model gaps in areas like non-sycophancy and safety, and benchmark gaps such as an over-representation of obedience-related concepts.",
      "mindmap": "graph LR\n        A[Uncovering Competency Gaps<br/>揭示能力差距] --> B[Problem: Aggregated metrics obscure model/benchmark gaps<br/>问题：聚合指标掩盖模型/基准差距]\n        A --> C[Method: Use Sparse Autoencoders (SAEs) for concept-level decomposition<br/>方法：使用稀疏自编码器进行概念级分解]\n        A --> D[Results: Found gaps in non-sycophancy, safety; benchmark over-represents obedience<br/>结果：发现非谄媚、安全方面的差距；基准过度代表服从性]"
    },
    {
      "title": "Automated Red-Teaming Framework for Large Language Model Security Assessment: A Comprehensive Attack Generation and Detection System",
      "authors": "Zhang Wei, Peilu Hu, Shengning Lang, Hao Yan, Li Mei, Yichao Zhang, Chen Yang, Junfeng Hao, Zhimo Han",
      "institution": "Stevens Institute of Technology, The University of Texas at Dallas, AI Safety Research Lab (Institute of Advanced Computing, Shenzhen), Zheng Zhou University of Light Industry, Affiliated Hospital of Guangdong Medical University",
      "link": "https://arxiv.org/pdf/2512.20677",
      "code": null,
      "tags": [
        "llm security assessment",
        "automated red-teaming",
        "adversarial prompts",
        "meta-prompting",
        "vulnerability detection",
        "alignment robustness"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/35d6a91284e231b153dfe35185eb27aafd1549063ba05304240c7a14c0b8f78d_w640_q70.webp",
      "contributions": "1. Introduces an automated framework for systematic generation, execution, and evaluation of adversarial prompts against LLMs. 2. Integrates meta-prompting-based attack synthesis and multi-modal detection across six major threat categories (e.g., reward hacking, deceptive alignment). 3. Demonstrates significant improvement in vulnerability discovery rate (3.9x over manual testing) with high detection accuracy (89%) on a target model.",
      "summary": "This paper proposes an automated red-teaming framework to systematically find security vulnerabilities in large language models. The framework uses meta-prompting to generate attacks and multi-modal detection to evaluate them across six threat categories. Experiments show it discovers vulnerabilities much faster than manual testing while maintaining high accuracy, enabling scalable AI safety evaluations.",
      "mindmap": "graph LR\n    A[Automated Red-Teaming Framework for LLM Security] --> B[核心问题/Problem: Manual red-teaming is not scalable for comprehensive LLM security assessment]\n    A --> C[主要方法/Method: Automated framework with meta-prompting attack synthesis & multi-modal vulnerability detection]\n    A --> D[关键结果/Results: 3.9x faster vulnerability discovery, 89% detection accuracy, 47 vulnerabilities found]"
    },
    {
      "title": "PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation",
      "authors": "Yuma Ichikawa, Naoya Takagi, Takumi Nakagawa, Yuzi Kanazawa, Akira Sakai",
      "institution": "Fujitsu Limited, RIKEN Center for AIP, Institute of Science Tokyo, Tokai University",
      "link": "https://arxiv.org/pdf/2512.20687",
      "code": null,
      "tags": [
        "llm inference",
        "hierarchical autoregressive model",
        "KV-cache optimization",
        "memory-bound inference",
        "multi-resolution context",
        "throughput-quality trade-off"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6824d7ad660d8d52e1568c90187924380b5fd436a69942bfac67084af3298d40_w640_q70.webp",
      "contributions": "1. Proposes PHOTON, a hierarchical autoregressive model that replaces the Transformer's flat token-by-token scanning with a vertical, multi-resolution context access pattern. 2. Introduces a persistent hierarchy of latent streams, with a bottom-up encoder compressing tokens and lightweight top-down decoders reconstructing token representations, reducing decode-time KV-cache traffic. 3. Demonstrates significant improvements in throughput per unit memory (up to 10^3x) and advantages in long-context and multi-query tasks compared to Transformer-based models.",
      "summary": "The paper identifies that Transformer inference becomes memory-bound due to ever-growing KV-cache reads/writes during autoregressive decoding. To solve this, it proposes PHOTON, a hierarchical model that accesses context vertically at multiple resolutions instead of scanning tokens horizontally. This architectural change drastically reduces memory traffic, yielding orders-of-magnitude higher throughput per unit memory while maintaining quality.",
      "mindmap": "graph LR\n    A[PHOTON: Hierarchical Autoregressive Modeling] --> B[核心问题/Problem: Transformer水平扫描导致KV缓存读写成为内存瓶颈/Horizontal scanning causes memory-bound KV-cache bottleneck]\n    A --> C[主要方法/Method: 用垂直多分辨率层次模型替代/Replace with vertical multi-resolution hierarchical model]\n    A --> D[关键结果/Results: 内存效率与吞吐量大幅提升/Significant improvement in memory efficiency & throughput]"
    },
    {
      "title": "SA-DiffuSeq: Addressing Computational and Scalability Challenges in Long-Document Generation with Sparse Attention",
      "authors": "Alexandros Christoforos, Chadbourne Davis",
      "institution": "Suffolk University",
      "link": "https://arxiv.org/pdf/2512.20724",
      "code": null,
      "tags": [
        "diffusion models",
        "sparse attention",
        "diffusion models",
        "long-text generation",
        "soft absorbing state",
        "computational complexity"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01893006a5e49ffeaca24f7c5197f5a706782f3051b02cc9dfef88521a05c523_w640_q70.webp",
      "contributions": "1. Introduces SA-DiffuSeq, a diffusion framework that integrates sparse attention to improve scalability for long-document modeling. 2. Proposes a novel soft absorbing state tailored to sparse attention dynamics to stabilize diffusion trajectories and accelerate sequence reconstruction. 3. Demonstrates superior training efficiency and sampling speed compared to state-of-the-art diffusion baselines, especially on extended sequences.",
      "summary": "The paper addresses the high computational cost of diffusion models for long-text generation by proposing SA-DiffuSeq, which integrates sparse attention and a novel soft absorbing state. This method reduces complexity while maintaining generation quality, making it suitable for applications like scientific writing and code generation. The results show that incorporating structured sparsity is a promising direction for efficient long-text generation.",
      "mindmap": "graph LR\n    A[SA-DiffuSeq] --> B[核心问题/Problem<br>Computational Cost & Scalability];\n    A --> C[主要方法/Method<br>Sparse Attention & Soft Absorbing State];\n    A --> D[关键结果/Results<br>Improved Efficiency & Quality];"
    },
    {
      "title": "AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent",
      "authors": "Haipeng Luo, Huawen Feng, Qingfeng Sun, Can Xu, Kai Zheng, Yufei Wang, Tao Yang, Han Hu, Yansong Tang, Di Wang",
      "institution": "Tsinghua University, Tencent Hunyuan",
      "link": "https://arxiv.org/pdf/2512.20745",
      "code": null,
      "tags": [
        "agent system",
        "tool-augmented agent",
        "agentic reinforcement learning",
        "supervised fine-tuning (SFT)",
        "request-level asynchronous rollout",
        "prefix-aware load balancing"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7211416872630b2f7d460fe4b986a1d141827d69b65487826e3374c5e4cce08d_w640_q70.webp",
      "contributions": "1. An automated method to convert natural language chain-of-thought into structured tool-augmented trajectories for generating high-quality SFT data. 2. A novel agentic reinforcement learning paradigm that dynamically interleaves natural language generation with real-time code execution for learning tool-use strategies. 3. An efficient training system with techniques like asynchronous rollout scheduling and prefix-aware load balancing, achieving 4-5x speedup for RL training on long sequences.",
      "summary": "This paper introduces AgentMath, a framework that combines language model reasoning with code interpreter precision to solve complex math problems. It uses automated SFT data generation, agentic RL for tool-use learning, and an efficient training system, achieving state-of-the-art results on benchmarks like AIME24 and AIME25.",
      "mindmap": "graph LR\n    A[AgentMath] --> B[核心问题/Problem: LRMs are inefficient and inaccurate for complex math]\n    A --> C[主要方法/Method: Tool-augmented agent framework with SFT data generation, agentic RL, and efficient training system]\n    A --> D[关键结果/Results: SOTA performance on AIME24, AIME25, HMMT25 benchmarks]"
    },
    {
      "title": "TokSuite: Measuring the Impact of Tokenizer Choice on Language Model Behavior",
      "authors": "Gül Sena Altıntaş, Malikeh Ehghaghi, Brian Lester, Fengyuan Liu, Wanru Zhao, Marco Ciccone, Colin Raffel",
      "institution": "University of Toronto, Vector Institute, Google DeepMind, McGill University, Mila - Quebec AI Institute, University of Cambridge, Hugging Face",
      "link": "https://arxiv.org/pdf/2512.20757",
      "code": "https://github.com/r-three/Tokenizers",
      "tags": [
        "tokenization",
        "tokenizer",
        "language models",
        "benchmark",
        "subword segmentation",
        "BPE"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48b6cd3c25dd384b02a8b1601f98df302b0d84a5c6e3b043841ea275f5ffdcbd_w640_q70.webp",
      "contributions": "1. Introduces TokSuite, a collection of fourteen language models that are identical except for their tokenizers, enabling isolated study of tokenizer impact. 2. Curates and releases a new benchmark designed to measure model performance under real-world text perturbations that affect tokenization. 3. Provides a robust framework that supports novel findings on the benefits and shortcomings of various popular tokenizers.",
      "summary": "This paper addresses the challenge of isolating the impact of tokenizer choice on language model behavior. It proposes TokSuite, a suite of models with different tokenizers but identical other components, along with a specialized benchmark. The work enables systematic analysis and reveals new insights into how different tokenizers affect model performance.",
      "mindmap": "graph LR\n        A[TokSuite: Measuring Tokenizer Impact] --> B[核心问题/Problem: Tokenization's role in LM performance is poorly understood]\n        A --> C[主要方法/Method: TokSuite - Identical models with different tokenizers + new benchmark]\n        A --> D[关键结果/Results: Novel findings on tokenizer benefits and shortcomings]"
    },
    {
      "title": "Generalization of RLVR Using Causal Reasoning as a Testbed",
      "authors": "Brian Lu, Hongyu Zhao, Shuo Sun, Hao Peng, Rui Ding, Hongyuan Mei",
      "institution": "Johns Hopkins University, University of Maryland, College Park, National University of Singapore, University of Illinois at Urbana-Champaign, Microsoft Research Asia, Toyota Technological Institute at Chicago",
      "link": "https://arxiv.org/pdf/2512.20760",
      "code": null,
      "tags": [
        "reinforcement learning",
        "RLVR",
        "causal reasoning",
        "generalization",
        "supervised fine-tuning",
        "large language models"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/472c557c79b64b352421bedd952ba76d099165d613e99323a1beb8845a24cf4c_w640_q70.webp",
      "contributions": "1. Provides an empirical study of RLVR generalization using causal inference as a structured testbed, examining generalization across query levels and structural complexity. 2. Identifies that RLVR's benefits over SFT for generalization are contingent on specific combinations of model size and training query level, and depend on the model's initial reasoning competence. 3. Shows that RLVR improves specific causal reasoning subskills, such as marginalization strategy and intermediate probability calculation, leading to accuracy gains on complex queries.",
      "summary": "This paper studies the generalization of Reinforcement Learning with Verifiable Rewards (RLVR) for large language models on causal reasoning tasks. It finds that RLVR can outperform supervised fine-tuning in generalization, but its effectiveness depends on model size, training data, and the model's initial competence. The results indicate RLVR improves specific reasoning sub-skills when the model has a sufficient foundational ability.",
      "mindmap": "graph LR\n    A[”Generalization of RLVR Using Causal Reasoning as a Testbed<br>以因果推理为测试平台的RLVR泛化研究”] --> B[”核心问题/Problem<br>RLVR何时能实现鲁棒泛化？<br>When does RLVR yield robust generalization?”]\n    A --> C[”主要方法/Method<br>在因果图模型上实证研究RLVR与SFT<br>Empirical study of RLVR vs SFT on causal graphical models”]\n    A --> D[”关键结果/Results<br>RLVR泛化更强，但依赖模型规模与初始能力<br>RLVR yields stronger generalization but depends on model size & initial competence”]"
    },
    {
      "title": "Adversarial Training for Failure-Sensitive User Simulation in Mental Health Dialogue Optimization",
      "authors": "Ziyi Zhu, Olivier Tieleman, Caitlin A. Stamatis, Luka Smyth, Thomas D. Hull, Daniel R. Cahn, Matteo Malgaroli",
      "institution": "Slingshot AI, NYU School of Medicine",
      "link": "https://arxiv.org/pdf/2512.20773",
      "code": null,
      "tags": [
        "dialogue systems",
        "adversarial training",
        "user simulation",
        "task-oriented dialogue",
        "mental health chatbots",
        "direct preference optimization"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f72756c707df5d24dd551e3e95152618e1b00d48b0aae580dd4f6ebbf8dc335_w640_q70.webp",
      "contributions": "1. Proposes an adversarial training framework for improving user simulator realism in task-oriented dialogue systems. 2. Applies the framework to mental health support chatbots, demonstrating enhanced ability to surface system failure modes. 3. Shows that the fine-tuned and adversarially trained simulator achieves strong correlation between simulated and real failure rates while maintaining low distributional divergence.",
      "summary": "This paper addresses the challenge of creating realistic user simulators for evaluating task-oriented dialogue systems. It proposes an adversarial training framework where a user simulator (generator) is refined against a discriminator to improve realism, specifically applied to mental health chatbots. The results show this approach creates simulators that effectively expose system failures, enabling more reliable and cost-effective evaluation before deployment.",
      "mindmap": "graph LR\n        A[Adversarial Training for Failure-Sensitive User Simulation<br>对抗性训练用于故障敏感的用户模拟] --> B(Problem: Realistic user simulation is challenging<br>核心问题：真实的用户模拟具有挑战性)\n        A --> C(Method: Adversarial training framework<br>主要方法：对抗性训练框架)\n        A --> D(Results: Enhanced failure exposure & realism<br>关键结果：增强的故障暴露与真实性)"
    },
    {
      "title": "Large Language Models Approach Expert Pedagogical Quality in Math Tutoring but Differ in Instructional and Linguistic Profiles",
      "authors": "Ramatu Oiza Abdulsalam, Segun Aroyehun",
      "institution": "African University of Science and Technology, University of Konstanz",
      "link": "https://arxiv.org/pdf/2512.20780",
      "code": null,
      "tags": [
        "educational technology / intelligent tutoring systems",
        "large language models",
        "pedagogical quality",
        "instructional strategies",
        "linguistic analysis",
        "math tutoring"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4c157f4475efaa64bb039e61eccf65a1facd8888dde9576734865854a42e878_w640_q70.webp",
      "contributions": "1. Conducted a controlled, turn-level comparison of tutoring responses between expert human tutors, novice human tutors, and multiple large language models (LLMs) in math remediation. 2. Identified systematic differences in instructional and linguistic profiles, finding that LLMs underuse restating/revoicing strategies but produce longer, more lexically diverse, and more polite responses compared to human tutors. 3. Established statistical associations between specific instructional/linguistic features (e.g., restating, lexical diversity) and perceived pedagogical quality, showing LLMs can achieve comparable quality using different strategies.",
      "summary": "This paper investigates how closely the instructional behavior of large language models (LLMs) aligns with expert human tutors in math tutoring. By comparing responses from experts, novices, and LLMs to the same conversation turns, the study analyzes instructional strategies and linguistic features. It finds that LLMs approach expert-level pedagogical quality on average but rely on systematically different strategies, such as underusing restating/revoicing while being more verbose and polite.",
      "mindmap": "graph LR\n    A[Large Language Models Approach Expert Pedagogical Quality in Math Tutoring but Differ in Instructional and Linguistic Profiles] --> B(核心问题/Problem: LLM教学行为与人类专家的一致性/Alignment of LLM instructional behavior with expert human tutors)\n    A --> C(主要方法/Method: 控制性对话轮比较/Controlled turn-level comparison of expert, novice, and LLM responses)\n    A --> D(关键结果/Results: LLM接近专家教学水平但策略不同/LLMs approach expert quality but use different instructional & linguistic strategies)"
    },
    {
      "title": "Investigating Model Editing for Unlearning in Large Language Models",
      "authors": "Shariqah Hossain, Lalana Kagal",
      "institution": "Massachusetts Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.20794",
      "code": null,
      "tags": [
        "machine unlearning",
        "model editing",
        "ROME",
        "IKE",
        "WISE",
        "TOFU benchmark"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/841879fe7d15bfc601ea216e8680f83f41000cc4f51b756525680ffd81869551_w640_q70.webp",
      "contributions": "1. Investigated the application of existing model editing algorithms (ROME, IKE, WISE) to the problem of machine unlearning in LLMs. 2. Designed new editing targets, including a novel \"Avoidant\" target, specifically formulated for the goal of information removal rather than alteration. 3. Demonstrated that model editing approaches can surpass traditional unlearning baselines in the quality of forgetting, while also highlighting the persistent trade-off between effective unlearning and preserving general model performance.",
      "summary": "This paper investigates using model editing techniques for machine unlearning in Large Language Models. It applies editing algorithms like ROME, IKE, and WISE with new \"unlearning\" targets and evaluates them on the TOFU benchmark. The results show that model editing can outperform baseline unlearning methods in some settings but still struggles to fully remove information without harming overall model performance.",
      "mindmap": "graph LR\n    A[Investigating Model Editing for Unlearning in LLMs] --> B(核心问题/Problem: Inefficient or damaging unlearning in LLMs)\n    A --> C(主要方法/Method: Apply model editing algorithms ROME/IKE/WISE with new unlearning targets)\n    A --> D(关键结果/Results: Can exceed baselines but trade-off with performance remains)"
    },
    {
      "title": "Measuring Mechanistic Independence: Can Bias Be Removed Without Erasing Demographics?",
      "authors": "Zhengyang Shan, Aaron Mueller",
      "institution": "Boston University",
      "link": "https://arxiv.org/pdf/2512.20796",
      "code": null,
      "tags": [
        "bias mitigation & interpretability",
        "sparse autoencoder",
        "feature ablation",
        "mechanistic interpretability",
        "demographic bias",
        "causal influence"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fb5fdb2f139d53a61fbac99afbf6f9d9a8061df4ee47ccc35f3e788fe619760_w640_q70.webp",
      "contributions": "1. Introduces a multi-task evaluation framework to measure the independence of demographic bias mechanisms from general demographic recognition in language models. 2. Compares attribution-based and correlation-based methods for locating bias features and demonstrates their differential effectiveness across bias dimensions (race/gender vs. education). 3. Shows that targeted sparse autoencoder feature ablations can enable surgical debiasing, reducing stereotypes without erasing legitimate demographic detection, indicating bias arises from task-specific mechanisms.",
      "summary": "This paper investigates whether demographic bias in language models can be removed without harming the model's ability to recognize demographics. The authors use a multi-task setup and compare attribution-based and correlation-based methods to locate bias features in a sparse autoencoder, performing targeted ablations on the Gemma-2-9B model. They find that such mechanistic interventions can reduce specific stereotypes (e.g., race/gender in professions) while preserving name recognition, but the effectiveness depends on the bias dimension, highlighting the need for task-specific debiasing strategies.",
      "mindmap": "graph LR\n    A[Measuring Mechanistic Independence<br/>机制独立性测量] --> B(核心问题/Problem: Can bias be removed without erasing demographics?<br/>能否去除偏见而不消除人口统计信息识别能力？)\n    A --> C(主要方法/Method: Multi-task evaluation & Sparse Autoencoder feature ablation<br/>多任务评估与稀疏自编码器特征消融)\n    A --> D(关键结果/Results: Attribution ablation works for race/gender; Correlation ablation works for education<br/>归因消融对种族/性别有效；相关消融对教育偏见有效)"
    },
    {
      "title": "Semantic Deception: When Reasoning Models Can't Compute an Addition",
      "authors": "Nathaniël de Leeuw, Marceau Nahon, Mathis Reymond, Raja Chatila, Mehdi Khamassi",
      "institution": "Institute of Intelligent Systems and Robotics (CNRS, Sorbonne University), Paris Cité University",
      "link": "https://arxiv.org/pdf/2512.20812",
      "code": null,
      "tags": [
        "large language model evaluation",
        "semantic deception",
        "symbolic reasoning",
        "abstraction",
        "chain-of-thought",
        "evaluation framework"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51eafa5ff63a45ff90df02eb9c82e60fc34432de99dc2dca39fb261430db4031_w640_q70.webp",
      "contributions": "1. Introduces the concept of \"semantic deceptions\" as a novel experimental framework to test LLMs' symbolic abstraction capabilities. 2. Demonstrates that misleading semantic cues can significantly degrade the performance of reasoning models on simple arithmetic tasks. 3. Reveals a critical limitation in LLMs' ability to perform robust symbolic manipulation, highlighting their over-reliance on surface-level semantics and statistical correlations.",
      "summary": "The paper investigates the symbolic reasoning capabilities of large language models by introducing \"semantic deceptions,\" where digits and operators are replaced with novel symbols carrying misleading associations. Experiments show that these semantic cues severely impair model performance on simple calculations, revealing a fundamental weakness in abstraction and a tendency to rely on learned correlations rather than true symbolic logic.",
      "mindmap": "graph LR\n        A[Semantic Deception: When Reasoning Models Can’t Compute an Addition] --> B[核心问题/Problem: LLMs' symbolic reasoning and abstraction capabilities under misleading semantic cues]\n        A --> C[主要方法/Method: Introduce semantic deceptions by redefining digits/operators with novel symbols]\n        A --> D[关键结果/Results: Semantic cues deteriorate performance, revealing over-reliance on surface semantics and limitations in symbolic manipulation]"
    },
    {
      "title": "EssayCBM: Rubric-Aligned Concept Bottleneck Models for Transparent Essay Grading",
      "authors": "Kumar Satvik Chaudhary, Chengshuai Zhao, Fan Zhang, Yung Hin Tse, Garima Agrawal, Yuli Deng, Huan Liu",
      "institution": "Arizona State University",
      "link": "https://arxiv.org/pdf/2512.20817",
      "code": "https://github.com/scott-f-zhang/CBM-Demo",
      "tags": [
        "automated essay scoring",
        "Concept Bottleneck Models",
        "Explainable AI",
        "Human-in-the-loop",
        "Rubric-Aligned",
        "Interpretability"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b05be6579e2ddbef36e15a910aaffe552adbb13cce68a7840f6e46806eb13aa0_w640_q70.webp",
      "contributions": "1. Proposes EssayCBM, a rubric-aligned framework that uses dedicated prediction heads to evaluate specific writing concepts (e.g., Thesis Clarity, Evidence Use) instead of predicting grades directly from text. 2. Introduces a transparent bottleneck where a lightweight network computes the final grade using only the concept scores, enabling interpretability and human-in-the-loop adjustments. 3. Demonstrates that the system matches black-box performance while providing actionable, concept-level feedback through an intuitive web interface.",
      "summary": "The paper addresses the lack of transparency in automated essay grading systems by introducing EssayCBM, a framework that first predicts scores for specific writing concepts aligned with a rubric and then uses these scores to compute a final grade. This approach provides interpretable, concept-level feedback and allows instructors to adjust predictions in a human-in-the-loop manner. The proposed method achieves performance comparable to black-box models while offering greater accountability and actionable insights for educators and students.",
      "mindmap": "graph LR\n        A[EssayCBM: Rubric-Aligned Concept Bottleneck Models] --> B[核心问题/Problem: 自动评分系统缺乏透明度/Black-box grading lacks transparency]\n        A --> C[主要方法/Method: 基于概念瓶颈和规则对齐的评估/Rubric-aligned concept bottleneck evaluation]\n        A --> D[关键结果/Results: 性能匹配黑盒并提供可解释反馈/Matches performance & provides interpretable feedback]"
    },
    {
      "title": "MediEval: A Unified Medical Benchmark for Patient-Contextual and Knowledge-Grounded Reasoning in LLMs",
      "authors": "Zhan Qu, Michael Färber",
      "institution": "TU Dresden, ScaDS.AI",
      "link": "https://arxiv.org/pdf/2512.20822",
      "code": null,
      "tags": [
        "medical nlp / llm evaluation",
        "medical benchmark",
        "electronic health records (EHR)",
        "knowledge grounding",
        "counterfactual reasoning",
        "DPO fine-tuning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59c4d88b1ecf7256d86a2c1dd12f74897d1a42b0c88d272ea8cf058355f013cd_w640_q70.webp",
      "contributions": "1. Introduces MediEval, a unified benchmark linking real EHRs (MIMIC-IV) to a biomedical knowledge base for evaluating LLMs on patient-contextual and knowledge-grounded reasoning. 2. Proposes a 4-quadrant evaluation framework to systematically assess models on both factual correctness and contextual consistency, identifying critical failure modes like hallucinated support and truth inversion. 3. Proposes Counterfactual Risk-Aware Fine-tuning (CoRFu), a DPO-based method with an asymmetric penalty, which significantly improves model accuracy and safety by eliminating truth inversion errors.",
      "summary": "The paper identifies a gap in evaluating LLMs for medical applications, where existing benchmarks either test isolated knowledge or patient reasoning without verifying correctness. To address this, the authors introduce the MediEval benchmark and a 4-quadrant evaluation framework to systematically assess LLMs, and propose a novel fine-tuning method called CoRFu. The results show that CoRFu significantly improves model performance and safety by eliminating dangerous error types like truth inversion.",
      "mindmap": "graph LR\n        A[MediEval] --> B[核心问题/Problem: LLMs in medicine lack reliable evaluation combining knowledge and patient context];\n        A --> C[主要方法/Method: Unified benchmark (EHR + KB) & 4-quadrant framework & CoRFu fine-tuning];\n        A --> D[关键结果/Results: Identifies failure modes; CoRFu improves accuracy and safety];"
    },
    {
      "title": "How important is Recall for Measuring Retrieval Quality?",
      "authors": "Shelly Schwartz, Oleg Vasilyev, Randy Sawaya",
      "institution": "Primer Technologies Inc.",
      "link": "https://arxiv.org/pdf/2512.20854",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "retrieval quality",
        "recall estimation",
        "LLM-based evaluation",
        "nDCG",
        "RAG"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8385a132c621f6e8d9e71274fc95535412aa2b9f0d0f40e834705d3548f0a601_w640_q70.webp",
      "contributions": "1. Evaluates established strategies for measuring retrieval quality when the total number of relevant documents (and thus recall) is unknown, by correlating metrics with LLM-based judgments of response quality. 2. Conducts experiments across multiple datasets with a low number of relevant documents (2-15) to assess these strategies. 3. Introduces a new, simple retrieval quality measure that performs well without requiring knowledge of the total number of relevant documents.",
      "summary": "The paper addresses the problem of evaluating retrieval quality in realistic settings where the total number of relevant documents is unknown, making recall uncomputable. It evaluates existing strategies and proposes a new simple metric by measuring their correlation with LLM-generated response quality. The main conclusion is that a simple measure can perform effectively without needing to know the total relevant documents, offering a practical solution for dynamic knowledge bases.",
      "mindmap": "graph LR\n    A[How important is Recall for Measuring Retrieval Quality?] --> B[核心问题/Problem: Realistic retrieval with unknown total relevant docs]\n    A --> C[主要方法/Method: Correlate metrics with LLM response quality; propose new measure]\n    A --> D[关键结果/Results: Simple measure works well without recall]"
    },
    {
      "title": "Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning",
      "authors": "NVIDIA, Aaron Blakeman, Aaron Grattafiori, Aarti Basant, Abhibha Gupta, Abhinav Khattar, Adi Renduchintala, Aditya Vavre, Akanksha Shukla, Akhiad Bercovich, Aleksander Ficek, Aleksandr Shaposhnikov, Alex Kondratenko, Alexander Bukharin, Alexandre Milesi, Ali Taghibakhshi, Alisa Liu, Amelia Barton, Ameya Sunil Mahabaleshwarkar, Amir Klein, Amit Zuker, Amnon Geifman, Amy Shen, Anahita Bhiwandiwalla, Andrew Tao, Ann Guan, Anubhav Mandarwal, Arham Mehta, Ashwath Aithal, Ashwin Poojary, Asif Ahamed, Asma Kuriparambil Thekkumpate, Ayush Dattagupta, Banghua Zhu, Bardiya Sadeghi, Barnaby Simkin, Ben Lanir, Benedikt Schifferer, Besmira Nushi, Bilal Kartal, Bita Darvish Rouhani, Boris Ginsburg, Brandon Norick, Brandon Soubasis, Branislav Kisacanin, Brian Yu, Bryan Catanzaro, Carlo del Mundo, Chantal Hwang, Charles Wang, Cheng-Ping Hsieh, Chenghao Zhang, Chenhan Yu, Chetan Mungekar, Chintan Patel, Chris Alexiuk, Christopher Parisien, Collin Neale, Damon Mosk-Aoyama, Dan Su, Dane Corneil, Daniel Afrimi, Daniel Rohrer, Daniel Serebrenik, Daria Gitman, Daria Levy, Darko Stosic, David Mosallanezhad, Deepak Narayanan, Dhruv Nathawani, Dima Rekesh, Dina Yared, Divyanshu Kakwani, Dong Ahn, Duncan Riach, Dusan Stosic, Edgar Minasyan, Edward Lin, Eileen Long, Eileen Peters Long, Elena Lantz, Ellie Evans, Elliott Ning, Eric Chung, Eric Harper, Eric Tramel, Erick Galinkin, Erik Pounds, Evan Briones, Evelina Bakhturina, Faisal Ladhak, Fay Wang, Fei Jia, Felipe Soares, Feng Chen, Ferenc Galko, Frankie Siino, Gal Hubara Agam, Ganesh Ajjanagadde, Gantavya Bhatt",
      "institution": "NVIDIA",
      "link": "https://arxiv.org/pdf/2512.20848",
      "code": null,
      "tags": [
        "llm inference",
        "Mixture-of-Experts",
        "Mamba-Transformer",
        "agentic reasoning",
        "sparse activation",
        "long context"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96a4b5c012acd8208519dcb9669276bd8c3c3709f26e7290e2fce500151c1ccc_w640_q70.webp",
      "contributions": "1. Introduces Nemotron 3 Nano, a hybrid MoE Mamba-Transformer model that sparsely activates only 3.2B out of 31.6B parameters per forward pass for efficiency. 2. Demonstrates superior inference throughput (up to 3.3x faster) compared to similarly-sized open models while maintaining or improving accuracy on benchmarks. 3. Supports an extended context length of up to 1 million tokens and shows enhanced agentic and reasoning capabilities through post-training.",
      "summary": "This paper presents Nemotron 3 Nano, an efficient 30B-parameter language model that combines Mixture-of-Experts with a Mamba-Transformer architecture to achieve sparse activation. It was pre-trained on 25 trillion tokens and post-trained for agentic reasoning, resulting in higher inference throughput and accuracy compared to similar models while supporting up to 1M token contexts.",
      "mindmap": "graph LR\n    A[Nemotron 3 Nano<br>论文标题/Paper Title] --> B[构建高效、能进行智能体推理的大模型<br>核心问题/Problem];\n    A --> C[混合MoE与Mamba-Transformer架构，稀疏激活参数<br>主要方法/Method];\n    A --> D[更高推理吞吐与精度，支持100万令牌上下文<br>关键结果/Results];"
    },
    {
      "title": "NVIDIA Nemotron 3: Efficient and Open Intelligence",
      "authors": "NVIDIA, Aaron Blakeman, Aaron Grattafiori, Aarti Basant, Abhibha Gupta, Abhinav Khattar, Adi Renduchintala, Aditya Vavre, Akanksha Shukla, Akhiad Bercovich, Aleksander Ficek, Aleksandr Shaposhnikov, Alex Kondratenko, Alexander Bukharin, Alexandre Milesi, Ali Taghibakhshi, Alisa Liu, Amelia Barton, Ameya Sunil Mahabaleshwarkar, Amir Klein, Amit Zuker, Amnon Geifman, Amy Shen, Anahita Bhiwandiwalla, Andrew Tao, Anjulie Agrusa, Ankur Verma, Ann Guan, Anubhav Mandarwal, Arham Mehta, Ashwath Aithal, Ashwin Poojary, Asif Ahamed, Asit Mishra, Asma Kuriparambil Thekkumpate, Ayush Dattagupta, Banghua Zhu, Bardiya Sadeghi, Barnaby Simkin, Ben Lanir, Benedikt Schifferer, Besmira Nushi, Bilal Kartal, Bita Darvish Rouhani, Boris Ginsburg, Brandon Norick, Brandon Soubasis, Branislav Kisacanin, Brian Yu, Bryan Catanzaro, Carlo del Mundo, Chantal Hwang, Charles Wang, Cheng-Ping Hsieh, Chenghao Zhang, Chenhan Yu, Chetan Mungekar, Chintan Patel, Chris Alexiuk, Christopher Parisien, Collin Neale, Cyril Meurillon, Damon Mosk-Aoyama, Dan Su, Dane Corneil, Daniel Afrimi, Daniel Lo, Daniel Rohrer, Daniel Serebrenik, Daria Gitman, Daria Levy, Darko Stosic, David Mosallanezhad, Deepak Narayanan, Dhruv Nathawani, Dima Rekesh, Dina Yared, Divyanshu Kakwani, Dong Ahn, Duncan Riach, Dusan Stosic, Edgar Minasyan, Edward Lin, Eileen Long, Eileen Peters Long, Elad Segal, Elena Lantz, Ellie Evans, Elliott Ning, Eric Chung, Eric Harper, Eric Tramel, Erick Galinkin, Erik Pounds, Evan Briones, Evelina Bakhturina, Evgeny Tsykunov, Faisal Ladhak, Fay Wang, Fei Jia",
      "institution": "NVIDIA",
      "link": "https://arxiv.org/pdf/2512.20856",
      "code": null,
      "tags": [
        "llm inference",
        "Mixture-of-Experts",
        "Mamba-Transformer",
        "LatentMoE",
        "NVFP4",
        "multi-environment reinforcement learning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5203ecd520d6e99bc9f0034f05e8945272d4a34a746eeeae01be1cc728049b5_w640_q70.webp",
      "contributions": "1. Introduces the Nemotron 3 family of models (Nano, Super, Ultra) built on a Mixture-of-Experts hybrid Mamba-Transformer architecture for high throughput and long context (up to 1M tokens). 2. Proposes novel techniques including LatentMoE for improved model quality and MTP layers for faster text generation in the larger models. 3. Employs multi-environment reinforcement learning for post-training, enabling advanced capabilities like reasoning, multi-step tool use, and granular reasoning budget control.",
      "summary": "This paper introduces the Nemotron 3 family of open models designed for efficient and intelligent agentic applications. The models use a novel hybrid Mamba-Transformer architecture and are trained with techniques like LatentMoE and multi-environment RL to achieve strong reasoning, conversational, and tool-use capabilities with high throughput. The conclusion is that these models provide state-of-the-art accuracy and efficiency, with plans for open release of weights, software, and data.",
      "mindmap": "graph LR\n    A[NVIDIA Nemotron 3] --> B[核心问题/Problem: Efficient and open intelligence for agentic applications]\n    A --> C[主要方法/Method: Mixture-of-Experts hybrid Mamba-Transformer, LatentMoE, multi-environment RL]\n    A --> D[关键结果/Results: High throughput, 1M context, strong agentic/reasoning capabilities, open release]"
    },
    {
      "title": "Architectural Trade-offs in Small Language Models Under Compute Constraints",
      "authors": "Shivraj Singh Bhatti",
      "institution": "University of Massachusetts Amherst",
      "link": "https://arxiv.org/pdf/2512.20877",
      "code": null,
      "tags": [
        "language modeling",
        "small language models",
        "compute constraints",
        "architectural trade-offs",
        "rotary positional embeddings",
        "transformer"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a2b54dee144c67bdb877818e8171163f9556734c09b3a1d7d29fe8464aee558b_w640_q70.webp",
      "contributions": "1. A systematic empirical study of architectural choices (from linear predictors to transformers) for small language models under strict compute constraints. 2. An analysis showing attention-based models are more FLOP-efficient than MLPs even at small scale, and that increasing depth/context without sufficient optimization can hurt performance. 3. An investigation revealing that techniques like Rotary Positional Embeddings (RoPE), successful in large models, do not necessarily transfer effectively to the small-model regime.",
      "summary": "This paper systematically studies how architectural choices affect small language model performance under limited compute. The method involves progressively building from linear predictors to multi-layer transformers and evaluating them on character and word-level datasets. The main conclusion is that attention is more efficient than MLPs per FLOP at small scales, but scaling depth or applying large-model techniques like RoPE can be detrimental without careful optimization.",
      "mindmap": "graph LR\n    A[Architectural Trade-offs in Small Language Models<br>小型语言模型的架构权衡] --> B[核心问题/Problem<br>How do architectural choices affect performance under compute constraints?<br>计算约束下架构选择如何影响性能？]\n    A --> C[主要方法/Method<br>Progressive architectural study from linear to transformer models<br>从线性到Transformer模型的渐进式架构研究]\n    A --> D[关键结果/Results<br>Attention > MLPs in per-FLOP efficiency; RoPE may not transfer<br>注意力机制单位FLOP效率优于MLP；RoPE可能不适用于小模型]"
    },
    {
      "title": "Where Did This Sentence Come From? Tracing Provenance in LLM Reasoning Distillation",
      "authors": "Kaiyuan Liu, Shaotian Yan, Rui Miao, Bing Wang, Chen Shen, Jun Zhang, Jieping Ye",
      "institution": "Zhejiang University, Alibaba Cloud Computing, Jilin University, University of Michigan",
      "link": "https://arxiv.org/pdf/2512.20908",
      "code": null,
      "tags": [
        "post-training (sft/rlhf)",
        "reasoning distillation",
        "provenance tracing",
        "teacher-guided data selection",
        "model generalization",
        "knowledge transfer"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d19fc56be8917fa897a8772f9f0c999250e917eda937c0e1b5176333830faf5_w640_q70.webp",
      "contributions": "1. Introduces a cross-model Reasoning Distillation Provenance Tracing framework to classify the origin of a distilled model's outputs into four categories. 2. Empirically demonstrates that teacher-originated actions in the distilled model correlate with its performance, providing an explanatory analysis for distillation. 3. Proposes a principled, teacher-guided data selection method based on teacher-student divergence, validated across multiple models.",
      "summary": "This paper addresses the lack of analysis on the origins of capabilities in reasoning-distilled models by introducing a provenance tracing framework. The method classifies model outputs by comparing probabilities from teacher, student, and distilled models, showing that teacher-originated actions explain performance. Based on this, a teacher-guided data selection method is proposed and validated to improve distillation.",
      "mindmap": "graph LR\n    A[论文标题 / Paper Title<br>Where Did This Sentence Come From?] --> B{核心问题 / Problem};\n    A --> C{主要方法 / Method};\n    A --> D{关键结果 / Results};\n    B --> B1[蒸馏模型能力来源不明 / Unclear provenance of distilled model capabilities];\n    B --> B2[泛化能力存疑 / Concerns about generalization];\n    C --> C1[溯源框架 / Provenance Tracing Framework];\n    C --> C2[概率比较分类 / Classify by comparing probabilities];\n    C --> C3[教师引导数据选择 / Teacher-guided data selection];\n    D --> D1[教师行为可被继承 / Teacher-originated actions are generated];\n    D --> D2[行为与性能相关 / Actions correlate with performance];\n    D --> D3[新方法有效 / New selection method is effective];"
    },
    {
      "title": "Transductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning",
      "authors": "Shengguang Wu, Xiaohan Wang, Yuhui Zhang, Hao Zhu, Serena Yeung-Levy",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2512.20934",
      "code": "https://transductive-visualprogram.github.io/",
      "tags": [
        "visual reasoning",
        "visual programming",
        "spatial reasoning",
        "tool induction",
        "transductive learning",
        "3D scene understanding"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6374488a70a5d9147002f5652452c2f63ea3698c6660c54123c36fc9deef3991_w640_q70.webp",
      "contributions": "1. Proposes Transductive Visual Programming (TVP), a novel framework that builds new tools from experiential solutions rather than speculative induction., 2. Introduces a closed-loop system with an evolving Tool Library and an Example Library, enabling self-improvement through experience., 3. Demonstrates state-of-the-art performance on spatial reasoning benchmarks and shows that transductively learned tools are used more frequently and generalize better.",
      "summary": "The paper addresses the challenge of spatial reasoning in 3D scenes by proposing Transductive Visual Programming (TVP), a framework that learns reusable higher-level tools by abstracting patterns from its own successful solutions. This experience-driven approach outperforms existing methods and GPT-4o on benchmarks, showing more effective tool discovery and strong generalization to unseen tasks.",
      "mindmap": "graph LR\n        A[Transductive Visual Programming] --> B[核心问题/Problem<br>Spatial reasoning is challenging for VLMs]\n        A --> C[主要方法/Method<br>Build tools from experience, not speculation]\n        A --> D[关键结果/Results<br>SOTA performance, better tool reuse & generalization]"
    },
    {
      "title": "Foundation Model-based Evaluation of Neuropsychiatric Disorders: A Lifespan-Inclusive, Multi-Modal, and Multi-Lingual Study",
      "authors": "Zhongren Dong, Haotian Guo, Weixiang Xu, Huan Zhao, Zixing Zhang",
      "institution": "Hunan University",
      "link": "https://arxiv.org/pdf/2512.20948",
      "code": null,
      "tags": [
        "multi-modal learning",
        "foundation models",
        "multi-modal fusion",
        "cross-corpus evaluation",
        "neuropsychiatric disorders",
        "multi-lingual datasets"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18e74bbfe865915192b7a6c5c53058f33d0688ed82ef83023913d356622a3899_w640_q70.webp",
      "contributions": "1. Proposed FEND, a comprehensive multi-modal framework using foundation models for evaluating neuropsychiatric disorders across the lifespan. 2. Conducted a systematic evaluation using 13 multi-lingual datasets, identifying strengths and limitations of multi-modal fusion for different disorders. 3. Provided extensive benchmarks and analysis of performance-influencing factors (e.g., modality imbalance, dataset heterogeneity) to advance reproducible research in the field.",
      "summary": "The paper proposes FEND, a foundation model-based multi-modal framework for detecting neuropsychiatric disorders like Alzheimer's, depression, and autism from speech and text. It evaluates the framework on 13 multi-lingual datasets, finding that multi-modal fusion works well for Alzheimer's and depression but underperforms for autism due to dataset heterogeneity, and identifies modality imbalance as a key challenge.",
      "mindmap": "graph LR\n    A[Foundation Model-based Evaluation of Neuropsychiatric Disorders] --> B(核心问题/Problem: Multi-lingual generalization & lack of unified framework)\n    A --> C(主要方法/Method: FEND multi-modal framework using speech & text)\n    A --> D(关键结果/Results: Multi-modal fusion excels for AD/depression, underperforms for ASD)"
    },
    {
      "title": "Neural Probe-Based Hallucination Detection for Large Language Models",
      "authors": "Shize Liang, Hongzhi Wang",
      "institution": "Harbin Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.20949",
      "code": null,
      "tags": [
        "hallucination detection",
        "MLP probes",
        "token-level detection",
        "Bayesian optimization",
        "hidden states",
        "multi-objective loss"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/256e2b7c6550072fc0e643c4045a4a592ba6b2241cd12656b7dd16ad27bf89b0_w640_q70.webp",
      "contributions": "1. Proposed a neural network-based framework using lightweight MLP probes for token-level hallucination detection, enabling nonlinear modeling of hidden states. 2. Designed a multi-objective joint loss function to improve detection stability and semantic disambiguation. 3. Established a layer position-probe performance response model and used Bayesian optimization to automatically search for optimal probe insertion layers.",
      "summary": "This paper addresses the problem of hallucination in large language models by proposing a real-time, token-level detection method. The method uses lightweight MLP probes on frozen model hidden states and a Bayesian-optimized layer search. Experiments show it outperforms existing methods in accuracy and recall under low false-positive conditions.",
      "mindmap": "graph LR\n    A[Neural Probe-Based Hallucination Detection for Large Language Models] --> B(核心问题/Problem: LLMs生成幻觉内容/LLMs generate hallucinations)\n    A --> C(主要方法/Method: MLP探针 & 贝叶斯优化/MLP probes & Bayesian optimization)\n    A --> D(关键结果/Results: 在多个数据集上表现优异/Outperforms SOTA on multiple datasets)"
    },
    {
      "title": "MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment",
      "authors": "Mohammad Mahdi Abootorabi, Alireza Ghahramani Kure, Mohammadali Mohammadkhani, Sina Elahimanesh, Mohammad Ali Ali Panah",
      "institution": "Based on the provided email domains (gmail.com), no specific institution can be reliably inferred. The team name is \"MultiMind\".",
      "link": "https://arxiv.org/pdf/2512.20950",
      "code": null,
      "tags": [
        "crosslingual information retrieval",
        "dual-encoder",
        "contrastive learning",
        "hard negative sampling",
        "data augmentation",
        "multi-source alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccb6e1762a9617f640573a86ea65e0e68afff48d53006aa74213e0a557970889_w640_q70.webp",
      "contributions": "1. Introduces TriAligner, a novel dual-encoder architecture with contrastive learning for crosslingual claim retrieval. 2. Proposes a method to learn the relative importance of different information sources (e.g., native text, English translations) for alignment. 3. Enhances robustness through LLM-based data preprocessing/augmentation and hard negative sampling strategies.",
      "summary": "This paper addresses the challenge of retrieving fact-checked claims across multiple languages to combat misinformation. The proposed TriAligner system uses a dual-encoder with contrastive learning and multi-source alignment, enhanced by LLM-based data processing. The method shows significant improvements in retrieval accuracy on monolingual and crosslingual benchmarks.",
      "mindmap": "graph LR\n        A[MultiMind at SemEval-2025 Task 7<br>Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment] --> B(核心问题/Problem: Rapid spread of multilingual misinformation);\n        A --> C(主要方法/Method: TriAligner - dual-encoder with contrastive learning & multi-source alignment);\n        A --> D(关键结果/Results: Improved retrieval accuracy on benchmarks);"
    },
    {
      "title": "Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models",
      "authors": "Xiang Zhang, Jiaqi Wei, Yuejin Yang, Zijie Qiu, Yuhan Chen, Zhiqiang Gao, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan, Wanli Ouyang, Chenyu You, Siqi Sun",
      "institution": "Fudan University, Shanghai Artificial Intelligence Laboratory, University of British Columbia, Zhejiang University, The Chinese University of Hong Kong, Stony Brook University",
      "link": "https://arxiv.org/pdf/2512.20954",
      "code": null,
      "tags": [
        "protein language models",
        "reflection pretraining",
        "chain-of-thought",
        "language expressiveness",
        "self-correction",
        "biological sequences"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5c51a6a0ca0e6bf5774254f47e4581544610c262b22a0cc12fe84b840bda40a_w640_q70.webp",
      "contributions": "1. Proposed and defined the concept of \"language expressiveness\" to explain the difficulty of applying Chain-of-Thought reasoning to biological sequence models. 2. Introduced reflection pretraining for biological sequence models, enabling intermediate reasoning through auxiliary \"thinking tokens\". 3. Demonstrated that this approach enables self-correction, improves performance, and offers benefits like counter-memorization and enhanced human steerability.",
      "summary": "This paper addresses the challenge of applying Chain-of-Thought reasoning to biological sequence models like protein language models, which have limited token expressiveness. The authors propose reflection pretraining, which augments the model with auxiliary \"thinking tokens\" to enable intermediate reasoning and self-correction. The method theoretically enhances language expressiveness and experimentally leads to substantial performance gains compared to standard pretraining.",
      "mindmap": "graph LR\n    A[Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models] --> B(核心问题/Problem: Limited expressiveness of protein language restricts CoT reasoning)\n    A --> C(主要方法/Method: Reflection pretraining with auxiliary ”thinking tokens”)\n    A --> D(关键结果/Results: Enhanced expressiveness, self-correction, performance gains)"
    },
    {
      "title": "Automatic Replication of LLM Mistakes in Medical Conversations",
      "authors": "Oleksii Proniakin, Diego Fajardo, Ruslan Nazarenko, Razvan Marinescu",
      "institution": "Lumos AI",
      "link": "https://arxiv.org/pdf/2512.20983",
      "code": null,
      "tags": [
        "llm evaluation",
        "medical conversation",
        "mistake replication",
        "benchmark creation",
        "llm judges",
        "single-shot qa"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7799ccba99ce08a1cee1bd87ba7b9e986a373df0f78a25479ad9fec7478ca0e9_w640_q70.webp",
      "contributions": "1. Introduces MedMistake, an automatic pipeline for extracting and replicating LLM mistakes from complex medical conversations into a benchmark format. 2. Releases MedMistake-All, a dataset of 3,390 single-shot QA pairs derived from identified mistakes, and a validated subset, MedMistake-Bench. 3. Provides a comprehensive evaluation of 12 frontier LLMs using the validated benchmark, revealing performance trends among top models.",
      "summary": "The paper addresses the difficulty of replicating specific mistakes made by LLMs in clinical conversations. It proposes MedMistake, an automated pipeline that generates conversational data, uses LLM judges to identify errors, and distills them into single-shot QA pairs to create a benchmark. The resulting benchmark was used to evaluate 12 LLMs, finding that GPT, Claude, and Grok models performed best.",
      "mindmap": "graph LR\n    A[Automatic Replication of LLM Mistakes in Medical Conversations] --> B(核心问题/Problem: LLM错误难以在其他模型中复现/Mistakes hard to replicate across LLMs)\n    A --> C(主要方法/Method: MedMistake自动管道/MedMistake automatic pipeline)\n    A --> D(关键结果/Results: 发布基准并评估12个LLM/Released benchmark & evaluated 12 LLMs)\n    C --> C1(生成对话/Generate conversations)\n    C --> C2(LLM委员会评估/LLM committee evaluation)\n    C --> C3(创建单轮QA对/Create single-shot QA pairs)\n    D --> D1(MedMistake-All数据集/MedMistake-All dataset)\n    D --> D2(MedMistake-Bench验证子集/MedMistake-Bench validated subset)\n    D --> D3(GPT/Claude/Grok表现最佳/GPT/Claude/Grok performed best)"
    },
    {
      "title": "Distilling the Essence: Efficient Reasoning Distillation via Sequence Truncation",
      "authors": "Wei-Rui Chen, Vignesh Kothapalli, Ata Fatahibaarzi, Hejian Sang, Shao Tang, Qingquan Song, Zhipeng Wang, Muhammad Abdul-Mageed",
      "institution": "The University of British Columbia, LinkedIn",
      "link": "https://arxiv.org/pdf/2512.21002",
      "code": "https://github.com/weiruichen01/distilling-the-essence",
      "tags": [
        "llm training",
        "knowledge distillation",
        "chain-of-thought",
        "sequence truncation",
        "training efficiency",
        "reasoning models"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a99e2da19bbc9bacf5104e37b4afd860b26a5285dd752f9a6e025702d930839_w640_q70.webp",
      "contributions": "1. Analysis of supervision allocation in reasoning distillation, showing the CoT segment is the dominant factor for transferring reasoning capability. 2. Establishment of a truncation protocol to quantify computation-quality tradeoffs as a function of sequence length. 3. Empirical demonstration that training on only the first 50% of tokens retains ~94% of performance while halving computational costs.",
      "summary": "This paper addresses the computational expense of distilling reasoning capabilities from large to small models over long sequences. It proposes a method of selective distillation and sequence truncation, focusing on early reasoning tokens. The key finding is that training on just the first half of tokens can preserve most performance while significantly reducing training time, memory, and FLOPs.",
      "mindmap": "graph LR\n        A[Distilling the Essence<br>高效推理蒸馏] --> B{核心问题/Problem};\n        A --> C{主要方法/Method};\n        A --> D{关键结果/Results};\n        B --> B1[长序列推理蒸馏计算昂贵<br>Long-Sequence Reasoning Distillation is Expensive];\n        C --> C1[选择性监督与序列截断<br>Selective Supervision & Sequence Truncation];\n        D --> D1[保留94%性能，减少50%成本<br>Retain 94% Performance, Reduce 50% Cost];"
    },
    {
      "title": "Rethinking Supervised Fine-Tuning: Emphasizing Key Answer Tokens for Improved LLM Accuracy",
      "authors": "Xiaofeng Shi, Qian Kou, Yuduo Li, Hua Zhou",
      "institution": "Beijing Academy of Artificial Intelligence (BAAI), Beijing Jiaotong University (BJTU)",
      "link": "https://arxiv.org/pdf/2512.21017",
      "code": null,
      "tags": [
        "post-training (sft/rlhf)",
        "Supervised Fine-Tuning",
        "Chain-of-Thought",
        "Two-Stage Training",
        "Attention Imbalance",
        "Key Answer Tokens"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7eab786d7e6ac187d45153b771fdc458d7c8434c0e133a9bcdb70a2afa441a73_w640_q70.webp",
      "contributions": "1. Identifies a key limitation in conventional SFT where models over-attend to lengthy Chain-of-Thought reasoning sequences at the expense of the shorter, critical final answer tokens. 2. Proposes SFTKey, a novel two-stage fine-tuning scheme that first applies conventional SFT for format learning, then fine-tunes only on the Key (final answer) portion to boost accuracy. 3. Demonstrates through extensive experiments that SFTKey achieves an average accuracy improvement of over 5% compared to standard SFT while maintaining correct output formatting.",
      "summary": "The paper identifies that standard Supervised Fine-Tuning (SFT) for LLMs can cause an attention imbalance, where models focus too much on long reasoning chains (CoT) and not enough on the final answer. To solve this, the authors propose SFTKey, a two-stage method that first does standard SFT for formatting, then fine-tunes only on the key answer tokens. Experiments show this approach improves average accuracy by over 5% without harming output format correctness.",
      "mindmap": "graph LR\n    A[论文标题 / Paper Title<br>Rethinking Supervised Fine-Tuning] --> B[核心问题 / Problem<br>注意力失衡于长推理链 / Attention Imbalance on Long CoT]\n    A --> C[主要方法 / Method<br>两阶段训练 SFTKey / Two-Stage Training SFTKey]\n    A --> D[关键结果 / Results<br>准确率提升>5% / Accuracy Improvement >5%]"
    },
    {
      "title": "Semi-Supervised Learning for Large Language Models Safety and Content Moderation",
      "authors": "Eduard Stefan Dinuta, Iustin Sirbu, Traian Rebedea",
      "institution": "National University of Science and Technology Politehnica Bucharest, Renius Technologies, NVIDIA",
      "link": "https://arxiv.org/pdf/2512.21107",
      "code": null,
      "tags": [
        "content moderation",
        "semi-supervised learning",
        "data augmentation",
        "safety classifiers",
        "LLM safety",
        "prompt harmfulness"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/035c08c88d89969ce37594942a40aa577a3c0c7c7743cd71bdf84366a9dfa5f2_w640_q70.webp",
      "contributions": "1. Analysis of state-of-the-art semi-supervised learning algorithms for LLM safety, focusing on both prompt and response harmfulness. 2. Introduction of a new, task-specific augmentation technique for safety tasks. 3. Demonstration that task-specific augmentations significantly outperform general-purpose methods like backtranslation.",
      "summary": "This paper addresses the challenge of acquiring high-quality labeled data for training safety classifiers for Large Language Models. It proposes using semi-supervised learning techniques that leverage both labeled and unlabeled data, and introduces a task-specific data augmentation method. The key finding is that this approach, particularly with custom augmentations, significantly improves performance on safety tasks compared to using general-purpose techniques.",
      "mindmap": "graph LR\n    A[论文标题 / Paper Title<br>Semi-Supervised Learning for LLM Safety] --> B[核心问题 / Problem<br>依赖大量标注数据 / Reliance on large labeled data]\n    A --> C[主要方法 / Method<br>半监督学习与任务特定增强 / SSL & Task-Specific Augmentation]\n    A --> D[关键结果 / Results<br>性能显著提升 / Significant Performance Improvement]"
    },
    {
      "title": "Semantic Refinement with LLMs for Graph Representations",
      "authors": "Safal Thapaliya, Zehong Wang, Jiazheng Li, Ziming Li, Yanfang Ye, Chuxu Zhang",
      "institution": "University of Connecticut, University of Notre Dame",
      "link": "https://arxiv.org/pdf/2512.21106",
      "code": null,
      "tags": [
        "graph representation learning",
        "graph neural network",
        "large language model",
        "semantic refinement",
        "structure-semantics heterogeneity",
        "data-centric adaptation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfae73c72759ca834d898f3c6ca5f0824bada06285918fca678e0f809fce9afd_w640_q70.webp",
      "contributions": "1. Proposes a data-centric perspective to address structure-semantics heterogeneity in graphs by treating node semantics as a task-adaptive variable, shifting focus from model-centric inductive bias injection. 2. Introduces the Data-Adaptive Semantic Refinement (DAS) framework, which couples a fixed GNN and an LLM in a closed feedback loop for iterative semantic refinement and graph learning. 3. Demonstrates the framework's effectiveness on diverse graphs, showing consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs.",
      "summary": "This paper addresses the challenge of structure-semantics heterogeneity in graph data, where predictive signals vary across domains. It proposes a Data-Adaptive Semantic Refinement (DAS) framework that uses a closed feedback loop between a GNN and an LLM to iteratively refine node semantics for the learning task. The method shows strong performance on structure-dominated graphs and remains competitive on semantics-rich graphs, validating the data-centric adaptation approach.",
      "mindmap": "graph LR\n    A[Semantic Refinement with LLMs for Graph Representations] --> B(核心问题/Problem: Graph structure-semantics heterogeneity 图的结构-语义异质性)\n    A --> C(主要方法/Method: Data-Adaptive Semantic Refinement (DAS) framework 数据自适应语义精炼框架)\n    A --> D(关键结果/Results: Improves structure-dominated graphs, competitive on semantics-rich graphs 提升结构主导图性能，在语义丰富图上保持竞争力)"
    },
    {
      "title": "Beyond Context: Large Language Models Failure to Grasp Users Intent",
      "authors": "Ahmed M. Hussain, Salahuddin Salahuddin, Panos Papadimitratos",
      "institution": "KTH Royal Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.21110",
      "code": null,
      "tags": [
        "ai safety",
        "intent recognition",
        "contextual understanding",
        "safety circumvention",
        "prompt engineering",
        "transformer architectures"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/55c1a596dd6375317c809bb19f466455285faf18a1f9810649d755b8027e383c_w640_q70.webp",
      "contributions": "1. Identifies and empirically demonstrates a critical vulnerability in LLMs: their inability to understand user intent and context, which allows safety mechanisms to be circumvented. 2. Evaluates multiple state-of-the-art LLMs (ChatGPT, Claude, Gemini, DeepSeek) and shows that exploitation techniques like emotional framing and progressive revelation are effective, and that reasoning capabilities can amplify this risk. 3. Proposes a paradigmatic shift in AI safety design, arguing for contextual understanding and intent recognition to be core capabilities rather than post-hoc protective mechanisms.",
      "summary": "This paper identifies a fundamental vulnerability in Large Language Models (LLMs): their lack of contextual understanding and intent recognition, which allows safety mechanisms to be systematically bypassed. The authors empirically evaluate several LLMs, showing they can be exploited through techniques like emotional framing, and find that reasoning capabilities often worsen the problem. They conclude that a paradigm shift is needed to build intent recognition directly into LLM architectures for safety.",
      "mindmap": "graph LR\n    A[Beyond Context: Large Language Models Failure to Grasp Users Intent] --> B[核心问题/Problem: LLMs缺乏上下文和意图理解能力/LLMs lack contextual understanding & intent recognition]\n    A --> C[主要方法/Method: 对多种LLM进行经验性评估/Empirical evaluation of multiple LLMs]\n    A --> D[关键结果/Results: 安全机制可被系统规避，需范式转变/Safety mechanisms can be systematically circumvented, requiring a paradigm shift]\n    B --> E[导致可利用的漏洞/Creates exploitable vulnerabilities]\n    C --> F[使用情感框架、渐进揭示等技术/Using emotional framing, progressive revelation, etc.]\n    D --> G[Claude Opus 4.1部分例外，推理能力加剧风险/Claude Opus 4.1 partial exception, reasoning amplifies risk]"
    },
    {
      "title": "ClarifyMT-Bench: Benchmarking and Improving Multi-Turn Clarification for Conversational Large Language Models",
      "authors": "Sichun Luo, Yi Huang, Mukai Li, Shichang Meng, Fengyuan Liu, Zefa Hu, Junlan Feng, Qi Liu",
      "institution": "The University of Hong Kong, JIUTIAN Research (China Mobile), City University of Hong Kong",
      "link": "https://arxiv.org/pdf/2512.21120",
      "code": null,
      "tags": [
        "conversational ai",
        "multi-turn clarification",
        "ambiguity taxonomy",
        "agentic approach"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c251a364522d772d4c0ccb3f8108c9a5bafb4d76316e5783c96374fcd1c4488_w640_q70.webp",
      "contributions": "1. Introduces ClarifyMT-Bench, a novel benchmark for multi-turn clarification featuring a five-dimensional ambiguity taxonomy and diverse simulated user personas. 2. Uncovers a consistent \"under-clarification bias\" in LLMs, where they answer prematurely and performance degrades with dialogue depth. 3. Proposes ClarifyAgent, an agentic framework that decomposes clarification into perception, forecasting, tracking, and planning to improve robustness.",
      "summary": "The paper addresses the problem that LLMs tend to answer ambiguous user queries prematurely in multi-turn conversations. To study this, the authors introduce ClarifyMT-Bench, a multi-turn clarification benchmark, and propose ClarifyAgent, an agentic method that improves clarification robustness. The main finding is that current LLMs have an under-clarification bias, which the proposed agentic approach helps mitigate.",
      "mindmap": "graph LR\n    A[ClarifyMT-Bench] --> B[核心问题/Problem: LLMs under-clarify in multi-turn dialogues]\n    A --> C[主要方法/Method: Benchmark + ClarifyAgent]\n    C --> D[Benchmark: 多轮对话基准/Multi-turn Benchmark]\n    C --> E[Agent: 代理方法/Agentic Approach]\n    A --> F[关键结果/Results: Bias identified, Agent improves robustness]"
    },
    {
      "title": "SpidR-Adapt: A Universal Speech Representation Model for Few-Shot Adaptation",
      "authors": "Mahi Luthra, Jiayi Shen, Maxime Poli, Angelo Ortiz, Yosuke Higuchi, Youssef Benchekroun, Martin Gleize, Charles-Eric Saint-James, Dongyan Lin, Phillip Rust, Angel Villar, Surya Parimi, Vanessa Stark, Rashel Moritz, Juan Pino, Yann LeCun, Emmanuel Dupoux",
      "institution": "Meta AI, ENS-PSL, EHESS, CNRS",
      "link": "https://arxiv.org/pdf/2512.21204",
      "code": "https://github.com/facebookresearch/spidr-adapt",
      "tags": [
        "speech representation learning",
        "meta-learning",
        "bi-level optimization",
        "few-shot adaptation",
        "self-supervised learning",
        "speech representation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff9692c36cbda26291fde2551256e229a90f6eb51f087d833a2d84cb4b10925b_w640_q70.webp",
      "contributions": "1. Introduces the Multi-task Adaptive Pre-training (MAdaPT) protocol, framing few-shot speech representation learning as a bi-level optimization meta-learning problem. 2. Proposes a novel First-Order Bi-Level Optimization (FOBLO) heuristic to enable scalable meta-training by avoiding heavy computation costs. 3. Stabilizes meta-training with a robust initialization technique using interleaved supervision that alternates between self-supervised and supervised objectives.",
      "summary": "This paper introduces SpidR-Adapt, a method for rapid adaptation of speech representation models to new languages using minimal unlabeled data. It formulates the problem as meta-learning with a bi-level optimization framework (MAdaPT), proposes an efficient solver (FOBLO), and uses interleaved supervision for stable training. The model achieves significant gains in phonemic discrimination and language modeling after training on less than 1 hour of target-language audio, demonstrating over 100x greater data efficiency than standard methods.",
      "mindmap": "graph LR\n        A[SpidR-Adapt] --> B[核心问题/Problem: 数据效率差距/Data-Efficiency Gap]\n        A --> C[主要方法/Method: 元学习与双层优化/Meta-Learning & Bi-Level Optimization]\n        A --> D[关键结果/Results: 100倍数据效率/100x Data Efficiency]\n        B --> B1[婴儿高效 vs. 模型低效/Infant Efficiency vs. Model Inefficiency]\n        C --> C1[MAdaPT协议/MAdaPT Protocol]\n        C --> C2[FOBLO优化/FOBLO Optimization]\n        C --> C3[交错监督/Interleaved Supervision]\n        D --> D1[<1h音频/<1h Audio]\n        D --> D2[音素可辨性提升/Improved Phonemic Discriminability]"
    },
    {
      "title": "ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling",
      "authors": "Chuan Wang, Gaoming Yang, Han Wu, Jiakai Tang, Jiahao Yu, Jian Wu, Jianwu Hu, Junjun Zheng, Shuwen Xiao, Yeqiu Yang, Yuning Jiang, Ahjol Nurlanbek, Binbin Cao, Bo Zheng, Fangmei Zhu, Gaoming Zhou, Huimin Yi, Huiping Chu, Jin Huang, Jinzhe Shan, Kenan Cui, Longbin Li, Silu Zhou, Wen Chen, Xia Ming, Xiang Gao, Xin Yao, Xingyu Wen, Yan Zhang, Yiwen Hu, Yulin Wang, Ziheng Bao, Zongyuan Wu",
      "institution": "TaoRank Team (Alibaba Group / Taobao)",
      "link": "https://arxiv.org/pdf/2512.21257",
      "code": null,
      "tags": [
        "agent system",
        "sequential modeling",
        "chain-of-thought reasoning",
        "diffusion large language models",
        "multi-agent collaboration",
        "world knowledge"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f98d5c26b79acf6e7c20219639988198127de51ba1227ceaeb063216243ba42_w640_q70.webp",
      "contributions": "1. Proposes ReaSeq, a reasoning-enhanced framework that leverages LLM world knowledge to overcome limitations of log-driven recommender systems. 2. Introduces explicit Chain-of-Thought reasoning via multi-agent collaboration to distill structured product knowledge into enriched item representations. 3. Employs latent reasoning via Diffusion LLMs to infer plausible beyond-log user behaviors, enhancing interest modeling.",
      "summary": "The paper introduces ReaSeq, a framework that uses Large Language Models' world knowledge for explicit and implicit reasoning to address knowledge poverty and systemic blindness in log-driven industrial recommender systems. It enhances item representations and infers beyond-log user behaviors. Deployed on Taobao, it achieved significant improvements in key business metrics like CTR and GMV.",
      "mindmap": "graph LR\n        A[ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[知识贫乏/Knowledge Poverty in ID-based Representations]\n        B --> B2[系统盲区/Systemic Blindness to Beyond-Log Interests]\n        C --> C1[显式推理/Explicit Chain-of-Thought Reasoning via Multi-Agent]\n        C --> C2[隐式推理/Latent Reasoning via Diffusion LLMs]\n        D --> D1[IPV & CTR提升 >6.0%/IPV & CTR Gain >6.0%]\n        D --> D2[订单提升 >2.9%/Orders Gain >2.9%]\n        D --> D3[GMV提升 >2.5%/GMV Gain >2.5%]"
    },
    {
      "title": "SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance",
      "authors": "Divij Dudeja, Mayukha Pal",
      "institution": "ABB Ability Innovation Center, Indian Institute of Information Technology, Nagpur",
      "link": "https://arxiv.org/pdf/2512.21280",
      "code": null,
      "tags": [
        "document question answering",
        "Tree-LSTM",
        "Memory Augmented Neural Network (MANN)",
        "Retrieval Augmented Generation (RAG)",
        "Parameter Efficiency",
        "Fact Extraction"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fe5f40637f711007d6bb6875182fa80072536380614c5e93c7c4f5cf8dc2232_w640_q70.webp",
      "contributions": "1. Introduces a hierarchical, syntax-aware fact extractor (Grammarian Tree-LSTM) to parse engineering manuals into structured subject-relation-object triples., 2. Proposes a compact, indexed memory system (MANN) to store and retrieve extracted facts as vectors, enabling efficient knowledge access., 3. Designs a dual-mode inference system combining a fast path for known documents and a dynamic RAG-assisted path for new uploads, reducing hallucinations.",
      "summary": "The paper addresses the challenge of accurately answering questions from dense engineering manuals, where standard small language models fail. It proposes SMART, a structured model that hierarchically extracts facts, stores them in an indexed memory, and uses a transformer to generate answers from retrieved facts. The result is a parameter-efficient model that achieves higher accuracy with fewer parameters and reduced hallucinations compared to baselines like GPT-2.",
      "mindmap": "graph LR\n    A[SMART SLM] --> B[核心问题/Problem: 工程手册难以阅读，现有小模型处理为扁平token流，导致错误答案/Engineering manuals are hard to read; flat token processing leads to incorrect answers]\n    A --> C[主要方法/Method: 分层处理：语法感知事实提取器 + 索引记忆(MANN) + 6层Transformer/Hierarchical processing: Syntax-aware fact extractor + Indexed memory (MANN) + 6-layer Transformer]\n    A --> D[关键结果/Results: 参数减少64-69%，准确率提升21.3%，减少幻觉/64-69% fewer parameters, 21.3% higher accuracy, reduced hallucinations]"
    },
    {
      "title": "Parallel Token Prediction for Language Models",
      "authors": "Felix Draxler, Justus Will, Farrin Marouf Sofian, Theofanis Karaletsos, Sameer Singh, Stephan Mandt",
      "institution": "University of California, Irvine, Chan-Zuckerberg Initiative, Pyramidal AI",
      "link": "https://arxiv.org/pdf/2512.21323",
      "code": null,
      "tags": [
        "llm inference",
        "parallel token prediction",
        "speculative decoding",
        "autoregressive decoding",
        "transformer inference",
        "latency optimization"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d5681ed12f339fba2f3eb1e012a75a0b58e77b2c9c9aa20352d3b12fcba4f3c_w640_q70.webp",
      "contributions": "1. Proposes Parallel Token Prediction (PTP), a universal framework for parallel sequence generation that jointly predicts multiple dependent tokens in a single transformer call. 2. Proves that PTP can represent arbitrary autoregressive sequence distributions, avoiding the restrictive independence assumptions of prior multi-token prediction methods. 3. Demonstrates state-of-the-art speculative decoding performance, accepting over four tokens per step on Spec-Bench with Vicuna-7B, showing parallel long-sequence generation is feasible without losing modeling power.",
      "summary": "The paper addresses the high latency of autoregressive decoding in large language models by proposing Parallel Token Prediction (PTP), a framework that predicts multiple dependent tokens in parallel within a single transformer call. It proves PTP's universality in representing autoregressive distributions and shows it achieves superior speculative decoding performance, enabling faster text generation without sacrificing quality.",
      "mindmap": "graph LR\n    A[Parallel Token Prediction for Language Models] --> B[核心问题/Problem: Autoregressive decoding latency bottleneck]\n    A --> C[主要方法/Method: Parallel Token Prediction (PTP), joint prediction of dependent tokens]\n    A --> D[关键结果/Results: State-of-the-art speculative decoding, >4 tokens/step, universal framework]"
    },
    {
      "title": "Measuring all the noises of LLM Evals",
      "authors": "Sida Wang",
      "institution": "FAIR at Meta",
      "link": "https://arxiv.org/pdf/2512.21326",
      "code": null,
      "tags": [
        "llm inference",
        "LLM evaluation",
        "statistical noise",
        "paired analysis",
        "prediction variance",
        "data variance"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa15912febac5bc93aec8d1b8870feaf16ae89016c37e24c26550d053d396fec_w640_q70.webp",
      "contributions": "1. Clearly defines and measures three types of noise (prediction, data, total) in LLM evaluations using the law of total variance. 2. Proposes the \"all-pairs paired method\" to apply paired statistical analysis across all model pairs for increased statistical power. 3. Empirically reveals that total noise is predictable per evaluation and that prediction noise typically dominates data noise, enabling more effective significance testing.",
      "summary": "This paper addresses the challenge of statistical noise in Large Language Model (LLM) evaluations. It proposes an \"all-pairs paired method\" to measure prediction, data, and total noise across model pairs. The key findings are that each evaluation benchmark has a characteristic noise level and that reducing prediction noise through averaging can significantly improve the detection of performance differences.",
      "mindmap": "graph LR\n    A[Measuring all the noises of LLM Evals] --> B(核心问题/Problem: LLM评估中的统计噪声/Separating signal from noise in LLM evals)\n    A --> C(主要方法/Method: 全配对分析法/All-pairs paired method)\n    A --> D(关键结果/Results: 可预测的总噪声与主导的预测噪声/Predictable total noise & dominant prediction noise)"
    },
    {
      "title": "Your Reasoning Benchmark May Not Test Reasoning: Revealing Perception Bottleneck in Abstract Reasoning Benchmarks",
      "authors": "Xinhe Wang, Jin Huang, Xingjian Zhang, Tianhao Wang, Jiaqi W. Ma",
      "institution": "Carnegie Mellon University, University of Michigan, University of California San Diego, University of Illinois Urbana-Champaign",
      "link": "https://arxiv.org/pdf/2512.21329",
      "code": null,
      "tags": [
        "reasoning evaluation",
        "abstract reasoning",
        "perception bottleneck",
        "vision-language models",
        "inductive reasoning",
        "evaluation protocol"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fcc43646a911ef2be3f5f5aea5201f8582d0ad2c6e3465915701cc2f7fb9f09_w640_q70.webp",
      "contributions": "1. Proposes a two-stage experimental pipeline to explicitly separate perception and reasoning in abstract reasoning benchmarks. 2. Empirically demonstrates that perception capability, not reasoning, is the dominant factor in the performance gap for VLMs on ARC-style tasks. 3. Reveals through manual analysis that approximately 80% of model failures stem from perception errors, challenging the common interpretation of these benchmarks.",
      "summary": "The paper challenges the view that poor performance of vision-language models on abstract reasoning benchmarks like ARC indicates a reasoning deficiency. It introduces a two-stage pipeline that isolates perception (image-to-text description) from reasoning (rule induction on text) and shows that perception bottlenecks are the primary cause of failure, suggesting current benchmarks conflate these challenges.",
      "mindmap": "graph LR\n    A[Your Reasoning Benchmark May Not Test Reasoning] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[VLMs在抽象推理基准上表现不佳，通常归因于推理缺陷/VLMs perform poorly on abstract reasoning benchmarks, often attributed to reasoning deficits]\n    C --> C1[提出两阶段实验流程：感知（图像到文本）与推理（基于文本的规则归纳）/Propose a two-stage pipeline: Perception (image-to-text) and Reasoning (text-based rule induction)]\n    D --> D1[感知能力是性能差距的主导因素，约80%的失败源于感知错误/Perception is the dominant factor for the performance gap, ~80% of failures stem from perception errors]"
    },
    {
      "title": "C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling",
      "authors": "Jin Qin, Zihan Liao, Ziyin Zhang, Hang Yu, Peng Di, Rui Wang",
      "institution": "Ant Group, Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.21332",
      "code": "https://github.com/codefuse-ai/CodeFuse-Embeddings",
      "tags": [
        "code retrieval",
        "Pooling by Multihead Attention (PMA)",
        "contrastive learning",
        "code embedding",
        "MTEB-Code",
        "Qwen-2.5-Coder"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f27c6e6ad01eacb3bd759d1aafa323cd3f72410efd901b1df691e709d8fbe3a4_w640_q70.webp",
      "contributions": "1. Proposes a Pooling by Multihead Attention (PMA) module to generate sequence embeddings from token embeddings, effectively utilizing the LLM's causal representations. 2. The PMA module aggregates information from all tokens in a sequence, overcoming the information bottleneck of traditional EOS-based sequence embeddings. 3. The approach supports flexible adaptation of embedding dimensions, serving as an alternative to Multi-Representation Learning (MRL).",
      "summary": "This paper introduces C2LLM, a family of code embedding models built on Qwen-2.5-Coder backbones. It proposes a novel Pooling by Multihead Attention (PMA) module to create better sequence embeddings for code retrieval. The models, trained on three million data points, achieve state-of-the-art performance on the MTEB-Code benchmark, with the 7B version ranking first overall.",
      "mindmap": "graph LR\n        A[C2LLM Technical Report] --> B[核心问题/Problem: 代码检索中的序列表示瓶颈/Sequence representation bottleneck in code retrieval]\n        A --> C[主要方法/Method: 自适应交叉注意力池化 (PMA) / Adaptive Cross-Attention Pooling (PMA)]\n        A --> D[关键结果/Results: 在MTEB-Code上SOTA / SOTA on MTEB-Code]"
    },
    {
      "title": "Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty",
      "authors": "Ziyu Chen, Xinbei Jiang, Peng Sun, Tao Lin",
      "institution": "Zhejiang University, Westlake University, University of Chicago",
      "link": "https://arxiv.org/pdf/2512.21336",
      "code": "https://github.com/LINs-lab/DenoisingEntropy",
      "tags": [
        "diffusion models",
        "Denoising Entropy",
        "Masked Diffusion Models",
        "decoding path optimization",
        "predictive uncertainty",
        "non-autoregressive generation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4480eb4fa3d14900373effb4e74dd207b42c650b50de1044a2cad8b4036e465f_w640_q70.webp",
      "contributions": "1. Formalized the problem of decoding path sensitivity in Masked Diffusion Models (MDMs) by introducing the concept of cumulative Path Uncertainty. 2. Proposed Denoising Entropy, a novel, computable metric to quantify predictive uncertainty along a generative path. 3. Developed two entropy-guided algorithms (post-hoc selection and real-time guidance) to optimize the decoding path and improve generation quality.",
      "summary": "The paper identifies that the flexible generation of Masked Diffusion Models (MDMs) leads to variable output quality due to the chosen decoding order. To address this, it introduces Denoising Entropy to measure path uncertainty and proposes two algorithms that use this metric to guide the decoding process. Experiments show these methods significantly improve generation accuracy on reasoning, planning, and code tasks, turning uncertainty into an advantage.",
      "mindmap": "graph LR\n        A[Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty<br/>通过量化不确定性优化掩码扩散模型的解码路径] --> B(核心问题/Problem: MDMs生成质量对解码顺序敏感<br/>MDM output quality is sensitive to decoding order)\n        A --> C(主要方法/Method: 提出去噪熵和路径优化算法<br/>Propose Denoising Entropy & path optimization algorithms)\n        A --> D(关键结果/Results: 熵引导方法提升生成质量<br/>Entropy-guided methods improve generation quality)"
    },
    {
      "title": "Decoding Predictive Inference in Visual Language Processing via Spatiotemporal Neural Coherence",
      "authors": "Sean C. Borneman, Julia Krebs, Ronnie B. Wilbur, Evie A. Malaia",
      "institution": "Carnegie-Mellon University, University of Salzburg, Purdue University, University of Alabama",
      "link": "https://arxiv.org/pdf/2512.20929",
      "code": null,
      "tags": [
        "computational neuroscience",
        "predictive coding",
        "EEG",
        "neural coherence",
        "optical flow",
        "entropy-based feature selection"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d4252b4df430bb18f969d798aff092b793b8033ce3e2ca01f2a17d6aeff53f1_w640_q70.webp",
      "contributions": "1. A novel machine learning framework for decoding EEG responses to dynamic visual language (sign language) using spatiotemporal neural coherence. 2. The identification of frequency-specific neural signatures (distributed left-hemispheric and frontal low-frequency coherence) that differentiate linguistic from non-linguistic visual input. 3. Demonstration of experience-dependent neural signatures correlating with age, linking lifelong exposure to the shaping of internal generative models for visual language.",
      "summary": "This paper proposes a machine learning framework that uses coherence between EEG signals and optical flow features to decode predictive neural dynamics in Deaf signers watching sign language. The method identifies specific low-frequency neural signatures crucial for language comprehension and shows these signatures are experience-dependent. The work provides a novel multimodal approach for probing the brain's generative models of visual language perception.",
      "mindmap": "graph LR\n        A[Decoding Predictive Inference in Visual Language Processing via Spatiotemporal Neural Coherence<br>通过时空神经一致性解码视觉语言处理中的预测推理] --> B(核心问题/Problem: How does the brain perform predictive inference during visual language (sign language) comprehension?<br>大脑如何在视觉语言（手语）理解中进行预测推理？)\n        A --> C(主要方法/Method: A machine learning framework using EEG-optical flow coherence & entropy-based feature selection.<br>使用EEG-光流一致性及基于熵的特征选择的机器学习框架。)\n        A --> D(关键结果/Results: Identified left-hemispheric/frontal low-frequency coherence as key; neural signatures are experience-dependent.<br>发现左半球/前额低频一致性是关键；神经特征具有经验依赖性。)"
    },
    {
      "title": "HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data",
      "authors": "Shashi Kant Gupta, Arijeet Pramanik, Jerrin John Thomas, Regina Schwind, Lauren Wiener, Avi Raju, Jeremy Kornbluth, Yanshan Wang, Zhaohui Su, Hrituraj Singh",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19864",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e0cfa9ec043e8a27718dd14bb89bf3c4ceafb97fb48a8a0b61d661ec9d34b09_w640_q70.webp",
      "contributions": "",
      "summary": "HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data",
      "mindmap": ""
    },
    {
      "title": "How well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse",
      "authors": "Kirk Vanacore, Rene F. Kizilcec",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19903",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcd1ac8680cb9e68b32ea021e524b8dddd82c5081672c081d9ac46ec2f2c6180_w640_q70.webp",
      "contributions": "",
      "summary": "How well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse",
      "mindmap": ""
    },
    {
      "title": "Counterfactual LLM-based Framework for Measuring Rhetorical Style",
      "authors": "Jingyi Qiu, Hong Chen, Zongyi Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19908",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6db39310497bbc29a6efe3c72529c4c231f4c45f6ccb6856571045197a2f074d_w640_q70.webp",
      "contributions": "",
      "summary": "Counterfactual LLM-based Framework for Measuring Rhetorical Style",
      "mindmap": ""
    },
    {
      "title": "PRISM: A Personality-Driven Multi-Agent Framework for Social Media Simulation",
      "authors": "Zhixiang Lu, Xueyuan Deng, Yiran Liu, Yulong Li, Qiang Yan, Imran Razzak, Jionglong Su",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19933",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3acfc234a0a131551ac80194bbad4cea0eac21fb397065d4acf70449da5327f6_w640_q70.webp",
      "contributions": "",
      "summary": "PRISM: A Personality-Driven Multi-Agent Framework for Social Media Simulation",
      "mindmap": ""
    },
    {
      "title": "Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems",
      "authors": "Heet Bodara, Md Masum Mushfiq, Isma Farah Siddiqui",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19950",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25282dd436ce0f7a5fabd0438ec9d8be57567585d626e71c9a9af6d0ac8451b9_w640_q70.webp",
      "contributions": "",
      "summary": "Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems",
      "mindmap": ""
    },
    {
      "title": "Schoenfeld's Anatomy of Mathematical Reasoning by Language Models",
      "authors": "Ming Li, Chenrui Fan, Yize Cheng, Soheil Feizi, Tianyi Zhou",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19995",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf100eeda1c44688829760003993b1a83478a2d2901a0f5a0b9914bc5ef7c3b0_w640_q70.webp",
      "contributions": "",
      "summary": "Schoenfeld's Anatomy of Mathematical Reasoning by Language Models",
      "mindmap": ""
    },
    {
      "title": "Reason2Decide: Rationale-Driven Multi-Task Learning",
      "authors": "H M Quamran Hasan, Housam Khalifa Bashier, Jiayi Dai, Mi-Young Kim, Randy Goebel",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20074",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/187b806c979650defdb64bdb9ce297598ef473654b93625ec2257af228dbd0da_w640_q70.webp",
      "contributions": "",
      "summary": "Reason2Decide: Rationale-Driven Multi-Task Learning",
      "mindmap": ""
    },
    {
      "title": "Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents",
      "authors": "Yiming Du, Baojun Wang, Yifan Xiang, Zhaowei Wang, Wenyu Huang, Boyang Xue, Bin Liang, Xingshan Zeng, Fei Mi, Haoli Bai, Lifeng Shang, Jeff Z. Pan, Yuxin Jiang, Kam-Fai Wong",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20092",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f21f9409d7ddcd534ada400fa2d7b093de0f8e8672067e512129d84ead74883_w640_q70.webp",
      "contributions": "",
      "summary": "Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents",
      "mindmap": ""
    },
    {
      "title": "A Novel Graph-Sequence Learning Model for Inductive Text Classification",
      "authors": "Zuo Wang, Ye Yuan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20097",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d452912781840b7b95df9d1137178809626a19d0d789bf4b893df1553a7c677d_w640_q70.webp",
      "contributions": "",
      "summary": "A Novel Graph-Sequence Learning Model for Inductive Text Classification",
      "mindmap": ""
    },
    {
      "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language",
      "authors": "Aly Lidayan, Jakob Bjorner, Satvik Golechha, Kartik Goyal, Alane Suhr",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20111",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d0d34b2d9754cdb266cf6f4c20cff854836475921a3b1dfd5eebd552c7ef69c_w640_q70.webp",
      "contributions": "",
      "summary": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language",
      "mindmap": ""
    },
    {
      "title": "Multi-hop Reasoning via Early Knowledge Alignment",
      "authors": "Yuxin Wang, Shicheng Fang, Bo Wang, Qi Luo, Xuanjing Huang, Yining Zheng, Xipeng Qiu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20144",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d88b182b244d4a4ceb1d9822c08a4a4d748f40278f40b510b9dc474ab390f2c_w640_q70.webp",
      "contributions": "",
      "summary": "Multi-hop Reasoning via Early Knowledge Alignment",
      "mindmap": ""
    },
    {
      "title": "Retrieval-augmented Prompt Learning for Pre-trained Foundation Models",
      "authors": "Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20145",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028ab8e7171d7f497cbdc48e136d419e8642bf876111786382aee29b15d0992_w640_q70.webp",
      "contributions": "",
      "summary": "Retrieval-augmented Prompt Learning for Pre-trained Foundation Models",
      "mindmap": ""
    },
    {
      "title": "M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation",
      "authors": "Hyeongcheol Park, Jiyoung Seo, Jaewon Mun, Hogun Park, Wonmin Byeon, Sung June Kim, Hyeonsoo Im, JeungSub Lee, Sangpil Kim",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20136",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6c211a1c8d3a17c264fe9655b35305f3ece6ef329a1cb2344fb1a18976f11017_w640_q70.webp",
      "contributions": "",
      "summary": "M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation",
      "mindmap": ""
    },
    {
      "title": "Fun-Audio-Chat Technical Report",
      "authors": "Qian Chen, Luyao Cheng, Chong Deng, Xiangang Li, Jiaqing Liu, Chao-Hong Tan, Wen Wang, Junhao Xu, Jieping Ye, Qinglin Zhang, Qiquan Zhang, Jingren Zhou",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20156",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eedb25d29b9c63de7f75bd47632c06e734814fe19fe3f517a37a4d3d42f693c7_w640_q70.webp",
      "contributions": "",
      "summary": "Fun-Audio-Chat Technical Report",
      "mindmap": ""
    },
    {
      "title": "AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications",
      "authors": "Honglin Mu, Jinghao Liu, Kaiyang Wan, Rui Xing, Xiuying Chen, Timothy Baldwin, Wanxiang Che",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20164",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be09765889dd9516b45fd948d07346b8b6487f6dc02927a597c1cab7861bfb7_w640_q70.webp",
      "contributions": "",
      "summary": "AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications",
      "mindmap": ""
    },
    {
      "title": "Learning to Reason in LLMs by Expectation Maximization",
      "authors": "Junghyun Lee, Branislav Kveton, Sunav Choudhary, Subhojyoti Mukherjee, Anup Rao, Ryan A. Rossi, Alexa Siu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20169",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fc3f6af733f26b26d15d5332cff89ae665d865f5359eb651dbf107c200c4794_w640_q70.webp",
      "contributions": "",
      "summary": "Learning to Reason in LLMs by Expectation Maximization",
      "mindmap": ""
    },
    {
      "title": "Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark",
      "authors": "Hao Guo, Xugong Qin, Jun Jie Ou Yang, Peng Zhang, Gangyan Zeng, Yubo Li, Hailun Lin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20174",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a74295652803d99c4b0631ef38e9684d12032ddd9797f217033f356497ff647_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark",
      "mindmap": ""
    },
    {
      "title": "FaithLens: Detecting and Explaining Faithfulness Hallucination",
      "authors": "Shuzheng Si, Qingyi Wang, Haozhe Zhao, Yuzhuo Bai, Guanqiao Chen, Kangyang Luo, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20182",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/418ec0226018d595ee93c7097014ac35b5c5e68ad18001889120bf6c5aa27d11_w640_q70.webp",
      "contributions": "",
      "summary": "FaithLens: Detecting and Explaining Faithfulness Hallucination",
      "mindmap": ""
    },
    {
      "title": "Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings",
      "authors": "Marko Čechovič, Natália Komorníková, Dominik Macháček, Ondřej Bojar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20204",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d50c0d1f767aca0e832de0ef650261ca473b1bbf6f1ac37ad18132605e13bc77_w640_q70.webp",
      "contributions": "",
      "summary": "Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings",
      "mindmap": ""
    },
    {
      "title": "AprielGuard",
      "authors": "Jaykumar Kasundra, Anjaneya Praharaj, Sourabh Surana, Lakshmi Sirisha Chodisetty, Sourav Sharma, Abhigya Verma, Abhishek Bhardwaj, Debasish Kanhar, Aakash Bhagat, Khalil Slimi, Seganrasan Subramanian, Sathwik Tejaswi Madhusudhan, Ranga Prasad Chenna, Srinivas Sunkara",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20293",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1df72be31938b1703d3c0991c388a31ae15e5ab7e811b6868c1d2b87ce212408_w640_q70.webp",
      "contributions": "",
      "summary": "AprielGuard",
      "mindmap": ""
    },
    {
      "title": "Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives",
      "authors": "Karolina Drożdż, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20298",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e46ae09622d9142a3896f2528685617edcbaae96bc105754e16929ed630e3f0_w640_q70.webp",
      "contributions": "",
      "summary": "Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives",
      "mindmap": ""
    },
    {
      "title": "SlideTailor: Personalized Presentation Slide Generation for Scientific Papers",
      "authors": "Wenzheng Zeng, Mingyu Ouyang, Langyuan Cui, Hwee Tou Ng",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20292",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f80870c0718240101f019ec3db0f39be1afd3c26281e0c20366762d11e67351_w640_q70.webp",
      "contributions": "",
      "summary": "SlideTailor: Personalized Presentation Slide Generation for Scientific Papers",
      "mindmap": ""
    },
    {
      "title": "SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision",
      "authors": "Maxime Poli, Mahi Luthra, Youssef Benchekroun, Yosuke Higuchi, Martin Gleize, Jiayi Shen, Robin Algayres, Yu-An Chung, Mido Assran, Juan Pino, Emmanuel Dupoux",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20308",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6351d1c5218be825df7f7572c20ff77011eb6baf9648cff6ea5fd370a23fda1_w640_q70.webp",
      "contributions": "",
      "summary": "SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision",
      "mindmap": ""
    },
    {
      "title": "Can LLMs Solve My Grandma's Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles",
      "authors": "Nurul Labib Sayeedi, Md. Faiyaz Abdullah Sayeedi, Khushnur Binte Jahangir, Swakkhar Shatabda, Sarah Masud Preum",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20324",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76de34d24836232b3e2c53b464d6001663ee4428a6ebe0f1d009c4d37f298fc_w640_q70.webp",
      "contributions": "",
      "summary": "Can LLMs Solve My Grandma's Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles",
      "mindmap": ""
    },
    {
      "title": "Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation",
      "authors": "Nilesh Jain, Seyi Adeyinka, Leor Roseman, Aza Allsop",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20352",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2047f0800a6a91a372fd66013fa3526084396a7513879598fb459814e55b18c_w640_q70.webp",
      "contributions": "",
      "summary": "Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation",
      "mindmap": ""
    },
    {
      "title": "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems",
      "authors": "YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20387",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d9aa5293bf4ca8e839b122277f1484ffb43b6211d54741d7eb7f58312f5509_w640_q70.webp",
      "contributions": "",
      "summary": "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems",
      "mindmap": ""
    },
    {
      "title": "Sentiment-Aware Extractive and Abstractive Summarization for Unstructured Text Mining",
      "authors": "Junyi Liu, Stanley Kok",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20404",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cbe3d2a9e0dbffa2ba1d89f2d2d61bcc3900bbeb02faaa7db06ace8b2d8e09b_w640_q70.webp",
      "contributions": "",
      "summary": "Sentiment-Aware Extractive and Abstractive Summarization for Unstructured Text Mining",
      "mindmap": ""
    },
    {
      "title": "Step-DeepResearch Technical Report",
      "authors": "Chen Hu, Haikuo Du, Heng Wang, Lin Lin, Mingrui Chen, Peng Liu, Ruihang Miao, Tianchi Yue, Wang You, Wei Ji, Wei Yuan, Wenjin Deng, Xiaojian Yuan, Xiaoyun Zhang, Xiangyu Liu, Xikai Liu, Yanming Xu, Yicheng Cao, Yifei Zhang, Yongyao Wang, Yubo Shu, Yurong Zhang, Yuxiang Zhang, Zheng Gong, Zhichao Chang, Binyan Li, Dan Ma, Furong Jia, Hongyuan Wang, Jiayu Liu, Jing Bai, Junlan Liu, Manjiao Liu, Na Wang, Qiuping Wu, Qinxin Du, Shiwei Li, Wen Sun, Yifeng Gong, Yonglin Chen, Yuling Zhao, Yuxuan Lin, Ziqi Ren, Zixuan Wang, Aihu Zhang, Brian Li, Buyun Ma, Kang An, Li Xie, Mingliang Li, Pan Li, Shidong Yang, Xi Chen, Xiaojia Liu, Yuchu Luo, Yuan Song, YuanHao Ding, Yuanwei Liang, Zexi Li, Zhaoning Zhang, Zixin Zhang, Binxing Jiao, Daxin Jiang, Jiansheng Chen, Jing Li, Xiangyu Zhang, Yibo Zhu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20491",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e31009744d096e0b219624a8cb385cd29ef47c699069fff12401b051dd695f_w640_q70.webp",
      "contributions": "",
      "summary": "Step-DeepResearch Technical Report",
      "mindmap": ""
    },
    {
      "title": "Distilling to Hybrid Attention Models via KL-Guided Layer Selection",
      "authors": "Yanhong Li, Songlin Yang, Shawn Tan, Mayank Mishra, Rameswar Panda, Jiawei Zhou, Yoon Kim",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20569",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e36c08fad9c560eeacd24d61bbc8fc4ace2f57a4dda4d1eaeb59a63b10f01d2e_w640_q70.webp",
      "contributions": "",
      "summary": "Distilling to Hybrid Attention Models via KL-Guided Layer Selection",
      "mindmap": ""
    },
    {
      "title": "Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits",
      "authors": "Amirhosein Ghasemabadi, Di Niu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20578",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f0ae4be0acd6ad133b6649afc37037f398f8e5753e19ae55612dfc2522618af9_w640_q70.webp",
      "contributions": "",
      "summary": "Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits",
      "mindmap": ""
    },
    {
      "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
      "authors": "Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20586",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39917d1df3de96bd690d947b78c3c6d1ac037b54cc0591faa464cbc08cd8c729_w640_q70.webp",
      "contributions": "",
      "summary": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
      "mindmap": ""
    },
    {
      "title": "Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs",
      "authors": "Dhruv Anand, Ehsan Shareghi",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20595",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb95f031dbfb3f7bfc348a6d3e77d5c3ae7e2408f06dd57529b77764de0ce0b7_w640_q70.webp",
      "contributions": "",
      "summary": "Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs",
      "mindmap": ""
    },
    {
      "title": "Making Large Language Models Efficient Dense Retrievers",
      "authors": "Yibin Lei, Shwai He, Ang Li, Andrew Yates",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20612",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40238eef858f9a1a1327758d04b0c4c31e71fbbf6df6898a51ccf0f7ff9a8f36_w640_q70.webp",
      "contributions": "",
      "summary": "Making Large Language Models Efficient Dense Retrievers",
      "mindmap": ""
    },
    {
      "title": "MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts",
      "authors": "Alexandros Christoforos, Chadbourne Davis",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20604",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/740b7502b49c1387c998a9fd8b95bff7878c9c8ecb80d21efccf1c64db303459_w640_q70.webp",
      "contributions": "",
      "summary": "MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts",
      "mindmap": ""
    },
    {
      "title": "Coherence in the brain unfolds across separable temporal regimes",
      "authors": "Davide Stauba, Finn Rabe, Akhil Misra, Yves Pauli, Roya Hüppi, Nils Lang, Lars Michels, Victoria Edkins, Sascha Frühholz, Iris Sommer, Wolfram Hinzen, Philipp Homan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20481",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ad4bde9d11d688dda33f0f878fe578450d6097fcbcbf36ba57e75d54765a25e_w640_q70.webp",
      "contributions": "",
      "summary": "Coherence in the brain unfolds across separable temporal regimes",
      "mindmap": ""
    },
    {
      "title": "Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning",
      "authors": "Lihui Liu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17912",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/154351bb01594c209c639a3724124babafa831a2c5526b2f6bb79e4ec436950a_w640_q70.webp",
      "contributions": "",
      "summary": "Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning",
      "mindmap": ""
    },
    {
      "title": "Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression",
      "authors": "Rahul Baxi",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17920",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e85dcb740e46985e03fe90bf075468b334e1528a3de2a4858fac5b2ddbc2dc9_w640_q70.webp",
      "contributions": "",
      "summary": "Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression",
      "mindmap": ""
    },
    {
      "title": "Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models",
      "authors": "Hongji Li, Junchi yao, Manjiang Yu, Priyanka Singh, Xue Li, Di Wang, Lijie Hu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17911",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/218d6b0cd750a67af41f0ec36e744aed0a36e9ad83656c3a4c9ed70aa75b977d_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Learning to Prioritize IT Tickets: A Comparative Evaluation of Embedding-based Approaches and Fine-Tuned Transformer Models",
      "authors": "Minh Tri LÊ, Ali Ait-Bachir",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17916",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a9a26225e6a2c495c48df9cb6a0e4bd0c624c036e56d8d0cf9885d0d909a745_w640_q70.webp",
      "contributions": "",
      "summary": "Learning to Prioritize IT Tickets: A Comparative Evaluation of Embedding-based Approaches and Fine-Tuned Transformer Models",
      "mindmap": ""
    },
    {
      "title": "KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction",
      "authors": "Aomufei Yuan, Zhiming Wang, Ruijie Miao, Dayu Wang, Yuxuan Tian, Zihan Wang, Yebo Peng, Yuhan Wu, Bairen Yi, Xin Liu, Tong Yang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17917",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ca40de411c47ab6f32fb67699fbcdce0808ef0d5179742bf46c64d088a640d3_w640_q70.webp",
      "contributions": "",
      "summary": "KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction",
      "mindmap": ""
    },
    {
      "title": "Q-KVComm: Efficient Multi-Agent Communication Via Adaptive KV Cache Compression",
      "authors": "Boris Kriuk, Logic Ng",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17914",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d4fd665329b7eb837ca00f1091de17f8b4c1eb920670c43995680ca539562ae_w640_q70.webp",
      "contributions": "",
      "summary": "Q-KVComm: Efficient Multi-Agent Communication Via Adaptive KV Cache Compression",
      "mindmap": ""
    },
    {
      "title": "Supplementary Resources and Analysis for Automatic Speech Recognition Systems Trained on the Loquacious Dataset",
      "authors": "Nick Rossenbach, Robin Schmitt, Tina Raissi, Simon Berger, Larissa Kleppel, Ralf Schlüter",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17915",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6036cb69e2cb0f832a1b1088209441a1b5309cc94cf18961ca3b07bffec7a52c_w640_q70.webp",
      "contributions": "",
      "summary": "Supplementary Resources and Analysis for Automatic Speech Recognition Systems Trained on the Loquacious Dataset",
      "mindmap": ""
    },
    {
      "title": "ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India",
      "authors": "Shubham Kumar Nigam, Tanuj Tyagi, Siddharth Shukla, Aditya Kumar Guru, Balaramamahanthi Deepak Patnaik, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18014",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0d10da8d503938592e2a709885e1a4ad114f85d7b47234084835f143d49cd6_w640_q70.webp",
      "contributions": "",
      "summary": "ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India",
      "mindmap": ""
    },
    {
      "title": "Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models",
      "authors": "Shubham Kumar Nigam, Parjanya Aditya Shukla, Noel Shallum, Arnab Bhattacharya",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18004",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2ffa85f9a5ddd1bd5f673a211deae55a7bad9087838680e7b143e6daac52df8_w640_q70.webp",
      "contributions": "",
      "summary": "Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models",
      "mindmap": ""
    },
    {
      "title": "CoPE: A Small Language Model for Steerable and Scalable Content Labeling",
      "authors": "Samidh Chakrabarti, David Willner, Kevin Klyman, Tiffany Saade, Emily Capstick, Sabina Nong",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18027",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/423158010714f415c807a9ae93864ccaf58e7d33b462039083dce106e5d195f2_w640_q70.webp",
      "contributions": "",
      "summary": "CoPE: A Small Language Model for Steerable and Scalable Content Labeling",
      "mindmap": ""
    },
    {
      "title": "Narrative Consolidation: Formulating a New Task for Unifying Multi-Perspective Accounts",
      "authors": "Roger A. Finger, Eduardo G. Cortes, Sandro J. Rigo, Gabriel de O. Ramos",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18041",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/405c807df8e2ce95661469b072db6898b3dcf1bb175cd81aa868ecc9d2c06c12_w640_q70.webp",
      "contributions": "",
      "summary": "Narrative Consolidation: Formulating a New Task for Unifying Multi-Perspective Accounts",
      "mindmap": ""
    },
    {
      "title": "Statistical laws and linguistics inform meaning in naturalistic and fictional conversation",
      "authors": "Ashley M. A. Fehr, Calla G. Beauregard, Julia Witte Zimmerman, Katie Ekström, Pablo Rosillo-Rodes, Christopher M. Danforth, Peter Sheridan Dodds",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18072",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0119bf39897b4bb6f848dd8818e4a75f43e327cbc8223e8cff6bafd0a8277d08_w640_q70.webp",
      "contributions": "",
      "summary": "Statistical laws and linguistics inform meaning in naturalistic and fictional conversation",
      "mindmap": ""
    },
    {
      "title": "Layout-Aware Text Editing for Efficient Transformation of Academic PDFs to Markdown",
      "authors": "Changxu Duan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18115",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13ec88807faf2814dad94d8489b36894b8aa8c290f9026ca2108a6c17ac22ca6_w640_q70.webp",
      "contributions": "",
      "summary": "Layout-Aware Text Editing for Efficient Transformation of Academic PDFs to Markdown",
      "mindmap": ""
    },
    {
      "title": "External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning",
      "authors": "Jian Yan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18190",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebbd501809c39f1f08745f358ebdf2df886f93b7202aeedbd613476ffb27866b_w640_q70.webp",
      "contributions": "",
      "summary": "External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning",
      "mindmap": ""
    },
    {
      "title": "Training LLMs with LogicReward for Faithful and Rigorous Reasoning",
      "authors": "Jundong Xu, Hao Fei, Huichi Zhou, Xin Quan, Qijun Huang, Shengqiong Wu, William Yang Wang, Mong-Li Lee, Wynne Hsu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18196",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/10a4cb0521ac4192e49080ee2ad4da1d452c4469bd6d7c8279e1ca666dd437a6_w640_q70.webp",
      "contributions": "",
      "summary": "Training LLMs with LogicReward for Faithful and Rigorous Reasoning",
      "mindmap": ""
    },
    {
      "title": "Stable and Efficient Single-Rollout RL for Multimodal Reasoning",
      "authors": "Rui Liu, Dian Yu, Lei Ke, Haolin Liu, Yujun Zhou, Zhenwen Liang, Haitao Mi, Pratap Tokekar, Dong Yu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18215",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81e83852cf5de78a73c53dc039a80d4328420c326e71217ed656de7348457003_w640_q70.webp",
      "contributions": "",
      "summary": "Stable and Efficient Single-Rollout RL for Multimodal Reasoning",
      "mindmap": ""
    },
    {
      "title": "GeoSense-AI: Fast Location Inference from Crisis Microblogs",
      "authors": "Deepit Sapru",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18225",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5c58318afd02a0e78246cd4d9114fc0566ca0ff40a0a1ad3e92124da0582633_w640_q70.webp",
      "contributions": "",
      "summary": "GeoSense-AI: Fast Location Inference from Crisis Microblogs",
      "mindmap": ""
    },
    {
      "title": "Investigating Spatial Attention Bias in Vision-Language Models",
      "authors": "Aryan Chaudhary, Sanchit Goyal, Pratik Narang, Dhruv Kumar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18231",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/be5cd89ea4d004fbb18410473c51ae236387bc088e028d1ddd84dbce2d703bfc_w640_q70.webp",
      "contributions": "",
      "summary": "Investigating Spatial Attention Bias in Vision-Language Models",
      "mindmap": ""
    },
    {
      "title": "Explainable Transformer-CNN Fusion for Noise-Robust Speech Emotion Recognition",
      "authors": "Sudip Chakrabarty, Pappu Bishwas, Rajdeep Chatterjee",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18298",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2d1fa5f1ea12d3598f0bd43290aa418e4ebda7629f53494201d317e1a493a95_w640_q70.webp",
      "contributions": "",
      "summary": "Explainable Transformer-CNN Fusion for Noise-Robust Speech Emotion Recognition",
      "mindmap": ""
    },
    {
      "title": "Measuring Fine-Grained Negotiation Tactics of Humans and LLMs in Diplomacy",
      "authors": "Wenkai Li, Lynnette Hui Xian Ng, Andy Liu, Daniel Fried",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18292",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bca157c21b274184903d6db27d719924ad61a7ebd545421b88ee4959f34a8c8_w640_q70.webp",
      "contributions": "",
      "summary": "Measuring Fine-Grained Negotiation Tactics of Humans and LLMs in Diplomacy",
      "mindmap": ""
    },
    {
      "title": "InstructNet: A Novel Approach for Multi-Label Instruction Classification through Advanced Deep Learning",
      "authors": "Tanjim Taharat Aurpa, Md Shoaib Ahmed, Md Mahbubur Rahman, Md. Golam Moazzam",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18301",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7a5ce8e8f2666469be8a7a0bffad58a614870a283a7d6d1dca8f43d9f0a9304_w640_q70.webp",
      "contributions": "",
      "summary": "InstructNet: A Novel Approach for Multi-Label Instruction Classification through Advanced Deep Learning",
      "mindmap": ""
    },
    {
      "title": "CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher",
      "authors": "Tianlun Liu, Zhiliang Tian, Zhen Huang, Xingzhi Zhou, Wanlong Yu, Tianle Liu, Feng Liu, Dongsheng Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18321",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a3cf2be9f3faea6343f7391291b649e6555516f57a7f71804673fdebc50f3e4_w640_q70.webp",
      "contributions": "",
      "summary": "CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher",
      "mindmap": ""
    },
    {
      "title": "LIR$^3$AG: A Lightweight Rerank Reasoning Strategy Framework for Retrieval-Augmented Generation",
      "authors": "Guo Chen, Junjie Huang, Huaijin Xie, Fei Sun, Tao Jia",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18329",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dd393abec358205f73a078d58f2d077d68b22ce62c1b8d3eb7bc25329e59e8a_w640_q70.webp",
      "contributions": "",
      "summary": "LIR$^3$AG: A Lightweight Rerank Reasoning Strategy Framework for Retrieval-Augmented Generation",
      "mindmap": ""
    },
    {
      "title": "Towards Efficient Agents: A Co-Design of Inference Architecture and System",
      "authors": "Weizhe Lin, Hui-Ling Zhen, Shuai Yang, Xian Wang, Renxi Liu, Hanting Chen, Wangze Zhang, Chuansai Zhou, Yiming Li, Chen Chen, Xing Li, Zhiyuan Yang, Xiaosong Li, Xianzhi Yu, Zhenhua Dong, Mingxuan Yuan, Yunhe Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18337",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7ed4e66482149eeb38c88b95b26442424c5cb783935dd1d2ae998dcbe934a3_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Efficient Agents: A Co-Design of Inference Architecture and System",
      "mindmap": ""
    },
    {
      "title": "LLM-based Few-Shot Early Rumor Detection with Imitation Agent",
      "authors": "Fengzhu Zeng, Qian Shao, Ling Cheng, Wei Gao, Shih-Fen Cheng, Jing Ma, Cheng Niu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18352",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68253881479be80c6f5156b8929dcea7c9affda2463411703dbff80daa9a6787_w640_q70.webp",
      "contributions": "",
      "summary": "LLM-based Few-Shot Early Rumor Detection with Imitation Agent",
      "mindmap": ""
    },
    {
      "title": "SRS-Stories: Vocabulary-constrained multilingual story generation for language learning",
      "authors": "Wiktor Kamzela, Mateusz Lango, Ondrej Dusek",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18362",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9bb1bdec7e9243a15f59e7c93c8e0fc83a1b1ee3982dfb0225c524424979ac69_w640_q70.webp",
      "contributions": "",
      "summary": "SRS-Stories: Vocabulary-constrained multilingual story generation for language learning",
      "mindmap": ""
    },
    {
      "title": "LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators",
      "authors": "Mateusz Lango, Ondřej Dušek",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18360",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e70af4d7e4c119643e3631c8815a5d46438a6f1b8881a5821764fb495f8608f_w640_q70.webp",
      "contributions": "",
      "summary": "LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators",
      "mindmap": ""
    },
    {
      "title": "DACE For Railway Acronym Disambiguation",
      "authors": "El Mokhtar Hribach, Oussama Mechhour, Mohammed Elmonstaser, Yassine El Boudouri, Othmane Kabal",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18357",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/491cdc5ad5360c6518de9b4fdc6851733d3db21d281c60aa6fe7296ba2016a65_w640_q70.webp",
      "contributions": "",
      "summary": "DACE For Railway Acronym Disambiguation",
      "mindmap": ""
    },
    {
      "title": "AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3",
      "authors": "Mark Kashirskiy, Artiom Lipinski, Ilya Makarov",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18399",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb721fc55d6ea689ae069e1c50129b86f7fc25c4c3433aa154aaa38bf9378cd3_w640_q70.webp",
      "contributions": "",
      "summary": "AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3",
      "mindmap": ""
    },
    {
      "title": "An Agentic AI Framework for Training General Practitioner Student Skills",
      "authors": "Victor De Marez, Jens Van Nooten, Luna De Bruyne, Walter Daelemans",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18440",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937c34e04859d95b3aed57029c9c5791e5aa2e5a17dbc8d2d6ac7882d0933e37_w640_q70.webp",
      "contributions": "",
      "summary": "An Agentic AI Framework for Training General Practitioner Student Skills",
      "mindmap": ""
    },
    {
      "title": "Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling",
      "authors": "Christopher Román Jaimes",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18462",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27cc701f0cd5020bdc7452f202a07cee2cdb12b9d80e26c528184ec53ea76847_w640_q70.webp",
      "contributions": "",
      "summary": "Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling",
      "mindmap": ""
    },
    {
      "title": "Research on a hybrid LSTM-CNN-Attention model for text-based web content classification",
      "authors": "Mykola Kuz, Ihor Lazarovych, Mykola Kozlenko, Mykola Pikuliak, Andrii Kvasniuk",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18475",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d6cee54c1b292cf87f190d497421a3a323bc276532b71bc07f75f60e88c9a5d_w640_q70.webp",
      "contributions": "",
      "summary": "Research on a hybrid LSTM-CNN-Attention model for text-based web content classification",
      "mindmap": ""
    },
    {
      "title": "Teaching and Critiquing Conceptualization and Operationalization in NLP",
      "authors": "Vagrant Gautam",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18505",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124f7904bd6c9c1e7dda9c02619db7d1384dfe77987878e3270100575989ec37_w640_q70.webp",
      "contributions": "",
      "summary": "Teaching and Critiquing Conceptualization and Operationalization in NLP",
      "mindmap": ""
    },
    {
      "title": "Generalization Gaps in Political Fake News Detection: An Empirical Study on the LIAR Dataset",
      "authors": "S Mahmudul Hasan, Shaily Roy, Akib Jawad Nafis",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18533",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ae98cacefd250f660449f7354216ce0a7f9d0395ed396c825595eada053e771_w640_q70.webp",
      "contributions": "",
      "summary": "Generalization Gaps in Political Fake News Detection: An Empirical Study on the LIAR Dataset",
      "mindmap": ""
    },
    {
      "title": "Neologism Learning as a Parameter-Efficient Alternative to Fine-Tuning for Model Steering",
      "authors": "Sungjoon Park, Varun Ramamurthi, Owen Terry",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18551",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2fa6d5c65b00f54388a5a5958e1d779544648a0e4bcc5878bdac10755ae186e1_w640_q70.webp",
      "contributions": "",
      "summary": "Neologism Learning as a Parameter-Efficient Alternative to Fine-Tuning for Model Steering",
      "mindmap": ""
    },
    {
      "title": "LLMs on Drugs: Language Models Are Few-Shot Consumers",
      "authors": "Alexander Doudkin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18546",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fccef5b4c858e71f601c763675964730c550bdc2fa2972235024cc1e538c6bf7_w640_q70.webp",
      "contributions": "",
      "summary": "LLMs on Drugs: Language Models Are Few-Shot Consumers",
      "mindmap": ""
    },
    {
      "title": "SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models",
      "authors": "Scott Thornton",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18542",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afb4d99182c71c26adf649cc513b4f7ffee3c07f215e3f4067f2ce9fa660fa0_w640_q70.webp",
      "contributions": "",
      "summary": "SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models",
      "mindmap": ""
    },
    {
      "title": "Toward Training Superintelligent Software Agents through Self-Play SWE-RL",
      "authors": "Yuxiang Wei, Zhiqing Sun, Emily McMilin, Jonas Gehring, David Zhang, Gabriel Synnaeve, Daniel Fried, Lingming Zhang, Sida Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18552",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Training Superintelligent Software Agents through Self-Play SWE-RL",
      "mindmap": ""
    },
    {
      "title": "From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation",
      "authors": "Amit Barman, Atanu Mandal, Sudip Kumar Naskar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18593",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4841f825fcb7cf75a5d51e2769fdede7c9af6b25f2faafea290804903c41f40_w640_q70.webp",
      "contributions": "",
      "summary": "From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation",
      "mindmap": ""
    },
    {
      "title": "A Comparative Study of Light-weight Language Models for PII Masking and their Deployment for Real Conversational Texts",
      "authors": "Prabigya Acharya, Liza Shrestha",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18608",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58ef9e00613b3a5bfbc5cce08d668a7661f6fb069cae338e88db1f35673ee946_w640_q70.webp",
      "contributions": "",
      "summary": "A Comparative Study of Light-weight Language Models for PII Masking and their Deployment for Real Conversational Texts",
      "mindmap": ""
    },
    {
      "title": "On Finding Inconsistencies in Documents",
      "authors": "Charles J. Lovering, Seth Ebner, Brandon Smock, Michael Krumdick, Saad Rabbani, Ahmed Muhammad, Varshini Reddy, Chris Tanner",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18601",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c61e64bf42843ef58fd5d03121ce8b9fe2e96bcf5d34bd8dd2619416e3f08f59_w640_q70.webp",
      "contributions": "",
      "summary": "On Finding Inconsistencies in Documents",
      "mindmap": ""
    },
    {
      "title": "LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction",
      "authors": "Jensen Zhang, Ningyuan Liu, Yijia Fan, Zihao Huang, Qinglin Zeng, Kaitong Cai, Jian Wang, Keze Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18623",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3883290af621e53ac54109af76617e157c55068c77c267e0c4643eac11fc0ec_w640_q70.webp",
      "contributions": "",
      "summary": "LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction",
      "mindmap": ""
    },
    {
      "title": "A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback",
      "authors": "Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18622",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp",
      "contributions": "",
      "summary": "A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback",
      "mindmap": ""
    },
    {
      "title": "Does It Tie Out? Towards Autonomous Legal Agents in Venture Capital",
      "authors": "Pierre Colombo, Malik Boudiaf, Allyn Sweet, Michael Desa, Hongxi Wang, Kevin Candra, Syméon del Marmol",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18658",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99cb2c0d15c54813fefddf4670e9d0dc5b70cdc79ff9a13a7d5fb4f3a38f7143_w640_q70.webp",
      "contributions": "",
      "summary": "Does It Tie Out? Towards Autonomous Legal Agents in Venture Capital",
      "mindmap": ""
    },
    {
      "title": "brat: Aligned Multi-View Embeddings for Brain MRI Analysis",
      "authors": "Maxime Kayser, Maksim Gridnev, Wanting Wang, Max Bain, Aneesh Rangnekar, Avijit Chatterjee, Aleksandr Petrov, Harini Veeraraghavan, Nathaniel C. Swinburne",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18679",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e2d9cbeed3e332a02f5cc9adf5abc0ec370a32b059de24cd550cc930eb84a82_w640_q70.webp",
      "contributions": "",
      "summary": "brat: Aligned Multi-View Embeddings for Brain MRI Analysis",
      "mindmap": ""
    },
    {
      "title": "Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design",
      "authors": "Yuchen Li, Handing Wang, Bing Xue, Mengjie Zhang, Yaochu Jin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18682",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d33a421c48ad59f7420161a73adc3cf5979c2e95cd4ded4b6c5ac3a603e0e95_w640_q70.webp",
      "contributions": "",
      "summary": "Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design",
      "mindmap": ""
    },
    {
      "title": "Code2Doc: A Quality-First Curated Dataset for Code Documentation",
      "authors": "Recep Kaan Karaman, Meftun Akarsu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18748",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b6da5096797c358f77d8022914985853333b12b54cf68425fe470f42a60638b_w640_q70.webp",
      "contributions": "",
      "summary": "Code2Doc: A Quality-First Curated Dataset for Code Documentation",
      "mindmap": ""
    },
    {
      "title": "MemEvolve: Meta-Evolution of Agent Memory Systems",
      "authors": "Guibin Zhang, Haotian Ren, Chong Zhan, Zhenhong Zhou, Junhao Wang, He Zhu, Wangchunshu Zhou, Shuicheng Yan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18746",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0bcb0edebf98e4279185979654fe8f92c41ebcbd3b45786b67e305d7a65d04f6_w640_q70.webp",
      "contributions": "",
      "summary": "MemEvolve: Meta-Evolution of Agent Memory Systems",
      "mindmap": ""
    },
    {
      "title": "InSight-o3: Empowering Multimodal Foundation Models with Generalized Visual Search",
      "authors": "Kaican Li, Lewei Yao, Jiannan Wu, Tiezheng Yu, Jierun Chen, Haoli Bai, Lu Hou, Lanqing Hong, Wei Zhang, Nevin L. Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18745",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87556fdc09b55b65c0d472d205a384cc42453256afeb9e7a28db98178fe1d145_w640_q70.webp",
      "contributions": "",
      "summary": "InSight-o3: Empowering Multimodal Foundation Models with Generalized Visual Search",
      "mindmap": ""
    },
    {
      "title": "From Natural Language to Control Signals: A Conceptual Framework for Semantic Channel Finding in Complex Experimental Infrastructure",
      "authors": "Thorsten Hellert, Nikolay Agladze, Alex Giovannone, Jan Jug, Frank Mayet, Mark Sherwin, Antonin Sulc, Chris Tennant",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18779",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4811b7a6317b8d33b2f92f5249b3e215e280fef25b4d76030d5495c78a7d02f_w640_q70.webp",
      "contributions": "",
      "summary": "From Natural Language to Control Signals: A Conceptual Framework for Semantic Channel Finding in Complex Experimental Infrastructure",
      "mindmap": ""
    },
    {
      "title": "AraMix: Recycling, Refiltering, and Deduplicating to Deliver the Largest Arabic Pretraining Corpus",
      "authors": "Sultan Alrashed, Francesco Orabona",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18834",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b37cd3dd620b849ae8ae05331dd8a70314996ab6497e0c72c29ceac5b60b6899_w640_q70.webp",
      "contributions": "",
      "summary": "AraMix: Recycling, Refiltering, and Deduplicating to Deliver the Largest Arabic Pretraining Corpus",
      "mindmap": ""
    },
    {
      "title": "From Word to World: Can Large Language Models be Implicit Text-based World Models?",
      "authors": "Yixia Li, Hongru Wang, Jiahao Qiu, Zhenfei Yin, Dongdong Zhang, Cheng Qian, Zeping Li, Pony Ma, Guanhua Chen, Heng Ji, Mengdi Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18832",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7359ba2b2edde0aa35db68272c398f7be194a19334cd0996c3e220c7df0b0c05_w640_q70.webp",
      "contributions": "",
      "summary": "From Word to World: Can Large Language Models be Implicit Text-based World Models?",
      "mindmap": ""
    },
    {
      "title": "MDToC: Metacognitive Dynamic Tree of Concepts for Boosting Mathematical Problem-Solving of Large Language Models",
      "authors": "Tung Duong Ta, Tim Oates",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18841",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/904d7953eb4dbc5c149d55e1575a3ed4dcd44d5ed3985c2f466d1edfe62296e9_w640_q70.webp",
      "contributions": "",
      "summary": "MDToC: Metacognitive Dynamic Tree of Concepts for Boosting Mathematical Problem-Solving of Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Application of deep learning approaches for medieval historical documents transcription",
      "authors": "Maksym Voloshchuk, Bohdana Zarembovska, Mykola Kozlenko",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18865",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bc697efc3bfd30e66b187f56c365b6a8add07756fb768bc77ba4586f1ab7d205_w640_q70.webp",
      "contributions": "",
      "summary": "Application of deep learning approaches for medieval historical documents transcription",
      "mindmap": ""
    },
    {
      "title": "Toward Human-Centered AI-Assisted Terminology Work",
      "authors": "Antonio San Martin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18859",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9d1c947f7ae3816e7677add1e89a2192fc6c70c465f3c393e895ab239f5a20f_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Human-Centered AI-Assisted Terminology Work",
      "mindmap": ""
    },
    {
      "title": "Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction",
      "authors": "Ming Li, Han Chen, Yunze Xiao, Jian Chen, Hong Jiao, Tianyi Zhou",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18880",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69c02cdd0b38302d7f949dfe357cef926fc143c19edf1038c18dd4c5b1573b09_w640_q70.webp",
      "contributions": "",
      "summary": "Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction",
      "mindmap": ""
    },
    {
      "title": "Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations",
      "authors": "Shaomu Tan, Ryosuke Mitani, Ritvik Choudhary, Qiyu Wu, Toshiyuki Sekiya, Christof Monz",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18906",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76fe48c6335a2271e131697f68ce5e1bd4c38bb02d11e569ba97f897ef4100cd_w640_q70.webp",
      "contributions": "",
      "summary": "Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations",
      "mindmap": ""
    },
    {
      "title": "FASTRIC: Prompt Specification Language for Verifiable LLM Interactions",
      "authors": "Wen-Long Jin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18940",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5496d384aad293547e961ed7f2ce4568121f384e9e0b977144128668dc8445cb_w640_q70.webp",
      "contributions": "",
      "summary": "FASTRIC: Prompt Specification Language for Verifiable LLM Interactions",
      "mindmap": ""
    },
    {
      "title": "Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework",
      "authors": "Jinyan Liu, Zikang Chen, Qinchuan Wang, Tan Xie, Heming Zheng, Xudong Lv",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18999",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e96bd25bfb48e12bba787eb322582c438c99e6cb5614ad626a47b788b4598038_w640_q70.webp",
      "contributions": "",
      "summary": "Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework",
      "mindmap": ""
    },
    {
      "title": "Affordance RAG: Hierarchical Multimodal Retrieval with Affordance-Aware Embodied Memory for Mobile Manipulation",
      "authors": "Ryosuke Korekata, Quanting Xie, Yonatan Bisk, Komei Sugiura",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18987",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/456f5beecc1c2c45f598578f8491d702dc76e9f500bae44e01454f783dc10b05_w640_q70.webp",
      "contributions": "",
      "summary": "Affordance RAG: Hierarchical Multimodal Retrieval with Affordance-Aware Embodied Memory for Mobile Manipulation",
      "mindmap": ""
    },
    {
      "title": "Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline",
      "authors": "Akshaj Prashanth Rao, Advait Singh, Saumya Kumaar Saksena, Dhruv Kumar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19011",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddd38197559bfa789648dce3d4d675d0a05e678684e3999b2ba550170a5c8c1e_w640_q70.webp",
      "contributions": "",
      "summary": "Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline",
      "mindmap": ""
    },
    {
      "title": "Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models",
      "authors": "Tongyuan Miao, Gary Huang, Kai Jun Han, Annie Jiang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19004",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0ec45adefdbba0ff1f29513a557351fab96e8636ad950ecb6008ff575d0f496_w640_q70.webp",
      "contributions": "",
      "summary": "Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models",
      "mindmap": ""
    },
    {
      "title": "DramaBench: A Six-Dimensional Evaluation Framework for Drama Script Continuation",
      "authors": "Shijian Ma, Yunqi Huang, Yan Lin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19012",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61a55d81fc2fbbe12d82874badb4ccf6267053cf79d4294994aa54685dbd78fd_w640_q70.webp",
      "contributions": "",
      "summary": "DramaBench: A Six-Dimensional Evaluation Framework for Drama Script Continuation",
      "mindmap": ""
    },
    {
      "title": "Watch Closely: Mitigating Object Hallucinations in Large Vision-Language Models with Disentangled Decoding",
      "authors": "Ruiqi Ma, Yu Yan, Chunhong Zhang, Minghao Yin, XinChao Liu, Zhihong Jin, Zheng Hu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19070",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d56f2f61fcc600eaa02837139337fdefe7e31f2b7f624524c972734f069b6c0f_w640_q70.webp",
      "contributions": "",
      "summary": "Watch Closely: Mitigating Object Hallucinations in Large Vision-Language Models with Disentangled Decoding",
      "mindmap": ""
    },
    {
      "title": "A Large Language Model Based Method for Complex Logical Reasoning over Knowledge Graphs",
      "authors": "Ziyan Zhang, Chao Wang, Zhuo Chen, Lei Chen, Chiyi Li, Kai Song",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19092",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4872220afe78cb4c58d8419cbef85a647f38abc69798722db414463aacc8757f_w640_q70.webp",
      "contributions": "",
      "summary": "A Large Language Model Based Method for Complex Logical Reasoning over Knowledge Graphs",
      "mindmap": ""
    },
    {
      "title": "BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation",
      "authors": "Mahir Labib Dihan, Sadif Ahmed, Md Nafiu Rahman",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19122",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf739862e73c646805e217bdf5e2cd5a0f6ec312b673bc4801a828112773cb1d_w640_q70.webp",
      "contributions": "",
      "summary": "BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation",
      "mindmap": ""
    },
    {
      "title": "Stop saying LLM: Large Discourse Models (LDM) and Artificial Discursive Agent (ADA)?",
      "authors": "Amar Lakel",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19117",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f46c06d65cdf6f99dbc4e1a6dd9ba52726ca28bfeec49c8ae2faf170ca9124e_w640_q70.webp",
      "contributions": "",
      "summary": "Stop saying LLM: Large Discourse Models (LDM) and Artificial Discursive Agent (ADA)?",
      "mindmap": ""
    },
    {
      "title": "AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards",
      "authors": "Zihan Lin, Xiaohan Wang, Hexiong Yang, Jiajun Chai, Jie Cao, Guojun Yin, Wei Lin, Ran He",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19126",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea562f5265303d30f48412af8f0c2c84f8e98bc5e8f45118efe7f417df403e8d_w640_q70.webp",
      "contributions": "",
      "summary": "AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards",
      "mindmap": ""
    },
    {
      "title": "SAP: Syntactic Attention Pruning for Transformer-based Language Models",
      "authors": "Tzu-Yun Lee, Ding-Yong Hong, Jan-Jan Wu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19125",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3141b4a53facc55a384f90382f9ca7bbbdeafdff36d3027e35548bc8ba2ea87_w640_q70.webp",
      "contributions": "",
      "summary": "SAP: Syntactic Attention Pruning for Transformer-based Language Models",
      "mindmap": ""
    },
    {
      "title": "QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation",
      "authors": "Dehai Min, Kailin Zhang, Tongtong Wu, Lu Cheng",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19134",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/829ce6a74a55abeea6f6d10fec5338ad05441e95283687a525b0f2525bbf8a12_w640_q70.webp",
      "contributions": "",
      "summary": "QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation",
      "mindmap": ""
    },
    {
      "title": "From Speech to Subtitles: Evaluating ASR Models in Subtitling Italian Television Programs",
      "authors": "Alessandro Lucca, Francesco Pierri",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19161",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53c07d75233bf3941b1b0c41209affef3033b0d43a91f61416cc01001baa79ef_w640_q70.webp",
      "contributions": "",
      "summary": "From Speech to Subtitles: Evaluating ASR Models in Subtitling Italian Television Programs",
      "mindmap": ""
    },
    {
      "title": "JEPA-Reasoner: Decoupling Latent Reasoning from Token Generation",
      "authors": "Bingyang Kelvin Liu, Ziyu Patrick Chen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19171",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73c8bb7209d6fc574cd2b7517828b640ea0eaabfd4d5cb2bba4396c7e2c1fa0a_w640_q70.webp",
      "contributions": "",
      "summary": "JEPA-Reasoner: Decoupling Latent Reasoning from Token Generation",
      "mindmap": ""
    },
    {
      "title": "CycleChart: A Unified Consistency-Based Learning Framework for Bidirectional Chart Understanding and Generation",
      "authors": "Dazhen Deng, Sen Yang, Yuchen He, Yuan Tian, Yingcai Wu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19173",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4924c981ea9ee58543e98b565a1e8fca0e8ce65bad7464a4041f4c5ffc756918_w640_q70.webp",
      "contributions": "",
      "summary": "CycleChart: A Unified Consistency-Based Learning Framework for Bidirectional Chart Understanding and Generation",
      "mindmap": ""
    },
    {
      "title": "Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation",
      "authors": "Anna-Maria Gueorguieva, Aylin Caliskan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19238",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d125f49a56a4f052b1faf9015b89460bff5794de36222547ccabb3b4a08eca86_w640_q70.webp",
      "contributions": "",
      "summary": "Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation",
      "mindmap": ""
    },
    {
      "title": "ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models",
      "authors": "Mingxu Zhang, Dazhong Shen, Qi Zhang, Ying Sun",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19240",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aeb3b37133d9071af2bfeeecd0da8171d70b3d3d9b3b0658553484d1919570f5_w640_q70.webp",
      "contributions": "",
      "summary": "ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics",
      "authors": "Do Minh Duc, Quan Xuan Truong, Nguyen Tat Dat, Nguyen Van Vinh",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19247",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3e85ac8e144e835ca46b7dcdc94a82085e98b53bc5c52cfa6addea751cf9af2_w640_q70.webp",
      "contributions": "",
      "summary": "Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics",
      "mindmap": ""
    },
    {
      "title": "CienaLLM: Generative Climate-Impact Extraction from News Articles with Autoregressive LLMs",
      "authors": "Javier Vela-Tambo, Jorge Gracia, Fernando Dominguez-Castro",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19305",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e378c47c250804c75f74ae7dab654f342496632f097065fedb247e2353e13310_w640_q70.webp",
      "contributions": "",
      "summary": "CienaLLM: Generative Climate-Impact Extraction from News Articles with Autoregressive LLMs",
      "mindmap": ""
    },
    {
      "title": "MAGIC: Achieving Superior Model Merging via Magnitude Calibration",
      "authors": "Yayuan Li, Jian Zhang, Jintao Guo, Zihan Cheng, Lei Qi, Yinghuan Shi, Yang Gao",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19320",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7204250ada52cfa8e70ee24634b9a58aab0085ac9d5854e5c672a585fb92a0a6_w640_q70.webp",
      "contributions": "",
      "summary": "MAGIC: Achieving Superior Model Merging via Magnitude Calibration",
      "mindmap": ""
    },
    {
      "title": "HATS: High-Accuracy Triple-Set Watermarking for Large Language Models",
      "authors": "Zhiqing Hu, Chenxu Zhao, Jiazhong Lu, Xiaolei Liu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19378",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57616dcd6c2bbaa04b7fa3a0787e49d5a02a47c5a4535936d5c9f62643957b10_w640_q70.webp",
      "contributions": "",
      "summary": "HATS: High-Accuracy Triple-Set Watermarking for Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara",
      "authors": "Yacouba Diarra, Panga Azazia Kamate, Nouhoum Souleymane Coulibaly, Michael Leventhal",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19400",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b8ba0dabc6aa24a9c91f88fe9dbdb71fe95fe660fb7d092170d584e8ca01617_w640_q70.webp",
      "contributions": "",
      "summary": "Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara",
      "mindmap": ""
    },
    {
      "title": "From Retrieval to Reasoning: A Framework for Cyber Threat Intelligence NER with Explicit and Adaptive Instructions",
      "authors": "Jiaren Peng, Hongda Sun, Xuan Tian, Cheng Huang, Zeqing Li, Rui Yan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19414",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/553b6290892a9990d1a3b4b102abcd09ff7265499b12fe86a581ef08a388f0b6_w640_q70.webp",
      "contributions": "",
      "summary": "From Retrieval to Reasoning: A Framework for Cyber Threat Intelligence NER with Explicit and Adaptive Instructions",
      "mindmap": ""
    },
    {
      "title": "CodeSimpleQA: Scaling Factuality in Code Large Language Models",
      "authors": "Jian Yang, Wei Zhang, Yizhi Li, Shawn Guo, Haowen Wang, Aishan Liu, Ge Zhang, Zili Wang, Zhoujun Li, Xianglong Liu, Weifeng Lv",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19424",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91e94588098b016a931e564501e220f391d8186f55b4c39b93da715a899afb11_w640_q70.webp",
      "contributions": "",
      "summary": "CodeSimpleQA: Scaling Factuality in Code Large Language Models",
      "mindmap": ""
    },
    {
      "title": "MobileWorld: Benchmarking Autonomous Mobile Agents in Agent-User Interactive, and MCP-Augmented Environments",
      "authors": "Quyu Kong, Xu Zhang, Zhenyu Yang, Nolan Gao, Chen Liu, Panrong Tong, Chenglin Cai, Hanzhang Zhou, Jianan Zhang, Liangyu Chen, Zhidan Liu, Steven Hoi, Yue Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19432",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1f9de7d24f3262309b81c73b75271d399f4875308f21feaf79b5ca283f85311c_w640_q70.webp",
      "contributions": "",
      "summary": "MobileWorld: Benchmarking Autonomous Mobile Agents in Agent-User Interactive, and MCP-Augmented Environments",
      "mindmap": ""
    },
    {
      "title": "Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations",
      "authors": "Jinwei Chi, Ke Wang, Yu Chen, Xuanye Lin, Qiang Xu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19456",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44e2303feb430ac2c66a05d707fa59f0184a8efed477dd24968816daffaaf4a2_w640_q70.webp",
      "contributions": "",
      "summary": "Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations",
      "mindmap": ""
    },
    {
      "title": "Epistemological Fault Lines Between Human and Artificial Intelligence",
      "authors": "Walter Quattrociocchi, Valerio Capraro, Matjaž Perc",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19466",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e38aa1bf279d77f222964e2fa6eaf6b1a85cc9955ae786124894e9ed3fb93c1_w640_q70.webp",
      "contributions": "",
      "summary": "Epistemological Fault Lines Between Human and Artificial Intelligence",
      "mindmap": ""
    },
    {
      "title": "SiamGPT: Quality-First Fine-Tuning for Stable Thai Text Generation",
      "authors": "Thittipat Pairatsuppawat, Abhibhu Tachaapornchai, Paweekorn Kusolsomboon, Chutikan Chaiwong, Thodsaporn Chay-intr, Kobkrit Viriyayudhakorn, Nongnuch Ketui, Aslan B. Wong",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19455",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa063ad12c4a8d092558907067bccfddb046268125d4e779376dab9a3d77d1e0_w640_q70.webp",
      "contributions": "",
      "summary": "SiamGPT: Quality-First Fine-Tuning for Stable Thai Text Generation",
      "mindmap": ""
    },
    {
      "title": "A Large-Language-Model Framework for Automated Humanitarian Situation Reporting",
      "authors": "Ivan Decostanzi, Yelena Mejova, Kyriaki Kalimeri",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19475",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a54fad5edc889b5ad9104209f3afb0330725100e661de009b823a7db7e07d9ec_w640_q70.webp",
      "contributions": "",
      "summary": "A Large-Language-Model Framework for Automated Humanitarian Situation Reporting",
      "mindmap": ""
    },
    {
      "title": "Algerian Dialect",
      "authors": "Zakaria Benmounah, Abdennour Boulesnane",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19543",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b20aa2b1c53242ea58da6106d340fde3ef7bc07b9c5b254164c44ae1890074a7_w640_q70.webp",
      "contributions": "",
      "summary": "Algerian Dialect",
      "mindmap": ""
    },
    {
      "title": "Event Extraction in Large Language Model",
      "authors": "Bobo Li, Xudong Han, Jiang Liu, Yuzhe Ding, Liqiang Jing, Zhaoqi Zhang, Jinheng Li, Xinya Du, Fei Li, Meishan Zhang, Min Zhang, Aixin Sun, Philip S. Yu, Hao Fei",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19537",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd9b5f9c26e59b2ed6103844101a774216e9cbe68f45ba35eb88ca2b32f24ec6_w640_q70.webp",
      "contributions": "",
      "summary": "Event Extraction in Large Language Model",
      "mindmap": ""
    },
    {
      "title": "MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery",
      "authors": "Angelo Ortiz Tandazo, Manel Khentout, Youssef Benchekroun, Thomas Hueber, Emmanuel Dupoux",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19612",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d640e4e40b2a6b04fca6e826cd560376d85f3c26277639aacff733108db2cc6_w640_q70.webp",
      "contributions": "",
      "summary": "MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery",
      "mindmap": ""
    },
    {
      "title": "Increasing the Thinking Budget is Not All You Need",
      "authors": "Ignacio Iacobacci, Zhaozhi Qian, Faroq AL-Tam, Muhammad AL-Qurishi, Riad Souissi",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19585",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1349874483030f6b12e0c38e99a95b5753e35155a3ffc245d9bfc23d426e906f_w640_q70.webp",
      "contributions": "",
      "summary": "Increasing the Thinking Budget is Not All You Need",
      "mindmap": ""
    },
    {
      "title": "Exploring the features used for summary evaluation by Human and GPT",
      "authors": "Zahra Sadeghi, Evangelos Milios, Frank Rudzicz",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19620",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e154f176f186b8dabd43d09d2a96579db8d3bbe3ccbf6debeb1b756642ffa2a_w640_q70.webp",
      "contributions": "",
      "summary": "Exploring the features used for summary evaluation by Human and GPT",
      "mindmap": ""
    },
    {
      "title": "Diacritic Restoration for Low-Resource Indigenous Languages: Case Study with Bribri and Cook Islands Māori",
      "authors": "Rolando Coto-Solano, Daisy Li, Manoela Teleginski Ferraz, Olivia Sasse, Cha Krupka, Sharid Loáiciga, Sally Akevai Tenamu Nicholas",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19630",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2b93b8d306871e2d8f350baf0bfd0f0d6c6c700437457c6697698611b042a41_w640_q70.webp",
      "contributions": "",
      "summary": "Diacritic Restoration for Low-Resource Indigenous Languages: Case Study with Bribri and Cook Islands Māori",
      "mindmap": ""
    },
    {
      "title": "Exploring Zero-Shot ACSA with Unified Meaning Representation in Chain-of-Thought Prompting",
      "authors": "Filippos Ventirozos, Peter Appleby, Matthew Shardlow",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19651",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7a48528a8f2854ae05c55d577072800564793ed86ef6169c7375b1685f01ca86_w640_q70.webp",
      "contributions": "",
      "summary": "Exploring Zero-Shot ACSA with Unified Meaning Representation in Chain-of-Thought Prompting",
      "mindmap": ""
    },
    {
      "title": "Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies",
      "authors": "Yuqiao Tan, Minzheng Wang, Shizhu He, Huanxuan Liao, Chengfeng Zhao, Qiunan Lu, Tian Liang, Jun Zhao, Kang Liu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19673",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a324294583c22f2459c7cd427d13db040bb89f060fd51e26bb284a001119f6d4_w640_q70.webp",
      "contributions": "",
      "summary": "Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies",
      "mindmap": ""
    },
    {
      "title": "GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators",
      "authors": "Jiacheng Guo, Ling Yang, Peter Chen, Qixin Xiao, Yinjie Wang, Xinzhe Juan, Jiahao Qiu, Ke Shen, Mengdi Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19682",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f15c4d0f8b9a87e3d2373c2b35ef0faccb02043a099a932d6e9b7afa805adea_w640_q70.webp",
      "contributions": "",
      "summary": "GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators",
      "mindmap": ""
    },
    {
      "title": "A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI Augmented Framework",
      "authors": "Ravi Prasad",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17968",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7665945961b2f7304f7c1df5cbe15f902828795ce6193b462edbd1a98af56880_w640_q70.webp",
      "contributions": "",
      "summary": "A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI Augmented Framework",
      "mindmap": ""
    },
    {
      "title": "Distributed Asymmetric Allocation: A Topic Model for Large Imbalanced Corpora in Social Sciences",
      "authors": "Kohei Watanabe",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18119",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67542bc330fbf0441e0930413b5ebeee7ea4fb111df4bff5fba61c49280b9f8a_w640_q70.webp",
      "contributions": "",
      "summary": "Distributed Asymmetric Allocation: A Topic Model for Large Imbalanced Corpora in Social Sciences",
      "mindmap": ""
    },
    {
      "title": "TICL+: A Case Study On Speech In-Context Learning for Children's Speech Recognition",
      "authors": "Haolong Zheng, Yekaterina Yegorova, Mark Hasegawa-Johnson",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18263",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a32dd492d99bdbfa3ef2453e70a027129c638aca8cddc500a7ae12d1a4ae23df_w640_q70.webp",
      "contributions": "",
      "summary": "TICL+: A Case Study On Speech In-Context Learning for Children's Speech Recognition",
      "mindmap": ""
    },
    {
      "title": "Merge on workspaces as Hopf algebra Markov chain",
      "authors": "Matilde Marcolli, David Skigin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18861",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0e865fcb929853efc360d95d314faf7e223840ff014d953cb55dcb92aadbc95_w640_q70.webp",
      "contributions": "",
      "summary": "Merge on workspaces as Hopf algebra Markov chain",
      "mindmap": ""
    },
    {
      "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework",
      "authors": "Kamer Ali Yuksel",
      "institution": "aiXplain Inc",
      "link": "https://arxiv.org/pdf/2512.16970",
      "code": null,
      "tags": [
        "llm inference",
        "context engineering",
        "plan-aware compression",
        "next-k-task relevance",
        "instruction co-refinement",
        "function-preserving compression",
        "synthetic data generation",
        "knowledge distillation"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces PAACE, a framework for compressing the expanding context of LLM agents in multi-step workflows. It uses plan-aware techniques like next-k-task relevance modeling and function-preserving compression, trained on synthetic data and distilled into efficient models. The method improves agent accuracy while significantly reducing context load and inference costs.",
      "mindmap": ""
    },
    {
      "title": "Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows",
      "authors": "Wanghan Xu, Yuhao Zhou, Yifan Zhou, Qinglong Cao, Shuo Li, Jia Bu, Bo Liu, Yixin Chen, Xuming He, Xiangyu Zhao, Xiang Zhuang, Fengxiang Wang, Zhiwang Zhou, Qiantai Feng, Wenxuan Huang, Jiaqi Wei, Hao Wu, Yuejin Yang, Guangshuai Wang, Sheng Xu, Ziyan Huang, Xinyao Liu, Jiyao Liu, Cheng Tang, Wei Li, Ying Chen, Junzhi Ning, Pengfei Jiang, Chenglong Ma, Ye Du, Changkai Ji, Huihui Xu, Ming Hu, Jiangbin Zheng, Xin Chen, Yucheng Wu, Feifei Jiang, Xi Chen, Xiangru Tang, Yuchen Fu, Yingzhou Lu, Yuanyuan Zhang, Lihao Sun, Chengbo Li, Jinzhe Ma, Wanhao Liu, Yating Liu, Kuo-Cheng Wu, Shengdu Chai, Yizhou Wang, Ouwen Zhangjin, Chen Tang, Shufei Zhang, Wenbo Cao, Junjie Ren, Taoyong Cui, Zhouheng Yao, Juntao Deng, Yijie Sun, Feng Liu, Wangxu Wei, Jingyi Xu, Zhangrui Li, Junchao Gong, Zijie Guo, Zhiyu Yao, Zaoyu Chen, Tianhao Peng, Fangchen Yu, Bo Zhang, Dongzhan Zhou, Shixiang Tang, Jiaheng Liu, Fenghua Ling, Yan Lu, Yuchen Ren, Ben Fei, Zhen Zhao, Xinyu Gu, Rui Su, Xiao-Ming Wu, Weikang Si, Yang Liu, Hao Chen, Xiangchao Yan, Xue Yang, Junchi Yan, Jiamin Wu, Qihao Zheng, Chenhui Li, Zhiqiang Gao, Hao Kong, Junjun He, Mao Su, Tianfan Fu, Peng Ye, Chunfeng Song, Nanqing Dong, Yuqiang Li, Huazhu Fu",
      "institution": "Shanghai Artificial Intelligence Laboratory",
      "link": "https://arxiv.org/pdf/2512.16969",
      "code": null,
      "tags": [
        "scientific ai evaluation",
        "Practical Inquiry Model (PIM)",
        "SGI-Bench",
        "Test-Time Reinforcement Learning (TTRL)",
        "retrieval-augmented novelty",
        "agent-based evaluation"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40fba3081819027f6af6208a55e87bd4bfc888d4ba6ce07d9baa5f158fbe6fa2_w640_q70.webp",
      "contributions": "",
      "summary": "This paper proposes a framework for evaluating Scientific General Intelligence (SGI) in LLMs, grounded in the Practical Inquiry Model and operationalized through the SGI-Bench benchmark. The results reveal significant performance gaps across tasks like deep research and experimental reasoning. The authors also introduce Test-Time Reinforcement Learning (TTRL) to enhance hypothesis novelty without requiring reference answers.",
      "mindmap": ""
    },
    {
      "title": "A Women's Health Benchmark for Large Language Models",
      "authors": "Victoria-Elisabeth Gruber, Razvan Marinescu, Diego Fajardo, Amin H. Nassar, Christopher Arkfeld, Alexandria Ludlow, Shama Patel, Mehrnoosh Samaei, Valerie Klug, Anna Huber, Marcel Gühner, Albert Botta i Orfila, Irene Lagoja, Kimya Tarr, Haleigh Larson, Mary Beth Howard",
      "institution": "Lumos AI, Yale Cancer Center, Harvard Medical School, UCSF, Brown University, Emory University, Clinic Ottakring, NHS, Yale School of Medicine, Johns Hopkins University School of Medicine",
      "link": "https://arxiv.org/pdf/2512.17028",
      "code": null,
      "tags": [
        "healthcare AI evaluation",
        "women's health benchmark",
        "large language models",
        "error types",
        "model stumps",
        "query types"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces the Women's Health Benchmark (WHB), a novel evaluation framework comprising 96 validated model stumps across five medical specialties, three query types, and eight error types to assess LLM performance in women's health. It finds that current LLMs have approximately 60% failure rates, with significant weaknesses in detecting urgency, indicating they are not yet reliable for providing women's health advice.",
      "mindmap": ""
    },
    {
      "title": "Knowledge Distillation with Structured Chain-of-Thought for Text-to-SQL",
      "authors": "Khushboo Thaker, Yony Bresler",
      "institution": "Crater Labs",
      "link": "https://arxiv.org/pdf/2512.17053",
      "code": null,
      "tags": [
        "llm training",
        "knowledge distillation",
        "chain-of-thought",
        "structured reasoning",
        "query execution plan",
        "text-to-sql"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/906b49597857a3cad8e1c9c8d6cdbec46e7807fe819943d1e6d91facfb7f18bd_w640_q70.webp",
      "contributions": "",
      "summary": "The paper proposes Struct-SQL, a knowledge distillation framework that trains a small language model using a structured chain-of-thought derived from query execution plans, rather than unstructured reasoning traces. The distilled model achieves an 8.1% absolute improvement over an unstructured baseline, primarily due to a reduction in syntactic errors. This demonstrates that structured logical blueprints are beneficial for reliable SQL generation in small models.",
      "mindmap": ""
    },
    {
      "title": "Perturb Your Data: Paraphrase-Guided Training Data Watermarking",
      "authors": "Pranav Shetty, Mirazul Haque, Petr Babkin, Zhiqiang Ma, Xiaomo Liu, Manuela Veloso",
      "institution": "JPMorgan AI Research",
      "link": "https://arxiv.org/pdf/2512.17075",
      "code": null,
      "tags": [
        "llm training",
        "SPECTRA",
        "watermarking",
        "training data detection",
        "membership inference attack",
        "paraphrase generation",
        "scoring model",
        "token probability comparison"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b47f34679362a94a5413b86758bfca6d1690e7158a9b8bc7a21706264c5e833c_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces SPECTRA, a watermarking method that subtly paraphrases text using an LLM to embed a detectable signature into training data without altering its statistical distribution. It verifies unauthorized use by comparing token probabilities between a suspect model and a scoring model. The approach reliably detects watermarked data even when it constitutes a minuscule fraction of the training corpus, providing a scalable pre-release watermark for data owners.",
      "mindmap": ""
    },
    {
      "title": "When F1 Fails: Granularity-Aware Evaluation for Dialogue Topic Segmentation",
      "authors": "Michael H. Coen",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.17083",
      "code": null,
      "tags": [
        "dialogue topic segmentation",
        "window-tolerant F1",
        "boundary density",
        "segment coherence",
        "granularity-aware evaluation"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a new evaluation framework for dialogue topic segmentation that emphasizes boundary density and segment coherence alongside window-tolerant F1. It demonstrates through cross-dataset experiments that reported performance differences are often artifacts of annotation granularity mismatches, not model quality. The core conclusion is that topic segmentation should be viewed as selecting an appropriate granularity rather than predicting a single correct boundary set.",
      "mindmap": ""
    },
    {
      "title": "A Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving",
      "authors": "Timo Pierre Schrader, Lukas Lange, Tobias Kaminski, Simon Razniewski, Annemarie Friedrich",
      "institution": "Bosch Center for AI, University of Augsburg, ScaDS.AI & TU Dresden",
      "link": "https://arxiv.org/pdf/2512.17093",
      "code": null,
      "tags": [
        "llm training",
        "solver-in-the-loop",
        "instruction-tuning",
        "supervised fine-tuning",
        "best-of-N sampling",
        "answer set programming",
        "semantic parsing"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38c83df2ce552270bc09f323934a96a0aad16af58e736a7049ccfd73afeed0d4_w640_q70.webp",
      "contributions": "",
      "summary": "This paper introduces a solver-in-the-loop framework that uses an ASP solver to provide feedback on LLM-generated code, creating a dataset of chosen and rejected instances for supervised fine-tuning. The method improves LLM performance on generating Answer Set Programming code for logic puzzles, demonstrating consistent gains across different prompting settings and datasets.",
      "mindmap": ""
    },
    {
      "title": "Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition",
      "authors": "Zahra Rahmani, Hossein Sameti",
      "institution": "Sharif University of Technology",
      "link": "https://arxiv.org/pdf/2512.17247",
      "code": null,
      "tags": [
        "llm inference",
        "error level noise embedding",
        "n-best hypotheses",
        "noise-aware modeling",
        "whisper",
        "llama-2",
        "word error rate",
        "fine-tuning"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a robust noise-sensitive ASR error correction framework for Persian. It introduces Error Level Noise (ELN) embeddings, derived from disagreements in multiple ASR hypotheses, to condition a fine-tuned LLaMA-2 model, enabling it to reason about noise-induced uncertainty. The ELN-conditioned model significantly reduces Word Error Rate compared to text-only baselines, demonstrating the effectiveness of combining multiple hypotheses with noise-aware embeddings for robust speech recognition in noisy environments.",
      "mindmap": ""
    },
    {
      "title": "AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators",
      "authors": "Michael J. Ryan, Yanzhe Zhang, Amol Salunkhe, Yi Chu, Di Xu, Diyi Yang",
      "institution": "Stanford University, American Express",
      "link": "https://arxiv.org/pdf/2512.17267",
      "code": null,
      "tags": [
        "evaluation framework",
        "LLM-as-a-Judge",
        "regression",
        "MetricBank",
        "retrieval",
        "human feedback correlation"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74363ce6b272cc866e0e9407e36b6e57863b7642ae94357d478230d1f46735a0_w640_q70.webp",
      "contributions": "",
      "summary": "The paper presents AutoMetrics, a framework that synthesizes evaluation metrics by combining retrieved metrics from a curated bank with automatically generated LLM-as-a-Judge criteria, composed via regression to maximize correlation with human feedback. It demonstrates that AutoMetrics significantly improves correlation with human judgments over standard LLM-as-a-Judge approaches while requiring minimal human feedback data. The method can serve as an effective proxy reward for optimizing AI applications.",
      "mindmap": ""
    },
    {
      "title": "Understanding Generalization in Role-Playing Models via Information Theory",
      "authors": "Yongqi Li, Hao Lang, Fei Huang, Tieyun Qian, Yongbin Li",
      "institution": "Wuhan University, Tongyi Lab, Zhongguancun Academy",
      "link": "https://arxiv.org/pdf/2512.17270",
      "code": null,
      "tags": [
        "natural language processing",
        "information theory",
        "mutual information",
        "reinforcement learning",
        "distribution shift",
        "role-playing models"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85ede876c98e7e8d1d360bf9eb2cb767cc2570e218ebc72489f68b5cec65ce55_w640_q70.webp",
      "contributions": "",
      "summary": "This paper introduces an information-theoretic metric called reasoning-based effective mutual information difference (R-EMID) to measure and analyze the generalization degradation of role-playing models under distribution shifts. It also proposes a co-evolving reinforcement learning framework to improve response probability estimation for calculating R-EMID. The main conclusion is that user shift poses the highest risk to model performance and reinforcement learning is the most effective approach for enhancing generalization.",
      "mindmap": ""
    },
    {
      "title": "Subjective Question Generation and Answer Evaluation using NLP",
      "authors": "G. M. Refatul Islam, Safwan Shaheer, Yaseen Nur, Mohammad Rafid Hamid",
      "institution": "Brac University",
      "link": "https://arxiv.org/pdf/2512.17289",
      "code": null,
      "tags": [
        "llm training",
        "large language models",
        "instruct-tuning",
        "bloom's taxonomy",
        "subjective evaluation",
        "question generation",
        "answer evaluation"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f03ca77cc9ebde43ea5a7c83c936ce7c8843b9c39c6b6c58614cb92eb1ce8fc_w640_q70.webp",
      "contributions": "",
      "summary": "This research proposes a framework that uses instruct-tuned large language models (LLMs) to generate subjective questions and evaluate student answers, particularly for higher-order thinking skills. The study concludes that this approach can effectively automate the assessment of complex, subjective understanding, a task traditionally requiring human evaluators.",
      "mindmap": ""
    },
    {
      "title": "Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation",
      "authors": "Daksh Jain, Aarya Jain, Ashutosh Desai, Avyakt Verma, Ishan Bhanuka, Pratik Narang, Dhruv Kumar",
      "institution": "Birla Institute of Technology and Science, Pilani",
      "link": "https://arxiv.org/pdf/2512.17308",
      "code": null,
      "tags": [
        "llm inference",
        "large language models",
        "turn-based battle system",
        "strategic decision-making",
        "content generation",
        "procedural generation",
        "adaptive difficulty"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper develops a turn-based Pokémon battle system where LLMs act as agents, making tactical decisions based on a structured battle state without domain-specific training. The core method involves evaluating LLMs on strategic reasoning and their ability to generate novel game content. The main conclusion is that LLMs can function as dynamic game opponents and designers, offering a practical alternative to reinforcement learning for strategic games.",
      "mindmap": ""
    },
    {
      "title": "Task Schema and Binding: A Double Dissociation Study of In-Context Learning",
      "authors": "Chaeha Kim",
      "institution": "Changwon National University",
      "link": "https://arxiv.org/pdf/2512.17325",
      "code": null,
      "tags": [
        "in-context learning",
        "activation patching",
        "double dissociation",
        "task schema",
        "binding",
        "transformer",
        "mamba"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper uses activation patching experiments across multiple Transformer models and Mamba to causally dissect in-context learning. It concludes that ICL decomposes into two separable mechanisms: Task Schema (abstract task recognition) and Binding (specific input-output associations), with their reliance governed by a trade-off with the model's prior knowledge.",
      "mindmap": ""
    },
    {
      "title": "AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens",
      "authors": "Tung-Ling Li, Yuhao Wu, Hongliang Liu",
      "institution": "Palo Alto Networks",
      "link": "https://arxiv.org/pdf/2512.17375",
      "code": null,
      "tags": [
        "post-training",
        "adversarial control tokens",
        "beam-search exploration",
        "last-layer logit gap",
        "LoRA-based adversarial training",
        "reward hacking"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces AdvJudge-Zero, a method that uses beam-search on a model's next-token distribution to discover short, low-perplexity control token sequences that can flip the binary decisions of LLM-as-a-Judge systems from \"No\" to \"Yes\". It concludes that these tokens represent a realistic reward-hacking vulnerability in post-training pipelines, and shows that adversarial training can mitigate the issue while preserving evaluation quality.",
      "mindmap": ""
    },
    {
      "title": "Are Vision Language Models Cross-Cultural Theory of Mind Reasoners?",
      "authors": "Zabir Al Nazi, G M Shahariar, Abrar Hossain, Wei Peng",
      "institution": "University of California, Riverside, University of Dhaka, Stanford University",
      "link": "https://arxiv.org/pdf/2512.17394",
      "code": null,
      "tags": [
        "vision-language models",
        "CulturalToM-VQA",
        "visual question answering",
        "chain-of-thought prompting",
        "compositional chain-of-thought prompting",
        "false belief reasoning",
        "social desirability bias"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces CulturalToM-VQA, a benchmark dataset built via a VLM-assisted human-in-the-loop pipeline to evaluate cross-cultural Theory of Mind reasoning in Vision-Language Models. It finds that while newer VLMs show strong performance on explicit tasks, they systematically struggle with false belief reasoning, and their results may be inflated by social desirability bias rather than genuine visual understanding.",
      "mindmap": ""
    },
    {
      "title": "RadImageNet-VQA: A Large-Scale CT and MRI Dataset for Radiologic Visual Question Answering",
      "authors": "Léo Butsanets, Charles Corbière, Julien Khlaut, Pierre Manceron, Corentin Dancette",
      "institution": "Raidium, Université de Paris Cité, Hôpital Européen Georges Pompidou, AP-HP, INSERM",
      "link": "https://arxiv.org/pdf/2512.17396",
      "code": null,
      "tags": [
        "multi-modal inference",
        "visual question answering",
        "vision-language models",
        "fine-tuning",
        "benchmark dataset",
        "CT",
        "MRI"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ed7cbd6c6a04ef8f9a23147e56923de1ca94a48cc51c20cfa98200b90baa146_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces RadImageNet-VQA, a large-scale CT and MRI dataset with expert-curated annotations for radiologic visual question answering, designed to evaluate vision-language models on tasks like abnormality detection and pathology identification. Experiments show that current models struggle with fine-grained pathology identification, especially in open-ended settings, and the dataset avoids linguistic shortcuts as models perform near-random without image inputs.",
      "mindmap": ""
    },
    {
      "title": "SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories",
      "authors": "Lilin Wang, Lucas Ramalho, Alan Celestino, Phuc Anthony Pham, Yu Liu, Umang Kumar Sinha, Andres Portillo, Onassis Osunwa, Gabriel Maduekwe",
      "institution": "Turing",
      "link": "https://arxiv.org/pdf/2512.17419",
      "code": null,
      "tags": [
        "llm inference",
        "SWE-Bench++",
        "automated benchmark generation",
        "pull request harvesting",
        "environment synthesis",
        "test oracle extraction",
        "hint-guided trajectory synthesis",
        "fine-tuning"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces SWE-Bench++, an automated framework that generates software engineering benchmarks by harvesting pull requests from GitHub to create reproducible, execution-based coding tasks across multiple languages. The method involves programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance, with a final step to create training trajectories from failed instances. The main conclusion is that this scalable, multilingual approach provides a valuable benchmark for evaluating and improving LLMs on repository-level code generation, as demonstrated by model performance metrics and fine-tuning improvements.",
      "mindmap": ""
    },
    {
      "title": "Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection",
      "authors": "Menna Elgabry, Ali Hamdi",
      "institution": "MSA University",
      "link": "https://arxiv.org/pdf/2512.17630",
      "code": null,
      "tags": [
        "natural language processing",
        "ensemble learning",
        "weighted voting",
        "Condorcet’s Jury Theorem",
        "fine-tuning",
        "transformer models"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a confidence- and credibility-weighted ensemble framework using diverse small transformer models (BERT, RoBERTa, etc.) for emotion detection. The method combines global validation performance and instance-level confidence to weight model votes. The ensemble achieves a 93.5% macro F1-score on the DAIR-AI dataset, outperforming larger LLMs while being more parameter-efficient.",
      "mindmap": ""
    },
    {
      "title": "AncientBench: Towards Comprehensive Evaluation on Excavated and Transmitted Chinese Corpora",
      "authors": "Zhihan Zhou, Daqian Shi, Rui Song, Lida Shi, Xiaolei Diao, Hao Xu",
      "institution": "Jilin University, Queen Mary University of London, University of Trento",
      "link": "https://arxiv.org/pdf/2512.17756",
      "code": null,
      "tags": [
        "llm inference",
        "AncientBench",
        "benchmark evaluation",
        "ancient character comprehension",
        "excavated documents",
        "glyph comprehension",
        "pronunciation comprehension",
        "meaning comprehension",
        "contextual comprehension"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a15f186f48b4cc77c0d16272783515a0f56f75b51cf745384fc582f7e77f37a_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces AncientBench, a comprehensive benchmark designed to evaluate large language models' comprehension of ancient Chinese, particularly focusing on excavated documents. It assesses four competencies (glyph, pronunciation, meaning, and contextual) through ten tasks. The experimental results show that while LLMs have significant potential in ancient text scenarios, a performance gap remains compared to human experts.",
      "mindmap": ""
    },
    {
      "title": "Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity",
      "authors": "Tanjim Taharat Aurpa, Farzana Akter, Md. Mehedi Hasan, Shakil Ahmed, Shifat Ara Rafiq, Fatema Khan",
      "institution": "University of Frontier Technology, University of Liberal Arts Bangladesh",
      "link": "https://arxiv.org/pdf/2512.17769",
      "code": null,
      "tags": [
        "others",
        "BERT",
        "DistilBERT",
        "ELECTRA",
        "RoBERTa",
        "Multi-BERT Ensemble",
        "transformer models",
        "medical entity recognition"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a Multi-BERT Ensemble approach for Bangla Medical Entity Recognition (MedER), evaluating models like BERT, DistilBERT, ELECTRA, and RoBERTa. The ensemble method achieved 89.58% accuracy, an 11.80% improvement over single-layer BERT, and the authors also created a new annotated dataset for this low-resource language task.",
      "mindmap": ""
    },
    {
      "title": "ShareChat: A Dataset of Chatbot Conversations in the Wild",
      "authors": "Yueru Yan, Tuc Nguyen, Bo Su, Melissa Lieffers, Thai Le",
      "institution": "Indiana University",
      "link": "https://arxiv.org/pdf/2512.17843",
      "code": null,
      "tags": [
        "others",
        "dataset collection",
        "multi-turn conversations",
        "platform affordances",
        "source citations",
        "temporal analysis",
        "cross-platform corpus"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces ShareChat, a large-scale dataset of real-world chatbot conversations collected from five major platforms, preserving interface-specific features like reasoning traces and source links. It demonstrates the dataset's utility through analyses of user intent satisfaction, citation behaviors, and evolving usage patterns, providing a resource for studying authentic user-LLM interactions.",
      "mindmap": ""
    },
    {
      "title": "When Reasoning Meets Its Laws",
      "authors": "Junyu Zhang, Yifan Sun, Tianang Leng, Jingyan Shen, Liu Ziyin, Paul Pu Liang, Huan Zhang",
      "institution": "University of Illinois Urbana-Champaign, Massachusetts Institute of Technology, University of Pennsylvania, New York University, NTT Research",
      "link": "https://arxiv.org/pdf/2512.17901",
      "code": null,
      "tags": [
        "large reasoning models",
        "laws of reasoning",
        "compute law",
        "accuracy law",
        "monotonicity",
        "compositionality",
        "LoRe-Bench",
        "finetuning"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f9db7b3665dbba1bcaed95897dff8a53103ef5bfe963b50f03c044189965a72_w640_q70.webp",
      "contributions": "",
      "summary": "This paper introduces the Laws of Reasoning (LoRe), a framework that formalizes desired reasoning behaviors in large reasoning models, including compute and accuracy laws. It proposes LoRe-Bench to evaluate monotonicity and compositionality, and develops a finetuning method to improve compositionality. The study finds that better compliance with these laws leads to enhanced reasoning performance across benchmarks.",
      "mindmap": ""
    },
    {
      "title": "Value Lens: Using Large Language Models to Understand Human Values",
      "authors": "Eduardo de la Cruz Fernández, Marcelo Karanik, Sascha Ossowski",
      "institution": "Universidad Politécnica de Madrid, Universidad Rey Juan Carlos",
      "link": "https://arxiv.org/pdf/2512.15722",
      "code": null,
      "tags": [
        "llm inference",
        "large language models",
        "value detection",
        "generative AI",
        "dual-LLM approach",
        "expert verification"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes Value Lens, a two-stage model that uses Large Language Models (LLMs) to detect human values in text. The first stage uses an LLM to conceptualize a value theory verified by experts, and the second stage employs a dual-LLM approach for detection and critical review. The results show that Value Lens performs comparably to or better than other models in similar tasks.",
      "mindmap": ""
    },
    {
      "title": "LLaDA2.0: Scaling Up Diffusion Language Models to 100B",
      "authors": "Tiwei Bie, Maosong Cao, Kun Chen, Lun Du, Mingliang Gong, Zhuochen Gong, Yanmei Gu, Jiaqi Hu, Zenan Huang, Zhenzhong Lan, Chengxi Li, Chongxuan Li, Jianguo Li, Zehuan Li, Huabin Liu, Ling Liu, Guoshan Lu, Xiaocheng Lu, Yuxin Ma, Jianfeng Tan, Lanning Wei, Ji-Rong Wen, Yipeng Xing, Xiaolu Zhang, Junbo Zhao, Da Zheng, Jun Zhou, Junlin Zhou, Zhanchao Zhou, Liwang Zhu, Yihong Zhuang",
      "institution": "Ant Group, Renmin University of China, Zhejiang University, Westlake University, HongKong University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.15745",
      "code": null,
      "tags": [
        "llm training",
        "discrete diffusion language model",
        "block-level WSD training",
        "mixture-of-experts",
        "knowledge inheritance",
        "parallel decoding",
        "SFT",
        "DPO"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces LLaDA2.0, a method for converting pre-trained auto-regressive language models into large-scale discrete diffusion models (dLLMs) using a novel three-phase block-level training scheme. The resulting instruction-tuned models, including a 100B-parameter variant, achieve superior performance and efficiency through parallel decoding. The work establishes a new paradigm for frontier-scale model deployment by enabling efficient scaling and knowledge inheritance from existing models.",
      "mindmap": ""
    },
    {
      "title": "D3G: Diverse Demographic Data Generation Increases Zero-Shot Image Classification Accuracy within Multimodal Models",
      "authors": "Javon Hickmon",
      "institution": "University of Washington",
      "link": "https://arxiv.org/pdf/2512.15747",
      "code": null,
      "tags": [
        "multi-modal inference",
        "CLIP",
        "Stable Diffusion XL",
        "zero-shot classification",
        "demographic bias mitigation",
        "data generation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes D3G, a training-free method that uses Stable Diffusion XL to generate diverse demographic data at inference time to improve zero-shot image classification with CLIP. The method is shown to boost classification accuracy while reducing harmful demographic bias in pre-trained multimodal models.",
      "mindmap": ""
    },
    {
      "title": "Auto-Tuning Safety Guardrails for Black-Box Large Language Models",
      "authors": "Perry Abdulkadir",
      "institution": "University of St. Thomas",
      "link": "https://arxiv.org/pdf/2512.15782",
      "code": null,
      "tags": [
        "llm inference",
        "hyperparameter optimization",
        "system prompts",
        "content filters",
        "jailbreak detection",
        "malware generation",
        "Optuna",
        "ModernBERT",
        "grid search"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes treating the design of safety guardrails (like system prompts and content filters) for a frozen black-box LLM as a hyperparameter optimization problem. Using a proof-of-concept with Mistral-7B-Instruct and ModernBERT, it shows that a black-box optimizer (Optuna) can efficiently find safe configurations, matching the best grid search results with far fewer evaluations and less time. The conclusion is that this auto-tuning approach is a feasible method to harden LLM deployments under practical constraints.",
      "mindmap": ""
    },
    {
      "title": "A Systematic Analysis of Biases in Large Language Models",
      "authors": "Xulang Zhang, Rui Mao, Erik Cambria",
      "institution": "Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.15792",
      "code": null,
      "tags": [
        "fairness and bias analysis",
        "news summarization",
        "stance classification",
        "UN voting patterns",
        "multilingual story completion",
        "World Values Survey"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper systematically analyzes biases in large language models (LLMs) across political, ideological, alliance, language, and gender dimensions using experiments like news summarization and stance classification. The main conclusion is that despite being aligned for neutrality, the studied LLMs still exhibit various types of biases and affinities.",
      "mindmap": ""
    },
    {
      "title": "Evaluation of AI Ethics Tools in Language Models: A Developers' Perspective Case Stud",
      "authors": "Jhessica Silva, Diego A. B. Moreira, Gabriel O. dos Santos, Alef Ferreira, Helena Maia, Sandra Avila, Helio Pedrini",
      "institution": "Universidade Estadual de Campinas (UNICAMP), Universidade Federal de Goiás (UFG)",
      "link": "https://arxiv.org/pdf/2512.15791",
      "code": null,
      "tags": [
        "ai ethics evaluation",
        "Model Cards",
        "ALTAI",
        "FactSheets",
        "Harms Modeling",
        "literature survey",
        "interviews"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper presents a methodology to evaluate AI Ethics Tools (AIETs) for language models by selecting four tools (Model Cards, ALTAI, FactSheets, Harms Modeling) and applying them to Portuguese language models, with developer interviews. The results indicate that these tools help guide general ethical considerations but fail to address language-specific aspects like idiomatic expressions or identify negative impacts for Portuguese.",
      "mindmap": ""
    },
    {
      "title": "Explainable Ethical Assessment on Human Behaviors by Generating Conflicting Social Norms",
      "authors": "Yuxi Sun, Wei Gao, Hongzhan Lin, Jing Ma, Wenxuan Zhang",
      "institution": "Hong Kong Baptist University, Singapore Management University, Singapore University of Technology and Design",
      "link": "https://arxiv.org/pdf/2512.15793",
      "code": null,
      "tags": [
        "ethical ai",
        "contrastive learning",
        "social norms generation",
        "moral reasoning",
        "explainable ai",
        "valence prediction"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces ClarityEthic, a method that enhances ethical assessment of human actions by generating conflicting social norms to explain and predict valence (support/oppose). It uses a contrastive learning strategy to strengthen the moral reasoning of language models. Experiments show the method outperforms baselines and human evaluations confirm the generated norms provide plausible explanations.",
      "mindmap": ""
    },
    {
      "title": "Seeing Beyond Words: Self-Supervised Visual Learning for Multimodal Large Language Models",
      "authors": "Davide Caffagni, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Pier Luigi Dovesi, Shaghayegh Roohi, Mark Granroth-Wilding, Rita Cucchiara",
      "institution": "University of Modena and Reggio Emilia, AMD Silo AI",
      "link": "https://arxiv.org/pdf/2512.15885",
      "code": null,
      "tags": [
        "multi-modal training",
        "self-supervised learning",
        "vision-language alignment",
        "I-JEPA",
        "JARVIS",
        "masked predictive loss",
        "frozen vision foundation models"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces JARVIS, a self-supervised framework that integrates the I-JEPA learning paradigm into multimodal large language model (MLLM) training to enhance visual understanding. It uses frozen vision models as encoders and trains an LLM-based predictor to learn visual regularities without relying solely on textual supervision. The method consistently improves performance on vision-centric benchmarks across different LLM families without degrading multimodal reasoning abilities.",
      "mindmap": ""
    },
    {
      "title": "DSO: Direct Steering Optimization for Bias Mitigation",
      "authors": "Lucas Monteiro Paes, Nivedha Sivakumar, Yinong Oliver Wang, Masha Fedzechkina Donaldson, Luca Zappella, Nicholas Apostoloff",
      "institution": "Apple, Carnegie Mellon University",
      "link": "https://arxiv.org/pdf/2512.15926",
      "code": null,
      "tags": [
        "fairness and bias mitigation",
        "activation steering",
        "reinforcement learning",
        "linear transformations",
        "inference-time control"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes Direct Steering Optimization (DSO), a method using reinforcement learning to find linear transformations for steering activations in generative models to mitigate bias while maintaining performance. It demonstrates state-of-the-art trade-offs between fairness and capabilities in VLMs and LLMs, offering inference-time control over bias reduction. The work highlights the advantage of directly optimized steering strategies over heuristic-based approaches for effective bias intervention.",
      "mindmap": ""
    },
    {
      "title": "Social Story Frames: Contextual Reasoning about Narrative Intent and Reception",
      "authors": "Joel Mire, Maria Antoniak, Steven R. Wilson, Zexin Ma, Achyutarama R. Ganti, Andrew Piper, Maarten Sap",
      "institution": "Carnegie Mellon University, University of Colorado Boulder, University of Michigan-Flint, University of Connecticut, McGill University",
      "link": "https://arxiv.org/pdf/2512.15925",
      "code": null,
      "tags": [
        "natural language processing",
        "SocialStoryFrames",
        "SSF-Generator",
        "SSF-Classifier",
        "narrative theory",
        "linguistic pragmatics",
        "taxonomy",
        "reader response"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces SocialStoryFrames, a formalism and computational framework for modeling nuanced reader responses to social media stories, including inferences about author intent and affective reactions. It develops two models (SSF-Generator and SSF-Classifier) and applies them to a corpus of online narratives to analyze storytelling practices across communities. The main conclusion is that this approach enables scalable, context-sensitive research into the social dynamics of online storytelling.",
      "mindmap": ""
    },
    {
      "title": "BRAID: Bounded Reasoning for Autonomous Inference and Decisions",
      "authors": "Armağan Amcalar, Eyup Cinar",
      "institution": "OpenServ Labs, Eskisehir Osmangazi University",
      "link": "https://arxiv.org/pdf/2512.15959",
      "code": null,
      "tags": [
        "llm inference",
        "bounded reasoning",
        "structured prompting",
        "instruction graphs",
        "mermaid",
        "chain-of-thought"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces BRAID, a bounded reasoning framework that uses Mermaid-based instruction graphs to structure prompts for LLMs, enabling them to reason structurally instead of through unbounded natural language. The method is shown to substantially increase reasoning accuracy and cost efficiency across multiple GPT model tiers on several benchmark datasets.",
      "mindmap": ""
    },
    {
      "title": "Dynamic Rank Reinforcement Learning for Adaptive Low-Rank Multi-Head Self Attention in Large Language Models",
      "authors": "Caner Erden",
      "institution": "Sakarya University of Applied Sciences",
      "link": "https://arxiv.org/pdf/2512.15973",
      "code": null,
      "tags": [
        "llm inference",
        "reinforcement learning",
        "low-rank approximation",
        "dynamic rank selection",
        "matrix perturbation theory",
        "singular value decomposition"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes Dynamic Rank Reinforcement Learning (DR-RL), a framework that uses a reinforcement learning agent to dynamically select low-rank approximations for Multi-Head Self-Attention in LLMs during inference, balancing accuracy and computational cost. It employs online matrix perturbation theory for efficient updates. Experiments show the method maintains accuracy equivalent to full-rank attention while significantly reducing FLOPs, especially for long sequences.",
      "mindmap": ""
    },
    {
      "title": "Cross-Language Bias Examination in Large Language Models",
      "authors": "Yuxuan Liang, Marwa Mahmoud",
      "institution": "Georgia Institute of Technology, University of Glasgow",
      "link": "https://arxiv.org/pdf/2512.16029",
      "code": null,
      "tags": [
        "fairness and bias evaluation",
        "multilingual bias evaluation",
        "BBQ benchmark",
        "prompt-based Implicit Association Test",
        "explicit bias",
        "implicit bias"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a multilingual bias evaluation framework that combines explicit bias assessment using the BBQ benchmark with implicit bias measurement via a prompt-based Implicit Association Test, applied across five languages. The results show significant variation in bias across languages, with Arabic and Spanish exhibiting higher stereotype bias, and reveal contrasting patterns between explicit and implicit bias, such as age having low explicit but high implicit bias. The study highlights the importance of cross-lingual bias analysis for developing equitable multilingual LLMs.",
      "mindmap": ""
    },
    {
      "title": "Are We on the Right Way to Assessing LLM-as-a-Judge?",
      "authors": "Yuanning Feng, Sinan Wang, Zhengxiang Cheng, Yao Wan, Dongping Chen",
      "institution": "Huazhong University of Science and Technology, University of Maryland",
      "link": "https://arxiv.org/pdf/2512.16041",
      "code": null,
      "tags": [
        "post-training",
        "LLM-as-a-Judge",
        "Sage evaluation suite",
        "local self-consistency",
        "global logical consistency",
        "situational preference",
        "panel-based judge",
        "deep reasoning",
        "finetuned LLM-as-a-Judge"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces Sage, a novel evaluation suite that assesses LLM-as-a-Judge without human annotation by measuring local self-consistency and global logical consistency. It finds that even top LLMs exhibit significant reliability problems, attributing this to situational preference, and shows that finetuning, panel-based judging, and deep reasoning can improve consistency. The work also questions the reliability of human annotation as a gold standard.",
      "mindmap": ""
    },
    {
      "title": "MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation",
      "authors": "Pengyu Wang, Shuchang Ye, Usman Naseem, Jinman Kim",
      "institution": "The University of Sydney, Macquarie University",
      "link": "https://arxiv.org/pdf/2512.16145",
      "code": null,
      "tags": [
        "multi-modal training",
        "reinforcement learning",
        "group relative policy optimization",
        "margin-based cosine similarity",
        "semantic-driven reinforcement learning",
        "large vision-language model"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes a semantic-driven reinforcement learning method (MRG-R1) for medical report generation, which uses a report-level reward based on clinical findings similarity and Group Relative Policy Optimization to improve clinical correctness over token-level objectives. It achieves state-of-the-art performance on benchmark datasets, demonstrating that optimizing for semantic alignment meaningfully enhances clinical accuracy in generated reports.",
      "mindmap": ""
    },
    {
      "title": "Decoding Fake Narratives in Spreading Hateful Stories: A Dual-Head RoBERTa Model with Multi-Task Learning",
      "authors": "Yash Bhaskar, Sankalp Bahad, Parameswari Krishnamurthy",
      "institution": "IIIT Hyderabad",
      "link": "https://arxiv.org/pdf/2512.16147",
      "code": null,
      "tags": [
        "natural language processing",
        "RoBERTa",
        "multi-task learning",
        "transformer models",
        "code-mixed text",
        "hate speech detection",
        "fake narratives"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes a dual-head RoBERTa model with multi-task learning to detect hate speech driven by fake narratives (Faux-Hate) in code-mixed Hindi-English text. It addresses binary classification and target/severity prediction tasks. The system achieved competitive results, demonstrating the effectiveness of multi-task learning for this complex problem.",
      "mindmap": ""
    },
    {
      "title": "Science Consultant Agent",
      "authors": "Karthikeyan K, Philip Wu, Xin Tang, Alexandre Alves",
      "institution": "Duke University, Amazon",
      "link": "https://arxiv.org/pdf/2512.16171",
      "code": null,
      "tags": [
        "others",
        "Retrieval-Augmented Generation (RAG)",
        "fine-tuning",
        "knowledge distillation",
        "prompting",
        "AutoML"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces the Science Consultant Agent, a web-based AI tool that uses structured questionnaires, literature-backed recommendations, and prototype generation to guide practitioners in selecting optimal AI modeling strategies. It aims to prevent resource misallocation by providing evidence-based guidance, moving beyond brute-force exploration or example-induced bias to accelerate development.",
      "mindmap": ""
    }
  ]
}