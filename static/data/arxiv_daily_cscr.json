{
  "label": "cs.CR",
  "slug": "cscr",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "Audited Skill-Graph Self-Improvement for Agentic LLMs via Verifiable Rewards, Experience Synthesis, and Continual Memory",
      "authors": "Ken Huang, Jerry Huang",
      "institution": "DistributedApps.ai, OWASP, Kleiner Perkins",
      "link": "https://arxiv.org/pdf/2512.23760",
      "code": null,
      "tags": [
        "agent system",
        "skill graph",
        "verifiable rewards",
        "continual memory",
        "experience synthesis",
        "audit logging"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bdd2b1c94a27644963b1a77d560eb3715fa72ea6468dc6c4e39e42eb5e040187_w640_q70.webp",
      "contributions": "1. Proposes the Audited Skill-Graph Self-Improvement (ASG-SI) framework, which treats agent self-improvement as the iterative compilation of an auditable, growing skill graph. 2. Introduces a verifier-auditor mechanism that uses replayable evidence and decomposed rewards to gate skill promotion, enabling independent audit and governance. 3. Integrates experience synthesis for scalable testing and continual memory control to manage context growth and preserve long-horizon performance.",
      "summary": "This paper addresses security and governance challenges in self-improving AI agents, such as reward hacking and opaque behavioral drift. It proposes the ASG-SI framework, which compiles agent improvements into an auditable skill graph verified by replayable evidence. The approach reframes self-improvement as the accumulation of verifiable, reusable capabilities for reproducible evaluation and operational governance.",
      "mindmap": "graph TB\n        Root[”Audited Skill-Graph Self-Improvement (ASG-SI) / 审计技能图自我改进”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem”] --> P1[”部署的自我改进代理存在安全与治理挑战 / Deployed self-improving agents pose security & governance challenges”]\n        P1 --> P2[”奖励黑客行为、行为漂移、不透明的更新 / Reward hacking, behavioral drift, opaque updates”]\n        Method[”主要方法/Method”] --> M1[”ASG-SI 框架 / ASG-SI Framework”]\n        M1 --> M2[”将改进编译为可审计技能图 / Compile improvements into auditable skill graph”]\n        M2 --> M3[”基于验证器的证据和可分解奖励进行技能提升 / Verifier-backed evidence & decomposed rewards gate skill promotion”]\n        M3 --> M4[”集成经验合成和持续记忆控制 / Integrate experience synthesis & continual memory control”]\n        Results[”关键结果/Results”] --> R1[”提供可验证、可重用的能力积累 / Provides accumulation of verifiable, reusable capabilities”]\n        R1 --> R2[”为自我改进AI提供可复现评估和操作治理的路径 / Offers path for reproducible evaluation & operational governance of self-improving AI”]"
    },
    {
      "title": "Secure and Governed API Gateway Architectures for Multi-Cluster Cloud Environments",
      "authors": "Vinoth Punniyamoorthy, Kabilan Kannan, Akshay Deshpande, Lokesh Butra, Akash Kumar Agarwal, Adithya Parthasarathy, Suhas Malempati, Bikesh Kumar",
      "institution": "Albertsons Companies, AMD Inc, Cato Corporation, NTT Data",
      "link": "https://arxiv.org/pdf/2512.23774",
      "code": null,
      "tags": [
        "cloud computing",
        "API gateway",
        "multi-cluster",
        "intent-driven",
        "policy enforcement",
        "Kubernetes"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c9e7c82e3adcf3bb6e3cf8d21f828445c3a35236865472e64fcb3eb1b0c25f_w640_q70.webp",
      "contributions": "1. A governance-aware, intent-driven architecture for coordinated API gateway management in multi-cluster cloud environments. 2. A method to decouple high-level declarative intents from enforcement, enabling bounded, policy-compliant adaptation across heterogeneous gateways. 3. A prototype demonstrating significant improvements in policy drift reduction (42%), configuration propagation time (31%), and low latency overhead (&lt;6% p95).",
      "summary": "This paper addresses the challenge of maintaining consistent security, governance, and performance across API gateways in multi-cluster cloud environments. It proposes an intent-driven architecture that translates high-level policies into enforceable configurations and validates them continuously. The prototype shows the approach effectively reduces policy drift, speeds up configuration, and maintains low latency overhead.",
      "mindmap": "graph TB\n        Root[Secure and Governed API Gateway Architectures for Multi-Cluster Cloud Environments] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Maintaining consistent policy enforcement and performance across multi-cluster API gateways is challenging.] --> P1[配置漂移/Configuration Drift]\n        Problem --> P2[策略传播延迟/Delayed Policy Propagation]\n        Problem --> P3[运行时不稳定/Unstable Runtime Behavior]\n        Method[主要方法/Method: Governance-aware, intent-driven architecture.] --> M1[声明式意图/Declarative Intents]\n        Method --> M2[策略验证与反馈/Policy Verification & Telemetry Feedback]\n        Method --> M3[解耦意图与执行/Decouple Intent from Enforcement]\n        Results[关键结果/Results: Prototype evaluation on Kubernetes clusters.] --> R1[政策漂移减少42%/42% Reduction in Policy Drift]\n        Results --> R2[配置传播时间提升31%/31% Improvement in Propagation Time]\n        Results --> R3[P95延迟开销低于6%/P95 Latency Overhead <6%]"
    },
    {
      "title": "Prompt-Induced Over-Generation as Denial-of-Service: A Black-Box Attack-Side Benchmark",
      "authors": "Manu, Yi Guo, Jo Plested, Tim Lynar, Kanchana Thilakarathna, Nirhoshan Sivaroopan, Jack Yang, Wangli Yang",
      "institution": "Western Sydney University, University of New South Wales Canberra, The University of Sydney, University of Wollongong",
      "link": "https://arxiv.org/pdf/2512.23779",
      "code": null,
      "tags": [
        "adversarial attacks on llms",
        "denial-of-service",
        "over-generation",
        "black-box attack",
        "evolutionary search",
        "reinforcement learning"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3002b15ce3957d88befc241c59f1be73a9e49f4e8ad4c345e9d472f11883059e_w640_q70.webp",
      "contributions": "1. Introduces a black-box, query-only benchmark for evaluating prompt-induced denial-of-service attacks on LLMs. 2. Proposes two novel prompt-only attackers: an evolutionary search method (EOGen) and a goal-conditioned reinforcement learning method (RL-GOAL). 3. Defines the Over-Generation Factor (OGF) as a key metric to quantify attack success and characterize model vulnerability.",
      "summary": "This paper addresses the problem of denial-of-service attacks on large language models via prompt-induced over-generation. It proposes a standardized black-box benchmark and two automated attack methods, EOGen and RL-GOAL, to find adversarial prefixes that delay model termination. The results show that the RL-GOAL attacker is particularly effective at forcing models to generate excessively long outputs, highlighting a significant vulnerability.",
      "mindmap": "graph TB\n        A[Prompt-Induced Over-Generation as Denial-of-Service<br/>提示诱导过度生成作为拒绝服务攻击] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br/>LLM过度生成导致服务拒绝、延迟和成本增加]\n        C[主要方法/Method<br/>黑盒基准与两种攻击者: EOGen(进化搜索)和RL-GOAL(强化学习)]\n        D[关键结果/Results<br/>RL-GOAL攻击者实现更高的平均过度生成因子(OGF)]"
    },
    {
      "title": "Application-Specific Power Side-Channel Attacks and Countermeasures: A Survey",
      "authors": "Sahan Sanjaya, Aruna Jayasena, Prabhat Mishra",
      "institution": "University of Florida, University of Tennessee at Chattanooga",
      "link": "https://arxiv.org/pdf/2512.23785",
      "code": null,
      "tags": [
        "side-channel attacks",
        "Power Side-Channel",
        "Differential Power Analysis",
        "Correlation Power Analysis",
        "Cryptographic Implementations",
        "Machine Learning"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/810f0ec77a1c980a8f82a207e83ff9ad2ad13c72bf05c84cdd7752fed92150b4_w640_q70.webp",
      "contributions": "1. Provides a comprehensive survey of power side-channel attacks beyond just cryptographic implementations, covering diverse application domains like machine learning, user behavior, and instruction disassembly. 2. Classifies recent power side-channel attacks and provides a comprehensive comparison based on application-specific considerations. 3. Surveys and discusses countermeasures for power side-channel attacks across the different application domains.",
      "summary": "This paper surveys power side-channel attacks and their countermeasures across various application domains, moving beyond the traditional focus on cryptography. It classifies attacks and compares them based on application-specific factors. The main conclusion is that power side-channel attacks are a prominent threat to a wide range of systems, necessitating domain-aware defenses.",
      "mindmap": "graph TB\n        Root[”Application-Specific Power Side-Channel Attacks and Countermeasures: A Survey”] --> Problem[”核心问题/Problem: Power side-channel attacks threaten diverse applications beyond cryptography.”]\n        Root --> Method[”主要方法/Method: Comprehensive survey and classification of attacks & countermeasures.”]\n        Root --> Results[”关键结果/Results: Highlights the prominence of PSC attacks and the need for application-specific defenses.”]"
    },
    {
      "title": "SyncGait: Robust Long-Distance Authentication for Drone Delivery via Implicit Gait Behaviors",
      "authors": "Zijian Ling, Man Zhou, Hongda Zhai, Yating Huang, Lingchen Zhao, Qi Li, Chao Shen, Qian Wang",
      "institution": "Huazhong University of Science and Technology, Wuhan University, Tsinghua University, Xi'an Jiaotong University",
      "link": "https://arxiv.org/pdf/2512.23778",
      "code": null,
      "tags": [
        "biometric authentication",
        "gait authentication",
        "drone delivery",
        "mutual authentication",
        "arm swing",
        "spoofing attack"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aafeeb48e8be50aaee42b0a5fde6849716a124c81c8181642e777e2398cbf364_w640_q70.webp",
      "contributions": "1. Proposed SyncGait, a novel implicit gait-based mutual authentication system for drone delivery that leverages a user's unique arm swing during walking. 2. Demonstrated robust long-distance authentication performance (&gt;18m) with high accuracy (99.84%) through extensive experiments on 14 datasets from 31 subjects. 3. Showed strong resilience against various spoofing attacks, enhancing security for real-world drone delivery scenarios.",
      "summary": "This paper introduces SyncGait, a system for secure drone delivery that performs mutual authentication by implicitly analyzing a user's unique arm-swing gait as they walk towards the drone. It achieves high accuracy over long distances without requiring extra hardware or explicit user actions. The results show it is robust against spoofing attacks, offering a secure and user-friendly authentication solution.",
      "mindmap": "graph TB\n        Root[”SyncGait: 无人机配送的鲁棒远距离认证 / SyncGait: Robust Long-Distance Authentication for Drone Delivery”] --> Problem[”核心问题 / Problem: 现有无人机配送认证方案距离短、易受攻击 / Existing drone delivery authentication schemes have short range and are vulnerable to attacks.”]\n        Root --> Method[”主要方法 / Method: 利用行走时独特的摆臂行为进行隐式步态认证 / Implicit gait authentication using unique arm swing during walking.”]\n        Root --> Results[”关键结果 / Results: 在>18米距离实现99.84%准确率，抗欺骗攻击 / Achieves 99.84% accuracy at >18m, resilient to spoofing attacks.”]"
    },
    {
      "title": "Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems",
      "authors": "Samaresh Kumar Singh, Joyjit Roy, Martin So",
      "institution": "Independent Researchers (based on provided affiliations: IEEE Senior Member in Texas, IEEE Member in Texas, Independent Researcher in Canada)",
      "link": "https://arxiv.org/pdf/2512.23809",
      "code": null,
      "tags": [
        "federated learning",
        "Zero-Trust Architecture",
        "SHAP-weighted aggregation",
        "TPM-based attestation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/baa785fc442fcbc6a80214c4fdc6361e67a8e34e5a9bb6f5dd8fb34baf21bb68_w640_q70.webp",
      "contributions": "1) Proposed a hierarchical edge-fog-cloud zero-trust federated learning architecture for trusted agent participation. 2) Introduced a novel SHAP-weighted aggregation algorithm for explainable Byzantine detection in non-IID environments. 3) Integrated TPM-based cryptographic attestation and on-device adversarial training into a defense-in-depth framework.",
      "summary": "The paper addresses security vulnerabilities in Federated Learning for Industrial IoT by proposing ZTA-FL, a framework combining zero-trust agent authentication, explainable Byzantine-resilient aggregation, and on-device adversarial training. It demonstrates high detection accuracy and robustness against attacks on intrusion detection benchmarks while reducing communication overhead.",
      "mindmap": "graph TB\n        Root[Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: IIoT安全漏洞与联邦学习攻击 / IIoT Security Gaps & FL Attacks]\n        Method[主要方法/Method: 零信任认证与可解释聚合 / Zero-Trust Attestation & Explainable Aggregation]\n        Results[关键结果/Results: 高检测精度与抗攻击鲁棒性 / High Detection Accuracy & Attack Robustness]"
    },
    {
      "title": "VBSF: A Visual-Based Spam Filtering Technique for Obfuscated Emails",
      "authors": "Ali Hossary, Stefano Tomasin",
      "institution": "University of Padova",
      "link": "https://arxiv.org/pdf/2512.23788",
      "code": null,
      "tags": [
        "email security",
        "visual-based spam filter",
        "optical character recognition",
        "convolutional neural network",
        "stacking ensemble learning"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81885918d1e949206f0eaf96f024c0d6b2e328732f3b57d000024b46b7428920_w640_q70.webp",
      "contributions": "1. A novel visual-based spam detection architecture (VBSF) that mimics human visual perception by rendering emails and capturing their on-screen appearance to counter visual obfuscation techniques., 2. A dual-pipeline processing approach combining OCR-based text classification (using NB and DT) with image-based classification via a custom CNN, integrated using a stacking ensemble meta-classifier., 3. Demonstration of high effectiveness, achieving over 98% accuracy on a designed dataset, outperforming existing techniques against visually obfuscated spam.",
      "summary": "This paper addresses the problem of spam emails that use visual tricks like hidden text to evade traditional text-based filters. It proposes VBSF, a visual-based spam filter that renders emails, processes them through parallel text and image analysis pipelines, and combines the results with ensemble learning. The method achieves over 98% accuracy, outperforming existing techniques.",
      "mindmap": "graph TB\n        A[VBSF: 视觉垃圾邮件过滤技术 / VBSF: Visual-Based Spam Filtering] --> B[核心问题: 视觉混淆的垃圾邮件 / Problem: Visually Obfuscated Spam]\n        A --> C[主要方法: 双通道视觉处理与集成学习 / Method: Dual-Pipeline Visual Processing & Ensemble Learning]\n        A --> D[关键结果: 准确率>98% / Results: Accuracy >98%]\n        B --> B1[文本检测失效 / Text Detection Evasion]\n        C --> C1[渲染与捕获 / Rendering & Capture]\n        C1 --> C2[文本管道: OCR+分类器 / Text Pipeline: OCR+Classifiers]\n        C1 --> C3[图像管道: CNN / Image Pipeline: CNN]\n        C2 & C3 --> C4[元分类器集成 / Meta-Classifier Ensemble]"
    },
    {
      "title": "Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense",
      "authors": "Samaresh Kumar Singh, Joyjit Roy",
      "institution": "IEEE (Inferred from author affiliations as IEEE members; specific institutional affiliation not provided in the excerpt)",
      "link": "https://arxiv.org/pdf/2512.23849",
      "code": null,
      "tags": [
        "IoT Security",
        "Economic Denial Security",
        "Stackelberg Game",
        "Cost Asymmetry",
        "Computational Puzzles"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53020dd5fb969c1980dd7f764afe5f97440c1ef68620bdcd3383e97bf39600fc_w640_q70.webp",
      "contributions": "1. Proposed the Economic Denial Security (EDS) framework, a detection-independent defense that exploits the defender's environmental control to impose economic infeasibility on attackers., 2. Formally modeled EDS as a Stackelberg game, deriving optimal parameters and proving that the composition of its four mechanisms yields superlinear (2.1x) cost amplification., 3. Demonstrated practical efficacy with a lightweight (&lt;12KB) implementation, validated on a 20-device IoT testbed and against IoT-23 malware, showing significant attack slowdown, cost asymmetry, and improved mitigation rates.",
      "summary": "The paper addresses the failure of detection-based security in resource-constrained IoT/edge environments. It proposes Economic Denial Security (EDS), a framework that uses mechanisms like computational puzzles and bandwidth taxation to make attacks economically infeasible by amplifying attacker costs. The method is proven to be lightweight, effective in significantly slowing attacks and reducing success rates, and provides a detection-independent layer of defense.",
      "mindmap": "graph TB\n        A[Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[检测安全在资源受限的IoT/边缘环境中失效/Detection-based security fails in resource-constrained IoT/edge]\n        C --> C1[经济拒绝安全框架 / Economic Denial Security (EDS) Framework]\n        C1 --> C2[四种机制组合 / Four Mechanism Composition]\n        C2 --> C3[计算谜题 / Computational Puzzles]\n        C2 --> C4[交互熵 / Interaction Entropy]\n        C2 --> C5[时间拉伸 / Temporal Stretching]\n        C2 --> C6[带宽征税 / Bandwidth Taxation]\n        C --> C7[斯塔克尔伯格博弈建模 / Stackelberg Game Modeling]\n        D --> D1[32-560倍攻击减速 / 32-560x Attack Slowdown]\n        D --> D2[85-520:1 成本不对称 / 85-520:1 Cost Asymmetry]\n        D --> D3[内存占用<12KB / <12KB Memory Footprint]\n        D --> D4[94% 恶意软件缓解 / 94% Malware Mitigation]"
    },
    {
      "title": "Breaking Audio Large Language Models by Attacking Only the Encoder: A Universal Targeted Latent-Space Audio Attack",
      "authors": "Roee Ziv, Raz Lapid, Moshe Sipper",
      "institution": "Ben Gurion University of the Negev, Deepkeep",
      "link": "https://arxiv.org/pdf/2512.23881",
      "code": null,
      "tags": [
        "adversarial attacks",
        "universal adversarial perturbation",
        "latent-space attack",
        "audio-language models",
        "encoder-level vulnerability",
        "targeted attack"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aec73155c062c3c66b8e33c0e7892e17d374292349cfa71e3389850584cf8195_w640_q70.webp",
      "contributions": "1. Proposes a universal targeted latent-space attack against audio-language models, focusing solely on the audio encoder. 2. Introduces an attack method that learns a single perturbation effective across different inputs and speakers, without needing access to the downstream language model. 3. Demonstrates high attack success rates with minimal perceptual distortion on a state-of-the-art model, revealing a critical new attack surface in multimodal systems.",
      "summary": "This paper identifies a security vulnerability in audio-language models where adversarial attacks can be launched by manipulating only the audio encoder's latent representations. The proposed method learns a universal perturbation that forces the model to generate attacker-specified text outputs, and experiments show it is highly effective and stealthy. This reveals a significant and previously underexplored attack surface at the encoder level of multimodal AI systems.",
      "mindmap": "graph TB\n        Root[”Breaking Audio Large Language Models by Attacking Only the Encoder<br>仅攻击编码器来攻破音频大语言模型”] --> Problem[”核心问题/Problem<br>Audio-language models have new security vulnerabilities.<br>音频-语言模型存在新的安全漏洞”]\n        Root --> Method[”主要方法/Method<br>Universal targeted latent-space attack on the encoder.<br>针对编码器的通用目标潜空间攻击”]\n        Root --> Results[”关键结果/Results<br>High attack success with minimal distortion.<br>高攻击成功率，最小感知失真”]"
    },
    {
      "title": "DivQAT: Enhancing Robustness of Quantized Convolutional Neural Networks against Model Extraction Attacks",
      "authors": "Kacem Khaled, Felipe Gohring de Magalhães, Gabriela Nicolescu",
      "institution": "Polytechnique Montreal",
      "link": "https://arxiv.org/pdf/2512.23948",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "Quantization Aware Training",
        "Model Extraction Attack",
        "Quantized Convolutional Neural Networks",
        "Edge Device",
        "Robustness"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c08371f06267ec2fffb37ff15727bbbcfaf1e05de4f88d1541883445740a65d_w640_q70.webp",
      "contributions": "1. Proposes DivQAT, a novel algorithm to train quantized CNNs that integrates a defense mechanism directly into the Quantization Aware Training process to enhance robustness against model extraction attacks. 2. Demonstrates that the proposed technique effectively defends against model extraction attacks without compromising the model's accuracy, as validated on benchmark vision datasets. 3. Shows that combining the proposed quantization technique with other defense mechanisms improves their effectiveness compared to using traditional QAT.",
      "summary": "This paper addresses the vulnerability of quantized Convolutional Neural Networks to model extraction attacks. It proposes DivQAT, a novel training algorithm that modifies the quantization process to integrate a defense mechanism directly, enhancing model robustness. The method is shown to be effective against attacks without harming accuracy and can improve other defenses when combined.",
      "mindmap": "graph TB\n        Root[”DivQAT: Enhancing Robustness of Quantized CNNs against Model Extraction Attacks”] --> Problem[”核心问题/Problem: Quantized CNNs are vulnerable to model extraction attacks, posing IP theft risks.”]\n        Root --> Method[”主要方法/Method: Proposes DivQAT, a novel QAT-based algorithm integrating defense into the quantization training process.”]\n        Root --> Results[”关键结果/Results: Enhances robustness against attacks without compromising accuracy; improves other defenses.”]"
    },
    {
      "title": "MeLeMaD: Adaptive Malware Detection via Chunk-wise Feature Selection and Meta-Learning",
      "authors": "Ajvad Haneef K, Karan Kuwar Singh, Madhu Kumar S D",
      "institution": "National Institute of Technology Calicut",
      "link": "https://arxiv.org/pdf/2512.23987",
      "code": null,
      "tags": [
        "malware detection",
        "Model-Agnostic Meta-Learning (MAML)",
        "Chunk-wise Feature Selection (CFSGB)",
        "Gradient Boosting"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1509044c1c0bdfbb4a075c799e3c0cafd035f0b7c579548b445cf04caee2975d_w640_q70.webp",
      "contributions": "1. Proposed MeLeMaD, a novel malware detection framework leveraging Model-Agnostic Meta-Learning (MAML) for adaptability and generalization. 2. Introduced a novel Chunk-wise Feature Selection based on Gradient Boosting (CFSGB) technique to handle large-scale, high-dimensional datasets efficiently. 3. Demonstrated state-of-the-art performance on benchmark datasets (CIC-AndMal2020, BODMAS) and a custom dataset (EMBOD), achieving high accuracy and robustness.",
      "summary": "The paper proposes MeLeMaD, a novel malware detection framework that combines a new chunk-wise feature selection method (CFSGB) with meta-learning (MAML) to improve adaptability and efficiency on large-scale datasets. It achieves high accuracy on benchmark and custom datasets, outperforming existing state-of-the-art approaches and demonstrating robustness against evolving threats.",
      "mindmap": "graph TB\n        A[MeLeMaD: Adaptive Malware Detection] --> B[核心问题/Problem: Malware detection needs robustness & adaptability]\n        A --> C[主要方法/Method: Meta-Learning (MAML) + Chunk-wise Feature Selection (CFSGB)]\n        A --> D[关键结果/Results: High accuracy on benchmarks (98.04%, 99.97%) & custom dataset]"
    },
    {
      "title": "RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress",
      "authors": "Ruixuan Huang, Qingyue Wang, Hantao Huang, Yudong Gao, Dong Chen, Shuai Wang, Wei Wang",
      "institution": "HKUST, NTU",
      "link": "https://arxiv.org/pdf/2512.23995",
      "code": null,
      "tags": [
        "llm inference",
        "Mixture-of-Experts",
        "Router Imbalance",
        "Denial-of-Service",
        "Expert Parallelism",
        "Adversarial Prompt"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d78c253b115346789599383601182c2e6e0cd34050dd3dfd9f1541a370776561_w640_q70.webp",
      "contributions": "1. Identifies a novel DoS vulnerability in MoE LLMs where adversarial inputs can cause severe routing concentration and load imbalance during inference. 2. Proposes RepetitionCurse, a low-cost, black-box, and model-agnostic attack method that uses simple repetitive token patterns to exploit the router's universal flaw. 3. Empirically demonstrates significant performance degradation (e.g., 3.063x latency increase on Mixtral-8x7B), highlighting a critical risk to service-level agreements for real-world MoE deployments.",
      "summary": "This paper identifies a denial-of-service vulnerability in Mixture-of-Experts LLMs, where adversarial prompts can manipulate the router to concentrate all tokens on a few experts, creating severe load imbalance. The authors propose RepetitionCurse, a simple black-box attack using repetitive token patterns to exploit this flaw. Their method significantly increases inference latency, demonstrating a critical risk to the availability of MoE-based services.",
      "mindmap": "graph TB\n        A[RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[MoE推理负载不均/MoE Inference Load Imbalance]\n        B --> B2[路由集中导致DoS/Routing Concentration Leads to DoS]\n        C --> C1[重复令牌攻击/Repetitive Token Attack]\n        C --> C2[黑盒方法/Black-box Method]\n        D --> D1[延迟显著增加/Latency Significantly Increased]\n        D --> D2[服务可用性下降/Service Availability Degraded]"
    },
    {
      "title": "Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?",
      "authors": "Yuan Xin, Dingfan Chen, Linyi Yang, Michael Backes, Xiao Zhang",
      "institution": "CISPA Helmholtz Center for Information Security, Max Planck Institute for Intelligent Systems, Southern University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.24044",
      "code": null,
      "tags": [
        "adversarial attacks",
        "jailbreaking",
        "content safety filters",
        "LLM safety alignment",
        "input/output filtering"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e40bd85a824936f762c47f0b98464b3b30e7733690440363f10ee46695920a8_w640_q70.webp",
      "contributions": "1. First systematic evaluation of jailbreak attacks across the full LLM inference pipeline including input and output safety filters, 2. Demonstration that nearly all jailbreak techniques can be detected by at least one safety filter, challenging prior overestimations of attack success, 3. Identification of gaps in balancing recall and precision for optimizing protection and user experience in safety systems",
      "summary": "This paper addresses the gap in evaluating jailbreak attacks by systematically testing them against both LLM safety alignment and external content filters in the full deployment pipeline. The study finds that most jailbreaks can be detected by safety filters, suggesting prior success rates were overestimated, and highlights the need for better precision-recall balance in filter design.",
      "mindmap": "graph TB\n    A[Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?] --> B[核心问题/Problem: Jailbreak attacks bypass LLM safety alignment, prior evaluations neglect full deployment pipeline with content filters]\n    A --> C[主要方法/Method: First systematic evaluation of jailbreak attacks across full inference pipeline including input/output filtering stages]\n    A --> D[关键结果/Results: Most jailbreaks detectable by safety filters, prior success overestimated; need better recall-precision balance]"
    },
    {
      "title": "FedLiTeCAN : A Federated Lightweight Transformer for Fast and Robust CAN Bus Intrusion Detection",
      "authors": "Devika S, Pratik Narang, Tejasvi Alladi",
      "institution": "BITS Pilani, Pilani Campus",
      "link": "https://arxiv.org/pdf/2512.24088",
      "code": "https://github.com/Transformer",
      "tags": [
        "federated learning",
        "Controller Area Network (CAN)",
        "Intrusion Detection System (IDS)",
        "Transformer",
        "Federated Learning",
        "Lightweight Model"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fccdaefce6abd0f6935fde57aedf3ec8956dfd7f60385f88dafe7a2ba8e6ef09_w640_q70.webp",
      "contributions": "1. Proposes FedLiTeCAN, a supervised intrusion detection framework using a two-layer encoder-only transformer in a Federated Learning environment. 2. Achieves a highly lightweight model (0.4MB) and fast real-time inference (0.608 ms per message), significantly outperforming baselines in size and speed. 3. Demonstrates strong generalization capability through cross-dataset analysis, achieving high accuracy on unseen cyber threats.",
      "summary": "This paper proposes FedLiTeCAN, a lightweight Transformer-based Intrusion Detection System for CAN bus security, deployed using Federated Learning. The model is designed to be fast, small, and robust, achieving high accuracy and rapid inference on resource-constrained hardware like Jetson Nano. The results show it is an effective solution for real-time intrusion detection in vehicular networks.",
      "mindmap": "graph TB\n        A[FedLiTeCAN: A Federated Lightweight Transformer for Fast and Robust CAN Bus Intrusion Detection] --> B[核心问题/Problem: CAN协议缺乏内置安全，需要轻量、快速、鲁棒的入侵检测系统]\n        A --> C[主要方法/Method: 在联邦学习环境中使用轻量级两层编码器Transformer]\n        A --> D[关键结果/Results: 模型小(0.4MB)，检测快(0.608ms)，精度高(98.5%)，泛化能力强]"
    },
    {
      "title": "Spatial Discretization for Fine-Grain Zone Checks with STARKs",
      "authors": "Sungmin Lee, Kichang Lee, Gyeongmin Han, JeongGil Ko",
      "institution": "Yonsei University",
      "link": "https://arxiv.org/pdf/2512.24238",
      "code": null,
      "tags": [
        "zero-knowledge proofs",
        "STARKs",
        "point-in-polygon",
        "spatial discretization",
        "grid-based lookup",
        "distance-aware encoding"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b21a7e9aa05b0d0cd0b65c69a5d0b074af0efeaa891e8961a53b6a3c6b9c0099_w640_q70.webp",
      "contributions": "1. Systematically studies the accuracy-cost trade-offs of different grid-based discretization strategies for performing private point-in-polygon (PiP) tests using STARKs., 2. Proposes a novel distance-aware encoding approach that stores per-cell distance to zone boundaries and uses interpolation for finer reasoning within a cell., 3. Demonstrates through experiments on real-world data that the distance-aware method achieves significantly higher accuracy on coarse grids (up to 60%p gain) with only a moderate verification overhead (~1.4x).",
      "summary": "This paper addresses the challenge of performing private, verifiable point-in-polygon checks using zero-knowledge proofs, where geometric operations are expensive. The authors propose using grid-based lookup tables and introduce a distance-aware encoding method to improve accuracy on coarse grids. Their experiments show this method achieves substantial accuracy gains with only a moderate increase in proof verification cost.",
      "mindmap": "graph TB\n        A[”Spatial Discretization for Fine-Grain Zone Checks with STARKs<br/>基于STARK的细粒度区域检查的空间离散化”] --> B[”核心问题/Problem<br/>Private PiP tests are expensive in ZKPs<br/>在零知识证明中进行私有点在多边形内测试成本高昂”]\n        A --> C[”主要方法/Method<br/>Grid-based lookup tables with distance-aware encoding<br/>采用距离感知编码的基于网格的查找表”]\n        A --> D[”关键结果/Results<br/>Higher accuracy on coarse grids, moderate verification overhead<br/>在粗网格上实现更高精度，验证开销适度增加”]"
    },
    {
      "title": "How Would Oblivious Memory Boost Graph Analytics on Trusted Processors?",
      "authors": "Jiping Yu, Xiaowei Zhu, Kun Chen, Guanyu Feng, Yunyi Chen, Xiaoyu Fan, Wenguang Chen",
      "institution": "Tsinghua University, Ant Group",
      "link": "https://arxiv.org/pdf/2512.24255",
      "code": null,
      "tags": [
        "trusted execution environments",
        "oblivious memory",
        "trusted processors",
        "graph analytics",
        "access-pattern attacks",
        "co-design"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08e433695d838ba73c5b984792b816e4adc4fbf80f8832a16de957766cf1aa5f_w640_q70.webp",
      "contributions": "1. Proposes the integration of Oblivious Memory (OM) into trusted processors to mitigate performance degradation from data-oblivious algorithms. 2. Presents a co-design of storage structures and algorithms specifically for graph analytics to leverage OM efficiently. 3. Demonstrates a prototype system achieving 100x speedup over baselines with an OM sized around per-core cache, showing feasibility on existing hardware.",
      "summary": "This paper addresses the performance overhead of data-oblivious algorithms in Trusted Execution Environments (TEEs) for graph analytics by proposing the use of Oblivious Memory (OM). Through a co-design of storage and algorithms, the authors' prototype system achieves a 100x speedup, demonstrating that OM can be feasibly integrated into existing processors with minimal overhead to boost privacy-preserving computations.",
      "mindmap": "graph TB\n        Root[”How Would Oblivious Memory Boost Graph Analytics on Trusted Processors?”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>Data-oblivious algorithms in TEEs cause performance degradation for graph analytics due to access-pattern leaks.”]\n        Method[”主要方法/Method<br>Co-design of storage structure & algorithms to leverage Oblivious Memory (OM) integrated into processors.”]\n        Results[”关键结果/Results<br>Prototype is 100x faster than baselines with OM sized near per-core cache; feasible on existing hardware.”]"
    },
    {
      "title": "FedSecureFormer: A Fast, Federated and Secure Transformer Framework for Lightweight Intrusion Detection in Connected and Autonomous Vehicles",
      "authors": "Devika S, Vishnu Hari, Pratik Narang, Tejasvi Alladi, F. Richard Yu",
      "institution": "BITS Pilani, Pilani Campus; Carleton University",
      "link": "https://arxiv.org/pdf/2512.24345",
      "code": null,
      "tags": [
        "federated learning",
        "Transformer",
        "Federated Learning",
        "Differential Privacy",
        "Intrusion Detection",
        "Connected and Autonomous Vehicles"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7914a9d504b1c6d9fb36172de5c5c3554e336d7411316a13768fea0423324240_w640_q70.webp",
      "contributions": "1. Proposed FedSecureFormer, a lightweight encoder-only Transformer model with only 1.7M parameters for efficient intrusion detection in CAVs. 2. Integrated the model within a Federated Learning framework with Differential Privacy to enhance data privacy and enable collaborative training. 3. Demonstrated high performance (93.69% accuracy on 19 attacks) and fast inference (3.7775 ms on Jetson Nano), making it 100x faster than SOTA models.",
      "summary": "This paper addresses cybersecurity threats in Connected and Autonomous Vehicles (CAVs) by proposing FedSecureFormer, a lightweight Transformer model trained using Federated Learning and Differential Privacy. The model achieves high accuracy for intrusion detection while ensuring data privacy and demonstrates extremely fast inference on edge devices, making it suitable for real-world deployment.",
      "mindmap": "graph TB\n        Root[FedSecureFormer: A Fast, Federated and Secure Transformer Framework] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: CAV网络安全威胁 / Cybersecurity threats in CAVs]\n        Method[主要方法/Method: 轻量Transformer + 联邦学习 + 差分隐私 / Lightweight Transformer + FL + DP]\n        Results[关键结果/Results: 高精度 & 快速推理 / High Accuracy & Fast Inference]"
    },
    {
      "title": "SourceBroken: A large-scale analysis on the (un)reliability of SourceRank in the PyPI ecosystem",
      "authors": "Biagio Montaruli, Serena Elisa Ponta, Luca Compagna, Davide Balzarotti",
      "institution": "EURECOM, SAP, Endor Labs",
      "link": "https://arxiv.org/pdf/2512.24400",
      "code": null,
      "tags": [
        "software supply chain security",
        "SourceRank",
        "PyPI",
        "evasion attacks",
        "URL confusion",
        "threat model"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937ebee908f3f922e7d4e234d04ec0945535d6e38e06052bb2dad84c98f5f6b1_w640_q70.webp",
      "contributions": "1. Proposes a threat model for SourceRank, identifying evasion approaches for each of its 18 metrics, including the novel URL confusion technique. 2. Conducts a large-scale empirical analysis revealing that SourceRank distributions of benign and malicious packages significantly overlap in real-world PyPI data, limiting its reliability. 3. Quantifies the prevalence and impact of URL confusion as an emerging attack vector, showing its use alongside other techniques to inflate malicious package scores.",
      "summary": "This paper analyzes the reliability of the SourceRank scoring system in the PyPI ecosystem against evasion attacks. It proposes a threat model and conducts a large-scale empirical study, finding that SourceRank cannot reliably distinguish benign from malicious packages in real-world scenarios due to overlapping score distributions and vulnerabilities like URL confusion.",
      "mindmap": "graph TB\n        Root(”SourceBroken: SourceRank可靠性分析 / SourceBroken: SourceRank Reliability Analysis”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”SourceRank抗规避攻击的可靠性未知 / SourceRank's reliability against evasion attacks is unknown”)\n        Method --> M1(”提出威胁模型 / Propose threat model”)\n        Method --> M2(”大规模实证分析 / Large-scale empirical analysis”)\n        M1 --> M1a(”识别URL混淆等技术 / Identify techniques like URL confusion”)\n        M2 --> M2a(”分析恶意/良性包分布 / Analyze malicious/benign package distributions”)\n        Results --> R1(”真实世界分数分布重叠 / Real-world score distributions overlap”)\n        Results --> R2(”URL混淆攻击增加 / URL confusion attack is increasing”)\n        Results --> R3(”SourceRank不可靠 / SourceRank is unreliable”)"
    },
    {
      "title": "FAST-IDS: A Fast Two-Stage Intrusion Detection System with Hybrid Compression for Real-Time Threat Detection in Connected and Autonomous Vehicles",
      "authors": "Devika S, Vishnu Hari, Pratik Narang, Tejasvi Alladi, Vinay Chamola",
      "institution": "BITS Pilani, Pilani Campus",
      "link": "https://arxiv.org/pdf/2512.24391",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "hybrid model compression",
        "two-stage IDS",
        "BiGAN",
        "CNN-LSTM",
        "real-time inference"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e22580ef1d7646dbfb5cbb4038c5aaef82d4f9a515521bd0405cb40b44178ee2_w640_q70.webp",
      "contributions": "1. A novel two-stage Intrusion Detection System (IDS) architecture combining a coarse-grained BiGAN-CNN for anomaly detection and a fine-grained CNN-LSTM for attack classification. 2. The application of hybrid model compression (structural pruning and static quantization) to achieve a 77.2% model size reduction while maintaining performance. 3. Demonstrated real-time, efficient deployment on resource-constrained edge devices (e.g., Jetson Nano) with low per-vehicle inference latency.",
      "summary": "This paper proposes FAST-IDS, a fast two-stage intrusion detection system for Connected and Autonomous Vehicles (CAVs). It uses a hybrid model compression technique to create a lightweight system that combines anomaly detection (BiGAN-CNN) and attack classification (CNN-LSTM) for efficient real-time threat detection. The compressed model achieves significant size reduction and faster inference, making it suitable for deployment on edge devices like the Jetson Nano.",
      "mindmap": "graph TB\n        A[FAST-IDS: 面向CAV的快速入侵检测系统] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[CAV网络安全威胁 / CAV Cybersecurity Threats]\n        B --> B2[资源受限环境部署 / Deployment in Resource-Constrained Environments]\n        C --> C1[两阶段IDS / Two-Stage IDS]\n        C1 --> C1_1[阶段1: BiGAN-CNN异常检测 / Stage 1: BiGAN-CNN Anomaly Detection]\n        C1 --> C1_2[阶段2: CNN-LSTM攻击分类 / Stage 2: CNN-LSTM Attack Classification]\n        C --> C2[混合模型压缩 / Hybrid Model Compression]\n        C2 --> C2_1[结构化剪枝 / Structural Pruning]\n        C2 --> C2_2[静态量化 / Static Quantization]\n        D --> D1[模型大小减少77.2% / 77.2% Model Size Reduction]\n        D --> D2[推理时间减少50.05% / 50.05% Inference Time Reduction]\n        D --> D3[高检测准确率 / High Detection Accuracy]"
    },
    {
      "title": "Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service",
      "authors": "Jingyu Zhang",
      "institution": "University of Washington",
      "link": "https://arxiv.org/pdf/2512.24415",
      "code": null,
      "tags": [
        "agent system",
        "prompt injection attack",
        "customer-service agents",
        "cross-domain benchmark",
        "uncertainty reporting"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6779572a24da1e0c74a9dfbfb9709e2eded3ecfb7b6ce939ef10467a1fe6647f_w640_q70.webp",
      "contributions": "1. Introduced a cross-domain benchmark for evaluating profit-seeking direct prompt injection attacks against customer-service LLM agents, spanning 10 service domains and 100 realistic attack scripts. 2. Conducted a systematic evaluation across five widely used models, revealing that attack success is highly dependent on both the service domain and the specific attack technique used. 3. Released data and evaluation code to support reproducible auditing and to inform the design of oversight and recovery workflows for more trustworthy agent interfaces.",
      "summary": "This paper investigates how customer-service LLM agents can be exploited through direct prompt injection attacks to obtain unauthorized concessions. The authors propose a cross-domain benchmark to evaluate these attacks and find that their success varies significantly by domain and technique, with airline support being most vulnerable. The study concludes by releasing resources to help audit and build more robust, human-centered agent systems.",
      "mindmap": "graph TB\n        Root[”Language Model Agents Under Attack<br>语言模型智能体攻击研究”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>Customer-service LLM agents can be exploited for unauthorized profit<br>客服LLM智能体可能被利用谋取不当利益”]\n        Method[”主要方法/Method<br>Cross-domain benchmark of direct prompt injection attacks<br>跨领域直接提示注入攻击基准”]\n        Results[”关键结果/Results<br>Attacks are domain & technique dependent; Airline support most exploitable<br>攻击效果因领域和技术而异；航空客服最易受攻击”]"
    },
    {
      "title": "GateChain: A Blockchain Based Application for Country Entry Exit Registry Management",
      "authors": "Mohamad Akkad, Hüseyin Bodur",
      "institution": "Düzce University",
      "link": "https://arxiv.org/pdf/2512.24416",
      "code": null,
      "tags": [
        "blockchain applications",
        "blockchain",
        "distributed ledger",
        "data integrity",
        "border management",
        "access control"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24cbaf1f4e268b6a47f629b6a4fe561fec935c63abef7aaf082d6a093d3de2c7_w640_q70.webp",
      "contributions": "1. Proposes GateChain, a novel blockchain-based application specifically designed for managing country entry-exit registries. 2. Introduces an architecture that enhances data integrity, reliability, and transparency through an immutable, distributed ledger. 3. Provides real-time access control and verification mechanisms for authorized institutions to improve interoperability and security.",
      "summary": "This paper presents GateChain, a blockchain-based application designed to address vulnerabilities in traditional centralized border control systems. By recording entry and exit events on a distributed, immutable ledger, it aims to enhance data integrity, transparency, and real-time verification for authorized institutions. The study concludes by describing GateChain's architecture and evaluating its performance and security features.",
      "mindmap": "graph TB\n    A[GateChain: A Blockchain Based Application for Country Entry Exit Registry Management] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[传统边境系统脆弱性/Vulnerabilities of traditional border systems]\n    B --> B2[数据完整性与互操作性需求/Need for data integrity & interoperability]\n    C --> C1[基于区块链的登记管理/Blockchain-based registry management]\n    C --> C2[分布式不可变账本/Distributed immutable ledger]\n    D --> D1[增强数据完整性与透明度/Enhanced data integrity & transparency]\n    D --> D2[实时访问控制/Real-time access control]"
    },
    {
      "title": "Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations",
      "authors": "Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus",
      "institution": "Nexcepta, The Ohio State University, University of Maryland",
      "link": "https://arxiv.org/pdf/2512.24452",
      "code": null,
      "tags": [
        "semantic communications",
        "min-max optimization",
        "adversarial perturbations",
        "multi-task learning"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25e9c394c6a473f54b07d7337b43fb693f3ebef1de80e7b275ea3c91df03de11_w640_q70.webp",
      "contributions": "1. A deep learning-based semantic communication framework that jointly supports multiple receiver tasks (e.g., inference and reconstruction) while explicitly limiting semantic information leakage to an eavesdropper. 2. Formulation of the privacy problem as an iterative min-max optimization, where the legitimate transmitter-receiver pair is trained to degrade an adaptive eavesdropper's semantic inference performance. 3. Introduction of an auxiliary adversarial perturbation layer that superimposes a crafted signal on the transmitted waveform to degrade eavesdropper performance, even when the legitimate link is not co-trained against it.",
      "summary": "This paper addresses privacy leakage in semantic communications, where task-optimized representations can be exploited by eavesdroppers. The proposed method uses a min-max adversarial training framework and an auxiliary perturbation layer to protect semantic information. Evaluations on image datasets show the approach significantly reduces eavesdropper inference accuracy without harming legitimate receiver performance.",
      "mindmap": "graph TB\n        Root[Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Semantic representations leak sensitive information to eavesdroppers] --> Problem_Detail[语义泄露/Semantic Leakage]\n        Method[主要方法/Method: Deep learning framework with min-max optimization and adversarial perturbations] --> Method_Detail1[对抗训练/Min-Max Optimization]\n        Method --> Method_Detail2[扰动层/Perturbation Layer]\n        Results[关键结果/Results: Reduces eavesdropper accuracy, maintains legitimate performance] --> Results_Detail[有效隐私保护/Effective Privacy Preservation]"
    },
    {
      "title": "Document Data Matching for Blockchain-Supported Real Estate",
      "authors": "Henrique Lin, Tiago Dias, Miguel Correia",
      "institution": "INESC-ID, Instituto Superior Técnico, Universidade de Lisboa, Unlockit",
      "link": "https://arxiv.org/pdf/2512.24457",
      "code": null,
      "tags": [
        "decentralized systems",
        "Verifiable Credentials",
        "Optical Character Recognition",
        "Natural Language Processing",
        "Blockchain",
        "Data Matching"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/77d42eaf9ccd48f40b91694b8109e5b2c7abc796e86c6fd2151ac05f73c2f492_w640_q70.webp",
      "contributions": "1. Development of a prototype system that automates the extraction of key information from heterogeneous real estate documents using an OCR and NLP pipeline trained on synthetic data. 2. A framework for converting extracted document data into standardized Verifiable Credentials and performing automated data matching to detect inconsistencies. 3. Integration of blockchain as a decentralized trust layer to reinforce transparency and integrity in document verification and management.",
      "summary": "This paper addresses the inefficiency and fraud risk in manual real estate document handling by proposing a system that integrates OCR, NLP, and Verifiable Credentials to automate document extraction and verification, backed by a blockchain trust layer. The developed prototype demonstrates competitive accuracy in information extraction and reduces verification time while maintaining reliability. The framework shows potential to streamline transactions and enhance trust in the real estate sector.",
      "mindmap": "graph TB\n        A[Document Data Matching for Blockchain-Supported Real Estate] --> B(核心问题/Problem: Manual document handling in real estate is inefficient and prone to fraud.)\n        A --> C(主要方法/Method: Integrates OCR, NLP, and Verifiable Credentials for automated extraction and verification, using blockchain for trust.)\n        A --> D(关键结果/Results: Prototype achieves competitive accuracy and reduces verification time, demonstrating potential to streamline transactions.)"
    },
    {
      "title": "Training-Free Color-Aware Adversarial Diffusion Sanitization for Diffusion Stegomalware Defense at Security Gateways",
      "authors": "Vladimir Frants, Sos Agaian",
      "institution": "University of Texas at San Antonio (inferred from author \"Sos Agaian\" affiliation)",
      "link": "https://arxiv.org/pdf/2512.24499",
      "code": null,
      "tags": [
        "steganography defense",
        "adversarial sanitization",
        "diffusion models",
        "pretrained denoiser",
        "quaternion update",
        "stegomalware"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c855da6cedcd1ea0c4dd38e35e187e7080351881b3a1515b6079801e94495a6_w640_q70.webp",
      "contributions": "1. Proposes Adversarial Diffusion Sanitization (ADS), a training-free defense that neutralizes hidden payloads in diffusion-based steganography instead of detecting them. 2. Introduces a color-aware, quaternion-coupled update rule to minimize perceptual artifacts under strict distortion constraints. 3. Demonstrates effectiveness by driving decoder success rates of the state-of-the-art method Pulsar to near zero with minimal impact on image utility.",
      "summary": "This paper addresses the threat of diffusion model-based steganography used for covert malware delivery. It proposes Adversarial Diffusion Sanitization (ADS), a training-free method that uses a pretrained denoiser and a color-aware update rule to subtly perturb images and neutralize hidden payloads. The results show ADS effectively disrupts steganographic decoding with minimal visual distortion, offering a practical defense for security gateways.",
      "mindmap": "graph TB\n    A[Training-Free Color-Aware Adversarial Diffusion Sanitization<br>免训练颜色感知对抗扩散净化] --> B\n    A --> C\n    A --> D\n    B[核心问题/Problem<br>Diffusion steganography enables covert stegomalware delivery<br>扩散隐写术实现隐蔽的隐写恶意软件传递]\n    C[主要方法/Method<br>ADS: Training-free sanitization using pretrained denoiser & color-aware quaternion update<br>ADS: 使用预训练去噪器和颜色感知四元数更新的免训练净化]\n    D[关键结果/Results<br>Neutralizes Pulsar payloads with near-zero success rate & minimal distortion<br>以接近零的成功率和最小失真中和Pulsar有效载荷]"
    },
    {
      "title": "Correctness of Extended RSA Public Key Cryptosystem",
      "authors": "Dar-jen Chang, Suranjan Gautam",
      "institution": "University of Louisville",
      "link": "https://arxiv.org/pdf/2512.24531",
      "code": null,
      "tags": [
        "public-key cryptography",
        "RSA",
        "correctness proof",
        "Euler's totient function",
        "encryption scheme",
        "extended framework"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d77ed6a545644c2ccdf966a071393d3cfcee6f07a446350e34a622ca676f40c_w640_q70.webp",
      "contributions": "1. Proposes an alternative methodology for formally proving the correctness of the RSA cryptosystem, deviating from conventional proofs. 2. Explores and defines an extended framework for RSA, specifically examining conditions for the choice of the integer N beyond standard criteria. 3. Derives explicit conditions that determine the validity of N for the encryption scheme and explains why certain values fail to meet correctness requirements.",
      "summary": "This paper presents an alternative method for formally proving the correctness of the RSA public-key cryptosystem. It investigates an extended framework where the choice of the modulus N can go beyond standard selection rules, deriving explicit conditions for valid N. The main conclusion is a set of conditions that determine when the extended scheme remains mathematically correct, while deliberately not addressing cryptographic security.",
      "mindmap": "graph TB\n        A[Correctness of Extended RSA Public Key Cryptosystem] --> B[核心问题/Problem: Conditions for valid N in RSA]\n        A --> C[主要方法/Method: Alternative correctness proof & extended framework]\n        A --> D[关键结果/Results: Explicit validity conditions for N]"
    },
    {
      "title": "SynRAG: A Large Language Model Framework for Executable Query Generation in Heterogeneous SIEM System",
      "authors": "Md Hasan Saju, Austin Page, Akramul Azim, Jeff Gardiner, Farzaneh Abazari, Frank Eargle",
      "institution": "Ontario Tech University, GlassHouse Systems Inc.",
      "link": "https://arxiv.org/pdf/2512.24571",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "SIEM",
        "query generation",
        "platform-agnostic specification",
        "cross-platform",
        "LLM framework"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d87255708c71cdba68b8c5ca7054cc8216b56e3021254a7bbbd7c64c9a53687_w640_q70.webp",
      "contributions": "1. Introduces SynRAG, a unified LLM framework for generating executable queries for heterogeneous SIEM systems from a single high-level specification. 2. Enables seamless threat detection and incident investigation across different SIEM platforms, reducing the need for specialized training. 3. Demonstrates superior performance compared to state-of-the-art base LLMs (GPT, Llama, etc.) in generating platform-specific queries for systems like Qradar and SecOps.",
      "summary": "The paper introduces SynRAG, a framework that uses large language models to automatically generate platform-specific SIEM queries from a single, high-level, platform-agnostic specification. This addresses the challenge of monitoring diverse SIEM systems with different query languages. Evaluation shows SynRAG outperforms base LLMs in generating accurate queries for cross-platform threat detection and investigation.",
      "mindmap": "graph TB\n        A[SynRAG: 异构SIEM系统的可执行查询生成框架<br>SynRAG: Executable Query Generation in Heterogeneous SIEM Systems] --> B[核心问题/Problem: SIEM平台多样性导致查询语言不同，分析师监控多平台困难<br>Problem: SIEM platform diversity leads to different query languages, making multi-platform monitoring difficult for analysts]\n        A --> C[主要方法/Method: 提出SynRAG框架，从平台无关的高级描述自动生成特定平台查询<br>Method: Proposes SynRAG framework to auto-generate platform-specific queries from a platform-agnostic high-level specification]\n        A --> D[关键结果/Results: SynRAG生成的查询优于GPT、Llama等先进基础模型<br>Results: SynRAG generates better queries than SOTA base models like GPT, Llama]"
    },
    {
      "title": "Secure Digital Semantic Communications: Fundamentals, Challenges, and Opportunities",
      "authors": "Weixuan Chen, Qianqian Yang, Yuanyuan Jia, Junyu Pan, Shuo Shao, Jincheng Dai, Meixia Tao, Ping Zhang",
      "institution": "Zhejiang University, University of Shanghai for Science and Technology, Beijing University of Posts and Telecommunications, Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.24602",
      "code": null,
      "tags": [
        "semantic communication security",
        "digital semantic communication",
        "semantic leakage",
        "probabilistic modulation",
        "deterministic modulation",
        "threat landscape"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abeb8d239a7e8c68cec436e0b796d7ed725be30de8ba11eb9a40c8bddac3296e_w640_q70.webp",
      "contributions": "1. Clarifies the architectural differences between analog and digital semantic communication and their distinct security implications. 2. Systematically organizes the threat landscape for digital semantic communication, identifying vulnerabilities at the bit/symbol, modulation, and protocol levels. 3. Discusses potential defense mechanisms and outlines open research directions for building secure and deployable digital semantic communication systems.",
      "summary": "This paper identifies that digital semantic communication, which transmits discrete semantic symbols for better compatibility, introduces unique and underexplored security risks compared to analog semantic communication. It systematically reviews these vulnerabilities and discusses potential defenses. The main conclusion is a call for focused research to secure this promising communication paradigm for future deployment.",
      "mindmap": "graph TB\n        Root[”Secure Digital Semantic Communications: Fundamentals, Challenges, and Opportunities”] --> Problem[”核心问题/Problem: Digital SemCom has distinct and underexplored security risks.”]\n        Root --> Method[”主要方法/Method: Review fundamentals, clarify analog vs. digital differences, organize threat landscape, discuss defenses.”]\n        Root --> Results[”关键结果/Results: Outlines vulnerabilities and open research directions for secure digital SemCom.”]"
    },
    {
      "title": "Practical Traceable Over-Threshold Multi-Party Private Set Intersection",
      "authors": "Le Yang, Weijing You, Huiyang He, Kailiang Ji, Jingqiang Lin",
      "institution": "University of Science and Technology of China, Fujian Normal University, NIO Inc.",
      "link": "https://arxiv.org/pdf/2512.24652",
      "code": null,
      "tags": [
        "secure multi-party computation",
        "private set intersection",
        "threshold PSI",
        "oblivious programmable pseudorandom function",
        "secret sharing",
        "oblivious linear evaluation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f97cda79fc2970d2ffe5bf0e6a5be91a976069fd55c0bc36a2e4b1480d0cda4_w640_q70.webp",
      "contributions": "1. Proposes the concept of Traceable Over-Threshold MP-PSI (T-OT-MP-PSI), which reveals not only intersection elements but also their holders, enhancing reliability. 2. Designs ET-OT-MP-PSI, an efficient protocol combining Shamir's secret sharing and oblivious programmable pseudorandom function, resistant to t-2 semi-honest participants. 3. Designs ST-OT-MP-PSI, a security-enhanced protocol leveraging oblivious linear evaluation to achieve security against up to n-1 semi-honest participants, removing special non-collusion assumptions.",
      "summary": "This paper addresses the problem of traceable multi-party private set intersection with a threshold, where elements appearing in at least t sets and their holders are revealed. The authors propose two protocols: an efficient one (ET-OT-MP-PSI) and a security-enhanced one (ST-OT-MP-PSI), both offering stronger security without special non-collusion assumptions and achieving significant speedups (e.g., 15056x and 505x) compared to prior work.",
      "mindmap": "graph TB\n        A[Practical Traceable Over-Threshold Multi-Party Private Set Intersection] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[MP-PSI with threshold lacks traceability of element holders / 带阈值的多方PSI缺乏元素持有者的可追溯性]\n        C --> C1[ET-OT-MP-PSI: Efficient protocol using secret sharing & OPPRF / 高效协议: 秘密共享与OPPRF]\n        C --> C2[ST-OT-MP-PSI: Security-enhanced protocol using OLE / 安全增强协议: OLE]\n        D --> D1[Removes special non-collusion assumption / 移除特殊不共谋假设]\n        D --> D2[Significant speedup vs. prior work (e.g., 15056x) / 相比现有工作显著加速 (如15056倍)]"
    },
    {
      "title": "CellSecInspector: Safeguarding Cellular Networks via Automated Security Analysis on Specifications",
      "authors": "Ke Xie, Xingyi Zhao, Yiwen Hu, Munshi Saifuzzaman, Wen Li, Shuhan Yuan, Tian Xie, Guan-Hua Tu",
      "institution": "Utah State University, University of Maryland, Baltimore County, Michigan State University",
      "link": "https://arxiv.org/pdf/2512.24682",
      "code": null,
      "tags": [
        "cellular network security",
        "3GPP specifications",
        "state-condition-action (SCA)",
        "automated vulnerability discovery"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24e28705efeddad933ffb8777e8d25c1f77132448926c4186362d68b4fa35c92_w640_q70.webp",
      "contributions": "1. Proposes CellSecInspector, an automated framework that extracts structured SCA representations and models mobile network procedures with function chains from 3GPP specifications. 2. Enables systematic validation against foundational security properties and automatic test case generation without relying on manually predefined rules. 3. Discovers 43 vulnerabilities (including 8 new ones) in 5G/4G NAS and RRC specifications, demonstrating its scalability and effectiveness.",
      "summary": "This paper presents CellSecInspector, an automated framework for security analysis of complex 3GPP cellular network specifications. It extracts structured procedure models and validates them against security properties to discover vulnerabilities without manual rules. The system found 43 vulnerabilities in 5G/4G specifications, proving to be a scalable solution for safeguarding cellular networks.",
      "mindmap": "graph TB\n        Root[CellSecInspector: Safeguarding Cellular Networks] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[3GPP规范复杂且快速演变/Complex & Evolving 3GPP Specs]\n        Problem --> P2[现有方法无法捕获深度语义依赖/Existing Methods Fail on Deep Semantics]\n        Method[主要方法/Method] --> M1[提取SCA表示与函数链/Extract SCA & Function Chains]\n        Method --> M2[系统化验证安全属性/Systematic Security Validation]\n        Method --> M3[自动生成测试用例/Automated Test Case Generation]\n        Results[关键结果/Results] --> R1[发现43个漏洞/Discover 43 Vulnerabilities]\n        Results --> R2[包含8个新漏洞/Include 8 New Vulnerabilities]\n        Results --> R3[证明可扩展与有效/Proven Scalable & Effective]"
    },
    {
      "title": "SoK: Web3 RegTech for Cryptocurrency VASP AML/CFT Compliance",
      "authors": "Qian'ang Mao, Jiaxin Wang, Ya Liu, Li Zhu, Jiaman Chen, Jiaqi Yan",
      "institution": "Nanjing University",
      "link": "https://arxiv.org/pdf/2512.24888",
      "code": null,
      "tags": [
        "blockchain security",
        "RegTech",
        "AML/CFT",
        "transaction graph analysis",
        "cross-chain analytics",
        "privacy-preserving verification"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/436795f273ee49bee1ec9b9451624284da67c6c60b7f58ea946d5c0fd61ac8b8_w640_q70.webp",
      "contributions": "1. Developed three taxonomies to organize the Web3 RegTech domain, including a regulatory paradigm evolution framework, a compliance protocol taxonomy, and a RegTech lifecycle framework. 2. Conducted a systematic analysis of 41 commercial platforms and 28 academic prototypes to demonstrate the novel capabilities of blockchain-native RegTech solutions. 3. Identified critical research gaps and synthesized architectural best practices for future Web3 compliance solutions that respect decentralization principles.",
      "summary": "This paper systematically examines how blockchain-native regulatory technology (RegTech) addresses AML/CFT compliance challenges in Web3. It proposes new taxonomies and analyzes existing solutions, finding that Web3 RegTech enables novel capabilities like transaction graph analysis and cross-chain tracking but faces gaps between academic research and industry deployment.",
      "mindmap": "graph TB\n        Root[SoK: Web3 RegTech for Cryptocurrency VASP AML/CFT Compliance] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[传统合规方案不适用于Web3/Traditional compliance inadequate for Web3]\n        Problem --> P2[去中心化架构带来AML/CFT挑战/Decentralized architecture creates AML/CFT challenges]\n        Method[主要方法/Method] --> M1[提出三个分类法/Propose three taxonomies]\n        Method --> M2[分析69个平台与原型/Analyze 69 platforms & prototypes]\n        Results[关键结果/Results] --> R1[Web3 RegTech实现新能力/Web3 RegTech enables novel capabilities]\n        Results --> R2[揭示学术与产业间的差距/Reveals gaps between academia & industry]"
    },
    {
      "title": "MTSP-LDP: A Framework for Multi-Task Streaming Data Publication under Local Differential Privacy",
      "authors": "Chang Liu, Junzhou Zhao",
      "institution": "Xi'an Jiaotong University",
      "link": "https://arxiv.org/pdf/2512.24899",
      "code": null,
      "tags": [
        "privacy-preserving protocols",
        "local differential privacy",
        "streaming data",
        "privacy budget allocation",
        "multi-task queries",
        "data-adaptive tree"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/def5ebea41b1bf2a4a6e8fe823e1914e917b47ae36d0997f3d710c3caef7f636_w640_q70.webp",
      "contributions": "1. An Optimal Privacy Budget Allocation algorithm that dynamically allocates privacy budgets by analyzing temporal correlations within each window. 2. A data-adaptive private binary tree structure, refined by cross-timestamp grouping and smoothing, to support complex queries. 3. A unified Budget-Free Multi-Task Processing mechanism to support various streaming queries without consuming additional privacy budget.",
      "summary": "The paper proposes MTSP-LDP, a framework for publishing streaming data under local differential privacy. It addresses limitations of existing methods by dynamically allocating privacy budgets, using a data-adaptive tree for complex queries, and enabling multi-task processing without extra budget. Experiments show it achieves higher utility than existing methods across various streaming tasks.",
      "mindmap": "graph TB\n        A[MTSP-LDP: 多任务流数据发布框架 / Multi-Task Streaming Data Publication Framework] --> B\n        A --> C\n        A --> D\n        B[核心问题 / Problem: 现有w-事件LDP方法不适合复杂查询且忽略时序相关性 / Existing w-event LDP methods are unsuitable for complex queries and ignore temporal correlations]\n        C[主要方法 / Method: 动态隐私预算分配、数据自适应私有二叉树、无预算多任务处理 / Dynamic Privacy Budget Allocation, Data-adaptive Private Binary Tree, Budget-Free Multi-Task Processing]\n        D[关键结果 / Results: 在真实数据集上实现高效用，显著优于现有方法 / Achieves high utility on real-world datasets, significantly outperforming existing methods]"
    },
    {
      "title": "Towards Provably Secure Generative AI: Reliable Consensus Sampling",
      "authors": "Yu Cui, Hang Fu, Sicheng Pan, Zhuoyu Sun, Yifei Liu, Yuhong Nie, Bo Ran, Baohan Huang, Xufeng Zhang, Haibin Zhang, Cong Zuo, Licheng Wang",
      "institution": "Beijing Institute of Technology, Yangtze Delta Region Institute of Tsinghua University, Zhejiang",
      "link": "https://arxiv.org/pdf/2512.24925",
      "code": null,
      "tags": [
        "generative ai security",
        "consensus sampling",
        "provable security",
        "adversarial robustness",
        "risk threshold",
        "abstention"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f86b2057e16407bdea9522c4bcc17ab118bd975ebf15313de450cc457b7b3de9_w640_q70.webp",
      "contributions": "1. Proposes Reliable Consensus Sampling (RCS), a new primitive that traces acceptance probability to tolerate extreme adversarial behaviors and eliminates the need for abstention. 2. Develops a feedback algorithm to continuously and dynamically enhance the safety of the RCS system. 3. Provides theoretical guarantees that RCS maintains a controllable risk threshold, with experiments showing improved robustness and utility.",
      "summary": "The paper identifies limitations in the Consensus Sampling (CS) algorithm for provably secure generative AI, such as reduced utility from frequent abstention and vulnerability to malicious models. To address this, the authors propose Reliable Consensus Sampling (RCS), which improves robustness and eliminates abstention. Theoretical and experimental results show that RCS maintains a controllable risk while significantly improving utility and robustness.",
      "mindmap": "graph TB\n        A[Towards Provably Secure Generative AI: Reliable Consensus Sampling] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>CS算法缺陷/CS Algorithm Flaws] --> B1[依赖弃权，降低效用/Relies on Abstention, Reduces Utility]\n        B --> B2[对抗模型下易受攻击/Vulnerable to Adversarial Models]\n        C[主要方法/Method<br>可靠共识采样/Reliable Consensus Sampling (RCS)] --> C1[追踪接受概率/Traces Acceptance Probability]\n        C --> C2[容忍极端对抗行为/Tolerates Extreme Adversarial Behaviors]\n        C --> C3[无需弃权/Eliminates Abstention]\n        C --> C4[反馈算法增强安全/Feedback Algorithm Enhances Safety]\n        D[关键结果/Results<br>理论保证与实验/Theoretical Guarantees & Experiments] --> D1[可控风险阈值/Controllable Risk Threshold]\n        D --> D2[显著提升鲁棒性与效用/Significantly Improves Robustness & Utility]\n        D --> D3[延迟与CS相当/Latency Comparable to CS]"
    },
    {
      "title": "Exposed: Shedding Blacklight on Online Privacy",
      "authors": "Lucas Shen, Gaurav Sood",
      "institution": "Agency for Science, Technology and Research (A*STAR), Colorado State University",
      "link": "https://arxiv.org/pdf/2512.24041",
      "code": "https://github.com/themains/private_blacklight",
      "tags": [
        "web privacy measurement",
        "online tracking",
        "third-party cookies",
        "canvas fingerprinting",
        "session recording",
        "keylogging"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c7829afd90142167314b4ea6c389efad9936582f7817882df41c04e4b7e1863a_w640_q70.webp",
      "contributions": "1. A novel methodology combining large-scale, representative user browsing data with domain-level tracking detection from Blacklight to measure real-world surveillance exposure. 2. Quantification of the prevalence of various tracking technologies, from common ad trackers to invasive techniques like session recording and canvas fingerprinting, across a population. 3. Analysis revealing the concentration of tracking power (often by Google) and the persistence of demographic disparities in surveillance risk based on browsing behavior.",
      "summary": "This paper investigates the extent and nature of online surveillance by combining anonymized browsing data from a representative sample of Americans with the Blacklight tracking detection tool. The study finds that nearly all users encounter trackers, identifies the prevalence of more invasive techniques, and shows that tracking is highly concentrated among a few organizations. It concludes that while demographic differences in exposure are partly explained by browsing volume, disparities by age and race persist, indicating that the type of content browsed also influences surveillance risk.",
      "mindmap": "graph TB\n        A[Exposed: Shedding Blacklight on Online Privacy] --> B[核心问题/Problem<br>用户网络监控的程度、技术与主体]\n        A --> C[主要方法/Method<br>结合用户浏览数据与Blacklight跟踪检测]\n        A --> D[关键结果/Results<br>普遍存在跟踪、技术侵入性差异、组织集中度与人口差异]"
    },
    {
      "title": "Pruning Graphs by Adversarial Robustness Evaluation to Strengthen GNN Defenses",
      "authors": "Yongyu Wang",
      "institution": "Michigan Technological University",
      "link": "https://arxiv.org/pdf/2512.22128",
      "code": null,
      "tags": [
        "graph neural networks",
        "adversarial robustness",
        "graph pruning",
        "message passing",
        "spurious connections",
        "graph defense"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d658f9bc62a6d2a57e4602f69b9d0c69056551601abd2ba0336e97d592bae1dc_w640_q70.webp",
      "contributions": "1. Introduces a novel graph pruning framework that uses adversarial robustness evaluation to identify fragile graph components. 2. Proposes a method that selectively prunes edges based on robustness scores to improve model reliability and resilience. 3. Validates the framework by instantiating it on three representative GNN architectures and demonstrating significant defense enhancement in high-perturbation regimes.",
      "summary": "This paper addresses the vulnerability of Graph Neural Networks (GNNs) to adversarial attacks and noise in graph structure. It proposes a pruning framework that uses adversarial robustness scores to identify and remove detrimental edges, resulting in cleaner and more resilient graph representations. Experiments show this method significantly strengthens GNN defenses against high levels of perturbation.",
      "mindmap": "graph TB\n        A[Pruning Graphs by Adversarial Robustness Evaluation to Strengthen GNN Defenses] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1(GNNs对图结构和特征的扰动敏感/GNNs vulnerable to graph & feature perturbations)\n        C --> C1(基于对抗鲁棒性评分的剪枝框架/Pruning framework guided by adversarial robustness scores)\n        D --> D1(显著增强高扰动下的防御能力/Significantly enhances GNN defense in high-perturbation regime)"
    },
    {
      "title": "IANEC: Digital Forensic Investigation of Contemporary Writers' Archives",
      "authors": "Emmanuel Giguet",
      "institution": "Université Caen Normandie, ENSICAEN, CNRS, Normandie Univ, GREYC UMR 6072",
      "link": "https://arxiv.org/pdf/2512.22167",
      "code": null,
      "tags": [
        "digital forensics",
        "digital forensics",
        "file fingerprinting",
        "FUSE",
        "OS virtualization",
        "document classification"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a4c37c326ec3830119685f14996db61a1f1efdecaefecd64e96244e26e9512b_w640_q70.webp",
      "contributions": "1. Development of a method to separate system/application files from user files using fingerprint databases for archival analysis, 2. Creation of tools for reading files on Mac partitions and virtualizing operating systems to emulate original computing environments, 3. Implementation of semantic analysis techniques for automatic text classification, image analysis, and detection of sensitive content (e.g., hate speech) in digital archives.",
      "summary": "The IANEC project develops digital forensic tools to automate the analysis of born-digital archives from contemporary writers. The proposed method combines technical file system analysis (e.g., fingerprinting, virtualization) with semantic document analysis (e.g., text/image classification). The main conclusion is that these tools are essential for the effective extraction, processing, and description of native digital archival corpora in cultural heritage institutions.",
      "mindmap": "graph TB\n        Root[”IANEC: Digital Forensic Investigation of Contemporary Writers' Archives”] --> Problem[”核心问题/Problem: Born-digital archives are prevalent but difficult to analyze manually.”]\n        Root --> Method[”主要方法/Method: Develop digital forensic tools for technical and semantic analysis of archives.”]\n        Root --> Results[”关键结果/Results: Automated tools are essential for processing and describing digital archival corpora.”]"
    },
    {
      "title": "Practical challenges of control monitoring in frontier AI deployments",
      "authors": "David Lindner, Charlie Griffin, Tomek Korbak, Roland S. Zimmermann, Geoffrey Irving, Sebastian Farquhar, Alan Cooney",
      "institution": "Google DeepMind, UK AI Safety Institute, University of Oxford",
      "link": "https://arxiv.org/pdf/2512.22154",
      "code": null,
      "tags": [
        "ai security",
        "control monitoring",
        "oversight latency",
        "safety case",
        "scheming agents",
        "incremental attacks"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7cfc3d08c169a23a56cd0a16a1471c5bceacb1b76913f7079f51b7024f030d1_w640_q70.webp",
      "contributions": "1. Analysis of real-world deployment dynamics (parallelism, latency, incremental attacks, partial incrimination) for control monitoring, 2. Proposal and comparison of three monitoring protocols (synchronous, semi-synchronous, asynchronous) with different latency-safety trade-offs, 3. Introduction of a high-level safety case sketch as a tool for analyzing and comparing monitoring protocols, applied to four case studies.",
      "summary": "This paper analyzes the practical challenges of scaling automated control monitors for overseeing frontier AI agents in real-world deployments. It proposes and compares three monitoring protocols (synchronous, semi-synchronous, asynchronous) with different latency-safety trade-offs and introduces a safety case sketch as an analytical tool. The analysis identifies oversight, latency, and recovery as key challenges, explored through four case studies of potential AI attacks.",
      "mindmap": "graph TB\n        Root(”Practical challenges of control monitoring in frontier AI deployments<br>前沿AI部署中控制监控的实际挑战”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”现实部署的动态<br>Real-world Deployment Dynamics”)\n        P1 --> P1_1(”并行实例<br>Parallel Instances”)\n        P1 --> P1_2(”监督延迟<br>Oversight Latency”)\n        P1 --> P1_3(”增量攻击<br>Incremental Attacks”)\n        P1 --> P1_4(”部分归责<br>Partial Incrimination”)\n        Method --> M1(”监控协议<br>Monitoring Protocols”)\n        M1 --> M1_1(”同步监控<br>Synchronous”)\n        M1 --> M1_2(”半同步监控<br>Semi-synchronous”)\n        M1 --> M1_3(”异步监控<br>Asynchronous”)\n        Method --> M2(”安全案例草图<br>Safety Case Sketch”)\n        Results --> R1(”识别核心挑战<br>Identified Core Challenges”)\n        R1 --> R1_1(”监督<br>Oversight”)\n        R1 --> R1_2(”延迟<br>Latency”)\n        R1 --> R1_3(”恢复<br>Recovery”)\n        Results --> R2(”案例研究应用<br>Case Studies Application”)"
    },
    {
      "title": "Latent Sculpting for Zero-Shot Generalization: A Manifold Learning Approach to Out-of-Distribution Anomaly Detection",
      "authors": "Rajeeb Thapa Chhetri, Zhixiong Chen, Saurab Thapa",
      "institution": "Mercy University",
      "link": "https://arxiv.org/pdf/2512.22179",
      "code": null,
      "tags": [
        "anomaly detection",
        "manifold learning",
        "normalizing flows",
        "dual-centroid compactness loss",
        "out-of-distribution detection",
        "zero-shot generalization"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfcac5687161ad2a09f74eab3c1b7f91a350a2435fb71a0c791f2e305dff108c_w640_q70.webp",
      "contributions": "1. Proposes Latent Sculpting, a novel two-stage framework that decouples manifold structure learning from density estimation for OOD anomaly detection. 2. Introduces the Dual-Centroid Compactness Loss (DCCL) to actively sculpt a compact, low-entropy latent manifold for benign data. 3. Demonstrates superior zero-shot generalization on the CIC-IDS-2017 benchmark, significantly outperforming supervised and unsupervised baselines on complex distribution shifts like \"Infiltration\".",
      "summary": "The paper addresses the problem of \"Generalization Collapse\" in supervised models when detecting Out-of-Distribution (OOD) anomalies. It proposes Latent Sculpting, a two-stage method that first uses a novel loss to sculpt a compact latent manifold for benign data and then applies a normalizing flow for density estimation. The results show this approach enables robust zero-shot anomaly detection, significantly outperforming existing methods on unseen attack scenarios.",
      "mindmap": "graph TB\n        A[Latent Sculpting for Zero-Shot Generalization] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[泛化崩溃 / Generalization Collapse]\n        B --> B2[OOD异常检测失败 / OOD Anomaly Detection Failure]\n        C --> C1[潜在空间雕刻 / Latent Sculpting]\n        C1 --> C2[阶段1: DCCL损失 / Stage 1: DCCL Loss]\n        C1 --> C3[阶段2: MAF密度估计 / Stage 2: MAF Density Estimation]\n        D --> D1[零样本F1分数0.87 / Zero-Shot F1-Score 0.87]\n        D --> D2[渗透攻击检测率88.89% / Infiltration Detection 88.89%]"
    },
    {
      "title": "ReGAIN: Retrieval-Grounded AI Framework for Network Traffic Analysis",
      "authors": "Shaghayegh Shajarian, Kennedy Marsh, James Benson, Sajad Khorsandroo, Mahmoud Abdelsalam",
      "institution": "North Carolina A&T State University, University of Texas at San Antonio",
      "link": "https://arxiv.org/pdf/2512.22223",
      "code": "https://github.com/270771/llm-traffictraffic",
      "tags": [
        "rag (retrieval-augmented generation)",
        "retrieval-augmented generation (RAG)",
        "network traffic analysis",
        "large language models (LLMs)",
        "hierarchical retrieval",
        "explainable AI"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/56c5ba03e3d4a510212509143bfecf0fa8b76f9171aa38dd765dadecc7b1ab32_w640_q70.webp",
      "contributions": "1. Proposes ReGAIN, a multi-stage framework combining traffic summarization, RAG, and LLM reasoning for transparent network traffic analysis. 2. Introduces a hierarchical retrieval pipeline with metadata filtering, MMR sampling, cross-encoder reranking, and an abstention mechanism to ground responses and reduce hallucinations. 3. Demonstrates high accuracy (95.95%-98.82%) on real-world attack traces and outperforms traditional baselines while providing explainable, evidence-cited outputs.",
      "summary": "The paper presents ReGAIN, a framework that uses retrieval-augmented generation (RAG) and LLMs to analyze network traffic. It converts traffic into summaries, retrieves relevant evidence from a vector database, and generates interpretable, grounded analyses. The method achieves high accuracy on attack detection and provides explainable results, outperforming traditional rule-based and ML approaches.",
      "mindmap": "graph TB\n        A[ReGAIN: Retrieval-Grounded AI Framework for Network Traffic Analysis] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Traditional traffic analysis systems have high false positives and lack interpretability.]\n        C[主要方法/Method: Multi-stage framework using traffic summarization, RAG, and LLM reasoning with a hierarchical retrieval pipeline.]\n        D[关键结果/Results: Achieves 95.95%-98.82% accuracy, outperforms baselines, and provides explainable, evidence-grounded responses.]"
    },
    {
      "title": "Failure Analysis of Safety Controllers in Autonomous Vehicles Under Object-Based LiDAR Attacks",
      "authors": "Daniyal Ganiuly, Nurzhau Bolatbek, Assel Smaiyl",
      "institution": "Astana IT University",
      "link": "https://arxiv.org/pdf/2512.22244",
      "code": null,
      "tags": [
        "autonomous vehicle security",
        "LiDAR attacks",
        "safety controllers",
        "adversarial perception",
        "cut-in scenarios",
        "time to collision"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f08729d3ab6d3cb95ef74d24b6a8c9504767e34a79b6a8ed3d819b7a0449654_w640_q70.webp",
      "contributions": "1. Presents a systematic failure analysis of longitudinal safety controllers under object-based LiDAR attacks in highway scenarios., 2. Demonstrates that short-duration LiDAR-induced object hallucinations can trigger unsafe braking, delayed hazard responses, and unstable control., 3. Shows that controller failures are more influenced by the temporal consistency of spoofed objects than by spatial inaccuracies alone.",
      "summary": "This paper analyzes how object-based LiDAR attacks impact the safety controllers of autonomous vehicles. Using a high-fidelity simulation framework, it evaluates attacks in highway scenarios and finds they can cause unsafe braking and delayed responses. The key conclusion is that temporal consistency of adversarial objects is a stronger driver of controller failure than spatial errors, revealing a gap between perception robustness and control-level safety.",
      "mindmap": "graph TB\n        Root[”Failure Analysis of Safety Controllers in Autonomous Vehicles Under Object-Based LiDAR Attacks”] --> Problem[”核心问题/Problem: Impact of LiDAR attacks on vehicle safety controllers is not well understood”]\n        Root --> Method[”主要方法/Method: High-fidelity simulation of attacks in cut-in and car-following scenarios”]\n        Root --> Results[”关键结果/Results: Attacks cause unsafe braking; failures depend more on temporal consistency than spatial accuracy”]"
    },
    {
      "title": "Learning from Negative Examples: Why Warning-Framed Training Data Teaches What It Warns Against",
      "authors": "Tsogt-Ochir Enkhbayar",
      "institution": "Mongol-AI (inferred from email domain)",
      "link": "https://arxiv.org/pdf/2512.22293",
      "code": null,
      "tags": [
        "language model safety",
        "sparse autoencoder",
        "feature orthogonalization",
        "stealth slip",
        "pragmatic interpretation",
        "statistical co-occurrence"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fddb803a434c3d49e04dd722184b33f238c4b81254540d6bb0d1961a3d09e1_w640_q70.webp",
      "contributions": "1. Empirically demonstrates that warning-framed training data fails to teach language models to avoid warned-against behaviors, showing generation rates similar to direct exposure. 2. Provides a mechanistic interpretation using sparse autoencoders, identifying a failure of feature orthogonalization where \"describing\" and \"performing\" an action activate overlapping latent features. 3. Identifies and names the \"stealth slip\" phenomenon, where conversational preambles can rotate activations into subspaces undetectable by linear probes, and shows that training-time feature ablation, not prompting, is required to address the issue.",
      "summary": "This paper investigates why language models trained on warning-framed examples (e.g., \"DO NOT USE\") still learn to generate the warned-against content. Through behavioral experiments and sparse autoencoder analysis, it finds that models learn statistical co-occurrences rather than pragmatic intent, due to overlapping latent features for description and action. The core conclusion is that current architectures prioritize pattern completion over understanding speaker intent, requiring training-time interventions like feature ablation for correction.",
      "mindmap": "graph TB\n        Root(”Learning from Negative Examples: Why Warning-Framed Training Data Teaches What It Warns Against”) --> Problem(”核心问题/Problem: Do warning-framed examples teach models to avoid bad behavior?”)\n        Root --> Method(”主要方法/Method: Behavioral analysis & Sparse Autoencoder mechanistic interpretability”)\n        Root --> Results(”关键结果/Results: No. Models learn statistical co-occurrence, not pragmatic intent.”)"
    },
    {
      "title": "A Statistical Side-Channel Risk Model for Timing Variability in Lattice-Based Post-Quantum Cryptography",
      "authors": "Aayush Mainali, Sirjan Ghimire",
      "institution": "Amrita Vishwa Vidyapeetham (Amrita School of Computing, Bengaluru)",
      "link": "https://arxiv.org/pdf/2512.22301",
      "code": null,
      "tags": [
        "side-channel analysis",
        "timing side-channel",
        "post-quantum cryptography",
        "statistical distinguishability",
        "leakage modeling",
        "TLRI risk score"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49d5ecfc4cfe65ff274ea29a13c0adef37a682fd3b6e2173f7c594c08b22fb00_w640_q70.webp",
      "contributions": "1. Proposes a scenario-based statistical risk model for timing leakage in lattice-based PQC, framing it as a problem of distributional distinguishability under controlled execution conditions (idle, jitter, loaded). 2. Synthesizes traces for multiple leakage models and quantifies leakage using a combination of statistical tests (Welch's t-test, KS distance, Cliff's delta, mutual information, distribution overlap) combined in a TLRI-like manner to produce a consistent risk score. 3. Empirically analyzes and compares the timing side-channel risk across representative lattice-based KEM families (Kyber, Saber, Frodo), identifying that idle conditions yield the highest distinguishability and that cache-index/branch-style leaks pose the highest risk.",
      "summary": "This paper proposes a statistical risk model to assess timing side-channel vulnerabilities in lattice-based post-quantum cryptographic implementations under different environmental noise scenarios. The method synthesizes execution traces and quantifies leakage using multiple statistical metrics combined into a single risk score for scenario ranking. The analysis shows that idle execution conditions are most vulnerable, and faster schemes like Kyber can exhibit higher peak risk, enabling early-stage, reproducible comparisons before hardware-specific testing.",
      "mindmap": "graph TB\n        Root[”A Statistical Side-Channel Risk Model for Timing Variability in Lattice-Based PQC<br>基于统计的时序侧信道风险模型用于后量子密码学”] --> Problem\n        Root --> Method\n        Root --> Results\n    \n        Problem[”核心问题/Problem<br>Lattice-based PQC implementations have secret-dependent timing variability, and real measurements are noisy.<br>基于格的PQC实现存在秘密相关的时序可变性，且真实测量受环境噪声影响。”]\n        Method[”主要方法/Method<br>Scenario-based statistical risk model. Synthesize traces, use multiple metrics (t-test, KS, MI, etc.), combine into TLRI-like score.<br>基于场景的统计风险模型。合成迹线，使用多种度量指标，组合成类TLRI风险分数。”]\n        Results[”关键结果/Results<br>Idle conditions have best distinguishability. Cache/branch leaks are highest risk. Faster schemes can have higher peak risk.<br>空闲条件下可区分性最佳。缓存/分支泄露风险最高。更快的方案可能具有更高的峰值风险。”]"
    },
    {
      "title": "Beyond Single Bugs: Benchmarking Large Language Models for Multi-Vulnerability Detection",
      "authors": "Chinmay Pushkar, Sanchit Kabra, Dhruv Kumar, Jagat Sesh Challa",
      "institution": "BITS Pilani, Virginia Tech",
      "link": "https://arxiv.org/pdf/2512.22306",
      "code": null,
      "tags": [
        "vulnerability detection",
        "multi-vulnerability detection",
        "count bias",
        "selection bias",
        "long-context code",
        "CWE injection"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd6a5fa286f161d0dab7d6a06a8f54502b88fd2f448edc9ed3609a31efaf97f5_w640_q70.webp",
      "contributions": "1. Introduced a comprehensive benchmark for Multi-Vulnerability Detection across four programming languages (C, C++, Python, JavaScript) to address the limitations of existing single-vulnerability benchmarks. 2. Constructed a novel dataset of 40,000 files by systematically injecting controlled counts of vulnerabilities (1, 3, 5, 9) into long-context code samples, enabling the study of performance under varying vulnerability densities. 3. Quantified the performance degradation of state-of-the-art LLMs (e.g., GPT-4o-mini, Llama-3.3-70B) in high-density vulnerability settings, revealing distinct failure modes like severe \"under-counting\" in Python and JavaScript.",
      "summary": "This paper addresses the gap in evaluating LLMs for detecting multiple vulnerabilities in large, real-world code files. The authors propose a new benchmark by creating a dataset of long code files with systematically injected vulnerabilities and evaluate several LLMs. The main finding is that LLM performance sharply degrades as the number of vulnerabilities per file increases, with significant drops in recall for languages like Python.",
      "mindmap": "graph TB\n        A[Beyond Single Bugs: Benchmarking LLMs for Multi-Vulnerability Detection] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Existing benchmarks are simplistic, focusing on single bugs, not reflecting real-world multi-vulnerability files.]\n        C[主要方法/Method<br>Build a new benchmark with 40k files across 4 languages, injecting controlled vulnerability counts into long code.]\n        D[关键结果/Results<br>LLM performance degrades sharply with more vulnerabilities; distinct failure modes in Python/JS vs. C/C++.]"
    },
    {
      "title": "LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators",
      "authors": "You Li, Guannan Zhao, Yuhao Ju, Yunqi He, Jie Gu, Hai Zhou",
      "institution": "Northwestern University",
      "link": "https://arxiv.org/pdf/2512.22307",
      "code": null,
      "tags": [
        "hardware security",
        "model protection",
        "logic locking",
        "intellectual property protection",
        "hardware accelerator",
        "model theft",
        "supply chain security"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp",
      "contributions": "1. Proposes LLA, a hardware-software co-design scheme for protecting generative AI models by embedding key bits into neurons and using invariance transformations to obscure them. 2. Integrates a lightweight, dataflow-compatible locking module into the AI accelerator, using the accelerator with a secret key as a license for model access. 3. Demonstrates that the approach is resilient against oracle-guided key optimization attacks while adding minimal computational overhead (&lt;0.1% for 7,168 key bits).",
      "summary": "The paper introduces LLA, a method to protect generative AI models from supply chain threats like theft and corruption by combining software-based key embedding in neurons with a hardware locking module in the accelerator. This approach uses the accelerator as a license key, ensuring only authorized hardware can run the model correctly. Evaluation shows it effectively resists attacks with negligible performance overhead.",
      "mindmap": "graph TB\n        Root[LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators] --> Problem(核心问题/Problem: Model IP Protection & Supply Chain Threats)\n        Root --> Method(主要方法/Method: Hardware-Software Co-design with Logic Locking)\n        Root --> Results(关键结果/Results: Resists Attacks, <0.1% Overhead)\n        Problem --> P1(模型盗窃/Model Theft)\n        Problem --> P2(模型破坏/Model Corruption)\n        Problem --> P3(信息泄露/Information Leakage)\n        Method --> M1(软件侧: 神经元嵌入密钥/Software: Key Embedding in Neurons)\n        Method --> M2(硬件侧: 轻量级锁定模块/Hardware: Lightweight Locking Module)\n        Results --> R1(抵御优化攻击/Withstands Oracle-Guided Attacks)\n        Results --> R2(低计算开销/Low Computational Overhead)"
    },
    {
      "title": "NOWA: Null-space Optical Watermark for Invisible Capture Fingerprinting and Tamper Localization",
      "authors": "Edwin Vargas",
      "institution": "Rice University, Universidad Industrial de Santander",
      "link": "https://arxiv.org/pdf/2512.22501",
      "code": null,
      "tags": [
        "digital watermarking",
        "optical watermarking",
        "null-space watermark",
        "tamper localization",
        "phase mask",
        "Null-Space Network"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae6666e8baf82000692a95ce2ef303fcc0c463c0552bda78000f2c121ebe772e_w640_q70.webp",
      "contributions": "1. Proposes a hybrid optical-digital framework (NOWA) that embeds an invisible watermark during image capture via a phase mask in the camera's null space. 2. Introduces a Null-Space Network (NSN) for measurement-consistent reconstruction that preserves the watermark while delivering high-quality images. 3. Enables precise tamper localization by detecting pixel-level inconsistencies through null-space projection, establishing a structural security asymmetry against forgery.",
      "summary": "The paper addresses the vulnerability of digital watermarks to attacks by proposing NOWA, a hybrid system that embeds an invisible optical watermark during image capture using a phase mask and reconstructs the image with a learned network to preserve it. This method allows for accurate tamper localization and resists common degradations like compression, providing a hardware-level security advantage that is difficult to forge without access to the specific optical and network parameters.",
      "mindmap": "graph TB\n        Root[NOWA: Null-space Optical Watermark] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Digital watermarks are vulnerable to attacks] --> P1[挑战/Challenge: Ensuring image authenticity]\n        Method[主要方法/Method: Hybrid optical-digital framework] --> M1[光学层面/Optical: Phase mask creates null-space watermark]\n        Method --> M2[数字层面/Digital: Null-Space Network for reconstruction]\n        Results[关键结果/Results] --> R1[性能/Performance: High image quality & tamper localization]\n        Results --> R2[安全性/Security: Structural asymmetry prevents forgery]"
    },
    {
      "title": "Verifiable Dropout: Turning Randomness into a Verifiable Claim",
      "authors": "Kichang Lee, Sungmin Lee, Jaeho Jin, JeongGil Ko",
      "institution": "Yonsei University",
      "link": "https://arxiv.org/pdf/2512.22526",
      "code": null,
      "tags": [
        "others",
        "verifiable dropout",
        "zero-knowledge proofs",
        "stochastic training",
        "cloud training accountability",
        "privacy-preserving verification"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0082678600127810e766281f97240dd59255c617276adff01d3cc8157b30c0f0_w640_q70.webp",
      "contributions": "1. Introduces the concept of \"Verifiable Dropout,\" a novel mechanism that treats stochasticity in training as a verifiable claim rather than a source of ambiguity. 2. Proposes a privacy-preserving method using zero-knowledge proofs to bind dropout masks to a deterministic, cryptographically verifiable seed, enabling post-hoc integrity audits. 3. Addresses the \"plausible deniability\" gap in cloud-based AI training by allowing verification that stochastic operations were executed honestly without exposing sensitive model or data information.",
      "summary": "The paper identifies a security gap in cloud-based AI training where stochastic operations like dropout allow attackers to mask manipulations as random variance. To solve this, it proposes Verifiable Dropout, a method using zero-knowledge proofs to cryptographically verify the correct execution of dropout, ensuring integrity while preserving privacy. This enables post-hoc audits to confirm randomness was not biased, closing the accountability loophole in stochastic training.",
      "mindmap": "graph TB\n        A[Verifiable Dropout: Turning Randomness into a Verifiable Claim] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Cloud training logs fail to verify honest execution of stochastic operations (e.g., dropout), creating a ”plausible deniability” gap for attackers.]\n        C[主要方法/Method<br>Proposes Verifiable Dropout using zero-knowledge proofs to bind dropout masks to a verifiable seed, proving correct execution.]\n        D[关键结果/Results<br>Enables privacy-preserving, post-hoc integrity audits of stochastic training steps, ensuring randomness was not biased or manipulated.]"
    },
    {
      "title": "Raven: Mining Defensive Patterns in Ethereum via Semantic Transaction Revert Invariants Categories",
      "authors": "Mojtaba Eshghie, Melissa Mazura, Alexandre Bartel",
      "institution": "Umeå University, KTH Royal Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.22616",
      "code": null,
      "tags": [
        "smart contract security",
        "transaction revert",
        "invariant mining",
        "semantic clustering",
        "BERT",
        "fuzzing oracle"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21def4401bf4eec329b37e2bead75f15935fd47b2aa5b0fdd0f0f2d34710eb06_w640_q70.webp",
      "contributions": "1. Proposes a novel framework (RAVEN) that mines defensive patterns from Ethereum's reverted transactions by aligning them to source code invariants and clustering them semantically., 2. Discovers six new, previously undocumented categories of defensive invariants (e.g., feature toggles, replay prevention) through expert review of the mined clusters., 3. Demonstrates the practical utility of the mined invariant catalog by using a discovered category as a fuzzing oracle to detect vulnerabilities in a real-world attack case study.",
      "summary": "The paper addresses the underutilization of reverted Ethereum transactions as signals of successful on-chain defenses. It introduces RAVEN, a framework that semantically clusters the invariants causing transaction reverts using a fine-tuned BERT model. The approach successfully mines new defensive invariant categories, which can be used to build data-driven security analysis tools like fuzzing oracles.",
      "mindmap": "graph TB\n        Root(RAVEN: Mining Defensive Patterns in Ethereum) --> Problem(核心问题/Problem)\n        Root --> Method(主要方法/Method)\n        Root --> Results(关键结果/Results)\n        Problem --> P1(未充分利用的防御信号/Underutilized Defensive Signal)\n        P1 --> P2(回滚交易中的模式未发现/Patterns in Reverted Transactions Undiscovered)\n        Method --> M1(对齐与嵌入/Alignment & Embedding)\n        M1 --> M2(基于BERT的语义聚类/BERT-based Semantic Clustering)\n        Results --> R1(发现19个语义集群/19 Semantic Clusters Discovered)\n        R1 --> R2(识别6个新不变式类别/6 New Invariant Categories Identified)\n        R2 --> R3(作为模糊测试预言机的案例研究/Case Study as Fuzzing Oracle)"
    },
    {
      "title": "SCyTAG: Scalable Cyber-Twin for Threat-Assessment Based on Attack Graphs",
      "authors": "David Tayouri, Elad Duani, Abed Showgan, Ofir Manor, Ortal Lavi, Igor Podoski, Miro Ohana, Yuval Elovici, Andres Murillo, Asaf Shabtai, Rami Puzis",
      "institution": "Ben-Gurion University of the Negev, Fujitsu Research Europe, Fujitsu Technology Solutions",
      "link": "https://arxiv.org/pdf/2512.22669",
      "code": null,
      "tags": [
        "threat assessment",
        "cyber twin",
        "attack graph",
        "threat emulation",
        "scalability",
        "cyber threat intelligence"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec5ac37b7ca1ba4ebe171d8048cb05279ccfadd515f5bc3dee92b6c9be5fd4a0_w640_q70.webp",
      "contributions": "1. Proposes SCyTAG, a multi-step framework for generating a minimal viable cyber twin for attack scenario assessment. 2. Automates the construction of a cyber twin based on an attack graph derived from network specs and a CTI report. 3. Demonstrates significant resource reduction (up to 85% fewer components, half the resources) while preserving attack emulation fidelity.",
      "summary": "The paper addresses the scalability problem of using cyber twins for threat assessment in enterprise networks. It proposes SCyTAG, a framework that automatically generates a minimal cyber twin based on an attack graph to emulate specific attack scenarios from CTI reports. The evaluation shows SCyTAG drastically reduces the required emulation resources while maintaining accuracy, offering a scalable and cost-effective solution.",
      "mindmap": "graph TB\n        Root[SCyTAG: Scalable Cyber-Twin for Threat-Assessment] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[Cyber twins难以扩展/Cyber twins lack scalability]\n        Method --> M1[生成攻击图/Generate Attack Graph]\n        Method --> M2[构建最小可行网络孪生/Build Minimal Viable Cyber Twin]\n        Results --> R1[组件减少高达85%/Components reduced by up to 85%]\n        Results --> R2[资源减半/Resources halved]\n        Results --> R3[保持攻击仿真保真度/Preserves attack emulation fidelity]"
    },
    {
      "title": "When RSA Fails: Exploiting Prime Selection Vulnerabilities in Public Key Cryptography",
      "authors": "Murtaza Nikzad, Kerem Atas",
      "institution": "Davidson College",
      "link": "https://arxiv.org/pdf/2512.22720",
      "code": null,
      "tags": [
        "cryptography",
        "RSA",
        "prime selection",
        "Fermat factorization",
        "GCD attack",
        "random number generation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01c26b183514e853f6971e7477e3cf770aff9bb9bdc49986bb22b84d77365990_w640_q70.webp",
      "contributions": "1. Analysis of prime selection vulnerabilities in RSA, specifically the Close Prime and Shared Prime vulnerabilities. 2. Demonstration of the real-world prevalence of these vulnerabilities by referencing landmark and recent studies (e.g., Heninger et al., Böck 2023). 3. Identification of weak random number generation in embedded devices as the primary cause and discussion of mitigation strategies like proper entropy collection.",
      "summary": "This paper investigates vulnerabilities in RSA cryptosystems caused by improper prime number selection during key generation, focusing on Fermat's factorization method for close primes and the GCD attack for shared primes. It demonstrates that these vulnerabilities are prevalent in real-world implementations, primarily due to weak random number generation in embedded devices. The paper concludes by discussing mitigation strategies, emphasizing the critical need for proper entropy collection and prime validation checks.",
      "mindmap": "graph TB\n        A[When RSA Fails: Exploiting Prime Selection Vulnerabilities<br>RSA失败：利用公钥密码学中的素数选择漏洞] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Improper prime selection in RSA key generation<br>RSA密钥生成中的不当素数选择]\n        C --> C1[Analyze Fermat factorization & GCD attacks<br>分析费马分解与GCD攻击]\n        C --> C2[Review real-world studies (e.g., Heninger et al., Böck)<br>回顾现实世界研究]\n        D --> D1[Vulnerabilities remain prevalent<br>漏洞仍然普遍存在]\n        D --> D2[Weak RNG in embedded devices is primary cause<br>嵌入式设备中的弱随机数生成是主因]\n        D --> D3[Discuss mitigation strategies (entropy, validation)<br>讨论缓解策略（熵收集，验证）]"
    },
    {
      "title": "A generalized motif-based Naïve Bayes model for sign prediction in complex networks",
      "authors": "Yijun Ran, Si-Yuan Liu, Junjie Huang, Tao Jia, Xiao-Ke Xu",
      "institution": "Guizhou Normal University, Beijing Normal University Zhuhai, Southwest University, Chongqing Normal University",
      "link": "https://arxiv.org/pdf/2512.22765",
      "code": null,
      "tags": [
        "network science",
        "link prediction",
        "signed networks",
        "sign prediction",
        "motif-based Naïve Bayes",
        "heterogeneous influence",
        "feature-driven model"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6763274252bfc8c0b048ebb576b9629c3b09537a9f4eddc189476ae192f701bb_w640_q70.webp",
      "contributions": "1. Proposed a generalizable sign prediction framework that models the heterogeneous influence of neighboring nodes using designed role functions. 2. Extended the framework from single to multiple motifs via two strategies: a linear combination model and a feature-driven machine learning model (FGMNB). 3. Demonstrated through experiments that FGMNB outperforms state-of-the-art embedding-based baselines and identified that predictive motif structures vary across datasets.",
      "summary": "This paper addresses the problem of sign prediction in signed networks by proposing a generalized motif-based Naïve Bayes model that accounts for the heterogeneous influence of neighboring nodes. The key innovation is the Feature-driven Generalized Motif-based Naïve Bayes (FGMNB) model, which integrates high-dimensional motif features using machine learning. Experiments on real-world networks show that FGMNB outperforms several embedding-based baselines, highlighting the importance of dataset-specific local structural patterns for prediction.",
      "mindmap": "graph TB\n        A[论文标题: A generalized motif-based Naïve Bayes model for sign prediction in complex networks] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: 传统模型忽略邻居节点的异质性影响/Traditional models overlook heterogeneous influence of neighbors]\n        C[主要方法/Method: 提出FGMNB模型，使用角色函数和机器学习整合多模体特征/Propose FGMNB model, using role functions and ML to integrate multi-motif features]\n        D[关键结果/Results: FGMNB优于基线，关键模体结构因数据集而异/FGMNB outperforms baselines, key motif structures vary by dataset]"
    },
    {
      "title": "Identifying social bots via heterogeneous motifs based on Naïve Bayes model",
      "authors": "Yijun Ran, Jingjing Xiao, Xiao-Ke Xu",
      "institution": "Guizhou University, Beijing Normal University, Dalian Minzu University",
      "link": "https://arxiv.org/pdf/2512.22759",
      "code": null,
      "tags": [
        "social bot detection",
        "heterogeneous motifs",
        "Naïve Bayes model",
        "maximum capability"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb36358979a0b66f0c0d952f628d15412b4ad6b609d8f895096dd7ac8efbe40_w640_q70.webp",
      "contributions": "1. Proposed a theoretical framework that refines homogeneous motifs into heterogeneous ones by incorporating node-label information to capture neighborhood preference heterogeneity. 2. Systematically evaluated the contribution of different node pairs within heterogeneous motifs to the likelihood of a node being a social bot. 3. Mathematically quantified the maximum capability of each heterogeneous motif to estimate its potential benefits, showing that selecting high-capability motifs yields performance comparable to using all motifs.",
      "summary": "This paper proposes a new method for detecting social bots by using heterogeneous motifs within a Naïve Bayes model framework. It captures the heterogeneity of node neighborhoods and mathematically evaluates the detection capability of different motifs. The method outperforms state-of-the-art techniques on several benchmarks, and selecting only the highest-capability motifs achieves similar performance to using all motifs.",
      "mindmap": "graph TB\n        A[Identifying social bots via heterogeneous motifs based on Naïve Bayes model<br>基于朴素贝叶斯模型的异质模体社交机器人检测] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[拓扑方法忽视邻居偏好异质性<br>Topology methods ignore neighborhood preference heterogeneity]\n        B --> B2[缺乏系统理论基础<br>Lack of systematic theoretical foundation]\n        C --> C1[将同质模体细化为异质模体<br>Refine homogeneous motifs into heterogeneous motifs]\n        C --> C2[基于朴素贝叶斯模型评估贡献<br>Evaluate contributions using Naïve Bayes model]\n        C --> C3[量化模体的最大能力<br>Quantify maximum capability of motifs]\n        D --> D1[在四个基准上超越SOTA<br>Outperforms SOTA on four benchmarks]\n        D --> D2[选择高能力模体性能相当<br>Selecting high-capability motifs yields comparable performance]"
    },
    {
      "title": "Breaking the illusion: Automated Reasoning of GDPR Consent Violations",
      "authors": "Ying Li, Wenjun Qiu, Faysal Hossain Shezan, Kunlin Cai, Michelangelo van Dam, Lisa Austin, David Lie, Yuan Tian",
      "institution": "University of California, Los Angeles, University of Toronto, University of Texas at Arlington, in2it",
      "link": "https://arxiv.org/pdf/2512.22789",
      "code": null,
      "tags": [
        "privacy compliance",
        "automated auditing",
        "web forms",
        "GDPR",
        "Datalog",
        "large language model"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd68f5183b431442e1fe836b2b579a11383989f81394c35468b7402eac13d870_w640_q70.webp",
      "contributions": "1. An LLM-based framework to extract consent requirements from privacy policies and locate relevant forms using multimodal web agents. 2. A domain-specific language (DSL) to formally describe heterogeneous web form structures for systematic analysis. 3. Machine-interpretable Datalog rules, derived with privacy experts, to translate GDPR requirements into formal logic for automated verification.",
      "summary": "This paper introduces Cosmic, an automated framework for detecting GDPR consent violations in web forms. It uses LLMs, a custom DSL, and Datalog rules to audit forms, finding widespread violations (3,384 on 94.1% of forms) with high accuracy (TPR &gt;98.6%), demonstrating a significant gap between legal requirements and implementation.",
      "mindmap": "graph TB\n        A[Breaking the Illusion: Automated Reasoning of GDPR Consent Violations] --> B[核心问题/Problem: Gap between GDPR consent requirements and implementation in web forms]\n        A --> C[主要方法/Method: Cosmic framework using LLMs, DSL, and Datalog rules]\n        A --> D[关键结果/Results: Detects 3,384 violations on 94.1% of forms with high accuracy]"
    },
    {
      "title": "Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks",
      "authors": "Soham Padia, Dhananjay Vaidya, Ramchandra Mangrulkar",
      "institution": "Northeastern University, Dwarkadas J. Sanghvi College of Engineering",
      "link": "https://arxiv.org/pdf/2512.22860",
      "code": null,
      "tags": [
        "blockchain security",
        "IoT security",
        "adversarial machine learning",
        "Fully Homomorphic Encryption",
        "Attribute-Based Access Control",
        "Multi-Agent Reinforcement Learning",
        "Byzantine Fault Tolerance",
        "Trust-Based Consensus"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373f990d6c218afb4f9e660bb84fd86dc8e9d7006d2b7bdef3d956a991960bff_w640_q70.webp",
      "contributions": "1. Proposes a novel trust-based delegated consensus framework for blockchain IoT that integrates Fully Homomorphic Encryption (FHE) with Attribute-Based Access Control (ABAC) for privacy-preserving policy evaluation. 2. Systematically compares the performance of three reinforcement learning approaches (RL, DRL, MARL) against five distinct and sophisticated adversarial attack families. 3. Empirically demonstrates that Multi-Agent RL (MARL) provides superior defense against collusive attacks and identifies the catastrophic vulnerability of all learning agents to Time-Delayed Poisoning (sleeper) attacks.",
      "summary": "This paper addresses securing blockchain-enabled IoT networks by proposing a trust-based consensus framework that combines privacy-preserving techniques (FHE and ABAC) with learning-based defenses. It compares RL, DRL, and MARL against five attack types, finding MARL most effective against collusive attacks but revealing that all methods are highly vulnerable to time-delayed poisoning attacks.",
      "mindmap": "graph TB\n        Root[”Adaptive Trust Consensus for Blockchain IoT<br/>区块链物联网自适应信任共识”] --> Problem\n        Root --> Method\n        Root --> Results\n    \n        Problem[”Securing Blockchain IoT Against Attacks<br/>保护区块链物联网免受攻击”] --> A1[”Naive Malicious Attack (NMA)<br/>简单恶意攻击”]\n        Problem --> A2[”Collusive Rumor Attack (CRA)<br/>合谋谣言攻击”]\n        Problem --> A3[”Adaptive Adversarial Attack (AAA)<br/>自适应对抗攻击”]\n        Problem --> A4[”Byzantine Fault Injection (BFI)<br/>拜占庭故障注入”]\n        Problem --> A5[”Time-Delayed Poisoning (TDP)<br/>时间延迟投毒”]\n    \n        Method[”Trust Framework with FHE & ABAC + Learning Defenses<br/>基于FHE和ABAC的信任框架与学习防御”] --> M1[”Reinforcement Learning (RL)<br/>强化学习”]\n        Method --> M2[”Deep RL (DRL)<br/>深度强化学习”]\n        Method --> M3[”Multi-Agent RL (MARL)<br/>多智能体强化学习”]\n    \n        Results[”Key Experimental Findings<br/>关键实验结果”] --> R1[”MARL best vs. Collusive Attacks<br/>MARL对合谋攻击最佳”]\n        Results --> R2[”DRL & MARL perfect vs. Adaptive Attacks<br/>DRL和MARL完美防御自适应攻击”]\n        Results --> R3[”All agents fail vs. Time-Delayed Poisoning<br/>所有智能体在延迟投毒攻击下失效”]"
    },
    {
      "title": "Agentic AI for Cyber Resilience: A New Security Paradigm and Its System-Theoretic Foundations",
      "authors": "Tao Li, Quanyan Zhu",
      "institution": "City University of Hong Kong, New York University",
      "link": "https://arxiv.org/pdf/2512.22883",
      "code": null,
      "tags": [
        "cyber resilience",
        "agentic AI",
        "game theory",
        "autonomous agents",
        "system-theoretic framework",
        "equilibrium-based design"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1d5f82743a059040190978c2a78338bb73c72bc9cec9a0aafe00a0d12f0f24d_w640_q70.webp",
      "contributions": "1. Proposes a paradigm shift from prevention-centric security to agentic cyber resilience, arguing for systems that anticipate, maintain, recover, and learn under attack. 2. Develops a system-level framework and general architecture for designing AI workflows where autonomous agents participate in sensing, reasoning, and action. 3. Demonstrates how game-theoretic formulations provide a unifying design language for analyzing coupled attacker-defender workflows and enable equilibrium-based resiliency design, illustrated with case studies.",
      "summary": "This paper argues that the rise of foundation-model-based AI necessitates a shift from traditional prevention-focused cybersecurity to a new paradigm of agentic cyber resilience. It proposes a system-theoretic framework for designing autonomous AI workflows and uses game theory as a unifying language to model attacker-defender dynamics, concluding that equilibrium-based design enables system-level resilience as demonstrated in case studies like automated penetration testing.",
      "mindmap": "graph TB\n        Root(”Agentic AI for Cyber Resilience: A New Security Paradigm and Its System-Theoretic Foundations”) --> Problem(”核心问题/Problem: Traditional static, human-centered security architectures are mismatched with AI-driven, adaptive cyber threats.”)\n        Root --> Method(”主要方法/Method: Proposes a shift to agentic cyber resilience and a system-level framework using game theory to design autonomous AI workflows.”)\n        Root --> Results(”关键结果/Results: Equilibrium-based design enables system-level resiliency, illustrated through case studies in automated pentesting and cyber deception.”)"
    },
    {
      "title": "DECEPTICON: How Dark Patterns Manipulate Web Agents",
      "authors": "Phil Cuvin, Hao Zhu, Diyi Yang",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2512.22894",
      "code": "https://agentdarkpatterns.org",
      "tags": [
        "agent system",
        "dark patterns",
        "web agents",
        "adversarial robustness",
        "deceptive UI",
        "agent testing"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8998ab43971416f683709173f00be5e8d5373de89f15ac199ec42d645a75b8b6_w640_q70.webp",
      "contributions": "1. Introduces DECEPTICON, a novel environment for testing dark patterns in isolation with 700 web navigation tasks, 2. Demonstrates that dark patterns successfully manipulate agent trajectories in over 70% of tasks, significantly higher than human susceptibility, 3. Shows that larger, more capable models are more susceptible to dark patterns, and existing countermeasures like in-context prompting and guardrail models fail to mitigate the risk effectively.",
      "summary": "This paper introduces DECEPTICON, a testing environment to evaluate how dark patterns manipulate web agents, revealing that these deceptive UI designs successfully steer agent actions in over 70% of tasks, with larger models being more vulnerable and current defenses ineffective. The findings highlight an urgent need for robust defenses against such manipulative designs in agent systems.",
      "mindmap": "graph TB\n        A[DECEPTICON: How Dark Patterns Manipulate Web Agents] --> B[核心问题/Problem: Dark patterns manipulate users and pose risks to agent robustness]\n        A --> C[主要方法/Method: DECEPTICON environment with 700 tasks to test dark patterns in isolation]\n        A --> D[关键结果/Results: Dark patterns steer agents in >70% tasks, larger models more susceptible, defenses fail]"
    },
    {
      "title": "SecureBank: A Financially-Aware Zero Trust Architecture for High-Assurance Banking Systems",
      "authors": "Paulo Fernandes Biao",
      "institution": "Biaotech.dev",
      "link": "https://arxiv.org/pdf/2512.23124",
      "code": null,
      "tags": [
        "Zero Trust Architecture",
        "Zero Trust",
        "Micro-Segmentation",
        "Adaptive Identity",
        "Security Automation",
        "Financial Risk Modeling"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcead853a793849eb23351043665ca37b119208adc01fb0dece96fde5c56ad05_w640_q70.webp",
      "contributions": "1. Proposes SecureBank, a financially-aware and context-adaptive Zero Trust architecture specifically for high-assurance banking systems. 2. Integrates novel components like Financial Zero Trust, Adaptive Identity Scoring, Contextual Micro-Segmentation, and Impact-Driven Security Automation. 3. Provides experimental validation through Monte Carlo simulation using new metrics (TII, ITAL, SAE), showing improved attack handling and trust adaptation.",
      "summary": "This paper introduces SecureBank, a Zero Trust architecture designed for banking systems that incorporates financial risk and context. It integrates components like adaptive identity scoring and impact-driven automation. Simulation results show it improves automated attack handling and identity trust adaptation while maintaining transactional integrity.",
      "mindmap": "graph TB\n        Root[SecureBank: A Financially-Aware Zero Trust Architecture] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[传统安全模型不足/Limitations of Traditional Security]\n        Problem --> P2[现有零信任缺乏金融语义/Existing ZT Lacks Financial Awareness]\n        Method[主要方法/Method] --> M1[金融零信任/Financial Zero Trust]\n        Method --> M2[自适应身份评分/Adaptive Identity Scoring]\n        Method --> M3[上下文微隔离/Contextual Micro-Segmentation]\n        Method --> M4[影响驱动自动化/Impact-Driven Automation]\n        Results[关键结果/Results] --> R1[提升攻击自动化处理/Improved Automated Attack Handling]\n        Results --> R2[加速身份信任适应/Accelerated Identity Trust Adaptation]\n        Results --> R3[保持交易完整性/Preserved Transactional Integrity]"
    },
    {
      "title": "Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems",
      "authors": "Armstrong Foundjem, Lionel Nganyewou Tidjon, Leuson Da Silva, Foutse Khomh",
      "institution": "Polytechnique Montréal (based on author affiliations and sMIEEE notation)",
      "link": "https://arxiv.org/pdf/2512.23132",
      "code": null,
      "tags": [
        "machine learning security",
        "TTPs",
        "threat graph",
        "multi-agent RAG",
        "model stealing",
        "jailbreaking"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3da226bc9e7639392b95f6f00808f162580d1a90050c1261b3a0703259e42cf_w640_q70.webp",
      "contributions": "1. Conducted a large-scale empirical analysis of ML security, extracting 93 distinct threats from multiple sources including real-world incidents and code repositories. 2. Developed a multi-agent RAG system to automatically build an ontology-driven threat graph linking TTPs, vulnerabilities, and lifecycle stages from over 300 articles. 3. Identified unreported threats and dominant attack patterns (e.g., commercial LLM API model stealing, preference-guided jailbreaks) and highlighted vulnerability clusters in ML libraries with poor patch propagation.",
      "summary": "This paper characterizes modern security risks in AI systems by analyzing threats from multiple sources and using a multi-agent RAG system to construct a threat graph. The analysis uncovers unreported attack vectors and dominant TTPs, concluding that adaptive, ML-specific security frameworks are urgently needed to mitigate supply-chain and inference-time risks.",
      "mindmap": "graph TB\n    A[Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[传统安全框架缺乏针对ML的威胁建模/Traditional cybersecurity lacks ML-specific threat modeling]\n    C --> C1[多智能体RAG系统分析威胁/Multi-agent RAG system analyzes threats]\n    C1 --> C2[构建本体驱动的威胁图谱/Builds ontology-driven threat graph]\n    D --> D1[识别未报告的威胁/Identifies unreported threats]\n    D --> D2[发现主要的攻击TTPs/Identifies dominant attack TTPs]\n    D --> D3[强调自适应ML安全框架的必要性/Highlights need for adaptive ML security frameworks]"
    },
    {
      "title": "Certifying the Right to Be Forgotten: Primal-Dual Optimization for Sample and Label Unlearning in Vertical Federated Learning",
      "authors": "Yu Jiang, Xindi Tong, Ziyao Liu, Xiaoxi Zhang, Kwok-Yan Lam, Chee Wei Tan",
      "institution": "Nanyang Technological University, Sun Yat-sen University",
      "link": "https://arxiv.org/pdf/2512.23171",
      "code": null,
      "tags": [
        "federated learning",
        "vertical federated learning",
        "machine unlearning",
        "primal-dual optimization",
        "sample unlearning",
        "label unlearning"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05dcd254c3941fc5cbf6bc3c063f2a726b8607659a3f7b4a526ad900e9e2b5de_w640_q70.webp",
      "contributions": "1. Proposes FedORA, a primal-dual optimization framework for sample and label unlearning in Vertical Federated Learning (VFL). 2. Introduces a new unlearning loss function that promotes classification uncertainty instead of misclassification. 3. Employs an adaptive step size and an asymmetric batch design to enhance stability and reduce computational costs.",
      "summary": "This paper addresses the challenge of data removal (unlearning) in Vertical Federated Learning (VFL), where different parties hold different features of the same data samples. The authors propose FedORA, a method that formulates unlearning as a constrained optimization problem solved via a primal-dual algorithm. Experiments show FedORA achieves unlearning effectiveness and model utility comparable to retraining from scratch, but with lower computational and communication costs.",
      "mindmap": "graph TB\n        Root[”Certifying the Right to Be Forgotten: Primal-Dual Optimization for Sample and Label Unlearning in Vertical Federated Learning”]\n        Root --> Problem[”核心问题/Problem<br>Unlearning in VFL is challenging due to distributed features and cross-party coordination.”]\n        Root --> Method[”主要方法/Method<br>Propose FedORA: a primal-dual optimization framework with a new uncertainty-promoting loss.”]\n        Root --> Results[”关键结果/Results<br>Achieves effective unlearning & utility preservation with lower overhead vs. retraining.”]"
    },
    {
      "title": "EquaCode: A Multi-Strategy Jailbreak Approach for Large Language Models via Equation Solving and Code Completion",
      "authors": "Zhen Liang, Hai Huang, Zhengkui Chen",
      "institution": "Zhejiang Sci-Tech University",
      "link": "https://arxiv.org/pdf/2512.23173",
      "code": "https://github.com/lzzzr123/Equacode",
      "tags": [
        "adversarial attacks",
        "jailbreak attacks",
        "large language models",
        "adversarial prompting",
        "equation solving",
        "code completion"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3023ba644e0cdeddfd98604ca7c5871aceb213706aede21b77e0d35b95cf6d23_w640_q70.webp",
      "contributions": "1. Proposes a novel multi-strategy jailbreak approach that combines mathematical equation solving and code completion to bypass LLM safety constraints. 2. Demonstrates high attack success rates (e.g., 91.19% on GPT series) with only a single query, outperforming single-strategy attacks. 3. Shows through ablation studies a strong synergistic effect between the equation and code modules, proving the multi-strategy approach is more effective than the sum of its parts.",
      "summary": "This paper introduces EquaCode, a multi-strategy jailbreak attack that transforms malicious intent into a mathematical problem and forces the LLM to solve it via code, diverting its focus from safety. The method achieves high success rates on various LLMs with a single query, and ablation studies confirm the synergistic benefit of combining equation-solving and code completion strategies.",
      "mindmap": "graph TB\n        A[EquaCode: 多策略越狱方法 / Multi-Strategy Jailbreak Approach] --> B[核心问题: LLM安全性评估不足 / Problem: Insufficient LLM Safety Evaluation]\n        A --> C[主要方法: 方程求解与代码补全 / Method: Equation Solving & Code Completion]\n        A --> D[关键结果: 高成功率与协同效应 / Results: High Success Rate & Synergistic Effect]"
    },
    {
      "title": "Multiparty Authorization for Secure Data Storage in Cloud Environments using Improved Attribute-Based Encryption",
      "authors": "Partha Paul, Keshav Sinha",
      "institution": "Birla Institute of Technology, Mesra; UPES Dehradun",
      "link": "https://arxiv.org/pdf/2512.23216",
      "code": null,
      "tags": [
        "attribute-based encryption",
        "Attribute-Based Encryption (ABE)",
        "Functional-Based Stream Cipher (FBSC)",
        "Shamir Secret Sharing",
        "2D-Lagrange Interpolation",
        "Multiparty Authorization"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bb58ab759ba01f8553bf4c4b7944b13301c8c797fdfea762a267af289cc3fc8_w640_q70.webp",
      "contributions": "1. Proposed an improved ABE scheme using a Functional-Based Stream Cipher (FBSC) for secure data storage in the cloud. 2. Introduced a multiparty authorization mechanism using scalar points on a parabolic curve and Shamir secret sharing with 2D-Lagrange Interpolation for key reconstruction. 3. Demonstrated the scheme's robustness through security analysis (resisting collision attacks) and performance evaluation (minimal storage overhead, analyzed via NIST tests).",
      "summary": "This paper addresses secure data storage and access control in cloud environments by proposing an improved Attribute-Based Encryption (ABE) scheme combined with a Functional-Based Stream Cipher. The method enables multiparty authorization using parabolic curve points and secret sharing, requiring a threshold of users to reconstruct decryption keys. The analysis shows the scheme is robust, secure against collisions, and imposes minimal storage overhead.",
      "mindmap": "graph TB\n        A[Multiparty Authorization for Secure Data Storage in Cloud Environments using Improved Attribute-Based Encryption] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[云中安全存储与访问控制/Secure Cloud Storage & Access Control]\n        B --> B2[数据泄露与计算开销/Data Leakage & Computational Overhead]\n        C --> C1[改进的基于属性加密/Improved ABE]\n        C --> C2[基于功能的流密码/Functional-Based Stream Cipher]\n        C --> C3[多方授权与秘密共享/Multiparty Auth & Secret Sharing]\n        D --> D1[抵抗碰撞攻击/Resists Collision Attacks]\n        D --> D2[最小存储开销/Minimal Storage Overhead]\n        D --> D3[性能与安全分析/Performance & Security Analysis]"
    },
    {
      "title": "RobustMask: Certified Robustness against Adversarial Neural Ranking Attack via Randomized Masking",
      "authors": "Jiawei Liu, Zhuo Chen, Rui Zhu, Miaokun Chen, Yuyang Gong, Wei Lu, Xiaofeng Wang",
      "institution": "Wuhan University, Yale University, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.23307",
      "code": null,
      "tags": [
        "adversarial robustness",
        "randomized smoothing",
        "certified robustness",
        "neural ranking models",
        "adversarial attacks",
        "retrieval-augmented generation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92efd69f112646f719a80cc74cecc9d34018b0607ad1f827ed960e54e754af07_w640_q70.webp",
      "contributions": "1. Proposes RobustMask, a novel defense combining pretrained language models' context-prediction with a randomized masking-based smoothing mechanism to protect neural ranking models. 2. Provides a theoretical proof for RobustMask's certified top-K robustness against character-, word-, and phrase-level adversarial perturbations. 3. Demonstrates through extensive experiments that RobustMask can certify over 20% of candidate documents within the top-10 ranking against perturbations affecting up to 30% of content.",
      "summary": "This paper addresses the vulnerability of neural ranking models to adversarial attacks that manipulate retrieval results. It proposes RobustMask, a defense method that uses randomized masking and smoothing to provide certified robustness. The results show it can effectively certify a significant portion of top-ranking documents against substantial content perturbations.",
      "mindmap": "graph TB\n        A[RobustMask: Certified Robustness against Adversarial Neural Ranking Attack via Randomized Masking] --> B[核心问题/Problem: Neural ranking models are vulnerable to adversarial manipulations that poison retrieval results.]\n        A --> C[主要方法/Method: Combines PLM context-prediction with randomized masking-based smoothing.]\n        A --> D[关键结果/Results: Certifies >20% of top-10 docs against perturbations affecting up to 30% content.]"
    },
    {
      "title": "Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?",
      "authors": "Anh Nguyen, Triet Huynh Minh Le, M. Ali Babar",
      "institution": "University of Adelaide",
      "link": "https://arxiv.org/pdf/2512.23385",
      "code": null,
      "tags": [
        "AI Security",
        "AI supply chain",
        "security taxonomy",
        "distilBERT classifier"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp",
      "contributions": "1. Developed a pipeline combining keyword matching with a fine-tuned distilBERT classifier to identify 312,868 security discussions from Hugging Face and GitHub. 2. Conducted a thematic analysis to create a fine-grained taxonomy of 32 security issues and 24 solutions across four themes (System/Software, External Tools/Ecosystem, Model, Data). 3. Provided empirical insights revealing that security issues stem from complex dependencies and black-box AI components, with Model and Data challenges often lacking concrete solutions.",
      "summary": "This paper investigates security issues in the AI supply chain by analyzing developer discussions from Hugging Face and GitHub. The authors use a keyword and classifier pipeline to build a large dataset and perform a thematic analysis to create a taxonomy of issues and solutions. They conclude that many security problems arise from dependencies and the black-box nature of AI, with solutions for Model and Data issues being particularly scarce.",
      "mindmap": "graph TB\n        Root[Securing the AI Supply Chain] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[AI供应链安全格局复杂/Complex AI supply chain security landscape]\n        Problem --> P2[缺乏对常见问题与解决方案的了解/Lack of knowledge on common issues & solutions]\n        Method[主要方法/Method] --> M1[实证调查/Empirical investigation]\n        M1 --> M1_1[数据源: Hugging Face, GitHub/Data Sources: Hugging Face, GitHub]\n        M1 --> M1_2[构建分类管道/Build classification pipeline]\n        M1_2 --> M1_2_1[关键词匹配+微调distilBERT/Keyword matching + fine-tuned distilBERT]\n        Results[关键结果/Results] --> R1[数据集: 312,868个安全讨论/Dataset: 312,868 security discussions]\n        Results --> R2[分类法: 32个问题, 24个解决方案/Taxonomy: 32 issues, 24 solutions]\n        Results --> R3[洞察: 依赖复杂性和黑盒性导致问题/Insight: Issues from dependencies & black-box nature]"
    },
    {
      "title": "Fuzzilicon: A Post-Silicon Microcode-Guided x86 CPU Fuzzer",
      "authors": "Johannes Lenzen, Mohamadreza Rostami, Lichao Wu, Ahmad-Reza Sadeghi",
      "institution": "Technical University of Darmstadt",
      "link": "https://arxiv.org/pdf/2512.23438",
      "code": null,
      "tags": [
        "hardware security",
        "microcode fuzzing",
        "post-silicon analysis",
        "speculative execution",
        "coverage-guided fuzzing",
        "microarchitecture"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9d463f1925a4bae02edf8bf6e5276b970d1d085133ad48e32ea838e5db2fe1a_w640_q70.webp",
      "contributions": "1. Developed the first post-silicon fuzzing framework for x86 CPUs using microcode-level introspection and feedback. 2. Introduced a novel technique for extracting microarchitectural feedback by reverse-engineering Intel's microcode update interface. 3. Demonstrated the framework's effectiveness by discovering new vulnerabilities and significantly reducing coverage collection overhead.",
      "summary": "This paper presents Fuzzilicon, a novel fuzzing framework that automates vulnerability discovery in x86 CPUs by using microcode-level instrumentation and feedback. It reverse-engineers Intel's microcode interface to guide input generation without needing RTL access. The framework successfully uncovered new speculative execution vulnerabilities and established a new baseline for post-silicon CPU analysis.",
      "mindmap": "graph TB\n        Root[Fuzzilicon: A Post-Silicon Microcode-Guided x86 CPU Fuzzer] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Modern CPUs are proprietary black boxes with hard-to-detect microarchitectural flaws.]\n        Method[主要方法/Method: Microcode-guided fuzzing with feedback extracted via reverse-engineered update interface.]\n        Results[关键结果/Results: Found new vulnerabilities, reduced overhead, and achieved unique microcode coverage.]"
    },
    {
      "title": "Bitcoin-IPC: Scaling Bitcoin with a Network of Proof-of-Stake Subnets",
      "authors": "Marko Vukolić, Orestis Alpos, Jakov Mitrovski, Themis Papameletiou, Nikola Ristić, Dionysis Zindros",
      "institution": "Bitcoin Scaling Labs, Common Prefix",
      "link": "https://arxiv.org/pdf/2512.23439",
      "code": null,
      "tags": [
        "blockchain scalability",
        "Bitcoin",
        "Layer-2",
        "Proof-of-Stake",
        "interoperability",
        "SegWit"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c762e73812d8ecf4dff85e3904f4f2897f640f483515f122ffbda6dd2edfabcc_w640_q70.webp",
      "contributions": "1. Introduces Bitcoin-IPC, a protocol enabling permissionless creation of Proof-of-Stake Layer-2 subnets with stake denominated in Bitcoin (BTC). 2. Proposes a novel design embedded within Bitcoin's SegWit mechanism, inspired by SWIFT messaging, for seamless cross-subnet value transfer routed through Bitcoin L1. 3. Achieves significant scalability improvements, reducing transaction cost by up to 23x and increasing throughput from 7 to over 160 tps without modifying Bitcoin L1.",
      "summary": "The paper addresses Bitcoin's limited transaction throughput for use as a Medium of Exchange. It proposes Bitcoin-IPC, a protocol that creates a network of programmable Proof-of-Stake Layer-2 chains (subnets) that use Bitcoin for security and settlement. The design significantly increases transaction throughput and reduces cost without requiring changes to the Bitcoin base layer.",
      "mindmap": "graph TB\n        A[Bitcoin-IPC: Scaling Bitcoin with a Network of Proof-of-Stake Subnets] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[比特币作为交换媒介的可扩展性不足/Bitcoin's limited scalability as Medium of Exchange]\n        C --> C1[基于SegWit和SWIFT启发的L2 PoS子网协议/L2 PoS Subnet protocol inspired by SegWit & SWIFT]\n        D --> D1[吞吐量从7 tps提升至160+ tps/Throughput increased from 7 to 160+ tps]\n        D --> D2[每笔交易成本降低高达23倍/Tx cost reduced up to 23x]"
    },
    {
      "title": "Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation",
      "authors": "Toqeer Ali Syed, Mohammad Riyaz Belgaum, Salman Jan, Asadullah Abdullah Khan, Saad Said Alqahtani",
      "institution": "Islamic University of Madinah, Arab Open University-Bahrain",
      "link": "https://arxiv.org/pdf/2512.23480",
      "code": null,
      "tags": [
        "software supply chain security",
        "agentic AI",
        "reinforcement learning",
        "large language model",
        "blockchain security ledger",
        "CI/CD"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f037ac5977c7275a7c48edbcb676154bcff19330c107fe4c9769750efc5350_w640_q70.webp",
      "contributions": "1. Proposes an autonomous, agentic AI framework for software supply chain security that integrates LLM-based reasoning, RL, and multi-agent coordination for proactive vulnerability identification and mitigation. 2. Implements a system that interfaces with real CI/CD environments (e.g., GitHub Actions, Jenkins) via the Model Context Protocol (MCP) and logs actions to a blockchain for auditability. 3. Demonstrates through experiments that the framework outperforms rule-based and provenance-only baselines in detection accuracy and mitigation latency with acceptable operational overhead.",
      "summary": "This paper addresses the limitation of current software supply chain security frameworks (like SLSA) which focus on provenance but lack active vulnerability mitigation. It proposes an agentic AI system that combines LLMs for semantic analysis and RL for adaptive response, integrated with CI/CD pipelines via MCP and logged on a blockchain. Experiments show it achieves better detection and faster mitigation than baselines, enabling a shift from reactive to proactive defense.",
      "mindmap": "graph TB\n        A[Agentic AI for Autonomous Defense in Software Supply Chain Security] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[传统溯源框架无法主动缓解漏洞/Traditional provenance frameworks lack active vulnerability mitigation]\n        C --> C1[多智能体协调/Multi-Agent Coordination]\n        C --> C2[LLM推理与RL策略/LLM Reasoning & RL]\n        C --> C3[集成CI/CD与区块链日志/CI/CD Integration & Blockchain Ledger]\n        D --> D1[更高的检测准确率/Higher Detection Accuracy]\n        D --> D2[更短的缓解延迟/Lower Mitigation Latency]\n        D --> D3[合理的构建开销/Reasonable Build Overhead]"
    },
    {
      "title": "A Privacy Protocol Using Ephemeral Intermediaries and a Rank-Deficient Matrix Power Function (RDMPF)",
      "authors": "Eduardo Salazar",
      "institution": "Nebula Technology Lab",
      "link": "https://arxiv.org/pdf/2512.23535",
      "code": "https://icpp.tech",
      "tags": [
        "privacy-preserving protocols",
        "ephemeral intermediaries",
        "rank-deficient matrix power function (RDMPF)",
        "private transfer",
        "Internet Computer (ICP)",
        "forward secrecy"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/328b76baab034954fecc09fa2e47ca08dd1df2f1b8b10c108a90b5989ec00391_w640_q70.webp",
      "contributions": "1. A private transfer architecture using two short-lived intermediaries and sealed storage to decouple deposit and retrieval, 2. A non-interactive encapsulation scheme based on a Rank-Deficient Matrix Power Function (RDMPF) to derive per-transfer keys and enable discovery without fingerprinting, 3. A protocol where all intermediaries are ephemeral and provide certified destruction proofs, enabling auditable finalization and properties like sender anonymity and forward secrecy.",
      "summary": "This paper presents a privacy protocol for the Internet Computer that uses ephemeral intermediaries and a novel RDMPF-based encapsulation to enable private asset transfers. The method ensures sender anonymity, content confidentiality against intermediaries, and forward secrecy, and has been implemented and deployed as ICPP.",
      "mindmap": "graph TB\n    Root[”A Privacy Protocol Using Ephemeral Intermediaries and RDMPF<br>使用临时中介和RDMPF的隐私协议”] --> Problem[”核心问题/Problem<br>如何在区块链上实现私密、可审计的资产转移<br>How to achieve private, auditable asset transfer on a blockchain”]\n    Root --> Method[”主要方法/Method<br>使用两个临时中介、RDMPF封装和认证销毁<br>Uses two ephemeral intermediaries, RDMPF encapsulation, and attested teardown”]\n    Root --> Results[”关键结果/Results<br>实现发送方匿名、前向安全性并已部署(ICPP)<br>Achieves sender anonymity, forward secrecy, and is deployed (ICPP)”]"
    },
    {
      "title": "Toward Trustworthy Agentic AI: A Multimodal Framework for Preventing Prompt Injection Attacks",
      "authors": "Toqeer Ali Syed, Mishal Ateeq Almutairi, Mahmoud Abdel Moaty",
      "institution": "Islamic University of Madinah, Arab Open University-Bahrain",
      "link": "https://arxiv.org/pdf/2512.23557",
      "code": null,
      "tags": [
        "ai security",
        "prompt injection",
        "multi-agent systems",
        "provenance tracking",
        "trust validation",
        "multimodal sanitization"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05cd3aa22e07307bda78f06b6f87c2195c61c758b4fe44dc5bffbc281d72a8e4_w640_q70.webp",
      "contributions": "1. Proposes a Cross-Agent Multimodal Provenance-Aware Defense Framework to secure agentic AI workflows against prompt injection attacks. 2. Introduces a coordinated defense with specialized sanitizer agents (text, visual) and an output validator, managed by a provenance ledger for tracking trust metadata. 3. Demonstrates through experiments that the framework significantly improves multimodal injection detection accuracy and minimizes trust leakage across agents.",
      "summary": "This paper addresses the security threat of multimodal prompt injection attacks in agentic AI systems like LangChain. It proposes a defense framework that sanitizes inputs and validates outputs using specialized agents coordinated by a provenance ledger. The experimental results show the framework enhances detection accuracy and stabilizes agentic execution pathways.",
      "mindmap": "graph TB\n        A[Toward Trustworthy Agentic AI<br>构建可信的智能体AI] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Multimodal Prompt Injection Attacks<br>多模态提示注入攻击]\n        C --> C1[Cross-Agent Provenance-Aware Framework<br>跨智能体溯源感知框架]\n        C1 --> C2[Sanitizer & Validator Agents<br>净化与验证智能体]\n        C1 --> C3[Provenance Ledger<br>溯源账本]\n        D --> D1[Enhanced Detection Accuracy<br>提升检测准确率]\n        D --> D2[Minimized Trust Leakage<br>最小化信任泄漏]\n        D --> D3[Stable Execution Pathways<br>稳定的执行路径]"
    },
    {
      "title": "Enhanced Web Payload Classification Using WAMM: An AI-Based Framework for Dataset Refinement and Model Evaluation",
      "authors": "Heba Osama, Omar Elebiary, Youssef Qassim, Mohamed Amgad, Ahmed Maghawry, Ahmed Saafan, Haitham Ghalwash",
      "institution": "Cyshield, Coventry University - Egypt Branch",
      "link": "https://arxiv.org/pdf/2512.23610",
      "code": null,
      "tags": [
        "web application security",
        "WAF",
        "XGBoost",
        "LLM-guided relabeling",
        "dataset augmentation",
        "multiclass detection"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd1d738f4ed0f98c5c6365f48a9a30b2b8734d30e82e01c7f23fd1fac1002fa8_w640_q70.webp",
      "contributions": "1. Proposes WAMM, an AI-driven multiclass web attack detection framework that reclassifies HTTP requests into OWASP-aligned categories. 2. Introduces a multi-phase dataset refinement pipeline for the SR-BH 2020 dataset, including deduplication, LLM-guided relabeling, augmentation, and LLM-based filtering. 3. Demonstrates that XGBoost on the refined dataset achieves high accuracy and microsecond-level inference, outperforming deep learning models and significantly improving upon rule-based OWASP CRS detection rates.",
      "summary": "This paper introduces WAMM, an AI-based framework for detecting web attacks. It refines a security dataset using techniques like LLM-guided relabeling and augmentation, then trains ML models like XGBoost for classification. The results show that WAMM with XGBoost achieves high accuracy and fast inference, significantly outperforming traditional rule-based WAFs in detecting obfuscated attacks.",
      "mindmap": "graph TB\n        A[Enhanced Web Payload Classification Using WAMM] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[传统WAF规则集难以检测混淆/零日攻击/Traditional WAF rules struggle with obfuscated/zero-day attacks]\n        C --> C1[提出WAMM框架/Propose WAMM framework]\n        C1 --> C2[多阶段数据集增强/Multi-phase dataset enhancement]\n        C2 --> C3[LLM引导重标注与过滤/LLM-guided relabeling & filtering]\n        C2 --> C4[数据增强/Data augmentation]\n        C1 --> C5[统一特征空间与模型评估/Unified feature space & model evaluation]\n        D --> D1[XGBoost达99.59%准确率/XGBoost achieves 99.59% accuracy]\n        D --> D2[微秒级推理/Microsecond-level inference]\n        D --> D3[相比OWASP CRS提升达86%/Up to 86% improvement over OWASP CRS]"
    },
    {
      "title": "SemCovert: Secure and Covert Video Transmission via Deep Semantic-Level Hiding",
      "authors": "Zhihan Cao, Xiao Yang, Gaolei Li, Jun Wu, Jianhua Li, Yuchen Liu",
      "institution": "Shanghai Jiao Tong University, North Carolina State University",
      "link": "https://arxiv.org/pdf/2512.22233",
      "code": null,
      "tags": [
        "semantic communication security",
        "semantic hiding",
        "randomized embedding",
        "secret semantic extractor"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4b368b0e0e2b9ae1e6c7bf4629ba64b86e8e570fdf21089b033a631ae92af3c_w640_q70.webp",
      "contributions": "1. Proposes SemCovert, a deep semantic-level hiding framework for secure and covert video transmission, integrating co-designed hiding and extraction models into the semantic communication pipeline. 2. Introduces a randomized semantic hiding strategy to break embedding determinism and introduce unpredictable distribution patterns, improving resistance to analysis. 3. Demonstrates through experiments that the framework effectively mitigates eavesdropping/detection risks, reliably conceals secret videos with minor video quality degradation, preserving transmission fidelity.",
      "summary": "This paper addresses privacy leakage in video semantic communication by proposing SemCovert, a framework that hides secret information at the semantic level using co-designed models and a randomized hiding strategy. The method enables authorized recovery while remaining imperceptible to regular users and resistant to statistical analysis. Experimental results confirm its effectiveness for secure and covert transmission without significantly compromising video quality.",
      "mindmap": "graph TB\n        A[SemCovert: Secure and Covert Video Transmission] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[隐私泄露风险/Privacy Leakage Risk]\n        B --> B2[传统安全技术不适用/Traditional Security Inapplicable]\n        C --> C1[语义隐藏模型与提取器/Semantic Hiding Model & Extractor]\n        C --> C2[随机化语义隐藏策略/Randomized Semantic Hiding Strategy]\n        D --> D1[有效缓解窃听与检测风险/Effectively Mitigates Eavesdropping & Detection]\n        D --> D2[可靠隐藏秘密视频/Reliably Conceals Secret Videos]\n        D --> D3[视频质量轻微下降/Minor Video Quality Degradation]"
    },
    {
      "title": "Research Directions in Quantum Computer Cybersecurity",
      "authors": "Jakub Szefer",
      "institution": "Northwestern University",
      "link": "https://arxiv.org/pdf/2512.23607",
      "code": null,
      "tags": [
        "quantum computer security",
        "quantum computer cybersecurity",
        "post-quantum cryptography",
        "cloud-based quantum computers",
        "security threats",
        "research gaps"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ccb76e5e59fbc85e15321e60404ace187a6d10acc03adcb5c6cfa4ff3c3e0da_w640_q70.webp",
      "contributions": "1. Provides a high-level summary of major research directions in quantum computer cybersecurity for the first half of the current decade, 2. Synthesizes and presents the current landscape of security threats and defenses against emergent quantum computing technologies, 3. Identifies and discusses perceived research gaps that require future funding and research efforts from academia and industry.",
      "summary": "This document provides a concise overview of contemporary research directions in quantum computer cybersecurity, summarizing the major threats and defenses from the last five years of academic work. It aims to inform researchers and leaders about the current landscape and highlight key research gaps. The analysis is inspired by and extends beyond discussions from the Quantum Computer Cybersecurity Symposium.",
      "mindmap": "graph TB\n        Root(”Research Directions in Quantum Computer Cybersecurity”) --> Problem(”核心问题/Problem: Need to understand the security landscape of emerging quantum computers”)\n        Root --> Method(”主要方法/Method: Summarize recent academic research and symposium discussions”)\n        Root --> Results(”关键结果/Results: Overview of threats, defenses, and identified research gaps”)"
    },
    {
      "title": "Composition Theorems for f-Differential Privacy",
      "authors": "Natasha Fernandes, Annabelle McIver, Parastoo Sadeghi",
      "institution": "Macquarie University, UNSW (University of New South Wales)",
      "link": "https://arxiv.org/pdf/2512.21358",
      "code": null,
      "tags": [
        "Differential Privacy",
        "f-differential privacy",
        "quantitative information flow",
        "composition theorems",
        "Galois connection",
        "trade-off functions"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d202b6f3d64108f2672eaab827a63e5c6cfac205fcbbf58e2eb8b75c09924dbe_w640_q70.webp",
      "contributions": "1. Establishes an equivalence between f-Differential Privacy (f-DP) and the channel model of Quantitative Information Flow (QIF) via a Galois connection. 2. Derives novel general composition theorems for f-DP enabled by this equivalence. 3. Applies the new composition theorems to analyze privacy amplification mechanisms like sub-sampling and purification, producing new f-DP profiles for these algorithms.",
      "summary": "This paper connects the theory of f-Differential Privacy (f-DP) with Quantitative Information Flow (QIF) by showing their equivalence through a Galois connection. This foundational link enables the derivation of new, general composition theorems for f-DP. The authors apply these theorems to analyze complex privacy-enhancing algorithms, such as sub-sampling, yielding improved privacy profiles.",
      "mindmap": "graph TB\n        Root[Composition Theorems for f-Differential Privacy] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Need for better composition analysis in complex privacy designs] --> Problem_Sub[子问题/Sub-problem: Relating f-DP to foundational information theory]\n        Method[主要方法/Method: Formal equivalence via Galois connection] --> Method_Sub[子方法/Sub-method: Mapping between f-DP trade-off functions and QIF channels]\n        Results[关键结果/Results: Novel general composition theorems for f-DP] --> Results_Sub[子结果/Sub-results: Improved f-DP analysis for sub-sampling & purification]"
    },
    {
      "title": "Satellite Cybersecurity Across Orbital Altitudes: Analyzing Ground-Based Threats to LEO, MEO, and GEO",
      "authors": "Mark Ballard, Guanqun Song, Ting Zhu",
      "institution": "The Ohio State University",
      "link": "https://arxiv.org/pdf/2512.21367",
      "code": null,
      "tags": [
        "satellite cybersecurity",
        "Telemetry",
        "Tracking",
        "and Command (TT&C)",
        "encryption weaknesses",
        "radio-frequency (RF) links"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp",
      "contributions": "1. Presents a comparative analysis of satellite cybersecurity threats across LEO, MEO, and GEO orbital regimes, linking orbital altitude to attack feasibility and impact. 2. Synthesizes data from 60 publicly documented security incidents to characterize distinct threat profiles for different orbits (e.g., GEO uplink exposure vs. LEO hardware constraints). 3. Bridges the gap between cybersecurity and space sustainability, arguing that unmitigated cyber vulnerabilities accelerate hardware obsolescence and debris accumulation.",
      "summary": "This paper analyzes ground-based cybersecurity threats to satellites in different orbital altitudes (LEO, MEO, GEO). By synthesizing data from 60 security incidents and analyzing vulnerability proxies like TT&C anomalies and encryption, it characterizes how altitude dictates distinct threat profiles and concludes that weak encryption and command path irregularities are the most consistent predictors of adversarial success across all orbits.",
      "mindmap": "graph TB\n    A[Satellite Cybersecurity Across Orbital Altitudes] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[轨道高度如何影响卫星网络安全/How orbital altitude dictates satellite cybersecurity]\n    C --> C1[分析60起安全事件与漏洞代理/Analyze 60 security incidents & vulnerability proxies]\n    D --> D1[不同轨道有独特的威胁特征/Distinct threat profiles per orbit]\n    D --> D2[弱加密和指令异常是主要预测因子/Weak encryption & command irregularities are key predictors]"
    },
    {
      "title": "Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide",
      "authors": "Behnam Farnaghinejad, Antonio Porsia, Annachiara Ruospo, Alessandro Savino, Stefano Di Carlo, Ernesto Sanchez",
      "institution": "Politecnico di Torino",
      "link": "https://arxiv.org/pdf/2512.21362",
      "code": null,
      "tags": [
        "side-channel analysis",
        "RISC-V",
        "CVA6",
        "Correlation Power Analysis (CPA)",
        "RTL simulation",
        "power side-channel"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f1045d9314e37006547d2c94a7c4490ff95449687fd13d7c467003b4c095bac_w640_q70.webp",
      "contributions": "1. Presents the first side-channel vulnerability evaluation of the CVA6 RISC-V processor core. 2. Demonstrates the application of the VeriSide RTL-level power profiling framework for efficient power trace extraction without waveform files. 3. Shows that Correlation Power Analysis (CPA) on the CVA6 during software-based AES encryption enables key recovery, highlighting the need for early-stage RTL security assessments.",
      "summary": "This paper analyzes the power side-channel vulnerability of the CVA6 RISC-V core using the VeriSide RTL simulation framework. By applying Correlation Power Analysis (CPA) to power traces during software AES execution, the authors successfully recover the secret key. The findings demonstrate significant leakage in the CVA6 design, emphasizing the importance of pre-silicon RTL-level security evaluation.",
      "mindmap": "graph TB\n        A[Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[现代RISC-V处理器需要抗侧信道攻击能力 / Modern RISC-V processors require resilience to side-channel attacks]\n        C --> C1[使用VeriSide框架在RTL级进行功耗分析 / Use VeriSide framework for RTL-level power analysis]\n        C --> C2[对软件AES执行进行相关性功耗分析(CPA) / Perform Correlation Power Analysis (CPA) on software AES execution]\n        D --> D1[CVA6设计存在显著泄漏 / CVA6 design exhibits significant leakage]\n        D --> D2[成功恢复AES密钥 / Successful AES key recovery]"
    },
    {
      "title": "The Imitation Game: Using Large Language Models as Chatbots to Combat Chat-Based Cybercrimes",
      "authors": "Yifan Yao, Baojuan Wang, Jinhao Duan, Kaidi Xu, ChuanKai Guo, Zhibo Eric Sun, Yue Zhang",
      "institution": "Drexel University, Shandong University",
      "link": "https://arxiv.org/pdf/2512.21371",
      "code": null,
      "tags": [
        "adversarial interaction",
        "Large Language Models",
        "chat-based cybercrime",
        "adversarial engagement",
        "OCR-based analysis",
        "Telegram scams"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f4b9846e0125e1fe793dd441a994299b8568cd5c2bf7c05200309276b60eece_w640_q70.webp",
      "contributions": "1. Proposes LURE, the first system to deploy LLMs as active agents (not passive classifiers) within adversarial chat environments to combat cybercrime. 2. Introduces a novel methodology combining automated discovery, adversarial interaction, and OCR-based analysis of image-embedded payment data. 3. Demonstrates the system's effectiveness in real-world illicit Telegram scams, where it maintained human-like conversations in over 56% of interactions, revealing key scammer behavioral patterns.",
      "summary": "This paper proposes LURE, a system that uses Large Language Models as active chatbots to engage with and deceive chat-based cybercriminals, turning their own tactics against them. Applied to Telegram video chat scams, LURE successfully maintained undetected multi-round conversations in over 56% of interactions, uncovering scam operation patterns like payment flows and upselling strategies.",
      "mindmap": "graph TB\n        A[The Imitation Game: Using Large Language Models as Chatbots to Combat Chat-Based Cybercrimes] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Chat-based cybercrime using trust & deception, hard for traditional defenses]\n        C[主要方法/Method<br>LURE system: LLMs as active agents, adversarial interaction, OCR analysis]\n        D[关键结果/Results<br>56% success rate, engaged 53 actors, revealed scam patterns]"
    },
    {
      "title": "Key Length-Oriented Classification of Lightweight Cryptographic Algorithms for IoT Security",
      "authors": "Arsalan Vahi",
      "institution": "Middle East Technical University",
      "link": "https://arxiv.org/pdf/2512.21368",
      "code": null,
      "tags": [
        "lightweight cryptography",
        "lightweight ciphers",
        "key size",
        "IoT security",
        "symmetric cryptography",
        "security evaluation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07f480d571b5dcb81f609c0a05f097dbfe5bc783bd4de5936cf4b4c301e2ab61_w640_q70.webp",
      "contributions": "1. Conducts a security-focused survey of symmetric lightweight ciphers for IoT, addressing a gap in existing literature. 2. Proposes a taxonomy for classifying IoT applications based on their inherent characteristics. 3. Proposes a taxonomy for evaluating security levels of lightweight ciphers based on key size, concluding that keys shorter than 128 bits are less secure.",
      "summary": "This paper surveys lightweight cryptographic algorithms for IoT security, focusing on evaluating their security strength rather than just performance. It proposes two taxonomies for classifying IoT applications and cipher security levels based on key length. The main finding is that key size is critical, with ciphers using keys shorter than 128 bits being considered insecure for sensitive data.",
      "mindmap": "graph TB\n        A[Key Length-Oriented Classification of Lightweight Cryptographic Algorithms for IoT Security] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[现有调查缺乏针对物联网环境的全面安全评估/Existing surveys lack comprehensive IoT-specific security evaluation]\n        C --> C1[对轻量级密码进行以安全为重点的综述/Conduct a security-focused survey of lightweight ciphers]\n        C --> C2[提出物联网应用分类法/Propose an IoT application taxonomy]\n        C --> C3[提出基于密钥长度的安全等级分类法/Propose a key size-based security level taxonomy]\n        D --> D1[密钥长度是轻量级密码安全的关键参数/Key size is a critical security parameter]\n        D --> D2[密钥短于128位的密码安全性不足/Ciphers with keys <128 bits are less secure]"
    },
    {
      "title": "Reflection-Driven Control for Trustworthy Code Agents",
      "authors": "Bin Wang, Jiazheng Quan, Xingrui Yu, Hansen Hu, Yuhao, Ivor Tsang",
      "institution": "Peking University, Xiamen University, Agency for Science, Technology and Research (A*STAR)",
      "link": "https://arxiv.org/pdf/2512.21354",
      "code": null,
      "tags": [
        "agent system",
        "reflection-driven control",
        "secure code generation",
        "trustworthy agents",
        "reflective memory",
        "safety control"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp",
      "contributions": "1. Introduces Reflection-Driven Control, a standardized and pluggable control module that integrates self-reflection as an explicit, internal step in an agent's reasoning process. 2. Instantiates the method for secure code generation, using a reflection loop to monitor decisions and retrieve repair examples/guidelines from an evolving reflective memory to inject constraints. 3. Empirically demonstrates that the approach substantially improves security and policy compliance of generated code while preserving functional correctness, with minimal overhead.",
      "summary": "The paper addresses the lack of reliable safety controls in LLM agents by proposing Reflection-Driven Control, a module that makes self-reflection an explicit, continuous part of the agent's reasoning to monitor and constrain its decisions using evidence from a reflective memory. Evaluated on security-critical code generation tasks, the method significantly improves code security and compliance while maintaining functionality, offering a practical path toward trustworthy AI coding agents.",
      "mindmap": "graph TB\n        Root[Reflection-Driven Control for Trustworthy Code Agents] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[LLM代理缺乏可靠的安全控制/LLM agents lack reliable safety controls]\n        Problem --> P2[可能产生有害输出/Can produce harmful outputs]\n        Method --> M1[将自我反思作为推理的显式步骤/Elevates self-reflection to an explicit reasoning step]\n        Method --> M2[内部反思循环监控决策路径/Internal reflection loop monitors decision path]\n        Method --> M3[从反思记忆中检索修复示例/Retrieves repair examples from reflective memory]\n        Results --> R1[显著提高生成代码的安全性和合规性/Substantially improves security & policy compliance]\n        Results --> R2[基本保持功能正确性/Largely preserves functional correctness]\n        Results --> R3[运行时和token开销最小/Minimal runtime & token overhead]"
    },
    {
      "title": "A Systematic Review of Technical Defenses Against Software-Based Cheating in Online Multiplayer Games",
      "authors": "Adwa Alangari, Ohoud Alharbi",
      "institution": "King Saud University",
      "link": "https://arxiv.org/pdf/2512.21377",
      "code": null,
      "tags": [
        "game security",
        "server-side detection",
        "client-side anti-tamper",
        "kernel-level anti-cheat",
        "hardware-assisted TEEs",
        "adversarial resistance"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/137ad02b7b97dcc6332136fab185dc8b3ccf11a4a306f05b35f33d8d9520ec12_w640_q70.webp",
      "contributions": "1. A systematic categorization of technical anti-cheat defenses into four distinct categories: server-side detection, client-side anti-tamper, kernel-level drivers, and hardware-assisted TEEs. 2. A comparative evaluation framework for these categories based on detection effectiveness, performance overhead, privacy impact, and scalability. 3. An analysis highlighting the key trade-offs and the ongoing adversarial arms race, emphasizing the need for robust anti-cheat designs.",
      "summary": "This systematic review surveys technical defenses against software-based cheating in online multiplayer games. It categorizes and evaluates approaches like server-side detection and kernel-level anti-cheat, highlighting trade-offs between visibility and privacy. The review concludes that the field is an ongoing arms race, requiring robust, adversary-resistant designs.",
      "mindmap": "graph TB\n        Root[”A Systematic Review of Technical Defenses Against Software-Based Cheating in Online Multiplayer Games”] --> Problem[”核心问题/Problem: Software-based cheating threatens game integrity and fair competition”]\n        Root --> Method[”主要方法/Method: Systematic review and categorization of technical defenses (server-side, client-side, kernel-level, hardware-assisted)”]\n        Root --> Results[”关键结果/Results: Highlights trade-offs (e.g., visibility vs. privacy), emphasizes ongoing arms race and need for robust designs”]"
    },
    {
      "title": "Security Risks Introduced by Weak Authentication in Smart Home IoT Systems",
      "authors": "Daniyal Ganiuly, Nurzhau Bolatbek, Assel Smaiyl",
      "institution": "Astana IT University",
      "link": "https://arxiv.org/pdf/2512.21374",
      "code": null,
      "tags": [
        "IoT security",
        "authentication security",
        "replay attacks",
        "local network threats",
        "empirical security analysis"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85258f2b6afddb7ba218b720666454027995d978e3c0c5c5d1c10ce3ac5fd6ee_w640_q70.webp",
      "contributions": "1. Conducted an empirical analysis of authentication enforcement in deployed smart home IoT devices across multiple categories and ecosystems. 2. Demonstrated that authentication state is long-lived, persists through network changes, and can be replayed from another host on the same local network. 3. Identified that current mechanisms rely on long-lived trust with weak binding to session freshness, network context, or controller identity.",
      "summary": "This paper empirically analyzes authentication in smart home IoT devices, finding that authentication tokens are long-lived, persist through network events, and are vulnerable to replay attacks from other local hosts. The study concludes that current mechanisms prioritize usability over security, creating significant local network threats.",
      "mindmap": "graph TB\n        Root(”Security Risks Introduced by Weak Authentication in Smart Home IoT Systems”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”智能家居IoT认证机制需平衡安全与可用性/Smart home IoT authentication must balance security & usability”)\n        Method --> M1(”在受控住宅环境中进行实证分析/Empirical analysis in controlled residential environment”)\n        Method --> M2(”使用被动网络测量和官方应用交互/Using passive network measurement & official app interaction”)\n        Method --> M3(”检查配对、长期运行、网络变化和重放尝试/Examining pairing, long-term operation, network changes, replay”)\n        Results --> R1(”认证状态被长期重用且持久/Authentication state is long-lived & persistent”)\n        Results --> R2(”在网络事件后保持有效/Remains valid after network events”)\n        Results --> R3(”易受同一局域网重放攻击/Vulnerable to replay attacks from same local network”)"
    },
    {
      "title": "LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors",
      "authors": "Tianwei Lan, Farid Naït-Abdesselam",
      "institution": "Université Paris Cité",
      "link": "https://arxiv.org/pdf/2512.21404",
      "code": null,
      "tags": [
        "adversarial attacks",
        "adversarial attack",
        "large language model",
        "retrieval-augmented generation",
        "Android malware detection",
        "adversarial training"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6061210b194ba5cf79f70b8959faa3abe6b3e91ffad512d9cfd319de948593bb_w640_q70.webp",
      "contributions": "1. Proposes LAMLAD, a novel adversarial attack framework that uses a dual-agent LLM architecture (manipulator and analyzer) to generate feature-level perturbations for evading Android malware detectors., 2. Integrates Retrieval-Augmented Generation (RAG) into the LLM pipeline to improve the efficiency and contextual awareness of the attack., 3. Proposes and evaluates an adversarial training-based defense strategy to enhance model robustness against the proposed LAMLAD-style attacks.",
      "summary": "This paper proposes LAMLAD, a novel adversarial attack framework that leverages the generative and reasoning capabilities of Large Language Models (LLMs) to bypass ML-based Android malware classifiers. The method uses a dual-agent LLM architecture with RAG to generate realistic, functionality-preserving feature perturbations, achieving a high attack success rate. The paper also demonstrates that adversarial training can significantly reduce the effectiveness of such attacks, enhancing model robustness.",
      "mindmap": "graph TB\n        A[LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors] --> B[核心问题/Problem: ML-based Android malware detectors are vulnerable to adversarial attacks.]\n        A --> C[主要方法/Method: Proposes LAMLAD, a dual-agent LLM framework with RAG for generating stealthy perturbations.]\n        A --> D[关键结果/Results: Achieves up to 97% attack success rate; adversarial training defense reduces ASR by >30%.]"
    },
    {
      "title": "Weighted Fourier Factorizations: Optimal Gaussian Noise for Differentially Private Marginal and Product Queries",
      "authors": "Christian Janos Lebeda, Aleksandar Nikolov, Haohua Tang",
      "institution": "Inria, Université de Montpellier, INSERM, University of Toronto",
      "link": "https://arxiv.org/pdf/2512.21499",
      "code": null,
      "tags": [
        "differential privacy",
        "factorization mechanism",
        "Fourier basis",
        "marginal queries",
        "product queries",
        "Gaussian noise"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/589c857d3c263098ff5b7608b80fed9cb6cf72f1228f01d3ba136496420444dc_w640_q70.webp",
      "contributions": "1. Proposes a simpler, polynomial-time algorithm for releasing weighted marginal queries under differential privacy using Fourier factorization, achieving exact optimality among factorization mechanisms. 2. Extends the algorithm to a more general class of product queries, maintaining exact optimality. 3. Shows the mechanism is almost optimal for extended marginal queries with threshold predicates, achieving optimal noise variance up to lower-order terms.",
      "summary": "This paper proposes a new algorithm for releasing marginal and product queries under differential privacy by adding correlated Gaussian noise. The method works by releasing queries in the Fourier basis with independent, carefully calibrated noise and then reconstructing the answers, which is proven to be exactly optimal among factorization mechanisms and runs in polynomial time. It simplifies and improves upon prior work, extending optimality to more general query classes.",
      "mindmap": "graph TB\n        A[Weighted Fourier Factorizations<br>加权傅里叶分解] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Releasing marginal queries<br>with differential privacy<br>在差分隐私下发布边际查询]\n        C --> C1[Use Fourier basis &<br>independent Gaussian noise<br>使用傅里叶基和独立高斯噪声]\n        C --> C2[Reconstruct via<br>inverse Fourier transform<br>通过逆傅里叶变换重构]\n        D --> D1[Exactly optimal for<br>marginal & product queries<br>对边际和乘积查询精确最优]\n        D --> D2[Polynomial-time algorithm<br>多项式时间算法]\n        D --> D3[Simpler & better than<br>prior work (Xiao et al.)<br>比先前工作更简单更好]"
    },
    {
      "title": "Enhancing Distributed Authorization With Lagrange Interpolation And Attribute-Based Encryption",
      "authors": "Keshav Sinha, Sumitra, Richa Kumari, Akashdeep Bhardwaj, Shawon Rahman",
      "institution": "UPES (University of Petroleum and Energy Studies), University of Hawaii - Hilo",
      "link": "https://arxiv.org/pdf/2512.21525",
      "code": null,
      "tags": [
        "Attribute-Based Encryption",
        "Lagrange Interpolation",
        "Shamir Secret Sharing",
        "Involution Function-Based Stream Cipher"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d614980b77b93ae670a09dec954155af73838387f014f381092232a41d17e816_w640_q70.webp",
      "contributions": "1. Proposes a multi-party execution approach to reduce server computational overhead and response time in distributed authorization. 2. Introduces an encryption method using an Involution Function-Based Stream Cipher for file data. 3. Utilizes Shamir secret sharing with second-order Lagrange interpolation for secure key distribution and reconstruction.",
      "summary": "This paper addresses the server overhead and slow response time in secure data access by proposing a multi-party execution approach. The method combines an Involution Function-Based Stream Cipher for encryption with Shamir secret sharing and Lagrange interpolation for key management. The results show reduced computational overhead, evaluated through encryption/decryption time, throughput, and security analysis.",
      "mindmap": "graph TB\n        A[ENHANCING DISTRIBUTED AUTHORIZATION<br>增强分布式授权] --> B(核心问题/Problem: Server overhead & slow response in secure data access<br>服务器开销大、安全数据访问响应慢)\n        A --> C(主要方法/Method: Multi-party execution with encryption & key distribution<br>多参与方执行，结合加密与密钥分发)\n        C --> C1[加密/Encryption: Involution Function-Based Stream Cipher<br>基于对合函数的流密码]\n        C --> C2[密钥分发/Key Distribution: Shamir Secret Sharing & Lagrange Interpolation<br>沙米尔秘密共享与拉格朗日插值]\n        A --> D(关键结果/Results: Reduced computational overhead, evaluated via time & security analysis<br>降低计算开销，通过时间和安全分析评估)"
    },
    {
      "title": "GoldenFuzz: Generative Golden Reference Hardware Fuzzing",
      "authors": "Lichao Wu, Mohamadreza Rostami, Huimin Li, Nikhilesh Singh, Ahmad-Reza Sadeghi",
      "institution": "Technical University of Darmstadt",
      "link": "https://arxiv.org/pdf/2512.21524",
      "code": null,
      "tags": [
        "hardware security verification",
        "hardware fuzzing",
        "golden reference model",
        "RISC-V",
        "test case refinement",
        "vulnerability discovery"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp",
      "contributions": "1. Introduces a novel two-stage hardware fuzzing framework that decouples test refinement from coverage exploration using a fast Golden Reference Model (GRM) as a \"digital twin\". 2. Proposes a method to iteratively construct test cases by concatenating instruction blocks, balancing inter- and intra-instruction quality, and uses a feedback mechanism from high- and low-coverage samples. 3. Demonstrates superior performance over existing fuzzers on RISC-V processors, discovering new severe vulnerabilities and achieving higher coverage with lower computational overhead.",
      "summary": "This paper presents GoldenFuzz, a hardware fuzzing framework that uses a fast Golden Reference Model to refine test cases efficiently before exploring the actual device. It employs a feedback-driven mechanism for instruction block selection to enhance state exploration. The evaluation shows GoldenFuzz achieves higher coverage with less overhead and discovers new severe vulnerabilities in RISC-V processors.",
      "mindmap": "graph TB\n        A[GoldenFuzz: Generative Golden Reference Hardware Fuzzing] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[硬件模糊测试存在语义感知有限、测试低效、计算开销大的问题/Hardware fuzzing suffers from limited semantic awareness, inefficiency, and high overhead]\n        C --> C1[使用快速黄金参考模型(GRM)作为数字孪生进行两阶段模糊测试/Two-stage fuzzing using a fast Golden Reference Model (GRM) as a digital twin]\n        C --> C2[通过连接指令块和反馈机制构建测试用例/Constructing test cases via instruction block concatenation and feedback]\n        D --> D1[在RISC-V处理器上实现最高覆盖率和最小开销/Achieves highest coverage with minimal overhead on RISC-V processors]\n        D --> D2[发现新的高危漏洞/Uncovers new high-severity vulnerabilities]"
    },
    {
      "title": "Security Boundaries of Quantum Key Reuse: A Quantitative Evaluation Method for QKD Key Rotation Interval and Security Benefits Combined with Block Ciphers",
      "authors": "Xiaoming Chen, Haoze Chen, Fei Xu, Meifeng Gao, Jianguo Xie, Cheng Ye, An Hua, Jiao Zhao, Minghan Li, Feilong Li, Yajun Miao, Wei Qi",
      "institution": "CAS Quantum Network Co., Ltd., University of Science and Technology of China",
      "link": "https://arxiv.org/pdf/2512.21561",
      "code": null,
      "tags": [
        "Post-Quantum Cryptography / Quantum Cryptography",
        "Quantum Key Distribution (QKD)",
        "Key Rotation",
        "Block Cipher Modes (CTR/CBC/ECBC-MAC)",
        "Concrete Security",
        "SM4"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c46c72f07d378546c8a8a3c260c860de7093f78f6c38b6f32868e53b31ca6f56_w640_q70.webp",
      "contributions": "1. Constructed a precise calculation model for the key rotation interval in hybrid QKD-block cipher systems. 2. Proposed a quantitative method to evaluate the security benefit of using QKD keys with block ciphers, deriving the maximum safe number of files per key (Q*). 3. Quantified the security enhancement from key rotation, showing it can increase security strength by log2(k) to 2log2(k) bits for a target like 80-bit security.",
      "summary": "This paper addresses the security degradation when a single QKD-derived key is reused to encrypt multiple files with block ciphers. It proposes a quantitative model to calculate safe key rotation intervals and evaluates the security benefits, using SM4 as a case study. The results show that regular key rotation can significantly enhance the security level of the hybrid cryptographic system.",
      "mindmap": "graph TB\n        A[Security Boundaries of Quantum Key Reuse] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[QKD密钥重用导致安全强度降低/QKD Key Reuse Reduces Security]\n        C --> C1[构建密钥轮换间隔计算模型/Build Key Rotation Interval Model]\n        C --> C2[提出安全收益定量评估方法/Propose Quantitative Security Benefit Method]\n        C --> C3[分析不同分组密码模式/Analyze Block Cipher Modes (CTR, CBC, ECBC-MAC)]\n        D --> D1[推导单密钥最大安全文件数Q*/Derive Max Safe Files per Key Q*]\n        D --> D2[量化轮换提升安全强度log2k~2log2k位/Quantify Rotation Benefit: log2k~2log2k bits]"
    },
    {
      "title": "Verifiable Passkey: The Decentralized Authentication Standard",
      "authors": "Aditya Mitra, Sibi Chakkaravarthy Sethuraman",
      "institution": "Kadir Has University, VIT-AP University",
      "link": "https://arxiv.org/pdf/2512.21663",
      "code": null,
      "tags": [
        "authentication",
        "Verifiable Passkey",
        "Verifiable Credential",
        "Decentralized Identity",
        "FIDO2"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf89aa4a9e3ca27de6380a24d719d401a00dd63929ea0b794171f19c33959345_w640_q70.webp",
      "contributions": "1. Proposes a novel 'Verifiable Passkey' standard to enable decentralized, privacy-preserving authentication. 2. Addresses the storage limitation of traditional FIDO2 passkeys by allowing a single passkey to be used across multiple services. 3. Mitigates the user tracking risk associated with centralized Identity Providers (IdPs) in federated SSO systems.",
      "summary": "This paper identifies the problems of limited storage for FIDO2 passkeys and privacy risks in federated SSO. It proposes a new 'Verifiable Passkey' standard that leverages Verifiable Credentials to allow a single passkey to be used across different platforms without compromising privacy. The main conclusion is that this approach provides a decentralized, scalable, and privacy-preserving alternative to current authentication methods.",
      "mindmap": "graph TB\n        A[Verifiable Passkey: The Decentralized Authentication Standard] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[Passkey存储限制/Passkey Storage Limit]\n        B --> B2[集中式IdP的隐私风险/Centralized IdP Privacy Risk]\n        C --> C1[提出可验证通行密钥标准/Propose Verifiable Passkey Standard]\n        D --> D1[去中心化认证/Decentralized Authentication]\n        D --> D2[隐私保护/Privacy Preservation]"
    },
    {
      "title": "Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation",
      "authors": "Tian Li, Bo Lin, Shangwen Wang, Yusong Tan",
      "institution": "National University of Defense Technology",
      "link": "https://arxiv.org/pdf/2512.21681",
      "code": null,
      "tags": [
        "software security",
        "backdoor attack",
        "retrieval-augmented code generation",
        "vulnerable code",
        "supply-chain vulnerability",
        "stealthy attack"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74c266d46865bfe9ae8b97f18b92cf9b8209ecd63852c6f32f3fe8533329fe2_w640_q70.webp",
      "contributions": "1. Conducted the first systematic exploration of backdoor attacks targeting the retriever component in Retrieval-Augmented Code Generation (RACG), identifying it as a critical supply-chain vulnerability. 2. Proposed VenomRACG, a new class of potent and stealthy attack that makes poisoned code statistically indistinguishable from benign code, enabling realistic threat analysis. 3. Demonstrated the severe practical impact of the attack, showing that injecting only 0.05% poisoned data can manipulate the retriever and cause downstream models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while evading current defenses.",
      "summary": "This paper investigates the security threat of backdoor attacks on the retriever in Retrieval-Augmented Code Generation (RACG). To enable a realistic analysis, the authors developed a stealthy attack called VenomRACG. Their findings reveal that this attack is highly effective and evades current defenses, posing a practical threat to the software development ecosystem.",
      "mindmap": "graph TB\n        A[Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Retriever Backdoor: 供应链漏洞/Supply-Chain Vulnerability]\n        C --> C1[VenomRACG: 隐蔽攻击/Stealthy Attack]\n        D --> D1[低投毒率有效/Low Poisoning Rate Effective]\n        D --> D2[下游模型生成漏洞代码/Downstream Model Generates Vulnerable Code]\n        D --> D3[防御机制失效/Defenses Ineffective]"
    },
    {
      "title": "Raster Domain Text Steganography: A Unified Framework for Multimodal Secure Embedding",
      "authors": "A V Uday Kiran Kandala",
      "institution": "Queen Mary University of London",
      "link": "https://arxiv.org/pdf/2512.21698",
      "code": null,
      "tags": [
        "steganography",
        "raster domain steganography",
        "glyph perturbation",
        "deterministic rasterization",
        "multimodal embedding",
        "text-based data hiding"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/86fd7815a5837b02c5d9e31511c3faca8253eee6c4c977836c3a42782decfdc2_w640_q70.webp",
      "contributions": "1. Proposes a unified Glyph Perturbation Cardinality (GPC) framework for embedding heterogeneous data (text, images, audio, video) directly into the pixel space of rendered text glyphs. 2. Operates exclusively in the raster domain after font rendering, modifying bitmap pixels with minimal, visually imperceptible intensity increments for covert communication. 3. Introduces a decoding method based on re-rasterizing cover text, subtracting canonical glyph rasters, and recovering payload via pixel count analysis, leveraging deterministic raster behavior.",
      "summary": "This paper introduces a raster domain steganography framework that embeds multimodal data into text by minimally perturbing the interior pixels of rendered glyphs. The method is visually imperceptible and computationally lightweight, enabling ordinary text to serve as a covert medium for secure data embedding. It generalizes beyond traditional linguistic steganography by operating directly on the deterministic bitmap output of text rendering pipelines.",
      "mindmap": "graph TB\n        Root(”Raster Domain Text Steganography: A Unified Framework for Multimodal Secure Embedding”) --> Problem(”核心问题/Problem: How to embed multimodal data covertly into ordinary text?”)\n        Root --> Method(”主要方法/Method: Glyph Perturbation Cardinality (GPC) Framework”)\n        Root --> Results(”关键结果/Results: Visually imperceptible, lightweight embedding in raster domain”)\n        Problem --> P1(”传统方法局限/Limitations of linguistic & structural methods”)\n        Method --> M1(”操作于栅格化后/Operates post-rasterization”)\n        Method --> M2(”扰动字形内部像素/Perturbs interior ink pixels”)\n        Method --> M3(”基于像素基数编码/Encodes via pixel cardinality”)\n        Results --> R1(”支持多模态数据/Supports multimodal data”)\n        Results --> R2(”解码稳定可靠/Stable & decodable signal”)"
    },
    {
      "title": "Machine Learning Power Side-Channel Attack on SNOW-V",
      "authors": "Deepak, Rahul Balout, Anupam Golder, Suparna Kundu, Angshuman Karmakar, Debayan Das",
      "institution": "Indian Institute of Science, Bangalore; KU Leuven; Intel Corporation; Indian Institute of Technology, Kanpur",
      "link": "https://arxiv.org/pdf/2512.21737",
      "code": null,
      "tags": [
        "side-channel analysis",
        "SNOW-V",
        "power analysis",
        "profiling attack",
        "Linear Discriminant Analysis",
        "Fully Connected Neural Network"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/317918426c0513400f22837d9127c1ab14ed2fb0ca1358968c6f98ca7da95a39_w640_q70.webp",
      "contributions": "1. Systematically evaluates the effectiveness of Side-Channel Analysis (SCA) on the SNOW-V cipher using two profiling-based machine learning techniques: Linear Discriminant Analysis (LDA) and Fully Connected Neural Networks (FCN). 2. Demonstrates progressive recovery of the secret key using these ML models, with FCN achieving a greater than 5x reduction in Minimum Traces to Disclosure (MTD) compared to the state-of-the-art CPA+LDA method. 3. Highlights the vulnerability of the 5G candidate cipher SNOW-V to machine learning-based SCA and underscores the need for robust countermeasures.",
      "summary": "This paper demonstrates a power side-channel attack on the SNOW-V stream cipher, a candidate for 5G security. Using power traces from an STM32 microcontroller, the authors employ profiling attacks with Linear Discriminant Analysis (LDA) and Fully Connected Neural Networks (FCN) for key recovery. The results show that FCN significantly outperforms prior methods, revealing SNOW-V's vulnerability to machine learning-based attacks and emphasizing the need for stronger defenses.",
      "mindmap": "graph TB\n        A[Machine Learning Power Side-Channel Attack on SNOW-V] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: SNOW-V 对侧信道攻击的脆弱性/Vulnerability of SNOW-V to Side-Channel Attacks]\n        C[主要方法/Method: 使用LDA和FCN的侧信道分析/SCA using LDA and FCN]\n        D[关键结果/Results: FCN实现>5倍MTD降低/FCN achieves >5x lower MTD]"
    },
    {
      "title": "Assessing the Effectiveness of Membership Inference on Generative Music",
      "authors": "Kurtis Chow, Omar Samiullah, Vinesh Sridhar, Hewen Zhang",
      "institution": "University of California, Irvine",
      "link": "https://arxiv.org/pdf/2512.21762",
      "code": null,
      "tags": [
        "membership inference attacks",
        "membership inference attack (MIA)",
        "generative music",
        "MuseGAN",
        "privacy",
        "copyright"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b7176fccbb69c4f0a15bfa6bcbb6ff59b09cf6ac02e0f524334f306ce4041f_w640_q70.webp",
      "contributions": "1. Conducts the first preliminary study on the effectiveness of membership inference attacks (MIAs) specifically on generative music models., 2. Evaluates several existing MIA techniques on the popular MuseGAN model to assess their performance in this domain., 3. Provides empirical evidence suggesting that generative music data is relatively resilient to known membership inference techniques, aligning with prior findings in generative audio.",
      "summary": "This paper investigates whether membership inference attacks (MIAs) are effective against generative music models. The authors conduct a preliminary study by applying several existing MIA techniques to the MuseGAN model. Their findings indicate that generative music data is fairly resilient to these known attacks.",
      "mindmap": "graph TB\n        Root[”Assessing the Effectiveness of Membership Inference on Generative Music”] --> Problem[”核心问题/Problem: Lack of MIA study on generative music, privacy & copyright concerns”]\n        Root --> Method[”主要方法/Method: Apply existing MIAs to MuseGAN model”]\n        Root --> Results[”关键结果/Results: Music data is resilient to known MIAs”]"
    },
    {
      "title": "Organizational Learning in Industry 4.0: Applying Crossan's 4I Framework with Double Loop Learning",
      "authors": "Nimra Akram, Atif Ahmad, Sean B Maynard",
      "institution": "The University of Melbourne",
      "link": "https://arxiv.org/pdf/2512.21813",
      "code": null,
      "tags": [
        "cybersecurity incident response",
        "Dynamic Security Learning",
        "double-loop learning",
        "4I framework",
        "cyber-physical systems",
        "organizational learning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/140960f0ea33407610ec595750733a88a05966b1af849210f2f418cec775a463_w640_q70.webp",
      "contributions": "1. Proposes the Advanced Dynamic Security Learning (DSL) Process Model, a novel cybersecurity incident response architecture for Industry 4.0 environments. 2. Integrates Argyris and Schön's double-loop learning theory with Crossan's 4I organizational learning framework to address proactive and reflective governance. 3. Provides a scalable and methodical approach to cybersecurity maturity that bridges operational obstacles and promotes systemic resilience in complex cyber-physical systems.",
      "summary": "This paper addresses the critical gap in cybersecurity incident response for the dynamic and decentralized operational technology (OT) systems of Industry 4.0. It proposes the Advanced Dynamic Security Learning (DSL) Process Model, which combines double-loop learning with the 4I organizational learning framework to enable proactive governance and strategic adaptation. The model aims to help organizations build systemic resilience against growing cyber threats in industrial environments.",
      "mindmap": "graph TB\n        A[Organizational Learning in Industry 4.0: Applying Crossan's 4I Framework with Double Loop Learning] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Industry 4.0 cybersecurity threats in dynamic OT systems]\n        C[主要方法/Method: DSL Model combining Double-Loop Learning & 4I Framework]\n        D[关键结果/Results: Proactive governance & systemic resilience for incident response]"
    },
    {
      "title": "Securing Cross-Domain Internet of Drones: An RFF-PUF Allied Authenticated Key Exchange Protocol With Over-the-Air Enrollment",
      "authors": "Xuanyu Chen, Yue Zheng, Junqing Zhang, Guanxiong Shen, Chip-Hong Chang",
      "institution": "The Chinese University of Hong Kong, Shenzhen; University of Liverpool; Southeast University; Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.21827",
      "code": null,
      "tags": [
        "authenticated key exchange",
        "Radio Frequency Fingerprint (RFF)",
        "Physical Unclonable Function (PUF)",
        "One-Time-Pad (OTP)",
        "ProVerif",
        "over-the-air enrollment"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad8808d2092e10128228471d5fad90003211bb9fb8e1df6bb71ef3ac783f8df8_w640_q70.webp",
      "contributions": "1. Proposes a lightweight mutual authentication protocol for IoD by integrating RFF and PUF technologies for secure D2D and D2G communication. 2. Achieves over-the-air enrollment using RFF-based device identification and uses PUF as a root of trust, eliminating the need for secret storage in drones. 3. Co-designs PUF's on-the-fly key generation with OTP encryption for ephemeral keying and demonstrates security resilience through formal verification with ProVerif.",
      "summary": "This paper proposes a lightweight authenticated key exchange protocol for securing cross-domain Internet of Drones (IoD). The method integrates Radio Frequency Fingerprint (RFF) for over-the-air enrollment and Physical Unclonable Function (PUF) as a root of trust to enable mutual authentication and ephemeral keying without storing secrets on drones. The protocol is shown to be resilient against common attacks and outperforms existing schemes in security features and overhead.",
      "mindmap": "graph TB\n        A[Securing Cross-Domain IoD: RFF-PUF Protocol] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[IoD安全挑战/Security Challenges in IoD]\n        B1 --> B2[高开销与依赖第三方/High Overhead & Third-Party Reliance]\n        C --> C1[轻量级认证协议/Lightweight Authentication Protocol]\n        C1 --> C2[集成RFF与PUF/Integrating RFF & PUF]\n        C2 --> C3[RFF用于空中注册/RFF for OTA Enrollment]\n        C2 --> C4[PUF作为信任根/PUF as Root of Trust]\n        C4 --> C5[PUF+OTP实现临时密钥/PUF+OTP for Ephemeral Keying]\n        D --> D1[抵抗常见攻击/Resilient to Common Attacks]\n        D --> D2[优于现有方案/Outperforms Existing Schemes]\n        D2 --> D3[安全特性与开销/Security Features & Overhead]"
    },
    {
      "title": "Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?",
      "authors": "Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji",
      "institution": "Zhejiang University, University of California, Los Angeles, Palo Alto Networks",
      "link": "https://arxiv.org/pdf/2512.21871",
      "code": "https://github.com/bluedream02/CopyGuard",
      "tags": [
        "multi-modal inference",
        "copyright compliance",
        "vision-language models",
        "tool-augmented defense",
        "benchmark dataset",
        "multimodal query"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp",
      "contributions": "1. Introduced a large-scale benchmark dataset of 50,000 multimodal query-content pairs to evaluate copyright compliance in LVLMs. 2. Conducted a comprehensive evaluation revealing significant deficiencies in state-of-the-art LVLMs' ability to recognize and respect copyrighted content. 3. Proposed a novel tool-augmented defense framework to reduce copyright infringement risks in LVLM inference.",
      "summary": "This paper evaluates how large vision-language models (LVLMs) handle copyrighted visual content and finds they often fail to comply with copyright regulations. To address this, the authors propose a tool-augmented defense framework for copyright compliance. The work highlights the need for developing copyright-aware LVLMs to ensure responsible use.",
      "mindmap": "graph TB\n        Root[”Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?”]\n        Root --> Problem[”核心问题/Problem: LVLMs may infringe copyright when processing visual inputs”]\n        Root --> Method[”主要方法/Method: Benchmark dataset & Tool-augmented defense framework”]\n        Root --> Results[”关键结果/Results: Current LVLMs are deficient; Proposed framework reduces risk”]"
    },
    {
      "title": "Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models",
      "authors": "Zongmin Zhang, Zhen Sun, Yifan Liao, Wenhan Dong, Xinlei He, Xingshuo Han, Shengmin Xu, Xinyi Huang",
      "institution": "Hong Kong University of Science and Technology (Guangzhou), Nanjing University of Aeronautics and Astronautics, Fujian Normal University, Jinan University",
      "link": "https://arxiv.org/pdf/2512.22046",
      "code": null,
      "tags": [
        "backdoor attacks",
        "video segmentation foundation models",
        "backdoor attack",
        "two-stage training",
        "gradient analysis",
        "attention shift"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a7e9ff0ffc63f2085d6ca65db8e87f14fed435be5d8a51fd3d1265b22b668b1_w640_q70.webp",
      "contributions": "1. Identifies the ineffectiveness of classic backdoor attacks on prompt-driven Video Segmentation Foundation Models (VSFMs) and provides analysis via gradient and attention maps. 2. Proposes BadVSFM, the first dedicated backdoor attack framework for VSFMs, using a novel two-stage training strategy to separate clean and triggered representations. 3. Demonstrates strong, controllable attack performance across multiple models and datasets while preserving clean-task accuracy, and shows the vulnerability persists against existing defenses.",
      "summary": "This paper identifies that standard backdoor attacks fail on prompt-driven Video Segmentation Foundation Models (VSFMs) like SAM2. To solve this, the authors propose BadVSFM, a two-stage backdoor attack framework that successfully implants a controllable backdoor by steering the encoder and decoder separately. Experiments show the attack is effective and evades current defenses, revealing a significant security vulnerability in VSFMs.",
      "mindmap": "graph TB\n        A[Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Classic backdoor attacks fail on VSFMs (ASR<5%)]\n        C[主要方法/Method: BadVSFM - Two-stage training (steer encoder, train decoder)]\n        D[关键结果/Results: High ASR, preserves clean performance, defenses ineffective]"
    },
    {
      "title": "Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management",
      "authors": "Sunil Arora, John Hastings",
      "institution": "Dakota State University",
      "link": "https://arxiv.org/pdf/2512.22060",
      "code": null,
      "tags": [
        "AI Governance & Compliance",
        "lifecycle management",
        "bias detection",
        "differential privacy",
        "federated learning",
        "terminology drift"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/113703d05215aac7e8678f24cb38d882fa4c99927066ea2264ef3d1b4c3a1d67_w640_q70.webp",
      "contributions": "1. Proposes the SC-NLP-LMF, a comprehensive six-phase framework for secure and compliant NLP model lifecycle management. 2. Integrates established technical methods (e.g., bias detection, differential privacy) with leading organizational standards (e.g., NIST AI RMF, EU AI Act). 3. Validates the framework's practicality through a healthcare case study demonstrating detection of and response to terminology drift.",
      "summary": "This paper introduces the Secure and Compliant NLP Lifecycle Management Framework (SC-NLP-LMF), a six-phase model developed from a systematic review to address security, privacy, and compliance risks in NLP systems. It integrates methods like bias detection and differential privacy with standards like NIST AI RMF and the EU AI Act. The framework provides a practical structure for organizations to manage NLP systems in high-risk environments, as illustrated by a healthcare case study on handling terminology drift.",
      "mindmap": "graph TB\n        Root[”Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>NLP systems in sensitive domains face unaddressed security, privacy, and compliance risks.”]\n        Method[”主要方法/Method<br>Proposes SC-NLP-LMF, a six-phase framework integrating standards (NIST, ISO, EU AI Act) and techniques (bias detection, differential privacy).”]\n        Results[”关键结果/Results<br>Provides a practical lifecycle structure for secure, accountable NLP systems, validated via a healthcare case study.”]"
    },
    {
      "title": "ReSMT: An SMT-Based Tool for Reverse Engineering",
      "authors": "Nir Somech, Guy Katz",
      "institution": "The Hebrew University of Jerusalem",
      "link": "https://arxiv.org/pdf/2512.22076",
      "code": null,
      "tags": [
        "reverse engineering",
        "SMT solving",
        "deobfuscation",
        "logical assertions",
        "automated analysis"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/910bd3ef1ea1d824f29ec5a3c12c77ea64068337777edd67f0de1e2b98014c86_w640_q70.webp",
      "contributions": "1. A novel automated tool (ReSMT) that converts obfuscated assembly code into a system of logical assertions for analysis. 2. An approach that applies SMT solving and simulation to inspect obfuscated code execution, reducing the need for specialized manual skills. 3. Demonstration of the tool's effectiveness through a successful case study on complex, obfuscated code.",
      "summary": "The paper presents ReSMT, an automated tool that addresses the difficulty of reverse engineering obfuscated code by transforming it into logical assertions and using SMT solvers for analysis. This method reduces reliance on expert manual deobfuscation. A case study shows ReSMT can successfully answer queries about complex obfuscated code, demonstrating its potential utility.",
      "mindmap": "graph TB\n        A[ReSMT: An SMT-Based Tool for Reverse Engineering] --> B(核心问题/Problem: Reverse engineering obfuscated code is difficult and slow)\n        A --> C(主要方法/Method: Convert assembly to logical assertions, apply SMT solving and simulation)\n        A --> D(关键结果/Results: Tool successfully tackled complex code in a case study)"
    },
    {
      "title": "Abstraction of Trusted Execution Environments as the Missing Layer for Broad Confidential Computing Adoption: A Systematization of Knowledge",
      "authors": "Quentin Michaud, Sara Ramezanian, Dhouha Ayed, Olivier Levillain, Joaquin Garcia-Alfaro",
      "institution": "Télécom SudParis, Institut Polytechnique de Paris, Thales, Lund University, Karlstad University",
      "link": "https://arxiv.org/pdf/2512.22090",
      "code": null,
      "tags": [
        "trusted execution environments",
        "Trusted Execution Environments",
        "Confidential Computing",
        "Abstraction Layer",
        "WebAssembly",
        "Systematization of Knowledge"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e9b906f168ce76656e0e7d95497572cc5edc40d2ad1966cd32644ac97261bb7_w640_q70.webp",
      "contributions": "1. Provides a comprehensive overview and classification of existing TEE technologies based on their design choices. 2. Proposes a systematization of knowledge (SoK) focusing on abstraction layers for TEEs to unify the confidential computing ecosystem. 3. Identifies WebAssembly as a promising approach for abstraction and discusses future research directions for integrating abstraction layers.",
      "summary": "This paper addresses the fragmentation in Trusted Execution Environment (TEE) technologies by proposing abstraction layers as a solution to unify the confidential computing ecosystem. It conducts a systematization of knowledge, reviewing and classifying TEE designs and their corresponding abstraction layers. The study concludes that WebAssembly is a promising abstraction approach and highlights opportunities for future research to improve and integrate these layers.",
      "mindmap": "graph TB\n        Root[Abstraction of TEEs as the Missing Layer for Broad Confidential Computing Adoption] --> Problem[核心问题/Problem: Fragmentation of TEE technologies hinders broad adoption]\n        Root --> Method[主要方法/Method: Systematization of Knowledge on TEEs and abstraction layers]\n        Root --> Results[关键结果/Results: WebAssembly is a promising abstraction; Future research directions identified]"
    },
    {
      "title": "When the Base Station Flies: Rethinking Security for UAV-Based 6G Networks",
      "authors": "Ammar El Falou",
      "institution": "King Abdullah University of Science and Technology (KAUST)",
      "link": "https://arxiv.org/pdf/2512.21574",
      "code": null,
      "tags": [
        "wireless network security",
        "UAV-BS",
        "non-terrestrial networks (NTN)",
        "denial-of-service (DoS)",
        "GNSS spoofing",
        "handover manipulation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9bf0cf9e709be88409d70b055d12514f5509bc714ec219eefb408d1ab8fbe51_w640_q70.webp",
      "contributions": "1. Identifies unique security vulnerabilities introduced by mobile, wireless, and resource-constrained UAV base stations in 6G networks. 2. Outlines specific attack surfaces for UAV-BS systems, including emergency alert spoofing, DoS, jamming, and malicious handover manipulation. 3. Proposes principles and mitigation techniques for securing the architecture of UAV-based non-terrestrial networks.",
      "summary": "This paper analyzes the security challenges of using unmanned aerial vehicles (UAVs) as mobile base stations in 6G non-terrestrial networks. It identifies new attack vectors due to their mobility, wireless backhaul, and resource constraints, and outlines principles for mitigating these threats to build a secure architecture.",
      "mindmap": "graph TB\n    Root(”When the Base Station Flies: Rethinking Security for UAV-Based 6G Networks”) --> Problem(”核心问题/Problem”)\n    Root --> Method(”主要方法/Method”)\n    Root --> Results(”关键结果/Results”)\n    Problem --> P1(”UAV-BS引入新安全挑战/New Security Challenges from UAV-BS”)\n    Problem --> P2(”易受DoS、欺骗、干扰攻击/Vulnerable to DoS, Spoofing, Jamming”)\n    Method --> M1(”识别攻击面/Identify Attack Surfaces”)\n    Method --> M2(”提出缓解原则/Outline Mitigation Principles”)\n    Results --> R1(”为安全6G架构提供指导/Provide Guidance for Secure 6G Architecture”)"
    },
    {
      "title": "How Feasible are Passive Network Attacks on 5G Networks and Beyond? A Survey",
      "authors": "Atmane Ayoub Mansour Bahar, Andrés Alayón Glazunov, Romaric Duvignau",
      "institution": "Chalmers University of Technology and University of Gothenburg, Linköping University",
      "link": "https://arxiv.org/pdf/2512.20622",
      "code": null,
      "tags": [
        "network security",
        "passive network attacks",
        "5G",
        "beamforming",
        "encryption",
        "geolocation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/46b5a08db22dceb9bf9c444c5b6f5063e52245750a982f3a268cb84f22c9c640_w640_q70.webp",
      "contributions": "1. A comprehensive survey examining the feasibility of passive network attacks specifically in 5G and B5G/6G networks, 2. A structured analysis focusing on two major attack categories: information extraction (system ID, fingerprinting) and geolocation (user ID, tracking), 3. An assessment concluding that while attacks are theoretically possible in 5G, practical execution is constrained by new features like directional beamforming, and that attacks are currently infeasible in B5G/6G due to tool and hardware limitations.",
      "summary": "This survey investigates the feasibility of passive network attacks, which are hard to detect, on 5G and future mobile networks. It analyzes two main categories: information extraction and geolocation. The key finding is that while such attacks remain theoretically possible in 5G, practical execution is significantly hindered by technical features like beamforming and encryption, and they are currently infeasible in B5G/6G networks due to a lack of tools and high hardware costs.",
      "mindmap": "graph LR\n    A[How Feasible are Passive Network Attacks on 5G Networks and Beyond? A Survey] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[5G部署增加隐私风险 / 5G deployment increases privacy risks]\n    B --> B2[被动攻击难以检测 / Passive attacks are hard to detect]\n    C --> C1[调查可行性 / Survey feasibility]\n    C --> C2[分析信息提取与地理定位攻击 / Analyze info extraction & geolocation attacks]\n    D --> D1[5G: 理论可能, 实践受限 / 5G: Theoretically possible, practically constrained]\n    D --> D2[B5G/6G: 目前不可行 / B5G/6G: Currently infeasible]"
    },
    {
      "title": "Topology and Network Dynamics of the Lightning Network: A Comprehensive Analysis",
      "authors": "Danila Valko, Jorge Marx Gómez",
      "institution": "Carl von Ossietzky Universität Oldenburg, OFFIS – Institute for Information Technology",
      "link": "https://arxiv.org/pdf/2512.20641",
      "code": null,
      "tags": [
        "network topology analysis",
        "Lightning Network",
        "Payment Channel Networks",
        "Topological Stability",
        "Temporal Network Analysis",
        "Heuristic-based Routing"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a8847e5808205e6e481ce142d2069ee336c2c36ee4c39f42a1038800c675835_w640_q70.webp",
      "contributions": "1. Provides a comprehensive analysis of the Lightning Network's topology using 47 metrics over a five-year dataset (2019-2023). 2. Quantifies the network's topological stability over time, offering new insights into its structural evolution. 3. Derives implications for the design of heuristic-based pathfinding and routing protocols in Payment Channel Networks.",
      "summary": "This paper conducts a comprehensive temporal analysis of the Lightning Network's topology using a five-year dataset. By computing 47 network metrics, it characterizes the network's structure and evolution, quantifying its topological stability. The findings support the design of improved routing protocols and provide a detailed characterization for future network science research.",
      "mindmap": "graph LR\n    A[Topology and Network Dynamics of the Lightning Network] --> B(核心问题/Problem: Analyze LN's structural evolution & stability)\n    A --> C(主要方法/Method: Compute 47 metrics on 5-year topology snapshots)\n    A --> D(关键结果/Results: Quantified topological stability; Implications for routing protocols)"
    },
    {
      "title": "AIAuditTrack: A Framework for AI Security system",
      "authors": "Zixun Luo, Yuhang Fan, Yufei Li, Youzhi Zhang, Hengyu Lin, Ziqi Wang",
      "institution": "Huazhong University of Science and Technology, Lingnan University, Centre for Artificial Intelligence and Robotics (CAIR) Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences, Tsinghua University, Fujian Jiangxia University",
      "link": "https://arxiv.org/pdf/2512.20649",
      "code": null,
      "tags": [
        "AI governance and auditing",
        "blockchain",
        "decentralized identity (DID)",
        "verifiable credentials (VC)",
        "risk diffusion algorithm",
        "interaction graph"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74b6835bdebf655288e51122fb875aaa032b286789052e6467724b2eb1e0af84_w640_q70.webp",
      "contributions": "1. Proposes a blockchain-based framework (AiAuditTrack) for recording and governing AI usage traffic to enable auditing and risk traceability. 2. Introduces an identity management mechanism using Decentralized Identity (DID) and Verifiable Credentials (VC) to establish trusted and identifiable AI entities. 3. Designs a risk diffusion algorithm on a dynamic interaction graph model to trace the source of risky behaviors and propagate warnings.",
      "summary": "This paper addresses the security and accountability challenges in AI-driven applications by proposing AiAuditTrack, a blockchain framework that uses decentralized identity and verifiable credentials to record AI interaction data and enable auditing. It models AI entities as nodes in a graph and introduces a risk diffusion algorithm for tracing risky behavior origins. The framework's feasibility is demonstrated through blockchain performance metrics (TPS) under large-scale recording scenarios.",
      "mindmap": "graph LR\n    A[AiAuditTrack: AI安全系统框架<br>AiAuditTrack: AI Security System Framework] --> B[核心问题/Problem: AI交互数据激增导致安全与责任归属挑战<br>Explosive AI interaction data raises security & accountability issues]\n    A --> C[主要方法/Method: 基于区块链的框架，使用DID/VC进行身份管理，设计风险扩散算法<br>Blockchain-based framework with DID/VC for identity & risk diffusion algorithm]\n    A --> D[关键结果/Results: 实现可验证的AI审计与风险溯源，系统在大规模记录下稳定<br>Enables verifiable AI auditing & risk tracing, system stable at scale]"
    },
    {
      "title": "Automated Red-Teaming Framework for Large Language Model Security Assessment: A Comprehensive Attack Generation and Detection System",
      "authors": "Zhang Wei, Peilu Hu, Shengning Lang, Hao Yan, Li Mei, Yichao Zhang, Chen Yang, Junfeng Hao, Zhimo Han",
      "institution": "Stevens Institute of Technology, The University of Texas at Dallas, AI Safety Research Lab (Institute of Advanced Computing, Shenzhen), Zheng Zhou University of Light Industry, Affiliated Hospital of Guangdong Medical University",
      "link": "https://arxiv.org/pdf/2512.20677",
      "code": null,
      "tags": [
        "llm security assessment",
        "automated red-teaming",
        "adversarial prompts",
        "meta-prompting",
        "vulnerability detection",
        "alignment robustness"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/35d6a91284e231b153dfe35185eb27aafd1549063ba05304240c7a14c0b8f78d_w640_q70.webp",
      "contributions": "1. Introduces an automated framework for systematic generation, execution, and evaluation of adversarial prompts against LLMs. 2. Integrates meta-prompting-based attack synthesis and multi-modal detection across six major threat categories (e.g., reward hacking, deceptive alignment). 3. Demonstrates significant improvement in vulnerability discovery rate (3.9x over manual testing) with high detection accuracy (89%) on a target model.",
      "summary": "This paper proposes an automated red-teaming framework to systematically find security vulnerabilities in large language models. The framework uses meta-prompting to generate attacks and multi-modal detection to evaluate them across six threat categories. Experiments show it discovers vulnerabilities much faster than manual testing while maintaining high accuracy, enabling scalable AI safety evaluations.",
      "mindmap": "graph LR\n    A[Automated Red-Teaming Framework for LLM Security] --> B[核心问题/Problem: Manual red-teaming is not scalable for comprehensive LLM security assessment]\n    A --> C[主要方法/Method: Automated framework with meta-prompting attack synthesis & multi-modal vulnerability detection]\n    A --> D[关键结果/Results: 3.9x faster vulnerability discovery, 89% detection accuracy, 47 vulnerabilities found]"
    },
    {
      "title": "Anota: Identifying Business Logic Vulnerabilities via Annotation-Based Sanitization",
      "authors": "Meng Wang, Philipp Görz, Joschua Schilling, Keno Hassler, Liwei Guo, Thorsten Holz, Ali Abbasi",
      "institution": "CISPA Helmholtz Center for Information Security, University of Electronic Science and Technology, Max Planck Institute for Security and Privacy",
      "link": "https://arxiv.org/pdf/2512.20705",
      "code": null,
      "tags": [
        "vulnerability detection",
        "business logic vulnerabilities",
        "annotation-based sanitization",
        "human-in-the-loop",
        "fuzzing",
        "dynamic analysis"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7caa30a9225683b8242f9b5f327094c8a903deba3bbf3f5f13252c818b00e60d_w640_q70.webp",
      "contributions": "1. Proposes ANOTA, a novel human-in-the-loop sanitizer framework that uses lightweight user annotations to encode domain-specific knowledge and define intended application behavior. 2. Introduces a runtime execution monitor that compares observed program behavior against the annotation-defined policies to identify deviations indicative of business logic vulnerabilities. 3. Demonstrates the framework's effectiveness by integrating it with a fuzzer, outperforming other methods by reproducing 43 known vulnerabilities and discovering 22 new ones (17 assigned CVEs).",
      "summary": "The paper addresses the challenge of detecting business logic vulnerabilities, which are often missed by traditional fuzzing sanitizers. It proposes ANOTA, a framework where users define intended behavior via annotations, and a runtime monitor detects deviations. Evaluation shows ANOTA combined with a fuzzer effectively finds such vulnerabilities, reproducing 43 known and discovering 22 new ones.",
      "mindmap": "graph LR\n    A[Anota: Identifying Business Logic Vulnerabilities] --> B[核心问题/Problem: Traditional sanitizers fail to detect business logic vulnerabilities]\n    A --> C[主要方法/Method: Human-in-the-loop annotation system to define intended behavior]\n    A --> D[关键结果/Results: ANOTA+FUZZER found 43 known and 22 new vulnerabilities]"
    },
    {
      "title": "Real-World Adversarial Attacks on RF-Based Drone Detectors",
      "authors": "Omer Gazit, Yael Itzhakev, Yuval Elovici, Asaf Shabtai",
      "institution": "Ben-Gurion University of the Negev",
      "link": "https://arxiv.org/pdf/2512.20712",
      "code": null,
      "tags": [
        "adversarial machine learning",
        "adversarial attack",
        "drone detection",
        "radio frequency (RF)",
        "over-the-air (OTA)",
        "I/Q perturbation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/384206c86ac50ef9b9d711e77f0b2e691640ea7831fb12c1517a40575d8c07f3_w640_q70.webp",
      "contributions": "1. The first physical adversarial attack targeting image-based object detection models for RF-based drone detection. 2. A novel method that optimizes adversarial perturbations directly in the complex baseband (I/Q) domain for over-the-air transmission. 3. Demonstration of the attack's effectiveness and hardware compatibility through both digital and physical (OTA) evaluations with multiple drone types.",
      "summary": "This paper proposes the first physical adversarial attack against RF-based drone detectors. Instead of modifying digital spectrogram images, the method generates and transmits optimized I/Q perturbation waveforms alongside legitimate drone signals. The results show these structured perturbations are compatible with standard RF hardware and reliably reduce target drone detection while maintaining detection of legitimate ones.",
      "mindmap": "graph LR\n    A[Real-World Adversarial Attacks on RF-Based Drone Detectors] --> B(核心问题/Problem: Digital RF attacks are hard to implement over-the-air)\n    A --> C(主要方法/Method: Generate & transmit I/Q perturbation waveforms)\n    A --> D(关键结果/Results: Perturbations reduce target detection, preserve others, are hardware-compatible)"
    },
    {
      "title": "SoK: Speedy Secure Finality",
      "authors": "Yash Saraswat, Abhimanyu Nag",
      "institution": "Indian Institute of Technology, Roorkee; University of Alberta",
      "link": "https://arxiv.org/pdf/2512.20715",
      "code": null,
      "tags": [
        "blockchain consensus",
        "finality",
        "consensus protocol",
        "Ethereum",
        "Gasper",
        "reorg resilience"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/280bac4449b7f86317e6367c908a04f23445bf30d94bffc4957a4d305fac0548_w640_q70.webp",
      "contributions": "1. Provides a systematic survey of the state-of-the-art in Speedy Secure Finality (SSF) protocols, tracing their evolution from foundational works like Goldfish to RLMD-GHOST. 2. Introduces and explains core theoretical primitives for understanding SSF, such as reorganization resilience and the generalized sleepy model. 3. Analyzes the practical trade-offs of Single Slot Finality and surveys the 3-Slot Finality (3SF) protocol as a pragmatic solution balancing fast finality with Ethereum's engineering constraints.",
      "summary": "This paper surveys research on Speedy Secure Finality (SSF) to reduce the long confirmation latency in Ethereum's Gasper protocol. It reviews the evolution of fast finality protocols, analyzes their design trade-offs, and highlights the 3-Slot Finality protocol as a practical synthesis. The main conclusion is that 3SF offers a viable path to achieve faster, secure finality while addressing the network's practical limitations.",
      "mindmap": "graph LR\n    A[SoK: Speedy Secure Finality] --> B[核心问题/Problem: Ethereum Gasper协议15分钟最终确认延迟导致重组攻击和MEV提取]\n    A --> C[主要方法/Method: 系统综述快速最终性协议，分析单时隙最终性的瓶颈，调查3时隙最终性协议]\n    A --> D[关键结果/Results: 3SF协议在理论安全保证与工程约束间取得平衡，是实用的快速最终性方案]"
    },
    {
      "title": "Towards a Security Plane for 6G Ecosystems",
      "authors": "Xavi Masip-Bruin, Eva Rodríguez, Admela Jukan, Panos Trakadas",
      "institution": "Universitat Politècnica de Catalunya (UPC), Technische Universität Carolo-Wilhelmina zu Braunschweig, National and Kapodistrian University of Athens",
      "link": "https://arxiv.org/pdf/2512.20733",
      "code": null,
      "tags": [
        "network security",
        "Security Plane",
        "6G networks",
        "proactive security",
        "softwarized solution",
        "predictive models"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e2926f67c046b6b5db7319c0fdbdfbcf59eca521cb5919ee0309b4ed87a4b64_w640_q70.webp",
      "contributions": "1. Proposes a novel Security Plane architecture for 6G ecosystems, 2. Introduces a proactive strategy using programmable and adaptable \"live\" Security Functions, 3. Incorporates a pre-assessment scenario to verify actions from predictive models before deployment.",
      "summary": "This positioning paper addresses the security challenges of emerging 6G networks by proposing a softwarized Security Plane. The solution employs a proactive strategy with programmable security functions and a pre-assessment verification step to handle uncertainties. The authors argue this paradigm shift is essential for reliable security provisioning in future 6G ecosystems.",
      "mindmap": "graph LR\n    A[Towards a Security Plane for 6G Ecosystems] --> B(核心问题/Problem: 6G网络需要可靠安全/6G networks need reliable security)\n    A --> C(主要方法/Method: 基于可编程安全功能的主动式安全平面/Proactive Security Plane with programmable functions)\n    A --> D(关键结果/Results: 提出新范式应对安全挑战/Proposed new paradigm to face security challenges)"
    },
    {
      "title": "Sark: Oblivious Integrity Without Global State",
      "authors": "Alex Lynham, David Alesch, Ziyi Li, Geoff Goodell",
      "institution": "University College London (UCL)",
      "link": "https://arxiv.org/pdf/2512.20775",
      "code": null,
      "tags": [
        "distributed ledger systems",
        "oblivious integrity",
        "crash fault-tolerant blockchain",
        "integrity locus",
        "USO asset system",
        "local centrality"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b30bc13516511718c7bc6ed68789e79948291909f0ae043653903321e5a6bcc_w640_q70.webp",
      "contributions": "1. Presents Sark, a reference architecture implementing the Unforgeable, Stateful, and Oblivious (USO) asset system for oblivious, non-custodial asset management. 2. Introduces the concept of \"Integrity Locus\" as a framework to analyze and address design trade-offs related to decentralization. 3. Describes the design and implementation of Sloop, a permissioned crash fault-tolerant (CFT) blockchain, and Porters, subsystems that form the core of the Sark architecture.",
      "summary": "This paper introduces Sark, a distributed system architecture designed for managing assets with oblivious integrity, eliminating the need for a global state ledger. Its core components include the Sloop blockchain and Porters for handling client commitments, analyzed through the CIA triad. The main conclusion is that Sark offers a more decentralized trust topology by leveraging local integrity proofs instead of a global ledger, though it introduces trade-offs like local centrality.",
      "mindmap": "graph LR\n        A[Sark: Oblivious Integrity Without Global State] --> B(核心问题/Problem: How to achieve asset integrity without a global state ledger?);\n        A --> C(主要方法/Method: Implement USO asset system with Sloop CFT blockchain & Porters);\n        A --> D(关键结果/Results: Decentralized via local integrity proofs, introduces Integrity Locus concept);"
    },
    {
      "title": "pokiSEC: A Multi-Architecture, Containerized Ephemeral Malware Detonation Sandbox",
      "authors": "Alejandro Avina, Yashas Hariprasad, Naveen Kumar Chaudhary",
      "institution": "California State University, East Bay, National Forensic Sciences University",
      "link": "https://arxiv.org/pdf/2512.20860",
      "code": "https://github.com/PanLuvme/pokiSEC",
      "tags": [
        "malware analysis",
        "Docker",
        "QEMU",
        "KVM",
        "Universal Entrypoint",
        "ephemeral container"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58898439e3246ec551b562bfb2380c7db3d016ac4d87b780a7f10e905d0bdaef_w640_q70.webp",
      "contributions": "1. A lightweight, ephemeral malware detonation sandbox packaged entirely inside a Docker container, integrating QEMU with hardware acceleration and a browser-based workflow. 2. A Universal Entrypoint that performs runtime host-architecture detection and selects validated hypervisor configurations, enabling a single container to launch Windows guests on both ARM64 and x86_64 hosts. 3. Validation of the system on Apple Silicon (ARM64) and Ubuntu (AMD64), demonstrating interactive performance suitable for analyst workflows and consistent teardown via ephemeral container lifecycles.",
      "summary": "This paper presents pokiSEC, a containerized sandbox for dynamic malware analysis that packages QEMU and a browser interface into a Docker container to improve portability and automation. Its key innovation is a Universal Entrypoint that detects the host architecture and configures the hypervisor accordingly, allowing the same container to run on both ARM64 and x86_64 systems. The system was validated on Apple Silicon and Ubuntu, showing it provides interactive performance and clean isolation through ephemeral containers.",
      "mindmap": "graph LR\n    A[pokiSEC: 多架构容器化恶意软件引爆沙盒] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[恶意软件动态分析环境笨重且缺乏跨架构可移植性/Dynamic malware analysis environments are heavyweight and lack cross-architecture portability]\n    C --> C1[基于Docker的轻量级沙盒，集成QEMU与KVM/Lightweight sandbox in Docker container with QEMU and KVM]\n    C --> C2[通用入口点进行运行时架构检测与配置/Universal Entrypoint for runtime host-architecture detection and configuration]\n    D --> D1[在ARM64和x86_64主机上验证成功/Validated on ARM64 and x86_64 hosts]\n    D --> D2[提供交互式性能与一致的临时容器生命周期/Provides interactive performance and consistent ephemeral container lifecycle]"
    },
    {
      "title": "Better Call Graphs: A New Dataset of Function Call Graphs for Malware Classification",
      "authors": "Jakir Hossain, Gurvinder Singh, Lukasz Ziarek, Ahmet Erdem Sarıyüce",
      "institution": "University at Buffalo",
      "link": "https://arxiv.org/pdf/2512.20872",
      "code": "https://erdemub.github.io/BCG-dataset",
      "tags": [
        "malware detection",
        "function call graphs",
        "Android malware",
        "graph-based classification",
        "APK",
        "dataset"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87c9a8db7055364694bd0257a161b2a24a77226da1ab49504cd20679d8699222_w640_q70.webp",
      "contributions": "1. Introduces the Better Call Graphs (BCG) dataset, a new large-scale collection of unique and recent Android FCGs for malware classification., 2. Addresses limitations of existing datasets (outdated, redundant, small graphs) to prevent overfitting and enable reliable evaluation., 3. Demonstrates the necessity and value of the BCG dataset through extensive experiments with baseline classifiers.",
      "summary": "This paper addresses the lack of high-quality datasets for Android malware classification using function call graphs (FCGs). It introduces the Better Call Graphs (BCG) dataset, which contains large, unique, and recent FCGs from Android APKs. Experiments show BCG is necessary for reliable evaluation and helps overcome overfitting issues present with older datasets.",
      "mindmap": "graph LR\n    A[Better Call Graphs: A New Dataset of Function Call Graphs for Malware Classification] --> B(核心问题/Problem: Lack of large-scale, high-quality Android FCG datasets hinders malware classification research)\n    A --> C(主要方法/Method: Introduce BCG dataset with large, unique, recent Android APK FCGs)\n    A --> D(关键结果/Results: BCG enables more reliable evaluation and addresses overfitting compared to existing datasets)"
    },
    {
      "title": "Neutralization of IMU-Based GPS Spoofing Detection using external IMU sensor and feedback methodology",
      "authors": "Ji Hyuk Jung, Ji Won Yoon",
      "institution": "Korea University",
      "link": "https://arxiv.org/pdf/2512.20964",
      "code": null,
      "tags": [
        "GPS spoofing",
        "sensor fusion security",
        "GPS Spoofing",
        "IMU Sensor",
        "EKF Sensor Fusion",
        "Anomaly Detection",
        "Autonomous Vehicles"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd9c070e907e0838508f993530edb77577a0cb6b2e778d6fd9e55f8ce61ed915_w640_q70.webp",
      "contributions": "1. Proposes a novel attack model to neutralize IMU-based GPS spoofing detection systems. 2. Introduces a methodology using an external IMU sensor to steal internal dynamic state information for feedback. 3. Provides experimental analysis based on EKF sensor fusion demonstrating successful undetected value injection.",
      "summary": "This paper proposes a GPS spoofing attack system designed to bypass detection mechanisms that rely on internal IMU sensors. The method uses an external IMU to steal a vehicle's dynamic state information and feed it back to craft spoofing signals that align with the target's internal sensor fusion model. Experimental results show that this approach can inject false GPS data without triggering anomaly detection.",
      "mindmap": "graph LR\n    A[论文标题/Paper Title: Neutralization of IMU-Based GPS Spoofing Detection] --> B[核心问题/Problem: IMU-based detection thwarts GPS spoofing attacks on AVs]\n    A --> C[主要方法/Method: Use external IMU sensor & feedback to craft aligned spoofing signals]\n    A --> D[关键结果/Results: Attack values injected without detection]"
    },
    {
      "title": "AegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs",
      "authors": "Yihan Wang, Huanqi Yang, Shantanu Pal, Weitao Xu",
      "institution": "City University of Hong Kong, Deakin University",
      "link": "https://arxiv.org/pdf/2512.20986",
      "code": null,
      "tags": [
        "prompt injection defense",
        "autonomous agent",
        "semantic inconsistency reasoning",
        "dynamic memory",
        "verification and repair plan",
        "LLM-HAR security"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5eaecc4adef06aae596e51f6054c2fcc844292069d235bff82f251bd33e02a8a_w640_q70.webp",
      "contributions": "1. Proposes a paradigm shift from passive filtering to active, autonomous protection for securing LLM-based Human Activity Recognition (HAR) systems. 2. Introduces AegisAgent, an autonomous agent that acts as a cognitive guardian, capable of perceiving semantic inconsistencies, reasoning about user intent using dynamic memory, and executing multi-step verification plans. 3. Provides a systematic evaluation demonstrating that AegisAgent significantly reduces attack success rates with minimal latency overhead, establishing a foundation for trustworthy LLM-HAR systems.",
      "summary": "This paper addresses the vulnerability of LLM-based Human Activity Recognition (HAR) systems to prompt injection attacks. It proposes AegisAgent, an autonomous defense agent that actively reasons about semantic inconsistencies and user intent to verify and repair inputs. Evaluation shows it effectively reduces attack success rates with low performance overhead.",
      "mindmap": "graph LR\n    A[AegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs] --> B[核心问题/Problem: LLM-HAR系统易受提示注入攻击/LLM-HAR systems are vulnerable to prompt injection attacks]\n    A --> C[主要方法/Method: 自主代理进行语义推理与修复/Autonomous agent for semantic reasoning and repair]\n    A --> D[关键结果/Results: 攻击成功率降低30%，延迟开销仅78.6ms/Attack success rate reduced by 30%, 78.6ms latency overhead]"
    },
    {
      "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs",
      "authors": "Lichao Wu, Sasha Behrouzi, Mohamadreza Rostami, Stjepan Picek, Ahmad-Reza Sadeghi",
      "institution": "Technical University of Darmstadt, University of Zagreb, Radboud University",
      "link": "https://arxiv.org/pdf/2512.21008",
      "code": null,
      "tags": [
        "adversarial attacks",
        "Mixture-of-Experts",
        "safety alignment",
        "adversarial attack",
        "sparse routing",
        "neuron ablation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88f0ff9ac904d6732695b0ffa19ff6dd8569eca21d49a3f730ed81276400e8a0_w640_q70.webp",
      "contributions": "1. Proposes GateBreaker, the first training-free, lightweight, and architecture-agnostic attack framework to compromise the safety alignment of MoE LLMs at inference time. 2. Demonstrates that safety in MoE models is concentrated in a small subset of neurons coordinated by sparse routing, and disabling ~3% of targeted neurons significantly increases attack success rates. 3. Shows the attack's effectiveness transfers across model families and generalizes to MoE-based Vision Language Models (VLMs).",
      "summary": "This paper introduces GateBreaker, a novel attack framework that exploits the routing mechanisms in Mixture-of-Expert (MoE) Large Language Models to compromise their safety alignment. The method works by profiling safety-critical experts, localizing key safety neurons, and selectively disabling them, leading to a dramatic increase in the success rate of generating harmful outputs. The results reveal that safety in MoE models is surprisingly concentrated and fragile, posing a significant security risk for deployed models.",
      "mindmap": "graph LR\n    A[GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs] --> B[核心问题/Problem: MoE模型的安全性机制未被充分研究/Safety mechanisms in MoE LLMs are largely unexamined]\n    A --> C[主要方法/Method: 三阶段无训练攻击/Three-stage training-free attack: 门级分析, 专家定位, 安全移除/Gate profiling, Expert localization, Safety removal]\n    A --> D[关键结果/Results: 攻击成功率显著提升/ASR increases from 7.4% to 64.9%; 安全性神经元可迁移/Safety neurons transfer across models]"
    },
    {
      "title": "zkFL-Health: Blockchain-Enabled Zero-Knowledge Federated Learning for Medical AI Privacy",
      "authors": "Savvy Sharma, George Petrovic, Sarthak Kaushik",
      "institution": "George Brown Polytechnic",
      "link": "https://arxiv.org/pdf/2512.21048",
      "code": null,
      "tags": [
        "federated learning",
        "zero-knowledge proofs",
        "trusted execution environments",
        "blockchain",
        "medical AI",
        "verifiable aggregation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eaf3da543259b835ceee63f63b6675f8ca4fdd248035da93b3582ae546b60093_w640_q70.webp",
      "contributions": "1. Proposes a novel architecture (zkFL-Health) that integrates Federated Learning with Zero-Knowledge Proofs and Trusted Execution Environments to ensure privacy and verifiable correctness in medical AI training. 2. Introduces a protocol where the aggregator, operating within a TEE, generates a succinct ZK proof to attest it used the correct inputs and aggregation rule, without revealing client updates. 3. Leverages a blockchain to provide an immutable audit trail of cryptographic commitments and proof verification, removing the need to trust a single party and enhancing regulatory compliance.",
      "summary": "The paper addresses privacy leakage and trust issues in federated learning for healthcare by proposing zkFL-Health, a framework that combines FL with zero-knowledge proofs and TEEs to enable verifiable and private model aggregation. The method ensures the aggregator's computations are provably correct and recorded on a blockchain for auditability. The conclusion is that this approach provides strong confidentiality, integrity, and auditability, which are crucial for clinical adoption.",
      "mindmap": "graph LR\n    A[zkFL-Health] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[隐私泄露与聚合器信任/Privacy Leakage & Aggregator Trust]\n    C --> C1[FL+ZKP+TEE/FL+ZKP+TEE]\n    C --> C2[链上验证/On-chain Verification]\n    D --> D1[可验证的隐私保护/Verifiable Privacy]\n    D --> D2[审计与合规/Auditability & Compliance]"
    },
    {
      "title": "Beyond Context: Large Language Models Failure to Grasp Users Intent",
      "authors": "Ahmed M. Hussain, Salahuddin Salahuddin, Panos Papadimitratos",
      "institution": "KTH Royal Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.21110",
      "code": null,
      "tags": [
        "ai safety",
        "intent recognition",
        "contextual understanding",
        "safety circumvention",
        "prompt engineering",
        "transformer architectures"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/55c1a596dd6375317c809bb19f466455285faf18a1f9810649d755b8027e383c_w640_q70.webp",
      "contributions": "1. Identifies and empirically demonstrates a critical vulnerability in LLMs: their inability to understand user intent and context, which allows safety mechanisms to be circumvented. 2. Evaluates multiple state-of-the-art LLMs (ChatGPT, Claude, Gemini, DeepSeek) and shows that exploitation techniques like emotional framing and progressive revelation are effective, and that reasoning capabilities can amplify this risk. 3. Proposes a paradigmatic shift in AI safety design, arguing for contextual understanding and intent recognition to be core capabilities rather than post-hoc protective mechanisms.",
      "summary": "This paper identifies a fundamental vulnerability in Large Language Models (LLMs): their lack of contextual understanding and intent recognition, which allows safety mechanisms to be systematically bypassed. The authors empirically evaluate several LLMs, showing they can be exploited through techniques like emotional framing, and find that reasoning capabilities often worsen the problem. They conclude that a paradigm shift is needed to build intent recognition directly into LLM architectures for safety.",
      "mindmap": "graph LR\n    A[Beyond Context: Large Language Models Failure to Grasp Users Intent] --> B[核心问题/Problem: LLMs缺乏上下文和意图理解能力/LLMs lack contextual understanding & intent recognition]\n    A --> C[主要方法/Method: 对多种LLM进行经验性评估/Empirical evaluation of multiple LLMs]\n    A --> D[关键结果/Results: 安全机制可被系统规避，需范式转变/Safety mechanisms can be systematically circumvented, requiring a paradigm shift]\n    B --> E[导致可利用的漏洞/Creates exploitable vulnerabilities]\n    C --> F[使用情感框架、渐进揭示等技术/Using emotional framing, progressive revelation, etc.]\n    D --> G[Claude Opus 4.1部分例外，推理能力加剧风险/Claude Opus 4.1 partial exception, reasoning amplifies risk]"
    },
    {
      "title": "AutoBaxBuilder: Bootstrapping Code Security Benchmarking",
      "authors": "Tobias von Arx, Niels Mündler, Mark Vero, Maximilian Baader, Martin Vechev",
      "institution": "ETH Zurich, Snyk, INSAIT (Sofia University \"St. Kliment Ohridski\")",
      "link": "https://arxiv.org/pdf/2512.21132",
      "code": "https://github.com/eth-sri/autobaxbuilder",
      "tags": [
        "code security evaluation",
        "automated benchmarking",
        "LLM-generated code",
        "security vulnerabilities",
        "exploit generation",
        "plausibility checks"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/385abd6729afb970eba2217cc3d408efe70ab80f9d7aa0cbe7c2e0254f48b74c_w640_q70.webp",
      "contributions": "1. Introduces AutoBaxBuilder, a framework for generating code security benchmarking tasks and tests from scratch, addressing the limitations of manual benchmarks. 2. Proposes a robust pipeline with fine-grained plausibility checks that leverages LLMs to construct functionality tests and end-to-end security exploits. 3. Releases AutoBaxBench, a new benchmark of generated tasks, and demonstrates the framework's efficiency (under 2 hours and $10 per task) and quality through comparison with human-crafted tasks.",
      "summary": "The paper presents AutoBaxBuilder, a framework that automatically generates tasks and tests for benchmarking the security of code produced by large language models (LLMs). It uses an LLM-powered pipeline to create functional tests and security exploits, ensuring benchmark quality and scalability. The authors show the method is efficient and release a new benchmark, AutoBaxBench, to evaluate LLM security capabilities.",
      "mindmap": "graph LR\n    A[AutoBaxBuilder] --> B[核心问题/Problem: Manual security benchmarks are insufficient]\n    A --> C[主要方法/Method: Auto-generate tasks & tests with LLM pipeline]\n    A --> D[关键结果/Results: New benchmark, low cost, under 2 hours/task]"
    },
    {
      "title": "Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking",
      "authors": "Yifan Huang, Xiaojun Jia, Wenbo Guo, Yuqiang Sun, Yihao Huang, Chong Wang, Yang Liu",
      "institution": "Nanyang Technological University, National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.21236",
      "code": null,
      "tags": [
        "llm security",
        "jailbreaking",
        "malicious code generation",
        "prompt engineering",
        "time-division selection",
        "security alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8055c0aba333e58d26f29d81acab1f88f570f09122f7fafd38ac1c952dad67b1_w640_q70.webp",
      "contributions": "1. Proposes SPELL, a novel testing framework specifically designed to evaluate security alignment weaknesses in LLMs for malicious code generation. 2. Introduces a time-division selection strategy to systematically construct jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset. 3. Conducts extensive evaluation across multiple advanced code models and real-world tools, revealing significant security gaps and providing insights for improving AI safety.",
      "summary": "The paper addresses the security risk of LLMs being exploited to generate malicious code, a gap in existing jailbreaking research. It proposes the SPELL framework, which uses a time-division strategy to construct effective jailbreaking prompts. The evaluation shows high attack success rates across several models, revealing critical vulnerabilities in current AI safety alignments for code generation.",
      "mindmap": "graph LR\n        A[SPELL: Sentence Pairing Exploration for LLM Limitation-breaking] --> B[核心问题/Problem: LLMs可能被用于生成恶意代码/LLMs can be exploited for malicious code generation]\n        A --> C[主要方法/Method: 基于时间划分选择的提示构建框架/Time-division selection prompt construction framework]\n        A --> D[关键结果/Results: 在多模型上实现高攻击成功率/High attack success rates across multiple models]"
    },
    {
      "title": "Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks",
      "authors": "Xinjie Xu, Shuyu Cheng, Dongwei Xu, Qi Xuan, Chen Ma",
      "institution": "Zhejiang University of Technology, Binjiang Institute of Artificial Intelligence, ZJUT, JQ Investments",
      "link": "https://arxiv.org/pdf/2512.21241",
      "code": "https://github.com/machanic/hard_label_attacks",
      "tags": [
        "adversarial attacks",
        "hard-label black-box attacks",
        "query efficiency",
        "ray search optimization",
        "Nesterov's Accelerated Gradient",
        "momentum-based optimization"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/302b574932ba227c13854e5c9c2cab3d7cf8f1ed29ee145fbc73062632304cd4_w640_q70.webp",
      "contributions": "1. Proposed ARS-OPT, a momentum-based algorithm inspired by Nesterov's Accelerated Gradient to accelerate the convergence of ray search in hard-label attacks. 2. Introduced PARS-OPT, which further enhances ARS-OPT by incorporating surrogate-model priors into the gradient estimation. 3. Provided theoretical convergence guarantees for the proposed methods and demonstrated superior query efficiency over 13 state-of-the-art approaches on ImageNet and CIFAR-10.",
      "summary": "This paper addresses the high query cost of hard-label black-box adversarial attacks by optimizing ray search. The authors propose ARS-OPT, a momentum-based algorithm, and its enhanced version PARS-OPT, which uses surrogate-model priors, to accelerate convergence. Experiments show the methods outperform 13 existing approaches in query efficiency on standard datasets.",
      "mindmap": "graph LR\n    A[Improving the Convergence Rate of Ray Search Optimization<br>改进射线搜索优化的收敛率] --> B[核心问题/Problem<br>Hard-label攻击查询成本高<br>High query cost in hard-label attacks]\n    A --> C[主要方法/Method<br>提出ARS-OPT & PARS-OPT<br>Propose ARS-OPT & PARS-OPT]\n    A --> D[关键结果/Results<br>超越13种SOTA方法<br>Outperforms 13 SOTA methods]"
    },
    {
      "title": "Assessing the Software Security Comprehension of Large Language Models",
      "authors": "Mohammed Latif Siddiq, Natalie Sekerak, Antonio Karam, Maria Leal, Arvin Islam-Gomes, Joanna C. S. Santos",
      "institution": "University of Notre Dame",
      "link": "https://arxiv.org/pdf/2512.21238",
      "code": null,
      "tags": [
        "software security assessment",
        "Bloom's Taxonomy",
        "knowledge boundary",
        "misconception patterns"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b3809be1ff4cae9ad7acb47676829cd58ca3ea614efa57d9121857f85d97fc7_w640_q70.webp",
      "contributions": "1. Introduced a systematic evaluation framework using Bloom's Taxonomy to assess LLMs' software security comprehension across six cognitive levels. 2. Proposed the concept of a \"software security knowledge boundary\" to identify the highest reliable cognitive performance level for an LLM. 3. Identified and documented 51 recurring misconception patterns made by LLMs in software security tasks.",
      "summary": "This paper systematically evaluates the software security comprehension of five leading LLMs using Bloom's Taxonomy as a framework across diverse datasets. The results show that while LLMs perform well on lower-level cognitive tasks like recalling facts, their performance significantly degrades on higher-order tasks requiring reasoning and secure system creation. The study introduces a knowledge boundary to quantify reliable performance limits and identifies common misconception patterns.",
      "mindmap": "graph LR\n    A[Assessing LLM Software Security Comprehension<br/>评估LLM软件安全理解] --> B{核心问题/Problem};\n    A --> C{主要方法/Method};\n    A --> D{关键结果/Results};\n    B --> B1[LLMs' Security Expertise Unclear<br/>LLM安全专业知识不明];\n    C --> C1[Framework: Bloom's Taxonomy<br/>框架: 布鲁姆分类法];\n    C --> C2[Datasets: MCQs, Code, Courses, Case Studies<br/>数据集: 选择题, 代码, 课程, 案例];\n    D --> D1[Good on Low-Level Tasks<br/>低级任务表现好];\n    D --> D2[Poor on High-Order Reasoning<br/>高阶推理表现差];\n    D --> D3[Knowledge Boundary & Misconceptions<br/>知识边界与误解模式];"
    },
    {
      "title": "Industrial Ouroboros: Deep Lateral Movement via Living Off the Plant",
      "authors": "Richard Derbyshire",
      "institution": "Orange Cyberdefense",
      "link": "https://arxiv.org/pdf/2512.21248",
      "code": null,
      "tags": [
        "operational technology security",
        "lateral movement",
        "living off the plant",
        "programmable logic controller",
        "serial network",
        "covert technique"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7def06d73ea4dcb4c33adb050f7e18d5a5e1f8730eeb5c5d41ad47f504114465_w640_q70.webp",
      "contributions": "1. Introduces the first PLC-centric lateral movement technique that relies exclusively on native OT environment functionality, termed \"living off the plant\" (LOTP). 2. Demonstrates how the technique enables escape from IP networks onto legacy serial networks via dual-homed PLCs. 3. Highlights the covert nature of the technique, which leverages common network communication functions that are difficult to detect, challenging traditional OT defensive practices.",
      "summary": "This paper addresses the lack of lateral movement techniques within Operational Technology (OT) environments by proposing a novel, PLC-centric method that uses only native functionality, termed \"Living Off the Plant\" (LOTP). The technique is covert, facilitates movement onto serial networks, and demonstrates significant risks, calling for a fundamental reconsideration of OT security defenses.",
      "mindmap": "graph LR\n    A[Industrial Ouroboros: Deep Lateral Movement via Living Off the Plant] --> B[核心问题/Problem: Lack of OT lateral movement methods]\n    A --> C[主要方法/Method: PLC-centric LOTP using native functions]\n    A --> D[关键结果/Results: Covert, enables serial network escape, redefines OT defense]"
    },
    {
      "title": "Uncertainty in security: managing cyber senescence",
      "authors": "Martijn Dekker",
      "institution": "University of Amsterdam",
      "link": "https://arxiv.org/pdf/2512.21251",
      "code": null,
      "tags": [
        "cybersecurity risk management",
        "cyber senescence",
        "uncertainty",
        "security controls",
        "system aging",
        "risk accumulation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4544f7a758bb73cc4af02347555ec2e50592e1c7f1173cd44ba985218c26d1cb_w640_q70.webp",
      "contributions": "1. Introduces the novel concept of \"cyber senescence\" to describe the aging and increasing operational risk of the cybersecurity ecosystem. 2. Identifies the accumulation of overlapping security controls with uncertain effectiveness as a primary cause of this aging. 3. Proposes the need for \"pruning\" control frameworks to manage uncertainty and prevent potential system collapse.",
      "summary": "The paper introduces the concept of \"cyber senescence\" to describe the aging of the cybersecurity ecosystem, primarily caused by the accumulation of overlapping security controls whose risk reduction is uncertain. It argues that managing this fundamental uncertainty by pruning ineffective controls is necessary to prevent system collapse.",
      "mindmap": "graph LR\n    A[Uncertainty in Security: Managing Cyber Senescence] --> B[核心问题/Problem: Cybersecurity ecosystem aging (Cyber Senescence)]\n    A --> C[主要方法/Method: Identify uncertainty from overlapping controls, propose pruning]\n    A --> D[关键结果/Results: Need to manage uncertainty to prevent system collapse]"
    },
    {
      "title": "CoTDeceptor:Adversarial Code Obfuscation Against CoT-Enhanced LLM Code Agents",
      "authors": "Haoyang Li, Mingjin Li, Jinxin Zuo, Siqi Li, Xiao Li, Hao Wu, Yueming Lu, Xiaochuan He",
      "institution": "Beijing University of Posts and Telecommunications, Institute of Information Engineering, Chinese Academy of Sciences, National Key Lab for Novel Software Technology, Nanjing University",
      "link": "https://arxiv.org/pdf/2512.21250",
      "code": "https://github.com/hiki9712/CoT-Code-Obfuscation",
      "tags": [
        "software supply chain security",
        "adversarial obfuscation",
        "chain-of-thought reasoning",
        "LLM code agents",
        "vulnerability detection",
        "code poisoning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cefe211bbeb3689b53fe3c942123a9b959d545c2e5ca843e46619fd06066843b_w640_q70.webp",
      "contributions": "1. Identifies systematic weaknesses in the reasoning chains and semantic abstraction processes of CoT-enhanced LLM vulnerability detectors that can be exploited for evasion. 2. Proposes CoTDeceptor, the first adversarial code obfuscation framework designed to target and disrupt CoT-driven detection logic in LLMs. 3. Demonstrates superior evasion performance, with CoTDeceptor bypassing detection in 14 out of 15 vulnerability categories, significantly outperforming prior methods.",
      "summary": "This paper introduces CoTDeceptor, an adversarial code obfuscation framework that exploits weaknesses in Chain-of-Thought (CoT) reasoning used by LLM-based vulnerability detectors. It autonomously constructs multi-stage obfuscation strategies to embed malicious logic and evade detection. The results show it successfully bypasses most vulnerability categories, highlighting significant risks to software supply chain security and the need for more robust LLM-powered security systems.",
      "mindmap": "graph LR\n        A[CoTDeceptor] --> B[核心问题/Problem: CoT-Enhanced LLM Detectors Have Exploitable Weaknesses];\n        A --> C[主要方法/Method: Adversarial Multi-Stage Code Obfuscation Framework];\n        A --> D[关键结果/Results: High Evasion Rate (14/15 Categories), Supply Chain Risk];"
    },
    {
      "title": "Sequential Apportionment from Stationary Divisor Methods",
      "authors": "Michael A. Jones, Brittany Ohlinger, Jennifer Wilson",
      "institution": "American Mathematical Society, The New School",
      "link": "https://arxiv.org/pdf/2512.20686",
      "code": null,
      "tags": [
        "computational social choice",
        "apportionment sequence",
        "divisor methods",
        "stationary divisor methods",
        "house monotonicity",
        "large-party bias"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/374eb96da328decee43ab75fa7158077b2542fe4fe49d5dca6b8490935f159af_w640_q70.webp",
      "contributions": "1. Characterized the set of possible periodic apportionment sequences for two-party allocations under stationary divisor methods and linked their lexicographical ordering to the rounding cut point parameter c., 2. Demonstrated how to systematically extend two-party sequences to the n-party setting and determined the count of distinct sequences for all c., 3. Provided a refined perspective on large-party bias, showing it manifests as earlier seat acquisition in the sequence, and uncovered a new relationship between sequences from the Adams and d'Hondt/Jefferson methods.",
      "summary": "This paper analyzes sequential seat allocation using stationary divisor methods, which are defined by a rounding cut point. It characterizes the periodic sequences generated for integer votes, extends the analysis from two to n parties, and reinterprets large-party bias as receiving seats earlier in the sequence rather than just more seats.",
      "mindmap": "graph LR\n        A[Sequential Apportionments from Stationary Divisor Methods<br>平稳除数方法的顺序分配] --> B(核心问题/Problem: Understanding sequential seat allocation sequences from divisor methods<br>理解除数方法产生的顺序席位分配序列)\n        A --> C(主要方法/Method: Analyze stationary divisor methods with rounding cut point c<br>分析具有舍入临界点c的平稳除数方法)\n        A --> D(关键结果/Results: Characterized sequences, extended to n parties, refined bias view<br>表征序列，扩展到n方，精炼偏差视角)"
    },
    {
      "title": "Device-Independent Anonymous Communication in Quantum Networks",
      "authors": "Srijani Das, Manasi Patra, Tuhin Paul, Anish Majumdar, Ramij Rahaman",
      "institution": "Indian Statistical Institute",
      "link": "https://arxiv.org/pdf/2512.21047",
      "code": null,
      "tags": [
        "quantum cryptography",
        "device-independent",
        "anonymous communication",
        "quantum networks",
        "GHZ states",
        "parity protocol"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a69aa18a935e7be330a775f042ff297c5e62ee3491f11330b966618f188aae9d_w640_q70.webp",
      "contributions": "1. Introduces the first fully quantum protocol for anonymous communication that does not rely on classical subroutines. 2. Provides a device-independent security proof for the protocol, verifying quantum resources without trusting the devices. 3. Proposes secure quantum protocols for the Parity and Logical OR problems, eliminating the need for exponential private channels.",
      "summary": "This paper addresses the lack of information-theoretic security in classical anonymous communication by proposing the first fully quantum protocol for anonymous communication in quantum networks. The protocol's key innovation is its device-independent security proof, which certifies the necessary quantum resources (like GHZ correlations) based solely on observed statistics, removing trust assumptions about the hardware. This work establishes a foundation for provably secure anonymous communication in adversarial quantum network settings.",
      "mindmap": "graph LR\n    A[Device-Independent Anonymous Communication in Quantum Networks] --> B(核心问题/Problem: Classical & existing quantum anonymity protocols lack information-theoretic or device-independent security)\n    A --> C(主要方法/Method: First fully quantum protocol with device-independent security proof)\n    A --> D(关键结果/Results: Enables provably secure anonymous communication in adversarial quantum networks)"
    },
    {
      "title": "A Note on Publicly Verifiable Quantum Money with Low Quantum Computational Resources",
      "authors": "Fabrizio Genovese, Lev Stambler",
      "institution": "NeverLocal LTD, University of Maryland, College Park",
      "link": "https://arxiv.org/pdf/2512.21304",
      "code": "https://github.com/neverlocal/otm_billz",
      "tags": [
        "quantum cryptography",
        "quantum money",
        "one-time memories",
        "conjugate coding",
        "public verifiability",
        "trusted hardware"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02a34089948e85727ff675d66dbb3cf8d5fab3d5d57d85913e9b1d7ffe0b9c11_w640_q70.webp",
      "contributions": "1. A publicly verifiable quantum money protocol requiring minimal quantum computational capabilities., 2. A scheme enabling a limited number of verifications and supporting quantum tokens for digital signatures., 3. Prevention of double-spending by leveraging the no-cloning principle of conjugate coding states.",
      "summary": "This paper proposes a new protocol for publicly verifiable quantum money that requires almost no quantum computational resources. The method relies on one-time memories built from quantum conjugate coding and hardware assumptions to prevent double-spending. The main conclusion is that this approach enables practical quantum money with limited verification and support for digital signature tokens.",
      "mindmap": "graph LR\n    A[A Note on Publicly Verifiable Quantum Money with Low Quantum Computational Resources] --> B[核心问题/Problem: Publicly verifiable quantum money is elusive to implement.]\n    A --> C[主要方法/Method: Use one-time memories built from conjugate coding & hardware.]\n    A --> D[关键结果/Results: Prevents double-spending, allows limited verifications & signature tokens.]"
    },
    {
      "title": "PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility",
      "authors": "Md Nahid Hasan Shuvo, Moinul Hossain",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19711",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d516fcc6c3de6b0e65c078e5e3f3dda23bfd77fbb9c5f4abfe2c509c2cb6dfe_w640_q70.webp",
      "contributions": "",
      "summary": "PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility",
      "mindmap": ""
    },
    {
      "title": "ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures",
      "authors": "Zhonghao Yang, Cheng Luo, Daojing He, Yiming Li, Yu Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19730",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66bbe64f6f3cac5df3dfd69a018806ee7d1973ac071d8af57c13752826c622fe_w640_q70.webp",
      "contributions": "",
      "summary": "ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures",
      "mindmap": ""
    },
    {
      "title": "Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress",
      "authors": "Samruddhi Baviskar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19935",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f15b3890b1332bf926501d440f418e2e71c3b0c8c5b3dd19380d13e172c25ac_w640_q70.webp",
      "contributions": "",
      "summary": "Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress",
      "mindmap": ""
    },
    {
      "title": "Energy-Efficient Multi-LLM Reasoning for Binary-Free Zero-Day Detection in IoT Firmware",
      "authors": "Saeid Jamshidi, Omar Abdul-Wahab, Martine Bellaïche, Foutse Khomh",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19945",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba69b6cf6ff794728a11a67f2e412ba7c6cbeb4a15cbf4e50c0e283a191596a4_w640_q70.webp",
      "contributions": "",
      "summary": "Energy-Efficient Multi-LLM Reasoning for Binary-Free Zero-Day Detection in IoT Firmware",
      "mindmap": ""
    },
    {
      "title": "Efficient Mod Approximation and Its Applications to CKKS Ciphertexts",
      "authors": "Yufei Zhou",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19951",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f31feeade06dacefe2d41b427bfaa023f47b2b722f1e3424076bd4bbc4c4417_w640_q70.webp",
      "contributions": "",
      "summary": "Efficient Mod Approximation and Its Applications to CKKS Ciphertexts",
      "mindmap": ""
    },
    {
      "title": "Fast Deterministically Safe Proof-of-Work Consensus",
      "authors": "Ali Farahbakhsh, Giuliano Losa, Youer Pu, Lorenzo Alvisi, Ittay Eyal",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19968",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c8c2b22be0b35fb8cea5be26aaab91942070c6d5ce9f0ed18a50e2a65b7916af_w640_q70.webp",
      "contributions": "",
      "summary": "Fast Deterministically Safe Proof-of-Work Consensus",
      "mindmap": ""
    },
    {
      "title": "BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations",
      "authors": "Yanjing Yang, He Zhang, Bohan Liu, Jinwei Xu, Jinghao Hu, Liming Dong, Zhewen Mao, Dongxue Pan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19997",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/70a323ff0c6b620555f25fedefe7b12761782c69ac299e6333a9bde71caf7b04_w640_q70.webp",
      "contributions": "",
      "summary": "BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations",
      "mindmap": ""
    },
    {
      "title": "IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense",
      "authors": "Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20004",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea3f077bcaec1c639c8029881602d31bdf125a8cbefc2e15ec9ba3e07c126ee1_w640_q70.webp",
      "contributions": "",
      "summary": "IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense",
      "mindmap": ""
    },
    {
      "title": "On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities",
      "authors": "Sangryu Park, Gihyuk Ko, Homook Cho",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20062",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74a88fcd014c903ee16397aa497f69b488c2c3bdeb23c2bddfc09643306081ec_w640_q70.webp",
      "contributions": "",
      "summary": "On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities",
      "mindmap": ""
    },
    {
      "title": "Optimistic TEE-Rollups: A Hybrid Architecture for Scalable and Verifiable Generative AI Inference on Blockchain",
      "authors": "Aaron Chan, Alex Ding, Frank Chen, Alan Wu, Bruce Zhang, Arther Tian",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20176",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/010f385a6dbfdbcde49aa7a72dc0cdb0364dc379de9bd54859e7a4d735f42085_w640_q70.webp",
      "contributions": "",
      "summary": "Optimistic TEE-Rollups: A Hybrid Architecture for Scalable and Verifiable Generative AI Inference on Blockchain",
      "mindmap": ""
    },
    {
      "title": "Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography",
      "authors": "Songze Li, Jiameng Cheng, Yiming Li, Xiaojun Jia, Dacheng Tao",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20168",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/12bfaa681af3521489a5c856a7d28bf207a72778a776d4ae80d7e0271f100e3b_w640_q70.webp",
      "contributions": "",
      "summary": "Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography",
      "mindmap": ""
    },
    {
      "title": "Post-Quantum Cryptography in the 5G Core",
      "authors": "Thomas Attema, Bor de Kock, Sandesh Manganahalli Jayaprakash, Dimitrios Schoinianakis, Thom Sijpesteijn, Rintse van de Vlasakker",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20243",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/859dfd3ed6d1322ef0080bba0f59f3ae42dade36f0faa22a613bb943d0674177_w640_q70.webp",
      "contributions": "",
      "summary": "Post-Quantum Cryptography in the 5G Core",
      "mindmap": ""
    },
    {
      "title": "Achieving Flexible and Secure Authentication with Strong Privacy in Decentralized Networks",
      "authors": "Bin Xie, Rui Song, Xuyuan Cai",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20234",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02b09397db4876e894f238946f17dc14530af0c88ed90fd1e7f09be2d841e413_w640_q70.webp",
      "contributions": "",
      "summary": "Achieving Flexible and Secure Authentication with Strong Privacy in Decentralized Networks",
      "mindmap": ""
    },
    {
      "title": "From the Two-Capacitor Paradox to Electromagnetic Side-Channel Mitigation in Digital Circuits",
      "authors": "Raghvendra Pratap Singh, Baibhab Chatterjee, Shreyas Sen, Debayan Das",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20303",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f953b1db3d7436e32ea558917ba8a9ec9089c4025dad0aed481bfbc3ec5bd48b_w640_q70.webp",
      "contributions": "",
      "summary": "From the Two-Capacitor Paradox to Electromagnetic Side-Channel Mitigation in Digital Circuits",
      "mindmap": ""
    },
    {
      "title": "Differentially Private Feature Release for Wireless Sensing: Adaptive Privacy Budget Allocation on CSI Spectrograms",
      "authors": "Ipek Sena Yilmaz, Onur G. Tuncer, Zeynep E. Aksoy, Zeynep Yağmur Baydemir",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20323",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a21eec5a50074d8598533d3c42181cfd21159c9627ef487920d4e2b7369bfd26_w640_q70.webp",
      "contributions": "",
      "summary": "Differentially Private Feature Release for Wireless Sensing: Adaptive Privacy Budget Allocation on CSI Spectrograms",
      "mindmap": ""
    },
    {
      "title": "iblock: Accurate and Scalable Bitcoin Simulations with OMNeT++",
      "authors": "Niccolò Scatena, Pericle Perazzo, Giovanni Nardini",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20402",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6c948c2f471538c4ad6962b3c03e4c869eb3e5bfdea61004d6f568b880cedc1e_w640_q70.webp",
      "contributions": "",
      "summary": "iblock: Accurate and Scalable Bitcoin Simulations with OMNeT++",
      "mindmap": ""
    },
    {
      "title": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs",
      "authors": "Narges Khakpour, Nicolas Berthier",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20396",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6bdfa1cdb9c42587497d38e68d6ea55a15a3372a5c197a241c9e2cf0c52caf1_w640_q70.webp",
      "contributions": "",
      "summary": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs",
      "mindmap": ""
    },
    {
      "title": "ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected",
      "authors": "Kanchon Gharami, Sanjiv Kumar Sarkar, Yongxin Liu, Shafika Showkat Moni",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20405",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/594ed7491abb39e62fd7b3759310d809c622b7da530d48b7e61a79c247aa8e25_w640_q70.webp",
      "contributions": "",
      "summary": "ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected",
      "mindmap": ""
    },
    {
      "title": "Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit",
      "authors": "Adam Elaoumari",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20423",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b67cb70660ec29cf307ab6baf5a52c6e3cecc0888ba9656259ee05bcfef71b96_w640_q70.webp",
      "contributions": "",
      "summary": "Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit",
      "mindmap": ""
    },
    {
      "title": "ARBITER: AI-Driven Filtering for Role-Based Access Control",
      "authors": "Michele Lorenzo, Idilio Drago, Dario Salvadori, Fabio Romolo Vayr",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20535",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8509374311a264c5003d04ae262475f45c1a4ead7bfcf66fff72db8b5855470b_w640_q70.webp",
      "contributions": "",
      "summary": "ARBITER: AI-Driven Filtering for Role-Based Access Control",
      "mindmap": ""
    },
    {
      "title": "Making Sense of Private Advertising: A Principled Approach to a Complex Ecosystem",
      "authors": "Kyle Hogan, Alishah Chator, Gabriel Kaptchuk, Mayank Varia, Srinivas Devadas",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20583",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82fccde3da36f7b171a59e9ec66b1d7b70bd32ec2b0c0c8143776db2c9c5004c_w640_q70.webp",
      "contributions": "",
      "summary": "Making Sense of Private Advertising: A Principled Approach to a Complex Ecosystem",
      "mindmap": ""
    },
    {
      "title": "Fault Injection Attacks on Machine Learning-based Quantum Computer Readout Error Correction",
      "authors": "Anthony Etim, Jakub Szefer",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20077",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fc5f21e6b5370dfa3155d4e963f5fa0c392a8fca93c2b17266372826a40c1f7d_w640_q70.webp",
      "contributions": "",
      "summary": "Fault Injection Attacks on Machine Learning-based Quantum Computer Readout Error Correction",
      "mindmap": ""
    },
    {
      "title": "Scalable Multiterminal Key Agreement via Error-Correcting Codes",
      "authors": "Benjamin D. Kim, Daniel Alabi, Lav R. Varshney",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18025",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b90096ff5e16ca69f9b0956ddc32f3ea7cd08328fd1b4cdd12061ce901136047_w640_q70.webp",
      "contributions": "",
      "summary": "Scalable Multiterminal Key Agreement via Error-Correcting Codes",
      "mindmap": ""
    },
    {
      "title": "Towards Benchmarking Privacy Vulnerabilities in Selective Forgetting with Large Language Models",
      "authors": "Wei Qian, Chenxu Zhao, Yangyi Li, Mengdi Huai",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18035",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aaf9e957a407bb93f6576826db847a43f0675e8b765d8c6f38b7c40e06953c3_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Benchmarking Privacy Vulnerabilities in Selective Forgetting with Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Securing Agentic AI Systems -- A Multilayer Security Framework",
      "authors": "Sunil Arora, John Hastings",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18043",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96ca042b8b2e4295fa813434a544ac9adb3df55cbea55e3fe9b24f2dcbee4733_w640_q70.webp",
      "contributions": "",
      "summary": "Securing Agentic AI Systems -- A Multilayer Security Framework",
      "mindmap": ""
    },
    {
      "title": "From Coverage to Causes: Data-Centric Fuzzing for JavaScript Engines",
      "authors": "Kishan Kumar Ganguly, Tim Menzies",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18102",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/509a927741960d2c63062790fd8bebe6a6a22769c29f6985c39fb001039d9fab_w640_q70.webp",
      "contributions": "",
      "summary": "From Coverage to Causes: Data-Centric Fuzzing for JavaScript Engines",
      "mindmap": ""
    },
    {
      "title": "Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection",
      "authors": "Jie Yang, Rui Zhang, Ziyang Cheng, Dawei Cheng, Guang Yang, Bo Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18133",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b8052788abbad008c8487b789c1968d0448bbef8cdd15ad400f0c6303c23505_w640_q70.webp",
      "contributions": "",
      "summary": "Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection",
      "mindmap": ""
    },
    {
      "title": "PermuteV: A Performant Side-channel-Resistant RISC-V Core Securing Edge AI Inference",
      "authors": "Nuntipat Narkthong, Xiaolin Xu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18132",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5249dae70a6ea951da7229a4606840eb6080d2d0b091828439fd7dc722b3fe4e_w640_q70.webp",
      "contributions": "",
      "summary": "PermuteV: A Performant Side-channel-Resistant RISC-V Core Securing Edge AI Inference",
      "mindmap": ""
    },
    {
      "title": "Conscious Data Contribution via Community-Driven Chain-of-Thought Distillation",
      "authors": "Lena Libon, Meghana Bhange, Rushabh Solanki, Elliot Creager, Ulrich Aïvodji",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18174",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd7baf972d08bf5c53e0a32c68fda68879e3c2febf3407ecf6537a3fcd6d36fd_w640_q70.webp",
      "contributions": "",
      "summary": "Conscious Data Contribution via Community-Driven Chain-of-Thought Distillation",
      "mindmap": ""
    },
    {
      "title": "PROVEX: Enhancing SOC Analyst Trust with Explainable Provenance-Based IDS",
      "authors": "Devang Dhanuka, Nidhi Rastogi",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18199",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7026a8c8f552664c28724b8716e8e7e5cef6b29425c374a1c5439f2bfb877d5f_w640_q70.webp",
      "contributions": "",
      "summary": "PROVEX: Enhancing SOC Analyst Trust with Explainable Provenance-Based IDS",
      "mindmap": ""
    },
    {
      "title": "FedWiLoc: Federated Learning for Privacy-Preserving WiFi Indoor Localization",
      "authors": "Kanishka Roy, Tahsin Fuad Hasan, Chenfeng Wu, Eshwar Vangala, Roshan Ayyalasomayajula",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18207",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ab65d991dc4dbe544e6c4587e2801659a4146a874b527690e3a6d819a5d2d12_w640_q70.webp",
      "contributions": "",
      "summary": "FedWiLoc: Federated Learning for Privacy-Preserving WiFi Indoor Localization",
      "mindmap": ""
    },
    {
      "title": "Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation",
      "authors": "Zehao Liu, Xi Lin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18244",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a4ab3d36e0ccc56b5c8f0b5a9f82481bdfdc1f1bc14e54959edf8ba4006a00d_w640_q70.webp",
      "contributions": "",
      "summary": "Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation",
      "mindmap": ""
    },
    {
      "title": "Who Can See Through You? Adversarial Shielding Against VLM-Based Attribute Inference Attacks",
      "authors": "Yucheng Fan, Jiawei Chen, Yu Tian, Zhaoxia Yin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18264",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6181175b477e5c50e93e9a1a3a4690fb1673471073933b770754e208c7b0e776_w640_q70.webp",
      "contributions": "",
      "summary": "Who Can See Through You? Adversarial Shielding Against VLM-Based Attribute Inference Attacks",
      "mindmap": ""
    },
    {
      "title": "MORPHEUS: A Multidimensional Framework for Modeling, Measuring, and Mitigating Human Factors in Cybersecurity",
      "authors": "Giuseppe Desolda, Francesco Greco, Rosa Lanzilotti, Cesare Tucci",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18303",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/013fffaf0ed613ccbcc22a6990caf81327b42deac91bfb1c67c73cad88e1ab96_w640_q70.webp",
      "contributions": "",
      "summary": "MORPHEUS: A Multidimensional Framework for Modeling, Measuring, and Mitigating Human Factors in Cybersecurity",
      "mindmap": ""
    },
    {
      "title": "Theodosian: A Deep Dive into Memory-Hierarchy-Centric FHE Acceleration",
      "authors": "Wonseok Choi, Hyunah Yu, Jongmin Kim, Hyesung Ji, Jaiyoung Park, Jung Ho Ahn",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18345",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9e4c078425f57860f1303fe0449ae500adae2d4acf07294f16f8ed22a154bad_w640_q70.webp",
      "contributions": "",
      "summary": "Theodosian: A Deep Dive into Memory-Hierarchy-Centric FHE Acceleration",
      "mindmap": ""
    },
    {
      "title": "Federated Learning Based Decentralized Adaptive Intelligent Transmission Protocol for Privacy Preserving 6G Networks",
      "authors": "Ansar Ahmed",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18432",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8b17e8fd956e845305266fe6ff75f18289ac1b39f8db27ac25d02758609d8f9_w640_q70.webp",
      "contributions": "",
      "summary": "Federated Learning Based Decentralized Adaptive Intelligent Transmission Protocol for Privacy Preserving 6G Networks",
      "mindmap": ""
    },
    {
      "title": "SoK: Understanding (New) Security Issues Across AI4Code Use Cases",
      "authors": "Qilong Wu, Taoran Li, Tianyang Zhou, Varun Chandrasekaran",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18456",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f652ae22c8ea45edbe21093e80ef932b29b1703110171928654985064e108e1_w640_q70.webp",
      "contributions": "",
      "summary": "SoK: Understanding (New) Security Issues Across AI4Code Use Cases",
      "mindmap": ""
    },
    {
      "title": "Enhancing Decision-Making in Windows PE Malware Classification During Dataset Shifts with Uncertainty Estimation",
      "authors": "Rahul Yumlembam, Biju Issac, Seibu Mary Jacob",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18495",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39d0272a8734a4477ae1f6aa46e60e4c4f62aa860ef3a9559c12f0aad180ecb2_w640_q70.webp",
      "contributions": "",
      "summary": "Enhancing Decision-Making in Windows PE Malware Classification During Dataset Shifts with Uncertainty Estimation",
      "mindmap": ""
    },
    {
      "title": "QLink: Quantum-Safe Bridge Architecture for Blockchain Interoperability",
      "authors": "Joao Vitor Barros Da Silva, Arsh Gupta, Madhusudan Singh Irish Singh",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18488",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e02fbe99369c3c9618e628a86d08ccf626f1aca4a527b850a2ca8f5e4e07b3b7_w640_q70.webp",
      "contributions": "",
      "summary": "QLink: Quantum-Safe Bridge Architecture for Blockchain Interoperability",
      "mindmap": ""
    },
    {
      "title": "Insider Threat Detection Using GCN and Bi-LSTM with Explicit and Implicit Graph Representations",
      "authors": "Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang, Deepa Krishnan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18483",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1c098db4784c358fb7712e2be8c3c8d57e56fd9982bed1aff3f16699a16acd5_w640_q70.webp",
      "contributions": "",
      "summary": "Insider Threat Detection Using GCN and Bi-LSTM with Explicit and Implicit Graph Representations",
      "mindmap": ""
    },
    {
      "title": "Exploring Runtime Evolution in Android: A Cross-Version Analysis and Its Implications for Memory Forensics",
      "authors": "Babangida Bappah, Lauren G Bristol, Lamine Noureddine, Sideeq Bello, Umar Farooq, Aisha Ali-Gombe",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18517",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3a9124bae944bbb77edacf0f4ebac5624e3871756f8c22623cad79c6ea90ea6_w640_q70.webp",
      "contributions": "",
      "summary": "Exploring Runtime Evolution in Android: A Cross-Version Analysis and Its Implications for Memory Forensics",
      "mindmap": ""
    },
    {
      "title": "Protecting Human Activity Signatures in Compressed IEEE 802.11 CSI Feedback",
      "authors": "Mohamed Seif, Atsutse Kludze, Yasaman Ghasempour, H. Vincent Poor, Doru Calin, Andrea J. Goldsmith",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18529",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60834618422ac43daf125b6ae809cb9caca5ae7aecdcc53fdd4dd87833f61165_w640_q70.webp",
      "contributions": "",
      "summary": "Protecting Human Activity Signatures in Compressed IEEE 802.11 CSI Feedback",
      "mindmap": ""
    },
    {
      "title": "SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models",
      "authors": "Scott Thornton",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18542",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afb4d99182c71c26adf649cc513b4f7ffee3c07f215e3f4067f2ce9fa660fa0_w640_q70.webp",
      "contributions": "",
      "summary": "SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models",
      "mindmap": ""
    },
    {
      "title": "Proof of Authenticity of General IoT Information with Tamper-Evident Sensors and Blockchain",
      "authors": "Kenji Saito",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18560",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/32ec910f91d8d1488c0f9d63f1d11998ee65c7eeda5092f2969d5ed6f17bd9c4_w640_q70.webp",
      "contributions": "",
      "summary": "Proof of Authenticity of General IoT Information with Tamper-Evident Sensors and Blockchain",
      "mindmap": ""
    },
    {
      "title": "DNA-HHE: Dual-mode Near-network Accelerator for Hybrid Homomorphic Encryption on the Edge",
      "authors": "Yifan Zhao, Xinglong Yu, Yi Sun, Honglin Kuang, Jun Han",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18589",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1feca70dc6f2a05e35a48f6366ccdcc1accb232952639d7388e6316ca2ff652_w640_q70.webp",
      "contributions": "",
      "summary": "DNA-HHE: Dual-mode Near-network Accelerator for Hybrid Homomorphic Encryption on the Edge",
      "mindmap": ""
    },
    {
      "title": "DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System",
      "authors": "Zelin Wan, Han Jun Yoon, Nithin Alluru, Terrence J. Moore, Frederica F. Nelson, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Jin-Hee Cho",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18616",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fabd2c171e25c623bc7edccb8e1ef0506a926726f1d2a534aaa0d5113899beef_w640_q70.webp",
      "contributions": "",
      "summary": "DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System",
      "mindmap": ""
    },
    {
      "title": "Volley Revolver: A Novel Matrix-Encoding Method for Privacy-Preserving Deep Learning (Inference++)",
      "authors": "John Chiang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18646",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e368d3e5db4c96274e913e493ec3645d2625f4f233460535fdf775708a0ed0c2_w640_q70.webp",
      "contributions": "",
      "summary": "Volley Revolver: A Novel Matrix-Encoding Method for Privacy-Preserving Deep Learning (Inference++)",
      "mindmap": ""
    },
    {
      "title": "Multi-user Pufferfish Privacy",
      "authors": "Ni Ding, Songpei Lu, Wenjing Yang, Zijian Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18632",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91f9592647748019dab19673d79af904cc80d33ef1df181ad2582a03befab28d_w640_q70.webp",
      "contributions": "",
      "summary": "Multi-user Pufferfish Privacy",
      "mindmap": ""
    },
    {
      "title": "An Evidence-Driven Analysis of Threat Information Sharing Challenges for Industrial Control Systems and Future Directions",
      "authors": "Adam Hahn, Rubin Krief, Daniel Rebori-Carretero, Rami Puzis, Aviad Elyashar, Nik Urlaub",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18714",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67ba83d343de59d6ad4835c11615a68ae02823674751eae72c951e5ffa996b91_w640_q70.webp",
      "contributions": "",
      "summary": "An Evidence-Driven Analysis of Threat Information Sharing Challenges for Industrial Control Systems and Future Directions",
      "mindmap": ""
    },
    {
      "title": "Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection",
      "authors": "Junjun Pan, Yixin Liu, Rui Miao, Kaize Ding, Yu Zheng, Quoc Viet Hung Nguyen, Alan Wee-Chung Liew, Shirui Pan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18733",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7692bd1c5b9a982f1df045d952e852c9a8c6543c4c09cb5bf1bd92156eff8c8_w640_q70.webp",
      "contributions": "",
      "summary": "Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection",
      "mindmap": ""
    },
    {
      "title": "ISADM: An Integrated STRIDE, ATT&CK, and D3FEND Model for Threat Modeling Against Real-world Adversaries",
      "authors": "Khondokar Fida Hasan, Hasibul Hossain Shajeeb, Chathura Abeydeera, Benjamin Turnbull, Matthew Warren",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18751",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0d7d9f521a08ec3b58bedb028c24a036f1bf9fb611e16b3ce8a155e036de227_w640_q70.webp",
      "contributions": "",
      "summary": "ISADM: An Integrated STRIDE, ATT&CK, and D3FEND Model for Threat Modeling Against Real-world Adversaries",
      "mindmap": ""
    },
    {
      "title": "Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform",
      "authors": "Yichuan Zhang, Chengxin Li, Yujie Gu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18791",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/828d54530ed9add4098a79bb9dd1f4047ed230dfaa399d57cade241c18713658_w640_q70.webp",
      "contributions": "",
      "summary": "Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform",
      "mindmap": ""
    },
    {
      "title": "DPSR: Differentially Private Sparse Reconstruction via Multi-Stage Denoising for Recommender Systems",
      "authors": "Sarwan Ali",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18932",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c243588ebf5b62b4dd8e1854c41bcdec7ca5861520351edb4b3b12455148d30_w640_q70.webp",
      "contributions": "",
      "summary": "DPSR: Differentially Private Sparse Reconstruction via Multi-Stage Denoising for Recommender Systems",
      "mindmap": ""
    },
    {
      "title": "Quantum-Resistant Cryptographic Models for Next-Gen Cybersecurity",
      "authors": "Navin Chhibber, Amber Rastogi, Ankur Mahida, Vatsal Gupta, Piyush Ranjan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19005",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea04e5e38bc4854340e0d603e34c5fcc7136f5ff54d7f066efb77c5035624266_w640_q70.webp",
      "contributions": "",
      "summary": "Quantum-Resistant Cryptographic Models for Next-Gen Cybersecurity",
      "mindmap": ""
    },
    {
      "title": "Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline",
      "authors": "Akshaj Prashanth Rao, Advait Singh, Saumya Kumaar Saksena, Dhruv Kumar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19011",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddd38197559bfa789648dce3d4d675d0a05e678684e3999b2ba550170a5c8c1e_w640_q70.webp",
      "contributions": "",
      "summary": "Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline",
      "mindmap": ""
    },
    {
      "title": "DREAM: Dynamic Red-teaming across Environments for AI Models",
      "authors": "Liming Lu, Xiang Gu, Junyu Huang, Jiawei Du, Yunhuai Liu, Yongbin Zhou, Shuchao Pang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19016",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91e616c1fdbbf1150b5cdb72c376c3ff57d358fe39b4baf04da4b689fec8de4e_w640_q70.webp",
      "contributions": "",
      "summary": "DREAM: Dynamic Red-teaming across Environments for AI Models",
      "mindmap": ""
    },
    {
      "title": "The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation",
      "authors": "Hengrui Jia, Taoran Li, Jonas Guan, Varun Chandrasekaran",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19025",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d72daaf4e0b704bed60ade2228f84dd6c37332a3588377ebc905b92f9db787ee_w640_q70.webp",
      "contributions": "",
      "summary": "The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation",
      "mindmap": ""
    },
    {
      "title": "Elevating Intrusion Detection and Security Fortification in Intelligent Networks through Cutting-Edge Machine Learning Paradigms",
      "authors": "Md Minhazul Islam Munna, Md Mahbubur Rahman, Jaroslav Frnda, Muhammad Shahid Anwar, Alpamis Kutlimuratov",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19037",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f65bbdc2e7a521d46fdaeebb4c5a652347737b90cb0eb72dc48b2bfbbff2789_w640_q70.webp",
      "contributions": "",
      "summary": "Elevating Intrusion Detection and Security Fortification in Intelligent Networks through Cutting-Edge Machine Learning Paradigms",
      "mindmap": ""
    },
    {
      "title": "ShadowBlock: Efficient Dynamic Anonymous Blocklisting and Its Cross-chain Application",
      "authors": "Haotian Deng, Mengxuan Liu, Chuan Zhang, Wei Huang, Licheng Wang, Liehuang Zhu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19124",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c67a059c6abcc0307e4cdb222a9a8b2f3e828338b324562c7dbf7e93c77ddf6_w640_q70.webp",
      "contributions": "",
      "summary": "ShadowBlock: Efficient Dynamic Anonymous Blocklisting and Its Cross-chain Application",
      "mindmap": ""
    },
    {
      "title": "Evaluating MCC for Low-Frequency Cyberattack Detection in Imbalanced Intrusion Detection Data",
      "authors": "Prameshwar Thiyagarajan, Chad A. Williams",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19203",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f1578028cd0a2c948eadde3675d01ec72ab2f150050f83c476aeffff73f5d5d_w640_q70.webp",
      "contributions": "",
      "summary": "Evaluating MCC for Low-Frequency Cyberattack Detection in Imbalanced Intrusion Detection Data",
      "mindmap": ""
    },
    {
      "title": "GShield: Mitigating Poisoning Attacks in Federated Learning",
      "authors": "Sameera K. M., Serena Nicolazzo, Antonino Nocera, Vinod P., Rafidha Rehiman K. A",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19286",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c43d719deb3b65a2681b1c10fbb4647b0e73aa0efbe80e20c06d9f27f59d1058_w640_q70.webp",
      "contributions": "",
      "summary": "GShield: Mitigating Poisoning Attacks in Federated Learning",
      "mindmap": ""
    },
    {
      "title": "Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models",
      "authors": "Linzhi Chen, Yang Sun, Hongru Wei, Yuqi Chen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19297",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb0bd7eb8763e5b7b48b95fffa2b9d2689db5cbe27fd8dd5ff4a8a691095d826_w640_q70.webp",
      "contributions": "",
      "summary": "Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models",
      "mindmap": ""
    },
    {
      "title": "Protecting Quantum Circuits Through Compiler-Resistant Obfuscation",
      "authors": "Pradyun Parayil, Amal Raj, Vivek Balachandran",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19314",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/19e9d703111b56760090d1bf98998cdf5b4c316d9a06f7c018c0611047912043_w640_q70.webp",
      "contributions": "",
      "summary": "Protecting Quantum Circuits Through Compiler-Resistant Obfuscation",
      "mindmap": ""
    },
    {
      "title": "From Retrieval to Reasoning: A Framework for Cyber Threat Intelligence NER with Explicit and Adaptive Instructions",
      "authors": "Jiaren Peng, Hongda Sun, Xuan Tian, Cheng Huang, Zeqing Li, Rui Yan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19414",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/553b6290892a9990d1a3b4b102abcd09ff7265499b12fe86a581ef08a388f0b6_w640_q70.webp",
      "contributions": "",
      "summary": "From Retrieval to Reasoning: A Framework for Cyber Threat Intelligence NER with Explicit and Adaptive Instructions",
      "mindmap": ""
    },
    {
      "title": "Cyber Risk Scoring with QUBO: A Quantum and Hybrid Benchmark Study",
      "authors": "Remo Marini, Riccardo Arpe",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18305",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2611d126f03f77f4504fe1684b664b5069d80a230d6375aa257b191a8ecde0d_w640_q70.webp",
      "contributions": "",
      "summary": "Cyber Risk Scoring with QUBO: A Quantum and Hybrid Benchmark Study",
      "mindmap": ""
    },
    {
      "title": "Cyber Threat Detection Enabled by Quantum Computing",
      "authors": "Zisheng Chen, Zirui Zhu, Xiangyang Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18493",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/800b297e42947ac3f131fc8b9b841d1b5589ec0804435fe50487c90a19edd302_w640_q70.webp",
      "contributions": "",
      "summary": "Cyber Threat Detection Enabled by Quantum Computing",
      "mindmap": ""
    },
    {
      "title": "MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval",
      "authors": "Saksham Sahai Srivastava, Haoyu He",
      "institution": "University of Georgia",
      "link": "https://arxiv.org/pdf/2512.16962",
      "code": null,
      "tags": [
        "llm inference",
        "retrieval-augmented generation",
        "long-term memory",
        "semantic imitation",
        "indirect injection attack",
        "memory poisoning",
        "MetaGPT",
        "DataInterpreter"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces MemoryGraft, a novel attack that poisons an LLM agent's long-term memory by implanting malicious successful experiences, which are then retrieved and imitated during future tasks. The method exploits the agent's semantic imitation heuristic through a poisoned RAG store, leading to persistent behavioral compromise. The authors demonstrate that this attack can cause significant and stealthy behavioral drift in agents like MetaGPT's DataInterpreter.",
      "mindmap": ""
    },
    {
      "title": "Adversarial VR: An Open-Source Testbed for Evaluating Adversarial Robustness of VR Cybersickness Detection and Mitigation",
      "authors": "Istiak Ahmed, Ripan Kumar Kundu, Khaza Anuarul Hoque",
      "institution": "University of Missouri-Columbia",
      "link": "https://arxiv.org/pdf/2512.17029",
      "code": null,
      "tags": [
        "others",
        "adversarial attacks",
        "deep learning",
        "cybersickness detection",
        "visual tunneling",
        "MI-FGSM",
        "PGD",
        "C&W",
        "DeepTCN",
        "Transformer"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a313962e09ceaa54a617d0e446a38a50ffa44d10894d76830f87cd1e74c0749_w640_q70.webp",
      "contributions": "",
      "summary": "This paper introduces Adversarial-VR, an open-source Unity testbed that integrates DeepTCN and Transformer models for real-time cybersickness detection and mitigation, and evaluates their robustness against adversarial attacks like MI-FGSM, PGD, and C&W. The results show these attacks can successfully fool the system, significantly degrading model accuracy and preventing correct mitigation.",
      "mindmap": ""
    },
    {
      "title": "Biosecurity-Aware AI: Agentic Risk Auditing of Soft Prompt Attacks on ESM-Based Variant Predictors",
      "authors": "Huixin Zhan",
      "institution": "New Mexico Institute of Mining and Technology",
      "link": "https://arxiv.org/pdf/2512.17146",
      "code": null,
      "tags": [
        "others",
        "soft prompt attacks",
        "adversarial auditing",
        "agentic framework",
        "risk metrics",
        "embedding-space robustness"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/edf3a867526cb70d49c0816641a925b129fe30dc5f7871777c74f463824654df_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces SAGE, an agentic framework that audits genomic foundation models by injecting soft prompt perturbations and evaluating performance degradation. It finds that models like ESM2 are vulnerable to such attacks, revealing hidden security risks in biomedical applications.",
      "mindmap": ""
    },
    {
      "title": "AlignDP: Hybrid Differential Privacy with Rarity-Aware Protection for LLMs",
      "authors": "Madhava Gaikwad",
      "institution": "Microsoft",
      "link": "https://arxiv.org/pdf/2512.17251",
      "code": null,
      "tags": [
        "post-training",
        "differential privacy",
        "local differential privacy",
        "RAPPOR",
        "PAC indistinguishability",
        "hybrid privacy",
        "rarity-aware protection"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes AlignDP, a hybrid privacy mechanism that protects large language models by separating data into rare and non-rare fields. Rare fields are shielded with PAC indistinguishability for strong privacy, while non-rare fields are privatized using RAPPOR to allow useful frequency estimation. This approach aims to prevent knowledge extraction and unauthorized fine-tuning by design, making models more secure against distillation and editing attacks.",
      "mindmap": ""
    },
    {
      "title": "Practical Framework for Privacy-Preserving and Byzantine-robust Federated Learning",
      "authors": "Baolei Zhang, Minghong Fang, Zhuqing Liu, Biao Yi, Peizhao Zhou, Yuan Wang, Tong Li, Zheli Liu",
      "institution": "Nankai University, University of Louisville, University of North Texas",
      "link": "https://arxiv.org/pdf/2512.17254",
      "code": null,
      "tags": [
        "fault-tolerance",
        "federated learning",
        "byzantine-robust aggregation",
        "privacy-preserving",
        "dimensionality reduction",
        "secure multi-party computation",
        "adaptive tuning"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes ABBR, a practical framework for federated learning that combines Byzantine-robust aggregation with privacy-preserving techniques. Its core method uses dimensionality reduction to speed up private computations and an adaptive tuning strategy to minimize the impact of malicious models. The framework is shown to run significantly faster with minimal overhead while maintaining strong Byzantine resilience.",
      "mindmap": ""
    },
    {
      "title": "AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens",
      "authors": "Tung-Ling Li, Yuhao Wu, Hongliang Liu",
      "institution": "Palo Alto Networks",
      "link": "https://arxiv.org/pdf/2512.17375",
      "code": null,
      "tags": [
        "post-training",
        "adversarial control tokens",
        "beam-search exploration",
        "last-layer logit gap",
        "LoRA-based adversarial training",
        "reward hacking"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces AdvJudge-Zero, a method that uses beam-search on a model's next-token distribution to discover short, low-perplexity control token sequences that can flip the binary decisions of LLM-as-a-Judge systems from \"No\" to \"Yes\". It concludes that these tokens represent a realistic reward-hacking vulnerability in post-training pipelines, and shows that adversarial training can mitigate the issue while preserving evaluation quality.",
      "mindmap": ""
    },
    {
      "title": "DeepShare: Sharing ReLU Across Channels and Layers for Efficient Private Inference",
      "authors": "Yonathan Bornfeld, Shai Avidan",
      "institution": "Tel Aviv University",
      "link": "https://arxiv.org/pdf/2512.17398",
      "code": null,
      "tags": [
        "others",
        "Private Inference",
        "ReLU sharing",
        "DReLU",
        "cryptographic protocols",
        "activation sharing"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f38ab38719abeec4c59d997e57b2ecf1dd76acec3485b40aa5ccef81258f3179_w640_q70.webp",
      "contributions": "",
      "summary": "This paper introduces DeepShare, a method for efficient Private Inference (PI) that reduces computational costs by sharing the DReLU (the non-linear step function of ReLU) across channels and layers within a neural network. It achieves state-of-the-art results by drastically decreasing the number of expensive DReLU operations while maintaining model performance on tasks like classification and segmentation.",
      "mindmap": ""
    },
    {
      "title": "Detection and Analysis of Sensitive and Illegal Content on the Ethereum Blockchain Using Machine Learning Techniques",
      "authors": "Xingyu Feng",
      "institution": "Hainan University",
      "link": "https://arxiv.org/pdf/2512.17411",
      "code": null,
      "tags": [
        "others",
        "FastText",
        "NSFWJS",
        "sentiment analysis",
        "data restoration",
        "classification"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abd921f37f90b9dfaf497e986d1ae89307cf4b11dd527bf09bd11e36d239652c_w640_q70.webp",
      "contributions": "",
      "summary": "This paper presents a method for detecting sensitive and illegal content on the Ethereum blockchain using machine learning. It employs a data restoration algorithm and uses FastText for sentiment analysis and NSFWJS for image detection. The study concludes that harmful content, including personal data and explicit images, coexists with benign data on the blockchain, highlighting privacy and security concerns.",
      "mindmap": ""
    },
    {
      "title": "Key-Conditioned Orthonormal Transform Gating (K-OTG): Multi-Key Access Control with Hidden-State Scrambling for LoRA-Tuned Models",
      "authors": "Muhammad Haris Khan",
      "institution": "University of Copenhagen",
      "link": "https://arxiv.org/pdf/2512.17519",
      "code": null,
      "tags": [
        "llm inference",
        "LoRA",
        "PEFT",
        "orthonormal transform",
        "hidden-state scrambling",
        "access control",
        "instruction tuning",
        "4-bit quantization"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes K-OTG, a method for secret-key access control in language models. It uses a training-time dual-path corpus and inference-time orthonormal transforms to scramble hidden states, making the model unusable without the correct key while preserving authorized performance. The method is compatible with LoRA and 4-bit quantization, showing effective locking with minimal utility loss for authorized users.",
      "mindmap": ""
    },
    {
      "title": "SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals",
      "authors": "Muhammad Haris Khan",
      "institution": "University of Copenhagen",
      "link": "https://arxiv.org/pdf/2512.17527",
      "code": null,
      "tags": [
        "protein hazard screening",
        "homology clustering",
        "cluster-level holdout",
        "logistic regression",
        "random forest",
        "linear SVM",
        "calibrated probabilities",
        "AUROC",
        "AUPRC",
        "Brier score",
        "Expected Calibration Error"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces SafeBench-Seq, a benchmark and baseline classifier for screening hazardous protein sequences using only interpretable physicochemical and compositional features. The method employs homology clustering at ≤40% identity with cluster-level holdouts to evaluate performance on novel threats. The main conclusion is that random data splits overestimate robustness compared to this stricter homology-controlled evaluation, and that calibrated linear models provide good probability calibration for this CPU-only screening task.",
      "mindmap": ""
    },
    {
      "title": "MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification",
      "authors": "Tosin Ige, Christopher Kiekintveld, Aritran Piplai, Asif Rahman, Olukunle Kolade, Sasidhar Kunapuli",
      "institution": "The University of Texas at El Paso, University of North Carolina",
      "link": "https://arxiv.org/pdf/2512.17594",
      "code": null,
      "tags": [
        "others",
        "Gaussian Discriminant Analysis",
        "Z-score distance analysis",
        "cluster-driven deep learning",
        "two-stage framework"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes MAD-OOD, a two-stage cluster-driven deep learning framework for out-of-distribution malware detection. It uses Gaussian Discriminant Analysis to model class embeddings and Z-score distance analysis to identify anomalies, then integrates these predictions with a neural network for final classification. The method significantly outperforms state-of-the-art approaches on benchmark datasets, achieving high AUC for detecting unseen malware families.",
      "mindmap": ""
    },
    {
      "title": "STAR: Semantic-Traffic Alignment and Retrieval for Zero-Shot HTTPS Website Fingerprinting",
      "authors": "Yifei Cheng, Yujia Zhu, Baiyang Li, Xinhao Deng, Yitong Cai, Yaochen Ren, Qingyun Liu",
      "institution": "Institute of Information Engineering, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Tsinghua University",
      "link": "https://arxiv.org/pdf/2512.17667",
      "code": null,
      "tags": [
        "multi-modal inference",
        "zero-shot learning",
        "cross-modal retrieval",
        "dual-encoder architecture",
        "contrastive learning",
        "structure-aware augmentation",
        "semantic-traffic alignment"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces STAR, a method that reformulates website fingerprinting as a zero-shot cross-modal retrieval problem, using a dual-encoder architecture to learn a joint embedding space for encrypted traffic traces and website logic profiles. It achieves high accuracy on unseen websites by aligning semantic and traffic features, demonstrating that semantic leakage is a major privacy risk in encrypted HTTPS traffic.",
      "mindmap": ""
    },
    {
      "title": "Digital and Web Forensics Model Cards, V1",
      "authors": "Paola Di Maio",
      "institution": "Ronin Institute, W3C AI Knowledge Representation Community Group",
      "link": "https://arxiv.org/pdf/2512.17722",
      "code": null,
      "tags": [
        "knowledge representation",
        "model cards",
        "controlled vocabularies",
        "web-based generator",
        "digital forensics",
        "web forensics"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a web-based framework for generating standardized model cards to represent knowledge in digital and web forensics, featuring controlled vocabularies for classification, reasoning, bias, and error. The main conclusion is the presentation of this beta framework and tool to establish an emerging standard, inviting community feedback for refinement.",
      "mindmap": ""
    },
    {
      "title": "Adversarial Robustness of Vision in Open Foundation Models",
      "authors": "Jonathon Fox, William J Buchanan, Pavlos Papadopoulos",
      "institution": "Edinburgh Napier University",
      "link": "https://arxiv.org/pdf/2512.17902",
      "code": null,
      "tags": [
        "multi-modal inference",
        "Projected Gradient Descent",
        "adversarial robustness",
        "Visual Question Answering",
        "vision-language models"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper evaluates the adversarial robustness of vision-language models LLaVA-1.5-13B and Llama 3.2 Vision-8B-2 by applying untargeted Projected Gradient Descent attacks to their visual inputs and testing on a VQA v2 subset. The main conclusion is that the vision modality is a viable attack vector, and adversarial robustness does not directly correlate with standard benchmark performance, with Llama 3.2 Vision showing a smaller accuracy drop under attack despite a lower baseline.",
      "mindmap": ""
    },
    {
      "title": "PHANTOM: Progressive High-fidelity Adversarial Network for Threat Object Modeling",
      "authors": "Jamal Al-Karaki, Muhammad Al-Zafar Khan, Rand Derar Mohammad Al Athamneh",
      "institution": "Zayed University, The Hashemite University",
      "link": "https://arxiv.org/pdf/2512.15768",
      "code": null,
      "tags": [
        "others",
        "adversarial variational framework",
        "progressive training",
        "dual-path VAE-GAN",
        "domain-specific feature matching",
        "synthetic data generation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces PHANTOM, a progressive adversarial variational framework that uses a dual-path VAE-GAN architecture with domain-specific feature matching to generate high-fidelity synthetic cyberattack data. The method achieves 98% weighted accuracy in intrusion detection when models are trained on its synthetic data, demonstrating its effectiveness for augmenting training datasets, though it faces challenges with generating rare attack types.",
      "mindmap": ""
    },
    {
      "title": "Data-Chain Backdoor: Do You Trust Diffusion Models as Generative Data Supplier?",
      "authors": "Junchi Lu, Xinke Li, Yuheng Liu, Qi Alfred Chen",
      "institution": "University of California, Irvine, City University of Hong Kong",
      "link": "https://arxiv.org/pdf/2512.15769",
      "code": null,
      "tags": [
        "diffusion inference",
        "Data-Chain Backdoor (DCB)",
        "clean-label attack",
        "Early-Stage Trigger Manifestation (ESTM)",
        "backdoor triggers",
        "synthetic data generation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates the Data-Chain Backdoor (DCB) threat, where backdoor triggers are injected into and propagated through open-source diffusion models used for synthetic data generation. The method reveals that these triggers are memorized and reproduced in the generated data, subsequently poisoning downstream models, even in clean-label attack scenarios. The main conclusion is that this poses a severe, previously underexplored security risk in generative data pipelines, highlighting the need for mitigation strategies.",
      "mindmap": ""
    },
    {
      "title": "Adversarial Robustness in Financial Machine Learning: Defenses, Economic Impact, and Governance Evidence",
      "authors": "Samruddhi Baviskar",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.15780",
      "code": null,
      "tags": [
        "adversarial robustness",
        "adversarial training",
        "FGSM",
        "PGD",
        "SHAP",
        "Expected Calibration Error (ECE)",
        "Value-at-Risk (VaR)",
        "Expected Shortfall (ES)",
        "bootstrap inference"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces a dataset-agnostic pipeline to evaluate adversarial robustness in tabular financial ML models using gradient-based attacks like FGSM and PGD. It finds that small perturbations significantly degrade model performance and increase financial risk, but adversarial training can partially recover utility. The study also suggests SHAP stability as an early-warning indicator for adversarial influence.",
      "mindmap": ""
    },
    {
      "title": "Hyperparameter Tuning-Based Optimized Performance Analysis of Machine Learning Algorithms for Network Intrusion Detection",
      "authors": "Sudhanshu Sekhar Tripathy, Bichitrananda Behera",
      "institution": "C.V. Raman Global University",
      "link": "https://arxiv.org/pdf/2512.15779",
      "code": null,
      "tags": [
        "others",
        "hyperparameter tuning",
        "grid search",
        "random search",
        "recursive feature elimination",
        "support vector machine",
        "KDD CUP 1999 dataset",
        "tenfold cross-validation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper evaluates multiple machine learning algorithms for network intrusion detection, applying hyperparameter tuning via grid and random search along with Recursive Feature Elimination. The optimized Support Vector Machine classifier achieved the highest accuracy of 99.12% on the KDD CUP 1999 dataset, demonstrating that systematic tuning significantly enhances detection performance.",
      "mindmap": ""
    },
    {
      "title": "Auto-Tuning Safety Guardrails for Black-Box Large Language Models",
      "authors": "Perry Abdulkadir",
      "institution": "University of St. Thomas",
      "link": "https://arxiv.org/pdf/2512.15782",
      "code": null,
      "tags": [
        "llm inference",
        "hyperparameter optimization",
        "system prompts",
        "content filters",
        "jailbreak detection",
        "malware generation",
        "Optuna",
        "ModernBERT",
        "grid search"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes treating the design of safety guardrails (like system prompts and content filters) for a frozen black-box LLM as a hyperparameter optimization problem. Using a proof-of-concept with Mistral-7B-Instruct and ModernBERT, it shows that a black-box optimizer (Optuna) can efficiently find safe configurations, matching the best grid search results with far fewer evaluations and less time. The conclusion is that this auto-tuning approach is a feasible method to harden LLM deployments under practical constraints.",
      "mindmap": ""
    },
    {
      "title": "RAMBO: Reliability Analysis for Mamba through Bit-flip attack Optimization",
      "authors": "Sanjay Das, Swastik Bhattacharya, Shamik Kundu, Arnab Raha, Souvik Kundu, Kanad Basu",
      "institution": "University of Texas at Dallas, Intel Corporation, Rensselaer Polytechnic Institute",
      "link": "https://arxiv.org/pdf/2512.15778",
      "code": null,
      "tags": [
        "fault-tolerance",
        "bit-flip attack",
        "state-space models",
        "Mamba",
        "hardware faults",
        "adversarial robustness"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces RAMBO, a framework for conducting bit-flip attacks on Mamba-based state-space models to analyze their reliability. It demonstrates that flipping a single critical bit can catastrophically degrade model performance, reducing accuracy to 0% and drastically increasing perplexity. The results highlight the pronounced vulnerability of these efficient sequence models to hardware-level adversarial perturbations.",
      "mindmap": ""
    },
    {
      "title": "An empirical analysis of zero-day vulnerabilities disclosed by the zero day initiative",
      "authors": "Apurva Shet, Izzat Alsmadi",
      "institution": "Texas A&M University - San Antonio",
      "link": "https://arxiv.org/pdf/2512.15803",
      "code": null,
      "tags": [
        "others",
        "CVSS",
        "vulnerability classification",
        "machine learning",
        "deep learning",
        "predictive modeling"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper analyzes zero-day vulnerabilities disclosed by the Zero Day Initiative, employing machine learning and deep learning models on structured metadata and textual descriptions to classify severity. It aims to identify trends and characteristics indicative of high-severity vulnerabilities. The findings are intended to improve patch prioritization and vulnerability management strategies.",
      "mindmap": ""
    },
    {
      "title": "Cybercrime and Computer Forensics in Epoch of Artificial Intelligence in India",
      "authors": "Sahibpreet Singh, Shikha Dhiman",
      "institution": "Guru Nanak Dev University, Amritsar",
      "link": "https://arxiv.org/pdf/2512.15799",
      "code": null,
      "tags": [
        "cybersecurity",
        "computer forensics",
        "explainable AI (XAI)",
        "data minimization",
        "algorithmic bias",
        "deepfakes",
        "adversarial AI",
        "Digital Personal Data Protection Act"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper employs a doctrinal legal methodology to analyze the integration of AI into cybercrime and forensics in India, focusing on the Digital Personal Data Protection Act, 2023. It concludes that there is a critical tension between privacy principles and forensic needs, and proposes a human-centric forensic model using explainable AI (XAI) to ensure evidence admissibility while advocating for legislative synchronization with international standards.",
      "mindmap": ""
    },
    {
      "title": "Secure AI-Driven Super-Resolution for Real-Time Mixed Reality Applications",
      "authors": "Mohammad Waquas Usmani, Sankalpa Timilsina, Michael Zink, Susmit Shannigrahi",
      "institution": "University of Massachusetts Amherst, Tennessee Technological University",
      "link": "https://arxiv.org/pdf/2512.15823",
      "code": null,
      "tags": [
        "multi-modal inference",
        "point cloud super-resolution",
        "attribute-based encryption",
        "downsampling",
        "upscaling"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a system to reduce latency in AR/VR streaming by downsampling and partially encrypting point cloud content at the server, then using a machine learning-based super-resolution model to reconstruct it at the client. The evaluation shows this approach effectively reduces bandwidth and encryption overhead while accurately reconstructing the original point clouds with minimal error.",
      "mindmap": ""
    },
    {
      "title": "VET Your Agent: Towards Host-Independent Autonomy via Verifiable Execution Traces",
      "authors": "Artem Grigor, Christian Schroeder de Witt, Simon Birnbach, Ivan Martinovic",
      "institution": "University of Oxford",
      "link": "https://arxiv.org/pdf/2512.15892",
      "code": null,
      "tags": [
        "others",
        "verifiable execution traces",
        "agent identity document",
        "web proofs",
        "tee proxy",
        "host-independent authentication"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces VET, a framework for achieving host-independent authentication of autonomous agent outputs using verifiable execution traces and an Agent Identity Document. It demonstrates that practical authentication is possible by composing proof mechanisms like Web Proofs and TEE Proxies, with a case study showing overhead typically under 3x for API calls.",
      "mindmap": ""
    },
    {
      "title": "Autoencoder-based Denoising Defense against Adversarial Attacks on Object Detection",
      "authors": "Min Geun Song, Gang Min Kim, Woonmin Kim, Yongsik Kim, Jeonghyun Sim, Sangbeom Park, Huy Kang Kim",
      "institution": "Korea University",
      "link": "https://arxiv.org/pdf/2512.16123",
      "code": null,
      "tags": [
        "others",
        "autoencoder",
        "denoising",
        "adversarial attack",
        "Perlin noise",
        "YOLOv5",
        "object detection"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes an autoencoder-based denoising defense to mitigate adversarial attacks on object detection models. The method uses a single-layer convolutional autoencoder to remove Perlin noise perturbations from images before feeding them to a YOLOv5 detector. The results show that this approach provides a partial recovery of detection performance without requiring model retraining.",
      "mindmap": ""
    },
    {
      "title": "In-Context Probing for Membership Inference in Fine-Tuned Language Models",
      "authors": "Zhexi Lu, Hongliang Chi, Nathalie Baracaldo, Swanand Ravindra Kadhe, Yuseok Jeon, Lei Yu",
      "institution": "Rensselaer Polytechnic Institute, IBM Research, Korea University",
      "link": "https://arxiv.org/pdf/2512.16292",
      "code": null,
      "tags": [
        "llm inference",
        "membership inference attacks",
        "in-context probing",
        "optimization gap",
        "black-box attacks",
        "fine-tuning",
        "PEFT"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes ICP-MIA, a membership inference attack framework that estimates the optimization gap via in-context probing to simulate fine-tuning behavior without retraining. It shows that this method outperforms prior black-box attacks, especially at low false positive rates, providing a practical tool for auditing privacy risks in deployed LLMs.",
      "mindmap": ""
    },
    {
      "title": "Love, Lies, and Language Models: Investigating AI's Role in Romance-Baiting Scams",
      "authors": "Gilad Gressel, Rahul Pankajakshan, Shir Rozenfeld, Ling Li, Ivan Franceschini, Krishnahsree Achuthan, Yisroel Mirsky",
      "institution": "Amrita Vishwa Vidyapeetham, Ca’ Foscari University of Venice, University of Melbourne, Ben Gurion University of the Negev",
      "link": "https://arxiv.org/pdf/2512.16280",
      "code": null,
      "tags": [
        "llm inference",
        "large language models",
        "safety filters",
        "conversation study",
        "social engineering",
        "automation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper investigates the role of LLMs in romance-baiting scams through interviews with insiders and victims, a blinded long-term conversation study comparing LLM agents to human operators, and an evaluation of commercial safety filters. It finds that LLMs are already widely used in scams, can elicit greater trust and compliance than humans, and that current safety filters are ineffective at detecting such dialogues, suggesting scams are ripe for full LLM automation.",
      "mindmap": ""
    },
    {
      "title": "Beyond the Benchmark: Innovative Defenses Against Prompt Injection Attacks",
      "authors": "Safwan Shaheer, G.M. Refatul Islam, Mohammad Rafid Hamid, Tahsin Zaman Jilan",
      "institution": "BRAC University",
      "link": "https://arxiv.org/pdf/2512.16307",
      "code": null,
      "tags": [
        "llm inference",
        "prompt injection defense",
        "goal-hijacking",
        "Chain Of Thoughts",
        "automatic defense generation",
        "LLaMA"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a novel defense framework against prompt injection attacks for small open-source LLMs like LLaMA, using an iterative refinement process based on a Chain Of Thoughts seed to generate automatic defenses. The method significantly improves the detection of goal-hijacking attacks, reducing both attack success rates and false detection rates. The work demonstrates that this approach enables more secure and efficient deployment of LLMs in resource-constrained environments.",
      "mindmap": ""
    },
    {
      "title": "Agent Tools Orchestration Leaks More: Dataset, Benchmark, and Mitigation",
      "authors": "Yuxuan Qiao, Dongqin Liu, Hongchang Yang, Wei Zhou, Songlin Hu",
      "institution": "Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences",
      "link": "https://arxiv.org/pdf/2512.16310",
      "code": null,
      "tags": [
        "llm inference",
        "Tools Orchestration Privacy Risk (TOP-R)",
        "TOP-Bench",
        "Privacy Enhancement Principle (PEP)",
        "H-Score",
        "Risk Leakage Rate (RLR)"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper identifies and studies a new privacy risk in single-agent, multi-tool LLM architectures, termed Tools Orchestration Privacy Risk (TOP-R), where agents can synthesize sensitive information from aggregated tool outputs. It introduces a benchmark (TOP-Bench) and a mitigation method called the Privacy Enhancement Principle (PEP). The main conclusion is that TOP-R is a severe and prevalent risk in current models, but the proposed PEP method can effectively reduce leakage and improve the safety-robustness trade-off.",
      "mindmap": ""
    },
    {
      "title": "A Systematic Study of Code Obfuscation Against LLM-based Vulnerability Detection",
      "authors": "Xiao Li, Yue Li, Hao Wu, Yue Zhang, Yechao Zhang, Fengyuan Xu, Sheng Zhong",
      "institution": "Nanjing University, Shandong University, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.16538",
      "code": null,
      "tags": [
        "llm inference",
        "code obfuscation",
        "layout obfuscation",
        "data flow obfuscation",
        "control flow obfuscation",
        "LLM-driven implementation",
        "vulnerability detection",
        "adversarial robustness"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper systematically studies the impact of code obfuscation on LLM-based vulnerability detection by categorizing obfuscation techniques into layout, data flow, and control flow classes and implementing them across multiple programming languages. It evaluates these techniques against 15 LLMs and two coding agents, finding that obfuscation can both improve and degrade detection performance depending on the vulnerability type, code properties, and model attributes. The study highlights the need to enhance LLM robustness for reliable real-world security auditing.",
      "mindmap": ""
    },
    {
      "title": "Prefix Probing: Lightweight Harmful Content Detection for Large Language Models",
      "authors": "Jirui Yang, Hengqi Guo, Zhihui Lu, Yi Zhao, Yuansen Zhang, Shijing Hu, Qiang Duan, Yinggui Wang, Tao Wei",
      "institution": "Fudan University, Ant Group, Pennsylvania State University",
      "link": "https://arxiv.org/pdf/2512.16650",
      "code": null,
      "tags": [
        "llm inference",
        "prefix probing",
        "black-box detection",
        "log-probability comparison",
        "prefix caching",
        "prefix construction algorithm",
        "harmful content detection"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces Prefix Probing, a lightweight method for detecting harmful content in LLMs by comparing the model's log-probabilities for \"agreement\" versus \"refusal\" response prefixes. It uses prefix caching to reduce latency and an algorithm to automatically construct effective probe prefixes. The method achieves detection accuracy comparable to external safety models with minimal computational overhead, requiring no extra model deployment.",
      "mindmap": ""
    },
    {
      "title": "Protecting Deep Neural Network Intellectual Property with Chaos-Based White-Box Watermarking",
      "authors": "Sangeeth B, Serena Nicolazzo, Deepa K., Vinod P",
      "institution": "Cochin University of Science and Technology, University of Eastern Piedmont",
      "link": "https://arxiv.org/pdf/2512.16658",
      "code": null,
      "tags": [
        "others",
        "white-box watermarking",
        "chaotic sequences",
        "logistic map",
        "genetic algorithm",
        "weight injection"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes a white-box watermarking method for deep neural networks that embeds ownership information into model weights using chaotic sequences generated by a logistic map. Ownership verification is performed via a genetic algorithm to recover the original chaotic parameters. The approach maintains model accuracy and remains detectable after fine-tuning, offering a scalable solution for intellectual property protection.",
      "mindmap": ""
    },
    {
      "title": "Phishing Detection System: An Ensemble Approach Using Character-Level CNN and Feature Engineering",
      "authors": "Rudra Dubey, Arpit Mani Tripathi, Archit Srivastava, Sarvpal Singh",
      "institution": "Madan Mohan Malaviya University of Technology",
      "link": "https://arxiv.org/pdf/2512.16717",
      "code": null,
      "tags": [
        "others",
        "ensemble learning",
        "character-level CNN",
        "LightGBM",
        "feature engineering",
        "URL analysis",
        "FastAPI"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a phishing detection system using an ensemble model that combines a character-level Convolutional Neural Network (CNN) with a LightGBM classifier based on engineered URL features. The system achieves high performance metrics, such as 99.819% accuracy, and is deployed as a real-time service via FastAPI. The results show the ensemble approach outperforms individual models, effectively identifying modern phishing techniques with low false positive rates.",
      "mindmap": ""
    },
    {
      "title": "PrivateXR: Defending Privacy Attacks in Extended Reality Through Explainable AI-Guided Differential Privacy",
      "authors": "Ripan Kumar Kundu, Istiak Ahmed, Khaza Anuarul Hoque",
      "institution": "University of Missouri-Columbia",
      "link": "https://arxiv.org/pdf/2512.16851",
      "code": null,
      "tags": [
        "others",
        "explainable AI",
        "differential privacy",
        "membership inference attack",
        "re-identification attack",
        "post-hoc explanations",
        "feature selection",
        "transformer models"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes a framework that uses explainable AI (XAI) to identify the most influential features in AI-XR models and selectively applies differential privacy (DP) to those features during inference to defend against privacy attacks. This XAI-guided DP approach reduces the success rates of membership inference and re-identification attacks while preserving model accuracy and improving inference time compared to traditional DP. The method is deployed as a system called PrivateXR on an HTC VIVE Pro headset, allowing users to adjust privacy levels in real-time during XR gameplay.",
      "mindmap": ""
    },
    {
      "title": "Pixel Seal: Adversarial-only training for invisible image and video watermarking",
      "authors": "Tomáš Souček, Pierre Fernandez, Hady Elsahar, Sylvestre-Alvise Rebuffi, Valeriu Lacatusu, Tuan Tran, Tom Sander, Alexandre Mourachko",
      "institution": "Meta FAIR",
      "link": "https://arxiv.org/pdf/2512.16874",
      "code": null,
      "tags": [
        "multi-modal training",
        "adversarial-only training",
        "three-stage training schedule",
        "JND-based attenuation",
        "temporal watermark pooling"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "Pixel Seal introduces an adversarial-only training paradigm for invisible watermarking, eliminating unreliable perceptual losses and using a three-stage schedule to decouple robustness and imperceptibility. It addresses high-resolution scaling with JND-based attenuation and adapts to video via temporal pooling. The method achieves state-of-the-art robustness and imperceptibility for image and video watermarking.",
      "mindmap": ""
    },
    {
      "title": "Non-Linear Strong Data-Processing for Quantum Hockey-Stick Divergences",
      "authors": "Theshani Nuradha, Ian George, Christoph Hirche",
      "institution": "University of Illinois Urbana-Champaign, National University of Singapore, Leibniz Universität Hannover",
      "link": "https://arxiv.org/pdf/2512.16778",
      "code": null,
      "tags": [
        "quantum information theory",
        "strong data-processing inequalities",
        "hockey-stick divergence",
        "quantum channels",
        "contraction coefficients",
        "Fγ curves",
        "reverse-Pinsker inequalities"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper establishes non-linear strong data-processing inequalities (SDPI) for quantum hockey-stick divergences, improving upon existing linear bounds. The method involves defining Fγ curves to characterize SDPI for sequential compositions of noisy quantum channels. The results enable tighter finite mixing time bounds and stronger privacy guarantees for sequential private quantum channels.",
      "mindmap": ""
    },
    {
      "title": "Zero-Knowledge Audit for Internet of Agents: Privacy-Preserving Communication Verification with Model Context Protocol",
      "authors": "Guanlin Jing, Huayi Qi",
      "institution": "Beijing University of Technology",
      "link": "https://arxiv.org/pdf/2512.14737",
      "code": null,
      "tags": [
        "others",
        "zero-knowledge proof",
        "Model Context Protocol",
        "privacy-preserving audit",
        "Circom",
        "mutual auditing"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a framework that integrates zero-knowledge proofs with the Model Context Protocol (MCP) to enable verifiable, privacy-preserving audits of agent communications without revealing message content. It achieves mutual auditing for compliance and billing while maintaining data authenticity and privacy with negligible latency overhead. The authors implement the system, claiming it is the first to offer such verifiable mutual auditing for agent communications.",
      "mindmap": ""
    },
    {
      "title": "Quantum-Augmented AI/ML for O-RAN: Hierarchical Threat Detection with Synergistic Intelligence and Interpretability (Technical Report)",
      "authors": "Tan Le, Van Le, Sachin Shetty",
      "institution": "Hampton University, Virginia Polytechnic Institute and State University, Old Dominion University",
      "link": "https://arxiv.org/pdf/2512.14742",
      "code": null,
      "tags": [
        "others",
        "quantum machine learning",
        "hybrid quantum computing",
        "amplitude encoding",
        "entanglement encoding",
        "hierarchical threat detection",
        "anomaly detection",
        "intrusion confirmation",
        "multiattack classification",
        "deep neural networks",
        "ensemble classifiers"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a hierarchical cybersecurity framework for Open Radio Access Networks (O-RAN) that integrates hybrid quantum computing and machine learning. The method uses quantum-inspired feature encodings (amplitude- and entanglement-based) with deep and ensemble classifiers for anomaly detection, intrusion confirmation, and multiattack classification. The framework demonstrates near-perfect accuracy, high recall, and strong interpretability, indicating readiness for scalable deployment in O-RAN environments.",
      "mindmap": ""
    },
    {
      "title": "Persistent Backdoor Attacks under Continual Fine-Tuning of LLMs",
      "authors": "Jing Cui, Yufei Han, Jianbin Jiao, Junge Zhang",
      "institution": "University of Chinese Academy of Sciences, INRIA, Institute of Automation, Chinese Academy of Sciences",
      "link": "https://arxiv.org/pdf/2512.14741",
      "code": null,
      "tags": [
        "post-training",
        "backdoor attack",
        "continual fine-tuning",
        "gradient alignment",
        "P-Trojan",
        "persistence"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes P-Trojan, a backdoor attack method that optimizes for persistence by aligning poisoned gradients with clean task gradients on token embeddings during model poisoning. Experiments show it maintains over 99% backdoor persistence across continual fine-tuning updates on models like Qwen2.5 and LLaMA3 without harming clean-task accuracy. This highlights the need for stronger defenses and persistence-aware evaluation in real-world LLM adaptation pipelines.",
      "mindmap": ""
    },
    {
      "title": "Factor(U,T): Controlling Untrusted AI by Monitoring their Plans",
      "authors": "Edward Lue Chee Lip, Anthony Channg, Diana Kim, Aaron Sandoval, Kevin Zhu",
      "institution": "Algoverse AI Research, Colorado State University, Orange Coast College",
      "link": "https://arxiv.org/pdf/2512.14745",
      "code": null,
      "tags": [
        "ai safety",
        "factored cognition",
        "control protocols",
        "task decomposition",
        "untrusted decomposer",
        "monitoring",
        "BigCodeBench",
        "AUROC"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces Factor(U,T), a protocol where an untrusted, potentially malicious AI model decomposes a complex task into subtasks, which are then implemented by trusted models. It finds that monitoring only the natural language decomposition plans is ineffective for detecting attacks, whereas monitoring the concrete code solutions of the subtasks provides strong safety and discrimination. The main conclusion is that implementation-context monitoring is crucial for safety when using untrusted models for task decomposition.",
      "mindmap": ""
    },
    {
      "title": "CODE ACROSTIC: Robust Watermarking for Code Generation",
      "authors": "Li Lin, Siyuan Xin, Yang Cao, Xiaochun Cao",
      "institution": "Institute of Science Tokyo, Shanghai University, Sun Yat-sen University",
      "link": "https://arxiv.org/pdf/2512.14753",
      "code": null,
      "tags": [
        "post-training",
        "watermarking",
        "cue list",
        "low-entropy",
        "high-entropy",
        "comment removal attack"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a robust watermarking method for LLM-generated code that uses a Cue List to distinguish between low and high-entropy parts of the code for targeted watermark injection. It addresses the vulnerability of existing methods to comment removal attacks. The evaluation shows the method achieves higher detectability and usability compared to state-of-the-art techniques.",
      "mindmap": ""
    },
    {
      "title": "One Leak Away: How Pretrained Model Exposure Amplifies Jailbreak Risks in Finetuned LLMs",
      "authors": "Yixin Tan, Zhe Yu, Jun Sakuma",
      "institution": "Institute of Science Tokyo, Riken AIP",
      "link": "https://arxiv.org/pdf/2512.14751",
      "code": null,
      "tags": [
        "post-training",
        "jailbreak attack",
        "adversarial prompt",
        "representation-level probing",
        "linear separability",
        "Probe-Guided Projection (PGP)",
        "transferability",
        "finetuning",
        "pretrained model"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates how jailbreak vulnerabilities transfer from pretrained to finetuned LLMs. It introduces the Probe-Guided Projection (PGP) attack, which uses representation-level probing to guide adversarial prompt optimization for better transferability. The main conclusion is that the pretrain-finetune paradigm inherently amplifies security risks, as vulnerabilities encoded in the pretrained model's representations are inherited by its finetuned variants.",
      "mindmap": ""
    },
    {
      "title": "Privacy-Preserving Feature Valuation in Vertical Federated Learning Using Shapley-CMI and PSI Permutation",
      "authors": "Unai Laskurain, Aitor Aguirre-Ortuzar, Urko Zurutuza",
      "institution": "Mondragon Unibertsitatea",
      "link": "https://arxiv.org/pdf/2512.14767",
      "code": null,
      "tags": [
        "others",
        "Shapley-CMI",
        "Private Set Intersection",
        "Conditional Mutual Information",
        "Vertical Federated Learning",
        "data valuation"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a privacy-preserving method for evaluating feature contributions in Vertical Federated Learning (VFL) using Shapley-CMI and a Private Set Intersection (PSI) server to compute encrypted intersection sizes without sharing raw data. The system enables secure and fair data valuation before model training. Initial experiments confirm the approach's correctness and privacy, demonstrating its viability for secure feature contribution estimation in VFL.",
      "mindmap": ""
    },
    {
      "title": "MALCDF: A Distributed Multi-Agent LLM Framework for Real-Time Cyber",
      "authors": "Arth Bhardwaj, Sia Godika, Yuvam Loonker",
      "institution": "Saint Francis High School, Massachusetts Institute of Technology, JBCN International School",
      "link": "https://arxiv.org/pdf/2512.14846",
      "code": null,
      "tags": [
        "llm inference",
        "multi-agent system",
        "secure communication layer",
        "ontology-aligned messaging",
        "MITRE ATT&CK",
        "Lightweight Random Forest"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes MALCDF, a real-time cyber defense framework where four specialized LLM agents (Detection, Intelligence, Response, Analysis) collaborate via a secure communication layer. It demonstrates that this multi-agent approach with encrypted, ontology-aligned messaging outperforms a lightweight ML baseline and a single-LLM setup in detection accuracy and F1-score on a test stream. The conclusion is that coordinating simple LLM agents improves practical, real-time cyber defense.",
      "mindmap": ""
    },
    {
      "title": "Penetration Testing of Agentic AI: A Comparative Security Analysis Across Models and Frameworks",
      "authors": "Viet K. Nguyen, Mohammad I. Husain",
      "institution": "Cal Poly Pomona",
      "link": "https://arxiv.org/pdf/2512.14860",
      "code": null,
      "tags": [
        "llm inference",
        "penetration testing",
        "prompt injection",
        "agentic ai",
        "autogen",
        "crewai",
        "ssrf",
        "sql injection"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper conducts systematic penetration testing on agentic AI systems, comparing five LLM models across two frameworks using 13 attack scenarios. It finds significant security vulnerabilities, with over half of malicious prompts succeeding, and identifies novel defensive patterns like \"hallucinated compliance\".",
      "mindmap": ""
    },
    {
      "title": "Cloud Security Leveraging AI: A Fusion-Based AISOC for Malware and Log Behaviour Detection",
      "authors": "Nnamdi Philip Okonkwo, Lubna Luxmi Dhirani",
      "institution": "University of Limerick",
      "link": "https://arxiv.org/pdf/2512.14935",
      "code": null,
      "tags": [
        "others",
        "AI-Augmented Security Operations Center (AISOC)",
        "malware detection",
        "log-anomaly detection",
        "score fusion",
        "Elasticsearch",
        "Kibana",
        "Metasploit",
        "EC2"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper implements an AI-Augmented Security Operations Center (AISOC) on AWS that fuses outputs from a malware detector and a log-anomaly detector to triage threats. The method uses calibrated score fusion to classify activity as NORMAL, SUSPICIOUS, or HIGH_CONFIDENCE_ATTACK. It concludes that this simple, fused approach can effectively enhance cloud SOC capabilities in cost-sensitive environments.",
      "mindmap": ""
    },
    {
      "title": "Intrusion Detection in Internet of Vehicles Using Machine Learning",
      "authors": "Hop Le, Izzat Alsmadi",
      "institution": "Texas A&M University-San Antonio",
      "link": "https://arxiv.org/pdf/2512.14958",
      "code": null,
      "tags": [
        "others",
        "intrusion detection system",
        "machine learning",
        "multi-class classification",
        "CAN bus",
        "CICIoV2024 dataset"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper develops a machine learning-based intrusion detection system to classify malicious CAN bus traffic in the Internet of Vehicles. It uses the CICIoV2024 benchmark dataset to analyze attack patterns like DoS and spoofing. The initial findings confirm a clear structural difference between attack types and benign data, providing a strong foundation for machine learning models.",
      "mindmap": ""
    },
    {
      "title": "SeBERTis: A Framework for Producing Classifiers of Security-Related Issue Reports",
      "authors": "Sogol Masoumzadeh, Yufei Li, Shane McIntosh, Dániel Varró, Lili Wei",
      "institution": "McGill University, University of Waterloo, Linköping University",
      "link": "https://arxiv.org/pdf/2512.15003",
      "code": null,
      "tags": [
        "others",
        "masked language model",
        "fine-tuning",
        "semantic surrogates",
        "deep neural network",
        "BERT"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes SEBERTIS, a framework that fine-tunes bidirectional transformer models (like BERT) as Masked Language Models using semantically equivalent vocabulary (Semantic Surrogates) to create classifiers for security-related issue reports. This method reduces reliance on lexical shortcuts, enabling better detection of complex issues. The resulting classifier significantly outperforms existing ML and LLM baselines in precision, recall, and F1-score, demonstrating high effectiveness for real-time issue triage.",
      "mindmap": ""
    },
    {
      "title": "Quantifying Return on Security Controls in LLM Systems",
      "authors": "Richard Helder Moulton, Austin O'Brien, John D. Hastings",
      "institution": "Dakota State University",
      "link": "https://arxiv.org/pdf/2512.15081",
      "code": null,
      "tags": [
        "llm inference",
        "retrieval-augmented generation (RAG)",
        "Monte Carlo simulation",
        "loss exceedance curves",
        "Laplace's Rule of Succession",
        "adversarial probing",
        "Garak",
        "attribute-based access control (ABAC)",
        "named entity recognition (NER) redaction",
        "NeMo Guardrails"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a framework to quantify the financial return on security controls for LLM systems by simulating attacks on a RAG service, estimating attack success probabilities, and modeling potential losses with Monte Carlo methods. The main conclusion is that controls like ABAC and NER redaction significantly reduce expected financial losses and offer high return-on-control, whereas NeMo Guardrails provides minimal benefit in the tested scenarios.",
      "mindmap": ""
    },
    {
      "title": "An Efficient Gradient-Based Inference Attack for Federated Learning",
      "authors": "Pablo Montaña-Fernández, Ines Ortega-Fernandez",
      "institution": "Gradiant",
      "link": "https://arxiv.org/pdf/2512.15143",
      "code": null,
      "tags": [
        "others",
        "membership inference attack",
        "federated learning",
        "gradient-based methods",
        "shadow training",
        "attribute inference"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a new gradient-based inference attack for federated learning that analyzes the temporal evolution of last-layer gradients across multiple training rounds. The attack uses a shadow model technique to learn gradient patterns and can be extended to attribute inference. The findings show that multi-round federated learning increases vulnerability to such attacks, with aggregators posing a greater threat than data owners.",
      "mindmap": ""
    },
    {
      "title": "Quantum Machine Learning for Cybersecurity: A Taxonomy and Future Directions",
      "authors": "Siva Sai, Ishika Goyal, Shubham Sharma, Sri Harshita Manuri, Vinay Chamola, Rajkumar Buyya",
      "institution": "The University of Melbourne, Birla Institute of Technology and Science, Pilani, APPCAIR",
      "link": "https://arxiv.org/pdf/2512.15286",
      "code": null,
      "tags": [
        "others",
        "Quantum Neural Networks (QNNs)",
        "Quantum Support Vector Machines (QSVMs)",
        "Variational Quantum Circuits (VQCs)",
        "Quantum Generative Adversarial Networks (QGANs)"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This survey paper explores Quantum Machine Learning (QML) techniques, including QNNs, QSVMs, VQCs, and QGANs, for cybersecurity applications like intrusion detection and malware classification. It concludes that QML offers potential advantages for processing high-dimensional data and enhancing security in areas like cloud computing, but also discusses current limitations and future research directions needed to address them.",
      "mindmap": ""
    },
    {
      "title": "Bits for Privacy: Evaluating Post-Training Quantization via Membership Inference",
      "authors": "Chenxiang Zhang, Tongxi Qu, Zhong Li, Tian Zhang, Jun Pang, Sjouke Mauw",
      "institution": "University of Luxembourg, Nanjing University",
      "link": "https://arxiv.org/pdf/2512.15335",
      "code": null,
      "tags": [
        "post-training",
        "post-training quantization",
        "membership inference",
        "AdaRound",
        "BRECQ",
        "OBC",
        "quantization",
        "privacy-utility trade-off"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper systematically evaluates how post-training quantization (PTQ) affects privacy by using membership inference attacks on models quantized with algorithms like AdaRound, BRECQ, and OBC. The study finds that lower-precision PTQ (e.g., 4-bit, 2-bit, 1.58-bit) significantly reduces privacy leakage, offering up to an order of magnitude less vulnerability compared to full-precision models, though at the cost of decreased utility. The results provide practical insights for balancing efficiency, accuracy, and privacy in model deployment.",
      "mindmap": ""
    },
    {
      "title": "Remotely Detectable Robot Policy Watermarking",
      "authors": "Michael Amir, Manon Flageat, Amanda Prorok",
      "institution": "University of Cambridge",
      "link": "https://arxiv.org/pdf/2512.15379",
      "code": null,
      "tags": [
        "others",
        "policy watermarking",
        "colored noise coherency",
        "glimpse sequence",
        "remote detection",
        "spectral signal",
        "stochasticity"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces Colored Noise Coherency (CoNoCo), a watermarking method that embeds a spectral signal into a robot's motions using the policy's inherent stochasticity for remote detection. It is designed to be detectable from noisy external observations like video footage without degrading policy performance. The work demonstrates robust detection across various remote modalities, providing a non-invasive way to verify the provenance of physical robot policies.",
      "mindmap": ""
    },
    {
      "title": "How Do Semantically Equivalent Code Transformations Impact Membership Inference on LLMs for Code?",
      "authors": "Hua Yang, Alejandro Velasco, Thanh Le-Cong, Md Nazmul Haque, Bowen Xu, Denys Poshyvanyk",
      "institution": "North Carolina State University, William & Mary, The University of Melbourne",
      "link": "https://arxiv.org/pdf/2512.15468",
      "code": null,
      "tags": [
        "llm training",
        "membership inference",
        "semantically equivalent code transformation",
        "variable renaming",
        "causal analysis",
        "code obfuscation"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates how semantically equivalent code transformations, such as variable renaming, can be used to evade membership inference detection in large language models for code. It finds that these transformations, especially RenameVariable, can significantly reduce the success of membership inference attacks without substantially harming model performance. The results reveal a critical vulnerability in license compliance enforcement for code LLMs, showing that transformation-based obfuscation can weaken detection of unauthorized code usage.",
      "mindmap": ""
    },
    {
      "title": "Attention in Motion: Secure Platooning via Transformer-based Misbehavior Detection",
      "authors": "Konstantinos Kalogiannis, Ahmed Mohamed Hussain, Hexu Li, Panos Papadimitratos",
      "institution": "KTH Royal Institute of Technology, Lenovo",
      "link": "https://arxiv.org/pdf/2512.15503",
      "code": null,
      "tags": [
        "others",
        "transformer",
        "multi-head self-attention",
        "positional encoding",
        "precision-focused loss",
        "edge deployment",
        "TensorFlow Lite",
        "ONNX",
        "TensorRT"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes AIMformer, a transformer-based framework for real-time misbehavior detection in vehicular platoons. It uses multi-head self-attention to capture spatiotemporal dependencies and a precision-focused loss to minimize false positives. The method demonstrates high performance and achieves sub-millisecond inference latency, making it suitable for deployment on resource-constrained edge platforms.",
      "mindmap": ""
    },
    {
      "title": "BashArena: A Control Setting for Highly Privileged AI Agents",
      "authors": "Adam Kaufman, James Lucassen, Tyler Tracy, Cody Rushing, Aryan Bhatt",
      "institution": "Redwood Research",
      "link": "https://arxiv.org/pdf/2512.15688",
      "code": null,
      "tags": [
        "cluster infrastructure",
        "AI control",
        "red teaming",
        "blue teaming",
        "adversarial evaluation",
        "system administration tasks",
        "sabotage detection",
        "Linux environment",
        "control protocols"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces BashArena, a control setting with 637 Linux system administration tasks and sabotage objectives to study AI control techniques for highly privileged agents. It evaluates frontier LLMs in an adversarial game between red teams (performing sabotage) and blue teams (detecting it), finding that Claude Sonnet 4.5 can evade detection by GPT-4.1 mini 26% of the time, establishing a baseline for more effective control protocols.",
      "mindmap": ""
    }
  ]
}