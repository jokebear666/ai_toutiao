{
  "label": "cs.DB",
  "slug": "csdb",
  "week": "20260105-20260111",
  "items": [
    {
      "title": "From Metadata to Meaning: A Semantic Units Knowledge Graph for the Biodiversity Exploratories",
      "authors": "Tarek Al Mustafa",
      "institution": "Friedrich-Schiller-Universität Jena",
      "link": "https://arxiv.org/pdf/2601.00002",
      "code": null,
      "tags": [
        "knowledge graph",
        "semantic units",
        "biodiversity",
        "metadata extraction",
        "FAIR",
        "SPARQL"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f0a65aaa02c17c09630c9d229fe803647bb1e1e4c158125f8670b886fab3cbe_w640_q70.webp",
      "contributions": "1. Proposes and implements Semantic Units (SUs) as semantically significant, named subgraphs to enhance user cognitive interoperability and address KG modeling challenges. 2. Constructs a knowledge graph from publication and dataset metadata of the Biodiversity Exploratories research platform. 3. Demonstrates the use of LLMs for extracting structured metadata and embedding models for enriching metadata with latent information to support FAIR metadata creation.",
      "summary": "This paper addresses the difficulty users face in interacting with Knowledge Graphs (KGs) by proposing Semantic Units (SUs) as meaningful subgraphs to improve cognitive interoperability. The method involves building a KG from biodiversity metadata and implementing SUs, while also utilizing LLMs and embedding models for metadata extraction and enrichment. The work concludes that SUs can enhance KG usability and demonstrates practical applications for creating structured, FAIR metadata in biodiversity research.",
      "mindmap": "graph TB\n        Root[”From Metadata to Meaning: A Semantic Units Knowledge Graph for the Biodiversity Exploratories”]\n        Root --> Problem[”核心问题/Problem: KG难以交互，用户需求与技术实现脱节/KGs are hard to interact with; disconnect between user needs and technical requirements”]\n        Root --> Method[”主要方法/Method: 引入语义单元，构建知识图谱，利用LLM和嵌入模型/Introduce Semantic Units, construct KG, use LLMs & embedding models”]\n        Root --> Results[”关键结果/Results: 提升KG可用性，支持FAIR元数据创建/Enhanced KG usability, supports FAIR metadata creation”]"
    },
    {
      "title": "Database Theory in Action: Yannakakis' Algorithm",
      "authors": "Paraschos Koutris, Stijn Vansummeren, Qichen Wang, Yisu Remy Wang, Xiangyao Yu",
      "institution": "University of Wisconsin-Madison, UHasselt (Data Science Institute), Nanyang Technological University, University of California, Los Angeles",
      "link": "https://arxiv.org/pdf/2601.00098",
      "code": null,
      "tags": [
        "join algorithms",
        "Yannakakis' algorithm",
        "acyclic joins",
        "semijoin reduction",
        "instance optimality",
        "query optimization"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4b97884b39d19d5eedab7407e02b6e4a70fdfa6e3afd50b206df5b9712c98c5a_w640_q70.webp",
      "contributions": "1. Surveys recent advancements in making Yannakakis' algorithm more practical in terms of efficiency and implementation ease. 2. Highlights the algorithm's theoretical optimality for acyclic joins and its practical performance challenges. 3. Identifies future research directions to bridge the gap between theory and practice in join processing.",
      "summary": "This paper surveys Yannakakis' algorithm, which is theoretically optimal for acyclic joins but suffers from poor practical performance due to high overhead. It reviews recent efforts to improve its efficiency and implementation, and outlines future research avenues to enhance its adoption in database systems.",
      "mindmap": "graph TB\n    A[Database Theory in Action: Yannakakis' Algorithm] --> B[核心问题/Problem: Yannakakis' algorithm is optimal for acyclic joins but not widely adopted due to poor practical performance.]\n    A --> C[主要方法/Method: Survey recent advancements to improve the algorithm's efficiency and ease of implementation.]\n    A --> D[关键结果/Results: Highlights progress and points out avenues for future research to bridge theory and practice.]"
    },
    {
      "title": "Avoiding Thread Stalls and Switches in Key-Value Stores: New Latch-Free Techniques and More",
      "authors": "David Lomet, Rui Wang",
      "institution": "Microsoft",
      "link": "https://arxiv.org/pdf/2601.00208",
      "code": null,
      "tags": [
        "index structures",
        "latch-free",
        "delta updating",
        "B-tree",
        "key-value stores",
        "thread switching"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/71055543da9824b6a9f6a0949562239741e311573e70d8cf4d888de754c58729_w640_q70.webp",
      "contributions": "1. Introduces \"notices,\" a new latch-free technique to reduce wasted work during concurrent updates. 2. Demonstrates how latch-free techniques combined with delta record updating can avoid thread stalls and switches. 3. Applies the approach to solve B-tree index maintenance (SMO) problems in key-value stores.",
      "summary": "This paper addresses the performance problem of thread stalls and switches in key-value stores caused by resource contention. It proposes a new latch-free technique called \"notices\" that leverages delta record updating to significantly reduce wasted work and avoid blocking, particularly for B-tree index maintenance. The method improves performance under high load by keeping threads active and reducing code path length.",
      "mindmap": "graph TB\n        Root[”避免键值存储中的线程停顿与切换<br/>Avoiding Thread Stalls and Switches in Key-Value Stores”]\n        Root --> Problem[”核心问题/Problem: 线程切换与停顿成本高<br/>High cost of thread switching/stalls”]\n        Root --> Method[”主要方法/Method: 新的无锁技术与增量更新<br/>New latch-free techniques & delta updating”]\n        Root --> Results[”关键结果/Results: 减少浪费工作，避免阻塞<br/>Reduce wasted work, avoid blocking”]\n        Problem --> Cause[”原因/Cause: 资源争用<br/>Resource contention”]\n        Method --> Technique[”技术/Technique: 通知(notices)<br/>Notices”]\n        Results --> Application[”应用/Application: B树索引维护<br/>B-tree index maintenance”]"
    },
    {
      "title": "Combining Time-Series and Graph Data: A Survey of Existing Systems and Approaches",
      "authors": "Mouna Ammar, Marvin Hofer, Erhard Rahm",
      "institution": "University of Leipzig, ScaDS.AI",
      "link": "https://arxiv.org/pdf/2601.00304",
      "code": null,
      "tags": [
        "data integration",
        "graph data",
        "time-series data",
        "multi-model database",
        "polyglot persistence",
        "survey"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ea0cfd9823b8814d3dc3ce6fb385fdf0346010c946bbf9395ed582581d3d6de_w640_q70.webp",
      "contributions": "1. Provides a comprehensive survey of existing systems and approaches for combining graph and time-series data. 2. Categorizes these systems into four distinct architectural integration types (Single Model, Extended Single Model, Polyglot, Multi Model). 3. Evaluates and compares the systems based on a set of requirements and implementation characteristics to highlight trade-offs like integration degree and maturity.",
      "summary": "This paper surveys existing systems that aim to unify the management and analysis of graph and time-series data. It categorizes the approaches into four architectural types and analyzes their characteristics and trade-offs. The overview helps readers understand current options for integrated data handling.",
      "mindmap": "graph TB\n        A[Combining Time-Series and Graph Data: A Survey] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[Separate management of graph and time-series data is inefficient for combined analysis]\n        C --> C1[Survey and categorize existing systems into four architectural types]\n        D --> D1[Provides overview of options, trade-offs, and system characteristics]"
    },
    {
      "title": "KELP: Robust Online Log Parsing Through Evolutionary Grouping Trees",
      "authors": "Satyam Singh, Sai Niranjan Ramachandran",
      "institution": "StoneBuck Labs",
      "link": "https://arxiv.org/pdf/2601.00633",
      "code": "codeberg.org/stonebucklabs/kelp",
      "tags": [
        "log parsing",
        "Evolutionary Grouping Tree",
        "online clustering",
        "schema drift",
        "throughput",
        "benchmark"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c825e5ac9adebe7efdf4817dd2c8251ed03ac18f0076eb3fd628e34ff8c37232_w640_q70.webp",
      "contributions": "1. Proposes KELP, a high-throughput online log parser built on a novel Evolutionary Grouping Tree data structure. 2. Introduces a new benchmark designed to reflect the structural ambiguity and dynamism of modern production systems for rigorous evaluation. 3. Demonstrates that KELP maintains high accuracy on the new benchmark where traditional heuristic methods fail, without compromising throughput.",
      "summary": "The paper addresses the brittleness of existing online log parsers in dynamic production environments. It proposes KELP, a parser using an Evolutionary Grouping Tree to continuously cluster and adapt to log schema changes. The evaluation shows KELP achieves robust accuracy on a new, realistic benchmark without sacrificing throughput.",
      "mindmap": "graph TB\n        A[KELP: Robust Online Log Parsing Through Evolutionary Grouping Trees] --> B[核心问题/Problem: Existing online parsers are brittle for dynamic production environments]\n        A --> C[主要方法/Method: Evolutionary Grouping Tree for continuous online clustering]\n        A --> D[关键结果/Results: High accuracy on rigorous benchmark, maintains throughput]"
    },
    {
      "title": "DeXOR: Enabling XOR in Decimal Space for Streaming Lossless Compression of Floating-point Data",
      "authors": "Chuanyi Lv, Huan Li, Dingyu Yang, Zhongle Xie, Lu Chen, Christian S. Jensen",
      "institution": "Zhejiang University, Aalborg University",
      "link": "https://arxiv.org/pdf/2601.00695",
      "code": null,
      "tags": [
        "data compression",
        "decimal XOR",
        "streaming lossless compression",
        "floating-point data",
        "error-tolerant rounding",
        "exception handler"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fd04d7b8f2e98df7e248b5447e5f33922c7c8173ae8cddf4a174b08c725b6df_w640_q70.webp",
      "contributions": "1) Introduces a novel decimal XOR procedure to encode longest common decimal prefixes and suffixes for optimal redundancy elimination. 2) Proposes scaled truncation with error-tolerant rounding and specialized bit management to handle binary-decimal conversion errors for accurate, low-cost decompression. 3) Designs a robust exception handler to manage floating-point exponents, ensuring stability and high compression ratios under extreme conditions.",
      "summary": "This paper proposes DeXOR, a novel framework for streaming lossless compression of floating-point data. It introduces a decimal XOR procedure to exploit similarity and eliminate redundancy in decimal space, coupled with error-tolerant rounding and an exception handler for robustness. Evaluations show DeXOR achieves a 15% higher compression ratio and 20% faster decompression speed than state-of-the-art schemes.",
      "mindmap": "graph TB\n        Root[DeXOR: Enabling XOR in Decimal Space for Streaming Lossless Compression of Floating-point Data] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Efficient lossless compression for streaming floating-point data under extreme conditions] --> P1[挑战/Challenges: High-precision values, absence of smoothness]\n        Method[主要方法/Method: Decimal XOR framework] --> M1[关键技术/Key Techniques: Decimal XOR for common prefix/suffix encoding]\n        Method --> M2[误差处理/Error Handling: Scaled truncation with error-tolerant rounding]\n        Method --> M3[稳定性/Stability: Robust exception handler for exponents]\n        Results[关键结果/Results: Superior performance vs. state-of-the-art] --> R1[压缩比/Compression Ratio: 15% higher]\n        Results --> R2[解压速度/Decompression Speed: 20% faster]\n        Results --> R3[鲁棒性/Robustness: Works in extreme scenarios]"
    },
    {
      "title": "Hojabr: Towards a Theory of Everything for AI and Data Analytics",
      "authors": "Amir Shaikhha",
      "institution": "University of Edinburgh",
      "link": "https://arxiv.org/pdf/2512.23925",
      "code": null,
      "tags": [
        "compiler & ir",
        "declarative intermediate language",
        "unified algebraic framework",
        "bidirectional compilation",
        "constraint-specialization",
        "tensor algebra"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba9cf2437f8d68ebfda91126c670461fff1e81b455aa087018001ed68c112e8c_w640_q70.webp",
      "contributions": "1. Proposed Hojabr, a unified declarative intermediate language that integrates relational algebra, tensor algebra, and constraint-based reasoning within a single higher-order algebraic framework. 2. Introduced a novel approach where physical execution choices (e.g., join algorithms, tensor representations) are handled as constraint-specialization decisions within the same formalism. 3. Enabled systematic cross-paradigm optimization and reuse by supporting bidirectional translation with existing declarative languages and making semantic/structural properties explicit.",
      "summary": "The paper addresses the fragmentation in modern AI and data analytics pipelines by proposing Hojabr, a unified declarative intermediate language. Hojabr integrates relational, tensor, and constraint-based operations into a single algebraic framework, enabling cross-paradigm optimization through bidirectional compilation and constraint-specialization. The main conclusion is that this approach facilitates systematic reasoning and reuse of optimization techniques across database, ML, and compiler systems.",
      "mindmap": "graph TB\n        Root[”Hojabr: Towards a Theory of Everything for AI and Data Analytics”] --> Problem[”核心问题/Problem: Fragmentation across paradigms (relational, graph, tensor) and execution models”]\n        Root --> Method[”主要方法/Method: Unified declarative intermediate language (Hojabr) with higher-order algebraic framework”]\n        Root --> Results[”关键结果/Results: Enables systematic reasoning & reuse of optimizations across systems”]"
    },
    {
      "title": "High-dimensional Regret Minimization",
      "authors": "Junyu Liao, Ashwin Lall, Mitsunori Ogihara, Raymond Wong",
      "institution": "The Hong Kong University of Science and Technology, Denison University, University of Miami",
      "link": "https://arxiv.org/pdf/2512.24078",
      "code": null,
      "tags": [
        "interactive query processing",
        "regret minimization",
        "high-dimensional data",
        "interactive query",
        "skyline query",
        "top-k query"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc5adec19be3a80d0a53d2ec741bc611e59f7e2c74dd78fd4952eec991a81e0e_w640_q70.webp",
      "contributions": "1. Proposed FHDR (Fast High-Dimensional Reduction), a novel framework for scalable interactive regret minimization. 2. Achieved significant efficiency, requiring less than 0.01s and fewer than 30 rounds of user interaction. 3. Demonstrated performance improvements of at least an order of magnitude in execution time and several orders of magnitude in interaction rounds compared to prior work.",
      "summary": "This paper addresses the scalability challenge of interactive regret minimization queries in high-dimensional databases, where existing methods are too slow or require excessive user feedback. The authors propose the FHDR framework, which drastically reduces both computation time and the number of required user interactions. Experiments show FHDR establishes a new state-of-the-art, outperforming previous algorithms by orders of magnitude.",
      "mindmap": "graph TB\n        A[High-dimensional Regret Minimization] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有交互式算法无法扩展到高维数据集 / Existing interactive algorithms fail to scale to high-dimensional datasets]\n        B --> B2[用户交互轮数过多（常超1000轮）/ Excessive user interactions (often >1000 rounds)]\n        C --> C1[提出FHDR框架 / Propose FHDR (Fast High-Dimensional Reduction) framework]\n        D --> D1[交互轮数少于30轮 / Fewer than 30 rounds of interaction]\n        D --> D2[处理时间小于0.01秒 / Takes less than 0.01s]\n        D --> D3[性能提升数个数量级 / Outperforms prior work by orders of magnitude]"
    },
    {
      "title": "A Scalable Framework for logP Prediction: From Terabyte-Scale Data Integration to Interpretable Ensemble Modeling",
      "authors": "Malikussaid, Septian Caesar Floresko, Ade Romadhony, Isman Kurniawan, Warih Maharani, Hilal Hudan Nuha",
      "institution": "Telkom University",
      "link": "https://arxiv.org/pdf/2512.24643",
      "code": null,
      "tags": [
        "cluster infrastructure",
        "byte-offset indexing",
        "ensemble modeling",
        "SHAP analysis",
        "heteroskedasticity",
        "stratified modeling"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad416775f59ba17a28f8c4aa4f177b114e9e8b7b5d9ab0210d586ba595ee51e6_w640_q70.webp",
      "contributions": "1. Developed a novel computational infrastructure for terabyte-scale data integration, achieving a 740-fold speedup in processing time using a byte-offset indexing architecture. 2. Conducted a comprehensive analysis revealing the multivariate nature of lipophilicity, identifying molecular weight as the most important global predictor via SHAP analysis, despite its weak bivariate correlation. 3. Proposed and validated a stratified modeling strategy (specialized models for drug-like vs. extreme molecules) that achieved optimal predictive performance, demonstrating the competitiveness of well-curated descriptor-based ensemble models with graph neural networks.",
      "summary": "This paper presents a scalable framework for predicting molecular lipophilicity (logP). It introduces a high-performance data integration infrastructure and employs tree-based ensemble models with a stratified strategy, achieving robust prediction accuracy and providing insights into key molecular descriptors. The work shows that carefully engineered traditional machine learning models can remain competitive with advanced neural architectures for this task.",
      "mindmap": "graph TB\n        Root[”A Scalable Framework for logP Prediction<br>可扩展的logP预测框架”] --> Problem[”核心问题/Problem<br>Accurate, scalable logP prediction for drug discovery<br>药物发现中准确、可扩展的logP预测”]\n        Root --> Method[”主要方法/Method<br>Byte-offset indexing & stratified ensemble modeling<br>字节偏移索引与分层集成建模”]\n        Root --> Results[”关键结果/Results<br>740x speedup, robust models competitive with GNNs<br>740倍加速，模型性能与图神经网络相当”]"
    },
    {
      "title": "LMG Index: A Robust Learned Index for Multi-Dimensional Performance Balance",
      "authors": "Yuzhen Chen, Bin Yao",
      "institution": "Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.24824",
      "code": null,
      "tags": [
        "memory & caching",
        "learned index",
        "robust framework",
        "gap allocation",
        "performance balance",
        "update efficiency"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0974459a650b6313a94f7b1297fe756803d33e8efa166a5596c6acc1939a14f_w640_q70.webp",
      "contributions": "1. Proposes LMIndex, a robust learned indexing framework featuring an efficient top-layer structure with O(1) query/update complexity and an efficient optimal error threshold training algorithm., 2. Develops LMG (LMIndex with gaps), a variant that employs a novel gap allocation strategy to significantly enhance update performance and stability under dynamic workloads., 3. Demonstrates through extensive evaluation that LMG effectively breaks multi-dimensional performance trade-offs, achieving leading or competitive performance across bulk loading, point/range queries, updates, stability, and space usage.",
      "summary": "The paper addresses the limitations of existing learned indexes, which often optimize for single objectives and lack robustness under dynamic workloads. It proposes LMG Index, a robust learned index framework that uses a novel gap allocation strategy to balance multiple performance dimensions. The evaluation shows LMG achieves superior and balanced performance in query latency, update efficiency, stability, and space usage compared to state-of-the-art approaches.",
      "mindmap": "graph TB\n        A[LMG Index: A Robust Learned Index for Multi-Dimensional Performance Balance] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有学习索引优化目标单一，缺乏更新效率和稳定性/Existing learned indexes optimize limited objectives, lack update efficiency & stability]\n        B --> B2[依赖数据分布假设，缺乏理论保证/Rely on data distribution assumptions, lack theoretical guarantees]\n        C --> C1[提出LMIndex框架：高效顶层结构(O(1))与误差阈值训练算法/Propose LMIndex framework: efficient top-layer structure (O(1)) & error threshold training]\n        C --> C2[开发LMG变体：采用新颖间隙分配策略/Develop LMG variant: novel gap allocation strategy]\n        D --> D1[性能领先：批量加载、点/范围查询、更新、稳定性、空间使用/Leading performance: bulk load, point/range query, update, stability, space usage]\n        D --> D2[打破多维度性能权衡/Breaks multi-dimensional performance trade-offs]"
    },
    {
      "title": "MonoM: Enhancing Monotonicity in Learned Cardinality Estimators",
      "authors": "Lyu Yi, Weiqi Feng, Yuanbiao Wang, Yuhong Kan",
      "institution": "University of Wisconsin–Madison, Harvard University, University of Texas at Austin",
      "link": "https://arxiv.org/pdf/2512.22122",
      "code": null,
      "tags": [
        "query optimization",
        "cardinality estimation",
        "monotonicity",
        "regularization",
        "workload generator",
        "MSCN"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c0c68b14fa636a4e8969cdb572e60e2fdd2e789895a2bce33cefa2686133c9b_w640_q70.webp",
      "contributions": "1. Proposes MonoM, a metric to quantitatively measure monotonicity adherence in cardinality estimators. 2. Introduces a monotonic training framework with a workload generator for producing directly comparable queries. 3. Designs a novel regularization term for the loss function to enforce monotonicity and improve generalization.",
      "summary": "The paper addresses the problem of learned cardinality estimators violating monotonicity, a key barrier to their adoption. It proposes a new metric (MonoM) and a training framework with a specialized workload generator and a regularization term to enforce monotonicity. Experiments show the method improves both monotonicity adherence and estimation accuracy by reducing overfitting.",
      "mindmap": "graph TB\n        A[MonoM: Enhancing Monotonicity<br>增强单调性] --> B(Problem: Learned estimators violate monotonicity<br>问题: 学习模型违反单调性)\n        A --> C(Method: MonoM metric & training framework<br>方法: MonoM指标与训练框架)\n        C --> D(Sub-Method: Workload generator<br>子方法: 工作负载生成器)\n        C --> E(Sub-Method: Regularization term<br>子方法: 正则化项)\n        A --> F(Results: Improves monotonicity & accuracy<br>结果: 提升单调性与准确性)"
    },
    {
      "title": "Valori: A Deterministic Memory Substrate for AI Systems",
      "authors": "Varshith Gudur",
      "institution": "Independent Researcher (Valori Kernel Project)",
      "link": "https://arxiv.org/pdf/2512.22280",
      "code": "https://github.com/varshith-Git/Valori-Kernel",
      "tags": [
        "memory & caching",
        "deterministic memory",
        "fixed-point arithmetic",
        "vector embeddings",
        "approximate nearest neighbor search",
        "state machine"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb7ed17a8a06e6a2b8760f08fa9345391995aee74a3542cacf55dd051b383f_w640_q70.webp",
      "contributions": "1. Identifies and characterizes the fundamental non-determinism in AI memory systems caused by hardware-dependent floating-point arithmetic, which leads to divergent memory states and retrieval results. 2. Proposes Valori, a deterministic AI memory substrate that replaces floating-point operations with fixed-point arithmetic (Q16.16) and models memory as a replayable state machine. 3. Demonstrates that Valori guarantees bit-identical memory states, snapshots, and search results across different hardware platforms (e.g., x86 vs. ARM), establishing deterministic memory as a necessary primitive for trustworthy AI.",
      "summary": "The paper identifies non-determinism in AI memory systems due to hardware-dependent floating-point arithmetic, which compromises replayability and auditability. It proposes Valori, a memory substrate using fixed-point arithmetic and a state machine model to guarantee bit-identical behavior across platforms. The work concludes that deterministic memory is essential for building trustworthy AI systems.",
      "mindmap": "graph TB\n        A[Valori: A Deterministic Memory Substrate for AI Systems] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: AI内存非确定性/AI Memory Non-Determinism]\n        C[主要方法/Method: 固定点算术与状态机/Fixed-Point Arithmetic & State Machine]\n        D[关键结果/Results: 跨平台比特一致性/Cross-Platform Bit-Identical Results]"
    },
    {
      "title": "Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries",
      "authors": "Saurabh Deochake, Debajyoti Mukhopadhyay",
      "institution": "SentinelOne, WIDiCoReL Research Lab",
      "link": "https://arxiv.org/pdf/2512.22364",
      "code": null,
      "tags": [
        "llm inference",
        "Text-to-SQL",
        "Cloud Cost Optimization",
        "Query Efficiency",
        "Large Language Models",
        "Google BigQuery"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06f17566f5fb65cb73b79b0dbb64bde11c2f87d177f02865af7fc2d8910e3ac4_w640_q70.webp",
      "contributions": "1. Introduced a cloud-native cost evaluation methodology for Text-to-SQL systems, measuring bytes processed, slot utilization, and estimated query cost on production infrastructure. 2. Conducted an empirical evaluation of six LLMs on Google BigQuery, demonstrating that reasoning models achieve significantly lower cloud compute costs while maintaining high correctness. 3. Quantified cost variance across models, identified prevalent inefficiency patterns (e.g., missing partition filters), and provided deployment guidelines for cost-sensitive environments.",
      "summary": "This paper studies the cloud compute costs of SQL queries generated by Large Language Models (LLMs) for Text-to-SQL tasks. By evaluating six state-of-the-art LLMs on Google BigQuery, it finds that reasoning models are more cost-efficient, processing far fewer bytes, and that execution time is a poor proxy for cloud cost. The work provides a new cost-focused evaluation methodology and guidelines for deploying cost-aware Text-to-SQL systems.",
      "mindmap": "graph TB\n        A[Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Existing efficiency metrics (e.g., VES) measure time, not cloud compute costs.] --> B1[问题背景/Context<br>LLMs achieve high Text-to-SQL accuracy, but cost efficiency in cloud deployments is unknown.]\n        C[主要方法/Method<br>Systematic evaluation of 6 LLMs on Google BigQuery (StackOverflow dataset).] --> C1[评估指标/Metrics<br>Measure bytes processed, slot utilization, estimated cost, and correctness.]\n        D[关键结果/Results] --> D1[发现1/Finding 1<br>Reasoning models process 44.5% fewer bytes with equivalent correctness.]\n        D --> D2[发现2/Finding 2<br>Weak correlation (r=0.16) between execution time and query cost.]\n        D --> D3[发现3/Finding 3<br>Up to 3.4x cost variance; standard models produce high-cost outliers.]"
    },
    {
      "title": "Robust LLM-based Column Type Annotation via Prompt Augmentation with LoRA Tuning",
      "authors": "Hanze Meng, Jianhao Cao, Rachel Pottinger",
      "institution": "University of British Columbia",
      "link": "https://arxiv.org/pdf/2512.22742",
      "code": "https://github.com/fripSideMeng/PACTA",
      "tags": [
        "llm training",
        "Column Type Annotation",
        "Prompt Augmentation",
        "LoRA",
        "Parameter-Efficient Fine-Tuning",
        "Prompt Sensitivity"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95317c9af6072a1e0ffbb34950b7d9da057c55baaf301c56bb751746b366785a_w640_q70.webp",
      "contributions": "1. Proposes a parameter-efficient fine-tuning framework for Column Type Annotation (CTA) using Low-Rank Adaptation (LoRA) to reduce computational cost. 2. Introduces a prompt augmentation strategy during training to mitigate model sensitivity to variations in prompt wording and structure. 3. Demonstrates robust and stable performance across diverse datasets and prompt templates, achieving higher weighted F1 scores than single-template fine-tuning.",
      "summary": "This paper addresses the challenges of prompt sensitivity and high computational cost in using Large Language Models (LLMs) for Column Type Annotation. It proposes a parameter-efficient framework that fine-tunes LLMs using LoRA on prompt-augmented data. The method achieves robust performance across different prompts and datasets while requiring significantly fewer trainable parameters.",
      "mindmap": "graph TB\n        Root(”Robust LLM-based Column Type Annotation via Prompt Augmentation with LoRA Tuning”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”现有方法对提示词敏感/Existing methods are sensitive to prompts”)\n        Problem --> P2(”完全微调成本高昂/Full fine-tuning is computationally prohibitive”)\n        Method --> M1(”使用LoRA进行参数高效微调/Parameter-efficient fine-tuning with LoRA”)\n        Method --> M2(”使用增强的提示数据进行训练/Training on prompt-augmented data”)\n        Results --> R1(”对不同提示模式性能稳定/Stable performance across diverse prompts”)\n        Results --> R2(”获得更高的加权F1分数/Higher weighted F1 scores”)"
    },
    {
      "title": "OrchANN: A Unified I/O Orchestration Framework for Skewed Out-of-Core Vector Search",
      "authors": "Chengying Huan, Lizheng Chen, Zhengyi Yang, Shaonan Ma, Rong Gu, Renjie Yao, Zhibin Wang, Mingxing Zhang, Fang Xi, Jie Tao, Gang Zhang, Guihai Chen, Chen Tian",
      "institution": "Nanjing University, University of New South Wales, AISoft (QiyuanLab), Tsinghua University, China Mobile (Suzhou) Software Technology Co., Ltd.",
      "link": "https://arxiv.org/pdf/2512.22838",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "out-of-core",
        "approximate nearest neighbor search",
        "I/O orchestration",
        "vector search",
        "SSD"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efdb94f456d7410c515c5dcba047400662a1afb3a011cd9a57efd9526c5cc408_w640_q70.webp",
      "contributions": "1. Introduces a heterogeneous local index selection per cluster via offline auto-profiling to match varying cluster scales. 2. Maintains a query-aware in-memory navigation graph that adapts to skewed query workloads for efficient routing. 3. Applies multi-level pruning with geometric bounds to filter clusters and vectors before issuing SSD reads, preventing \"fetch-to-discard\" overhead.",
      "summary": "The paper presents OrchANN, a new out-of-core approximate nearest neighbor search engine designed for billion-scale vector search where data resides on SSD. It addresses performance degradation under skewed data distributions by unifying I/O governance through adaptive navigation and multi-level pruning. OrchANN significantly outperforms existing systems in queries per second and latency while reducing SSD accesses, without sacrificing accuracy.",
      "mindmap": "graph TB\n        Root(”OrchANN: A Unified I/O Orchestration Framework for Skewed Out-of-Core Vector Search”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”大规模ANNS是外存问题/Large-scale ANNS is an out-of-core problem”)\n        Problem --> P2(”现有系统在倾斜数据下失效/Existing systems break down under skewed data”)\n        Method --> M1(”异构本地索引/Heterogeneous local index per cluster”)\n        Method --> M2(”查询感知导航图/Query-aware in-memory navigation graph”)\n        Method --> M3(”多级剪枝/Multi-level pruning with geometric bounds”)\n        Results --> R1(”更高的QPS和更低延迟/Higher QPS and lower latency”)\n        Results --> R2(”减少SSD访问/Reduced SSD accesses”)\n        Results --> R3(”保持准确性/Maintains accuracy”)"
    },
    {
      "title": "Time Sensitive Multiple POIs Route Planning on Bus Networks",
      "authors": "Simu Liu, Kailin Jiao, Junping Du, Yawen Li, Zhe Xue, Xiaoyang Sean Wang, Ziqiang Yu, Yunchuan Shi",
      "institution": "Yantai University, Shandong University, Beijing University of Posts and Telecommunications, Fudan University",
      "link": "https://arxiv.org/pdf/2512.22893",
      "code": null,
      "tags": [
        "route planning",
        "bus network",
        "time-sensitive",
        "EA-Star algorithm",
        "DME-Graph",
        "A* algorithm"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4fea9498baf83db6fa13479c937b5c1a0181f3763fbacddea216bc87c93a7e0_w640_q70.webp",
      "contributions": "1. Proposed a modified graph structure (DME-Graph) to model bus networks with varying travel and waiting times. 2. Introduced the EA-Star algorithm to efficiently find the optimal route by evaluating promising POI visit sequences and using a terminal condition. 3. Employed the A* algorithm on the modified graph to compute the shortest route for each sequence, narrowing the search space and improving efficiency.",
      "summary": "This paper addresses the time-sensitive multi-POI route planning problem on bus networks, where travel and waiting times vary. The authors propose a new graph model (DME-Graph) and the EA-Star algorithm, which combines sequence evaluation with A* search, to find the optimal route efficiently. Experiments on the New York bus network demonstrate the effectiveness of the proposed approach.",
      "mindmap": "graph TB\n        A[Time Sensitive Multiple POIs Route Planning on Bus Networks] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[公交网络多POI路径规划/Bus Network Multi-POI Route Planning]\n        B --> B2[最小化包含等待时间的总旅行时间/Minimize Total Travel Time Including Waiting]\n        C --> C1[提出DME-Graph模型/Propose DME-Graph Model]\n        C --> C2[设计EA-Star算法/Design EA-Star Algorithm]\n        C2 --> C2_1[结合A*搜索与序列评估/Combine A* Search & Sequence Evaluation]\n        D --> D1[在纽约公交数据集上验证有效/Validated on New York Bus Dataset]"
    },
    {
      "title": "Evolution of Buffer Management in Database Systems: From Classical Algorithms to Machine Learning and Disaggregated Memory",
      "authors": "Prudhvi Gadupudi, Suman Saha",
      "institution": "The Pennsylvania State University",
      "link": "https://arxiv.org/pdf/2512.22995",
      "code": null,
      "tags": [
        "buffer management",
        "cache replacement",
        "machine learning",
        "disaggregated memory",
        "eBPF",
        "NVM"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/009dc91aabc69a6fa35d611d86e0b83916498ee8fea16451b55cdd26e0e623cd_w640_q70.webp",
      "contributions": "1. Provides a historical analysis and systematic taxonomy of buffer management algorithms from classical heuristics to modern learned policies. 2. Examines implementation details and trade-offs in production database systems and operating systems like PostgreSQL, Oracle, and Linux. 3. Surveys emerging trends and outlines a future research direction integrating machine learning with kernel extensibility (eBPF) for adaptive, cross-layer buffer management in heterogeneous memory hierarchies.",
      "summary": "This paper is a comprehensive survey that traces the evolution of buffer management in database systems over four decades. It systematically reviews the progression from classical algorithms (e.g., LRU-K, ARC) to contemporary approaches using machine learning and architectures for disaggregated memory. The authors conclude by proposing a research direction that integrates machine learning with kernel extensibility to enable adaptive buffer management for modern heterogeneous memory systems.",
      "mindmap": "graph TB\n        Root[Evolution of Buffer Management in Database Systems] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Bridging the latency gap between CPU and storage] --> P1[内存层次结构/Memory Hierarchy]\n        Problem --> P2[性能关键组件/Performance Critical Component]\n        Method[主要方法/Method: Comprehensive survey of evolution] --> M1[历史分析/Historical Analysis]\n        Method --> M2[分类与实现研究/Taxonomy & Implementation Study]\n        Method --> M3[新兴趋势调研/Emerging Trends Survey]\n        Results[关键结果/Results: Identified patterns and future direction] --> R1[架构模式与权衡/Architectural Patterns & Trade-offs]\n        Results --> R2[开放挑战/Open Research Challenges]\n        Results --> R3[研究方向/Research Direction: ML + eBPF for adaptation]"
    },
    {
      "title": "ChronoConnect: Tracking Pathways Along Highly Dynamic Vertices in Temporal Graphs",
      "authors": "Jiacheng Ding, Cong Guo, Xiaofei Zhang",
      "institution": "University of Memphis",
      "link": "https://arxiv.org/pdf/2512.23289",
      "code": null,
      "tags": [
        "temporal graph analysis",
        "temporal pathways",
        "dynamic vertices",
        "parallel processing",
        "interactive visualization"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb4541a015072fd8bffa44223cd262753902794a2deeb1726333290cd1c78cf9_w640_q70.webp",
      "contributions": "1. Introduces ChronoConnect, a novel system for tracking temporal pathways in evolving graphs with a focus on highly dynamic vertices. 2. Proposes a methodology for extracting significant subgraphs that maintain temporal correlation among dynamic vertices to understand information propagation. 3. Provides an interactive user interface for graph visualization and query result exploration, enabling detailed examination of information flow.",
      "summary": "The paper introduces ChronoConnect, a system designed to track information propagation pathways in temporal graphs, with a specific focus on analyzing the role of highly dynamic vertices. It enables users to configure temporal traversal algorithms and utilizes parallel processing to handle large-scale evolving graphs. The system is presented as an effective tool for analyzing information diffusion patterns over time.",
      "mindmap": "graph TB\n        A[ChronoConnect: Tracking Pathways in Temporal Graphs] --> B(核心问题/Problem: Existing static snapshot systems struggle to capture temporal information flows.)\n        A --> C(主要方法/Method: Novel system ChronoConnect tracks pathways along highly dynamic vertices using parallel processing.)\n        A --> D(关键结果/Results: Enables efficient analysis of information diffusion with interactive visualization.)"
    },
    {
      "title": "BRkNN-light: Batch Processing of Reverse k-Nearest Neighbor Queries for Moving Objects on Road Networks",
      "authors": "Anbang Song, Ziqiang Yu, Wei Liu, Yating Xu, Mingjin Tao",
      "institution": "Yantai University",
      "link": "https://arxiv.org/pdf/2512.23298",
      "code": null,
      "tags": [
        "spatial databases",
        "reverse k-nearest neighbor",
        "road network",
        "batch processing",
        "moving objects",
        "dynamic caching"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d343019169c0724222b0ab633a704338a075b230d1f2f1fe0089add7e443a1ec_w640_q70.webp",
      "contributions": "1. Proposes the first exploration of batch processing for multiple RkNN queries on road networks to share computations and reduce costs. 2. Introduces the BRkNN-Light algorithm with rapid verification, pruning, and optimized range search for efficient individual query processing. 3. Designs a dynamic distance caching mechanism to enable computation reuse across multiple queries, significantly cutting unnecessary calculations.",
      "summary": "This paper addresses the problem of efficiently processing multiple simultaneous Reverse k-Nearest Neighbor queries for moving objects on road networks. It proposes the BRkNN-Light algorithm, which uses geometric pruning, optimized search, and a dynamic caching mechanism to share computations across queries. Experiments on real-world road networks show the algorithm's superiority in batch query processing.",
      "mindmap": "graph TB\n    Root(”BRkNN-light: Batch Processing of Reverse k-Nearest Neighbor Queries for Moving Objects on Road Networks”) --> Problem(”核心问题/Problem”)\n    Root --> Method(”主要方法/Method”)\n    Root --> Results(”关键结果/Results”)\n    Problem --> P1(”现有方法忽略批量查询处理/Existing methods overlook batch query processing”)\n    Problem --> P2(”无法共享冗余计算/Cannot share redundant computations”)\n    Method --> M1(”BRkNN-Light算法/BRkNN-Light Algorithm”)\n    M1 --> M1_1(”快速验证与剪枝/Rapid verification & pruning”)\n    M1 --> M1_2(”优化范围搜索/Optimized range search”)\n    M1 --> M1_3(”动态距离缓存/Dynamic distance caching”)\n    Results --> R1(”减少总体计算成本/Reduces overall computation cost”)\n    Results --> R2(”实验证明优越性/Experiments demonstrate superiority”)"
    },
    {
      "title": "Flexible Keyword-Aware Top-$k$ Route Search",
      "authors": "Ziqiang Yu, Xiaohui Yu, Yueting Chen, Wei Liu, Anbang Song, Bolong Zheng",
      "institution": "Yantai University, York University, Seattle University, Wuhan University of Technology",
      "link": "https://arxiv.org/pdf/2512.23319",
      "code": null,
      "tags": [
        "spatial databases",
        "keyword-aware route search",
        "top-k query",
        "explore-and-bound paradigm",
        "bound estimation",
        "POI (Point of Interest)"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/71fbb7c8673230f33df0d1038d081c3e752c58145cafe731ca10b83c9a359a8d_w640_q70.webp",
      "contributions": "1. Introduces the Keyword-Aware Top-k Routes (KATR) query, a flexible semantic for route planning that supports flexible POI visiting order, flexible travel distance budget, and personalized POI ratings., 2. Proposes an efficient explore-and-bound paradigm to process KATR queries by pruning redundant route candidates using estimated score bounds at global and local levels., 3. Demonstrates through extensive experiments that the proposed approach outperforms existing methods in various scenarios.",
      "summary": "This paper addresses the problem of generating optimal tourist routes based on keyword queries, which is challenging for LLMs due to the vast search space of POIs and routes. It proposes the KATR query for flexible route planning and an efficient explore-and-bound algorithm to find top-k routes. Experiments show the method's superior performance over existing approaches.",
      "mindmap": "graph TB\n        Root(”Flexible Keyword-Aware Top-k Route Search<br>论文标题”) --> Problem(”LLMs无法生成满足详细需求的最优路线<br>核心问题/Problem”)\n        Root --> Method(”提出KATR查询与探索-定界范式<br>主要方法/Method”)\n        Root --> Results(”方法在多种场景下性能优于现有方法<br>关键结果/Results”)\n        Problem --> Method\n        Method --> Results"
    },
    {
      "title": "Database Theory in Action: From Inexpressibility to Efficiency in GQL's Order-Constrained Paths",
      "authors": "Hadar Rotschield, Liat Peterfreund",
      "institution": "The Hebrew University of Jerusalem",
      "link": "https://arxiv.org/pdf/2512.23330",
      "code": "https://github.com/hadarrot/Order-Constrained-Paths-in-Leveled-Graphs",
      "tags": [
        "graph query languages",
        "GQL",
        "property graphs",
        "pattern matching",
        "order-constrained paths",
        "leveled graphs"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37076b55eeee6292e1ced20bc6e34983c94d5ae41216828cbf2e182f986c992_w640_q70.webp",
      "contributions": "1. A constructive translation that overcomes the expressiveness limitation of core GQL for checking increasing edge values along a path. 2. A compilation method that transforms the input graph and order condition into a leveled graph to capture the intended semantics. 3. A proof-of-concept implementation demonstrating that the compiled approach yields practical performance gains, running faster and avoiding timeouts compared to native expressions in systems like Neo4j's Cypher.",
      "summary": "The paper addresses the inexpressibility of order-constrained path queries (e.g., checking for increasing edge values) in the core GQL standard. It proposes a method to compile this condition into the input graph, creating a leveled graph that enables such queries via reachability. The implementation shows this theoretically motivated translation not only closes the expressiveness gap but also leads to significant performance improvements in practice.",
      "mindmap": "graph TB\n        Root[”Database Theory in Action: From Inexpressibility to Efficiency in GQL's Order-Constrained Paths”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>Core GQL cannot express<br>increasing edge values along a path”]\n        Method[”主要方法/Method<br>Compile condition into input graph<br>using leveled graph construction”]\n        Results[”关键结果/Results<br>Restores expressiveness<br>and improves performance”]"
    },
    {
      "title": "HL-index: Fast Reachability Query in Hypergraphs",
      "authors": "Peiting Xie, Xiangjun Zai, Yanping Wu, Xiaoyang Wang, Wenjie Zhang, Lu Qin",
      "institution": "The University of New South Wales, University of Technology Sydney",
      "link": "https://arxiv.org/pdf/2512.23345",
      "code": null,
      "tags": [
        "graph databases",
        "hypergraph",
        "reachability query",
        "s-reachability",
        "HL-index",
        "index construction"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/319a455ca1c94672837d9f4e7ca6e0f1c6b652927ab50a3eaefdfd43f2b3cffc_w640_q70.webp",
      "contributions": "1. Introduces the novel concept of s-reachability and the max-reachability query for hypergraphs, generalizing traditional reachability to model groupwise interactions. 2. Proposes the HL-index, a compact vertex-to-hyperedge index specifically designed to answer max-reachability queries efficiently. 3. Develops a fast covering relationship detection method and a lightweight neighbor-index to accelerate the construction of a minimal HL-index.",
      "summary": "This paper addresses the problem of efficiently answering reachability queries in hypergraphs, which model complex group interactions. It proposes a new index structure called HL-index, along with optimization techniques for its construction, to solve the max-reachability query problem. Experiments on 20 datasets show the approach is efficient and scalable.",
      "mindmap": "graph TB\n        A[HL-index: Fast Reachability Query in Hypergraphs] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[超图可达性查询<br>Hypergraph Reachability Query]\n        B --> B2[建模高阶群体交互<br>Modeling Higher-order Group Interactions]\n        C --> C1[提出s-可达性与最大可达性查询<br>Propose s-reachability & Max-reachability Query]\n        C --> C2[设计HL-index索引结构<br>Design HL-index Structure]\n        C --> C3[快速覆盖关系检测与邻居索引<br>Fast Covering Detection & Neighbor-index]\n        D --> D1[在20个数据集上验证<br>Validated on 20 Datasets]\n        D --> D2[高效且可扩展<br>Efficient and Scalable]"
    },
    {
      "title": "AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis",
      "authors": "Cehua Yang, Dongyu Xiao, Junming Lin, Yuyang Song, Hanxu Yan, Shawn Guo, Wei Zhang, Jian Yang, Mingjie Tang, Bryan Dai",
      "institution": "Sichuan University, IQuest Research, Beihang University",
      "link": "https://arxiv.org/pdf/2512.23366",
      "code": null,
      "tags": [
        "text-to-sql",
        "Reinforcement Learning",
        "Data Synthesis",
        "Policy Optimization",
        "Semantic-Logic Alignment",
        "Group Relative Policy Optimization"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6740c1fc529b82b509bd38c2a7b5fb405b969bc5c3e11e6e0b7690e7fa791c85_w640_q70.webp",
      "contributions": "1. Proposes an iterative data factory for synthesizing high-quality, RL-ready Text-to-SQL data with strict semantic-logic verification. 2. Introduces a novel Agentic Reinforcement Learning framework featuring a Diversity-Aware Cold Start stage and Group Relative Policy Optimization (GRPO). 3. Demonstrates state-of-the-art performance on the BIRD and Spider benchmarks through the synergistic combination of data-centric and model-centric approaches.",
      "summary": "This paper addresses the challenges of data scarcity and limited reasoning in Text-to-SQL systems. It proposes a holistic framework that combines a data-centric approach for synthesizing high-fidelity training data with a model-centric approach using a novel Agentic Reinforcement Learning method called Group Relative Policy Optimization. The method achieves state-of-the-art results on major benchmarks, showing the effectiveness of the synergistic approach.",
      "mindmap": "graph TB\n        A[AGRO-SQL] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[数据稀缺与质量/Data Scarcity & Quality]\n        B --> B2[模型推理限制/Model Reasoning Limitations]\n        C --> C1[数据中心方法/Data-Centric Approach]\n        C --> C2[模型中心方法/Model-Centric Approach]\n        C1 --> C1a[迭代数据工厂/Iterative Data Factory]\n        C1 --> C1b[语义逻辑对齐/Semantic-Logic Alignment]\n        C2 --> C2a[多样性感知冷启动/Diversity-Aware Cold Start]\n        C2 --> C2b[组相对策略优化/Group Relative Policy Optimization]\n        D --> D1[在BIRD和Spider上SOTA/SOTA on BIRD & Spider]"
    },
    {
      "title": "Distributed Processing of kNN Queries over Moving Objects on Dynamic Road Networks",
      "authors": "Mingjin Tao, Kailin Jiao, Yawen Li, Wei Liu, Ziqiang Yu",
      "institution": "Yantai University, Beijing University of Posts and Telecommunications",
      "link": "https://arxiv.org/pdf/2512.23399",
      "code": null,
      "tags": [
        "spatial databases",
        "kNN query",
        "dynamic road network",
        "distributed algorithm",
        "Dijkstra's algorithm",
        "network expansion"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34095d1bd1c2f5f873ce8c45a88c287cb1232db027d484638870a82e174044f3_w640_q70.webp",
      "contributions": "1. Pioneers the study of kNN queries on dynamic road networks with evolving travel costs, moving beyond static distance metrics. 2. Proposes DkNN, a distributed algorithm that partitions the road network for parallel, incremental exploration using Dijkstra's algorithm, avoiding the maintenance overhead of global indexes. 3. Effectively addresses the challenge of maintaining global distance accuracy during local subgraph exploration while minimizing unnecessary searches and enabling early termination.",
      "summary": "This paper addresses the problem of finding k nearest neighbors for moving objects on dynamic road networks where travel costs fluctuate over time. It proposes DkNN, a distributed algorithm that partitions the network and performs parallel, incremental expansion using Dijkstra's algorithm to efficiently find results without relying on indexes that are costly to maintain. Implemented on Storm, DkNN shows superior efficiency and effectiveness compared to traditional methods in real-world scenarios.",
      "mindmap": "graph TB\n        A[Distributed Processing of kNN Queries over Moving Objects on Dynamic Road Networks] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: kNN查询在动态路网中/kNN query on dynamic road networks with fluctuating travel costs]\n        C[主要方法/Method: DkNN分布式算法，分区并行扩展/DkNN distributed algorithm, partitioned parallel expansion]\n        D[关键结果/Results: 在Storm上实现，优于传统方法/Implemented on Storm, outperforms traditional methods]"
    },
    {
      "title": "SPER: Accelerating Progressive Entity Resolution via Stochastic Bipartite Maximization",
      "authors": "Dimitrios Karapiperis, George Papadakis, Themis Palpanas, Vassilios Verykios",
      "institution": "International Hellenic University, National and Kapodistrian University of Athens, Université Paris Cité; IUF, Hellenic Open University",
      "link": "https://arxiv.org/pdf/2512.23491",
      "code": null,
      "tags": [
        "entity resolution",
        "progressive entity resolution",
        "stochastic bipartite maximization",
        "linear-time prioritization",
        "high-velocity streams",
        "scalability"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb9a0b2b37277a329fd22df71d790c106e63e812c17e0e0a3ae1c3882eb51179_w640_q70.webp",
      "contributions": "1. Introduces SPER, a novel framework that redefines candidate pair prioritization in Progressive ER from a ranking problem to a sampling problem. 2. Proposes a continuous stochastic bipartite maximization strategy to replace deterministic global sorting, enabling strictly linear-time operation. 3. Demonstrates through extensive experiments that SPER achieves significant speedups (3x to 6x) over state-of-the-art baselines while maintaining comparable recall and precision.",
      "summary": "The paper addresses the scalability limitations of existing Progressive Entity Resolution (ER) methods, which rely on super-linear deterministic sorting for candidate prioritization. It proposes SPER, a novel framework that uses a stochastic bipartite maximization strategy to act as a probabilistic high-pass filter, selecting high-utility pairs in linear time. Experiments show SPER achieves 3x to 6x speedups over state-of-the-art methods while maintaining similar accuracy.",
      "mindmap": "graph TB\n        A[SPER: Accelerating Progressive Entity Resolution via Stochastic Bipartite Maximization] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[传统渐进式ER方法无法扩展到高速数据流/Traditional Progressive ER fails to scale to high-velocity streams]\n        B --> B2[确定性排序导致超线性复杂度和高初始化成本/Deterministic sorting incurs super-linear complexity & heavy initialization]\n        C --> C1[将优先级排序重新定义为采样问题/Redefine prioritization as a sampling problem]\n        C --> C2[使用连续随机二分图最大化策略/Use continuous stochastic bipartite maximization strategy]\n        C --> C3[作为概率性高通滤波器，实现线性时间选择/Act as a probabilistic high-pass filter for linear-time selection]\n        D --> D1[在8个真实数据集上验证/Validated on 8 real-world datasets]\n        D --> D2[速度提升3-6倍/Speedups of 3x to 6x]\n        D --> D3[保持相当的召回率和精度/Maintains comparable recall & precision]"
    },
    {
      "title": "Harnessing Data Spaces to Build Intelligent Smart City Infrastructures Across the Cloud-Edge Continuum",
      "authors": "Dimitrios Amaxilatis, Themistoklis Sarantakos, Nikolaos Tsironis, Souvik Sengupta, Kostas Ramantas, Jhofre Ojeda",
      "institution": "Spark Works Ltd., IONOS SE, Iquadrat Informática S.L.",
      "link": "https://arxiv.org/pdf/2512.21340",
      "code": null,
      "tags": [
        "on-device ai",
        "data spaces",
        "cloud-edge continuum",
        "containerized microservices",
        "edge AI",
        "intelligent infrastructure monitoring"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp",
      "contributions": "1. A real-world implementation of intelligent infrastructure monitoring within a data space-enabled cloud-edge framework, demonstrating practical integration. 2. Leveraging edge computing, containerized microservices, and interoperable data sharing to address challenges like sensor integration, data privacy, and scalability. 3. Showcasing the training and deployment of AI/ML services directly at the edge for optimized resource use and timely decision-making in smart city applications.",
      "summary": "This paper presents a real-world use case for smart cities, implementing an intelligent climate monitoring system within a cloud-edge continuum framework enabled by data spaces. The method combines edge computing, containerized microservices, and secure data sharing to facilitate localized analytics and AI deployment. The conclusion highlights the transformative potential of integrating AI, edge computing, and data spaces for building efficient and resilient smart city infrastructures.",
      "mindmap": "graph TB\n        A[Harnessing Data Spaces for Smart City Infrastructures] --> B[核心问题/Problem: Enhancing smart city efficiency, sustainability, and resilience with secure, interoperable data exchange]\n        A --> C[主要方法/Method: Data space-enabled cloud-edge framework with edge computing, containerized microservices, and edge AI/ML]\n        A --> D[关键结果/Results: Demonstrates practical use case for intelligent monitoring, enabling localized analytics, real-time inference, and trusted data collaboration]"
    },
    {
      "title": "Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks",
      "authors": "Jasmin Saxer, Isabella Maria Aigner, Luise Linzmeier, Andreas Weiler, Kurt Stockinger",
      "institution": "Zurich University of Applied Sciences, University of Zurich",
      "link": "https://arxiv.org/pdf/2512.21345",
      "code": null,
      "tags": [
        "text-to-SQL",
        "unanswerable question detection",
        "few-shot prompting",
        "biomedical databases"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d95c00b7fa86810771a1c8fb0ff6fd8768baaa0419f172cc5c7a3068ac67a64_w640_q70.webp",
      "contributions": "1. Proposed Query Carefully, a pipeline integrating LLM-based SQL generation with explicit detection of unanswerable inputs. 2. Constructed OncoMX-NAQ, a benchmark dataset of 80 no-answer questions for biomedical text-to-SQL. 3. Demonstrated that balanced few-shot prompting with both answerable and unanswerable examples achieves high unanswerable-detection accuracy without degrading performance on answerable queries.",
      "summary": "This paper addresses the risk of text-to-SQL systems generating executable but incorrect SQL for ambiguous or unanswerable queries, especially in biomedical contexts. The authors propose the Query Carefully pipeline, which uses an LLM with schema-aware prompts and few-shot examples to detect and abstain from unanswerable inputs. Their evaluation shows the method achieves high detection accuracy for structurally unanswerable queries, though challenges remain for semantic ambiguities like missing values.",
      "mindmap": "graph TB\n        Root(”Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks”) --> Problem\n        Root --> Method\n        Root --> Results\n        Problem(”核心问题/Problem”) --> P1(”Text-to-SQL对不可回答查询生成可执行SQL/Text-to-SQL generates executable SQL for unanswerable queries”)\n        P1 --> P2(”生物医学领域风险高/High risk in biomedical contexts”)\n        Method(”主要方法/Method”) --> M1(”Query Carefully 管道/Query Carefully pipeline”)\n        M1 --> M2(”LLM (llama3.3:70b) + 模式感知提示 + 少样本/LLM (llama3.3:70b) + schema-aware prompts + few-shot”)\n        M2 --> M3(”包含可回答与不可回答示例/Includes answerable and unanswerable examples”)\n        Results(”关键结果/Results”) --> R1(”构建OncoMX-NAQ基准/Built OncoMX-NAQ benchmark”)\n        R1 --> R2(”不可回答检测准确率0.8/Unanswerable-detection accuracy 0.8”)\n        R2 --> R3(”结构性问题检测好，语义模糊挑战大/Good for structural, challenging for semantic ambiguity”)"
    },
    {
      "title": "Weighted Fourier Factorizations: Optimal Gaussian Noise for Differentially Private Marginal and Product Queries",
      "authors": "Christian Janos Lebeda, Aleksandar Nikolov, Haohua Tang",
      "institution": "Inria, Université de Montpellier, INSERM, University of Toronto",
      "link": "https://arxiv.org/pdf/2512.21499",
      "code": null,
      "tags": [
        "differential privacy",
        "factorization mechanism",
        "Fourier basis",
        "marginal queries",
        "product queries",
        "Gaussian noise"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/589c857d3c263098ff5b7608b80fed9cb6cf72f1228f01d3ba136496420444dc_w640_q70.webp",
      "contributions": "1. Proposes a simpler, polynomial-time algorithm for releasing weighted marginal queries under differential privacy using Fourier factorization, achieving exact optimality among factorization mechanisms. 2. Extends the algorithm to a more general class of product queries, maintaining exact optimality. 3. Shows the mechanism is almost optimal for extended marginal queries with threshold predicates, achieving optimal noise variance up to lower-order terms.",
      "summary": "This paper proposes a new algorithm for releasing marginal and product queries under differential privacy by adding correlated Gaussian noise. The method works by releasing queries in the Fourier basis with independent, carefully calibrated noise and then reconstructing the answers, which is proven to be exactly optimal among factorization mechanisms and runs in polynomial time. It simplifies and improves upon prior work, extending optimality to more general query classes.",
      "mindmap": "graph TB\n        A[Weighted Fourier Factorizations<br>加权傅里叶分解] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Releasing marginal queries<br>with differential privacy<br>在差分隐私下发布边际查询]\n        C --> C1[Use Fourier basis &<br>independent Gaussian noise<br>使用傅里叶基和独立高斯噪声]\n        C --> C2[Reconstruct via<br>inverse Fourier transform<br>通过逆傅里叶变换重构]\n        D --> D1[Exactly optimal for<br>marginal & product queries<br>对边际和乘积查询精确最优]\n        D --> D2[Polynomial-time algorithm<br>多项式时间算法]\n        D --> D3[Simpler & better than<br>prior work (Xiao et al.)<br>比先前工作更简单更好]"
    },
    {
      "title": "Embedding Samples Dispatching for Recommendation Model Training in Edge Environments",
      "authors": "Guopeng Li, Haisheng Tan, Chi Zhang, Hongqiu Ni, Zilong Wang, Xinyue Zhang, Yang Xu, Han Tian",
      "institution": "University of Science and Technology of China (USTC), Hefei University of Technology",
      "link": "https://arxiv.org/pdf/2512.21615",
      "code": null,
      "tags": [
        "memory & caching",
        "edge computing",
        "embedding cache",
        "parameter server",
        "sample dispatching",
        "transmission cost"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f94cc43f65f5fd909f8762bda535a33eea94f879931ebe1a563280cb0db1be81_w640_q70.webp",
      "contributions": "1. Proposed ESD, a novel mechanism to optimize the dispatch of input embedding samples to edge workers to minimize embedding transmission cost. 2. Designed HybridDis, a dispatch decision method that combines an optimal algorithm and a heuristic to balance decision quality and resource consumption. 3. Implemented a prototype and demonstrated significant reductions in transmission cost (up to 36.76%) and training speedup (up to 1.74x) on real-world workloads.",
      "summary": "This paper addresses the high communication cost of embedding transmission during Deep Learning Recommendation Model (DLRM) training in edge environments. It proposes ESD, a mechanism that dispatches input samples to edge workers to minimize expected transmission cost, using a hybrid decision method called HybridDis. Experimental results show that ESD significantly reduces transmission cost and speeds up end-to-end training compared to state-of-the-art methods.",
      "mindmap": "graph TB\n        Root[”Embedding Samples Dispatching for Recommendation Model Training in Edge Environments<br>边缘环境中推荐模型训练的嵌入样本调度”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>DLRM边缘训练中嵌入传输成本高”] --> P1[”挑战/Challenges<br>异构网络，资源受限”]\n        Method[”主要方法/Method<br>ESD机制与HybridDis调度”] --> M1[”方法核心/Core<br>基于预期传输成本的样本调度”]\n        Results[”关键结果/Results<br>减少传输成本，加速训练”] --> R1[”性能提升/Improvement<br>成本降低36.76%，速度提升1.74倍”]"
    },
    {
      "title": "Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets",
      "authors": "Matyas Bohacek, Ignacio Vilanova Echavarri",
      "institution": "Stanford University, Imperial College London",
      "link": "https://arxiv.org/pdf/2512.21775",
      "code": null,
      "tags": [
        "Data Provenance",
        "Data Provenance",
        "Compliance Rating",
        "Generative AI",
        "Dataset Ethics",
        "Transparency"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa33a1fedd52ef1c87e9bf7d9a25dad61aae942ba50660263862470b9b677745_w640_q70.webp",
      "contributions": "1. Proposes the Compliance Rating Scheme (CRS), a framework for evaluating dataset compliance with transparency, accountability, and security principles. 2. Develops and releases an open-source Python library that implements the CRS framework using data provenance technology. 3. Creates a tool that is both reactive (evaluating existing datasets) and proactive (guiding the responsible construction of new datasets).",
      "summary": "The paper addresses the lack of ethical and legal oversight in the creation and sharing of datasets for Generative AI. It proposes the Compliance Rating Scheme (CRS) framework and an accompanying open-source library to assess and ensure dataset compliance with key principles. The work aims to improve traceability and accountability in the AI data supply chain.",
      "mindmap": "graph TB\n        Root(”Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”数据集创建缺乏伦理与法律监督/Lack of ethical & legal oversight in dataset creation”)\n        Problem --> P2(”数据来源与合法性信息丢失/Loss of data origin & legitimacy info”)\n        Method --> M1(”提出合规评级方案(CRS)框架/Propose Compliance Rating Scheme (CRS) framework”)\n        Method --> M2(”开发基于数据溯源技术的开源库/Develop open-source library using data provenance”)\n        Results --> R1(”评估现有数据集的合规性/Evaluate compliance of existing datasets”)\n        Results --> R2(”指导负责任的新数据集构建/Guide responsible construction of new datasets”)"
    },
    {
      "title": "Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs",
      "authors": "Yafeng Tang, Xiaoou Ding, Jianzhuo Du, Zishuo Yan, Zhuang Ma, Zheng Liang, Zekai Qian, Hongzhi Wang",
      "institution": "Harbin Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.21915",
      "code": "https://github.com/windblow32/DATE",
      "tags": [
        "others",
        "Tabular Data Generation",
        "Large Language Models",
        "Multi-Arm Bandit",
        "Data Diversity",
        "In-context Learning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d8fa8039f8a5fa0717fc5e4a9c7ba2cf1fd158e44821059f4a767bc88790eaf_w640_q70.webp",
      "contributions": "1. Introduces DATE, a framework that partitions heterogeneous tabular data into diverse subsets to prepare high-quality examples for in-context learning. 2. Proves the selection problem in heterogeneous data generation lacks the greedy-choice property and designs a Multi-Arm Bandit-based sampling algorithm to balance diversity and quality. 3. Demonstrates that DATE-generated data improves downstream tasks like Direct Preference Optimization (DPO) and enhances LLM reasoning on target data.",
      "summary": "This paper addresses the challenge of generating high-quality synthetic tabular data from heterogeneous distributions. It proposes DATE, a framework that uses LLMs with decision tree feedback for subset-specific generation and a Multi-Arm Bandit algorithm for data selection. Experiments show DATE outperforms existing methods, reducing error rates and improving downstream model performance.",
      "mindmap": "graph TB\n        Root[”Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs”] --> Problem[”核心问题/Problem: Real-world tabular data is heterogeneous, making universal generation models challenging”]\n        Root --> Method[”主要方法/Method: DATE framework partitions data, uses LLMs with decision tree feedback, and applies Multi-Arm Bandit for selection”]\n        Root --> Results[”关键结果/Results: Outperforms SOTA methods, reduces error rate by 23.75%, improves DPO and LLM reasoning”]"
    },
    {
      "title": "MarineEval: Assessing the Marine Intelligence of Vision-Language Models",
      "authors": "YuK-Kwan Wong, Tuan-An To, Jipeng Zhang, Ziqiang Zheng, Sai-Kit Yeung",
      "institution": "Hong Kong University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.21126",
      "code": "https://marineeval.hkustvgd.com",
      "tags": [
        "vision-language models",
        "marine intelligence",
        "domain-specific evaluation",
        "benchmark dataset"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98ea3a0e94d1e540398b18f5612700e51ce9e190b312a741182b20da5ecfacac_w640_q70.webp",
      "contributions": "1. Introduces MarineEval, the first large-scale marine domain-specific dataset and benchmark for evaluating Vision-Language Models (VLMs). 2. Constructs a diverse dataset with 2,000 image-based QA pairs, covering 7 task dimensions and 20 capacity dimensions, validated by marine domain experts. 3. Provides a comprehensive benchmark evaluation of 17 existing VLMs, revealing their significant limitations in handling domain-specific marine questions and highlighting areas for future improvement.",
      "summary": "This paper investigates whether existing general-purpose Vision-Language Models (VLMs) can act as domain experts for marine science. To evaluate this, the authors construct MarineEval, a large-scale, expert-verified benchmark dataset of 2,000 marine image-question-answer pairs. The benchmark reveals that current VLMs perform poorly on this domain-specific task, indicating a significant gap and need for future research in specialized VLM capabilities.",
      "mindmap": "graph LR\n    A[MarineEval: Assessing the Marine Intelligence of Vision-Language Models] --> B(核心问题/Problem: Can VLMs act as marine domain experts?);\n    A --> C(主要方法/Method: Construct MarineEval benchmark with 2000 expert-verified marine image-QA pairs);\n    A --> D(关键结果/Results: Existing VLMs perform poorly, highlighting a large room for improvement);"
    },
    {
      "title": "An Allele-Centric Pan-Graph-Matrix Representation for Scalable Pangenome Analysis",
      "authors": "Roberto Garrone",
      "institution": "University of Milano-Bicocca",
      "link": "https://arxiv.org/pdf/2512.21320",
      "code": null,
      "tags": [
        "computational genomics",
        "pangenome representation",
        "allele-centric modeling",
        "sparse-dense hybrid encoding",
        "genomic data compression"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/47769022333474d616f56daabe2a8f15f3f606c9ff2cc86a0693b945b208b031_w640_q70.webp",
      "contributions": "1. Introduces H1, a novel allele-centric pan-graph-matrix representation that treats alleles as first-class objects and uses adaptive per-allele compression for efficient storage. 2. Introduces H2, a path-centric dual representation derived from the same underlying data, which restores explicit haplotype ordering while maintaining information equivalence. 3. Demonstrates that the representation achieves substantial compression gains, particularly for structural variants, while remaining informationally equivalent to pangenome graphs.",
      "summary": "The paper addresses the need for scalable, population-aware pangenome representations that unify different types of genomic variation. It proposes the H1 pan-graph-matrix, an allele-centric representation with adaptive compression, and its dual H2 representation. The method shows significant compression benefits, especially for structural variants, providing a unified foundation for large-scale pangenome analysis.",
      "mindmap": "graph LR\n    A[An Allele-Centric Pan-Graph-Matrix Representation] --> B(核心问题/Problem: Scalable, unified pangenome representation for population-scale analysis)\n    A --> C(主要方法/Method: H1 allele-centric matrix with adaptive compression & H2 path-centric dual)\n    A --> D(关键结果/Results: Substantial compression gains, equivalent information, unified foundation)"
    },
    {
      "title": "Asia Cup 2025: A Structured T20 Match-Level Dataset and Exploratory Analysis for Cricket Analytics",
      "authors": "Kousar Raza, Faizan Ali",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19740",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f547c21d7d60b5ce4f92522c83aa7c297fc051a77b6eddf69ef405348fda9d8_w640_q70.webp",
      "contributions": "",
      "summary": "Asia Cup 2025: A Structured T20 Match-Level Dataset and Exploratory Analysis for Cricket Analytics",
      "mindmap": ""
    },
    {
      "title": "Risk-Aware GPU-Assisted Cardinality Estimation for Cost-Based Query Optimizers",
      "authors": "Ilsun Chang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19750",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22261640471da63aebf047b2045859846dac3cc2b34448b820a7154bc31cfb4f_w640_q70.webp",
      "contributions": "",
      "summary": "Risk-Aware GPU-Assisted Cardinality Estimation for Cost-Based Query Optimizers",
      "mindmap": ""
    },
    {
      "title": "Automated Training of Learned Database Components with Generative AI",
      "authors": "Angjela Davitkova, Sebastian Michel",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20271",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cc880d38922c9b2f56b78a3d6cf42027fb2c3ae8eb0ea56ebd9907f0c6b0a8b_w640_q70.webp",
      "contributions": "",
      "summary": "Automated Training of Learned Database Components with Generative AI",
      "mindmap": ""
    },
    {
      "title": "Memelang: An Axial Grammar for LLM-Generated Vector-Relational Queries",
      "authors": "Bri Holt",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17967",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ebc97e26c8b4495d4266d2df2068075acfc72cc34bd5761f186017a45a8314b_w640_q70.webp",
      "contributions": "",
      "summary": "Memelang: An Axial Grammar for LLM-Generated Vector-Relational Queries",
      "mindmap": ""
    },
    {
      "title": "Sync Without Guesswork: Incomplete Time Series Alignment",
      "authors": "Ding Jia, Jingyu Zhu, Yu Sun, Aoqian Zhang, Shaoxu Song, Haiwei Zhang, Xiaojie Yuan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18238",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5f4c126958228d6ea59af83cad80432da90bc8efb5266f0e8786181c748bb51_w640_q70.webp",
      "contributions": "",
      "summary": "Sync Without Guesswork: Incomplete Time Series Alignment",
      "mindmap": ""
    },
    {
      "title": "Towards Scalable Visual Data Wrangling via Direct Manipulation",
      "authors": "El Kindi Rezig, Mir Mahathir Mohammad, Nicolas Baret, Ricardo Mayerhofer, Andrew McNutt, Paul Rosen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18405",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/790118e217a177acb4ecd824d816066f84640176a4ebb5ada4193f1841afa44c_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Scalable Visual Data Wrangling via Direct Manipulation",
      "mindmap": ""
    },
    {
      "title": "A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback",
      "authors": "Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18622",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp",
      "contributions": "",
      "summary": "A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback",
      "mindmap": ""
    },
    {
      "title": "A Computationally Efficient Framework for Overlapping Community Detection in Large Bipartite Graphs",
      "authors": "Yue Zeng, Rong-Hua Li, Qiangqiang Dai, Guoren Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19426",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f33f4dadd12545035534b76bb1ee771a53f3293698ac5dc76cc68d188c95b15a_w640_q70.webp",
      "contributions": "",
      "summary": "A Computationally Efficient Framework for Overlapping Community Detection in Large Bipartite Graphs",
      "mindmap": ""
    },
    {
      "title": "Knowledge Distillation with Structured Chain-of-Thought for Text-to-SQL",
      "authors": "Khushboo Thaker, Yony Bresler",
      "institution": "Crater Labs",
      "link": "https://arxiv.org/pdf/2512.17053",
      "code": null,
      "tags": [
        "llm training",
        "knowledge distillation",
        "chain-of-thought",
        "structured reasoning",
        "query execution plan",
        "text-to-sql"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/906b49597857a3cad8e1c9c8d6cdbec46e7807fe819943d1e6d91facfb7f18bd_w640_q70.webp",
      "contributions": "",
      "summary": "The paper proposes Struct-SQL, a knowledge distillation framework that trains a small language model using a structured chain-of-thought derived from query execution plans, rather than unstructured reasoning traces. The distilled model achieves an 8.1% absolute improvement over an unstructured baseline, primarily due to a reduction in syntactic errors. This demonstrates that structured logical blueprints are beneficial for reliable SQL generation in small models.",
      "mindmap": ""
    },
    {
      "title": "Scaling Text2SQL via LLM-efficient Schema Filtering with Functional Dependency Graph Rerankers",
      "authors": "Thanh Dat Hoang, Thanh Tam Nguyen, Thanh Trung Huynh, Hongzhi Yin, Quoc Viet Hung Nguyen",
      "institution": "Griffith University, VinUniversity, The University of Queensland",
      "link": "https://arxiv.org/pdf/2512.16083",
      "code": null,
      "tags": [
        "llm inference",
        "schema filtering",
        "functional dependency graph",
        "graph transformer",
        "Steiner-tree heuristic",
        "query-aware LLM encoder"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces GRAST-SQL, a framework for scaling Text2SQL systems by efficiently filtering and compacting database schemas before prompting an LLM. It uses a query-aware LLM encoder, a graph transformer over functional dependencies, and a Steiner-tree heuristic to select a relevant, connectivity-preserving sub-schema. The method achieves high recall and precision while maintaining low latency and scaling to schemas with over 23,000 columns.",
      "mindmap": ""
    },
    {
      "title": "ModelTables: A Corpus of Tables about Models",
      "authors": "Zhengyuan Dong, Victor Zhong, Renée J. Miller",
      "institution": "University of Waterloo",
      "link": "https://arxiv.org/pdf/2512.16106",
      "code": null,
      "tags": [
        "others",
        "table retrieval",
        "model lakes",
        "data lakes",
        "unionable tables",
        "joinable tables",
        "dense retrieval",
        "sparse retrieval",
        "hybrid retrieval",
        "benchmark construction"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces ModelTables, a benchmark corpus of structured tables describing AI models, built from sources like Hugging Face model cards and GitHub READMEs. It evaluates table search methods, finding that table-based dense retrieval performs best but leaves significant room for improvement. The work provides a foundation for better semantic retrieval and organization of structured model knowledge.",
      "mindmap": ""
    },
    {
      "title": "Graph Pattern-based Association Rules Evaluated Under No-repeated-anything Semantics in the Graph Transactional Setting",
      "authors": "Basil Ell",
      "institution": "Bielefeld University, University of Oslo",
      "link": "https://arxiv.org/pdf/2512.15308",
      "code": null,
      "tags": [
        "graph mining",
        "graph pattern-based association rules",
        "no-repeated-anything semantics",
        "confidence",
        "lift",
        "leverage",
        "conviction"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces Graph Pattern-based Association Rules (GPARs) for analyzing directed labeled multigraphs like RDF graphs. It evaluates these rules under a \"no-repeated-anything\" semantics to better account for graph topology and defines probabilistic metrics like confidence and lift. The framework is shown to extend beyond existing formalisms for graph data.",
      "mindmap": ""
    }
  ]
}