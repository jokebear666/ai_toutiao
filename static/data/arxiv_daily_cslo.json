{
  "label": "cs.LO",
  "slug": "cslo",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "Biochemical Computing Mode for Sequential Logic",
      "authors": "Han Huang, Chengzhi Ma, Yuxin Zhao, Qingyao Wang, Xinglong Xiao, Xiulin Shu, Zhifeng Hao",
      "institution": "South China University of Technology",
      "link": "https://arxiv.org/pdf/2512.23734",
      "code": null,
      "tags": [
        "unconventional computing",
        "biochemical computing",
        "sequential logic",
        "biochemical computing",
        "enzymatic reactions",
        "logic gate",
        "sequential mapping"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a445dc0ec7c178dcff0eacecd2ca96419424f5499d1a975b953630aaa1254da_w640_q70.webp",
      "contributions": "1. Demonstrates and highlights the concept of \"sequential mapping\" as a crucial necessary condition for realizing sequential logic circuits in general-purpose computers. 2. Proposes a novel biochemical computing mode using enzyme-controlled reactions to design a logic gate model composed of small molecules. 3. Mathematically proves that the proposed biochemical computing mode satisfies sequential mapping and, combined with storage characteristics, can realize sequential logic circuits.",
      "summary": "The paper addresses the challenge of implementing sequential logic in next-generation computing paradigms. It proposes a biochemical computing mode using enzyme-driven molecular logic gates and mathematically proves it satisfies the sequential mapping property, enabling sequential logic circuits. This work provides a theoretical foundation for developing general-purpose biochemical computers.",
      "mindmap": "graph TB\n        A[Biochemical Computing Mode for Sequential Logic] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Sequential logic implementation is overlooked in unconventional computing/非常规计算中时序逻辑的实现被忽视]\n        C --> C1[Design enzyme-driven molecular logic gates/设计酶驱动的分子逻辑门]\n        C --> C2[Mathematical analysis of input-output properties/输入输出特性的数学分析]\n        D --> D1[Proves biochemical mode satisfies sequential mapping/证明生化模式满足顺序映射]\n        D --> D2[Enables sequential logic circuits/能够实现时序逻辑电路]\n        D --> D3[Foundation for general-purpose biochemical computers/为通用生化计算机奠定基础]"
    },
    {
      "title": "Enforcing Temporal Constraints for LLM Agents",
      "authors": "Adharsh Kamath, Sishen Zhang, Calvin Xu, Shubham Ugare, Gagandeep Singh, Sasa Misailovic",
      "institution": "University of Illinois at Urbana-Champaign, Meta",
      "link": "https://arxiv.org/pdf/2512.23738",
      "code": "https://github.com/structuredllm/agent-c",
      "tags": [
        "agent system",
        "temporal constraints",
        "SMT solving",
        "constrained generation",
        "formal verification",
        "LLM agents"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a978adfab8b202d7b971f6b65f8d005235baabb93f5540985ad131638c67354_w640_q70.webp",
      "contributions": "1. A novel framework (Agent-C) providing runtime guarantees for LLM agents to adhere to formal temporal safety properties., 2. A domain-specific language for expressing temporal properties, which are translated to first-order logic and verified via SMT solving during token generation., 3. Demonstration of perfect safety (100% conformance) and improved task utility across real-world applications and multiple LLMs, outperforming state-of-the-art guardrails.",
      "summary": "The paper addresses the problem of LLM agents violating temporal safety policies, such as accessing data before authentication. It proposes Agent-C, a framework that uses a domain-specific language, formal logic translation, and SMT solving to enforce constraints during token generation, ensuring compliant actions. The evaluation shows Agent-C achieves 100% safety conformance and improves task utility compared to existing methods.",
      "mindmap": "graph TB\n        A[Enforcing Temporal Constraints for LLM Agents] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有护栏无法保证时间安全策略/Existing guardrails fail to enforce temporal safety policies]\n        C --> C1[提出Agent-C框架/Propose Agent-C framework]\n        C1 --> C2[使用DSL和SMT求解进行运行时验证/Use DSL & SMT solving for runtime verification]\n        C2 --> C3[采用约束生成确保合规/Achieve compliance via constrained generation]\n        D --> D1[100%安全性，0%危害/100% safety, 0% harm]\n        D --> D2[在真实应用中提高任务效用/Improve task utility in real-world applications]"
    },
    {
      "title": "A precise proof of the n-variable Bekic principle",
      "authors": "Jun Xu",
      "institution": "None (No affiliation or email domain provided in the given content)",
      "link": "https://arxiv.org/pdf/2512.24038",
      "code": null,
      "tags": [
        "formal verification",
        "Bekič principle",
        "fixed point",
        "lexicographic order",
        "complete lattice",
        "monotone function"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4db85492f5b6e4642bc422cde756fe37f08a0abcae8a05883ab79043a073280a_w640_q70.webp",
      "contributions": "1. Provides a rigorous, inductive proof of the n-variable Bekič principle for n&gt;3, which has been missing from the literature. 2. Formalizes the principle by expressing a vectorial fixpoint as nested fixpoints organized according to lexicographic order, making it suitable for theorem provers. 3. Clarifies the structure of the generalization by showing the correspondence between the nesting structure and strings over an alphabet without repetition.",
      "summary": "This paper addresses the lack of a formal proof for the n-variable generalization of the Bekič principle, which decomposes a vectorial fixed point into nested fixed points. The authors provide a rigorous inductive proof that structures the fixpoints according to lexicographic order, making the result suitable for formal verification in theorem provers.",
      "mindmap": "graph TB\n        Root[”A precise proof of the n-variable Bekic principle<br/>n变量Bekic原理的精确证明”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br/>Missing formal proof for n-ary Bekič principle (n>3)<br/>缺少n元Bekič原理（n>3）的形式化证明”] --> P1[”目标/Goal<br/>Generalize the 2-variable case to n variables<br/>将二元情况推广到n元”]\n        Method[”主要方法/Method<br/>Inductive proof based on lexicographic order<br/>基于字典序的归纳证明”] --> M1[”技术/Technique<br/>Organize fixpoints into a tree structure<br/>将不动点组织为树结构”]\n        Results[”关键结果/Results<br/>Precise statement and proof of the n-variable principle<br/>n变量原理的精确陈述与证明”] --> R1[”应用/Application<br/>Suitable for formalization in theorem provers<br/>适用于定理证明器中的形式化”]"
    },
    {
      "title": "Proof-Carrying PWL Verification for ReLU Networks: Convex-Hull Semantics, Exact / Encodings, and Symbolic Certificate Checking",
      "authors": "Chandrasekhar Gokavarapu",
      "institution": "Government College (Autonomous), Rajahmundry",
      "link": "https://arxiv.org/pdf/2512.24339",
      "code": null,
      "tags": [
        "neural network verification",
        "ReLU verification",
        "convex hull",
        "LP duality",
        "Farkas lemma",
        "proof-carrying verification"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c44dc227a06c8817ca647176e90fb57664e45f650fe73d475d3a56b323d3d0_w640_q70.webp",
      "contributions": "1. Formalizes ReLU networks as unions of polyhedra indexed by activation patterns. 2. Presents exact SMT/MILP encodings and the canonical convex-hull relaxation for bounded ReLUs. 3. Introduces a certificate calculus that emits explicit algebraic witnesses (like LP dual multipliers) for verification steps, enabling independent, exact symbolic checking.",
      "summary": "The paper addresses the need for checkable evidence in the formal verification of ReLU neural networks. It proposes a proof-carrying verification core that generates symbolic certificates (e.g., LP dual multipliers) for each step of the verification process, which can be independently verified using exact arithmetic. This approach transforms neural verification into a pipeline where the final safety claim is backed by a machine-checkable, compositional proof artifact.",
      "mindmap": "graph TB\n        A[Proof-Carrying PWL Verification for ReLU Networks] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Safety claims need checkable evidence, not just unsat verdicts]\n        C[主要方法/Method: Certificate calculus emitting symbolic witnesses (LP duals, Farkas certificates)]\n        D[关键结果/Results: Symbolic checker, compositional proof artifact for universal safety]"
    },
    {
      "title": "Open Horn Type Theory",
      "authors": "Iman Poernomo",
      "institution": "ICRA Press",
      "link": "https://arxiv.org/pdf/2512.24498",
      "code": null,
      "tags": [
        "type theory",
        "dependent type theory",
        "homotopy type theory",
        "simplicial sets",
        "coherence",
        "obstruction"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11be216c3251a0f9974241ff50b07a4182d33ebbf2733b1215675aa40cf6f09a_w640_q70.webp",
      "contributions": "1. Introduces Open Horn Type Theory (OHTT), a novel extension of dependent type theory with primitive coherence and gap judgments, 2. Develops the semantics of OHTT using ruptured simplicial sets and ruptured Kan complexes, 3. Demonstrates three classes of applications for OHTT's gap witnesses: topological, semantic, and logical obstructions",
      "summary": "The paper introduces Open Horn Type Theory (OHTT), a new dependent type theory that adds primitive \"coherence\" and \"gap\" judgments to model obstructions that standard Homotopy Type Theory cannot express. It provides a semantics based on ruptured simplicial sets and shows that OHTT can capture topological, semantic, and logical obstructions as positive structural witnesses.",
      "mindmap": "graph TB\n        Root[Open Horn Type Theory] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[HoTT无法表达某些阻碍/HoTT cannot express certain obstructions]\n        Method[主要方法/Method] --> M1[引入OHTT，扩展依赖类型论/Introduce OHTT, extending dependent type theory]\n        Method --> M2[原始判断：一致性、间隙/Primitive judgments: coherence, gap]\n        Method --> M3[语义：破裂单纯集/Semantics: ruptured simplicial sets]\n        Results[关键结果/Results] --> R1[捕获传输阻碍/Captures transport obstructions]\n        Results --> R2[嵌入HoTT为一致片段/Embeds HoTT as coherent fragment]\n        Results --> R3[发展三类阻碍应用/Develops three classes of obstruction applications]"
    },
    {
      "title": "A Tale of 1001 LoC: Potential Runtime Error-Guided Specification Synthesis for Verifying Large-Scale Programs",
      "authors": "Zhongyi Wang, Tengjie Lin, Mingshuai Chen, Haokun Li, Mingqi Yang, Xiao Yi, Shengchao Qin, Yixing Luo, Xiaofeng Li, Bin Gu, Liqiang Lu, Jianwei Yin",
      "institution": "Zhejiang University, Peking University, The Chinese University of Hong Kong, Xidian University, Beijing Institute of Control Engineering",
      "link": "https://arxiv.org/pdf/2512.24594",
      "code": null,
      "tags": [
        "formal verification",
        "specification synthesis",
        "deductive verification",
        "static analysis",
        "runtime error",
        "large language models"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59ea3656fd77af57b3d01dd85b22b70b81b2bc6a890ef83bd4e98afe3dad61df_w640_q70.webp",
      "contributions": "1. A modular framework (Preguss) that synergizes static analysis and deductive verification for specification generation. 2. A potential runtime error-guided method to construct and prioritize verification units, enabling divide-and-conquer verification. 3. An LLM-aided approach for synthesizing interprocedural specifications at the unit level, overcoming long-context reasoning limitations.",
      "summary": "This paper presents Preguss, a framework that combines static analysis and LLMs to automate the generation of formal specifications for verifying large-scale programs. It uses potential runtime errors to guide the creation of verification units and then synthesizes specifications for each unit, significantly reducing human effort. The method enables highly automated verification for programs over 1000 lines of code, reducing human verification effort by 80.6% to 88.9%.",
      "mindmap": "graph TB\n        Root[”A Tale of 1001 LoC: Potential Runtime Error-Guided Specification Synthesis for Verifying Large-Scale Programs”]\n        Root --> Problem[”核心问题/Problem<br>LLMs struggle with automated verification of large-scale programs due to long-context reasoning and complex specification inference.”]\n        Root --> Method[”主要方法/Method<br>Preguss framework synergizes static analysis and deductive verification via error-guided unit construction and LLM-aided specification synthesis.”]\n        Root --> Results[”关键结果/Results<br>Enables verification of 1000+ LoC programs with 80.6%~88.9% reduction in human effort, outperforming SOTA.”]"
    },
    {
      "title": "LeanCat: A Benchmark Suite for Formal Category Theory in Lean (Part I: 1-Categories)",
      "authors": "Rongge Xu, Hui Dai, Yiming Fu, Jiedong Jiang, Tianjiao Nie, Hongwei Wang, Junkai Wang, Holiverse Yang, Jiatong Yang, Zhi-Hao Zhang",
      "institution": "Tsinghua University, Southern University of Science and Technology, Westlake University, Xi'an Jiaotong-Liverpool University, The Chinese University of Hong Kong, Yanqi Lake Beijing Institute of Mathematical Sciences and Applications (BIMSA)",
      "link": "https://arxiv.org/pdf/2512.24796",
      "code": "https://github.com/sciencraft/LeanCat",
      "tags": [
        "theorem proving",
        "formal verification",
        "category theory",
        "benchmark",
        "Lean",
        "large language models"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4bb17bb33fa46697baca7f3b3a6262916453dd0a4bf5f92ff26cebdd7d681ffe_w640_q70.webp",
      "contributions": "1. Introduces LeanCat, a benchmark for formal category theory in Lean, designed to stress-test abstraction and library-mediated reasoning. 2. Presents a curated dataset of 100 tasks with topic families and difficulty tiers, created via an LLM-assisted human grading process. 3. Demonstrates the benchmark's utility by evaluating models and the LeanBridge method, showing current AI capabilities and providing a checkpoint for tracking progress.",
      "summary": "The paper introduces LeanCat, a benchmark for formalizing category theory in Lean to better evaluate AI's ability for abstract, library-based reasoning in mathematics. It presents a curated set of 100 tasks and evaluates models, finding low success rates, especially on harder problems, while showing that retrieval-augmented methods like LeanBridge can improve performance. The benchmark serves as a compact checkpoint for tracking progress in research-level formal theorem proving.",
      "mindmap": "graph TB\n        A[LeanCat: A Benchmark Suite for Formal Category Theory in Lean] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>现有基准未能充分衡量抽象和基于库的推理/Current benchmarks under-measure abstraction and library-mediated reasoning]\n        C[主要方法/Method<br>为Lean创建形式化范畴论基准，包含100个分级任务/Create a Lean benchmark for formal category theory with 100 graded tasks]\n        D[关键结果/Results<br>最佳模型pass@1为8.25%，检索增强方法有提升/Best model pass@1 is 8.25%, retrieval-augmented methods show gains]"
    },
    {
      "title": "A Modal Logic for Possibilistic Reasoning with Fuzzy Formal Contexts",
      "authors": "Prosenjit Howlader, Churn-Jung Liau",
      "institution": "Institute of Information Science, Academia Sinica",
      "link": "https://arxiv.org/pdf/2512.24980",
      "code": null,
      "tags": [
        "modal logic",
        "weighted modal logic",
        "possibilistic reasoning",
        "formal concept analysis",
        "fuzzy formal contexts",
        "rough set theory"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0eedb37864559f4df3443ff6f46099ca8b0528be3387a300ecd0f5068e2a25f9_w640_q70.webp",
      "contributions": "1. Introduces a novel two-sort weighted modal logic with necessity and sufficiency operators for possibilistic reasoning in fuzzy formal contexts. 2. Provides a sound and complete axiomatization for the logic and its fragments with respect to fuzzy context models. 3. Shows the logic can represent generalized formal, object-oriented, and property-oriented concepts in fuzzy FCA and can be extended to multi-relational contexts.",
      "summary": "This paper introduces a new two-sort weighted modal logic designed for possibilistic reasoning with fuzzy formal contexts, featuring necessity and sufficiency operators. It provides a sound and complete axiomatization for this logic and demonstrates its expressive power by showing it can represent key generalized concepts from Formal Concept Analysis (FCA) in the fuzzy setting. The work also indicates the logic's potential for extension to reasoning with multi-relational fuzzy contexts.",
      "mindmap": "graph TB\n        Root[论文标题: A Modal Logic for Possibilistic Reasoning with Fuzzy Formal Contexts] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Reasoning with uncertainty in fuzzy formal contexts] --> P1[模糊形式背景中的可能性推理/Possibilistic reasoning in fuzzy formal contexts]\n        Method[主要方法/Method: A two-sort weighted modal logic] --> M1[引入两种加权模态算子/Introduces two weighted modal operators]\n        M1 --> M1a[必要性算子/Necessity (□)]\n        M1 --> M1b[充分性算子/Sufficiency (⊟)]\n        Results[关键结果/Results] --> R1[逻辑是可靠且完备的/Logic is sound and complete]\n        Results --> R2[可表示FCA中的广义概念/Can represent generalized FCA concepts]\n        Results --> R3[可扩展至多关系模糊背景/Extensible to multi-relational contexts]"
    },
    {
      "title": "Logic Sketch Prompting (LSP): A Deterministic and Interpretable Prompting Method",
      "authors": "Satvik Tripathi",
      "institution": "University of Pennsylvania",
      "link": "https://arxiv.org/pdf/2512.22258",
      "code": "https://github.com/satviktri/LSP",
      "tags": [
        "prompt engineering",
        "Logic Sketch Prompting",
        "deterministic prompting",
        "interpretability",
        "rule adherence",
        "clinical decision support"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3b5d49d54027e4f7e6b110a48568a0255a45010197e26e8bc344e0cd3e1785a9_w640_q70.webp",
      "contributions": "1. Proposes Logic Sketch Prompting (LSP), a lightweight prompting framework that introduces typed variables and deterministic condition evaluators for structured reasoning., 2. Incorporates a rule-based validator to produce traceable and repeatable outputs, enhancing auditability., 3. Demonstrates significant performance gains over standard prompting methods (zero-shot, chain-of-thought, concise) on pharmacologic logic-compliance tasks across multiple open-weight LLMs.",
      "summary": "The paper addresses the unreliability of LLMs on tasks requiring strict rule adherence and determinism. It proposes Logic Sketch Prompting (LSP), a framework using typed variables and rule-based validation to produce traceable outputs. Evaluations on clinical tasks show LSP significantly outperforms standard prompting methods in accuracy and F1 score, making it suitable for safety-critical systems.",
      "mindmap": "graph TB\n        A[Logic Sketch Prompting (LSP)] --> B[核心问题/Problem: LLMs unreliable on tasks needing strict rules & determinism]\n        A --> C[主要方法/Method: Lightweight framework with typed variables, condition evaluators, rule validator]\n        A --> D[关键结果/Results: Highest accuracy/F1 vs. baselines; suitable for clinical/safety-critical systems]"
    },
    {
      "title": "ReVEAL: GNN-Guided Reverse Engineering for Formal Verification of Optimized Multipliers",
      "authors": "Chen Chen, Daniela Kaufmann, Chenhui Deng, Zhan Song, Hongce Zhang, Cunxi Yu",
      "institution": "University of Maryland, College Park; TU Wien; NVIDIA; Hong Kong University of Science and Technology (Guangzhou)",
      "link": "https://arxiv.org/pdf/2512.22260",
      "code": null,
      "tags": [
        "formal verification",
        "computer algebra",
        "reverse engineering",
        "graph neural network",
        "multiplier verification",
        "algebraic circuit verification",
        "SAT-based equivalence checking"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bdd1907cef6efb0b9b81d88b611f825942f30ef8a8674a9587cc4261e4774ef_w640_q70.webp",
      "contributions": "1. Proposes ReVEAL, a graph-learning-based framework for reverse engineering optimized multiplier architectures to recover their word-level structure. 2. Leverages structural graph features and learning-driven inference to identify architectural patterns at scale, enabling robust handling of large, optimized circuits. 3. Integrates smoothly with existing verification flows and supports downstream algebraic proof strategies, showing improvements in scalability and accuracy over traditional rule-based approaches.",
      "summary": "This paper introduces ReVEAL, a method that uses Graph Neural Networks (GNNs) to reverse engineer the architecture of optimized hardware multipliers. This recovered structure enables more effective formal verification using algebraic techniques. The approach demonstrates improved scalability and accuracy compared to traditional rule-based methods on diverse benchmarks.",
      "mindmap": "graph TB\n        A[ReVEAL: GNN-Guided Reverse Engineering for Formal Verification of Optimized Multipliers] --> B(核心问题/Problem: 优化乘法器形式验证困难/Challenges in formal verification of optimized multipliers)\n        A --> C(主要方法/Method: 基于图学习的逆向工程/GNN-guided reverse engineering)\n        A --> D(关键结果/Results: 提升可扩展性与准确性/Improved scalability and accuracy)"
    },
    {
      "title": "Symbolic Specification and Reasoning for Quantum Data and Operations",
      "authors": "Mingsheng Ying",
      "institution": "University of Technology Sydney",
      "link": "https://arxiv.org/pdf/2512.22383",
      "code": null,
      "tags": [
        "quantum programming languages & verification",
        "symbolic logic",
        "formal verification",
        "quantum computation",
        "automated reasoning",
        "SOL"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d170e9ed692953b589cb0ca609b55da71b661300061784405cc0fe9e73f4c680_w640_q70.webp",
      "contributions": "1. Proposes a novel logical framework called Symbolic Operator Logic (SOL) for symbolic specification of quantum data and operations., 2. Embeds classical first-order logic into SOL to enable reasoning about quantum properties modulo theories of classical data, leveraging existing classical verification tools., 3. Provides a conceptual foundation for formal verification and automated theorem proving of quantum computation in proof assistants like Lean and Coq.",
      "summary": "This paper addresses the lack of a formal theory for symbolic reasoning in quantum computing by introducing a general logical framework called Symbolic Operator Logic (SOL). The core method embeds classical first-order logic into a language of formal operators for quantum specifications, enabling automated reasoning by reusing classical verification tools. The authors conclude that SOL provides a foundational framework for the formal verification of quantum algorithms and programs.",
      "mindmap": "graph TB\n        Root[”Symbolic Specification and Reasoning for Quantum Data and Operations”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>缺乏量子数据与操作的形式化符号推理理论”] --> P1[”导致结果/Consequence<br>限制量子程序自动验证的实用性”]\n        Method[”主要方法/Method<br>提出符号算子逻辑(SOL)框架”] --> M1[”关键技术/Key Technique<br>将经典一阶逻辑嵌入形式算子语言”]\n        Method --> M2[”优势/Advantage<br>基于经典数据理论(如布尔代数)进行推理”]\n        Results[”关键结果/Results<br>为量子计算形式验证提供概念基础”] --> R1[”应用前景/Application<br>用于Lean, Coq等证明助手”]"
    },
    {
      "title": "A Representation of Explicit Knowledge and Epistemic Indistinguishability in a Logic of Awareness",
      "authors": "Yudai Kubono, Satoshi Tojo",
      "institution": "Shizuoka University, Asia University",
      "link": "https://arxiv.org/pdf/2512.22477",
      "code": null,
      "tags": [
        "epistemic logic",
        "awareness logic",
        "explicit knowledge",
        "logical omniscience",
        "modal logic",
        "completeness"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee03db160587ff877ac6134a739d58ab248a7f54166c46721902cd24c89d04bf_w640_q70.webp",
      "contributions": "1. Proposes a refined definition of explicit knowledge in awareness logic that addresses undesirable derivations from Modus Ponens in implicit knowledge, 2. Introduces a new formal logic called Awareness-Based Indistinguishability Logic (AIL) with enhanced expressive power over the Fagin-Halpern logic, 3. Provides a sound and complete axiomatic system for AIL.",
      "summary": "This paper addresses a flaw in the classic logic of awareness by Fagin and Halpern, where their definition of explicit knowledge can lead to undesirable conclusions. The authors propose a new logic called Awareness-Based Indistinguishability Logic (AIL), which refines the definition by linking indistinguishability of possible worlds to awareness. They prove AIL is more expressive than the prior logic and provide a sound and complete axiomatic system for it.",
      "mindmap": "graph TB\n        A[”A Representation of Explicit Knowledge and Epistemic Indistinguishability in a Logic of Awareness<br>论文标题”] --> B[”核心问题/Problem<br>Fagin-Halpern逻辑中显式知识的定义可能导致不良推论”]\n        A --> C[”主要方法/Method<br>提出基于意识的不可区分性逻辑(AIL)，精确定义显式知识”]\n        A --> D[”关键结果/Results<br>AIL更具表达力，可嵌入原逻辑，并具备可靠且完备的公理系统”]"
    },
    {
      "title": "Many-valued coalgebraic dynamic logics: Safety and strong completeness via reducibility",
      "authors": "Helle Hvid Hansen, Wolfgang Poiger",
      "institution": "University of Groningen, Institute of Computer Science of the Czech Academy of Sciences",
      "link": "https://arxiv.org/pdf/2512.22851",
      "code": null,
      "tags": [
        "formal methods",
        "coalgebraic modal logic",
        "many-valued logic",
        "dynamic logic",
        "bisimulation safety",
        "strong completeness"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3befe5f4bde38d3dda7c5a9f23902f5621b1316b62c6e3e2b1f3e208c172be1e_w640_q70.webp",
      "contributions": "1. Proposes a coalgebraic framework for generalizing dynamic modal logics (like PDL and game logic) to many-valued settings where both propositions and semantic structures can take truth-degrees from an FLew-algebra. 2. Introduces the concept of reducible coalgebra operations and tests, proving that such operations are safe for bisimulation and behavioural equivalence. 3. Proves a general strong completeness theorem for the framework, leading to new strong completeness results for specific logics like 2-valued iteration-free PDL with many-valued accessibility relations and many-valued iteration-free game logic.",
      "summary": "This paper presents a coalgebraic framework for generalizing dynamic modal logics to many-valued settings. It focuses on operations that are reducible, meaning modalities for composed actions can be reduced to compositions of simpler modalities, and proves these operations are safe for bisimulation and lead to strong completeness. The results yield new completeness theorems for specific many-valued versions of PDL and game logic.",
      "mindmap": "graph TB\n        A[Many-valued Coalgebraic Dynamic Logics] --> B[核心问题/Problem: Generalizing dynamic logics (PDL, game logic) to many-valued settings]\n        A --> C[主要方法/Method: Coalgebraic framework with A-valued predicate liftings and reducible operations]\n        A --> D[关键结果/Results: Reducible operations are safe for bisimulation; general strong completeness theorem proven]"
    },
    {
      "title": "PSPACE-Completeness of the Equational Theory of Relational Kleene Algebra with Graph Loop",
      "authors": "Yoshiki Nakamura",
      "institution": "Institute of Science Tokyo",
      "link": "https://arxiv.org/pdf/2512.22930",
      "code": null,
      "tags": [
        "Formal Languages and Automata Theory",
        "Kleene algebra",
        "graph loop",
        "PSpace-completeness",
        "loop-automata",
        "equational theory"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/143a4383124a50a9271d22d401dedf3a296d859fe9ccfaf34be96747d60ca607_w640_q70.webp",
      "contributions": "1. Proved that the equational theory of relational Kleene algebra with the graph loop operator is PSpace-complete. 2. Introduced a novel automaton model called loop-automata to facilitate the complexity analysis. 3. Established a polynomial-time reduction from the equational theories to the language inclusion problem for 2-way alternating string automata.",
      "summary": "This paper investigates the computational complexity of the equational theory for relational Kleene algebra extended with a graph loop operator. The authors introduce a new automaton model called loop-automata and use it to provide a polynomial-time reduction to a known automata problem. The main result is proving that this equational theory is PSpace-complete, a complexity that persists even with several other extensions.",
      "mindmap": "graph TB\n        Root[PSPACE-Completeness of the Equational Theory of Relational Kleene Algebra with Graph Loop] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Which extensions of Relational Kleene Algebra (RKA) keep PSpace-complete equational theory?]\n        Method[主要方法/Method: Introduce loop-automata; Reduce to 2-way alternating automata inclusion problem]\n        Results[关键结果/Results: Equational theory of loop-RKA is PSpace-complete; Result holds with top, tests, converse, nominals]"
    },
    {
      "title": "Hypergraph Semantics for Doxastic Logics",
      "authors": "Hans van Ditmarsch, Djanira Gomes, David Lehnherr, Valentin Müller, Thomas Studer",
      "institution": "CNRS, IRIT, University of Toulouse, University of Bern",
      "link": "https://arxiv.org/pdf/2512.23088",
      "code": null,
      "tags": [
        "modal logic",
        "directed hypergraphs",
        "doxastic logic",
        "simplicial models",
        "canonical models",
        "Kripke models"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9148e7fe21d36571fcaa8501e6f6f8e914b61b99c9fad3c304b84d0731e14147_w640_q70.webp",
      "contributions": "1. Introduces a new semantics for logics of belief based on directed hypergraphs, extending beyond the knowledge-only representation of simplicial models. 2. Provides complete axiomatizations for systems of both consistent belief and merely introspective belief, proven via the construction of canonical hypergraph models. 3. Presents direct conversion methods between traditional doxastic Kripke models and the new directed hypergraph models.",
      "summary": "This paper addresses the limitation of simplicial models, which can represent knowledge but not beliefs in distributed systems. It proposes a new semantics for belief logics using directed hypergraphs, which retain the structural benefits of simplicial models while accommodating agent beliefs. The work establishes complete axiomatizations for belief systems and shows how the new models relate to standard Kripke models.",
      "mindmap": "graph TB\n        Root(”Hypergraph Semantics for Doxastic Logics<br/>超图语义用于信念逻辑”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”Simplicial models cannot represent beliefs<br/>单纯复形模型无法表示信念”)\n        Method --> M1(”New semantics using directed hypergraphs<br/>使用有向超图的新语义”)\n        Results --> R1(”Complete axiomatizations for belief systems<br/>信念系统的完备公理化”)\n        Results --> R2(”Conversions to/from Kripke models<br/>与克里普克模型的相互转换”)"
    },
    {
      "title": "On Conformant Planning and Model-Checking of $^*^*$ Hyperproperties",
      "authors": "Raven Beutner, Bernd Finkbeiner",
      "institution": "CISPA Helmholtz Center for Information Security",
      "link": "https://arxiv.org/pdf/2512.23324",
      "code": null,
      "tags": [
        "formal methods",
        "conformant planning",
        "hyperproperties",
        "model-checking",
        "HyperLTL",
        "∃∗∀∗"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/47343ca7bc4bf16389257261dd21e0c1fa42c0f512178576ff4ba501df841e8b_w640_q70.webp",
      "contributions": "1. Establishes a formal connection between conformant planning and model-checking of ∃∗∀∗ hyperproperties, showing they share the same computational core. 2. Provides an efficient, sound, and complete reduction from a hyperproperty model-checking instance to a conformant planning instance. 3. Demonstrates that every conformant planning problem is itself a hyperproperty model-checking task, establishing the converse direction.",
      "summary": "This paper identifies and formalizes a deep connection between two seemingly unrelated problems: conformant planning (finding a robust sequential plan under uncertainty) and model-checking of ∃∗∀∗ hyperproperties (verifying system properties that relate multiple execution traces). The authors provide efficient, sound, and complete translations between instances of these two problems, showing they are essentially two sides of the same computational coin. This foundational link aims to enable cross-pollination of solution techniques between the planning and verification communities.",
      "mindmap": "graph TB\n        A[On Conformant Planning and Model-Checking of ∃∗∀∗ Hyperproperties] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[连接两个看似无关的问题 / Linking two seemingly unrelated problems]\n        B1 --> B2[Conformant Planning / 一致性规划]\n        B1 --> B3[Hyperproperty Model-Checking / 超属性模型检测]\n        C --> C1[构建双向高效规约 / Constructing bidirectional efficient reductions]\n        D --> D1[证明规约的可靠性与完备性 / Proving reductions are sound and complete]\n        D --> D2[确立问题的等价性 / Establishing the equivalence of the problems]"
    },
    {
      "title": "Checking Satisfiability of Hyperproperties using First-Order Logic",
      "authors": "Raven Beutner, Bernd Finkbeiner",
      "institution": "CISPA Helmholtz Center for Information Security",
      "link": "https://arxiv.org/pdf/2512.23332",
      "code": null,
      "tags": [
        "formal verification",
        "hyperproperties",
        "HyperLTL",
        "satisfiability checking",
        "first-order logic",
        "FOLHyper"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1df9c7eeb320b67a7ee7c2bfb2c3c7df8d5c7c6cfd6201d5246d2ea403911999_w640_q70.webp",
      "contributions": "1. Introduces FOLHyper, a tool for automatically checking the satisfiability of hyperproperties specified in HyperLTL. 2. Reduces the HyperLTL satisfiability problem to an equisatisfiable first-order logic formula, enabling the use of standard FOL solvers. 3. Extends applicability beyond the decidable ∃*∀* fragment of HyperLTL and is shown to be particularly effective at proving unsatisfiability, complementing existing bounded methods.",
      "summary": "This paper addresses the problem of checking the satisfiability of hyperproperties, which are crucial for security and information-flow specifications. It proposes FOLHyper, a tool that translates HyperLTL formulas into equisatisfiable first-order logic formulas, allowing the use of FOL solvers for analysis. The method extends beyond known decidable fragments and is shown to be effective, especially for proving unsatisfiability.",
      "mindmap": "graph TB\n        A[Checking Satisfiability of Hyperproperties using First-Order Logic] --> B[核心问题/Problem: 超属性可满足性检查/Hyperproperty Satisfiability Checking]\n        A --> C[主要方法/Method: 将HyperLTL约简为一阶逻辑公式/Reduce HyperLTL to FOL]\n        A --> D[关键结果/Results: FOLHyper工具，有效证明不可满足性/FOLHyper Tool, Effective for Unsatisfiability]"
    },
    {
      "title": "Verifying Asynchronous Hyperproperties in Reactive Systems",
      "authors": "Raven Beutner, Bernd Finkbeiner",
      "institution": "CISPA Helmholtz Center for Information Security",
      "link": "https://arxiv.org/pdf/2512.23344",
      "code": null,
      "tags": [
        "formal verification",
        "asynchronous hyperproperties",
        "HyperLTL",
        "model checking",
        "game semantics",
        "observational determinism"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e321908ac7277c8c91e3b8e509efae3be66dbe7c391e613f19a6ca343db4f16_w640_q70.webp",
      "contributions": "1. Proposes a novel game-based approach for verifying arbitrary ∀∗∃∗ formulas in Asynchronous HyperLTL (A-HLTL) in reactive systems. 2. Interprets verification as a game between a verifier and refuter, where a winning strategy provides witnesses for traces and asynchronous alignments for stutterings. 3. Identifies fragments for which the game-based interpretation is complete, providing a finite-state decision procedure, and contributes a prototype implementation with encouraging experimental results.",
      "summary": "This paper addresses the challenge of model-checking asynchronous hyperproperties in reactive systems, which require comparing execution traces across different timesteps. It proposes a novel game-based verification method for a logic called Asynchronous HyperLTL (A-HLTL), interpreting the problem as a two-player game to find suitable trace stutterings. The approach provides a decision procedure for certain formula fragments and is supported by a prototype implementation.",
      "mindmap": "graph TB\n        Root[Verifying Asynchronous Hyperproperties in Reactive Systems] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[同步HyperLTL无法表达异步超属性/Synchronous HyperLTL cannot express asynchronous hyperproperties]\n        Problem --> P2[现有方法限制于受限片段或终止系统/Existing methods limited to restricted fragments or terminating systems]\n        Method[主要方法/Method] --> M1[提出基于游戏的验证方法/Propose a game-based verification approach]\n        Method --> M2[验证者与反驳者的双人游戏/Two-player game between verifier and refuter]\n        Method --> M3[获胜策略对应存在量化的证据/Winning strategy corresponds to witnesses for existential quantification]\n        Results[关键结果/Results] --> R1[为∀∗∃∗ A-HLTL公式提供方法/Provides method for arbitrary ∀∗∃∗ A-HLTL formulas]\n        Results --> R2[识别完全性的片段/Identifies fragments for which the interpretation is complete]\n        Results --> R3[原型实现与实验结果/Prototype implementation and experimental results]"
    },
    {
      "title": "Modelling of logical systems by means of their fragments",
      "authors": "Mikhail Rybakov",
      "institution": "Moscow Institute of Physics and Technology (MIPT)",
      "link": "https://arxiv.org/pdf/2512.23509",
      "code": null,
      "tags": [
        "computational logic",
        "superintuitionistic logics",
        "modal logics",
        "complexity reduction",
        "Kripke incompleteness",
        "predicate calculi"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6250c5fb6676c8f8ac8f9a2e9bc581ee4e2c8b46c6236e4948549173497931aa_w640_q70.webp",
      "contributions": "1. Proved polynomial-time reducibility of propositional logics to their fragments with at most two variables. 2. Established reducibility of predicate logics to fragments with limited predicate letters and individual variables, with conditions and counterexamples. 3. Provided new complexity bounds, Kripke-incompleteness results, and analogues of Church and Trakhtenbrot theorems for quasiary predicate logic.",
      "summary": "This work investigates the algorithmic complexity of non-classical logics. It demonstrates that many propositional and predicate logics can be reduced to simpler, smaller fragments, establishing conditions for such reductions and providing counterexamples. The results include new complexity bounds and fundamental incompleteness theorems for these logical systems.",
      "mindmap": "graph TB\n        A[Modelling of logical systems by means of their fragments] --> B(核心问题/Problem: Algorithmic complexity of non-classical logics)\n        A --> C(主要方法/Method: Reduction to simpler fragments)\n        A --> D(关键结果/Results: Complexity bounds, reducibility conditions, incompleteness theorems)"
    },
    {
      "title": "A Note on the NP-Hardness of PARTITION Via First-Order Projections",
      "authors": "Paúl Risco Iturralde",
      "institution": "Independent researcher",
      "link": "https://arxiv.org/pdf/2512.21448",
      "code": null,
      "tags": [
        "computational complexity theory",
        "NP-hardness",
        "first-order reductions",
        "AC0 reductions",
        "PARTITION problem",
        "descriptive complexity"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b5d9f8d4b42755b482904c0cf03df329316dc9a10936a82fe27b6ce034a1e56_w640_q70.webp",
      "contributions": "1. Demonstrates NP-hardness of the PARTITION problem via first-order projections, 2. Overcomes the obstacle of requiring large sums in the standard reduction by using descriptive complexity techniques, 3. Fills a gap in the literature regarding the hardness of PARTITION under restricted reductions like AC0.",
      "summary": "This note addresses the open question of whether the PARTITION problem is NP-hard under restricted reductions like AC0. It modifies classic reductions from 3SAT to SUBSET-SUM to PARTITION, defining them using first-order logical formulas (first-order projections). The main conclusion is that PARTITION is indeed NP-hard via first-order projections, which implies hardness under polynomial-size AC0 reductions, thereby resolving the gap mentioned in prior work.",
      "mindmap": "graph TB\n        A[论文标题: A Note on the NP-Hardness of PARTITION Via First-Order Projections] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[PARTITION的NP-hardness在受限归约下是否成立?/Is PARTITION NP-hard under restricted reductions?]\n        C --> C1[使用一阶逻辑公式定义归约/Define reductions using first-order logic formulas]\n        C --> C2[修改经典归约(3SAT到SUBSET-SUM到PARTITION)/Modify classic reductions (3SAT to SUBSET-SUM to PARTITION)]\n        D --> D1[PARTITION对一阶投影是NP-hard的/PARTITION is NP-hard via first-order projections]\n        D --> D2[暗示对多项式大小AC0归约也是NP-hard的/Implies NP-hard under polynomial-size AC0 reductions]\n        D --> D3[填补了文献中的空白/Fills a gap in the literature]"
    },
    {
      "title": "Quantitative Verification of Omega-regular Properties in Probabilistic Programming",
      "authors": "Peixin Wang, Jianhao Bai, Min Zhang, C.-H. Luke Ong",
      "institution": "East China Normal University, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.21596",
      "code": null,
      "tags": [
        "probabilistic programming and verification",
        "temporal posterior inference",
        "omega-regular properties",
        "stochastic barrier certificates",
        "Rabin automata",
        "quantitative verification"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c111a01f9d5e96a85d9b5c62645dae0f5bb40053d723e34cb57dc7f31554dcda_w640_q70.webp",
      "contributions": "1. Introduces Temporal Posterior Inference (TPI), a new framework unifying probabilistic programming with temporal logic to compute posterior distributions over execution traces satisfying omega-regular properties. 2. Develops a novel method for computing rigorous upper and lower bounds on satisfaction probabilities by decomposing Rabin acceptance conditions and constructing sound stochastic barrier certificates. 3. Implements the approach in a prototype tool named TPInfer and demonstrates its effectiveness and efficiency on a suite of benchmarks.",
      "summary": "This paper addresses the limitation of standard probabilistic program inference, which fails to capture temporal behavior, by proposing Temporal Posterior Inference (TPI). TPI computes posterior distributions over program traces that satisfy omega-regular temporal specifications, using a method based on stochastic barrier certificates to provide quantitative verification bounds. The approach is implemented in the TPInfer tool and shown to be effective for inference over rich temporal properties.",
      "mindmap": "graph TB\n        Root(”Quantitative Verification of Omega-regular Properties in Probabilistic Programming”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”标准后验推断的局限/Limitation of Standard Posterior Inference”)\n        P1 --> P2(”无法捕捉程序执行的时间演化/Fails to capture temporal evolution”)\n        Method --> M1(”提出时间后验推断框架/Propose Temporal Posterior Inference (TPI)”)\n        M1 --> M2(”统一概率编程与时序逻辑/Unifies Probabilistic Programming & Temporal Logic”)\n        M2 --> M3(”基于随机屏障证书的定量验证方法/Quantitative Verification via Stochastic Barrier Certificates”)\n        Results --> R1(”实现原型工具 TPInfer/Implement Prototype Tool TPInfer”)\n        Results --> R2(”在基准测试中展示有效性与效率/Demonstrates Effectiveness & Efficiency on Benchmarks”)"
    },
    {
      "title": "First-Order Logic and Twin-Width for Some Geometric Graphs",
      "authors": "Colin Geniet, Gunwoo Kim, Lucas Meijer",
      "institution": "Institute for Basic Science (IBS), KAIST, Utrecht University",
      "link": "https://arxiv.org/pdf/2512.21896",
      "code": null,
      "tags": [
        "parameterized complexity",
        "twin-width",
        "first-order logic",
        "model checking",
        "geometric graphs",
        "FPT"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/813ec0f508efb48269593ee0f1c17c2ef7df235eda75353b1d1b0c5e93732fd3_w640_q70.webp",
      "contributions": "1. Proved that delineation (the equivalence between tractable FO model checking and bounded twin-width) holds for intersection graphs of non-degenerate axis-parallel unit segments. 2. Showed that delineation fails for visibility graphs of 1.5D terrains. 3. Proved delineation for intersection graphs of circular arcs.",
      "summary": "This paper investigates the relationship between tractable first-order (FO) logic model checking and the graph parameter twin-width for specific geometric graph classes. It answers open questions by proving this equivalence (delineation) holds for intersection graphs of axis-parallel unit segments and circular arcs, but fails for visibility graphs of 1.5D terrains. The work leverages the theory of twin-width for ordered graphs, exploiting natural vertex orderings in geometric representations.",
      "mindmap": "graph TB\n        A[First-Order Logic and Twin-Width for Some Geometric Graphs] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1(几何图类的FO模型检查复杂性/FO Model Checking Complexity for Geometric Graph Classes)\n        C --> C1(利用有序图的双宽理论/Using Twin-width Theory for Ordered Graphs)\n        D --> D1(证明轴平行单位线段图与圆弧图存在描绘/Prove Delineation for Axis-Parallel Unit Segment & Circular Arc Graphs)\n        D --> D2(证明1.5D地形可见性图不存在描绘/Prove Delineation Fails for 1.5D Terrain Visibility Graphs)"
    },
    {
      "title": "The Tensor-Plus Calculus",
      "authors": "Kostia Chardonnet, Marc de Visme, Benoît Valiron, Renaud Vilmart",
      "institution": "Université Paris-Saclay, Université de Lorraine, CentraleSupélec",
      "link": "https://arxiv.org/pdf/2512.21965",
      "code": null,
      "tags": [
        "categorical semantics",
        "graphical language",
        "PROP",
        "monoidal structure",
        "semiring",
        "semiadditive categories"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ff122e66fc78c3e6d82c25811f0de1bdfef20eb6e522efbf05297bfacf2592d_w640_q70.webp",
      "contributions": "1. A novel graphical language with implicit contextual distinction between multiplicative and additive monoidal structures, avoiding explicit annotations. 2. A universal categorical semantics for this language parameterized by a commutative semiring, applicable to non-deterministic, probabilistic, and quantum computation. 3. A sound and complete equational theory that captures semantic equivalence of diagrams.",
      "summary": "The paper proposes a new graphical calculus that implicitly combines multiplicative (pairing) and additive (branching) monoidal structures within a single, contextually-determined framework. It provides a universal categorical semantics for this language parameterized by a chosen commutative semiring, enabling the modeling of various computational paradigms. The work concludes by establishing a sound and complete equational theory for reasoning about diagram equivalence in this setting.",
      "mindmap": "graph TB\n        A[The Tensor-Plus Calculus] --> B[核心问题/Problem: How to unify multiplicative and additive structures in a graphical language?]\n        A --> C[主要方法/Method: Colored PROP with implicit, contextual structure; semantics parameterized by a commutative semiring.]\n        A --> D[关键结果/Results: Universal semantics; sound and complete equational theory for semiadditive categories.]"
    },
    {
      "title": "Random state comonads encode cellular automata evaluation",
      "authors": "Madalina I Sas, Julian H J Sutherland",
      "institution": "Imperial College London",
      "link": "https://arxiv.org/pdf/2512.22067",
      "code": null,
      "tags": [
        "formal methods & functional programming",
        "comonad",
        "cellular automata",
        "Haskell",
        "category theory",
        "stochastic"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4dfe9b8ed8e24df98b4c296aebfc6cfdffc4132d68260502b6f113e9e9d43939_w640_q70.webp",
      "contributions": "1. Introduces an accessible, practical category-theoretical model of Cellular Automata (CA) computation implemented in Haskell. 2. Proposes a novel instantiation of arrays as comonads with state and random generators, enabling the modeling of stochastic CA behavior. 3. Demonstrates the model's generality through case studies of classic 1D and 2D CAs and suggests extensions to N dimensions and arbitrary topologies.",
      "summary": "This paper addresses the gap between abstract formalizations and practical implementations of Cellular Automata (CA). It proposes a functional programming model in Haskell using random state comonads to encode CA evaluation, which supports stochastic behavior and provides a direct mapping between simulation, rules, and categorical theory. The work demonstrates the approach with several classic CA models and suggests it can be generalized to arbitrary topologies.",
      "mindmap": "graph TB\n        Root[”Random state comonads encode cellular automata evaluation”] --> Problem[”核心问题/Problem: Gap between abstract CA theory and practical, feature-rich implementations”]\n        Root --> Method[”主要方法/Method: Haskell implementation using random state comonads”]\n        Root --> Results[”关键结果/Results: Accessible model supporting stochastic CA, demonstrated on classic models, extensible to N-D”]"
    },
    {
      "title": "Eidoku: A Neuro-Symbolic Verification Gate for LLM Reasoning via Structural Constraint Satisfaction",
      "authors": "Shinobu Miya",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.20664",
      "code": "https://github.com/ShinobuMiya/Eidoku",
      "tags": [
        "reasoning verification",
        "structural constraint satisfaction",
        "neuro-symbolic verification",
        "hallucination detection",
        "constraint satisfaction problem",
        "system-2 gate"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62978c31bb485ddbb117f5081c33f608c011c35aca015e4df8eaad0dd42439ff_w640_q70.webp",
      "contributions": "1. Reformulates LLM reasoning verification as a Constraint Satisfaction Problem (CSP) independent of generation likelihood, focusing on structural feasibility instead of statistical plausibility. 2. Introduces a lightweight System-2 gate, Eidoku, that uses a context-calibrated cost threshold derived from intrinsic statistics to reject candidates based on structural violation cost. 3. Demonstrates the ability to deterministically reject \"smooth falsehoods\"—high-probability but structurally inconsistent statements—which probability-based verifiers cannot detect.",
      "summary": "The paper addresses LLM hallucinations by proposing Eidoku, a neuro-symbolic verification gate that treats reasoning verification as a structural constraint satisfaction problem, independent of generation likelihood. It uses a cost function based on graph connectivity, feature consistency, and logical entailment to reject structurally inconsistent statements. Experiments show this approach can deterministically reject high-probability yet structurally disconnected hallucinations, serving as a sanity check for generative reasoning.",
      "mindmap": "graph LR\n    A[Eidoku: 神经符号验证门<br>Neuro-Symbolic Verification Gate] --> B[核心问题/Problem: LLM产生高概率幻觉<br>LLMs produce high-likelihood hallucinations]\n    A --> C[主要方法/Method: 基于结构约束满足的验证<br>Verification via Structural Constraint Satisfaction]\n    A --> D[关键结果/Results: 拒绝平滑错误，确定性检测<br>Rejects smooth falsehoods, deterministic detection]"
    },
    {
      "title": "Verification of E-Voting Algorithms in Dafny",
      "authors": "Robert Büttner, Fabian Franz Dießl, Patrick Janoschek, Ivana Kostadinovic, Henrik Oback, Kilian Voß, Franziska Alber, Roland Herrmann, Sibylle Möhle, Philipp Rümmer",
      "institution": "University of Regensburg",
      "link": "https://arxiv.org/pdf/2512.21084",
      "code": null,
      "tags": [
        "formal verification",
        "Dafny",
        "electronic voting",
        "formal verification",
        "code extraction",
        "web service"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7066c8f96806bffcb3140ddc041c9ea8c5b1b62ecba3c75264676fa14b77aaf2_w640_q70.webp",
      "contributions": "1. Developed an open-source library of formally verified e-voting algorithms (Score Voting, Instant-Runoff Voting, Borda Count, Single Transferable Vote) in Dafny. 2. Formally verified the implementations' consistency with functional specifications and key correctness properties. 3. Demonstrated practical utility by extracting executable code from the verified Dafny methods to set up a voting web service.",
      "summary": "This paper addresses the need for verified implementations of electronic voting algorithms to ensure correctness and trust. The authors developed a library of four e-voting procedures in Dafny, formally verifying their consistency with specifications and key properties. They concluded by extracting executable code to create a functional voting web service, demonstrating the practical application of their formally verified library.",
      "mindmap": "graph LR\n    A[Verification of E-Voting Algorithms in Dafny] --> B[核心问题/Problem: Need for verified e-voting implementations]\n    A --> C[主要方法/Method: Formal verification in Dafny & code extraction]\n    A --> D[关键结果/Results: Verified library & functional web service]"
    },
    {
      "title": "Declarative distributed broadcast using three-valued modal logic and semitopologies",
      "authors": "Murdoch J. Gabbay",
      "institution": "Heriot-Watt University (inferred from author's affiliation)",
      "link": "https://arxiv.org/pdf/2512.21137",
      "code": null,
      "tags": [
        "distributed algorithms",
        "modal logic",
        "declarative specification",
        "semitopologies",
        "three-valued logic",
        "axiomatic theories"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13c32160b520274be9e08e195b14474c8b52625ca44889f1659468dad3c6d782_w640_q70.webp",
      "contributions": "1. Proposes a novel method to formally specify distributed algorithms as declarative axiomatic theories using modal logic, 2. Demonstrates the method's application and scalability on concrete protocols (voting, broadcast, agreement), 3. Shows the method's practical utility by finding errors in a proposed industrial protocol.",
      "summary": "This paper proposes a novel declarative approach for specifying distributed algorithms using three-valued modal logic and semitopologies. It demonstrates the method on protocols like Bracha Broadcast, providing a compact, human-readable specification that abstracts away low-level implementation details. The approach enables precise reasoning about correctness and has been used to find errors in industrial protocols.",
      "mindmap": "graph LR\n    A[Declarative distributed broadcast using three-valued modal logic and semitopologies] --> B[核心问题/Problem: 如何对分布式算法进行形式化、声明式规范？/How to formally specify distributed algorithms declaratively?]\n    A --> C[主要方法/Method: 使用三值模态逻辑和半拓扑作为公理化理论/Using three-valued modal logic and semitopologies as axiomatic theories]\n    A --> D[关键结果/Results: 创建了精确、紧凑的规范，可发现协议错误，支持验证/Creates precise, compact specifications that can find protocol errors and support verification]"
    },
    {
      "title": "When Natural Strategies Meet Fuzziness and Resource-Bounded Actions (Extended Version)",
      "authors": "Marco Aruta, Francesco Improta, Vadim Malvone, Aniello Murano",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20457",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/664463f9c309b65554e570fddf642935c026241a76429b252415a066c09c87df_w640_q70.webp",
      "contributions": "",
      "summary": "When Natural Strategies Meet Fuzziness and Resource-Bounded Actions (Extended Version)",
      "mindmap": ""
    },
    {
      "title": "The Design of an Interactive Proof Mode for Dafny",
      "authors": "Ştefan Ciobâcă, K. Rustan M. Leino, Ştefan-Alexandru Mercaş, Roxana-Mihaela Timon",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20486",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42d264c9576e381a24860f8b5db2df73cfe5b91eced7676d3179fc3df5b16918_w640_q70.webp",
      "contributions": "",
      "summary": "The Design of an Interactive Proof Mode for Dafny",
      "mindmap": ""
    },
    {
      "title": "The Limitations and Power of NP-Oracle-Based Functional Synthesis Techniques",
      "authors": "Brendan Juba, Kuldeep S. Meel",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20572",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de2df87019d1cbedfd51c5a870dde93a8eab1b9f2a4b9338c0ae76a746726ef0_w640_q70.webp",
      "contributions": "",
      "summary": "The Limitations and Power of NP-Oracle-Based Functional Synthesis Techniques",
      "mindmap": ""
    },
    {
      "title": "All-optical 3-input OR and 2-input AND/NIMPLY logic gates in a linear planar three-core optical fiber coupler",
      "authors": "J. P. T. Rodrigues, F. L. B. Martins, J. C. do Nascimento",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20024",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e69bcaffc19b92afdeb152f94f2bb508492478a1ec6fc8f0fe362f7d63605033_w640_q70.webp",
      "contributions": "",
      "summary": "All-optical 3-input OR and 2-input AND/NIMPLY logic gates in a linear planar three-core optical fiber coupler",
      "mindmap": ""
    },
    {
      "title": "MSC-180: A Benchmark for Automated Formal Theorem Proving from Mathematical Subject Classification",
      "authors": "Sirui Li, Wangyue Lu, Xiaorui Shi, Ke Weng, Haozhe Sun, Minghe Yu, Tiancheng Zhang, Ge Yu, Hengyu Liu, Lun Du",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18256",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fa370d48e50a94f7beaa30df78416e8de75e5bddd8996af2ad55d2751ed49c0_w640_q70.webp",
      "contributions": "",
      "summary": "MSC-180: A Benchmark for Automated Formal Theorem Proving from Mathematical Subject Classification",
      "mindmap": ""
    },
    {
      "title": "Neural Proofs for Sound Verification and Control of Complex Systems",
      "authors": "Alessandro Abate",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18389",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d4271cbf46eee03fa72db8edd09dea5b0753448d820460e4c09f1171c7bc8f8_w640_q70.webp",
      "contributions": "",
      "summary": "Neural Proofs for Sound Verification and Control of Complex Systems",
      "mindmap": ""
    },
    {
      "title": "A logic for default deontic reasoning",
      "authors": "Mario Piazza, Andrea Sabatini",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18824",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b683e7becc36058c91076084a94762db1382ac3b9b043a0e6e9133bc5c1c9e4_w640_q70.webp",
      "contributions": "",
      "summary": "A logic for default deontic reasoning",
      "mindmap": ""
    },
    {
      "title": "Modular Automatic Complexity Analysis of Recursive Integer Programs",
      "authors": "Nils Lommen, Jürgen Giesl",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18851",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ffd25b1f065a669c9a5f596a2c53fa9476a120ae24f1952e860abffd9ab1ba2_w640_q70.webp",
      "contributions": "",
      "summary": "Modular Automatic Complexity Analysis of Recursive Integer Programs",
      "mindmap": ""
    },
    {
      "title": "A Logical View of GNN-Style Computation and the Role of Activation Functions",
      "authors": "Pablo Barceló, Floris Geerts, Matthias Lanzinger, Klara Pakhomenko, Jan Van den Bussche",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19332",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d6cc724cbd8fd52ec250ad8e7e8c8c76440bef31c5f1eae060dbb796cd6e916_w640_q70.webp",
      "contributions": "",
      "summary": "A Logical View of GNN-Style Computation and the Role of Activation Functions",
      "mindmap": ""
    },
    {
      "title": "Undecidability of theories of semirings with fixed points",
      "authors": "Anupam Das, Abhishek De, Stepan L. Kuznetsov",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19401",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27a0ccad42b5f6840b27fde7bc6213ef0905a97d614527327e1e96f21ebaacd9_w640_q70.webp",
      "contributions": "",
      "summary": "Undecidability of theories of semirings with fixed points",
      "mindmap": ""
    },
    {
      "title": "Navigating Taxonomic Expansions of Entity Sets Driven by Knowledge Bases",
      "authors": "Pietro Cofone, Giovanni Amendola, Marco Manna, Aldo Ricioppo",
      "institution": "University of Calabria, University of Cyprus",
      "link": "https://arxiv.org/pdf/2512.16953",
      "code": null,
      "tags": [
        "knowledge representation and reasoning",
        "entity set expansion",
        "expansion graph",
        "logical formula",
        "semantic inclusion",
        "computational complexity"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a logic-based framework using expansion graphs, which are rooted directed acyclic graphs, to support taxonomic expansions of entity sets from knowledge bases. To avoid the impracticality of fully materializing these potentially large graphs, the authors formalize efficient reasoning tasks to check relationships between entity tuples within the graph structure. Their main conclusion is that, under realistic assumptions like bounded input, these tasks can be implemented efficiently, enabling local and incremental navigation without full graph construction.",
      "mindmap": ""
    },
    {
      "title": "About Time: Model-free Reinforcement Learning with Timed Reward Machines",
      "authors": "Anirban Majumdar, Ritam Raha, Rajarshi Roy, David Parker, Marta Kwiatkowska",
      "institution": "Tata Institute of Fundamental Research, Max Planck Institute for Software Systems, University of Oxford",
      "link": "https://arxiv.org/pdf/2512.17637",
      "code": null,
      "tags": [
        "reinforcement learning",
        "timed reward machines",
        "tabular Q-learning",
        "timed automata",
        "counterfactual-imagining"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes timed reward machines (TRMs), an extension of reward machines that incorporates timing constraints into the reward specification for reinforcement learning. The authors develop model-free RL algorithms, specifically using tabular Q-learning integrated with abstractions of timed automata and counterfactual-imagining heuristics, to learn optimal policies. The experimental results show that their approach successfully learns policies that achieve high rewards while satisfying the specified timing constraints.",
      "mindmap": ""
    },
    {
      "title": "A Neurosymbolic Approach to Loop Invariant Generation via Weakest Precondition Reasoning",
      "authors": "Daragh King, Vasileios Koutavas, Laura Kovacs",
      "institution": "Trinity College Dublin, Lero, TU Wien",
      "link": "https://arxiv.org/pdf/2512.15816",
      "code": null,
      "tags": [
        "others",
        "Hoare logic",
        "weakest precondition reasoning",
        "neurosymbolic AI",
        "OpenJML",
        "counterexample-guided repair"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper presents NeuroInv, a neurosymbolic method for generating loop invariants that combines a neural module using LLMs and Hoare logic for backward-chaining weakest precondition reasoning with a symbolic module that iteratively repairs invariants using counterexamples from OpenJML. It achieves a 99.5% success rate on a benchmark of 150 Java programs and demonstrates scalability on complex multi-loop programs, substantially outperforming other approaches.",
      "mindmap": ""
    },
    {
      "title": "Dual Computational Horizons: Incompleteness and Unpredictability in Intelligent Systems",
      "authors": "Abhisek Ganguly",
      "institution": "Jawaharlal Nehru Centre for Advanced Scientific Research",
      "link": "https://arxiv.org/pdf/2512.16707",
      "code": null,
      "tags": [
        "computational theory",
        "Gödel incompleteness",
        "Lyapunov exponent",
        "prediction horizon",
        "algorithmic intelligence"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper formalizes two computational limitations—formal incompleteness from logic and dynamical unpredictability from chaos theory—to analyze algorithmic intelligence. It demonstrates that these constraints jointly bound an agent's ability to reason about its own predictive capabilities, concluding that an algorithmic agent generally cannot compute its own maximal prediction horizon.",
      "mindmap": ""
    },
    {
      "title": "Towards Mass Spectrum Analysis with ASP",
      "authors": "Nils Küchenmeister, Alex Ivliev, Markus Krötzsch",
      "institution": "TU Dresden",
      "link": "https://arxiv.org/pdf/2512.16780",
      "code": null,
      "tags": [
        "combinatorial search",
        "Answer Set Programming (ASP)",
        "symmetry-breaking",
        "canonical representations",
        "molecular structure",
        "mass spectrometry"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a novel application of Answer Set Programming (ASP) to determine molecular structures from mass spectrometry data by encoding chemical knowledge and using canonical representations to break symmetries and constrain the combinatorial search space. The authors evaluate their method on known structures and compare its performance to other ASP symmetry-breaking techniques and a commercial chemistry tool. The approach effectively reduces redundant solutions and demonstrates the utility of ASP for this chemical analysis problem.",
      "mindmap": ""
    },
    {
      "title": "TOGGLE: Temporal Logic-Guided Large Language Model Compression for Edge",
      "authors": "Khurram Khalil, Khaza Anuarul Hoque",
      "institution": "University of Missouri-Columbia",
      "link": "https://arxiv.org/pdf/2512.16855",
      "code": null,
      "tags": [
        "llm inference",
        "model compression",
        "quantization",
        "pruning",
        "signal temporal logic",
        "bayesian optimization"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces TOGGLE, a framework that uses Signal Temporal Logic (STL) and Bayesian optimization to guide the layer-wise compression of Large Language Models through quantization and pruning. It formally enforces linguistic properties during compression without requiring retraining. The method achieves significant reductions in model size and computational cost while preserving specified model behaviors, enabling verifiable deployment on edge devices.",
      "mindmap": ""
    }
  ]
}