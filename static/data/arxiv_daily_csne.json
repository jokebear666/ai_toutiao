{
  "label": "cs.NE",
  "slug": "csne",
  "week": "20260105-20260111",
  "items": [
    {
      "title": "Personalized Spiking Neural Networks with Ferroelectric Synapses for EEG Signal Processing",
      "authors": "Nikhil Garg, Anxiong Song, Niklas Plessnig, Nathan Savoia, Laura Bégon-Lours",
      "institution": "ETH Zurich (Integrated Systems Laboratory, Department of Information Technology and Electrical Engineering)",
      "link": "https://arxiv.org/pdf/2601.00020",
      "code": null,
      "tags": [
        "on-device ai",
        "ferroelectric synapses",
        "spiking neural networks",
        "EEG signal processing",
        "adaptive learning",
        "neuromorphic computing"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce95488f8704205e4a01e64825c78c800662f36da33df71b138881b21ab7b9bb_w640_q70.webp",
      "contributions": "1. Demonstrated the deployment and adaptation of Spiking Neural Networks (SNNs) on fabricated ferroelectric memristive synaptic devices for EEG-based motor imagery decoding under realistic device constraints. 2. Introduced a device-aware weight-update strategy that accumulates gradient updates digitally and triggers discrete programming events only when a threshold is exceeded, reducing programming frequency and emulating device dynamics. 3. Evaluated two complementary deployment strategies (device-aware training and transfer learning with on-device re-tuning) that achieve performance comparable to software-based SNNs and show improved accuracy through subject-specific adaptation.",
      "summary": "This paper addresses the challenge of adapting EEG-based brain-computer interfaces to non-stationary neural signals on resource-constrained hardware. It proposes deploying Spiking Neural Networks on ferroelectric memristive synapses with a novel device-aware update strategy and demonstrates two effective deployment methods for personalized, low-overhead adaptation. The results show that programmable ferroelectric hardware can support robust, efficient adaptation for personalized neuromorphic processing.",
      "mindmap": "graph TB\n        A[Personalized Spiking Neural Networks with Ferroelectric Synapses for EEG Signal Processing] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: EEG信号非平稳性限制模型泛化，需在资源受限平台上进行个性化适应/Non-stationary EEG signals limit model generalization, requiring personalized adaptation on resource-constrained platforms]\n        C[主要方法/Method: 在铁电忆阻突触上部署SNN，采用设备感知的权重更新策略/Deploy SNNs on ferroelectric memristive synapses with a device-aware weight-update strategy]\n        D[关键结果/Results: 两种部署策略性能媲美软件SNN，特定对象迁移学习提升准确率/Two deployment strategies achieve performance comparable to software SNNs, subject-specific transfer learning improves accuracy]"
    },
    {
      "title": "Covariance Matrix Adaptation Evolution Strategy without a matrix",
      "authors": "Jarosław Arabas, Adam Stelmaszczyk, Eryk Warchulski, Dariusz Jagodziński, Rafał Biedrzycki",
      "institution": "Warsaw University of Technology",
      "link": "https://arxiv.org/pdf/2601.00102",
      "code": null,
      "tags": [
        "evolutionary computation",
        "CMA-ES",
        "matrix-free",
        "high-dimensional optimization",
        "step-size adaptation",
        "black-box optimization"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57b7923e9e9cac21a68aeaefb1bed6421d350b6a739556df9a54b09abc025039_w640_q70.webp",
      "contributions": "1. Proposes a novel, matrix-free variant of CMA-ES that eliminates the need for covariance matrix decomposition by using an archive of normalized difference vectors. 2. Provides a theoretical proof that the probability distribution of individuals generated by the matrix-free method is identical to that of the standard CMA-ES. 3. Demonstrates experimentally that the method maintains or improves optimization efficiency, especially when combined with step-size adaptation, and allows for a reduced archive size without performance loss.",
      "summary": "This paper addresses the computational bottleneck of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) in high dimensions, which stems from the cubic cost of matrix decomposition. It introduces a matrix-free CMA-ES that generates new solutions by taking weighted combinations of past normalized difference vectors stored in an archive, eliminating the need for an explicit covariance matrix. The method is proven to be distributionally equivalent to standard CMA-ES and is shown to achieve comparable or superior performance, particularly when coupled with step-size adaptation.",
      "mindmap": "graph TB\n        A[Covariance Matrix Adaptation Evolution Strategy without a matrix] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>CMA-ES在高维空间的计算瓶颈<br>Computational bottleneck of CMA-ES in high dimensions]\n        C[主要方法/Method<br>提出无矩阵CMA-ES，使用存档向量加权组合<br>Propose matrix-free CMA-ES using weighted combination of archive vectors]\n        D[关键结果/Results<br>分布等价，性能相当或更优，收敛更快<br>Distributionally equivalent, comparable/superior performance, faster convergence]"
    },
    {
      "title": "Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting",
      "authors": "Ata Akbari Asanjan, Filip Wudarski, Daniel O'Connor, Shaun Geaney, Elena Strbac, P. Aaron Lott, Davide Venturelli",
      "institution": "USRA Research Institute for Advanced Computer Science (RIACS), Standard Chartered Bank",
      "link": "https://arxiv.org/pdf/2601.00172",
      "code": null,
      "tags": [
        "others",
        "Reservoir Computing",
        "Sequential Architecture",
        "Spatiotemporal Forecasting",
        "High-dimensional Data",
        "Training Efficiency"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80a4bf491108d4e92c2c08807229cd230f08dd3e916c820595ac48efa8952783_w640_q70.webp",
      "contributions": "1. Introduces a Sequential Reservoir Computing architecture that decomposes a large reservoir into smaller, interconnected ones to reduce computational and memory costs. 2. Demonstrates superior performance with longer forecast horizons and lower error metrics on chaotic and high-dimensional physical systems compared to RNN/LSTM baselines. 3. Achieves up to three orders of magnitude lower training cost, maintaining RC's efficiency while improving scalability for high-dimensional forecasting.",
      "summary": "This paper proposes Sequential Reservoir Computing, a novel architecture that breaks a large reservoir into a sequence of smaller ones to efficiently forecast high-dimensional spatiotemporal systems. It outperforms traditional RNNs and LSTMs in forecast horizon and accuracy while drastically reducing training costs, offering a path to real-time, energy-efficient forecasting.",
      "mindmap": "graph TB\n        Root[”Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>RNN/LSTM训练成本高，传统RC扩展性差”]\n        Method[”主要方法/Method<br>顺序储层计算架构”]\n        Results[”关键结果/Results<br>预测更长，误差更低，训练成本大幅降低”]"
    },
    {
      "title": "Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing",
      "authors": "Osvaldo Simeone",
      "institution": "Northeastern University London (Intelligent Networked Systems Institute - INSI)",
      "link": "https://arxiv.org/pdf/2601.00245",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "neuromorphic computing",
        "state-space models",
        "sparse attention",
        "surrogate gradients",
        "local learning rules"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9154dccb8e64d45d3b60bd0f6bb1e84fa9423cf041633e14a8cb6272baa46_w640_q70.webp",
      "contributions": "1. Proposes a novel conceptual framework for analyzing modern neuromorphic AI through the lens of intra-token (feature-level) and inter-token (contextual) processing. 2. Systematically reviews the convergence of neuromorphic principles (e.g., sparse, discrete activations) with state-of-the-art AI architectures like state-space models and transformers. 3. Reviews and categorizes training methodologies for neuromorphic models, from surrogate gradients to local learning rules based on reinforcement learning.",
      "summary": "This paper addresses the high energy costs of modern AI by exploring the convergence of neuromorphic computing principles with contemporary architectures. It proposes a framework distinguishing between intra-token and inter-token processing to analyze how neuromorphic ideas like sparse activations and state dynamics are embodied in models such as transformers and state-space models. The main conclusion is that modern AI is increasingly adopting brain-inspired, energy-efficient neuromorphic principles for both processing types, offering a path toward more sustainable intelligent systems.",
      "mindmap": "graph TB\n        A[Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[AI能耗增长 / Escalating AI Energy Requirements]\n        C --> C1[神经形态计算原则 / Neuromorphic Computing Principles]\n        C1 --> C2[离散稀疏激活 / Discrete & Sparse Activations]\n        C1 --> C3[循环动态 / Recurrent Dynamics]\n        C --> C4[处理框架: 令牌内与令牌间 / Processing Framework: Intra-Token vs. Inter-Token]\n        D --> D1[现代AI体现神经形态原则 / Modern AI Embodies Neuromorphic Principles]\n        D --> D2[连接SNN、状态空间模型、Transformer / Connects SNNs, State-Space Models, Transformers]"
    },
    {
      "title": "Rectifying Adversarial Examples Using Their Vulnerabilities",
      "authors": "Fumiya Morimoto, Ryuto Morita, Satoshi Ono",
      "institution": "Kagoshima University",
      "link": "https://arxiv.org/pdf/2601.00270",
      "code": null,
      "tags": [
        "adversarial defense",
        "adversarial examples",
        "label rectification",
        "re-attack",
        "white-box attack",
        "black-box attack"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c32aaba927fb42e32f98d767a04b8c60ecebe5d8f0f13c4c25f72d7d23e5138c_w640_q70.webp",
      "contributions": "1. Proposes a novel adversarial example rectification method based on \"re-attacking\" AEs to move them beyond the decision boundary for correct label estimation. 2. The method is designed to be straightforward, requiring only AEs as input without parameter adjustments or preliminary training, enabling it to address diverse attack types. 3. Demonstrates consistent performance and superior stability against various attacks, including targeted and black-box attacks, compared to conventional rectification and input transformation methods.",
      "summary": "This paper addresses the problem of rectifying adversarial examples (AEs) to recover the correct labels of the original inputs, which is crucial for applications like autonomous driving. The proposed method works by \"re-attacking\" the AEs to push them across the model's decision boundary. The results show that this method performs consistently across different attack types and is more stable than existing approaches.",
      "mindmap": "graph TB\n        A[Rectifying Adversarial Examples Using Their Vulnerabilities] --> B(核心问题/Problem: DNNs misclassify adversarial examples, needing correct label recovery)\n        A --> C(主要方法/Method: Re-attack AEs to move them beyond decision boundary)\n        A --> D(关键结果/Results: Consistent performance across attacks, outperforms conventional methods in stability)"
    },
    {
      "title": "Vehicle Painting Robot Path Planning Using Hierarchical Optimization",
      "authors": "Yuya Nagai, Hiromitsu Nakamura, Narito Shinmachi, Yuta Higashizono, Satoshi Ono",
      "institution": "Kagoshima University, TOYOTA Body Research & Development Co., Ltd.",
      "link": "https://arxiv.org/pdf/2601.00271",
      "code": null,
      "tags": [
        "robotic path planning",
        "hierarchical optimization",
        "vehicle routing problem (VRP)",
        "constraint handling",
        "evolutionary computation"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd6fcb32eb9c80960a0ed996281f691e7732ffdfe85f78eaf940b5a4d0c7ce64_w640_q70.webp",
      "contributions": "1. Formulates vehicle painting robot path planning as a hierarchical optimization problem, separating high-level task assignment (VRP-like) from low-level detailed path planning. 2. Proposes a flexible constraint handling framework for the painting process through custom variable representation, repair operators, and initialization. 3. Demonstrates the method's effectiveness by automatically generating paths for commercial vehicles that are comparable in quality to manual designs.",
      "summary": "This paper addresses the manual and time-consuming task of planning paint paths for multiple robotic arms in vehicle factories. It proposes a hierarchical optimization method that treats the problem as a high-level vehicle routing task and a low-level detailed path planning task, enabling automated design. Experiments on real vehicle models show the method can generate constraint-satisfying paths of comparable quality to those created by human engineers.",
      "mindmap": "graph TB\n        Root(”Vehicle Painting Robot Path Planning Using Hierarchical Optimization”) --> Problem(”核心问题/Problem: Manual paint path design for multiple robotic arms is time-consuming”)\n        Root --> Method(”主要方法/Method: Hierarchical optimization (Upper: VRP-like assignment, Lower: detailed path planning)”)\n        Root --> Results(”关键结果/Results: Automatically generates constraint-satisfying paths comparable to manual designs”)"
    },
    {
      "title": "Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems",
      "authors": "Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar Susanna Pirttikangas, Lauri Lovén",
      "institution": "University of Oulu, Stockholm University, EURECOM, University of Helsinki, RISE Research Institutes of Sweden, Luleå University of Technology, Peking University, TU Wien",
      "link": "https://arxiv.org/pdf/2601.00339",
      "code": null,
      "tags": [
        "agent system",
        "self-healing",
        "distributed computing continuum",
        "language model agents",
        "multi-agent systems",
        "fault tolerance"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61eb83e4510dadeebc7e84fe1a44a89c218981f7cc3a6c7ef337ea51860d2146_w640_q70.webp",
      "contributions": "1. Introduces ReCiSt, a novel bio-inspired framework that maps biological self-healing phases (Hemostasis, Inflammation, Proliferation, Remodeling) to computational layers (Containment, Diagnosis, Meta-Cognitive, Knowledge) for resilience in DCCS. 2. Proposes the use of Language Model (LM)-powered agents to autonomously interpret logs, diagnose faults, and reconfigure resources with minimal human intervention. 3. Demonstrates the framework's capability for self-healing within tens of seconds with low resource overhead (e.g., 10% CPU usage) through evaluation on public fault datasets.",
      "summary": "This paper proposes ReCiSt, a bio-inspired, agent-based framework that uses Language Model-powered agents to autonomously detect, diagnose, and recover from faults in Distributed Computing Continuum Systems. The framework is evaluated on public datasets, showing it can achieve self-healing in tens of seconds with minimal resource overhead.",
      "mindmap": "graph TB\n        Root[”Bio-inspired Agentic Self-healing Framework<br>生物启发的智能体自愈框架”] --> Problem[”核心问题/Problem<br>DCCS中的复杂性与故障频发<br>Complexity & Frequent Faults in DCCS”]\n        Root --> Method[”主要方法/Method<br>ReCiSt框架: 仿生四层与LM智能体<br>ReCiSt Framework: Bio-inspired Layers & LM Agents”]\n        Root --> Results[”关键结果/Results<br>数十秒内自愈，低CPU开销<br>Self-healing in tens of seconds, low CPU overhead”]"
    },
    {
      "title": "RMAAT: Astrocyte-Inspired Memory Compression and Replay for Efficient Long-Context Transformers",
      "authors": "Md Zesun Ahmed Mia, Malyaban Bal, Abhronil Sengupta",
      "institution": "Pennsylvania State University",
      "link": "https://arxiv.org/pdf/2601.00426",
      "code": null,
      "tags": [
        "efficient transformers",
        "astrocyte-inspired computing",
        "long-term plasticity (LTP)",
        "short-term plasticity (STP)",
        "memory compression",
        "Long Range Arena (LRA)"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48db0bbab3b8ca0fcbec4bfde72ebb384d63651cf925a575ef2f9e06a070abc5_w640_q70.webp",
      "contributions": "1. Introduces RMAAT, a novel Transformer architecture that integrates abstracted astrocyte functionalities for efficient long-context processing. 2. Proposes an adaptive memory compression mechanism governed by a novel retention factor derived from simulated astrocyte long-term plasticity (LTP). 3. Develops Astrocytic Memory Replay Backpropagation (AMRB), a novel training algorithm designed for memory efficiency in recurrent networks.",
      "summary": "This paper addresses the quadratic complexity problem of Transformer self-attention for long sequences by proposing RMAAT, an architecture inspired by astrocyte functions in biological memory. The method uses recurrent segment-based processing with adaptive memory compression and a linear-complexity attention mechanism. Evaluations on the Long Range Arena benchmark show that RMAAT achieves competitive accuracy with substantial improvements in computational and memory efficiency.",
      "mindmap": "graph TB\n        Root[RMAAT: Astrocyte-Inspired Memory Compression and Replay] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Transformer自注意力二次复杂度/Quadratic Complexity of Self-Attention]\n        Method[主要方法/Method: 星形胶质细胞启发的循环记忆架构/Astrocyte-Inspired Recurrent Memory Architecture]\n        Results[关键结果/Results: 在LRA基准上具有竞争力的准确性和效率/Competitive Accuracy & Efficiency on LRA]"
    },
    {
      "title": "Benchmarking ERP Analysis: Manual Features, Deep Learning, and Foundation Models",
      "authors": "Yihe Wang, Zhiqiao Kang, Bohan Chen, Yu Zhang, Xiang Zhang",
      "institution": "University of North Carolina-Charlotte, South China University of Technology, University of California-Davis, Stanford University",
      "link": "https://arxiv.org/pdf/2601.00573",
      "code": "https://github.com/DL4mHealth/ERP-Benchmark",
      "tags": [
        "brain-computer interfaces",
        "event-related potential",
        "EEG",
        "deep learning",
        "transformer",
        "benchmark"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58ac79c471f534c1c0facf539a3aecc0242ffa2b33fb14835383bc5dbe5a8d85_w640_q70.webp",
      "contributions": "1. Conducted a comprehensive benchmark comparing manual features, deep learning models, and EEG foundation models for ERP analysis. 2. Established a unified data preprocessing and training pipeline and evaluated methods on two tasks across 12 public datasets. 3. Investigated various patch-embedding strategies within Transformer architectures to identify designs better suited for ERP data.",
      "summary": "This paper benchmarks methods for analyzing Event-Related Potentials (ERPs) in EEG data. It systematically compares traditional manual features, deep learning models, and pre-trained foundation models using a unified pipeline across 12 datasets. The study provides a framework for method selection and identifies effective Transformer embedding strategies for ERP data.",
      "mindmap": "graph TB\n        A[Benchmarking ERP Analysis] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[ERP分析中深度学习方法有效性未充分探索/Deep learning effectiveness on ERP data underexplored]\n        C --> C1[建立统一预处理与训练流水线/Establish unified preprocessing & training pipeline]\n        C --> C2[系统比较三类方法/Systematically compare three method categories]\n        C --> C3[研究Transformer的Patch嵌入策略/Investigate Transformer patch-embedding strategies]\n        D --> D1[提供方法选择与模型设计框架/Provide framework for method selection & model design]"
    },
    {
      "title": "Three factor delay learning rules for spiking neural networks",
      "authors": "Luke Vassallo, Nima Taherinejad",
      "institution": "Heidelberg University",
      "link": "https://arxiv.org/pdf/2601.00668",
      "code": null,
      "tags": [
        "on-device ai",
        "spiking neural networks",
        "delay learning",
        "three-factor learning",
        "online learning",
        "neuromorphic processors"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58cabcbc7350cb70af9599a2c224309ae64c370ecf64ef754054d42693a8f504_w640_q70.webp",
      "contributions": "1. Introduced learnable synaptic and axonal delays into LIF-based SNNs and proposed novel three-factor learning rules for online, simultaneous learning of both weights and delays. 2. Employed a smooth Gaussian surrogate gradient exclusively for eligibility trace calculation to enable gradient-equivalent delay parameter updates. 3. Demonstrated significant improvements in model efficiency, achieving up to 6.6x model size reduction and 67% lower inference latency with minimal accuracy loss, enabling on-device learning for resource-constrained environments.",
      "summary": "This paper addresses the limited temporal learning capability of Spiking Neural Networks (SNNs) by introducing learnable synaptic and axonal delays and proposing online three-factor learning rules to train them. The method uses a Gaussian surrogate gradient for eligibility traces and achieves competitive accuracy on temporal tasks like speech recognition while drastically reducing model size and latency. The findings facilitate efficient, on-device learning for power and area-constrained neuromorphic hardware.",
      "mindmap": "graph TB\n        A[Three factor delay learning rules for spiking neural networks] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[SNNs lack temporal parameters/SNNs缺乏时间参数]\n        B --> B2[Existing delay learning is offline & large/现有延迟学习是离线的且模型大]\n        C --> C1[Learnable synaptic & axonal delays/可学习的突触和轴突延迟]\n        C --> C2[Three-factor online learning rules/三因素在线学习规则]\n        C --> C3[Gaussian surrogate for eligibility trace/用于资格迹的高斯代理梯度]\n        D --> D1[Accuracy improved up to 20%/准确率提升高达20%]\n        D --> D2[Model size reduced 6.6x/模型大小减少6.6倍]\n        D --> D3[Latency reduced 67%/延迟降低67%]"
    },
    {
      "title": "QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models",
      "authors": "Rachmad Vidya Wicaksana Putra, Pasindu Wickramasinghe, Muhammad Shafique",
      "institution": "New York University (NYU) Abu Dhabi",
      "link": "https://arxiv.org/pdf/2601.00679",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "quantization",
        "spike-driven language models (SLMs)",
        "memory footprint",
        "tiered search",
        "embedded systems"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/911838f93e33219fcf586121369dd081b9908c86a1169c367cfdd1bb7e50139b_w640_q70.webp",
      "contributions": "1. Proposes QSLM, an automated quantization framework for compressing pre-trained Spike-driven Language Models (SLMs) to meet performance and memory constraints. 2. Introduces a tiered quantization strategy (global-, block-, and module-level) guided by network hierarchy and layer sensitivity analysis. 3. Leverages a multi-objective performance-and-memory trade-off function to select the final quantization setting, achieving significant memory and power reduction while maintaining high task performance.",
      "summary": "The paper proposes QSLM, an automated framework for quantizing Spike-driven Language Models (SLMs) to reduce their memory footprint for embedded deployment. It uses a tiered search strategy based on network hierarchy and layer sensitivity, along with a multi-objective trade-off function, to find optimal quantization settings. Experimental results show QSLM can reduce memory by up to 86.5% and power by up to 20% while maintaining performance close to the original model.",
      "mindmap": "graph TB\n        A[QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: SLMs内存占用大，难以部署在资源受限的嵌入式设备/SLMs have large memory footprints, challenging for resource-constrained embedded deployment]\n        C[主要方法/Method: 自动化分层量化策略，结合网络层次、层敏感性和多目标权衡函数/Automated tiered quantization strategy using network hierarchy, layer sensitivity, and multi-objective trade-off]\n        D[关键结果/Results: 内存占用减少高达86.5%，功耗降低高达20%，性能接近原始模型/Memory footprint reduced by up to 86.5%, power by up to 20%, performance close to original model]"
    },
    {
      "title": "Cost Optimization in Production Line Using Genetic Algorithm",
      "authors": "Alireza Rezaee",
      "institution": "University of Tehran",
      "link": "https://arxiv.org/pdf/2601.00689",
      "code": null,
      "tags": [
        "combinatorial optimization",
        "genetic algorithm",
        "task scheduling",
        "production line",
        "chromosome encoding",
        "JGAP"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d46632061e4499187a195e89a09ba37b6eff28c44f9881da5b237c2b781953b_w640_q70.webp",
      "contributions": "1. Proposes and compares two chromosome encoding strategies (station-based and task-based) for a GA applied to a production line scheduling problem. 2. Adapts standard GA operators (crossover, mutation, etc.) to preserve solution feasibility under precedence and capacity constraints. 3. Empirically demonstrates that the task-based encoding yields smoother convergence and more reliable cost minimization, especially for problems with a large number of valid schedules.",
      "summary": "This paper applies a genetic algorithm to optimize task scheduling in a production line to minimize cost. It investigates two different ways to represent the schedule (encoding) within the algorithm and finds that a task-based encoding performs better, converging more smoothly to lower-cost solutions. The study shows GAs are advantageous for this type of complex, constrained scheduling problem.",
      "mindmap": "graph TB\n        A[Cost Optimization in Production Line Using Genetic Algorithm] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[最小化生产线成本/Minimize Production Line Cost]\n        B --> B2[任务调度与约束/Task Scheduling with Constraints]\n        C --> C1[遗传算法/Genetic Algorithm]\n        C --> C2[两种编码策略/Two Encoding Strategies]\n        C2 --> C21[基于工位的编码/Station-based Encoding]\n        C2 --> C22[基于任务的编码/Task-based Encoding]\n        D --> D1[基于任务的编码性能更优/Task-based Encoding Performs Better]\n        D --> D2[更平滑的收敛/Smoother Convergence]\n        D --> D3[更可靠的优化/More Reliable Optimization]"
    },
    {
      "title": "Quadratic Unconstrained Binary Optimisation for Training and Regularisation of Binary Neural Networks",
      "authors": "Jonas Christoffer Villumsen, Yusuke Sugita",
      "institution": "Hitachi Europe Ltd., Hitachi Ltd.",
      "link": "https://arxiv.org/pdf/2601.00449",
      "code": null,
      "tags": [
        "on-device ai",
        "binary neural networks",
        "quadratic unconstrained binary optimization",
        "ising machine",
        "regularization",
        "simulated annealing"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28133ab4719e6b11d3441bf2c924e33139268781e601ff1ef434dd50fa7de88c_w640_q70.webp",
      "contributions": "1. Extends existing QUBO models for training Binary Neural Networks to accommodate arbitrary network topologies. 2. Proposes a novel regularization method that maximizes neuron margins to bias training toward configurations with larger pre-activation magnitudes. 3. Proposes a second novel, dropout-inspired iterative regularization scheme that trains reduced subnetworks to adjust linear penalties on network parameters.",
      "summary": "This paper addresses the challenge of efficiently training discrete Binary Neural Networks (BNNs) by formulating the training as a Quadratic Unconstrained Binary Optimization (QUBO) problem. It extends existing QUBO models to arbitrary network topologies and introduces two new regularization methods to improve generalization. Experimental results on a GPU-based Ising machine show that the proposed methods modify training behavior and improve classification accuracy on unseen data.",
      "mindmap": "graph TB\n        A[Quadratic Unconstrained Binary Optimisation for Training and Regularisation of Binary Neural Networks] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[训练二元神经网络的挑战/Challenge of training BNNs]\n        C --> C1[扩展QUBO模型/Extend QUBO models]\n        C --> C2[提出两种正则化方法/Propose two regularization methods]\n        C2 --> C2_1[最大化神经元间隔/Maximize neuron margins]\n        C2 --> C2_2[Dropout启发式迭代方案/Dropout-inspired iterative scheme]\n        D --> D1[正则化改变训练行为/Regularization modifies training behavior]\n        D --> D2[提升未见数据分类精度/Improves classification accuracy on unseen data]"
    },
    {
      "title": "Identification of fixations and saccades in eye-tracking data using adaptive threshold-based method",
      "authors": "Charles Oriioma, Josef Krivan, Rujeena Mathema, Pedro G. Lind, Alexander Szorkovszky, Shailendra Bhandari",
      "institution": "OsloMet – Oslo Metropolitan University, Simula Research Laboratory, Kristiania University of Applied Sciences",
      "link": "https://arxiv.org/pdf/2512.23926",
      "code": null,
      "tags": [
        "eye-tracking analysis",
        "adaptive thresholding",
        "velocity threshold",
        "dispersion threshold",
        "K-ratio minimization",
        "Markovian approximation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a34005335e56be821cea4646a8d8f8815324d67d0e2f0bb4fe8830262cf34e0_w640_q70.webp",
      "contributions": "1. Introduced an adaptive thresholding method for eye-tracking data that uses a Markovian model to find the optimal threshold by minimizing state transitions (K-ratio). 2. Systematically evaluated and compared the noise robustness of three common threshold-based algorithms (velocity, angular velocity, dispersion) with and without the adaptive optimization. 3. Provided practical guidance for algorithm selection, showing that while velocity thresholds have high baseline accuracy, adaptive dispersion thresholds offer superior robustness to high noise levels.",
      "summary": "This paper addresses the problem of distinguishing fixations from saccades in noisy eye-tracking data, where fixed thresholds can introduce bias. The authors propose an adaptive thresholding method that models gaze dynamics as a Markov process and optimizes the threshold to minimize state transitions. Their evaluation shows that adaptive thresholds, especially for dispersion-based algorithms, significantly improve classification robustness under high noise conditions compared to fixed-threshold baselines.",
      "mindmap": "graph TB\n        A[Identification of fixations and saccades in eye-tracking data using adaptive threshold-based methods] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Fixed thresholds in eye-tracking algorithms neglect variability and are noise-sensitive.]\n        C[主要方法/Method: Adaptive threshold optimization via Markovian model and K-ratio minimization.]\n        D[关键结果/Results: Adaptive dispersion is most noise-robust; velocity has high baseline accuracy but degrades with noise.]"
    },
    {
      "title": "Decoupling Constraint from Two Direction in Evolutionary Constrained Multi-objective Optimization",
      "authors": "Ruiqing Sun, Dawei Feng, Xing Zhou, Lianghao Li, Sheng Qi, Bo Ding, Yijie Wang, Rui Wang, Huaimin Wang",
      "institution": "National University of Defense Technology",
      "link": "https://arxiv.org/pdf/2512.23945",
      "code": "https://github.com/KFC-Grandpa/DCF2D-Decoupling-Constraint-from-Two-Direction",
      "tags": [
        "evolutionary computation",
        "Constrained Multi-objective Optimization",
        "Constraint Decoupling",
        "Coevolutionary Algorithm"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9961a6ec373a0059008d366a3c457c71a3b16f2e308e3aca87ae29a142caf095_w640_q70.webp",
      "contributions": "1. Analysis of constraint coupling, showing the Constrained Pareto Front depends on individual constraint fronts and infeasible region boundaries., 2. Insight that CMOPs with different coupling types require different search directions., 3. Proposal of the DCF2D algorithm, which periodically detects constraint couplings and spawns auxiliary populations with appropriate search directions.",
      "summary": "This paper addresses the limitation of existing Constrained Multi-objective Evolutionary Algorithms (CMOEAs) that treat all constraints as a single aggregate, ignoring their couplings. The authors propose a novel algorithm called Decoupling Constraint from Two Directions (DCF2D), which detects constraint couplings and uses auxiliary populations with tailored search directions. Experiments on benchmark and real-world problems show DCF2D outperforms several state-of-the-art CMOEAs.",
      "mindmap": "graph TB\n        Root[”Decoupling Constraint from Two Direction in Evolutionary Constrained Multi-objective Optimization”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>Existing CMOEAs ignore constraint couplings, treating them as a single aggregate.”]\n        Method[”主要方法/Method<br>Propose DCF2D: periodically detects constraint couplings and spawns auxiliary populations with appropriate search directions.”]\n        Results[”关键结果/Results<br>DCF2D outperforms five state-of-the-art CMOEAs on benchmarks and real-world CMOPs.”]"
    },
    {
      "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
      "authors": "Bulent Soykan, Sean Mondesire, Ghaith Rabadi",
      "institution": "University of Central Florida",
      "link": "https://arxiv.org/pdf/2512.24007",
      "code": "github.com/bulentsoykan/TESO",
      "tags": [
        "metaheuristics",
        "simulation optimization",
        "tabu search",
        "elite memory",
        "noisy black-box",
        "aspiration criterion"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/00ac2df6705adb84c43e6fe1380cb528473aee412ea23024864f40a91dfd7ec9_w640_q70.webp",
      "contributions": "1. Proposes TESO, a novel metaheuristic framework that integrates adaptive search with memory-based strategies for simulation optimization. 2. Introduces a dual-memory mechanism combining a short-term Tabu List for diversification and a long-term Elite Memory for intensification. 3. Demonstrates the framework's effectiveness and reliability on a queue optimization problem, showing improved performance over benchmarks.",
      "summary": "This paper introduces TESO, a metaheuristic framework for noisy, expensive black-box simulation optimization. It combines a Tabu List and an Elite Memory with an aspiration criterion to balance exploration and exploitation. The method is validated on a queue optimization problem, showing improved performance and reliability compared to benchmarks.",
      "mindmap": "graph TB\n        Root[TESO: Tabu-Enhanced Simulation Optimization] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Noisy, expensive, multimodal simulation optimization] --> P1[挑战/Challenges: Noisy evaluations, high cost, complex landscapes]\n        Method[主要方法/Method: Memory-based metaheuristic framework] --> M1[组件/Components: Tabu List, Elite Memory, Aspiration Criterion]\n        Results[关键结果/Results: Validated on queue optimization] --> R1[结论/Conclusion: Improved performance & reliability]"
    },
    {
      "title": "Generalising E-prop to Deep Networks",
      "authors": "Beren Millidge",
      "institution": "Zyphra",
      "link": "https://arxiv.org/pdf/2512.24506",
      "code": null,
      "tags": [
        "biologically plausible learning algorithms",
        "E-prop",
        "eligibility traces",
        "credit assignment",
        "recurrent neural networks",
        "backpropagation through time"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6eda8a1b73fb9e52a5baf437a42dfe8578438c0dde5dfa6d166ba856f037f47_w640_q70.webp",
      "contributions": "1. Extends the E-prop framework to handle arbitrarily deep networks, enabling credit assignment across both time and depth. 2. Derives a novel recursion relationship across depth that generalizes eligibility traces to deeper layers. 3. Demonstrates an online learning algorithm capable of training deep recurrent networks without backpropagation through time.",
      "summary": "This paper addresses the biological implausibility of Backpropagation Through Time (BPTT) for training recurrent neural networks. It proposes an extension of the E-prop algorithm to deep networks, enabling online credit assignment across both time and depth. The main conclusion is that this method allows for the training of deep recurrent networks without BPTT.",
      "mindmap": "graph TB\n        Root(”Generalising E-prop to Deep Networks”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”BPTT生物不可信/BPTT biologically implausible”)\n        Problem --> P2(”RTRL计算复杂/RTRL computationally expensive”)\n        Problem --> P3(”现有方法局限于单层/Existing methods limited to single layer”)\n        Method --> M1(”扩展E-prop框架/Extend E-prop framework”)\n        Method --> M2(”推导跨深度的递归关系/Derive depth-wise recursion”)\n        Method --> M3(”推广资格迹到深层/Generalize eligibility traces to deep layers”)\n        Results --> R1(”实现跨时空的在线信用分配/Online credit assignment across time and depth”)\n        Results --> R2(”无需BPTT训练深度循环网络/Train deep recurrent networks without BPTT”)"
    },
    {
      "title": "Evolutionary Discovery of Sequence Acceleration Methods for Slab Geometry Neutron Transport",
      "authors": "Japan K. Patel, Barry D. Ganapol, Anthony Magliari, Matthew C. Schmidt, Todd A. Wareing",
      "institution": "Gateway Scripts, University of Arizona, Varian Medical Systems, Washington University in St. Louis",
      "link": "https://arxiv.org/pdf/2512.24559",
      "code": null,
      "tags": [
        "computational physics",
        "numerical methods",
        "genetic programming",
        "sequence acceleration",
        "neutron transport",
        "slab geometry",
        "discrete ordinates"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d34d82f8c1e37e97ac83244d31b5fb8965de8b3a0c8f93a666dd8bc4b3585880_w640_q70.webp",
      "contributions": "1. Applied genetic programming to automatically discover novel convergence acceleration methods for neutron transport problems, moving beyond classical methods with fixed assumptions. 2. Evolved a specific mathematical formula accelerator tailored to the convergence characteristics of discrete ordinates (SN) solutions in slab geometry. 3. Demonstrated the discovered accelerator's superior performance, achieving over 75% success rate in improving convergence, nearly double that of classical techniques on the tested problem set.",
      "summary": "This paper uses genetic programming to automatically discover new mathematical formulas for accelerating the convergence of numerical solutions to neutron transport problems in slab geometry. The evolved accelerator, which uses second differences and cross-product terms, significantly outperformed classical methods like Aitken's and Wynn's, showing the potential of AI to generate novel numerical methods in computational physics.",
      "mindmap": "graph TB\n        A[Evolutionary Discovery of Sequence Acceleration Methods for Slab Geometry Neutron Transport] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[经典加速方法泛化性差<br>Classical acceleration methods lack generalization]\n        C --> C1[使用遗传编程进化公式<br>Use Genetic Programming to evolve formulas]\n        D --> D1[发现新型加速器<br>Discovered novel accelerator]\n        D --> D2[成功率 >75%, 性能翻倍<br>>75% success rate, nearly double performance]"
    },
    {
      "title": "Equivalence of Personalized PageRank and Successor Representations",
      "authors": "Beren Millidge",
      "institution": "Zyphra",
      "link": "https://arxiv.org/pdf/2512.24722",
      "code": null,
      "tags": [
        "computational neuroscience",
        "personalized pagerank",
        "successor representation",
        "stationary distribution",
        "random walk",
        "hippocampus"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/130f6ae2c386370de68fa70e71e8766a30a8d563c1baa5dda86dea70938b910b_w640_q70.webp",
      "contributions": "1. Demonstrates an isomorphism between Personalized PageRank (used for memory retrieval) and Successor Representations (used for planning/navigation). 2. Shows both algorithms utilize the same underlying representation: the stationary distribution of a random walk on a graph. 3. Proposes a unifying hypothesis that the core computational function of the hippocampus is to compute this stationary distribution representation on arbitrary input graphs.",
      "summary": "This paper shows that two seemingly distinct algorithms proposed for hippocampal function—Personalized PageRank for memory retrieval and Successor Representations for planning—are mathematically equivalent, as both compute the stationary distribution of a random walk on a graph. The authors conclude that this shared representation suggests a unified computational role for the hippocampus in processing graph-structured information for both memory and navigation tasks.",
      "mindmap": "graph TB\n    A[Equivalence of Personalized PageRank and Successor Representations] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[海马体功能看似不同<br/>Hippocampus functions appear distinct]\n    B1 --> B2[记忆检索 vs. 规划导航<br/>Memory Retrieval vs. Planning/Navigation]\n    C --> C1[证明算法同构<br/>Demonstrate Algorithm Isomorphism]\n    C1 --> C2[个性化PageRank<br/>Personalized PageRank]\n    C1 --> C3[后继表示<br/>Successor Representations]\n    D --> D1[共享基础表示<br/>Shared Underlying Representation]\n    D1 --> D2[图上随机游走的平稳分布<br/>Stationary Distribution of Random Walk on Graph]\n    D --> D3[统一计算假说<br/>Unified Computational Hypothesis]\n    D3 --> D4[海马体核心功能<br/>Core Function of Hippocampus]"
    },
    {
      "title": "Projection-based Adversarial Attack using Physics-in-the-Loop Optimization for Monocular Depth Estimation",
      "authors": "Takeru Kusakabe, Yudai Hirose, Mashiho Mukaida, Satoshi Ono",
      "institution": "Kagoshima University",
      "link": "https://arxiv.org/pdf/2512.24792",
      "code": null,
      "tags": [
        "monocular depth estimation",
        "adversarial attack",
        "physics-in-the-loop optimization",
        "sep-CMA-ES"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5085ff109d1d570d16fe1fa964d0eb5cc890f0ebaed8dcfe0c3cdaa01d4f00bd_w640_q70.webp",
      "contributions": "1. Proposes a projection-based adversarial attack method for monocular depth estimation models, using projected light as the perturbation. 2. Employs physics-in-the-loop (PITL) optimization to design perturbations in real-world environments, accounting for device specifications and disturbances. 3. Utilizes a distributed covariance matrix adaptation evolution strategy (sep-CMA-ES) for effective black-box optimization to generate adversarial examples.",
      "summary": "This paper proposes a physical adversarial attack method for monocular depth estimation models. The method projects perturbation light onto a target object and uses physics-in-the-loop optimization with a distributed evolution strategy to create adversarial examples. Experiments confirmed the attack's success, causing depth misestimations that made parts of objects disappear from the scene.",
      "mindmap": "graph TB\n        Root[Projection-based Adversarial Attack using Physics-in-the-Loop Optimization for Monocular Depth Estimation] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: DNN-based monocular depth estimation models are vulnerable to adversarial attacks, threatening reliability in applications like autonomous systems.]\n        Method[主要方法/Method: Proposes a projection-based attack using physics-in-the-loop optimization and sep-CMA-ES to generate adversarial light perturbations.]\n        Results[关键结果/Results: Successfully created adversarial examples causing depth misestimation, making parts of objects disappear from the scene.]"
    },
    {
      "title": "Self-Supervised Neural Architecture Search for Multimodal Deep Neural Networks",
      "authors": "Shota Suzuki, Satoshi Ono",
      "institution": "Kagoshima University",
      "link": "https://arxiv.org/pdf/2512.24793",
      "code": null,
      "tags": [
        "multi-modal training",
        "neural architecture search",
        "self-supervised learning",
        "multimodal fusion",
        "contrastive learning",
        "gradient-based search"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a6c1a495cc476572529c11ecd2d19b6e7849693fc7a5c6941d8e99e91599cc5_w640_q70.webp",
      "contributions": "1. Proposes a self-supervised learning (SSL) method for neural architecture search (NAS) specifically for multimodal deep neural networks. 2. Applies SSL comprehensively to both the architecture search and model pretraining processes, eliminating the need for labeled data during search. 3. Demonstrates that the method can successfully design network architectures from unlabeled training data, achieving performance comparable to supervised NAS methods.",
      "summary": "This paper addresses the problem that neural architecture search (NAS) for multimodal deep neural networks typically requires large amounts of labeled data. The authors propose a self-supervised learning method that uses contrastive learning to perform NAS without labeled data. Experimental results show the method can successfully design effective multimodal network architectures using only unlabeled data.",
      "mindmap": "graph TB\n        Root[Self-supervised Neural Architecture Search for Multimodal Deep Neural Networks] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Multimodal NAS requires substantial labeled data] --> P1[问题细化/Sub-problem: High labeling cost for multimodal data]\n        Method[主要方法/Method: Self-supervised NAS] --> M1[方法基础/Foundation: Gradient-based NAS (BM-NAS)] --> M1_1[技术/Technique: Differential Architecture Search]\n        Method --> M2[自监督机制/SSL Mechanism: Contrastive Learning (SimCLR)] --> M2_1[目标/Objective: Learn from unlabeled data]\n        Results[关键结果/Results: Successfully designed architectures from unlabeled data] --> R1[评估/Evaluation: Comparable to supervised methods]"
    },
    {
      "title": "Generative Classifiers Avoid Shortcut Solutions",
      "authors": "Alexander C. Li, Ananya Kumar, Deepak Pathak",
      "institution": "Carnegie Mellon University, Stanford University",
      "link": "https://arxiv.org/pdf/2512.25034",
      "code": "https://github.com/alexlioralexli/generative-classifiers",
      "tags": [
        "generative models",
        "generative classifiers",
        "spurious correlations",
        "distribution shift",
        "diffusion models",
        "autoregressive models"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f744eff83ad768a9dc5e431ef5b2d98baefe24c12d01fc980aa2fa92c3c21c65_w640_q70.webp",
      "contributions": "1. Demonstrates that generative classifiers (using class-conditional generative models) inherently avoid shortcut learning by modeling all features, not just spurious ones. 2. Shows that generative classifiers achieve state-of-the-art performance on multiple image and text distribution shift benchmarks without specialized techniques. 3. Provides a theoretical analysis in a Gaussian toy setting to explain the inductive biases and data conditions favoring generative classifiers.",
      "summary": "The paper addresses the problem of discriminative classifiers learning spurious shortcuts that fail under distribution shift. It proposes using generative classifiers, which model p(x|y), and finds they avoid shortcuts and achieve state-of-the-art robustness on standard benchmarks without needing specialized training tricks. The main conclusion is that generative classifiers offer a simple and effective alternative for building more robust models.",
      "mindmap": "graph TB\n        A[Generative Classifiers Avoid Shortcut Solutions] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Discriminative models learn spurious shortcuts<br>判别模型学习虚假捷径]\n        C --> C1[Use class-conditional generative models<br>使用类条件生成模型]\n        C --> C2[Model p(x|y) instead of p(y|x)<br>建模 p(x|y) 而非 p(y|x)]\n        D --> D1[Avoid shortcuts & SOTA on distribution shift<br>避免捷径并在分布偏移上达到SOTA]\n        D --> D2[Simple training, no specialized techniques<br>训练简单，无需专门技术]"
    },
    {
      "title": "Spike-Timing-Dependent Plasticity for Bernoulli Message Passing",
      "authors": "Sepideh Adamiat, Wouter M. Kouw, Bert de Vries",
      "institution": "TU Eindhoven, Lazy Dynamics B.V.",
      "link": "https://arxiv.org/pdf/2512.23728",
      "code": null,
      "tags": [
        "computational neuroscience",
        "spike-timing-dependent plasticity",
        "Bayesian inference",
        "message passing",
        "factor graphs",
        "spiking neural networks"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a449542e05c85b78a1c2c36d2343549e26e8c17a9edfccf34c692fd2512f710c_w640_q70.webp",
      "contributions": "1. Bridging Bayesian inference and spike-based neural computation by designing spiking neural networks for Bernoulli message passing. 2. Employing spike-timing-dependent plasticity (STDP), a biologically plausible Hebbian learning rule, to train these networks. 3. Demonstrating the approach's versatility by applying it to a factor graph example from coding theory for signal transmission over an unreliable channel.",
      "summary": "This paper bridges Bayesian inference and spike-based neural activity by designing spiking neural networks that perform message passing for Bernoulli variables. The networks are trained using the biologically plausible spike-timing-dependent plasticity rule. The results show the network's performance matches the true numerical solution, and the method is demonstrated on a coding theory problem.",
      "mindmap": "graph TB\n        A[Spike-Timing-Dependent Plasticity for Bernoulli Message Passing] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[连接贝叶斯推理与脉冲神经活动/Bridging Bayesian inference and spike-based neural activity]\n        C --> C1[设计用于伯努利消息传递的脉冲神经网络/Designing SNNs for Bernoulli message passing]\n        C --> C2[使用脉冲时序依赖可塑性进行训练/Using STDP for training]\n        D --> D1[网络性能匹配真实数值解/Network performance matches true numerical solution]\n        D --> D2[方法应用于编码理论因子图/Method applied to coding theory factor graph]"
    },
    {
      "title": "SymSeqBench: a unified framework for the generation and analysis of rule-based symbolic sequences and datasets",
      "authors": "Barna Zajzon, Younes Bouhadjar, Maxime Fabre, Felix Schmidt, Noah Ostendorf, Emre Neftci, Abigail Morrison, Renato Duarte",
      "institution": "Jülich Research Centre, RWTH Aachen University, University of Groningen, University of Coimbra",
      "link": "https://arxiv.org/pdf/2512.24977",
      "code": null,
      "tags": [
        "sequence learning",
        "formal language theory",
        "symbolic sequences",
        "benchmark suite",
        "cognitive modeling",
        "sequence processing"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/71331410faecaa464fb09419a580962b2cddad2a5e128910f8482dc81e965858_w640_q70.webp",
      "contributions": "1. Introduces SymSeq, a tool for the rigorous generation and analysis of structured symbolic sequences. 2. Introduces SeqBench, a comprehensive benchmark suite of rule-based sequence processing tasks for evaluating AI systems. 3. Provides a unified, domain-agnostic framework (SymSeqBench) based on Formal Language Theory to standardize experiments across cognitive science and AI.",
      "summary": "The paper introduces SymSeqBench, a unified software framework combining a symbolic sequence generator/analyzer (SymSeq) and a benchmark suite (SeqBench) for evaluating sequence learning. It is based on Formal Language Theory to provide a domain-agnostic, formal link between computation and cognition. The main conclusion is that this modular, open-source tool offers a versatile and standardized way to investigate sequential structure across diverse fields like psycholinguistics, cognitive psychology, and AI.",
      "mindmap": "graph TB\n        Root[SymSeqBench: 统一框架] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[评估序列学习/Evaluating Sequence Learning]\n        Problem --> P2[领域无关的评估/Domain-Agnostic Evaluation]\n        Problem --> P3[连接形式理论与认知/Linking Formal Theory & Cognition]\n        Method --> M1[SymSeq: 生成与分析/SymSeq: Generation & Analysis]\n        Method --> M2[SeqBench: 基准测试套件/SeqBench: Benchmark Suite]\n        Method --> M3[基于形式语言理论/Based on Formal Language Theory]\n        Results --> R1[跨领域多功能/Versatile Across Domains]\n        Results --> R2[标准化实验/Standardizes Experiments]\n        Results --> R3[模块化开源工具/Modular Open-Source Tool]"
    },
    {
      "title": "CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks",
      "authors": "Yogeswar Reddy Thota",
      "institution": "University of Texas at Dallas",
      "link": "https://arxiv.org/pdf/2512.22206",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "dynamic routing",
        "residual networks",
        "cosine incompatibility",
        "Gumbel-Softmax",
        "FLOPs regularization"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed7e3fa1c114a73795152210d2b55ffe2541fede331ce04d228e11ca599688fa_w640_q70.webp",
      "contributions": "1. Introduces CosineGate, an end-to-end differentiable architecture for dynamic routing in residual networks using cosine incompatibility as a self-supervised skip signal. 2. Proposes the Cosine Incompatibility Ratio (CIR) to measure semantic redundancy and employs Gumbel-Softmax relaxation for per-sample, per-block gating during training. 3. Incorporates a progressive FLOPs regularization term to control average computational usage without destabilizing the optimization process.",
      "summary": "The paper addresses the computational inefficiency in residual networks, where all blocks are evaluated for every input. It proposes CosineGate, a method that uses the cosine incompatibility between identity and residual features to dynamically skip redundant blocks, achieving significant FLOPs savings on CIFAR-10 while maintaining or improving accuracy.",
      "mindmap": "graph TB\n        A[CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks] --> B[核心问题/Problem: Modern residual networks perform redundant computation for all inputs]\n        A --> C[主要方法/Method: Uses cosine incompatibility ratio and Gumbel-Softmax for dynamic per-block gating]\n        A --> D[关键结果/Results: Achieves accuracy-efficiency Pareto frontier on CIFAR-10 with significant FLOPs savings]"
    },
    {
      "title": "CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation",
      "authors": "Santhosh Kumar Ravindran",
      "institution": "Microsoft Corporation",
      "link": "https://arxiv.org/pdf/2512.21351",
      "code": null,
      "tags": [
        "reinforcement learning",
        "dream-replay reinforcement learning",
        "evolutionary algorithms",
        "adaptive code generation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp",
      "contributions": "1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as \"genomes\" that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.",
      "summary": "CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.",
      "mindmap": "graph TB\n        A[CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM代码生成缺乏适应性，难以应对API变化/LLM code generation lacks adaptability to API changes]\n        C --> C1[将RL轨迹视为基因组进行进化操作/Treat RL trajectories as genomes for evolutionary operations]\n        C --> C2[在夜间回放阶段进行突变与选择/Mutation and selection during nocturnal replay]\n        D --> D1[解决方案新颖性提升35%/35% higher novelty in solutions]\n        D --> D2[适应速度加快25%/25% faster adaptation]"
    },
    {
      "title": "Conserved active information",
      "authors": "Yanchen Chen, Daniel Andrés Díaz-Pachón",
      "institution": "University of Miami",
      "link": "https://arxiv.org/pdf/2512.21834",
      "code": null,
      "tags": [
        "information theory",
        "conserved active information",
        "No-Free-Lunch",
        "KL divergence",
        "search space",
        "information conservation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1371f9cf2f5be050a2495fc2f2b19865fddd5c4a8834df1cd98fc2da7eea7111_w640_q70.webp",
      "contributions": "1. Introduces conserved active information (I⊕), a symmetric measure of net information gain/loss across a search space that respects No-Free-Lunch conservation. 2. Demonstrates that I⊕ can reveal regimes (e.g., strong knowledge reducing global disorder) that are hidden from traditional measures like KL divergence. 3. Applies the framework to resolve a longstanding critique of active information and illustrates its utility in domains like Markov chains and cosmological fine-tuning.",
      "summary": "This paper proposes a new information-theoretic measure called conserved active information (I⊕) to quantify net information change in search problems while respecting conservation laws. It shows that I⊕ uncovers scenarios, such as strong knowledge imposing order, which are missed by standard divergence measures. The work resolves a key critique of active information and enables applications in search and optimization.",
      "mindmap": "graph TB\n        Root[Conserved active information] --> Problem[核心问题/Problem: Limitations of average-focused information measures like KL divergence]\n        Root --> Method[主要方法/Method: Introduce conserved active information I⊕, a symmetric extension respecting No-Free-Lunch]\n        Root --> Results[关键结果/Results: I⊕ reveals hidden regimes (e.g., strong knowledge reduces disorder), resolves critique of active information]"
    },
    {
      "title": "Evolutionary Neural Architecture Search with Dual Contrastive Learning",
      "authors": "Xian-Rong Zhang, Yue-Jiao Gong, Wei-Neng Chen, Jun Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20112",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/659d1805ddb5e7863af4ee9eeedcfdd78686f84f207247f4d0e65555165f2577_w640_q70.webp",
      "contributions": "",
      "summary": "Evolutionary Neural Architecture Search with Dual Contrastive Learning",
      "mindmap": ""
    },
    {
      "title": "Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds",
      "authors": "Tarik Houichime, Abdelghani Souhar, Younes El Amrani",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20245",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1001e3781e678219db00950fa667bbe46bbaa2f98cd7e5064d91ede9a2cbc6fe_w640_q70.webp",
      "contributions": "",
      "summary": "Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds",
      "mindmap": ""
    },
    {
      "title": "Cross-Population White Matter Atlas Creation for Concurrent Mapping of Brain Connections in Neonates and Adults with Diffusion MRI Tractography",
      "authors": "Wei Zhang, Yijie Li, Ruixi Zheng, Nir A. Sochen, Yuqian Chen, Leo R. Zekelman, Ofer Pasternak, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Lauren J. O'Donnell, Fan Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20370",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74c696633339b92d89500e6f9b584dbdce271f9a63142e62f9874284f51b94a0_w640_q70.webp",
      "contributions": "",
      "summary": "Cross-Population White Matter Atlas Creation for Concurrent Mapping of Brain Connections in Neonates and Adults with Diffusion MRI Tractography",
      "mindmap": ""
    },
    {
      "title": "Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization",
      "authors": "Nikolaos Iliopoulos",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19986",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13f49f51d4e93dfaa76b5d85049c4b769868d3a8661c7cc58b3f721255548f39_w640_q70.webp",
      "contributions": "",
      "summary": "Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization",
      "mindmap": ""
    },
    {
      "title": "Self-motion as a structural prior for coherent and robust formation of cognitive maps",
      "authors": "Yingchao Yu, Pengfei Sun, Yaochu Jin, Kuangrong Hao, Hao Zhang, Yifeng Zhang, Wenxuan Pan, Wei Chen, Danyal Akarca, Yuchen Xiao",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20044",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73b00fb9e6496b8fed84e9b07a147285092862035b0b644359b32b6551253167_w640_q70.webp",
      "contributions": "",
      "summary": "Self-motion as a structural prior for coherent and robust formation of cognitive maps",
      "mindmap": ""
    },
    {
      "title": "Snapshot 3D image projection using a diffractive decoder",
      "authors": "Cagatay Isil, Alexander Chen, Yuhang Li, F. Onuralp Ardic, Shiqi Chen, Che-Yung Shen, Aydogan Ozcan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20464",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f05e75cf0d45d4f4a6b73b6c248e120e8372e756e8b025e6f78b8ce6098b183_w640_q70.webp",
      "contributions": "",
      "summary": "Snapshot 3D image projection using a diffractive decoder",
      "mindmap": ""
    },
    {
      "title": "Benchmarking metaheuristic algorithms for the bi-objective redundancy allocation problem in repairable systems with multiple strategies",
      "authors": "Mateusz Oszczypała, David Ibehej, Jakub Kudela",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18343",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/265909e0e39c1b7d97b0fb9c53cc263da8072c38b132bdcd7450963b18e38fa7_w640_q70.webp",
      "contributions": "",
      "summary": "Benchmarking metaheuristic algorithms for the bi-objective redundancy allocation problem in repairable systems with multiple strategies",
      "mindmap": ""
    },
    {
      "title": "Modality-Dependent Memory Mechanisms in Cross-Modal Neuromorphic Computing",
      "authors": "Effiong Blessing, Chiung-Yi Tseng, Somshubhra Roy, Junaid Rehman, Isaac Nkrumah",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18575",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab099f7e2d96fe21b9b811feaa87d815fe23feb7bea213071f724ebc69a87414_w640_q70.webp",
      "contributions": "",
      "summary": "Modality-Dependent Memory Mechanisms in Cross-Modal Neuromorphic Computing",
      "mindmap": ""
    },
    {
      "title": "Clustering-based Transfer Learning for Dynamic Multimodal MultiObjective Evolutionary Algorithm",
      "authors": "Li Yan, Bolun Liu, Chao Li, Jing Liang, Kunjie Yu, Caitong Yue, Xuzhao Chai, Boyang Qu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18947",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b46e7ee52db647b84d2f31cc7432f1e81dc459afc316c9b1daf014a0d4d28f5d_w640_q70.webp",
      "contributions": "",
      "summary": "Clustering-based Transfer Learning for Dynamic Multimodal MultiObjective Evolutionary Algorithm",
      "mindmap": ""
    },
    {
      "title": "Learning-Assisted Multi-Operator Variable Neighborhood Search for Urban Cable Routing",
      "authors": "Wei Liu, Tao Zhang, Chenhui Lin, Kaiwen Li, Rui Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19321",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c3d94e7990bf940cb4e587f12cfcbb0d8438eef591b7db89e5a77d7daec8f35d_w640_q70.webp",
      "contributions": "",
      "summary": "Learning-Assisted Multi-Operator Variable Neighborhood Search for Urban Cable Routing",
      "mindmap": ""
    },
    {
      "title": "Optimisation of Aircraft Maintenance Schedules",
      "authors": "Neil Urquhart, Amir Rahimi, Efstathios-Al. Tingas",
      "institution": "Edinburgh Napier University",
      "link": "https://arxiv.org/pdf/2512.17412",
      "code": null,
      "tags": [
        "evolutionary algorithms",
        "evolutionary algorithm",
        "genetic operators",
        "fitness function",
        "maintenance scheduling",
        "optimisation"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper applies an Evolutionary Algorithm to solve the aircraft maintenance scheduling problem, which involves assigning qualified staff to tasks within a turnaround window. The algorithm is benchmarked on 60 generated problem instances to evaluate its performance. The study demonstrates the proposed representation and genetic operators for this optimisation task.",
      "mindmap": ""
    },
    {
      "title": "Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning",
      "authors": "Javier Gonzalez-Ruiz, Carlos Rodriguez-Pardo, Iacopo Savelli, Alice Di Bella, Massimo Tavoni",
      "institution": "Politecnico di Milano, CMCC Foundation - Euro-Mediterranean Center on Climate Change, RFF-CMCC European Institute on Economics and the Environment, Bocconi University",
      "link": "https://arxiv.org/pdf/2512.17444",
      "code": null,
      "tags": [
        "others",
        "multi-agent reinforcement learning",
        "independent proximal policy optimization",
        "agent-based modeling",
        "electricity markets",
        "capacity markets",
        "contracts for difference"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a multi-agent reinforcement learning framework, using independent proximal policy optimization, to model investment decisions by generation companies in long-term electricity markets. The model is applied to a stylized Italian electricity system to test various market designs and policy scenarios. The results demonstrate that market design is critical for achieving decarbonization targets while mitigating price volatility.",
      "mindmap": ""
    },
    {
      "title": "PathBench-MIL: A Comprehensive AutoML and Benchmarking Framework for Multiple Instance Learning in Histopathology",
      "authors": "Siemen Brussee, Pieter A. Valkema, Jurre A. J. Weijer, Thom Doeleman, Anne M.R. Schrader, Jesper Kers",
      "institution": "Leiden University Medical Center, Utrecht University Medical Center, Amsterdam University Medical Center",
      "link": "https://arxiv.org/pdf/2512.17517",
      "code": null,
      "tags": [
        "others",
        "multiple instance learning",
        "AutoML",
        "feature extraction",
        "whole-slide images",
        "benchmarking",
        "computational pathology"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces PathBench-MIL, an automated machine learning and benchmarking framework designed for Multiple Instance Learning in histopathology. It automates the entire pipeline from preprocessing to model aggregation, enabling standardized and reproducible evaluation of various models and feature extractors on whole-slide image datasets. The main conclusion is that this open-source framework facilitates rapid experimentation and standardization in computational pathology research.",
      "mindmap": ""
    },
    {
      "title": "Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings",
      "authors": "Szymon Mazurek, Stephen Moore, Alessandro Crimi",
      "institution": "AGH University of Krakow, University of Cape Coast",
      "link": "https://arxiv.org/pdf/2507.15118",
      "code": null,
      "tags": [
        "others",
        "graph attention networks",
        "electroencephalography",
        "spatio-temporal graphs",
        "edge analysis",
        "low-cost hardware",
        "RaspberryPi"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d57b4723f1c065c80f840b86af58e96a683cea596741b961e8c90f8c5680da8_w640_q70.webp",
      "contributions": "",
      "summary": "The paper proposes a graph attention network (GAT) framework that models EEG signals as spatio-temporal graphs to detect epilepsy, with a focus on low-cost hardware for deployment in low-resource settings. The method adapts GATs to analyze edge connectivity for biomarker identification and is designed for lightweight training and deployment. The results demonstrate promising classification performance and highlight the potential for scalable, accessible diagnostic support in underserved regions.",
      "mindmap": ""
    },
    {
      "title": "Human-like Working Memory from Artificial Intrinsic Plasticity Neurons",
      "authors": "Jingli Liu, Huannan Zheng, Bohao Zou, Kezhou Yang",
      "institution": "The Hong Kong University of Science and Technology (Guangzhou)",
      "link": "https://arxiv.org/pdf/2512.15829",
      "code": null,
      "tags": [
        "others",
        "neuromorphic computing",
        "intrinsic plasticity",
        "Magnetic Tunnel Junctions (MTJs)",
        "hardware-software co-design",
        "near-sensor processing",
        "working memory"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces IPNet, a neuromorphic architecture that uses Magnetic Tunnel Junction (MTJ) neurons with intrinsic plasticity to physically emulate human-like working memory. The hardware-software co-designed system achieves high accuracy on dynamic vision tasks and significantly reduces energy consumption and footprint compared to traditional models like LSTMs. The work demonstrates that bio-inspired intrinsic plasticity can provide superior processing efficiency and performance for real-time applications.",
      "mindmap": ""
    },
    {
      "title": "Introduction to Symbolic Regression in the Physical Sciences",
      "authors": "Deaglan J. Bartlett, Harry Desmond, Pedro G. Ferreira, Gabriel Kronberger",
      "institution": "University of Oxford, University of Portsmouth, University of Applied Sciences Upper Austria",
      "link": "https://arxiv.org/pdf/2512.15920",
      "code": null,
      "tags": [
        "symbolic regression",
        "symbolic regression",
        "automated equation discovery",
        "effective theories",
        "surrogate models",
        "complexity control",
        "feature selection"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces symbolic regression (SR) as a method for discovering interpretable mathematical equations from data in the physical sciences. It reviews SR's foundations, applications, methodological considerations, and challenges. The authors conclude that SR is a rapidly advancing and increasingly relevant tool for scientific discovery and empirical modeling.",
      "mindmap": ""
    },
    {
      "title": "Explicit and Non-asymptotic Query Complexities of Rank-Based Zeroth-order Algorithms on Smooth Functions",
      "authors": "Haishan Ye",
      "institution": "Xi'an Jiaotong University",
      "link": "https://arxiv.org/pdf/2512.16200",
      "code": null,
      "tags": [
        "optimization theory",
        "rank-based zeroth-order optimization",
        "query complexity",
        "CMA-ES",
        "non-asymptotic analysis",
        "smooth functions"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper provides a theoretical analysis of a simple rank-based zeroth-order optimization algorithm, which selects search directions based on the ordering of function evaluations. It establishes the first explicit, non-asymptotic query complexities for finding solutions on smooth strongly convex and nonconvex functions. The main conclusion is that the algorithm achieves efficient convergence rates, offering new insight into why rank-based heuristics are effective for zeroth-order optimization.",
      "mindmap": ""
    },
    {
      "title": "Hypernetworks That Evolve Themselves",
      "authors": "Joachim Winther Pedersen, Erwan Plantec, Eleni Nisioti, Marcello Barylli, Milton Montero, Kathrin Korte, Sebastian Risi",
      "institution": "IT University of Copenhagen, Sakana AI",
      "link": "https://arxiv.org/pdf/2512.16406",
      "code": null,
      "tags": [
        "neuroevolution",
        "hypernetworks",
        "graph hypernetworks",
        "self-referential systems",
        "evolutionary algorithms",
        "adaptive mutation rates"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces Self-Referential Graph HyperNetworks, which embed evolutionary mechanisms like mutation and inheritance directly within neural networks, enabling them to evolve autonomously without external optimizers. The method demonstrates swift adaptation to environmental shifts and emergent population dynamics in reinforcement learning benchmarks, supporting the idea that evolvability can emerge from neural self-reference.",
      "mindmap": ""
    },
    {
      "title": "Topic Modelling Black Box Optimization",
      "authors": "Roman Akramov, Artem Khamatullin, Svetlana Glazyrina, Maksim Kryzhanovskiy, Roman Ischenko",
      "institution": "Lomonosov Moscow State University, Institute for Artificial Intelligence, Lomonosov Moscow State University",
      "link": "https://arxiv.org/pdf/2512.16445",
      "code": null,
      "tags": [
        "hyperparameter optimization",
        "latent dirichlet allocation",
        "black-box optimization",
        "genetic algorithm",
        "evolution strategy",
        "preferential amortized black-box optimization",
        "sharpness-aware black-box optimization"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper formulates selecting the number of topics in Latent Dirichlet Allocation (LDA) as a discrete black-box optimization problem. It compares evolutionary methods (GA, ES) against learned amortized optimizers (PABBO, SABBO), finding that the amortized approaches are substantially more sample- and time-efficient, with SABBO often finding a near-optimal topic number after essentially a single evaluation.",
      "mindmap": ""
    },
    {
      "title": "On the Universal Representation Property of Spiking Neural Networks",
      "authors": "Shayan Hundrieser, Philipp Tuchel, Insung Kong, Johannes Schmidt-Hieber",
      "institution": "University of Twente, Ruhr University Bochum",
      "link": "https://arxiv.org/pdf/2512.16872",
      "code": null,
      "tags": [
        "neuromorphic computing",
        "spiking neural networks",
        "universal approximation",
        "sequence-to-sequence processing",
        "spike train functions",
        "circuit complexity"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper analyzes the representational power of Spiking Neural Networks (SNNs) by modeling them as sequence-to-sequence processors of spike trains. It establishes a universal representation property for a class of spike train functions, with quantitative and near-optimal bounds on the required neurons and weights. The main conclusion is that SNNs are particularly well-suited for representing functions with few inputs, low temporal complexity, or compositions thereof, providing a foundation for understanding spike-based neuromorphic systems.",
      "mindmap": ""
    },
    {
      "title": "The Red Queen's Trap: Limits of Deep Evolution in High-Frequency Trading",
      "authors": "Yijia Chen",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.15732",
      "code": null,
      "tags": [
        "others",
        "deep reinforcement learning",
        "evolutionary computation",
        "LSTM",
        "Transformer",
        "genetic algorithm",
        "high-frequency trading",
        "multi-agent simulation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper analyzes the failure of a hybrid trading system called \"Galaxy Empire,\" which combines deep learning (LSTM/Transformer) for perception with evolutionary algorithms for agent survival in a high-frequency cryptocurrency market. Despite promising training results, the system suffered catastrophic live performance losses due to overfitting, survivor bias, and microstructure friction. The main conclusion is that increasing model complexity without true information asymmetry leads to systemic fragility in adaptive markets.",
      "mindmap": ""
    },
    {
      "title": "SGEMAS: A Self-Growing Ephemeral Multi-Agent System for Unsupervised Online Anomaly Detection via Entropic Homeostasis",
      "authors": "Mustapha Hamdi",
      "institution": "InnoDeep",
      "link": "https://arxiv.org/pdf/2512.14708",
      "code": null,
      "tags": [
        "others",
        "multi-agent system",
        "structural plasticity",
        "variational free energy",
        "metabolic lagrangian",
        "stochastic thermodynamics",
        "unsupervised anomaly detection"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces SGEMAS, a bio-inspired multi-agent system that uses agent birth/death and a variational free energy objective to achieve energy-efficient, unsupervised anomaly detection in physiological signals. It validates the approach on the MIT-BIH Arrhythmia Database, showing that this physics-based, energy-constrained model can detect anomalies in a zero-shot setting, outperforming a standard autoencoder baseline.",
      "mindmap": ""
    },
    {
      "title": "Offline Multi-Task Multi-Objective Data-Driven Evolutionary Algorithm with Language Surrogate Model and Implicit Q-Learning",
      "authors": "Xian-Rong Zhang, Yue-Jiao Gong, Zeyuan Ma, Jun Zhang",
      "institution": "South China University of Technology, Nankai University, Hanyang University",
      "link": "https://arxiv.org/pdf/2512.15149",
      "code": null,
      "tags": [
        "llm training",
        "surrogate modeling",
        "large language model",
        "sequence-to-sequence modeling",
        "offline training",
        "reinforcement learning fine-tuning",
        "implicit q-learning",
        "multi-task multi-objective optimization"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes Q-MetaSur, a plug-and-play surrogate modeling scheme that uses a Large Language Model as a sequence-to-sequence surrogate for offline multi-task multi-objective optimization, trained with a two-stage strategy combining supervised tuning and RL fine-tuning. The method demonstrates superior objective approximation accuracy and helps evolutionary algorithms achieve better convergence and Pareto optimality on benchmark problems.",
      "mindmap": ""
    }
  ]
}