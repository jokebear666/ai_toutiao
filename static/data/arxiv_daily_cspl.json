{
  "label": "cs.PL",
  "slug": "cspl",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "AInsteinBench: Benchmarking Coding Agents on Scientific Repositories",
      "authors": "Titouan Duston, Shuo Xin, Yang Sun, Daoguang Zan, Aoyan Li, Shulin Xin, Kai Shen, Yixiao Chen, Qiming Sun, Ge Zhang, Jiashuo Liu, Huan Zhou, Jingkai Liu, Zhichen Pu, Yuanheng Wang, Bo-Xuan Ge, Xin Tong, Fei Ye, Zhi-Chao Zhao, Wen-Biao Han, Zhoujian Cao, Yueran Zhao, Weiluo Ren, Qingshen Long, Yuxiao Liu, Anni Huang, Yidi Du, Yuanyuan Rong, Jiahao Peng",
      "institution": "ByteDance Seed, Princeton University",
      "link": "https://arxiv.org/pdf/2512.21373",
      "code": "https://github.com/ByteDance-Seed/AInsteinBench",
      "tags": [
        "software engineering",
        "benchmark",
        "scientific computing",
        "code generation",
        "pull requests",
        "test-driven verification"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp",
      "contributions": "1. Introduces a novel benchmark (AInsteinBench) for evaluating LLM agents in end-to-end scientific development using real-world, production-grade codebases. 2. Curates tasks from maintainer-authored pull requests across six diverse scientific domains, ensuring scientific challenge and calibrated difficulty. 3. Employs executable environments and test-driven verification to measure core competencies beyond surface-level code generation.",
      "summary": "The paper introduces AInsteinBench, a benchmark designed to evaluate LLM agents' ability to function as scientific computing developers by solving tasks derived from real pull requests in scientific repositories. It uses executable environments and test-driven verification to assess deeper competencies. The benchmark provides a new standard for measuring AI's role in computational scientific research.",
      "mindmap": "graph TB\n        A[AInsteinBench: Benchmarking Coding Agents on Scientific Repositories] --> B[核心问题/Problem: Can LLM agents operate as scientific computing development agents?]\n        A --> C[主要方法/Method: End-to-end evaluation using tasks from real scientific pull requests]\n        A --> D[关键结果/Results: Measures ability beyond surface-level code generation]"
    },
    {
      "title": "Quantitative Verification of Omega-regular Properties in Probabilistic Programming",
      "authors": "Peixin Wang, Jianhao Bai, Min Zhang, C.-H. Luke Ong",
      "institution": "East China Normal University, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.21596",
      "code": null,
      "tags": [
        "probabilistic programming and verification",
        "temporal posterior inference",
        "omega-regular properties",
        "stochastic barrier certificates",
        "Rabin automata",
        "quantitative verification"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c111a01f9d5e96a85d9b5c62645dae0f5bb40053d723e34cb57dc7f31554dcda_w640_q70.webp",
      "contributions": "1. Introduces Temporal Posterior Inference (TPI), a new framework unifying probabilistic programming with temporal logic to compute posterior distributions over execution traces satisfying omega-regular properties. 2. Develops a novel method for computing rigorous upper and lower bounds on satisfaction probabilities by decomposing Rabin acceptance conditions and constructing sound stochastic barrier certificates. 3. Implements the approach in a prototype tool named TPInfer and demonstrates its effectiveness and efficiency on a suite of benchmarks.",
      "summary": "This paper addresses the limitation of standard probabilistic program inference, which fails to capture temporal behavior, by proposing Temporal Posterior Inference (TPI). TPI computes posterior distributions over program traces that satisfy omega-regular temporal specifications, using a method based on stochastic barrier certificates to provide quantitative verification bounds. The approach is implemented in the TPInfer tool and shown to be effective for inference over rich temporal properties.",
      "mindmap": "graph TB\n        Root(”Quantitative Verification of Omega-regular Properties in Probabilistic Programming”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”标准后验推断的局限/Limitation of Standard Posterior Inference”)\n        P1 --> P2(”无法捕捉程序执行的时间演化/Fails to capture temporal evolution”)\n        Method --> M1(”提出时间后验推断框架/Propose Temporal Posterior Inference (TPI)”)\n        M1 --> M2(”统一概率编程与时序逻辑/Unifies Probabilistic Programming & Temporal Logic”)\n        M2 --> M3(”基于随机屏障证书的定量验证方法/Quantitative Verification via Stochastic Barrier Certificates”)\n        Results --> R1(”实现原型工具 TPInfer/Implement Prototype Tool TPInfer”)\n        Results --> R2(”在基准测试中展示有效性与效率/Demonstrates Effectiveness & Efficiency on Benchmarks”)"
    },
    {
      "title": "AutoBaxBuilder: Bootstrapping Code Security Benchmarking",
      "authors": "Tobias von Arx, Niels Mündler, Mark Vero, Maximilian Baader, Martin Vechev",
      "institution": "ETH Zurich, Snyk, INSAIT (Sofia University \"St. Kliment Ohridski\")",
      "link": "https://arxiv.org/pdf/2512.21132",
      "code": "https://github.com/eth-sri/autobaxbuilder",
      "tags": [
        "code security evaluation",
        "automated benchmarking",
        "LLM-generated code",
        "security vulnerabilities",
        "exploit generation",
        "plausibility checks"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/385abd6729afb970eba2217cc3d408efe70ab80f9d7aa0cbe7c2e0254f48b74c_w640_q70.webp",
      "contributions": "1. Introduces AutoBaxBuilder, a framework for generating code security benchmarking tasks and tests from scratch, addressing the limitations of manual benchmarks. 2. Proposes a robust pipeline with fine-grained plausibility checks that leverages LLMs to construct functionality tests and end-to-end security exploits. 3. Releases AutoBaxBench, a new benchmark of generated tasks, and demonstrates the framework's efficiency (under 2 hours and $10 per task) and quality through comparison with human-crafted tasks.",
      "summary": "The paper presents AutoBaxBuilder, a framework that automatically generates tasks and tests for benchmarking the security of code produced by large language models (LLMs). It uses an LLM-powered pipeline to create functional tests and security exploits, ensuring benchmark quality and scalability. The authors show the method is efficient and release a new benchmark, AutoBaxBench, to evaluate LLM security capabilities.",
      "mindmap": "graph LR\n    A[AutoBaxBuilder] --> B[核心问题/Problem: Manual security benchmarks are insufficient]\n    A --> C[主要方法/Method: Auto-generate tasks & tests with LLM pipeline]\n    A --> D[关键结果/Results: New benchmark, low cost, under 2 hours/task]"
    },
    {
      "title": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows",
      "authors": "Ivan Daunis",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19769",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e158baf642d33624c0967b1dcd509fbc3876a4bc52a539d4b6e7c800995b42_w640_q70.webp",
      "contributions": "",
      "summary": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows",
      "mindmap": ""
    },
    {
      "title": "Error Localization, Certificates, and Hints for Probabilistic Program Verification via Slicing (Extended Version)",
      "authors": "Philipp Schröer, Darion Haase, Joost-Pieter Katoen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20214",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69d3cbfad240346e5e410cac1825291c7eadf08769c78985ee6d4b0712429906_w640_q70.webp",
      "contributions": "",
      "summary": "Error Localization, Certificates, and Hints for Probabilistic Program Verification via Slicing (Extended Version)",
      "mindmap": ""
    },
    {
      "title": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs",
      "authors": "Narges Khakpour, Nicolas Berthier",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20396",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6bdfa1cdb9c42587497d38e68d6ea55a15a3372a5c197a241c9e2cf0c52caf1_w640_q70.webp",
      "contributions": "",
      "summary": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs",
      "mindmap": ""
    },
    {
      "title": "Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs",
      "authors": "Rupanshu Soi, Rohan Yadav, Fredrik Kjolstad, Alex Aiken, Maryam Mehri Dehnavi, Michael Garland, Michael Bauer",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18134",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cfd081b538bd7f4d1c91e06ba3fae36d2a230ad65cf3fc2e5160c3bdd9d98b3_w640_q70.webp",
      "contributions": "",
      "summary": "Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs",
      "mindmap": ""
    },
    {
      "title": "DafnyMPI: A Dafny Library for Verifying Message-Passing Concurrent Programs",
      "authors": "Aleksandr Fedchin, Antero Mejr, Hari Sundar, Jeffrey S. Foster",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18842",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/865d9d3085c35dc9683acc6a3733dcc32fd4a99cf1bb506d84b85aa30412cf3e_w640_q70.webp",
      "contributions": "",
      "summary": "DafnyMPI: A Dafny Library for Verifying Message-Passing Concurrent Programs",
      "mindmap": ""
    },
    {
      "title": "Small Language Models as Compiler Experts: Auto-Parallelization for Heterogeneous Systems",
      "authors": "Prathamesh Devadiga",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19250",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9992d696f5e075764c08a2b42f4505f7b8d093d1a3975265c2c2a7716a8fbcbc_w640_q70.webp",
      "contributions": "",
      "summary": "Small Language Models as Compiler Experts: Auto-Parallelization for Heterogeneous Systems",
      "mindmap": ""
    },
    {
      "title": "LOOPRAG: Enhancing Loop Transformation Optimization with Retrieval-Augmented Large Language Models",
      "authors": "Yijie Zhi, Yayu Cao, Jianhua Dai, Xiaoyang Han, Jingwen Pu, Qingran Wu, Sheng Cheng, Ming Cai",
      "institution": "Zhejiang University, Zhejiang Institute of Administration, Beijing ShenZhou Aerospace Software Technology Ltd.",
      "link": "https://arxiv.org/pdf/2512.15766",
      "code": null,
      "tags": [
        "llm inference",
        "retrieval-augmented generation",
        "loop transformation",
        "static control part",
        "feedback-based iterative mechanism",
        "equivalence checking"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes LOOPRAG, a retrieval-augmented generation framework that guides Large Language Models (LLMs) to perform effective loop transformation optimization. It uses a loop-aware retrieval algorithm and a feedback-based iterative mechanism with compilation and testing to generate correct and efficient code. The evaluation shows LOOPRAG achieves significant speedups over both traditional compilers and base LLMs on standard benchmark suites.",
      "mindmap": ""
    },
    {
      "title": "A Neurosymbolic Approach to Loop Invariant Generation via Weakest Precondition Reasoning",
      "authors": "Daragh King, Vasileios Koutavas, Laura Kovacs",
      "institution": "Trinity College Dublin, Lero, TU Wien",
      "link": "https://arxiv.org/pdf/2512.15816",
      "code": null,
      "tags": [
        "others",
        "Hoare logic",
        "weakest precondition reasoning",
        "neurosymbolic AI",
        "OpenJML",
        "counterexample-guided repair"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper presents NeuroInv, a neurosymbolic method for generating loop invariants that combines a neural module using LLMs and Hoare logic for backward-chaining weakest precondition reasoning with a symbolic module that iteratively repairs invariants using counterexamples from OpenJML. It achieves a 99.5% success rate on a benchmark of 150 Java programs and demonstrates scalability on complex multi-loop programs, substantially outperforming other approaches.",
      "mindmap": ""
    },
    {
      "title": "Optimizing Agentic Language Model Inference via Speculative Tool Calls",
      "authors": "Daniel Nichols, Prajwal Singhania, Charles Jekel, Abhinav Bhatele, Harshitha Menon",
      "institution": "Lawrence Livermore National Laboratory, University of Maryland",
      "link": "https://arxiv.org/pdf/2512.15834",
      "code": null,
      "tags": [
        "llm inference",
        "speculative tool calls",
        "tool cache",
        "vLLM",
        "prefix-caching"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces system optimizations for language model agents that use external tools, specifically by speculating future tool calls and keeping sequences resident in the inference engine to reduce overhead. These methods lead to significant throughput improvements of hundreds of tokens per second. The authors also propose a new \"tool cache\" API to facilitate adoption of these optimizations.",
      "mindmap": ""
    },
    {
      "title": "Sharing State Between Prompts and Programs",
      "authors": "Ellie Y. Cheng, Logan Weber, Tian Jin, Michael Carbin",
      "institution": "MIT CSAIL",
      "link": "https://arxiv.org/pdf/2512.14805",
      "code": null,
      "tags": [
        "llm inference",
        "natural language programming",
        "shared program state",
        "natural function interface",
        "interoperability",
        "Nightjar"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a programming abstraction called \"shared program state\" to enable seamless interoperability between natural language code (prompts) and formal program code (e.g., Python). It implements this abstraction in the Nightjar system, allowing natural code to directly read and write program variables. The results show that Nightjar programs can achieve higher task accuracy (+4-19%) and reduce lines of code by 39.6% on average, though with a runtime overhead of 0.4-4.3x compared to manual implementations.",
      "mindmap": ""
    }
  ]
}