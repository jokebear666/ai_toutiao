{
  "label": "cs.SE",
  "slug": "csse",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "Syntax Is Not Enough: An Empirical Study of Small Transformer Models for Neural Code Repair",
      "authors": "Shaunak Samant",
      "institution": "MIT World Peace University",
      "link": "https://arxiv.org/pdf/2512.22216",
      "code": null,
      "tags": [
        "automated program repair",
        "CodeT5",
        "syntax validity",
        "semantic correctness",
        "neural code repair",
        "transformer"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5b419b9d06731756aa85f1747cb55b61006764a0f1afdd4eef702af659daca2_w640_q70.webp",
      "contributions": "1. An empirical study demonstrating that a small transformer model (CodeT5-small) can achieve high syntactic correctness (94%) in code generation but fails to produce semantically correct repairs (0% exact match). 2. Identifies key failure factors: identifier abstraction removing semantic signals, cross-entropy training encouraging conservative copying, and insufficient model capacity for multi-step reasoning. 3. Argues that common evaluation metrics overestimate practical effectiveness and calls for future work to prioritize semantically informed datasets and execution-aware objectives.",
      "summary": "This study investigates whether a small transformer model can effectively repair Java bugs. The authors fine-tune CodeT5-small on bug-fix pairs and find that while it generates syntactically valid code 94% of the time, it fails to produce correct repairs, often just copying the buggy input. The conclusion is that syntactic correctness is not a reliable proxy for semantic correctness, highlighting a significant gap in neural code repair evaluation.",
      "mindmap": "graph TB\n        Root[”Syntax Is Not Enough: An Empirical Study of Small Transformer Models for Neural Code Repair<br/>论文标题”]\n        Root --> Problem[”核心问题/Problem<br/>Can small transformer models meaningfully repair real-world bugs? Is syntactic correctness a reliable proxy for semantic correctness?”]\n        Root --> Method[”主要方法/Method<br/>Fine-tune CodeT5-small on Java bug-fix pairs from CodeXGLUE. Evaluate token-level performance and syntactic validity using AST parsing.”]\n        Root --> Results[”关键结果/Results<br/>High syntax validity (94%) but zero correct repairs. Model copies buggy input 80% of the time. Syntax is not enough for semantic repair.”]"
    },
    {
      "title": "Failure Analysis of Safety Controllers in Autonomous Vehicles Under Object-Based LiDAR Attacks",
      "authors": "Daniyal Ganiuly, Nurzhau Bolatbek, Assel Smaiyl",
      "institution": "Astana IT University",
      "link": "https://arxiv.org/pdf/2512.22244",
      "code": null,
      "tags": [
        "autonomous vehicle security",
        "LiDAR attacks",
        "safety controllers",
        "adversarial perception",
        "cut-in scenarios",
        "time to collision"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f08729d3ab6d3cb95ef74d24b6a8c9504767e34a79b6a8ed3d819b7a0449654_w640_q70.webp",
      "contributions": "1. Presents a systematic failure analysis of longitudinal safety controllers under object-based LiDAR attacks in highway scenarios., 2. Demonstrates that short-duration LiDAR-induced object hallucinations can trigger unsafe braking, delayed hazard responses, and unstable control., 3. Shows that controller failures are more influenced by the temporal consistency of spoofed objects than by spatial inaccuracies alone.",
      "summary": "This paper analyzes how object-based LiDAR attacks impact the safety controllers of autonomous vehicles. Using a high-fidelity simulation framework, it evaluates attacks in highway scenarios and finds they can cause unsafe braking and delayed responses. The key conclusion is that temporal consistency of adversarial objects is a stronger driver of controller failure than spatial errors, revealing a gap between perception robustness and control-level safety.",
      "mindmap": "graph TB\n        Root[”Failure Analysis of Safety Controllers in Autonomous Vehicles Under Object-Based LiDAR Attacks”] --> Problem[”核心问题/Problem: Impact of LiDAR attacks on vehicle safety controllers is not well understood”]\n        Root --> Method[”主要方法/Method: High-fidelity simulation of attacks in cut-in and car-following scenarios”]\n        Root --> Results[”关键结果/Results: Attacks cause unsafe braking; failures depend more on temporal consistency than spatial accuracy”]"
    },
    {
      "title": "Hallucination Detection for LLM-based Text-to-SQL Generation via Two-Stage Metamorphic Testing",
      "authors": "Bo Yang, Yinfen Xia, Weisong Sun, Yang Liu",
      "institution": "Beijing Forestry University, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.22250",
      "code": null,
      "tags": [
        "software testing",
        "metamorphic testing",
        "hallucination detection",
        "text-to-sql",
        "large language models"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43979ca10fcd9708d38dc28b6f736979a5f93d12908536b02a9fbbaabdec599f_w640_q70.webp",
      "contributions": "1. Proposes SQLHD, a novel hallucination detection method for LLM-based Text-to-SQL that does not require ground-truth SQL answers. 2. Introduces a two-stage metamorphic testing framework with structure-aware and logic-aware metamorphic relations to detect schema-linking and logical-synthesis hallucinations separately. 3. Demonstrates superior performance over existing methods, including LLM self-evaluation, with F1-scores ranging from 69.36% to 82.76%.",
      "summary": "This paper addresses the challenge of detecting hallucinations in LLM-generated SQL queries without needing ground-truth data. It proposes SQLHD, a two-stage metamorphic testing method that uses structure-aware and logic-aware perturbations to cross-check model outputs. The method shows effective hallucination detection, outperforming baseline approaches.",
      "mindmap": "graph TB\n        A[Paper Title: Hallucination Detection for LLM-based Text-to-SQL Generation via Two-Stage Metamorphic Testing] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: LLM在Text-to-SQL中产生幻觉，难以检测且缺乏标准答案]\n        C[主要方法/Method: SQLHD - 两阶段蜕变测试，使用结构感知和逻辑感知的蜕变关系进行交叉检查]\n        D[关键结果/Results: F1分数69.36%至82.76%，性能优于LLM自评估方法]"
    },
    {
      "title": "Agentic Software Issue Resolution with Large Language Models: A Survey",
      "authors": "Zhonghao Jiang, David Lo, Zhongxin Liu",
      "institution": "Zhejiang University, Singapore Management University",
      "link": "https://arxiv.org/pdf/2512.22256",
      "code": "https://github.com/ZhonghaoJiang/Awesome-Issue-Solving",
      "tags": [
        "automated software maintenance",
        "large language models",
        "agentic systems",
        "software issue resolution",
        "reinforcement learning",
        "software engineering"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp",
      "contributions": "1. Provides a systematic survey of 126 recent studies on LLM-based agentic software issue resolution. 2. Establishes a taxonomy for the field across three key dimensions: benchmarks, techniques, and empirical studies. 3. Highlights the paradigm shift brought by agentic reinforcement learning in designing and training agentic systems for software engineering.",
      "summary": "This paper surveys the use of Large Language Model (LLM)-based agentic systems for automating complex software issue resolution, such as bug fixing. It reviews recent research, categorizes approaches, and discusses how agentic reinforcement learning is changing system design. The conclusion outlines current challenges and future research directions for improving automated software maintenance.",
      "mindmap": "graph TB\n        Root[Agentic Software Issue Resolution with LLMs: A Survey] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[传统方法依赖人工，效率低/Traditional methods rely on human expertise, inefficient]\n        Method[主要方法/Method] --> M1[基于LLM的智能体系统/LLM-based Agentic Systems]\n        Method --> M2[系统综述126项研究/Systematic survey of 126 studies]\n        Method --> M3[建立三维分类法/Establishes a 3D taxonomy]\n        Results[关键结果/Results] --> R1[增强软件维护效率/Enhances software maintenance efficiency]\n        Results --> R2[为智能体系统提供验证环境/Provides a validation environment for agentic systems]\n        Results --> R3[总结挑战与未来方向/Summarizes challenges & future directions]"
    },
    {
      "title": "AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents",
      "authors": "Bhanu Prakash Vangala, Ali Adibifar, Tanu Malik, Ashish Gehani",
      "institution": "University of Missouri, SRI International",
      "link": "https://arxiv.org/pdf/2512.22387",
      "code": null,
      "tags": [
        "agent system",
        "reproducibility",
        "dependency management",
        "code generation",
        "large language models",
        "empirical study"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp",
      "contributions": "1. Introduces a three-layer dependency framework (claimed, working, runtime) to quantify the execution reproducibility of LLM-generated code. 2. Conducts an empirical study evaluating three state-of-the-art LLM coding agents across 300 projects in three programming languages, revealing low out-of-the-box execution success rates. 3. Discovers a significant hidden dependency problem, with an average 13.5x expansion from declared to actual runtime dependencies.",
      "summary": "This paper investigates the reproducibility of code generated by LLM-based coding agents. It proposes a three-layer dependency framework and conducts an empirical study on 300 projects, finding that only 68.3% execute successfully out-of-the-box and that actual runtime dependencies are significantly larger than declared ones. The study concludes that AI-generated code currently suffers from major reproducibility issues due to dependency gaps and code generation errors.",
      "mindmap": "graph TB\n        Root[”AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents”] --> Problem[”核心问题/Problem: Is AI-generated code reproducible?”]\n        Root --> Method[”主要方法/Method: Empirical study using a three-layer dependency framework on 300 projects from 3 LLM agents.”]\n        Root --> Results[”关键结果/Results: Low out-of-the-box execution rate (68.3%) and large hidden dependencies (13.5x expansion).”]"
    },
    {
      "title": "Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection",
      "authors": "Quanzhi Fu, Qiyu Wu, Dan Williams",
      "institution": "Virginia Tech",
      "link": "https://arxiv.org/pdf/2512.22404",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent LLM framework",
        "knowledge gap detection",
        "student-AI dialogue analysis",
        "QueryQuilt",
        "educational technology"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/346f14200e9375ed815220f7c720c8952c5109e4bcf1c3f206a9c517e2f80947_w640_q70.webp",
      "contributions": "1. Proposes QueryQuilt, a novel multi-agent LLM framework for automated detection of common student knowledge gaps in large lectures. 2. Introduces a two-agent design: a Dialogue Agent that engages students with probing questions and a Knowledge Gap Identification Agent that analyzes chat logs. 3. Demonstrates the system's potential with high accuracy (100%) on simulated data and high completeness (95%) on real student-AI dialogue data.",
      "summary": "This paper proposes QueryQuilt, a multi-agent LLM framework that analyzes student-AI chat logs to automatically identify common knowledge gaps in large-scale lectures. The system uses a Dialogue Agent to interact with students and a Knowledge Gap Identification Agent to analyze the dialogues, providing instructors with insights into class-wide understanding. Initial evaluation shows promising accuracy and completeness, indicating its potential for improving teaching in real classroom environments.",
      "mindmap": "graph TB\n    A[Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[大班教学难以及时发现学生的知识缺口/Large lectures make timely knowledge gap identification challenging]\n    C --> C1[提出QueryQuilt: 一个多智能体LLM框架/Propose QueryQuilt: a multi-agent LLM framework]\n    C1 --> C2[对话智能体: 回答并探查学生问题/Dialogue Agent: responds and probes student questions]\n    C1 --> C3[知识缺口识别智能体: 分析对话识别共同缺口/Knowledge Gap Identification Agent: analyzes dialogues to identify common gaps]\n    D --> D1[模拟学生数据: 100%准确率/Simulated student data: 100% accuracy]\n    D --> D2[真实学生-AI对话数据: 95%完整性/Real student-AI dialogue data: 95% completeness]"
    },
    {
      "title": "Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding",
      "authors": "Yi-Hung Chou, Boyuan Jiang, Yi Wen Chen, Mingyue Weng, Victoria Jackson, Thomas Zimmermann, James A. Jones",
      "institution": "University of California, Irvine",
      "link": "https://arxiv.org/pdf/2512.22418",
      "code": null,
      "tags": [
        "human aspects of software engineering",
        "vibe coding",
        "large language models",
        "grounded theory",
        "prompt engineering",
        "software development practices"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eab8ec990fa93b887bf7f5945d43ce53b02d7e23a90f66d7421522c4fb50f07c_w640_q70.webp",
      "contributions": "1. Conducted a grounded theory study of \"vibe coding\" practices through analysis of 20 videos, providing empirical data on this emerging phenomenon. 2. Identified a spectrum of developer behaviors, from full reliance on AI without code inspection to active examination and adaptation of generated outputs. 3. Revealed that developers must contend with the stochastic nature of LLM generation, framing debugging as \"rolling the dice,\" and that divergent mental models influence prompting, evaluation, and trust.",
      "summary": "This paper investigates the emerging practice of \"vibe coding,\" where developers build software primarily by prompting LLMs. Through a qualitative grounded theory study of 20 videos, the research reveals a spectrum of developer behaviors and the central challenge of dealing with stochastic AI outputs, described as \"rolling the dice.\" The findings highlight how developers' mental models shape their interaction with AI and point to new research directions for the future of software engineering.",
      "mindmap": "graph TB\n        A[Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM驱动的”氛围编码”实践如何定义与进行?/How is LLM-driven ”vibe coding” defined and practiced?]\n        C --> C1[对20个视频进行扎根理论研究/Grounded theory study of 20 videos]\n        C --> C2[分析直播与观点视频/Analyze live-streamed & opinion videos]\n        D --> D1[行为谱系: 从完全依赖到检查适配/Spectrum of behaviors: from full reliance to inspection & adaptation]\n        D --> D2[核心挑战: 生成的随机性/”掷骰子”/Core challenge: stochastic generation / ”rolling the dice”]\n        D --> D3[心智模型影响策略与信任/Mental models influence strategies & trust]"
    },
    {
      "title": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization",
      "authors": "Wei Liu, Chao Peng, Pengfei Gao, Aofan Liu, Wei Zhang, Haiyan Zhao, Zhi Jin",
      "institution": "Peking University, Bytedance",
      "link": "https://arxiv.org/pdf/2512.22469",
      "code": null,
      "tags": [
        "issue localization",
        "causal issue graph",
        "dynamic issue disentangling",
        "symptom-to-cause mismatch",
        "one-to-many mismatch"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7dff9ac90f028731aa3b3d082126f3d3de229d3c53b61e302fd7d16eba1e084_w640_q70.webp",
      "contributions": "1. Proposes GraphLocator, an LLM-based approach for issue localization that addresses the semantic gap between issue descriptions and code. 2. Introduces the Causal Issue Graph (CIG) to model sub-issues and their causal dependencies, mitigating symptom-to-cause and one-to-many mismatches. 3. Demonstrates significant performance improvements in localization accuracy and downstream task performance through a two-phase workflow of symptom locating and dynamic graph discovery.",
      "summary": "This paper tackles the challenge of automatically localizing code that needs to be changed based on a natural language issue description. It proposes GraphLocator, a method that constructs a Causal Issue Graph to reason about underlying sub-issues and their dependencies, effectively bridging the semantic gap. Experiments show it significantly outperforms baselines in both recall and precision for issue localization.",
      "mindmap": "graph TB\n        A[GraphLocator: Graph-guided Causal Reasoning for Issue Localization] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[语义鸿沟/Semantic Gap]\n        B1 --> B2[症状-原因不匹配/Symptom-to-Cause Mismatch]\n        B1 --> B3[一对多不匹配/One-to-Many Mismatch]\n        C --> C1[因果问题图/Causal Issue Graph (CIG)]\n        C --> C2[两阶段工作流/Two-Phase Workflow]\n        C2 --> C3[症状定位/Symptom Vertices Locating]\n        C2 --> C4[动态图发现/Dynamic CIG Discovering]\n        D --> D1[定位更准确/More Accurate Localization]\n        D1 --> D2[召回率提升 +19.49%/Recall +19.49%]\n        D1 --> D3[精确率提升 +11.89%/Precision +11.89%]\n        D --> D4[下游任务性能提升/Downstream Task Improvement]\n        D4 --> D5[性能提升 +28.74%/Performance +28.74%]"
    },
    {
      "title": "Isolating Compiler Faults via Multiple Pairs of Adversarial Compilation Configurations",
      "authors": "Qingyang Li, Yibiao Yang, Maolin Sun, Jiangchang Wu, Qingkai Shi, Yuming Zhou",
      "institution": "State Key Laboratory for Novel Software Technology, Nanjing University, China",
      "link": "https://arxiv.org/pdf/2512.22538",
      "code": null,
      "tags": [
        "compiler & ir",
        "compiler fault localization",
        "adversarial compilation configurations",
        "spectrum-based fault localization (SBFL)",
        "weighted voting",
        "GCC bugs"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/437f9126029a1a7c1875bde92aa42b0d549a6a8a506d4dcc1135cf46b3380620_w640_q70.webp",
      "contributions": "1. Proposes MultiConf, a novel approach that automatically isolates compiler faults by constructing multiple pairs of adversarial compilation configurations (failing and passing). 2. Introduces a lightweight process to generate failing configurations and derives passing ones by selectively disabling bug-related fine-grained options. 3. Employs an SBFL formula and a weighted voting scheme to aggregate rankings from multiple configuration pairs, achieving more accurate and robust fault localization.",
      "summary": "The paper addresses the challenge of localizing faults in complex compilers by proposing MultiConf, a method that uses multiple pairs of adversarial compilation configurations and a weighted voting scheme to rank suspicious source files. Evaluated on 60 real GCC bugs, MultiConf significantly outperforms existing techniques, localizing 27 bugs at the Top-1 file level.",
      "mindmap": "graph TB\n        A[Isolating Compiler Faults via Multiple Pairs of Adversarial Compilation Configurations<br>基于多对抗编译配置对的编译器故障隔离] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Compiler fault localization is challenging due to complexity.<br>编译器故障定位因复杂性而极具挑战] --> B1[Prior methods are costly and unstable.<br>现有方法成本高且不稳定]\n        C[主要方法/Method<br>MultiConf: Constructs multiple adversarial configuration pairs.<br>构建多对抗配置对] --> C1[Generates failing & passing configs with fine-grained options.<br>生成细粒度选项的失败与通过配置]\n        C --> C2[Uses SBFL and weighted voting for ranking.<br>使用SBFL和加权投票进行排序]\n        D[关键结果/Results<br>Evaluation on 60 GCC bugs.<br>在60个GCC缺陷上评估] --> D1[Localizes 27 bugs at Top-1, outperforming state-of-the-art.<br>在Top-1定位27个缺陷，优于现有技术]"
    },
    {
      "title": "Rethinking the Capability of Fine-Tuned Language Models for Automated Vulnerability Repair",
      "authors": "Woorim Han, Yeongjun Kwak, Miseon Yu, Kyeongmin Kim, Younghan Lee, Hyungon Moon, Yunheung Paek",
      "institution": "Seoul National University, UNIST (Ulsan National Institute of Science and Technology), Sungshin Women’s University",
      "link": "https://arxiv.org/pdf/2512.22633",
      "code": null,
      "tags": [
        "automated program repair",
        "automated vulnerability repair",
        "fine-tuned language models",
        "test-based evaluation",
        "semantic-preserving transformations",
        "generalization"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d770d836cf9a18ac948b50e2b265b8ff346227d4dd0f8e12930e2897a03429f4_w640_q70.webp",
      "contributions": "1. Introduces semantic-preserving transformations to test sets to assess if models learn robust patterns or spurious features. 2. Re-splits datasets to be mutually exclusive to properly evaluate model generalization on unseen vulnerabilities. 3. Proposes L-AVRBench, a test-based benchmark, to overcome the limitations of token-level match-based evaluation metrics.",
      "summary": "This paper critically examines the capabilities of fine-tuned language models for automated vulnerability repair (AVR). It finds that state-of-the-art models often overfit and are evaluated on non-exclusive data splits using inadequate metrics. To address this, the authors propose methods to test robustness and generalization, and introduce a new test-based benchmark (L-AVRBench) to better assess true repair capability.",
      "mindmap": "graph TB\n        A[论文标题: Rethinking the Capability of Fine-Tuned Language Models for Automated Vulnerability Repair] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[模型过拟合 & 评估集非互斥/Models Overfit & Non-exclusive Evaluation Sets]\n        B --> B2[基于匹配的评估指标有局限/Match-based Metrics are Limited]\n        C --> C1[应用语义保持变换/Apply Semantic-preserving Transformations]\n        C --> C2[重新划分互斥的数据集/Re-split Mutually Exclusive Datasets]\n        C --> C3[引入测试基准 L-AVRBench/Introduce Test-based Benchmark L-AVRBench]\n        D --> D1[揭示模型泛化能力不足/Revealed Insufficient Model Generalization]\n        D --> D2[提出了更鲁棒的评估框架/Proposed a More Robust Evaluation Framework]"
    },
    {
      "title": "CFIghter: Automated Control-Flow Integrity Enablement and Evaluation for Legacy C/C++ Systems",
      "authors": "Sabine Houy, Bruno Kreyssig, Alexandre Bartel",
      "institution": "Umeå University",
      "link": "https://arxiv.org/pdf/2512.22701",
      "code": null,
      "tags": [
        "control-flow integrity",
        "control-flow integrity",
        "compiler-based security",
        "automated repair",
        "legacy systems",
        "runtime monitoring"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/436657782d1936c221bd69d6fb671fff796d4c4a2db996690bbe0d6bea5a3b55_w640_q70.webp",
      "contributions": "1. Presents CFIghter, the first fully automated system for enabling strict, type-based CFI in real-world C/C++ projects by detecting, classifying, and repairing unintended policy violations. 2. Integrates whole-program analysis with guided runtime monitoring to iteratively apply minimal adjustments to CFI enforcement only where required. 3. Demonstrates high effectiveness by automatically repairing 95.8% of unintended CFI violations in a large codebase while retaining strict enforcement at over 89% of indirect control-flow sites, showing automated repair makes strict CFI practically deployable.",
      "summary": "The paper addresses the challenge of deploying compiler-based Control-Flow Integrity (CFI) in large legacy C/C++ systems due to semantic mismatches that cause runtime crashes. It proposes CFIghter, an automated system that uses whole-program analysis and runtime monitoring to detect and repair these unintended violations, requiring minimal manual changes. The evaluation shows CFIghter successfully resolves most violations in real-world projects, making strict CFI practically deployable for mature software.",
      "mindmap": "graph TB\n        A[CFIghter: Automated Control-Flow Integrity Enablement and Evaluation for Legacy C/C++ Systems] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[CFI部署困难/CFI Deployment Challenges]\n        B1 --> B2[语义不匹配导致崩溃/Semantic Mismatch Causes Crashes]\n        C --> C1[自动化系统/Automated System]\n        C1 --> C2[检测与修复/Detection & Repair]\n        C2 --> C3[最小调整/Minimal Adjustments]\n        D --> D1[高修复率/High Repair Rate]\n        D1 --> D2[95.8% 违规修复/95.8% Violations Repaired]\n        D --> D3[严格CFI保留/Strict CFI Retained]\n        D3 --> D4[>89% 站点/>89% of Sites]"
    },
    {
      "title": "From Rookie to Expert: Manipulating LLMs for Automated Vulnerability Exploitation in Enterprise Software",
      "authors": "Moustapha Awwalou Diouf, Maimouna Tamah Diao, Iyiola Emmanuel Olatunji, Abdoul Kader Kaboré, Jordan Samhi, Gervais Mendy, Samuel Ouya, Jacques Klein, Tegawendé F. Bissyandé",
      "institution": "University of Luxembourg",
      "link": "https://arxiv.org/pdf/2512.22753",
      "code": "https://anonymous.4open.science/r/From-Rookie-to-Attacker-D8B3",
      "tags": [
        "vulnerability exploitation",
        "LLM",
        "social engineering",
        "pretexting",
        "Odoo ERP",
        "RSA"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9fa715a252b1e75790a16c013941796c349d193dcd31101439954451a3b63bf5_w640_q70.webp",
      "contributions": "1. Proposes RSA (Role-assignment, Scenario-pretexting, and Action-solicitation), a novel pretexting strategy to manipulate LLMs into generating functional exploits. 2. Demonstrates a 100% success rate in generating working exploits for tested CVEs against the Odoo ERP platform using five mainstream LLMs within 3-4 prompting rounds. 3. Shows that LLMs can eliminate the manual effort previously required for LLM-assisted attacks, fundamentally challenging core security principles about technical expertise and threat modeling.",
      "summary": "This paper demonstrates how publicly available Large Language Models (LLMs) can be manipulated through a social engineering strategy called RSA to automatically generate functional software exploits, effectively enabling novices to become capable attackers. The method achieved a 100% success rate against a popular enterprise platform, showing that exploitation no longer requires deep technical expertise but only the ability to craft prompts. This finding invalidates traditional security assumptions and signals a paradigm shift requiring redesigned security practices.",
      "mindmap": "graph TB\n        A[From Rookie to Expert: Manipulating LLMs for Automated Vulnerability Exploitation in Enterprise Software] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs的普及颠覆了软件安全的基本假设 / LLMs democratize access, undermining security assumptions]\n        C --> C1[提出RSA策略:角色分配、场景预设、行动诱导 / Propose RSA: Role-assignment, Scenario-pretexting, Action-solicitation]\n        D --> D1[在Odoo ERP上对5个主流LLM测试成功率达100% / 100% success rate on Odoo with 5 LLMs]\n        D --> D2[攻击无需专业知识，仅需提示工程 / Exploitation requires prompting, not coding expertise]"
    },
    {
      "title": "FasterPy: An LLM-based Code Execution Efficiency Optimization Framework",
      "authors": "Yue Wu, Minghao Han, Ruiyin Li, Peng Liang, Amjed Tahir, Zengyang Li, Qiong Feng, Mojtaba Shahin",
      "institution": "Wuhan University, Carnegie Mellon University, Massey University, Central China Normal University, Nanjing University of Science and Technology, RMIT University",
      "link": "https://arxiv.org/pdf/2512.22827",
      "code": "https://github.com/WuYue22/fasterpy",
      "tags": [
        "rag (retrieval-augmented generation)",
        "Code Optimization",
        "Retrieval-Augmented Generation (RAG)",
        "Low-Rank Adaptation (LoRA)",
        "Large Language Models (LLMs)",
        "Python"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49aae1b7cd12cfd30401a619c9b06d4bccc853d1d14eed57af87eb6c80858f31_w640_q70.webp",
      "contributions": "1. Proposes FasterPy, a low-cost and efficient framework that adapts LLMs for Python code execution efficiency optimization. 2. Combines Retrieval-Augmented Generation (RAG) with a knowledge base of performance-improving code pairs and Low-Rank Adaptation (LoRA) to enhance optimization performance. 3. Demonstrates superior performance over existing models on the Performance Improving Code Edits (PIE) benchmark.",
      "summary": "This paper introduces FasterPy, a framework that uses Large Language Models (LLMs) enhanced with Retrieval-Augmented Generation (RAG) and Low-Rank Adaptation (LoRA) to automatically optimize Python code for better execution efficiency. It addresses the limitations of traditional rule-based and data-intensive ML methods by providing a more scalable and cost-effective solution. Experimental results show that FasterPy outperforms existing models on standard benchmarks.",
      "mindmap": "graph TB\n        A[FasterPy: An LLM-based Code Execution Efficiency Optimization Framework] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[传统方法成本高，可扩展性差/Traditional methods are costly and hard to scale]\n        C --> C1[结合RAG与LoRA的LLM框架/LLM framework combining RAG and LoRA]\n        D --> D1[在PIE基准上表现优异/Outperforms existing models on PIE benchmark]"
    },
    {
      "title": "Towards the analysis of team members well-being",
      "authors": "Zan Xu, Sari Nurfauziyyah, Anastasia Romanova, Kaamesh G S, Yiqun Gao, Maria Spichkova",
      "institution": "RMIT University",
      "link": "https://arxiv.org/pdf/2512.22845",
      "code": null,
      "tags": [
        "software development team well-being",
        "well-being",
        "software development",
        "team members",
        "positive feedback",
        "prototype"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44b6ecf51f08897fa2d6ed662014dae0fe49b0c593bf9e815394b288ffd9d465_w640_q70.webp",
      "contributions": "1. Presents the results of a project focused on analyzing the well-being of software development team members. 2. Identifies the feeling of being appreciated and acknowledged as a critical factor for team member well-being. 3. Describes the development of a prototype tool-supported framework aimed at providing personalized positive feedback without creating significant additional workload.",
      "summary": "This paper addresses the growing concern for the well-being of software development team members, emphasizing the importance of feeling appreciated. It presents a project that developed a prototype for a tool-supported, personalized framework to provide positive feedback. The goal is to improve well-being without adding substantial extra work for team members.",
      "mindmap": "graph TB\n        A[Towards the analysis of team members well-being] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[软件团队成员幸福感/Software Team Member Well-being]\n        B1 --> B2[关键因素：被赞赏与认可/Critical Factor: Feeling Appreciated & Acknowledged]\n        C --> C1[项目分析与原型开发/Project Analysis & Prototype Development]\n        D --> D1[提出工具支持的个性化框架/Proposed Tool-supported Personalized Framework]"
    },
    {
      "title": "Interpretable Gallbladder Ultrasound Diagnosis: A Lightweight Web-Mobile Software Platform with Real-Time XAI",
      "authors": "Fuyad Hasan Bhoyan, Prashanta Sarker, Parsia Noor Ethila, Md. Emon Hossain, Md Kaviul Hossain, Md Humaion Kabir Mehedi",
      "institution": "University of Liberal Arts Bangladesh, BRAC University",
      "link": "https://arxiv.org/pdf/2512.23033",
      "code": null,
      "tags": [
        "medical image classification",
        "MobResTaNet",
        "Explainable AI (XAI)",
        "lightweight model",
        "ultrasound diagnosis",
        "web-mobile platform"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c6a6693ffd9f4375cd5a781c2544fba169bc30bc3cbb7590b1562ea78ba6678_w640_q70.webp",
      "contributions": "1. Proposed a hybrid deep learning model (MobResTaNet) for classifying ten gallbladder conditions from ultrasound images with high accuracy (99.85%) and low parameter count (2.24M). 2. Developed an interpretable diagnostic system with real-time Explainable AI (XAI) visualizations to support transparent clinical decision-making. 3. Deployed the system as an efficient and accessible web-mobile software platform using technologies like HTML, CSS, JavaScript, Bootstrap, and Flutter for point-of-care use.",
      "summary": "This paper addresses the challenge of interpreting gallbladder ultrasound images by developing an AI-driven diagnostic software. The core method is a lightweight hybrid deep learning model called MobResTaNet, which classifies diseases and provides real-time, interpretable predictions via XAI. The main conclusion is that the system achieves high accuracy with a small model size and is successfully deployed as accessible web and mobile applications for clinical support.",
      "mindmap": "graph TB\n        A[Interpretable Gallbladder Ultrasound Diagnosis] --> B[核心问题/Problem: Challenging ultrasound interpretation for gallbladder diseases]\n        A --> C[主要方法/Method: AI software with lightweight MobResTaNet model & real-time XAI]\n        A --> D[关键结果/Results: 99.85% accuracy, 2.24M parameters, deployed web-mobile platform]"
    },
    {
      "title": "An Architecture-Led Hybrid Report on Body Language Detection Project",
      "authors": "Thomson Tong, Diba Darooneh",
      "institution": "None",
      "link": "https://arxiv.org/pdf/2512.23028",
      "code": "BodyLanguageDetection",
      "tags": [
        "video understanding",
        "vision-language models",
        "structured generation",
        "bounding boxes",
        "mixture-of-experts",
        "video analysis"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a618c048bc336ad2ade96a7a97cf301fb10fee2c9c8e7bc16556348f1c0c4b9d_w640_q70.webp",
      "contributions": "1. Provides an architecture-led analysis of two modern VLMs (Qwen2.5-VL-7B-Instruct and Llama-4-Scout-17B-16E-Instruct) for a practical task. 2. Maps model architectural properties to a concrete video-to-artifact pipeline for person detection and attribute extraction. 3. Explicitly defines and analyzes critical system constraints and limitations arising from model behavior, such as semantic vs. syntactic correctness and frame-local identifiers.",
      "summary": "This report analyzes two vision-language models (VLMs) and connects their architectures to a practical system for detecting people and their emotions in video frames. The system prompts VLMs to generate structured outputs like bounding boxes, validates the output structure, and can render annotated videos. The core conclusion is that understanding model architecture is crucial for designing robust interfaces and making defensible claims, as VLMs can produce syntactically correct but semantically incorrect outputs.",
      "mindmap": "graph TB\n        A[An Architecture-Led Hybrid Report on Body Language Detection Project] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[如何基于VLM架构构建可靠的应用系统/How to build reliable application systems based on VLM architecture]\n        C --> C1[分析两种VLM架构并映射到视频处理流程/Analyze two VLM architectures and map to a video processing pipeline]\n        C --> C2[系统采样视频帧，提示VLM生成结构化输出/System samples video frames, prompts VLM for structured output]\n        C --> C3[使用预定义模式验证输出结构/Validate output structure with predefined schema]\n        D --> D1[结构化输出可能语法正确但语义错误/Structured outputs can be syntactically valid but semantically incorrect]\n        D --> D2[模式验证是结构性的，非几何正确性/Schema validation is structural, not geometric]\n        D --> D3[理解架构对设计稳健接口和评估至关重要/Understanding architecture is critical for robust interface design and evaluation]"
    },
    {
      "title": "Reimagining the Traditional Flight Computer: E6BJA as a Modern, Multi-Platform Tool for Flight Calculations and Training",
      "authors": "Jamie J. Alnasir",
      "institution": "None (Inferred from author's email domain: al-nasir.com, which appears to be a personal domain)",
      "link": "https://arxiv.org/pdf/2512.23055",
      "code": null,
      "tags": [
        "human-computer interaction",
        "flight computer",
        "multi-platform software",
        "aviation training",
        "educational monographs",
        "weight and balance"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/728f903c57bf352d1339c863c7cb1986de9a626a56f8a15516317cf7068bcb83_w640_q70.webp",
      "contributions": "1. Development of E6BJA, a modern, multi-platform (iOS, Android, Windows, web) software flight computer that replicates and extends traditional flight calculations. 2. Integration of enhanced modeling capabilities (e.g., 1976 International Standard Atmosphere, carburetor icing risk) and aircraft-specific calculators with embedded educational explanations. 3. A comparative analysis demonstrating the tool's improvements over traditional devices in accuracy, error reduction, discoverability, and educational value for pilot training.",
      "summary": "This paper addresses the limitations of traditional mechanical and electronic flight computers by proposing E6BJA, a modern multi-platform software tool. E6BJA replicates core flight calculations while adding enhanced models and embedded educational content. The work concludes that this approach represents a meaningful evolution in pilot tools, improving safety, intuition, and instructional value in aviation training contexts.",
      "mindmap": "graph TB\n        Root(”Reimagining the Traditional Flight Computer”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”传统飞行计算机的局限性/Limitations of Traditional Flight Computers”)\n        Method --> M1(”开发多平台软件E6BJA/Develop Multi-Platform Software E6BJA”)\n        Method --> M2(”扩展计算与教育功能/Extend Calculations & Educational Features”)\n        Results --> R1(”证明在准确性等方面的改进/Demonstrate Improvements in Accuracy, etc.”)\n        Results --> R2(”支持更安全的飞行规划/Support Safer Flight Planning”)"
    },
    {
      "title": "An Automated Grey Literature Extraction Tool for Software Engineering",
      "authors": "Houcine Abdelkader Cherief, Brahim Mahmoudi, Zacharie Chenail-Larcher, Naouel Moha, Quentin Sti'evenart, Florent Avellaneda",
      "institution": "École de technologie supérieure, Université du Québec à Montréal",
      "link": "https://arxiv.org/pdf/2512.23066",
      "code": null,
      "tags": [
        "grey literature extraction",
        "grey literature",
        "semantic classifier",
        "embedding",
        "reproducibility",
        "prompt-driven"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcd8d541170e102d077ea8b0f0d18f0b4d898d754f2e5dea87a8696f74de7b5c_w640_q70.webp",
      "contributions": "1. The GLiSE tool, a prompt-driven system for automated grey literature extraction from heterogeneous web sources. 2. A curated dataset of software engineering grey-literature search results classified by semantic relevance. 3. An empirical study evaluating the usability of the proposed tool.",
      "summary": "The paper addresses the difficulty of collecting and assessing grey literature in software engineering at scale due to heterogeneous sources and formats. It proposes GLiSE, a prompt-driven tool that generates platform-specific queries, gathers results from sources like GitHub and Stack Overflow, and uses embedding-based semantic classifiers to filter and rank results for relevance. The tool is designed for reproducibility and its usability is empirically evaluated.",
      "mindmap": "graph TB\n        A[An Automated Grey Literature Extraction Tool for Software Engineering] --> B[核心问题/Problem: 收集和评估软件工程灰文献困难/Difficulty in collecting and assessing software engineering grey literature at scale]\n        A --> C[主要方法/Method: GLiSE工具, 提示驱动, 嵌入语义分类器/GLiSE tool, prompt-driven, embedding-based semantic classifier]\n        A --> D[关键结果/Results: 提供工具、数据集和可用性研究/Provides tool, curated dataset, and usability study]"
    },
    {
      "title": "Anka: A Domain-Specific Language for Reliable LLM Code Generation",
      "authors": "Saif Khalfan Saif Al Mazrouei",
      "institution": "University of Wisconsin-Madison",
      "link": "https://arxiv.org/pdf/2512.23214",
      "code": null,
      "tags": [
        "llm inference",
        "Domain-Specific Language",
        "Constrained Syntax",
        "Code Generation",
        "Data Transformation Pipeline",
        "In-Context Learning"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e450f3b6354a05c4c0dfa0c22c4f8b8dfc33c08282380080deb2d2f3a335d4_w640_q70.webp",
      "contributions": "1. Introduced Anka, a domain-specific language (DSL) with explicit, constrained syntax designed to reduce ambiguity in LLM code generation. 2. Demonstrated that LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy without prior training. 3. Showed that purposefully designed DSLs can outperform general-purpose languages (e.g., Python) on complex multi-step tasks, significantly reducing errors in operation sequencing and state management.",
      "summary": "This paper hypothesizes that the flexibility of general-purpose languages leads to systematic errors in LLM code generation for complex tasks. To test this, it introduces Anka, a constrained DSL for data transformation pipelines. The results show that LLMs can learn Anka from prompts and achieve significantly higher accuracy on multi-step tasks compared to Python, demonstrating the advantage of constrained syntax for reliable code generation.",
      "mindmap": "graph TB\n        A[Anka: A Domain-Specific Language for Reliable LLM Code Generation] --> B[核心问题/Problem: LLMs make systematic errors in complex multi-step code generation]\n        A --> C[主要方法/Method: Design Anka, a constrained DSL for data transformation pipelines]\n        A --> D[关键结果/Results: High parse success & task accuracy; Anka outperforms Python on multi-step tasks]"
    },
    {
      "title": "An Empirical Study of Generative AI Adoption in Software Engineering",
      "authors": "Görkem Giray, Onur Demirörs, Marcos Kalinowski, Daniel Mendez",
      "institution": "Eindhoven University of Technology, Izmir Institute of Technology, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Blekinge Institute of Technology, fortiss",
      "link": "https://arxiv.org/pdf/2512.23327",
      "code": null,
      "tags": [
        "AI4SE",
        "Generative AI",
        "Software Engineering",
        "Empirical Study",
        "Survey",
        "Adoption"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45dc246f8337bce98d95170e37ed6c405c343b51bb32f568d576b057edc61ed3_w640_q70.webp",
      "contributions": "1. Provides an empirical overview of the current status of Generative AI adoption in software engineering practice. 2. Identifies and categorizes the key benefits, challenges, and organizational institutionalization patterns associated with GenAI use. 3. Investigates and reports on the anticipated long-term impacts of GenAI on the roles and job market for software engineering professionals.",
      "summary": "This paper conducts an international survey of 204 software engineering practitioners to empirically study the adoption of Generative AI tools. The results show widespread integration into daily tasks with reported benefits in productivity and quality, but also highlight persistent challenges like unreliable outputs and security concerns. The study concludes that a move from ad-hoc to systematic approaches is needed for sustainable and responsible GenAI integration in software engineering.",
      "mindmap": "graph TB\n        Root[An Empirical Study of Generative AI Adoption in Software Engineering] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[缺乏GenAI在SE中实际应用的实证证据/Lack of empirical evidence on practical GenAI use in SE]\n        Method[主要方法/Method] --> M1[国际问卷调查/Internationally distributed questionnaire survey]\n        Results[关键结果/Results] --> R1[广泛采用与深度集成/Wide adoption & deep integration]\n        Results --> R2[显著收益与持续挑战/Substantial benefits & persistent challenges]\n        Results --> R3[角色重定义而非替代/Role redefinition, not replacement]"
    },
    {
      "title": "Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?",
      "authors": "Anh Nguyen, Triet Huynh Minh Le, M. Ali Babar",
      "institution": "University of Adelaide",
      "link": "https://arxiv.org/pdf/2512.23385",
      "code": null,
      "tags": [
        "AI Security",
        "AI supply chain",
        "security taxonomy",
        "distilBERT classifier"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp",
      "contributions": "1. Developed a pipeline combining keyword matching with a fine-tuned distilBERT classifier to identify 312,868 security discussions from Hugging Face and GitHub. 2. Conducted a thematic analysis to create a fine-grained taxonomy of 32 security issues and 24 solutions across four themes (System/Software, External Tools/Ecosystem, Model, Data). 3. Provided empirical insights revealing that security issues stem from complex dependencies and black-box AI components, with Model and Data challenges often lacking concrete solutions.",
      "summary": "This paper investigates security issues in the AI supply chain by analyzing developer discussions from Hugging Face and GitHub. The authors use a keyword and classifier pipeline to build a large dataset and perform a thematic analysis to create a taxonomy of issues and solutions. They conclude that many security problems arise from dependencies and the black-box nature of AI, with solutions for Model and Data issues being particularly scarce.",
      "mindmap": "graph TB\n        Root[Securing the AI Supply Chain] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[AI供应链安全格局复杂/Complex AI supply chain security landscape]\n        Problem --> P2[缺乏对常见问题与解决方案的了解/Lack of knowledge on common issues & solutions]\n        Method[主要方法/Method] --> M1[实证调查/Empirical investigation]\n        M1 --> M1_1[数据源: Hugging Face, GitHub/Data Sources: Hugging Face, GitHub]\n        M1 --> M1_2[构建分类管道/Build classification pipeline]\n        M1_2 --> M1_2_1[关键词匹配+微调distilBERT/Keyword matching + fine-tuned distilBERT]\n        Results[关键结果/Results] --> R1[数据集: 312,868个安全讨论/Dataset: 312,868 security discussions]\n        Results --> R2[分类法: 32个问题, 24个解决方案/Taxonomy: 32 issues, 24 solutions]\n        Results --> R3[洞察: 依赖复杂性和黑盒性导致问题/Insight: Issues from dependencies & black-box nature]"
    },
    {
      "title": "An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes",
      "authors": "Vinoth Punniyamoorthy, Bikesh Kumar, Sumit Saha, Lokesh Butra, Mayilsamy Palanigounder, Akash Kumar Agarwal, Kabilan Kannan",
      "institution": "IEEE, East West Bank, NTT Data, Albertsons",
      "link": "https://arxiv.org/pdf/2512.23415",
      "code": null,
      "tags": [
        "cluster infrastructure",
        "Kubernetes",
        "Autoscaling",
        "AIOps",
        "Service Level Objectives",
        "Cost Optimization"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce581ba4d1249deeba9f1bffa6739ebbe74df663542fef3893eee5e0a117ae2e_w640_q70.webp",
      "contributions": "1. A gap-driven analysis of existing Kubernetes autoscaling approaches, highlighting their limitations. 2. A safe and explainable multi-signal autoscaling framework that integrates SLO-aware and cost-conscious control with demand forecasting. 3. Experimental evaluation demonstrating significant improvements in SLO violation duration, scaling response time, and infrastructure cost compared to baselines.",
      "summary": "This paper addresses SLO violations and cost inefficiencies in Kubernetes autoscaling by proposing an AIOps-driven framework that uses multi-signal control and lightweight forecasting. The method integrates SLO and cost awareness to improve responsiveness and stability. Evaluation shows it reduces SLO violations by up to 31%, improves response time by 24%, and lowers cost by 18% compared to standard Kubernetes autoscalers.",
      "mindmap": "graph TB\n        Root(”An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”SLO违反与成本低效/SLO Violations & Cost Inefficiency”)\n        Problem --> P2(”反应式扩展与不透明逻辑/Reactive Scaling & Opaque Logic”)\n        Method --> M1(”AIOps驱动的多信号框架/AIOps-Driven Multi-Signal Framework”)\n        Method --> M2(”SLO与成本感知控制/SLO & Cost-Aware Control”)\n        Method --> M3(”轻量级需求预测/Lightweight Demand Forecasting”)\n        Results --> R1(”SLO违反时长减少31%/SLO Violation Duration Reduced by 31%”)\n        Results --> R2(”扩展响应时间提升24%/Scaling Response Time Improved by 24%”)\n        Results --> R3(”基础设施成本降低18%/Infrastructure Cost Lowered by 18%”)"
    },
    {
      "title": "Embedding Quality Assurance in project-based learning",
      "authors": "Maria Spichkova",
      "institution": "RMIT University",
      "link": "https://arxiv.org/pdf/2512.23488",
      "code": null,
      "tags": [
        "Software Engineering Education",
        "Quality Assurance",
        "Project-based Learning",
        "Agile/Scrum",
        "Software Engineering Education",
        "Experience Report"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/77065f8ef568ef76fd85920a5579be34df22a20ec5cca17659010df66ea57edb_w640_q70.webp",
      "contributions": "1. Shares over a decade of lessons learned from teaching software quality within Agile/Scrum-based Software Engineering courses, including final-year projects and a project management course. 2. Identifies specific challenges students face in understanding and applying Quality Assurance (QA) within Agile/Scrum project-based learning environments. 3. Provides practical recommendations for effectively embedding QA topics into project-based learning curricula with an Agile/Scrum context.",
      "summary": "This paper presents an experience report on teaching software quality assurance in Agile/Scrum-focused Software Engineering courses over ten years. It identifies student struggles with QA in project-based learning and provides recommendations for better integrating QA topics into such curricula. The main conclusion is that a focused pedagogical approach is needed to ensure students value and apply QA practices effectively in Agile settings.",
      "mindmap": "graph TB\n        Root[”Embedding Quality Assurance in Project-based Learning<br/>项目式学习中嵌入质量保证”] --> Problem[”Students struggle with QA in Agile/Scrum PBL<br/>学生在敏捷/Scrum项目式学习中难以掌握质量保证”]\n        Root --> Method[”Experience report & lessons learned from 10+ years of teaching<br/>基于十多年教学的经验报告与经验教训”]\n        Root --> Results[”Recommendations for embedding QA in Agile/Scrum PBL<br/>为在敏捷/Scrum项目式学习中嵌入质量保证提供建议”]"
    },
    {
      "title": "Adaptable TeaStore: A Choreographic Approach",
      "authors": "Giuseppe De Palma, Saverio Giallorenzo, Ivan Lanese, Gianluigi Zavattaro",
      "institution": "Università di Bologna, INRIA",
      "link": "https://arxiv.org/pdf/2512.23497",
      "code": null,
      "tags": [
        "choreographic programming",
        "adaptable microservices",
        "choreographic programming",
        "AIOCJ",
        "runtime adaptation",
        "communication correctness"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/185975480d365934f5e03c65e64353b019eae6a649d47d0cfc956b5c90524a0a_w640_q70.webp",
      "contributions": "1. Presents an implementation of the Adaptable TeaStore reference model using the AIOCJ choreographic language. 2. Demonstrates that AIOCJ ensures by-construction correctness of communications (e.g., deadlock freedom) before, during, and after runtime adaptation. 3. Provides an analysis of the strengths and current limitations of the choreographic approach for adaptable cloud architectures, suggesting future refinements.",
      "summary": "This paper models the Adaptable TeaStore, a reference model for adaptable microservice architectures, using the AIOCJ choreographic programming language. The approach ensures communication correctness by construction and supports dynamic runtime adaptation. The work showcases the paradigm's strengths, identifies its limitations, and suggests future directions to better align it with real-world cloud systems.",
      "mindmap": "graph TB\n        Root(”Adaptable TeaStore: A Choreographic Approach”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”需要可适应的微服务架构/Need for adaptable microservice architectures”)\n        Method --> M1(”使用AIOCJ编排语言/Use AIOCJ choreographic language”)\n        Method --> M2(”确保通信正确性/Ensure communication correctness”)\n        Results --> R1(”展示方法的优势与局限/Showcase strengths and limitations”)\n        Results --> R2(”提出未来改进方向/Propose future refinements”)"
    },
    {
      "title": "Decoupling Adaptive Control in TeaStore",
      "authors": "Eddy Truyen",
      "institution": "DistriNet, KU Leuven",
      "link": "https://arxiv.org/pdf/2512.23495",
      "code": null,
      "tags": [
        "self-adaptive systems",
        "self-adaptation",
        "microservices",
        "control loop",
        "operator pattern",
        "software architecture"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78e96b6ab1b10ae0a32ddc4e7967c5bedce7be1b0fe5db13bec216c9e0b657ae_w640_q70.webp",
      "contributions": "1. Analyzes how software architectural methods, the cloud-native Operator pattern, and legacy programming techniques can decouple adaptive control from the application logic in a microservice system. 2. Examines the trade-offs between fine-grained expressive adaptation and system-wide control, highlighting when reuse of adaptation strategies is effective. 3. Proposes that these approaches are complementary and can be combined into a multi-tiered architecture for self-adaptive microservices.",
      "summary": "This paper discusses the implementation of self-adaptation in the Adaptable TeaStore microservice benchmark. It examines different technical approaches (software architecture, Operator pattern, programming techniques) for decoupling the adaptive control logic from the application, analyzing their trade-offs. The main conclusion is that these approaches can be combined into a multi-tiered architecture for effective self-adaptive microservices.",
      "mindmap": "graph TB\n        A[Decoupling Adaptive Control in TeaStore] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[实现微服务中的细粒度自适应/Implementing fine-grained self-adaptation in microservices]\n        C --> C1[软件架构方法/Software architectural methods]\n        C --> C2[Operator模式/Operator pattern]\n        C --> C3[传统编程技术/Legacy programming techniques]\n        D --> D1[权衡细粒度与系统范围控制/Trade-offs between fine-grained and system-wide control]\n        D --> D2[可组合的多层架构/Composable multi-tiered architecture]"
    },
    {
      "title": "Adaptable Teastore with Energy Consumption Awareness: A Case Study",
      "authors": "Henrique De Medeiros, Denisse Muñante, Sophie Chabridon, César Perdigão Batista, Denis Conan",
      "institution": "Télécom SudParis, Institut Polytechnique de Paris, SAMOVAR, ENSIIE",
      "link": "https://arxiv.org/pdf/2512.23498",
      "code": null,
      "tags": [
        "self-adaptive systems",
        "energy consumption monitoring",
        "self-adaptive systems",
        "microservices",
        "dynamic adaptation",
        "cloud computing"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ac42d90e6b95a7a182714a4c0e65c9755ffae7ca3f2ebec7e85bf313b892f10_w640_q70.webp",
      "contributions": "1. Introduction of EnCoMSAS, a tool for monitoring energy consumption in distributed, self-adaptive software systems. 2. An empirical evaluation demonstrating EnCoMSAS's effectiveness and validating its measurements through correlation with CPU usage. 3. An analysis showing that the energy overhead of the monitoring tool itself is modest compared to the overall system.",
      "summary": "This paper addresses the gap in energy-aware monitoring for self-adaptive systems by introducing EnCoMSAS, a tool for collecting runtime energy consumption data. The tool was evaluated using the Adaptable TeaStore case study, where it effectively gathered energy data and revealed that consumption is influenced by both algorithmic complexity and deployment environment. The study concluded that EnCoMSAS is a valid monitoring solution with a relatively low impact on the overall system's energy footprint.",
      "mindmap": "graph TB\n        A[Adaptable Teastore with Energy Consumption Awareness: A Case Study] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Lack of effective energy monitoring tools for Self-Adaptive Systems (SAS) and unclear impact of such tools]\n        C[主要方法/Method: Propose and evaluate EnCoMSAS tool using the Adaptable TeaStore case study on Grid5000]\n        D[关键结果/Results: EnCoMSAS is effective; measurements are valid; tool's energy impact is modest]"
    },
    {
      "title": "AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices",
      "authors": "Brice Arléon Zemtsop Ndadji, Simon Bliudze, Clément Quinton",
      "institution": "Univ. Lille, CNRS, Inria, Centrale Lille, CRIStAL",
      "link": "https://arxiv.org/pdf/2512.23499",
      "code": null,
      "tags": [
        "autonomic computing",
        "MAPE-K loop",
        "decentralized adaptation",
        "event-driven",
        "rule-based",
        "microservices"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cea3a497714ae1ca6ead099b1f31177f6fe2bf3d4bc5a184a21835b1744db4a_w640_q70.webp",
      "contributions": "1. A framework (AdaptiFlow) providing abstraction layers for the Monitor and Execute phases of the MAPE-K loop to enable autonomous microservices. 2. A lightweight, event-driven and rule-based mechanism for specifying adaptation logic, decoupling it from metrics collection and action execution. 3. A workflow for service instrumentation and evidence that decentralized adaptation can emerge from localized decisions without global coordination, validated through three adaptation scenarios (self-healing, self-protection, self-optimization).",
      "summary": "This paper presents AdaptiFlow, a framework for building self-adaptive cloud microservices by decoupling metrics collection and action execution from adaptation logic using an event-driven, rule-based approach. It enables decentralized autonomy, allowing services to adapt locally without global coordination. The framework was validated on a benchmark, demonstrating practical implementation of self-healing, self-protection, and self-optimization scenarios with minimal code changes.",
      "mindmap": "graph TB\n        A[AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有方案集中式控制不适用于微服务/Existing centralized control ill-suited for microservices]\n        C --> C1[基于MAPE-K的抽象层与事件驱动规则/MAPE-K abstraction layers & event-driven rules]\n        C --> C2[解耦监控、执行与逻辑/Decouple Monitor/Execute from adaptation logic]\n        D --> D1[实现三种自治场景/Implemented three autonomy scenarios]\n        D --> D2[去中心化适应无需全局协调/Decentralized adaptation without global coordination]"
    },
    {
      "title": "Beyond Correctness: Exposing LLM-generated Logical Flaws in Reasoning via Multi-step Automated Theorem Proving",
      "authors": "Xinyi Zheng, Ningke Li, Xiaokun Luan, Kailong Wang, Ling Shi, Meng Sun, Haoyu Wang",
      "institution": "Huazhong University of Science and Technology, National University of Singapore, Peking University, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.23511",
      "code": null,
      "tags": [
        "reasoning verification",
        "automated theorem proving",
        "first-order logic",
        "logical error detection",
        "multi-step reasoning"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b9201185009c06f76b12e788768ccb6a8e2846d1d6ae7c9dcca57af7e332cc0_w640_q70.webp",
      "contributions": "1. Proposes MATP, a novel evaluation framework that uses Multi-step Automated Theorem Proving to verify LLM reasoning by translating it into First-Order Logic. 2. Provides a fine-grained classification of reasoning correctness, identifying hidden logical errors that are masked by fluent language. 3. Demonstrates superior performance over prompting-based baselines by over 42 percentage points and reveals disparities in logical coherence between different types of LLMs.",
      "summary": "This paper introduces MATP, a framework that translates LLM-generated natural language reasoning into First-Order Logic and uses automated theorem provers to verify its step-by-step logical validity. It effectively exposes subtle logical flaws that existing methods miss. Evaluations show MATP significantly outperforms baselines and can enhance the trustworthiness of LLM reasoning for critical applications.",
      "mindmap": "graph TB\n        A[Beyond Correctness: Exposing LLM-generated Logical Flaws<br>超越正确性：通过多步自动定理证明揭示LLM推理中的逻辑缺陷] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM推理存在被流畅语言掩盖的微妙逻辑错误<br>Subtle logical errors in LLM reasoning masked by fluent language]\n        C --> C1[提出MATP框架：将自然语言推理转化为一阶逻辑<br>Propose MATP: Translates NL reasoning to FOL]\n        C --> C2[使用自动定理证明器进行多步验证<br>Uses automated theorem provers for multi-step verification]\n        D --> D1[在推理步骤验证上超越基线42个百分点<br>Surpasses baselines by over 42 percentage points]\n        D --> D2[揭示推理模型比通用模型逻辑更一致<br>Reveals reasoning models are more logically coherent]"
    },
    {
      "title": "Beyond Per-Thread Lock Sets: Multi-Thread Critical Sections and Dynamic Deadlock Prediction",
      "authors": "Martin Sulzmann",
      "institution": "Karlsruhe University of Applied Sciences",
      "link": "https://arxiv.org/pdf/2512.23552",
      "code": null,
      "tags": [
        "dynamic deadlock prediction",
        "lock sets",
        "critical sections",
        "partial order relations",
        "false positives",
        "false negatives"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d58fc411df804f4dd88c8339e7b2a1b64be70d9eca8844a0dbb324c049cdea_w640_q70.webp",
      "contributions": "1. Introduces a novel trace-based characterization of critical sections that can span multiple threads, correcting the standard per-thread model., 2. Proposes a sound approximation of the multi-thread critical section concept using partial order relations, enabling an improved lock set construction., 3. Integrates the improved lock set construction into an extended SPDOffline deadlock predictor, reducing both false positives and false negatives without impacting performance.",
      "summary": "The paper identifies that standard per-thread lock set analysis for deadlock prediction is flawed because it ignores locks acquired across thread boundaries, leading to inaccurate results. To solve this, the authors propose a new model of multi-thread critical sections and a sound approximation method using partial order relations to construct more precise lock sets. This approach, integrated into an extended predictor, reduces false positives and false negatives while maintaining performance.",
      "mindmap": "graph TB\n        A[Beyond Per-Thread Lock Sets: Multi-Thread Critical Sections and Dynamic Deadlock Prediction] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[标准每线程锁集分析忽略跨线程锁/Standard per-thread lock sets ignore cross-thread locks]\n        B1 --> B2[导致假阳性和假阴性/Leads to false positives and false negatives]\n        C --> C1[提出基于轨迹的多线程临界区概念/Propose trace-based multi-thread critical sections]\n        C1 --> C2[使用偏序关系进行可靠近似/Use partial order relations for sound approximation]\n        C2 --> C3[改进锁集构造/Improved lock set construction]\n        D --> D1[减少假阳性和假阴性/Reduces false positives and false negatives]\n        D1 --> D2[性能不受影响/Performance not affected]"
    },
    {
      "title": "Model-based Development for Autonomous Driving Software Considering Parallelization",
      "authors": "Kenshin Obi, Takumi Onozawa, Hiroshi Fujimoto, Takuya Azumi",
      "institution": "Saitama University, eSOL Co., Ltd.",
      "link": "https://arxiv.org/pdf/2512.23575",
      "code": null,
      "tags": [
        "compiler & ir",
        "Model-Based Development",
        "Parallelization",
        "Multi-core Processor",
        "Autonomous Driving Software",
        "Real-time Performance"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdaf1e9de27edf6ed5439e7e3abd6bd6f053fa858fced85d7eae12b8159fc8b4_w640_q70.webp",
      "contributions": "1. Proposes a method to extend the existing Model-Based Parallelizer (MBP) to support complex processing blocks (like Simulink Toolbox blocks) for autonomous driving software. 2. Addresses the problem of decreasing the number of blocks available for parallelization when using high-level Toolbox blocks and code descriptions. 3. Demonstrates a reduction in execution time, showing the method's suitability for achieving real-time performance in autonomous driving software development.",
      "summary": "This paper proposes a model-based development method for parallelizing autonomous driving software to meet real-time performance requirements. It extends the existing Model-Based Parallelizer (MBP) to handle complex processing blocks, thereby reducing execution time. The evaluation confirms the method's effectiveness for developing real-time autonomous driving systems.",
      "mindmap": "graph TB\n        A[Model-based Development for Autonomous Driving Software Considering Parallelization] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[自动驾驶软件需要实时性能/Autonomous driving software requires real-time performance]\n        C --> C1[扩展基于模型的并行化方法/Extend Model-Based Parallelizer (MBP) method]\n        D --> D1[执行时间减少/Execution time was reduced]"
    },
    {
      "title": "Parallelized Code Generation from Simulink Models for Event-driven and Timer-driven ROS 2 Nodes",
      "authors": "Kenshin Obi, Ryo Yoshinaka, Hiroshi Fujimoto, Takuya Azumi",
      "institution": "Saitama University, eSOL Co., Ltd.",
      "link": "https://arxiv.org/pdf/2512.23605",
      "code": null,
      "tags": [
        "embedded systems",
        "model-based development",
        "parallelization",
        "ROS 2",
        "Simulink",
        "multi-core processors"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1cb6e7053c79e3517530163d94d50906a3c12983608458bcd92e238407357675_w640_q70.webp",
      "contributions": "1. Proposes a model-based development framework that categorizes ROS 2-compatible Simulink models into event-driven and timer-driven types for targeted parallelization. 2. Extends conventional MBD parallelization to support ROS 2-based models with multiple inputs, addressing integration challenges. 3. Demonstrates the framework's effectiveness by showing reduced execution time for all tested patterns after parallelization.",
      "summary": "This paper addresses the challenge of integrating automatic model-based parallelization with the ROS 2 framework for autonomous driving systems. It proposes a framework that categorizes Simulink models as event-driven or timer-driven to generate parallelized code for ROS 2 nodes. Evaluation results confirm that the approach successfully reduces execution time.",
      "mindmap": "graph TB\n        A[Parallelized Code Generation from Simulink Models for Event-driven and Timer-driven ROS 2 Nodes] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[传统MBD难以集成ROS 2/Traditional MBD struggles with ROS 2 integration]\n        B --> B2[多输入场景的并行化挑战/Parallelization challenges in multi-input scenarios]\n        C --> C1[将模型分类为事件驱动与定时驱动/Categorize models as event-driven & timer-driven]\n        C --> C2[提出针对性并行化的MBD框架/Propose MBD framework for targeted parallelization]\n        D --> D1[所有模式执行时间减少/All patterns show reduced execution time]\n        D --> D2[验证了并行化的有效性/Confirms effectiveness of parallelization]"
    },
    {
      "title": "Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity",
      "authors": "Krishna Harsha Kovelakuntla Huthasana, Alireza Olama, Andreas Lundell",
      "institution": "Åbo Akademi University",
      "link": "https://arxiv.org/pdf/2512.23071",
      "code": null,
      "tags": [
        "federated learning",
        "L0 regularization",
        "probabilistic gates",
        "communication efficiency",
        "model sparsity",
        "federated stochastic gradient descent"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259d06fa8e807f154e153891f40b44308796040886ed51e218b65ee4e67a8c9c_w640_q70.webp",
      "contributions": "1. Proposes a novel federated learning method that enforces an L0 constraint on model parameters using probabilistic gates and their continuous relaxation to achieve target sparsity. 2. Derives the L0 constrained stochastic minimization objective from an entropy maximization problem of the stochastic gates. 3. Demonstrates that the method can achieve high target sparsity (down to ρ=0.005) under data and client heterogeneity with minimal loss in statistical performance, outperforming magnitude pruning-based methods.",
      "summary": "The paper addresses the problem of poor generalizability and communication inefficiency in Federated Learning due to overly dense models. It proposes a method to enforce L0 sparsity constraints via probabilistic gates, deriving the objective from entropy maximization and implementing it with federated stochastic gradient descent. The method is shown to be communication-efficient and achieves high target sparsity with better statistical performance than pruning-based baselines on synthetic and real datasets.",
      "mindmap": "graph TB\n        Root[Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: 数据与模型固有的稀疏性未被解决，导致模型过密、泛化性差，且存在数据和客户端参与异质性。]\n        Method[主要方法/Method: 通过概率门及其连续松弛对非零参数密度施加L0约束，目标源自随机门的熵最大化问题，并基于联邦随机梯度下降。]\n        Results[关键结果/Results: 在数据和客户端异质性下，能达到目标密度(ρ)，统计性能损失最小，且比基于幅度的剪枝方法更优、通信高效。]"
    },
    {
      "title": "LogosQ: A High-Performance and Type-Safe Quantum Computing Library in Rust",
      "authors": "Shiwen An, Jiayi Wang, Konstantinos Slavakis",
      "institution": "Institute of Science Tokyo, Georgia Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.23183",
      "code": null,
      "tags": [
        "compiler & ir",
        "Rust",
        "type safety",
        "quantum simulation",
        "variational algorithms",
        "parameter-shift rule"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3869523633aebacf98c54bdd34569f2d2e445db13de6918d6fa0d76072c1a8df_w640_q70.webp",
      "contributions": "1. Introduces LogosQ, a quantum computing library in Rust that uses compile-time type safety to eliminate runtime errors, especially in gradient computations. 2. Proposes novel optimization techniques like direct state-vector manipulation, adaptive parallel processing, and an FFT-optimized QFT for significant performance gains. 3. Demonstrates superior numerical stability and accuracy in variational quantum eigensolver (VQE) experiments compared to existing frameworks.",
      "summary": "The paper presents LogosQ, a high-performance quantum computing library written in Rust that ensures correctness through compile-time type safety. It introduces several optimization techniques that achieve speedups of up to 900x for certain operations and shows improved numerical stability in variational algorithm experiments. The work establishes a new standard for reliable and efficient quantum simulation by combining systems programming safety with advanced circuit optimizations.",
      "mindmap": "graph TB\n        Root[LogosQ: Rust高性能类型安全量子库] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[Python框架动态性导致运行时错误/Runtime errors in dynamic Python frameworks]\n        Problem --> P2[现有工具存在可扩展性瓶颈/Scalability bottlenecks in existing tools]\n        Method[主要方法/Method] --> M1[Rust实现与编译时类型安全/Rust implementation with compile-time type safety]\n        Method --> M2[引入新型优化技术/Novel optimization techniques]\n        Results[关键结果/Results] --> R1[性能大幅提升/Significant speedups (up to 900x)]\n        Results --> R2[数值稳定性验证/Validated numerical stability]\n        Results --> R3[建立可靠高效新标准/Establishes new standard for reliability & efficiency]"
    },
    {
      "title": "Understanding the Role of Large Language Models in Software Engineering: Evidence from an Industry Survey",
      "authors": "Vítor Mateus de Brito, Kleinner Farias",
      "institution": "University of Vale do Rio dos Sinos",
      "link": "https://arxiv.org/pdf/2512.21347",
      "code": null,
      "tags": [
        "software development tools",
        "Large Language Models",
        "Survey",
        "Industry",
        "Empirical Study",
        "Software Engineering Practices"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fdebd67326ef0fe8cc1a2f2e7ff34382bc7ee9e314bfea976a0e99b4b0eda04_w640_q70.webp",
      "contributions": "1. Provides empirical evidence on the adoption and impact of LLMs in professional software engineering practice through an industry survey. 2. Identifies key perceived benefits (e.g., faster problem resolution, better documentation) and concerns (e.g., cognitive dependence, security risks) associated with LLM use. 3. Bridges the gap between academic discourse and real-world development, offering actionable insights for responsible LLM integration.",
      "summary": "This paper conducts an empirical survey of 46 industry professionals to understand the adoption and impact of Large Language Models (LLMs) in software engineering. The study finds that while LLMs are perceived to accelerate technical tasks and improve documentation, significant concerns about over-reliance and security risks persist. The results highlight the need for critical and supervised use of LLM-based tools in software development.",
      "mindmap": "graph TB\n        A[Understanding the Role of LLMs in Software Engineering<br>理解LLM在软件工程中的作用] --> B(核心问题/Problem: How are LLMs adopted and perceived in industry software engineering?<br>LLM在工业界软件工程中的采用和认知如何？)\n        A --> C(主要方法/Method: Empirical survey of 46 industry professionals<br>对46位行业专业人员的实证调查)\n        A --> D(关键结果/Results: Positive perceptions (speed, documentation) but concerns about dependence and security<br>积极认知（速度、文档）但对依赖性和安全性的担忧)"
    },
    {
      "title": "CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation",
      "authors": "Santhosh Kumar Ravindran",
      "institution": "Microsoft Corporation",
      "link": "https://arxiv.org/pdf/2512.21351",
      "code": null,
      "tags": [
        "reinforcement learning",
        "dream-replay reinforcement learning",
        "evolutionary algorithms",
        "adaptive code generation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp",
      "contributions": "1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as \"genomes\" that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.",
      "summary": "CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.",
      "mindmap": "graph TB\n        A[CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM代码生成缺乏适应性，难以应对API变化/LLM code generation lacks adaptability to API changes]\n        C --> C1[将RL轨迹视为基因组进行进化操作/Treat RL trajectories as genomes for evolutionary operations]\n        C --> C2[在夜间回放阶段进行突变与选择/Mutation and selection during nocturnal replay]\n        D --> D1[解决方案新颖性提升35%/35% higher novelty in solutions]\n        D --> D2[适应速度加快25%/25% faster adaptation]"
    },
    {
      "title": "Multi-Agent LLM Committees for Autonomous Software Beta Testing",
      "authors": "Sumanth Bharadwaj Hachalli Karanam, Dhiwahar Adhithya Kennady",
      "institution": "New York University",
      "link": "https://arxiv.org/pdf/2512.21352",
      "code": null,
      "tags": [
        "automated software testing",
        "multi-agent system",
        "large language model",
        "vision-language model",
        "consensus voting",
        "beta testing"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40573d0b1209c41e9825c09111398107cc51ee9d86c5234b50bea2515d0ab37f_w640_q70.webp",
      "contributions": "1. A novel multi-agent committee framework that uses a three-round voting protocol for consensus-based decision-making in software testing. 2. Integration of vision-enabled LLMs and diverse testing personas to systematically explore and understand web application user interfaces. 3. Demonstrated significant performance improvements over single-agent baselines in task success, bug detection (F1 score), and security vulnerability coverage on established benchmarks.",
      "summary": "The paper addresses the high cost of manual software beta testing and the limitations of single-agent LLM approaches by proposing a multi-agent committee framework. The method employs diverse, vision-enabled LLMs that collaborate through a structured voting protocol and persona-driven behavior to autonomously test web applications. The results show that this multi-agent approach significantly outperforms single-agent baselines in task success rates, bug detection, and security testing coverage, making it suitable for real-time CI/CD integration.",
      "mindmap": "graph TB\n        A[Multi-Agent LLM Committees for Autonomous Software Beta Testing] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[手动测试成本高，单智能体LLM存在幻觉/Manual testing costly, single-agent LLM hallucinates]\n        C --> C1[多智能体委员会与三轮投票协议/Multi-agent committee & three-round voting]\n        C --> C2[视觉LLM与角色多样性/Vision LLMs & persona diversity]\n        D --> D1[任务成功率89.5%，超越基线/Task success 89.5%, beats baseline]\n        D --> D2[动作延迟0.71秒，适合CI/CD/Action latency 0.71s, suitable for CI/CD]\n        D --> D3[覆盖8/10 OWASP漏洞类别/Covers 8/10 OWASP Top 10]"
    },
    {
      "title": "Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software",
      "authors": "Ying Xiao, Shangwen Wang, Sicen Liu, Dingyuan Xue, Xian Zhan, Yepang Liu, Jie M. Zhang",
      "institution": "King’s College London, National University of Defense Technology, Southern University of Science and Technology, The Hong Kong Polytechnic University",
      "link": "https://arxiv.org/pdf/2512.21348",
      "code": null,
      "tags": [
        "software fairness",
        "correlation tuning",
        "phi-coefficient",
        "multi-objective optimization",
        "pre-processing",
        "bias mitigation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4f80681a9ac6a6c3ad7d2bd938623a06836acba00279d9cec368a5ebbe44df3_w640_q70.webp",
      "contributions": "1. Proposes a novel pre-processing bias mitigation method called Correlation Tuning (CoT) that adjusts data correlations. 2. Introduces the Phi-coefficient as an intuitive measure to quantify correlation between sensitive attributes and labels. 3. Employs multi-objective optimization to address proxy biases, demonstrating superior effectiveness over state-of-the-art methods in single and multiple attribute scenarios.",
      "summary": "This paper proposes Correlation Tuning (CoT), a novel pre-processing method to mitigate bias in ML software by adjusting data correlations using the Phi-coefficient and multi-objective optimization. It frames fairness as a core software quality issue. Extensive evaluation shows CoT significantly improves performance for unprivileged groups and reduces key bias metrics, outperforming existing methods.",
      "mindmap": "graph TB\n        A[Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[传统公平研究忽视软件质量维度/Traditional fairness research neglects software quality dimension]\n        B --> B2[预处理方法效果不足/Pre-processing methods lack effectiveness]\n        C --> C1[提出相关性调优 (CoT)/Propose Correlation Tuning (CoT)]\n        C --> C2[使用Phi系数量化相关性/Use Phi-coefficient to quantify correlation]\n        C --> C3[采用多目标优化/Employ multi-objective optimization]\n        D --> D1[提高弱势群体TPR 17.5%/Increase unprivileged group TPR by 17.5%]\n        D --> D2[关键偏差指标降低 >50%/Key bias metrics reduced by >50%]\n        D --> D3[超越SOTA方法 3-10个百分点/Outperform SOTA by 3-10 percentage points]"
    },
    {
      "title": "Reflection-Driven Control for Trustworthy Code Agents",
      "authors": "Bin Wang, Jiazheng Quan, Xingrui Yu, Hansen Hu, Yuhao, Ivor Tsang",
      "institution": "Peking University, Xiamen University, Agency for Science, Technology and Research (A*STAR)",
      "link": "https://arxiv.org/pdf/2512.21354",
      "code": null,
      "tags": [
        "agent system",
        "reflection-driven control",
        "secure code generation",
        "trustworthy agents",
        "reflective memory",
        "safety control"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp",
      "contributions": "1. Introduces Reflection-Driven Control, a standardized and pluggable control module that integrates self-reflection as an explicit, internal step in an agent's reasoning process. 2. Instantiates the method for secure code generation, using a reflection loop to monitor decisions and retrieve repair examples/guidelines from an evolving reflective memory to inject constraints. 3. Empirically demonstrates that the approach substantially improves security and policy compliance of generated code while preserving functional correctness, with minimal overhead.",
      "summary": "The paper addresses the lack of reliable safety controls in LLM agents by proposing Reflection-Driven Control, a module that makes self-reflection an explicit, continuous part of the agent's reasoning to monitor and constrain its decisions using evidence from a reflective memory. Evaluated on security-critical code generation tasks, the method significantly improves code security and compliance while maintaining functionality, offering a practical path toward trustworthy AI coding agents.",
      "mindmap": "graph TB\n        Root[Reflection-Driven Control for Trustworthy Code Agents] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[LLM代理缺乏可靠的安全控制/LLM agents lack reliable safety controls]\n        Problem --> P2[可能产生有害输出/Can produce harmful outputs]\n        Method --> M1[将自我反思作为推理的显式步骤/Elevates self-reflection to an explicit reasoning step]\n        Method --> M2[内部反思循环监控决策路径/Internal reflection loop monitors decision path]\n        Method --> M3[从反思记忆中检索修复示例/Retrieves repair examples from reflective memory]\n        Results --> R1[显著提高生成代码的安全性和合规性/Substantially improves security & policy compliance]\n        Results --> R2[基本保持功能正确性/Largely preserves functional correctness]\n        Results --> R3[运行时和token开销最小/Minimal runtime & token overhead]"
    },
    {
      "title": "AInsteinBench: Benchmarking Coding Agents on Scientific Repositories",
      "authors": "Titouan Duston, Shuo Xin, Yang Sun, Daoguang Zan, Aoyan Li, Shulin Xin, Kai Shen, Yixiao Chen, Qiming Sun, Ge Zhang, Jiashuo Liu, Huan Zhou, Jingkai Liu, Zhichen Pu, Yuanheng Wang, Bo-Xuan Ge, Xin Tong, Fei Ye, Zhi-Chao Zhao, Wen-Biao Han, Zhoujian Cao, Yueran Zhao, Weiluo Ren, Qingshen Long, Yuxiao Liu, Anni Huang, Yidi Du, Yuanyuan Rong, Jiahao Peng",
      "institution": "ByteDance Seed, Princeton University",
      "link": "https://arxiv.org/pdf/2512.21373",
      "code": "https://github.com/ByteDance-Seed/AInsteinBench",
      "tags": [
        "software engineering",
        "benchmark",
        "scientific computing",
        "code generation",
        "pull requests",
        "test-driven verification"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp",
      "contributions": "1. Introduces a novel benchmark (AInsteinBench) for evaluating LLM agents in end-to-end scientific development using real-world, production-grade codebases. 2. Curates tasks from maintainer-authored pull requests across six diverse scientific domains, ensuring scientific challenge and calibrated difficulty. 3. Employs executable environments and test-driven verification to measure core competencies beyond surface-level code generation.",
      "summary": "The paper introduces AInsteinBench, a benchmark designed to evaluate LLM agents' ability to function as scientific computing developers by solving tasks derived from real pull requests in scientific repositories. It uses executable environments and test-driven verification to assess deeper competencies. The benchmark provides a new standard for measuring AI's role in computational scientific research.",
      "mindmap": "graph TB\n        A[AInsteinBench: Benchmarking Coding Agents on Scientific Repositories] --> B[核心问题/Problem: Can LLM agents operate as scientific computing development agents?]\n        A --> C[主要方法/Method: End-to-end evaluation using tasks from real scientific pull requests]\n        A --> D[关键结果/Results: Measures ability beyond surface-level code generation]"
    },
    {
      "title": "What Makes a GitHub Issue Ready for Copilot?",
      "authors": "Mohammed Sayagh",
      "institution": "École de Technologie Supérieure, Université du Québec",
      "link": "https://arxiv.org/pdf/2512.21426",
      "code": null,
      "tags": [
        "ai-assisted software engineering",
        "GitHub Copilot",
        "AI-agent",
        "interpretable machine learning",
        "pull request merge prediction",
        "issue quality criteria"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/998bd51b7cec267b5219b085eac5068f7a996cf57d816c17d8e06474fbae27f0_w640_q70.webp",
      "contributions": "1. Developed a set of 32 detailed criteria to measure the quality of GitHub issues for AI-agents like Copilot. 2. Built an interpretable machine learning model to predict the likelihood of a GitHub issue resulting in a merged pull request. 3. Identified key characteristics of successful issues (e.g., shorter, well-scoped) and those associated with failure (e.g., external references), providing actionable guidance for issue writing.",
      "summary": "This paper investigates what makes a GitHub issue suitable for AI-agents like Copilot to successfully implement. The authors propose 32 quality criteria and build an interpretable machine learning model to predict if an issue will lead to a merged pull request. They conclude that successful issues are shorter, well-scoped, and provide clear implementation guidance, while issues with external references are less likely to succeed.",
      "mindmap": "graph TB\n        A[What Makes a GitHub Issue Ready for Copilot?] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[AI-agent性能依赖输入质量/AI-agent performance depends on input quality]\n        B --> B2[如何评估Issue对Copilot的适用性/How to evaluate Issue suitability for Copilot]\n        C --> C1[定义32项质量评估标准/Define 32 quality criteria]\n        C --> C2[构建可解释机器学习模型/Build interpretable ML model]\n        C --> C3[比较合并与关闭的PR/Compare merged vs. closed PRs]\n        D --> D1[成功Issue特征:简短、范围明确、指导清晰/Successful Issue traits: short, well-scoped, clear guidance]\n        D --> D2[外部引用关联低合并率/External references linked to lower merge rate]\n        D --> D3[模型AUC中位数72%/Model median AUC 72%]"
    },
    {
      "title": "Cerberus: Multi-Agent Reasoning and Coverage-Guided Exploration for Static Detection of Runtime Errors",
      "authors": "Hridya Dhulipala, Xiaokai Rong, Tien N. Nguyen",
      "institution": "University of Texas at Dallas",
      "link": "https://arxiv.org/pdf/2512.21431",
      "code": null,
      "tags": [
        "software testing",
        "runtime error detection",
        "coverage-guided testing",
        "multi-agent reasoning",
        "large language models",
        "static analysis"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d41379a4c8476f7ed1a8a02b193c5fe427e6a274d56beccd85313ce47ba5e76_w640_q70.webp",
      "contributions": "1. Proposes Cerberus, a novel predictive, execution-free coverage-guided testing framework that uses LLMs for input generation, coverage prediction, and error detection without code execution. 2. Introduces a two-phase feedback loop that first maximizes code coverage and detects errors, then focuses solely on error detection after coverage is maximized, improving performance over single-phase prompting. 3. Empirically demonstrates that Cerberus outperforms conventional and learning-based testing frameworks for both complete and incomplete code snippets by generating high-coverage test cases more efficiently and discovering more runtime errors.",
      "summary": "The paper proposes Cerberus, a framework that uses Large Language Models (LLMs) to statically detect runtime errors in code snippets without execution. It employs a multi-agent reasoning approach with a two-phase, coverage-guided feedback loop to generate test inputs and predict errors. The evaluation shows Cerberus is more efficient and effective at finding runtime errors than existing testing methods.",
      "mindmap": "graph TB\n        A[Cerberus: Multi-Agent Reasoning and Coverage-Guided Exploration for Static Detection of Runtime Errors] --> B(核心问题/Problem: Detecting runtime errors in code snippets without execution is crucial for software safety.)\n        A --> C(主要方法/Method: Uses LLMs for execution-free, coverage-guided testing with a two-phase feedback loop.)\n        A --> D(关键结果/Results: Outperforms conventional and learning-based frameworks by generating high-coverage tests and finding more errors.)"
    },
    {
      "title": "Fuzzwise: Intelligent Initial Corpus Generation for Fuzzing",
      "authors": "Hridya Dhulipala, Xiaokai Rong, Aashish Yadavally, Tien N. Nguyen",
      "institution": "University of Texas at Dallas",
      "link": "https://arxiv.org/pdf/2512.21440",
      "code": null,
      "tags": [
        "fuzz testing",
        "initial corpus generation",
        "large language models",
        "multi-agent framework",
        "predictive code coverage",
        "mutation-based fuzzing"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcb8eafec283e39ae04e0274dc4688aced924346193560581e8469f1151507f6_w640_q70.webp",
      "contributions": "1. Proposes FuzzWise, a novel method that integrates initial corpus generation and minimization into a single, streamlined process using an LLM-based multi-agent framework., 2. Introduces a predictive code coverage module (an LLM agent) that assesses new test cases without requiring actual program execution, saving computational resources., 3. Demonstrates empirically that FuzzWise generates a smaller, higher-quality initial corpus that achieves higher code coverage and triggers more runtime errors more efficiently than baseline methods.",
      "summary": "The paper addresses the problem of generating a high-quality initial seed corpus for mutation-based fuzzing. It proposes FuzzWise, a method that uses a multi-agent LLM framework to generate and intelligently select test cases based on predicted coverage without execution. The evaluation shows FuzzWise produces a smaller, more effective corpus that achieves higher coverage and finds more bugs efficiently.",
      "mindmap": "graph TB\n        A[FuzzWise: Intelligent Initial Corpus Generation for Fuzzing] --> B[核心问题/Problem: 为模糊测试生成高质量的初始种子语料库/Generating high-quality initial seed corpus for fuzzing]\n        A --> C[主要方法/Method: 基于LLM的多智能体框架，集成生成与预测性覆盖评估/LLM-based multi-agent framework integrating generation and predictive coverage assessment]\n        A --> D[关键结果/Results: 用更少的测试用例实现更高的代码覆盖率和错误发现率/Achieves higher code coverage and bug detection with fewer test cases]"
    },
    {
      "title": "Code Clone Refactoring in C# with Lambda Expressions",
      "authors": "Takuto Kawamoto, Yoshiki Higo",
      "institution": "Osaka University",
      "link": "https://arxiv.org/pdf/2512.21511",
      "code": null,
      "tags": [
        "code refactoring",
        "lambda expressions",
        "extract method",
        "behavior parameterization",
        "code clone",
        "C#"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c89087084c80383647290bcc69c8c950eca517f6ba4f10a7237d77a54477bdd_w640_q70.webp",
      "contributions": "1. Proposed a C#-specific technique for code clone refactoring using lambda expressions for behavior parameterization, addressing a gap in language-specific research beyond Java. 2. Developed an analysis method to determine the refactorability of clone pairs detected by the NiCad clone detector. 3. Conducted an empirical evaluation on 2,217 clone pairs from 22 projects, measuring the success rate of the proposed consolidation approach.",
      "summary": "This paper addresses the problem of consolidating code clones in C# programs using \"Extract Method\" refactoring. It proposes a novel technique that uses lambda expressions to parameterize behavioral differences between clones, which is tailored to C#'s language specifications. The evaluation on real-world projects showed that 35.0% of clone pairs were deemed refactorable by the approach, with 28.9% of those successfully refactored.",
      "mindmap": "graph TB\n        Root(”Code Clone Refactoring in C# with Lambda Expressions”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”Clone Refactoring with Differences/存在差异的克隆重构”)\n        Problem --> P2(”Language-Specific Techniques Needed/需要语言特定技术”)\n        Method --> M1(”C#-Specific Lambda Expressions/C#特定的Lambda表达式”)\n        Method --> M2(”Behavior Parameterization/行为参数化”)\n        Results --> R1(”35.0% Pairs Refactorable/35.0% 可重构”)\n        Results --> R2(”28.9% Successfully Refactored/28.9% 成功重构”)"
    },
    {
      "title": "XTrace: A Non-Invasive Dynamic Tracing Framework for Android Applications in Production",
      "authors": "Qi Hu, Jiangchao Liu, Xin Yu, Lin Zhang, Edward Jiang",
      "institution": "ByteDance",
      "link": "https://arxiv.org/pdf/2512.21555",
      "code": null,
      "tags": [
        "mobile systems",
        "dynamic tracing",
        "method interception",
        "ART virtual machine",
        "non-invasive proxying",
        "runtime observability"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/35b382ca224e5947c252f1f122f264a5993cf96e0069d9fecd115eb850c5ea49_w640_q70.webp",
      "contributions": "1. Proposes a novel non-invasive proxying paradigm for dynamic tracing that avoids modifying the ART VM's underlying data structures. 2. Achieves high-performance method interception by leveraging and optimizing the stable, built-in instrumentation mechanism of the Android ART virtual machine. 3. Demonstrates production-grade stability, minimal overhead, and broad compatibility through large-scale A/B experiments on a major app, successfully diagnosing severe online issues.",
      "summary": "This paper proposes XTrace, a non-invasive dynamic tracing framework for Android that intercepts arbitrary methods at runtime without app releases by leveraging the ART VM's instrumentation. It shows minimal performance impact and high stability in large-scale production use, significantly improving the efficiency of diagnosing online crashes and performance bottlenecks.",
      "mindmap": "graph TB\n        Root[XTrace: 一个用于生产环境的Android应用非侵入式动态追踪框架 / XTrace: A Non-Invasive Dynamic Tracing Framework for Android Applications in Production]\n        Root --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[移动应用复杂性 & 设备碎片化 / Mobile App Complexity & Device Fragmentation]\n        Problem --> P2[”传统方法(静态日志)缺乏实时上下文 / Traditional Methods Lack Real-time Context”]\n        Problem --> P3[”难以捕获'幽灵bug' / Difficulty in Catching 'Ghost Bugs'”]\n        Method --> M1[非侵入式代理范式 / Non-Invasive Proxying Paradigm]\n        Method --> M2[利用并优化ART内置插桩机制 / Leverage & Optimize ART's Built-in Instrumentation]\n        Results --> R1[生产级稳定性 & 最小开销 / Production-Grade Stability & Minimal Overhead]\n        Results --> R2[诊断严重线上崩溃 & 性能瓶颈 / Diagnosed Severe Online Crashes & Performance Bottlenecks]\n        Results --> R3[根因定位效率提升>90% / Root-Cause Localization Efficiency Improved >90%]"
    },
    {
      "title": "Co-Evolution of Types and Dependencies: Towards Repository-Level Type Inference for Python Code",
      "authors": "Shuo Sun, Shixin Zhang, Jiwei Yan, Jun Yan, Jian Zhang",
      "institution": "Institute of Software, Chinese Academy of Sciences",
      "link": "https://arxiv.org/pdf/2512.21591",
      "code": null,
      "tags": [
        "type inference",
        "Entity Dependency Graph",
        "co-evolution",
        "type-checker-in-the-loop",
        "LLM",
        "repository-level"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d664d948e35d5ccaf8cf1c7880d512bf91868eeaf908b4683c1db08768e3940_w640_q70.webp",
      "contributions": "1. An Entity Dependency Graph (EDG) model designed to capture repository-level type dependencies. 2. An iterative type inference approach where types and dependencies co-evolve in each iteration. 3. A type-checker-in-the-loop strategy that validates and corrects inferences on-the-fly to reduce error propagation.",
      "summary": "This paper proposes PyTIR, a novel approach for repository-level type inference in Python. It uses an Entity Dependency Graph (EDG) and an iterative co-evolution process between types and dependencies, enhanced by a type-checker-in-the-loop, to achieve accurate type annotations. The method significantly outperforms prior works, demonstrating a major improvement in automated type annotation for real-world Python code.",
      "mindmap": "graph TB\n        A[Co-Evolution of Types and Dependencies: Towards Repository-Level Type Inference for Python Code] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Python动态类型导致运行时错误/Python dynamic typing causes runtime errors]\n        B --> B2[现有工具难以处理仓库级依赖/Existing tools struggle with repository-level dependencies]\n        C --> C1[构建实体依赖图(EDG)/Construct Entity Dependency Graph (EDG)]\n        C --> C2[类型与依赖协同进化迭代推理/Co-evolution iterative inference of types and dependencies]\n        C --> C3[集成类型检查器循环验证/Type-checker-in-the-loop validation]\n        D --> D1[TypeSim 0.89, TypeExact 0.84/TypeSim 0.89, TypeExact 0.84]\n        D --> D2[相对基线提升27%和40%/27% and 40% relative improvement over baseline]\n        D --> D3[减少92.7%的新类型错误/Reduced 92.7% of new type errors]"
    },
    {
      "title": "Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation",
      "authors": "Tian Li, Bo Lin, Shangwen Wang, Yusong Tan",
      "institution": "National University of Defense Technology",
      "link": "https://arxiv.org/pdf/2512.21681",
      "code": null,
      "tags": [
        "software security",
        "backdoor attack",
        "retrieval-augmented code generation",
        "vulnerable code",
        "supply-chain vulnerability",
        "stealthy attack"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74c266d46865bfe9ae8b97f18b92cf9b8209ecd63852c6f32f3fe8533329fe2_w640_q70.webp",
      "contributions": "1. Conducted the first systematic exploration of backdoor attacks targeting the retriever component in Retrieval-Augmented Code Generation (RACG), identifying it as a critical supply-chain vulnerability. 2. Proposed VenomRACG, a new class of potent and stealthy attack that makes poisoned code statistically indistinguishable from benign code, enabling realistic threat analysis. 3. Demonstrated the severe practical impact of the attack, showing that injecting only 0.05% poisoned data can manipulate the retriever and cause downstream models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while evading current defenses.",
      "summary": "This paper investigates the security threat of backdoor attacks on the retriever in Retrieval-Augmented Code Generation (RACG). To enable a realistic analysis, the authors developed a stealthy attack called VenomRACG. Their findings reveal that this attack is highly effective and evades current defenses, posing a practical threat to the software development ecosystem.",
      "mindmap": "graph TB\n        A[Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Retriever Backdoor: 供应链漏洞/Supply-Chain Vulnerability]\n        C --> C1[VenomRACG: 隐蔽攻击/Stealthy Attack]\n        D --> D1[低投毒率有效/Low Poisoning Rate Effective]\n        D --> D2[下游模型生成漏洞代码/Downstream Model Generates Vulnerable Code]\n        D --> D3[防御机制失效/Defenses Ineffective]"
    },
    {
      "title": "How Do Agents Perform Code Optimization? An Empirical Study",
      "authors": "Huiyun Peng, Antonio Zhong, Ricardo Andrés Calvo Méndez, Kelechi G. Kalu, James C. Davis",
      "institution": "Purdue University",
      "link": "https://arxiv.org/pdf/2512.21757",
      "code": null,
      "tags": [
        "code optimization",
        "AI coding agents",
        "performance optimization",
        "empirical study",
        "pull request analysis",
        "AIDev dataset"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp",
      "contributions": "1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices.",
      "summary": "This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement.",
      "mindmap": "graph TB\n        A[How Do Agents Perform Code Optimization? An Empirical Study] --> B[核心问题/Problem: AI coding agents' effectiveness on real-world performance optimization tasks is unknown.]\n        A --> C[主要方法/Method: Empirical comparison of 324 agent-generated and 83 human-authored performance PRs from AIDev dataset.]\n        A --> D[关键结果/Results: AI-authored PRs use similar patterns but include less explicit performance validation (45.7% vs 63.6%).]"
    },
    {
      "title": "The State of the SBOM Tool Ecosystems: A Comparative Analysis of SPDX and CycloneDX",
      "authors": "Abdul Ali Bangash, Tongxu Ge, Zhimin Zhao, Arshdeep Singh, Zitao Wang, Bram Adams",
      "institution": "Lahore University of Management Sciences, Queen's University, Indian Institute of Technology Ropar, University of Waterloo",
      "link": "https://arxiv.org/pdf/2512.21781",
      "code": null,
      "tags": [
        "software supply chain security",
        "Software Bill of Materials",
        "SBOM",
        "SPDX",
        "CycloneDX",
        "tool ecosystem"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91bc1035c2c5b265034f618902937bd2da58ada7ea4b50d403537bd0f48a030c_w640_q70.webp",
      "contributions": "1. Conducted a quantitative comparison of use cases for 170 publicly advertised SBOM tools to identify enhancement areas for the SPDX and CycloneDX formats. 2. Compared health metrics of both ecosystems (171 CycloneDX vs. 470 SPDX tools) and analyzed 36,990 issue reports from open-source tools to evaluate robustness and identify challenges. 3. Investigated and compared the health metrics of the top 250 open-source projects using each tool ecosystem.",
      "summary": "This paper conducts a comparative analysis of the two dominant Software Bill of Materials (SBOM) tool ecosystems, SPDX and CycloneDX. The authors quantitatively analyze tool use cases, ecosystem health metrics, issue reports, and project adoption. The findings reveal that CycloneDX tools show higher developer engagement in some areas, while SPDX benefits from a more mature ecosystem with broader tool availability and industry adoption.",
      "mindmap": "graph TB\n        A[The State of the SBOM Tool Ecosystems: A Comparative Analysis of SPDX and CycloneDX] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[SBOM adoption depends on tool ecosystems<br/>SBOM采用依赖于工具生态系统]\n        C --> C1[Quantitative comparison of tools, issues, and projects<br/>对工具、问题、项目进行定量比较]\n        D --> D1[CycloneDX: higher developer engagement<br/>CycloneDX: 更高的开发者参与度]\n        D --> D2[SPDX: more mature ecosystem & broader adoption<br/>SPDX: 更成熟的生态系统和更广泛的采用]"
    },
    {
      "title": "A Story About Cohesion and Separation: Label-Free Metric for Log Parser Evaluation",
      "authors": "Qiaolin Qin, Jianchen Zhao, Heng Li, Weiyi Shang, Ettore Merlo",
      "institution": "Polytechnique Montreal, University of Waterloo",
      "link": "https://arxiv.org/pdf/2512.21811",
      "code": null,
      "tags": [
        "log parsing",
        "PMSS",
        "label-free evaluation",
        "silhouette analysis",
        "Levenshtein distance",
        "log parser"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4dbe635df301e13b1acf1f17c8fb241f287195f74aae223daca138f58797fb87_w640_q70.webp",
      "contributions": "1. Proposed PMSS, a novel label-free metric for evaluating log parser performance that does not require ground-truth data. 2. Demonstrated that PMSS is significantly correlated with existing label-based metrics (FGA and FTA) and can lead to comparable parser selection conclusions. 3. Provided guidelines and discussion on interpreting evaluation results with PMSS, addressing challenges and its application when labels are unavailable or inconsistent.",
      "summary": "The paper identifies that existing metrics for evaluating log parsers rely on labeled data, which is often unavailable or inconsistent. To solve this, it proposes PMSS, a label-free metric based on medoid silhouette analysis and Levenshtein distance. The results show PMSS is strongly correlated with label-based metrics, offering a viable alternative for parser evaluation and selection without ground truth.",
      "mindmap": "graph TB\n        Root[”A Story About Cohesion and Separation: Label-Free Metric for Log Parser Evaluation<br>论文标题”]\n        Root --> Problem[”现有评估指标依赖标注数据，导致评估受限且结论不一致<br>Problem: Label-based metrics limit evaluation”]\n        Root --> Method[”提出PMSS，一种基于中心点轮廓分析和编辑距离的无标签评估指标<br>Method: Propose PMSS, a label-free metric”]\n        Root --> Results[”PMSS与FGA/FTA显著相关，为无标签场景提供有效替代方案<br>Results: PMSS correlates with label-based metrics”]"
    },
    {
      "title": "Analyzing Code Injection Attacks on LLM-based Multi-Agent Systems in Software Development",
      "authors": "Brian Bowers, Smita Khapre, Jugal Kalita",
      "institution": "Loyola Marymount University, University of Colorado Colorado Springs",
      "link": "https://arxiv.org/pdf/2512.21818",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent system",
        "code injection",
        "threat model",
        "security analysis agent",
        "LLM"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43b214bf9d80e3aaa2e2412bbf3ea1727db748cf0f33f818d81076fa53654f97_w640_q70.webp",
      "contributions": "1. Proposed and evaluated LLM-based multi-agent architectures (coder, coder-tester, coder-reviewer-tester) for software implementation, assessing their accuracy, attack resilience, and efficiency. 2. Introduced a security analysis agent to mitigate code injection attacks, showing it improves resilience while recovering lost efficiency. 3. Demonstrated a vulnerability in the security analysis agent where embedding poisonous few-shot examples in injected code drastically increases attack success rate.",
      "summary": "This paper analyzes the vulnerability of LLM-based multi-agent systems in software development to code injection attacks. It proposes and evaluates several agent architectures, finding that adding a security analysis agent improves resilience and efficiency. However, the study concludes that even this security agent can be compromised by advanced attacks using poisoned few-shot examples, significantly increasing the attack success rate.",
      "mindmap": "graph TB\n        Root[Analyzing Code Injection Attacks on LLM-based Multi-Agent Systems] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: LLM-based multi-agent systems for software development are vulnerable to code injection attacks] --> Problem_Detail[缺乏人在环/No Human-in-the-Loop]\n        Method[主要方法/Method: Propose and evaluate multi-agent architectures, then add a security analysis agent] --> Method_Arch[架构评估/Architecture Evaluation: coder, coder-tester, coder-reviewer-tester]\n        Method --> Method_Sec[安全代理/Security Agent: Add a security analysis agent for mitigation]\n        Results[关键结果/Results: Security agent improves resilience but is itself vulnerable to advanced attacks] --> Results_Resilience[韧性提升/Improved Resilience: coder-reviewer-tester is more resilient]\n        Results --> Results_Vulnerability[新漏洞/New Vulnerability: Poisonous few-shot examples increase attack success to 71.95%]"
    },
    {
      "title": "Proceedings First Workshop on Adaptable Cloud Architectures",
      "authors": "Giuseppe De Palma, Saverio Giallorenzo",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.22054",
      "code": null,
      "tags": [],
      "day": "2025-12-29",
      "thumbnail": null,
      "contributions": "",
      "summary": "",
      "mindmap": ""
    },
    {
      "title": "HALF: Process Hollowing Analysis Framework for Binary Programs with the Assistance of Kernel Modules",
      "authors": "Zhangbo Long, Letian Sha, Jiaye Pan, Dongpeng Xu, Yifei Huang, Fu Xiao",
      "institution": "Nanjing University of Posts and Telecommunications, The University of New Hampshire",
      "link": "https://arxiv.org/pdf/2512.22043",
      "code": null,
      "tags": [
        "binary analysis",
        "process hollowing",
        "dynamic binary instrumentation",
        "kernel module",
        "fine-grained analysis",
        "malware analysis"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e19e32f77dc6c92df186a9244b45aa21db814a27ce5e27275643fa1e71537cf7_w640_q70.webp",
      "contributions": "1. Proposes a new binary program analysis framework that uses a kernel module to extend the capabilities of traditional dynamic binary instrumentation. 2. Introduces a novel method to construct the analysis environment within a container process using process hollowing techniques, enabling decoupled analysis. 3. Demonstrates the framework's practical value through validation with benchmarks, actual exploit programs, and malicious code on the Windows platform.",
      "summary": "This paper proposes HALF, a new binary program analysis framework designed to improve the usability and performance of fine-grained analysis. It combines kernel modules with process hollowing to decouple the analysis environment from the target program, reducing its impact. The framework is validated on Windows, showing effectiveness in analyzing exploits and malware.",
      "mindmap": "graph TB\n        A[HALF: Process Hollowing Analysis Framework<br>HALF: 进程镂空分析框架] --> B(Problem: Fine-grained binary analysis has deployability and performance issues<br>问题: 细粒度二进制分析存在部署性和性能问题)\n        A --> C(Method: Uses kernel modules & process hollowing for decoupled analysis<br>方法: 使用内核模块和进程镂空进行解耦分析)\n        A --> D(Results: Validated on Windows, effective for exploit/malware analysis<br>结果: 在Windows上验证，对漏洞利用/恶意软件分析有效)"
    },
    {
      "title": "Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications",
      "authors": "Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer",
      "institution": "University of Illinois at Urbana-Champaign, IBM Research",
      "link": "https://arxiv.org/pdf/2512.22113",
      "code": null,
      "tags": [
        "agent system",
        "root cause analysis",
        "service dependency graph",
        "program dependence graph",
        "LLM agent",
        "cloud incident"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp",
      "contributions": "1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment.",
      "summary": "This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents.",
      "mindmap": "graph TB\n        A[Agentic Structured Graph Traversal for Root Cause Analysis<br/>基于智能体结构化图遍历的云应用根因分析] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br/>High cost of unresolved cloud incidents; Need for effective root cause analysis]\n        C[主要方法/Method<br/>PRAXIS: LLM-driven traversal over Service Dependency Graph and Program Dependence Graph]\n        D[关键结果/Results<br/>3.1x higher RCA accuracy, 3.8x lower token consumption vs. ReAct baselines]"
    },
    {
      "title": "Managing the Stochastic: Foundations of Learning in Neuro-Symbolic Systems for Software Engineering",
      "authors": "Matthew Thompson",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.20660",
      "code": null,
      "tags": [
        "agent system",
        "dual-state architecture",
        "atomic action pairs",
        "guard functions",
        "neuro-symbolic systems",
        "code generation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a73fceac46d6997904de43696e8db407d645c6e4388012a9e24a3b9565e06fb_w640_q70.webp",
      "contributions": "1. Proposes a control boundary that treats the LLM as a stochastic environment component, not the decision-making agent, to manage its unpredictability. 2. Formalizes a Dual-State Architecture separating deterministic workflow state from stochastic environment state. 3. Introduces Atomic Action Pairs and Guard Functions to couple generation with verification as indivisible transactions, projecting probabilistic outputs onto observable workflow state.",
      "summary": "This paper addresses the problem of stochastic failures in AI coding agents by proposing a neuro-symbolic architectural framework that treats the LLM as part of the environment. The method uses a Dual-State Architecture with Atomic Action Pairs and Guard Functions to separate deterministic control from stochastic generation. The main conclusion is that such architectural constraints can significantly improve task success rates for qualified models, potentially substituting for parameter scale in achieving reliable code generation.",
      "mindmap": "graph LR\n    A[Managing the Stochastic<br>管理随机性] --> B[Problem: LLM-based agents prone to stochastic failures<br>问题: 基于LLM的智能体易受随机性故障影响]\n    A --> C[Method: Dual-State Architecture, Atomic Action Pairs, Guard Functions<br>方法: 双态架构, 原子动作对, 守卫函数]\n    A --> D[Results: Improved success rates, architectural constraints can substitute for scale<br>结果: 成功率提升, 架构约束可替代模型规模]"
    },
    {
      "title": "Process Analytics -- Data-driven Business Process Management",
      "authors": "Matthias Stierle, Karsten Kraume, Martin Matzner",
      "institution": "Friedrich-Alexander University Erlangen-Nürnberg, University of Münster",
      "link": "https://arxiv.org/pdf/2512.20703",
      "code": null,
      "tags": [
        "Business Process Management",
        "Process Analytics",
        "Process Mining",
        "Socio-technical Perspective",
        "Data-driven Analysis",
        "Business Process Automation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937a3a879686d02d64d7fdcbd142c2e1c0049f0a58b9c32c9a47215b24c74f1e_w640_q70.webp",
      "contributions": "1. Proposes a new, integrated perspective on data-driven process analysis that combines the analysis process with organizational and stakeholder concerns, moving beyond purely technical views. 2. Conceptualizes the term \"Process Analytics\" and its various dimensions through a combined inductive and deductive research approach. 3. Validates and discusses the conceptualization by contrasting it with a real-life case study of data-driven process analysis and automation in a large company.",
      "summary": "This paper identifies a narrowing focus on the technical aspects of process mining, which overlooks human and organizational factors. To address this, it proposes and conceptualizes \"Process Analytics\" as a new, socio-technical perspective that integrates the analysis process with the organization and its stakeholders. The conceptual framework is discussed and contrasted with a real-world implementation case.",
      "mindmap": "graph LR\n        A[Process Analytics – Data-driven Business Process Management] --> B[核心问题/Problem: 对流程挖掘的认知狭隘化，忽视人机组织因素/Overly narrow focus on process mining, neglecting human & organizational factors]\n        A --> C[主要方法/Method: 提出”流程分析学”新视角，结合归纳与演绎法进行概念化/Proposes ”Process Analytics” perspective, conceptualized via inductive & deductive approach]\n        A --> D[关键结果/Results: 建立多维度概念框架，并通过真实案例进行对比讨论/Establishes multi-dimensional conceptual framework, discussed via real-life case study]"
    },
    {
      "title": "FEM-Bench: A Structured Scientific Reasoning Benchmark for Evaluating Code-Generating LLMs",
      "authors": "Saeed Mohammadzadeh, Erfan Hamdi, Joel Shor, Emma Lejeune",
      "institution": "Boston University, Move37 Labs",
      "link": "https://arxiv.org/pdf/2512.20732",
      "code": null,
      "tags": [
        "llm inference",
        "Finite Element Method (FEM)",
        "Code Generation",
        "LLM Benchmark",
        "Computational Mechanics",
        "Scientific Machine Learning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1933a2d33b13b692f95ee8ddec0a65840af091998d38a7f0154837874636590_w640_q70.webp",
      "contributions": "1. Introduces FEM-Bench, a novel benchmark for evaluating LLMs' ability to generate scientifically valid code for computational mechanics problems. 2. Provides a structured suite of tasks based on finite element methods that enforce physical and numerical constraints for objective evaluation. 3. Presents initial evaluation results showing that state-of-the-art LLMs (e.g., Gemini 3 Pro, GPT-5) still struggle to reliably solve these introductory tasks.",
      "summary": "The paper identifies a lack of benchmarks for evaluating LLMs' scientific reasoning and code generation for physical modeling. It proposes FEM-Bench, a computational mechanics benchmark based on the Finite Element Method, to fill this gap. Initial evaluations show that even advanced LLMs cannot reliably solve all its tasks, establishing a foundation for tracking progress in AI-generated scientific code.",
      "mindmap": "graph LR\n        A[FEM-Bench Paper] --> B[核心问题/Problem: 缺乏评估LLM生成科学物理模型代码能力的基准/Lack of benchmark for evaluating LLMs' ability to generate scientifically valid physical model code]\n        A --> C[主要方法/Method: 提出基于计算力学和有限元法的结构化基准/Proposes a structured benchmark based on computational mechanics and the Finite Element Method]\n        A --> D[关键结果/Results: 先进LLM无法可靠解决所有基准任务，为跟踪进展奠定基础/State-of-the-art LLMs cannot reliably solve all benchmark tasks, establishing a foundation for tracking progress]"
    },
    {
      "title": "One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents",
      "authors": "Zhaoxi Zhang, Yitong Duan, Yanzhi Zhang, Yiming Xu, Jiyan He, Yunfang Wu",
      "institution": "Affiliation not explicitly stated in provided text. Email domains suggest potential institutions, but cannot be reliably inferred from given content.",
      "link": "https://arxiv.org/pdf/2512.20957",
      "code": null,
      "tags": [
        "repository-level code understanding",
        "LLM agent",
        "reinforcement learning",
        "tool usage",
        "code navigation",
        "execution-aware"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6254efa02c0725684b783a26c76c1825bf8aaa25aee61fb7aaea40887f0efc46_w640_q70.webp",
      "contributions": "1. Proposes RepoNavigator, an LLM agent that uses a single, execution-aware tool (\"jump to definition\") for navigating code repositories, simplifying agent control and aligning with code execution logic. 2. Introduces an end-to-end Reinforcement Learning (RL) training method for the agent directly from a pretrained model, eliminating the need for closed-source model distillation. 3. Demonstrates state-of-the-art performance on repository-level issue localization, showing that smaller RL-trained models (e.g., 7B) can outperform larger baseline models (e.g., 14B, 32B) and even closed-source models like Claude-3.7.",
      "summary": "The paper addresses the challenge of locating code to modify in large software repositories. It proposes RepoNavigator, an LLM agent trained with Reinforcement Learning to use a single \"jump to definition\" tool for navigation. Experiments show this approach achieves state-of-the-art performance, with smaller models outperforming larger baselines, proving the efficiency of a simple, execution-aware tool combined with RL training.",
      "mindmap": "graph LR\n    A[One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents] --> B[核心问题/Problem: Locating modification points in large, complex code repositories is difficult]\n    A --> C[主要方法/Method: RepoNavigator agent with a single ”jump to definition” tool, trained end-to-end via RL]\n    A --> D[关键结果/Results: SOTA performance; smaller RL-trained models outperform larger baselines and closed-source models]"
    },
    {
      "title": "Artificial or Just Artful? Do LLMs Bend the Rules in Programming?",
      "authors": "Oussama Ben Sghaier, Kevin Delcourt, Houari Sahraoui",
      "institution": "Queen’s University, Université de Montréal",
      "link": "https://arxiv.org/pdf/2512.21028",
      "code": null,
      "tags": [
        "code generation",
        "large language models",
        "code generation",
        "unit tests",
        "prompting strategies",
        "alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da2f579fa34b3f18209ec129b76141b35f2706432dd12ec1d06d02f9b23b4198_w640_q70.webp",
      "contributions": "1. Investigates the conflict between LLM pretraining objectives (exploit all signals) and alignment choices (follow rules) in the context of code generation with unit tests. 2. Designs a systematic experimental framework using the BigCodeBench (Hard) dataset with five prompting conditions to manipulate test visibility and restrictions. 3. Identifies and analyzes recurring adaptation strategies used by LLMs when exposed to conflicting signals, with test-driven refinement being the most frequent.",
      "summary": "This paper investigates how Large Language Models (LLMs) adapt their code generation strategies when given access to unit tests under different prompting conditions that may restrict their use. The authors evaluate five models on the BigCodeBench dataset, finding that test visibility dramatically improves correctness and that models employ specific adaptation strategies, like test-driven refinement, to reconcile pretraining objectives with alignment constraints.",
      "mindmap": "graph LR\n        A[Artificial or Just Artful? Do LLMs Bend the Rules in Programming?] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs在代码生成中<br>预训练目标与对齐要求的冲突/Conflict between pretraining and alignment in LLM code generation]\n        C --> C1[设计五种提示条件<br>操作测试可见性与限制/Design five prompting conditions manipulating test visibility & restrictions]\n        C --> C2[评估五个LLM在BigCodeBench上的<br>正确性、相似性等/Evaluate five LLMs on BigCodeBench for correctness, similarity, etc.]\n        D --> D1[测试可见性显著改变性能<br>正确性近乎翻倍/Test visibility dramatically alters performance, correctness nearly doubles]\n        D --> D2[识别出四种重复的适应策略<br>测试驱动优化最常见/Identify four recurring adaptation strategies, test-driven refinement most frequent]"
    },
    {
      "title": "Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking",
      "authors": "Yifan Huang, Xiaojun Jia, Wenbo Guo, Yuqiang Sun, Yihao Huang, Chong Wang, Yang Liu",
      "institution": "Nanyang Technological University, National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.21236",
      "code": null,
      "tags": [
        "llm security",
        "jailbreaking",
        "malicious code generation",
        "prompt engineering",
        "time-division selection",
        "security alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8055c0aba333e58d26f29d81acab1f88f570f09122f7fafd38ac1c952dad67b1_w640_q70.webp",
      "contributions": "1. Proposes SPELL, a novel testing framework specifically designed to evaluate security alignment weaknesses in LLMs for malicious code generation. 2. Introduces a time-division selection strategy to systematically construct jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset. 3. Conducts extensive evaluation across multiple advanced code models and real-world tools, revealing significant security gaps and providing insights for improving AI safety.",
      "summary": "The paper addresses the security risk of LLMs being exploited to generate malicious code, a gap in existing jailbreaking research. It proposes the SPELL framework, which uses a time-division strategy to construct effective jailbreaking prompts. The evaluation shows high attack success rates across several models, revealing critical vulnerabilities in current AI safety alignments for code generation.",
      "mindmap": "graph LR\n        A[SPELL: Sentence Pairing Exploration for LLM Limitation-breaking] --> B[核心问题/Problem: LLMs可能被用于生成恶意代码/LLMs can be exploited for malicious code generation]\n        A --> C[主要方法/Method: 基于时间划分选择的提示构建框架/Time-division selection prompt construction framework]\n        A --> D[关键结果/Results: 在多模型上实现高攻击成功率/High attack success rates across multiple models]"
    },
    {
      "title": "Assessing the Software Security Comprehension of Large Language Models",
      "authors": "Mohammed Latif Siddiq, Natalie Sekerak, Antonio Karam, Maria Leal, Arvin Islam-Gomes, Joanna C. S. Santos",
      "institution": "University of Notre Dame",
      "link": "https://arxiv.org/pdf/2512.21238",
      "code": null,
      "tags": [
        "software security assessment",
        "Bloom's Taxonomy",
        "knowledge boundary",
        "misconception patterns"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b3809be1ff4cae9ad7acb47676829cd58ca3ea614efa57d9121857f85d97fc7_w640_q70.webp",
      "contributions": "1. Introduced a systematic evaluation framework using Bloom's Taxonomy to assess LLMs' software security comprehension across six cognitive levels. 2. Proposed the concept of a \"software security knowledge boundary\" to identify the highest reliable cognitive performance level for an LLM. 3. Identified and documented 51 recurring misconception patterns made by LLMs in software security tasks.",
      "summary": "This paper systematically evaluates the software security comprehension of five leading LLMs using Bloom's Taxonomy as a framework across diverse datasets. The results show that while LLMs perform well on lower-level cognitive tasks like recalling facts, their performance significantly degrades on higher-order tasks requiring reasoning and secure system creation. The study introduces a knowledge boundary to quantify reliable performance limits and identifies common misconception patterns.",
      "mindmap": "graph LR\n    A[Assessing LLM Software Security Comprehension<br/>评估LLM软件安全理解] --> B{核心问题/Problem};\n    A --> C{主要方法/Method};\n    A --> D{关键结果/Results};\n    B --> B1[LLMs' Security Expertise Unclear<br/>LLM安全专业知识不明];\n    C --> C1[Framework: Bloom's Taxonomy<br/>框架: 布鲁姆分类法];\n    C --> C2[Datasets: MCQs, Code, Courses, Case Studies<br/>数据集: 选择题, 代码, 课程, 案例];\n    D --> D1[Good on Low-Level Tasks<br/>低级任务表现好];\n    D --> D2[Poor on High-Order Reasoning<br/>高阶推理表现差];\n    D --> D3[Knowledge Boundary & Misconceptions<br/>知识边界与误解模式];"
    },
    {
      "title": "Flow Gym",
      "authors": "Francesco Banelli, Antonio Terpin, Alan Bonomi, Raffaello D'Andrea",
      "institution": "ETH Zürich",
      "link": "https://arxiv.org/pdf/2512.20642",
      "code": "https://github.com/antonioterpin/flowgym",
      "tags": [
        "optical flow / particle image velocimetry",
        "flow-field quantification",
        "synthetic data generation",
        "JAX",
        "reinforcement learning environment",
        "benchmarking toolkit"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e5173f537ce94701f33cf868d525b0c8117477e440d08e96c43c778b59915a4_w640_q70.webp",
      "contributions": "1. Introduces Flow Gym, a unified toolkit for research and deployment of flow-field quantification methods, inspired by OpenAI Gym. 2. Provides a modular, stateless interface for testing, training, and deploying both learning-based and classical algorithms using a synthetic image generation engine (SynthPix). 3. Offers stable JAX re-implementations and integrations of existing algorithms for standardized benchmarking.",
      "summary": "The paper presents Flow Gym, a toolkit designed to standardize the development and evaluation of algorithms for quantifying flow fields from particle images. It provides a unified, modular interface inspired by reinforcement learning environments, enabling easy testing and training of methods using synthetic data. The main outcome is a framework that facilitates reproducible research and benchmarking in flow-field quantification.",
      "mindmap": "graph LR\n    A[Flow Gym] --> B[核心问题/Problem: 流场量化算法缺乏标准化测试框架/Lack of standardized framework for flow-field quantification algorithms];\n    A --> C[主要方法/Method: 提供受RL启发的统一接口与合成数据引擎/Provides RL-inspired unified interface & synthetic data engine];\n    A --> D[关键结果/Results: 用于算法开发与基准测试的JAX兼容工具包/JAX-compatible toolkit for algorithm dev & benchmarking];"
    },
    {
      "title": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows",
      "authors": "Ivan Daunis",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19769",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e158baf642d33624c0967b1dcd509fbc3876a4bc52a539d4b6e7c800995b42_w640_q70.webp",
      "contributions": "",
      "summary": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows",
      "mindmap": ""
    },
    {
      "title": "Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models",
      "authors": "Wang Bin, Ao Yang, Kedan Li, Aofan Liu, Hui Li, Guibo Luo, Weixiang Huang, Yan Zhuang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19758",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45aa033e5d42a870c8059ab54cb6cefa331610516ad0bef063a9ce423cb132dc_w640_q70.webp",
      "contributions": "",
      "summary": "Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Larger Is Not Always Better: Leveraging Structured Code Diffs for Comment Inconsistency Detection",
      "authors": "Phong Nguyen, Anh M. T. Bui, Phuong T. Nguyen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19883",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb02d6486b7648f66dabcf681fd3aa648ad9d4d97929893d6c718261d7cdd896_w640_q70.webp",
      "contributions": "",
      "summary": "Larger Is Not Always Better: Leveraging Structured Code Diffs for Comment Inconsistency Detection",
      "mindmap": ""
    },
    {
      "title": "Towards Analysing Invoices and Receipts with Amazon Textract",
      "authors": "Sneha Oommen, Gabby Sanchez, Cassandra T. Britto, Di Wang, Jordan Chiou, Maria Spichkova",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19958",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8027409d62cb78b143f7d21e2c36fb093ab6a4978dfa9fe88c1a8339d40565fd_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Analysing Invoices and Receipts with Amazon Textract",
      "mindmap": ""
    },
    {
      "title": "Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?",
      "authors": "Zhe Yin, Xiaodong Gu, Beijun Shen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19980",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/612b57ba54262082ae033612387571cddc86ac826d14c6f5b1ba4c241011b3b9_w640_q70.webp",
      "contributions": "",
      "summary": "Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?",
      "mindmap": ""
    },
    {
      "title": "BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations",
      "authors": "Yanjing Yang, He Zhang, Bohan Liu, Jinwei Xu, Jinghao Hu, Liming Dong, Zhewen Mao, Dongxue Pan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19997",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/70a323ff0c6b620555f25fedefe7b12761782c69ac299e6333a9bde71caf7b04_w640_q70.webp",
      "contributions": "",
      "summary": "BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations",
      "mindmap": ""
    },
    {
      "title": "Detecting Non-Optimal Decisions of Embodied Agents via Diversity-Guided Metamorphic Testing",
      "authors": "Wenzhao Wu, Yahui Tang, Mingfei Cheng, Wenbing Tang, Yuan Zhou, Yang Liu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20083",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2f6a93b0ca9601c38b73ad3e8c062333303a8f9538415f2546b2a923116462a_w640_q70.webp",
      "contributions": "",
      "summary": "Detecting Non-Optimal Decisions of Embodied Agents via Diversity-Guided Metamorphic Testing",
      "mindmap": ""
    },
    {
      "title": "AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration",
      "authors": "Ruiqi Wang, Xinchen Wang, Cuiyun Gao, Chun Yong Chong, Xin Xia, Qing Liao",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20159",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9b4276c369f7cc83453b7385f456424f32c6a43157de7895979a0b4e9cd33bf_w640_q70.webp",
      "contributions": "",
      "summary": "AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration",
      "mindmap": ""
    },
    {
      "title": "Well Begun is Half Done: Location-Aware and Trace-Guided Iterative Automated Vulnerability Repair",
      "authors": "Zhenlei Ye, Xiaobing Sun, Sicong Cao, Lili Bo, Bin Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20203",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/689696655ef1a605fe01d3f671d2e7d5eb99f438f83f110a88f303de369b7dc4_w640_q70.webp",
      "contributions": "",
      "summary": "Well Begun is Half Done: Location-Aware and Trace-Guided Iterative Automated Vulnerability Repair",
      "mindmap": ""
    },
    {
      "title": "Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds",
      "authors": "Tarik Houichime, Abdelghani Souhar, Younes El Amrani",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20245",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1001e3781e678219db00950fa667bbe46bbaa2f98cd7e5064d91ede9a2cbc6fe_w640_q70.webp",
      "contributions": "",
      "summary": "Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds",
      "mindmap": ""
    },
    {
      "title": "Auditing Reproducibility in Non-Targeted Analysis: 103 LC/GC--HRMS Tools Reveal Temporal Divergence Between Openness and Operability",
      "authors": "Sarah Alsubaie, Sakhaa Alsaedi, Xin Gao",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20279",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8461db004ea160aa8af9906d632218283ad8a987409958ac11bd49b4d9c79d3c_w640_q70.webp",
      "contributions": "",
      "summary": "Auditing Reproducibility in Non-Targeted Analysis: 103 LC/GC--HRMS Tools Reveal Temporal Divergence Between Openness and Operability",
      "mindmap": ""
    },
    {
      "title": "Toward Explaining Large Language Models in Software Engineering Tasks",
      "authors": "Antonio Vitale, Khai-Nguyen Nguyen, Denys Poshyvanyk, Rocco Oliveto, Simone Scalabrino, Antonio Mastropaolo",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20328",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2779c954fdfbaebf8f7d7d236f2c601ab45082cae14229886e2b749d6d8cd669_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Explaining Large Language Models in Software Engineering Tasks",
      "mindmap": ""
    },
    {
      "title": "Comment Traps: How Defective Commented-out Code Augment Defects in AI-Assisted Code Generation",
      "authors": "Yuan Huang, Yukang Zhou, Xiangping Chen, Zibin Zheng",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20334",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96e3cbe7534ab0200cc8de3dd256a72556796af563c3231e3ae3fe377c613650_w640_q70.webp",
      "contributions": "",
      "summary": "Comment Traps: How Defective Commented-out Code Augment Defects in AI-Assisted Code Generation",
      "mindmap": ""
    },
    {
      "title": "A Comprehensive Study of Bugs in Modern Distributed Deep Learning Systems",
      "authors": "Xiaoxue Ma, Wanwei Zhan, Jiale Chen, Yishu Li, Jacky Keung, Federica Sarro",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20345",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68f886744860ac84868ef1c9d8e90cca2237c662d2aa29c92c0a15e76969507a_w640_q70.webp",
      "contributions": "",
      "summary": "A Comprehensive Study of Bugs in Modern Distributed Deep Learning Systems",
      "mindmap": ""
    },
    {
      "title": "Identifying Appropriately-Sized Services with Deep Reinforcement Learning",
      "authors": "Syeda Tasnim Fabiha, Saad Shafiq, Wesley Klewerton Guez Assunção, Nenad Medvidović",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20381",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/295a39edb17ec8824ad34080df5c2a960bf42d578ae6e9a2db55f3775d90e225_w640_q70.webp",
      "contributions": "",
      "summary": "Identifying Appropriately-Sized Services with Deep Reinforcement Learning",
      "mindmap": ""
    },
    {
      "title": "iblock: Accurate and Scalable Bitcoin Simulations with OMNeT++",
      "authors": "Niccolò Scatena, Pericle Perazzo, Giovanni Nardini",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20402",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6c948c2f471538c4ad6962b3c03e4c869eb3e5bfdea61004d6f568b880cedc1e_w640_q70.webp",
      "contributions": "",
      "summary": "iblock: Accurate and Scalable Bitcoin Simulations with OMNeT++",
      "mindmap": ""
    },
    {
      "title": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs",
      "authors": "Narges Khakpour, Nicolas Berthier",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20396",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6bdfa1cdb9c42587497d38e68d6ea55a15a3372a5c197a241c9e2cf0c52caf1_w640_q70.webp",
      "contributions": "",
      "summary": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs",
      "mindmap": ""
    },
    {
      "title": "SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization",
      "authors": "Revanth Gangi Reddy, Ye Liu, Wenting Zhao, JaeHyeok Doo, Tarun Suresh, Daniel Lee, Caiming Xiong, Yingbo Zhou, Semih Yavuz, Shafiq Joty",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20482",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61a2f4887d3f7e1f76ef9da213d8cbb2fd86e68bd8a8206e3a2e53677aa7151e_w640_q70.webp",
      "contributions": "",
      "summary": "SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization",
      "mindmap": ""
    },
    {
      "title": "Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration",
      "authors": "Victor Stasiuc, Round Table Collaboration",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17956",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57a72b745466d47b8a8056586ccf86e4e40bd0ac42a76b0061c6576b563f4532_w640_q70.webp",
      "contributions": "",
      "summary": "Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration",
      "mindmap": ""
    },
    {
      "title": "Specification and Detection of LLM Code Smells",
      "authors": "Brahim Mahmoudi, Zacharie Chenail-Larcher, Naouel Moha, Quentin Stievenert, Florent Avellaneda",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18020",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cee6a3c076b484391912c8b6083413504d86a9475e81592b3004ce305e4f9c4_w640_q70.webp",
      "contributions": "",
      "summary": "Specification and Detection of LLM Code Smells",
      "mindmap": ""
    },
    {
      "title": "Detecting Flaky Tests in Quantum Software: A Dynamic Approach",
      "authors": "Dongchan Kim, Hamidreza Khoramrokh, Lei Zhang, Andriy Miranskyy",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18088",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d0f2432ccc8ddbb1d6847d4ef5de32df143c118ab7994523048741c8d3083cc_w640_q70.webp",
      "contributions": "",
      "summary": "Detecting Flaky Tests in Quantum Software: A Dynamic Approach",
      "mindmap": ""
    },
    {
      "title": "From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems",
      "authors": "Marcos Ortiz, Justin Hill, Collin Overbay, Ingrida Semenec, Frederic Sauve-Hoover, Jim Schwoebel, Joel Shor",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18080",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0154cb62824a09bcbf4a6476b89c563b0f548b2e6721f62b4207082ab09ee544_w640_q70.webp",
      "contributions": "",
      "summary": "From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems",
      "mindmap": ""
    },
    {
      "title": "From Coverage to Causes: Data-Centric Fuzzing for JavaScript Engines",
      "authors": "Kishan Kumar Ganguly, Tim Menzies",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18102",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/509a927741960d2c63062790fd8bebe6a6a22769c29f6985c39fb001039d9fab_w640_q70.webp",
      "contributions": "",
      "summary": "From Coverage to Causes: Data-Centric Fuzzing for JavaScript Engines",
      "mindmap": ""
    },
    {
      "title": "Holistic Evaluation of State-of-the-Art LLMs for Code Generation",
      "authors": "Le Zhang, Suresh Kothari",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18131",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e08a9f551315e560db6179abac192d75f62ffe1b185263cb90784842012ac802_w640_q70.webp",
      "contributions": "",
      "summary": "Holistic Evaluation of State-of-the-Art LLMs for Code Generation",
      "mindmap": ""
    },
    {
      "title": "Understanding Typing-Related Bugs in Solidity Compiler",
      "authors": "Lantian Li, Yue Pan, Dan Wang, Jingwen Wu, Zhongxing Yu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18182",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1edd902d54a210d4adc69bf8b9c2e90b98ee4461ca8ff9631e5105665c2af358_w640_q70.webp",
      "contributions": "",
      "summary": "Understanding Typing-Related Bugs in Solidity Compiler",
      "mindmap": ""
    },
    {
      "title": "Toward Efficient Testing of Graph Neural Networks via Test Input Prioritization",
      "authors": "Lichen Yang, Qiang Wang, Zhonghao Yang, Daojing He, Yu Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18228",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9987a54aec669e601a71ba8b0ee7d5434ba0c73d08a66e20538cf347a09669cd_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Efficient Testing of Graph Neural Networks via Test Input Prioritization",
      "mindmap": ""
    },
    {
      "title": "Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective",
      "authors": "M. Mehdi Kholoosi, Triet Huynh Minh Le, M. Ali Babar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18261",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c527700e49403d8d115fcd9b121714ac7cc66ca4c4917d88ae5eeb6712cf705e_w640_q70.webp",
      "contributions": "",
      "summary": "Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective",
      "mindmap": ""
    },
    {
      "title": "Monitoring Monitorability",
      "authors": "Melody Y. Guan, Miles Wang, Micah Carroll, Zehao Dou, Annie Y. Wei, Marcus Williams, Benjamin Arnav, Joost Huizinga, Ian Kivlichan, Mia Glaese, Jakub Pachocki, Bowen Baker",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18311",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b80143b15f0287eaa0d31decbf1a350d64c8110ec245d21e81c64ae73cd6febc_w640_q70.webp",
      "contributions": "",
      "summary": "Monitoring Monitorability",
      "mindmap": ""
    },
    {
      "title": "VeruSAGE: A Study of Agent-Based Verification for Rust Systems",
      "authors": "Chenyuan Yang, Natalie Neamtu, Chris Hawblitzel, Jacob R. Lorch, Shan Lu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18436",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a6dcac7fed2f39d9b3c88cf4fcec2c0a341fe5463b697a482bfb914d0610c67_w640_q70.webp",
      "contributions": "",
      "summary": "VeruSAGE: A Study of Agent-Based Verification for Rust Systems",
      "mindmap": ""
    },
    {
      "title": "SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios",
      "authors": "Minh V. T. Thai, Tue Le, Dung Nguyen Manh, Huy Phan Nhat, Nghi D. Q. Bui",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18470",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aa84e9ee4a961b04628c969b7317aae944aad76753539183cd0213072cfce14_w640_q70.webp",
      "contributions": "",
      "summary": "SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios",
      "mindmap": ""
    },
    {
      "title": "Toward Training Superintelligent Software Agents through Self-Play SWE-RL",
      "authors": "Yuxiang Wei, Zhiqing Sun, Emily McMilin, Jonas Gehring, David Zhang, Gabriel Synnaeve, Daniel Fried, Lingming Zhang, Sida Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18552",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Training Superintelligent Software Agents through Self-Play SWE-RL",
      "mindmap": ""
    },
    {
      "title": "AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software",
      "authors": "Bin Wang, Wenjie Yu, Yilu Zhong, Hao Yu, Keke Lian, Chaohua Lu, Hongfang Zheng, Dong Zhang, Hui Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18567",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a9235d0c624936af1cfc09fc3a4442da3cad4b4006c63ac0a8fe4392c0673dc_w640_q70.webp",
      "contributions": "",
      "summary": "AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software",
      "mindmap": ""
    },
    {
      "title": "Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design",
      "authors": "Yuchen Li, Handing Wang, Bing Xue, Mengjie Zhang, Yaochu Jin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18682",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d33a421c48ad59f7420161a73adc3cf5979c2e95cd4ded4b6c5ac3a603e0e95_w640_q70.webp",
      "contributions": "",
      "summary": "Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design",
      "mindmap": ""
    },
    {
      "title": "Code2Doc: A Quality-First Curated Dataset for Code Documentation",
      "authors": "Recep Kaan Karaman, Meftun Akarsu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18748",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b6da5096797c358f77d8022914985853333b12b54cf68425fe470f42a60638b_w640_q70.webp",
      "contributions": "",
      "summary": "Code2Doc: A Quality-First Curated Dataset for Code Documentation",
      "mindmap": ""
    },
    {
      "title": "Misbehavior Forecasting for Focused Autonomous Driving Systems Testing",
      "authors": "M M Abid Naziri, Stefano Carlo Lambertenghi, Andrea Stocco, Marcelo d'Amorim",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18823",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d28332e6cbfc968e2f126c36ef57e40da98c2cdac079ecc02d7dc88024294d89_w640_q70.webp",
      "contributions": "",
      "summary": "Misbehavior Forecasting for Focused Autonomous Driving Systems Testing",
      "mindmap": ""
    },
    {
      "title": "What Drives Issue Resolution Speed? An Empirical Study of Scientific Workflow Systems on GitHub",
      "authors": "Khairul Alam, Banani Roy",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18852",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a91b214a3f60d6731e87235c417f1926ce91f9c4cae6b181b384b9e7b05c01f2_w640_q70.webp",
      "contributions": "",
      "summary": "What Drives Issue Resolution Speed? An Empirical Study of Scientific Workflow Systems on GitHub",
      "mindmap": ""
    },
    {
      "title": "An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects",
      "authors": "Shaokang Jiang, Daye Nam",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18925",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2089c7618775b9b9cdc54e25f2f7b14898adbf8c1ce8308d624be1f22c566408_w640_q70.webp",
      "contributions": "",
      "summary": "An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects",
      "mindmap": ""
    },
    {
      "title": "FASTRIC: Prompt Specification Language for Verifiable LLM Interactions",
      "authors": "Wen-Long Jin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18940",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5496d384aad293547e961ed7f2ce4568121f384e9e0b977144128668dc8445cb_w640_q70.webp",
      "contributions": "",
      "summary": "FASTRIC: Prompt Specification Language for Verifiable LLM Interactions",
      "mindmap": ""
    },
    {
      "title": "Scrum Sprint Planning: LLM-based and algorithmic solutions",
      "authors": "Yuwon Yoon, Kevin Iwan, Madeleine Zwart, Xiaohan Qin, Hina Lee, Maria Spichkova",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18966",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbba1000019eeb305645e5c8c1e960d23972872aca223b91a22bf2273fe7382d_w640_q70.webp",
      "contributions": "",
      "summary": "Scrum Sprint Planning: LLM-based and algorithmic solutions",
      "mindmap": ""
    },
    {
      "title": "Modular Layout Synthesis (MLS): Front-end Code via Structure Normalization and Constrained Generation",
      "authors": "Chong Liu, Ming Zhang, Fei Li, Hao Zhou, Xiaoshuang Chen, Ye Yuan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18996",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bc934518ca031428cca5fd8c00520837bb98e48a55a7433a62c9c6ec593d172_w640_q70.webp",
      "contributions": "",
      "summary": "Modular Layout Synthesis (MLS): Front-end Code via Structure Normalization and Constrained Generation",
      "mindmap": ""
    },
    {
      "title": "PEAK: A Performance Engineering AI-Assistant for GPU Kernels Powered by Natural Language Transformations",
      "authors": "Muhammad Usman Tariq, Abhinav Jangda, Angelica Moreira, Madan Musuvathi, Tyler Sorensen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19018",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/439d8019fabcd76a49be539fc77d4ae2bfc00f17e5e2185ecf1bd06604924e4b_w640_q70.webp",
      "contributions": "",
      "summary": "PEAK: A Performance Engineering AI-Assistant for GPU Kernels Powered by Natural Language Transformations",
      "mindmap": ""
    },
    {
      "title": "BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation",
      "authors": "Mahir Labib Dihan, Sadif Ahmed, Md Nafiu Rahman",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19122",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf739862e73c646805e217bdf5e2cd5a0f6ec312b673bc4801a828112773cb1d_w640_q70.webp",
      "contributions": "",
      "summary": "BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation",
      "mindmap": ""
    },
    {
      "title": "University Rents Enabling Corporate Innovation: Mapping Academic Researcher Coding and Discursive Labour in the R Language Ecosystem",
      "authors": "Xiaolan Cai, Mathieu O'Neil, Stefano Zacchiroli",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19153",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4fa74baba8cc4201da92e76936c3c5ee2263734f0d3691411e21f6034b3d1130_w640_q70.webp",
      "contributions": "",
      "summary": "University Rents Enabling Corporate Innovation: Mapping Academic Researcher Coding and Discursive Labour in the R Language Ecosystem",
      "mindmap": ""
    },
    {
      "title": "Semantically-Equivalent Transformations-Based Backdoor Attacks against Neural Code Models: Characterization and Mitigation",
      "authors": "Junyao Ye, Zhen Li, Xi Tang, Shouhuai Xu, Deqing Zou, Zhongsheng Yuan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19215",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e737e397a7b3abd370c7787c30a3c048ffd5544877e123bf750070107c4a6f8_w640_q70.webp",
      "contributions": "",
      "summary": "Semantically-Equivalent Transformations-Based Backdoor Attacks against Neural Code Models: Characterization and Mitigation",
      "mindmap": ""
    },
    {
      "title": "A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis",
      "authors": "Katharina Stengg, Christian Macho, Martin Pinzger",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19481",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83f5edcaed3e66cf570a1118c40709f58e2f28ea874fce90d48d26c98b1618e8_w640_q70.webp",
      "contributions": "",
      "summary": "A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis",
      "mindmap": ""
    },
    {
      "title": "Beyond Language Boundaries: Uncovering Programming Language Families for Code Language Models",
      "authors": "Shangbo Yun, Xiaodong Gu, Jianghong Huang, Beijun Shen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19509",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0f18c1ffcb7a64966a1ef778f8e8147966017df0eef1de11cbbbc67539b5f0e_w640_q70.webp",
      "contributions": "",
      "summary": "Beyond Language Boundaries: Uncovering Programming Language Families for Code Language Models",
      "mindmap": ""
    },
    {
      "title": "More code, less validation: Risk factors for over-reliance on AI coding tools among scientists",
      "authors": "Gabrielle O'Brien, Alexis Parker, Nasir Eisty, Jeffrey Carver",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19644",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fa42c82b2739bd1b4c7111c0c7d29876d12dbca90ed48e9b300fd1778d6e033_w640_q70.webp",
      "contributions": "",
      "summary": "More code, less validation: Risk factors for over-reliance on AI coding tools among scientists",
      "mindmap": ""
    },
    {
      "title": "Toward Live Noise Fingerprinting in Quantum Software Engineering",
      "authors": "Avner Bensoussan, Elena Chachkarova, Karine Even-Mendoza, Sophie Fortz, Vasileios Klimis",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18667",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d160a181b86cae75d281b58d0cfe8931c29e5725f4c44ec2695ca299321e15da_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Live Noise Fingerprinting in Quantum Software Engineering",
      "mindmap": ""
    },
    {
      "title": "SpIDER: Spatially Informed Dense Embedding Retrieval for Software Issue Localization",
      "authors": "Shravan Chaudhari, Rahul Thomas Jacob, Mononito Goswami, Jiajun Cao, Shihab Rashid, Christian Bock",
      "institution": "Johns Hopkins University, AWS AI Labs",
      "link": "https://arxiv.org/pdf/2512.16956",
      "code": null,
      "tags": [
        "llm inference",
        "dense embedding retrieval",
        "graph-based exploration",
        "BM25",
        "LLM-based reasoning",
        "code localization"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c743ebe3d40c5416b7ff367b0e7e93ca8ff7bf1bd771b2359d8a7333521abcbc_w640_q70.webp",
      "contributions": "",
      "summary": "The paper proposes SpIDER, a method that enhances dense retrieval for code localization by using graph-based exploration of a codebase to gather auxiliary context, which is then reasoned over by an LLM. This approach addresses the limitations of standard embedding methods that underutilize code structure. Empirical results show that SpIDER consistently improves retrieval performance across multiple programming languages.",
      "mindmap": ""
    },
    {
      "title": "SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories",
      "authors": "Lilin Wang, Lucas Ramalho, Alan Celestino, Phuc Anthony Pham, Yu Liu, Umang Kumar Sinha, Andres Portillo, Onassis Osunwa, Gabriel Maduekwe",
      "institution": "Turing",
      "link": "https://arxiv.org/pdf/2512.17419",
      "code": null,
      "tags": [
        "llm inference",
        "SWE-Bench++",
        "automated benchmark generation",
        "pull request harvesting",
        "environment synthesis",
        "test oracle extraction",
        "hint-guided trajectory synthesis",
        "fine-tuning"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces SWE-Bench++, an automated framework that generates software engineering benchmarks by harvesting pull requests from GitHub to create reproducible, execution-based coding tasks across multiple languages. The method involves programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance, with a final step to create training trajectories from failed instances. The main conclusion is that this scalable, multilingual approach provides a valuable benchmark for evaluating and improving LLMs on repository-level code generation, as demonstrated by model performance metrics and fine-tuning improvements.",
      "mindmap": ""
    },
    {
      "title": "When Data Quality Issues Collide: A Large-Scale Empirical Study of Co-Occurring Data Quality Issues in Software Defect Prediction",
      "authors": "Emmanuel Charleson Dapaah, Jens Grabowski",
      "institution": "University of Göttingen",
      "link": "https://arxiv.org/pdf/2512.17460",
      "code": null,
      "tags": [
        "software defect prediction",
        "Explainable Boosting Machines",
        "stratified interaction analysis",
        "class imbalance",
        "class overlap",
        "irrelevant features",
        "attribute noise",
        "outliers"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper conducts a large-scale empirical study using Explainable Boosting Machines and stratified interaction analysis to examine five co-occurring data quality issues in software defect prediction across 374 datasets. It finds that co-occurrence is nearly universal, identifies tipping points for issues like class overlap and imbalance, and reveals context-dependent effects, concluding that no single model performs best under all conditions.",
      "mindmap": ""
    },
    {
      "title": "PathBench-MIL: A Comprehensive AutoML and Benchmarking Framework for Multiple Instance Learning in Histopathology",
      "authors": "Siemen Brussee, Pieter A. Valkema, Jurre A. J. Weijer, Thom Doeleman, Anne M.R. Schrader, Jesper Kers",
      "institution": "Leiden University Medical Center, Utrecht University Medical Center, Amsterdam University Medical Center",
      "link": "https://arxiv.org/pdf/2512.17517",
      "code": null,
      "tags": [
        "others",
        "multiple instance learning",
        "AutoML",
        "feature extraction",
        "whole-slide images",
        "benchmarking",
        "computational pathology"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces PathBench-MIL, an automated machine learning and benchmarking framework designed for Multiple Instance Learning in histopathology. It automates the entire pipeline from preprocessing to model aggregation, enabling standardized and reproducible evaluation of various models and feature extractors on whole-slide image datasets. The main conclusion is that this open-source framework facilitates rapid experimentation and standardization in computational pathology research.",
      "mindmap": ""
    },
    {
      "title": "LLM-based Behaviour Driven Development for Hardware Design",
      "authors": "Rolf Drechsler, Qian Liu",
      "institution": "University of Bremen, DFKI",
      "link": "https://arxiv.org/pdf/2512.17814",
      "code": null,
      "tags": [
        "others",
        "Behavior Driven Development (BDD)",
        "Large Language Models (LLMs)",
        "hardware design",
        "test and verification",
        "natural language processing",
        "Electronic Design Automation (EDA)"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates the use of Large Language Models (LLMs) to automate the generation of behavioral scenarios from textual specifications for Behavior Driven Development (BDD) in hardware design. The core method involves applying LLM-based techniques to interpret specifications and produce high-level behavioral descriptions. The main conclusion is that LLMs offer a promising opportunity to support and automate BDD workflows in hardware design, addressing the manual effort and complexity of current verification practices.",
      "mindmap": ""
    },
    {
      "title": "Enhanced Web User Interface Design Via Cross-Device Responsiveness Assessment Using An Improved HCI-INTEGRATED DL Schemes",
      "authors": "Shrinivass Arunachalam Balasubramanian",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.15775",
      "code": null,
      "tags": [
        "others",
        "Finite Exponential Continuous State Machine (FECSM)",
        "Quokka Nonlinear Difference Swarm Optimization Algorithm (QNDSOA)",
        "Bidirectional Gated Luong and Mish Recurrent Unit (BiGLMRU)",
        "HDBSCAN",
        "min-max normalization",
        "User Interface Change Prediction Index (UICPI)"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a dynamic web UI optimization method that uses a Finite Exponential Continuous State Machine for cross-device responsiveness assessment and a novel Quokka Nonlinear Difference Swarm Optimization Algorithm for design optimization. The core technique involves classifying user experience changes with a Bidirectional Gated Luong and Mish Recurrent Unit model. The main conclusion is that this integrated approach achieves an average fitness of 98.5632% for optimal UI design by incorporating cross-responsiveness assessment and user behavior patterns.",
      "mindmap": ""
    },
    {
      "title": "CodeMem: Architecting Reproducible Agents via Dynamic MCP and Procedural Memory",
      "authors": "Nishant Gaurav, Adit Akarsh, Tejas Ravishankar, Manoj Bajaj",
      "institution": "AgentR",
      "link": "https://arxiv.org/pdf/2512.15813",
      "code": null,
      "tags": [
        "others",
        "CodeAct",
        "procedural memory",
        "deterministic reliability",
        "reusable agentic workflows",
        "Python action space",
        "dynamic MCP"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes CodeMem, an architecture that uses code as procedural memory to build reproducible AI agents. It addresses probabilistic instability in LLM-based agents by shifting workflow logic from volatile context into deterministic, saved code blocks. The main conclusion is that this approach enables the creation of reusable agentic workflows with reliable, deterministic execution.",
      "mindmap": ""
    },
    {
      "title": "Optimizing Agentic Language Model Inference via Speculative Tool Calls",
      "authors": "Daniel Nichols, Prajwal Singhania, Charles Jekel, Abhinav Bhatele, Harshitha Menon",
      "institution": "Lawrence Livermore National Laboratory, University of Maryland",
      "link": "https://arxiv.org/pdf/2512.15834",
      "code": null,
      "tags": [
        "llm inference",
        "speculative tool calls",
        "tool cache",
        "vLLM",
        "prefix-caching"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces system optimizations for language model agents that use external tools, specifically by speculating future tool calls and keeping sequences resident in the inference engine to reduce overhead. These methods lead to significant throughput improvements of hundreds of tokens per second. The authors also propose a new \"tool cache\" API to facilitate adoption of these optimizations.",
      "mindmap": ""
    },
    {
      "title": "OLAF: Towards Robust LLM-Based Annotation Framework in Empirical Software Engineering",
      "authors": "Mia Mohammad Imran, Tarannum Shaila Zaman",
      "institution": "Missouri University of Science and Technology, University of Maryland Baltimore County",
      "link": "https://arxiv.org/pdf/2512.15979",
      "code": null,
      "tags": [
        "empirical software engineering",
        "annotation framework",
        "reliability",
        "calibration",
        "drift",
        "consensus",
        "aggregation",
        "transparency"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This position paper proposes OLAF, a conceptual framework for treating LLM-based annotation as a measurement process in empirical software engineering. It organizes key constructs like reliability, calibration, and drift to address current methodological gaps. The paper concludes that such a framework is necessary to improve the transparency and reproducibility of LLM-assisted annotation in software engineering research.",
      "mindmap": ""
    },
    {
      "title": "Embedding Software Intent: Lightweight Java Module Recovery",
      "authors": "Yirui He, Yuqi Huai, Xingyu Chen, Joshua Garcia",
      "institution": "University of California, Irvine",
      "link": "https://arxiv.org/pdf/2512.15980",
      "code": null,
      "tags": [
        "software architecture recovery",
        "ClassLAR",
        "JPMS",
        "language models",
        "fully-qualified class names",
        "reverse engineering"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces ClassLAR, a lightweight approach for recovering Java modules from monolithic systems by using language models to extract semantic information from fully-qualified class names. The method captures structural and functional intent to map code to architectural modules. The evaluation shows ClassLAR outperforms state-of-the-art techniques in accuracy and is significantly faster in execution time.",
      "mindmap": ""
    },
    {
      "title": "Beyond Blind Spots: Analytic Hints for Mitigating LLM-Based Evaluation Pitfalls",
      "authors": "Ora Nova Fandina, Eitan Farchi, Shmulik Froimovich, Raviv Gal, Wesam Ibraheem, Rami Katan, Alice Podolsky",
      "institution": "IBM Research, Israel",
      "link": "https://arxiv.org/pdf/2512.16272",
      "code": null,
      "tags": [
        "llm inference",
        "llm-as-a-judge",
        "analytic checker",
        "hybrid evaluation",
        "prompt injection",
        "cobol code generation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a hybrid evaluation method that combines an LLM-as-a-Judge (LaaJ) with a lightweight analytic checker that provides domain-specific hints, which are dynamically injected into the judge's prompt. The method was tested on COBOL code generation, where LaaJs alone missed many errors. The results show that the LaaJ+Hints configuration significantly improves error detection coverage and explanation quality, demonstrating the effectiveness of analytic-LLM hybrids for reliable evaluation.",
      "mindmap": ""
    },
    {
      "title": "ParamExplorer: A framework for exploring parameters in generative art",
      "authors": "Julien Gachadoat, Guillaume Lagarde",
      "institution": "University of Bordeaux",
      "link": "https://arxiv.org/pdf/2512.16529",
      "code": null,
      "tags": [
        "generative art",
        "reinforcement learning",
        "parameter exploration",
        "human-in-the-loop",
        "p5.js"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces ParamExplorer, an interactive and modular framework inspired by reinforcement learning to help explore the high-dimensional parameter spaces of generative art algorithms. It allows for exploration guided by human feedback and integrates with existing p5.js projects. The framework implements and evaluates several automated exploration strategies, referred to as agents, to discover aesthetically compelling outputs more efficiently than manual trial-and-error.",
      "mindmap": ""
    },
    {
      "title": "Revisiting the Reliability of Language Models in Instruction-Following",
      "authors": "Jianshuo Dong, Yutong Zhang, Yan Liu, Zhenyu Zhong, Tao Wei, Chao Zhang, Han Qiu",
      "institution": "Tsinghua University, Ant Group",
      "link": "https://arxiv.org/pdf/2512.14754",
      "code": null,
      "tags": [
        "llm evaluation",
        "instruction-following",
        "reliability",
        "data augmentation",
        "benchmark",
        "IFEval++",
        "reliable@k"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces a new metric, reliable@k, and an automated data augmentation pipeline to generate \"cousin prompts\" for evaluating nuance-oriented reliability in LLMs, constructing the IFEval++ benchmark. It finds that current LLMs show significant performance drops (up to 61.8%) with nuanced prompt variations, highlighting a crucial gap in real-world reliability.",
      "mindmap": ""
    },
    {
      "title": "CAPE: Capability Achievement via Policy Execution",
      "authors": "David Ball",
      "institution": "Superficial Labs",
      "link": "https://arxiv.org/pdf/2512.14761",
      "code": null,
      "tags": [
        "post-training",
        "capability engineering",
        "policy execution",
        "specification language",
        "verification",
        "DPO",
        "contextual objectivity",
        "verification-fidelity scaling"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces CAPE, a protocol for Capability Engineering that implements a Specify-&gt;Verify-&gt;Correct-&gt;Train loop to convert requirements into executable specifications and train models to satisfy them by default. It demonstrates that CAPE reduces policy violation rates by 81% compared to DPO and significantly lowers costs and development timelines by using reusable specifications.",
      "mindmap": ""
    },
    {
      "title": "Workflows vs Agents for Code Translation",
      "authors": "Henry Gray, Tom Yotam, Octavian Udrea",
      "institution": "Code Metal",
      "link": "https://arxiv.org/pdf/2512.14762",
      "code": null,
      "tags": [
        "llm inference",
        "Model Context Protocol (MCP)",
        "syntax repair",
        "code translation",
        "MATLAB-to-HDL",
        "agentic framework",
        "conditional retrieval"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper compares two LLM-driven methods for syntax repair in a MATLAB-to-hardware-description-language translation pipeline: a fixed expert-designed workflow and a more autonomous agentic approach using the Model Context Protocol (MCP). The agentic approach, which dynamically selects tools, was more effective at resolving syntax errors, especially for small and mid-sized models, leading to significant downstream improvements in simulation success rates.",
      "mindmap": ""
    },
    {
      "title": "IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection",
      "authors": "Roman Nekrasov, Stefano Fossati, Indika Kumara, Damian Andrew Tamburri, Willem-Jan van den Heuvel",
      "institution": "Jheronimus Academy of Data Science, Tilburg University, Eindhoven University of Technology, University of Sannio",
      "link": "https://arxiv.org/pdf/2512.14792",
      "code": null,
      "tags": [
        "llm inference",
        "Retrieval-Augmented Generation (RAG)",
        "Graph RAG",
        "knowledge injection",
        "error taxonomy",
        "Terraform",
        "IaC-Eval benchmark"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates improving Large Language Model (LLM) generation of Infrastructure as Code (IaC) by injecting structured configuration knowledge using techniques from naive to Graph RAG. The study finds that while knowledge injection significantly boosts technical correctness, LLMs still struggle with nuanced user intent, revealing a \"Correctness-Congruence Gap\" where they are better coders than architects.",
      "mindmap": ""
    },
    {
      "title": "Let the Barbarians In: How AI Can Accelerate Systems Performance Research",
      "authors": "Audrey Cheng, Shu Liu, Melissa Pan, Zhifei Li, Shubham Agarwal, Mert Cemri, Bowen Wang, Alexander Krentsel, Tian Xia, Jongseok Park, Shuo Yang, Jeff Chen, Lakshya Agrawal, Ashwin Naren, Shulu Li, Ruiying Ma, Aditya Desai, Jiarong Xing, Koushik Sen, Matei Zaharia, Ion Stoica",
      "institution": "UC Berkeley",
      "link": "https://arxiv.org/pdf/2512.14806",
      "code": null,
      "tags": [
        "cluster infrastructure",
        "AI-Driven Research for Systems (ADRS)",
        "OpenEvolve",
        "GEPA",
        "ShinkaEvolve",
        "multi-region cloud scheduling",
        "mixture-of-experts load balancing",
        "LLM-based SQL",
        "transaction scheduling"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces AI-Driven Research for Systems (ADRS), a method using AI to automate the generation, evaluation, and refinement of performance-optimizing algorithms for computer systems. Through case studies with frameworks like OpenEvolve, it demonstrates that ADRS can produce solutions matching or surpassing human-designed state-of-the-art. The work outlines best practices for applying ADRS and discusses its potential to shift researcher effort toward problem formulation and strategic oversight.",
      "mindmap": ""
    },
    {
      "title": "Imitation Game: Reproducing Deep Learning Bugs Leveraging an Intelligent Agent",
      "authors": "Mehil B Shah, Mohammad Masudur Rahman, Foutse Khomh",
      "institution": "Dalhousie University, Polytechnique Montreal",
      "link": "https://arxiv.org/pdf/2512.14990",
      "code": null,
      "tags": [
        "fault-tolerance",
        "bug reproduction",
        "LLM",
        "iterative generate-validate-refine",
        "agentic AI"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper presents RepGen, an automated approach that uses an LLM-based intelligent agent to reproduce deep learning bugs by constructing a learning-enhanced context and employing an iterative generate-validate-refine mechanism. It achieves an 80.19% reproduction rate on real-world bugs, significantly outperforming the state-of-the-art, and a developer study confirms it improves success rates and reduces time and cognitive load for bug reproduction.",
      "mindmap": ""
    },
    {
      "title": "SeBERTis: A Framework for Producing Classifiers of Security-Related Issue Reports",
      "authors": "Sogol Masoumzadeh, Yufei Li, Shane McIntosh, Dániel Varró, Lili Wei",
      "institution": "McGill University, University of Waterloo, Linköping University",
      "link": "https://arxiv.org/pdf/2512.15003",
      "code": null,
      "tags": [
        "others",
        "masked language model",
        "fine-tuning",
        "semantic surrogates",
        "deep neural network",
        "BERT"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes SEBERTIS, a framework that fine-tunes bidirectional transformer models (like BERT) as Masked Language Models using semantically equivalent vocabulary (Semantic Surrogates) to create classifiers for security-related issue reports. This method reduces reliance on lexical shortcuts, enabling better detection of complex issues. The resulting classifier significantly outperforms existing ML and LLM baselines in precision, recall, and F1-score, demonstrating high effectiveness for real-time issue triage.",
      "mindmap": ""
    },
    {
      "title": "The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops",
      "authors": "Fanzhe Fu",
      "institution": "Zhejiang University",
      "link": "https://arxiv.org/pdf/2512.15053",
      "code": null,
      "tags": [
        "llm inference",
        "Meta-Prompting Protocol",
        "Adversarial Trinity",
        "DSPy",
        "TextGrad",
        "textual gradients",
        "semantic computation graph"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces the Meta-Prompting Protocol, a framework that formalizes LLM orchestration as a programmable system using an adversarial topology (Generator, Auditor, Optimizer) to treat prompts as differentiable variables. It leverages textual critiques as gradients within a semantic computation graph to mitigate hallucination and improve reliability. The authors demonstrate its theoretical viability with tools like DSPy and TextGrad, proposing a foundation for deterministic \"Observable Software Engineering\" for probabilistic models.",
      "mindmap": ""
    },
    {
      "title": "On Assessing the Relevance of Code Reviews Authored by Generative Models",
      "authors": "Robert Heumüller, Frank Ortmeier",
      "institution": "Otto von Guericke University Magdeburg",
      "link": "https://arxiv.org/pdf/2512.15466",
      "code": null,
      "tags": [
        "llm inference",
        "multi-subjective ranking",
        "code review generation",
        "ChatGPT",
        "human evaluation",
        "CodeReview StackExchange"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a multi-subjective ranking method to evaluate AI-generated code review comments, comparing ChatGPT outputs against top human responses from CodeReview StackExchange. The results show that ChatGPT's comments were ranked significantly better than human-authored ones, even outperforming accepted answers. The method aims to provide a more meaningful assessment of generative AI in code review while highlighting risks of unchecked integration.",
      "mindmap": ""
    },
    {
      "title": "How Do Semantically Equivalent Code Transformations Impact Membership Inference on LLMs for Code?",
      "authors": "Hua Yang, Alejandro Velasco, Thanh Le-Cong, Md Nazmul Haque, Bowen Xu, Denys Poshyvanyk",
      "institution": "North Carolina State University, William & Mary, The University of Melbourne",
      "link": "https://arxiv.org/pdf/2512.15468",
      "code": null,
      "tags": [
        "llm training",
        "membership inference",
        "semantically equivalent code transformation",
        "variable renaming",
        "causal analysis",
        "code obfuscation"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates how semantically equivalent code transformations, such as variable renaming, can be used to evade membership inference detection in large language models for code. It finds that these transformations, especially RenameVariable, can significantly reduce the success of membership inference attacks without substantially harming model performance. The results reveal a critical vulnerability in license compliance enforcement for code LLMs, showing that transformation-based obfuscation can weaken detection of unauthorized code usage.",
      "mindmap": ""
    },
    {
      "title": "FrontierCS: Evolving Challenges for Evolving Intelligence",
      "authors": "Qiuyang Mang, Wenhao Chai, Zhifei Li, Huanzhi Mao, Shang Zhou, Alexander Du, Hanchen Li, Shu Liu, Edwin Chen, Yichuan Wang, Xieting Chu, Zerui Cheng, Yuan Xu, Tian Xia, Zirui Wang, Tianneng Shi, Jianzhu Yao, Yilong Zhao, Qizheng Zhang, Charlie Ruan, Zeyu Shen, Kaiyuan Liu, Runyuan He, Dong Xing, Zerui Li, Zirong Zeng, Yige Jiang, Lufeng Cheng, Ziyi Zhao, Youran Sun, Wesley Zheng, Meiyuwang Zhang, Ruyi Ji, Xuechang Tu, Zihan Zheng, Zexing Chen, Kangyang Zhou, Zhaozi Wang, Jingbang Chen, Aleksandra Korolova, Peter Henderson, Pramod Viswanath, Vijay Ganesh, Saining Xie, Zhuang Liu, Dawn Song, Sewon Min, Ion Stoica, Joseph E. Gonzalez, Jingbo Shang, Alvin Cheung",
      "institution": "UC Berkeley, Princeton University, UCSD, X-camp Academy, Georgia Tech, Stanford University, University of Washington, Nanyang Technological University, University of Toronto, UIUC, University of Michigan, New York University, MIT",
      "link": "https://arxiv.org/pdf/2512.15699",
      "code": null,
      "tags": [
        "benchmarking",
        "benchmark",
        "open-ended problems",
        "competitive programming",
        "NP-hard",
        "automatic evaluation",
        "expert reference solution"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces FrontierCS, a benchmark of 156 open-ended computer science problems where the optimal solution is unknown but can be objectively evaluated, requiring models to generate executable programs. It finds that current frontier reasoning models significantly lag behind human experts, and that merely increasing reasoning budgets or generating workable code does not close this performance gap.",
      "mindmap": ""
    }
  ]
}